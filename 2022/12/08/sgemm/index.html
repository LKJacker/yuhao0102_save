<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zn-ch">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="积累,">










<meta name="description" content="在开始之前，我想提一下，这项工作的大部分都是从对cublas Kepler和Maxwell的sgemm实现的详细研究中得出的。我做了一些适度的改进，但大多数难题都由英伟达的优秀工程师和他们对硬件的专业知识解决了。本文档的目标是传播这些知识，供其他人在自己的代码中使用。我还想联系两篇关于sgemm主题的优秀论文：MAGMA原始论文（http://icl.cs.utk.edu/projectsfile">
<meta name="keywords" content="积累">
<meta property="og:type" content="article">
<meta property="og:title" content="SGEMM实施的完整演练">
<meta property="og:url" content="http://yoursite.com/2022/12/08/sgemm/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="在开始之前，我想提一下，这项工作的大部分都是从对cublas Kepler和Maxwell的sgemm实现的详细研究中得出的。我做了一些适度的改进，但大多数难题都由英伟达的优秀工程师和他们对硬件的专业知识解决了。本文档的目标是传播这些知识，供其他人在自己的代码中使用。我还想联系两篇关于sgemm主题的优秀论文：MAGMA原始论文（http://icl.cs.utk.edu/projectsfile">
<meta property="og:locale" content="zn-ch">
<meta property="og:image" content="http://yoursite.com/img/image-20221208152310575.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208153216716.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208153237832.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208162657316.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208162949337.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208164843431.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208165042717.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208165147533.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208165203670.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208165218383.png">
<meta property="og:image" content="http://yoursite.com/img/image-20221208165238932.png">
<meta property="og:updated_time" content="2022-12-25T03:05:54.614Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SGEMM实施的完整演练">
<meta name="twitter:description" content="在开始之前，我想提一下，这项工作的大部分都是从对cublas Kepler和Maxwell的sgemm实现的详细研究中得出的。我做了一些适度的改进，但大多数难题都由英伟达的优秀工程师和他们对硬件的专业知识解决了。本文档的目标是传播这些知识，供其他人在自己的代码中使用。我还想联系两篇关于sgemm主题的优秀论文：MAGMA原始论文（http://icl.cs.utk.edu/projectsfile">
<meta name="twitter:image" content="http://yoursite.com/img/image-20221208152310575.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2022/12/08/sgemm/">





  <title>SGEMM实施的完整演练 | Hao Yu's blog</title>
  








 
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zn-ch">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hao Yu's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The program monkey was eaten by the siege lion.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/resume.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-mybetterhalf">
          <a href="/mybetterhalf/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            mybetterhalf
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/12/08/sgemm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">SGEMM实施的完整演练</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-12-08T14:55:00+08:00">
                2022-12-08
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>在开始之前，我想提一下，这项工作的大部分都是从对cublas Kepler和Maxwell的sgemm实现的详细研究中得出的。我做了一些适度的改进，但大多数难题都由英伟达的优秀工程师和他们对硬件的专业知识解决了。本文档的目标是传播这些知识，供其他人在自己的代码中使用。我还想联系两篇关于sgemm主题的优秀论文：MAGMA原始论文（<a href="http://icl.cs.utk.edu/projectsfiles/magma/pubs/fermi_gemm.pdf）和赖俊杰的Kepler" target="_blank" rel="noopener">http://icl.cs.utk.edu/projectsfiles/magma/pubs/fermi_gemm.pdf）和赖俊杰的Kepler</a> sgemm论文（<a href="http://hal.inria.fr/docs/00/78/99/58/PDF/112_Lai.pdf）。本文档基本上是Junjie工作的扩展，但具有Maxwell架构和额外的汇编级优化。" target="_blank" rel="noopener">http://hal.inria.fr/docs/00/78/99/58/PDF/112_Lai.pdf）。本文档基本上是Junjie工作的扩展，但具有Maxwell架构和额外的汇编级优化。</a></p>
<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><p>以sgemm为例，本文旨在描述如何最大化Maxwell架构及其他架构的计算能力。拥有数千个计算核心对你没有好处，除非你让它们得到数据。要做到这一点，您需要构建计算结构，以最大限度地重用通过各种内存层次结构提取的数据。在GPU上，这些是：设备内存到二级缓存，二级缓存到纹理缓存，纹理缓存到寄存器，寄存器到共享内存，共享内存到寄存器，从寄存器到指令操作数缓存（Maxwell的新功能），最后从寄存器返回到设备内存。这些数据路径中的每一条都有延迟，我们需要用指令和线程级并行性（ILP&amp;TLP）来隐藏这些延迟。此外，还可能存在bank和联合约束。所提出的sgemm代码能够克服所有这些约束，并在硬件理论错误的2%内运行。</p>
<p>本文档将介绍两种不同的布局：每个块64个线程和每个块256个线程。我将主要讨论64线程版本，因为映射更小更简单。256线程版本或多或少是相同的，只是放大了4倍。这两个版本分别针对小型或大型矩阵进行了优化。较小的64线程版本可以将矩阵拆分为4倍多的块，这在SM稀少的情况下非常有用，但代价是所需的设备内存带宽是256线程版本的两倍。在GM204硬件上，这个额外的带宽实际上超过了可用的带宽，因此只有当有更多的可用块来填充SM超过了成本时，您才想使用它（除非L2可以隐藏它）。虽然，如果您有足够的并行工作，使用流来填充SM是更好的方法。</p>
<p>在这两个版本中，我们将使用双缓冲8寄存器块来加载A和B中的每一个。双缓冲允许我们从共享内存中隐藏加载的大部分延迟：我们可以计算一个寄存器块，同时加载下一个寄存器。我们选择8个寄存器块，因为它与使用四矢量内存指令很好地对齐，并且因为我们可以将总寄存器预算保持在128以下。跨越128个寄存器的障碍将使我们的占用率从每个调度器的4个活动减少到64线程版本的3个，从256线程版本的4个减少到2个。64线程版本不太容易受到下降的影响，我实际上看到了一些矩阵大小的性能提高（减少了L2和纹理缓存稀释，每个SM的块更少），但256线程版本的工作性能稍好，每个调度程序多了1个扭曲，以覆盖延迟。我们在这两种实现中的性能都不会受到占用率下降的巨大影响，这说明了这段代码如何很好地隐藏ILP的延迟。</p>
<p>我们还将对共享内存进行双重缓冲，以便删除其中一个我们通常需要在主循环中进行的bar.syncs，而不是在存储下一批之前等待所有共享加载完成，我们只需开始写入一个新的共享区域，而其他线程可以从上一个区域读取数据。您将在下面看到，这将向主循环添加3个XOR，但这仍然比bar.syncs便宜。至于共享内存的大小，这是由每个线程块加载的内存宽度乘以主循环展开因子来定义的。我们有64个（或256个）线程，每个线程将计算8*8或64个C点。所有这些点将一起排列成正方形，因为我们从a和B均匀拉动。所以这个正方形的宽度就是总点数的平方根。对于我们的两个实现，我们计算：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">64  Threads: sqrt(64  * 8*8) = 64  units wide</span><br><span class="line">256 Threads: sqrt(256 * 8*8) = 128 units wide*</span><br></pre></td></tr></table></figure>
<p>我们的展开因子是我们一次从A和B读取、从共享存储/读取和计算的行数。它将在几个方面受到限制。我们希望能够通过尽可能多的计算工作来隐藏纹理负载的延迟。但是，我们不希望循环的大小超过指令缓存的大小。这样做会增加额外的指令获取延迟，我们需要隐藏这些延迟。在Maxwell上，我测得这个缓存为8KB。因此，这意味着我们不希望循环大小超过1024个8字节指令，其中每4个指令都是一个控制代码。所以768是有用指令的极限。此外，还有指令对齐的注意事项，因此您也希望安全地处于该值之下。简而言之，使用8的循环展开因子可以得到8 x 64=512 ffma指令加上循环所需的额外内存和整数算术指令（约40）。这使我们大大低于768。每个循环8行也与纹理内存负载的维度很好地对齐。最后，512个FFMA应该足以大部分隐藏200+时钟纹理加载延迟。</p>
<p>因此，我们现在知道了共享内存的总大小：（每个循环8行）x（块加载宽度）x（字大小）x（A的2个缓冲区）x（B的2个缓存区）。64个线程为8192字节，256个线程为16384字节。这种大小不会影响占用率，占用率由寄存器计数（我们将保持在128以下）决定。</p>
<p>下面是两种实现共享的基本内存布局。注意，我将X维度与来自A的载荷相等，并沿lda对齐，而Y维度与来自B的载荷相等并沿ldb对齐。这与x和y通常在空间上的定义方式相反，如下图所示。还要注意的是，A和C的图像被布置为转置。回想起来，我可能会把它改成B作为转置，并与A交换，但这就是我最初的计算方法。在下一节中，我将开始详细讨论64线程版本。</p>
<p><img src="/img/image-20221208152310575.png" alt="image-20221208152310575"></p>
<h1 id="64-Thread-Implementation"><a href="#64-Thread-Implementation" class="headerlink" title="64 Thread Implementation"></a>64 Thread Implementation</h1><h2 id="加载A和B，然后存储到共享"><a href="#加载A和B，然后存储到共享" class="headerlink" title="加载A和B，然后存储到共享"></a>加载A和B，然后存储到共享</h2><p>为了加载A和B矩阵，我们使用了一种在cuda c或ptx中无法有效实现的技术。我们将线程分成两半，让每一半加载一个矩阵。由于我们有64个线程，这意味着每个warp加载一个矩阵。cuda中的条件加载没有得到很好的优化，因为编译器没有努力确定加载是否在warp上均匀发生。对于纹理加载，这是必要的，因为指令每次只能处理一个纹理。因此，除了纹理加载之外，编译器还会添加一堆warp刷新以及分支和同步指令，以确保强制执行。如果Nvidia提供一种方式来提示条件或谓词是warp一致的（而不仅仅是分支，即bra.uni），那就太好了。</p>
<p>使用此技术的主要优点是，我们只需要一组跟踪寄存器来保存纹理加载索引。在主循环内部，这是一个巨大的胜利，因为它减少了我们需要的整数加法指令的一半。我们利用一切机会提高FFMA指令与非FFMA指令的比率。</p>
<p>我们还维护了4个单独的轨迹变量，以避免在每次纹理加载后使用依赖性屏障将单个轨迹变量增加ldx*2。内存指令发出时不会复制其操作数寄存器。这样做可能会节省晶体管。相反，当内存指令仍在运行时，您可以使用屏障来防止对这些寄存器的写入。在障碍处等待并不一定很糟糕，因为TLP可以启动并覆盖延迟，但减少需要覆盖的延迟总数可以帮助性能，因为这增加了有翘曲覆盖它们的机会。我们没有任何额外的循环IADDS，因为它有4个跟踪变量，只有3个额外的寄存器，这是我们可以轻松负担的。</p>
<p>所以我们将通过纹理单元加载。通过使用显式纹理加载而不是全局加载，无论是否使用非相干缓存，我们都可以获得一些好处。一是这使得代码更加简单，因为我们不需要担心加载超出范围。第二，使用相同的内核代码，我们可以加载8位或16位浮点，从而显著减少带宽和存储需求。有些应用程序不需要完全32位精度，在这种情况下这是一个巨大的胜利。</p>
<p>此外，我们将加载四元向量。这是对cublas代码的更改，在性能方面产生了最大的差异。虽然我可以理解为什么它不在立方体中使用，因为它对输入数据施加了4个字的对齐约束。立方体有一个固定的规范（这并不是说如果检测到四边对齐，它就不能选择不同的代码路径）。因此，通过使用四元向量，我们需要将lda/ldb索引向下折叠4。这有一个额外的好处，即允许我们加载索引大小为31位的矩阵，而不是常规纹理加载27位的限制。四元加载的另一个工件是我们的内存访问模式在每次提取时都会拉入并消耗全部缓存线。这意味着我们只能得到非常有限的纹理缓存使用率（1-2%），而我们的内存缓存性能将由二级缓存控制。</p>
<p>下面是一些伪代码，它只显示了主循环中的纹理加载和共享存储。你可以从地图上看到，这是非常直接的。你会注意到STS。128条指令，我们将遇到存储体冲突，但这些冲突是不可避免的，结果不会影响性能，因为批量加载和存储到向量指令中是一个双赢。此外，我甚至不确定银行冲突期间发生的指令回放是否重要，因为我认为这些指令可能会与FFMA一起发出。事实上，所有的内存操作都是在我们的主循环中发出的，根本不考虑flops计算（除非在寄存器组冲突一节中以一种微妙的方式描述）。</p>
<p>仅从这段代码和我们的主循环中时钟消耗指令的数量，我们就可以粗略估计内核所需的内存带宽上限。对于GM204，以下是数学公式：</p>
<ul>
<li><p>每个线程在每个循环中进行4个vec4 4字节的加载，或者每个循环中每个线程进行64个字节的加载。</p>
</li>
<li><p>下面我们将计算每个循环消耗大约520个时钟。</p>
</li>
<li>每个SM同时执行128个线程。</li>
<li>有16个SM的时钟频率为1.216 GHz（升压）。</li>
<li>每GB有.931 GiB：</li>
<li>64 x 128 x 16 x 1.216 x.931/520=285 GiB/秒</li>
</ul>
<p>GM204有224 GiB/sec可用。但这部分设备带宽将不需要，因为二级缓存将为其提供服务。但在设备带宽上有余量总是很好的。您的负载将不会以完全统一的方式执行，并且当它们聚集在一起时，您的净空越小，出现暂停的机会就越大。虽然只有运行接近理论吞吐量的代码才可能注意到这些暂停，但我们的代码恰好会这样做。</p>
<p>因此，您可以看到，64线程的实现对于GM204来说并不理想。然而，对于GM107来说，它是理想的，对于即将推出的具有384位内存总线的GM200来说也是如此。与256线程实现相比，这一实现使用了双倍的带宽，因此功耗更大。因此，当您有足够的数据来提供数据时，通常会首选更大的版本。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">tid = threadId.x;</span><br><span class="line">bx  = blockId.x;</span><br><span class="line">by  = blockId.y;</span><br><span class="line"></span><br><span class="line">blk = tid &gt;= 32 ? by    : bx;</span><br><span class="line">ldx = tid &gt;= 32 ? ldb/4 : lda/4;</span><br><span class="line">tex = tid &gt;= 32 ? texB  : texA;</span><br><span class="line">tid2  = (tid &gt;&gt; 4) &amp; 1;</span><br><span class="line">tid15 = tid &amp; 15;</span><br><span class="line"></span><br><span class="line">track0 = blk*64/4 + tid15 + (ldx * tid2);</span><br><span class="line">track2 = track0 + ldx*2;</span><br><span class="line">track4 = track0 + ldx*4;</span><br><span class="line">track6 = track0 + ldx*6;</span><br><span class="line"></span><br><span class="line">end = track0 + (k-8)*ldx;</span><br><span class="line"></span><br><span class="line">writeS = tid15*4*4 + tid2*64*4;</span><br><span class="line">writeS += tid &gt;= 32 ? 2048 : 0;</span><br><span class="line"></span><br><span class="line">while (track0 &lt; end)</span><br><span class="line">&#123;</span><br><span class="line">    tex.1d.v4.f32.s32 loadX0, [tex, track0];</span><br><span class="line">    tex.1d.v4.f32.s32 loadX2, [tex, track2];</span><br><span class="line">    tex.1d.v4.f32.s32 loadX4, [tex, track4];</span><br><span class="line">    tex.1d.v4.f32.s32 loadX6, [tex, track6];</span><br><span class="line"></span><br><span class="line">    st.shared.v4.f32 [writeS + 4*0*64], loadX0;</span><br><span class="line">    st.shared.v4.f32 [writeS + 4*2*64], loadX2;</span><br><span class="line">    st.shared.v4.f32 [writeS + 4*4*64], loadX4;</span><br><span class="line">    st.shared.v4.f32 [writeS + 4*6*64], loadX6;</span><br><span class="line"></span><br><span class="line">    // our loop needs one bar sync after share is loaded</span><br><span class="line">    bar.sync 0;</span><br><span class="line"></span><br><span class="line">    // Increment the track variables and swap shared buffers after the sync.</span><br><span class="line">    // We know at this point that these registers are not tied up with any in flight memory op.</span><br><span class="line">    track0 += ldx*8;</span><br><span class="line">    track2 += ldx*8;</span><br><span class="line">    track4 += ldx*8;</span><br><span class="line">    track6 += ldx*8;</span><br><span class="line">    writeS ^= 4*16*64;</span><br><span class="line"></span><br><span class="line">    // Additional loop code omitted for clarity.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过四矢量纹理索引加载A和B：</p>
<p><img src="/img/image-20221208153216716.png" alt="image-20221208153216716"></p>
<p>使用四矢量将A和B存储到共享地址空间中：</p>
<p><img src="/img/image-20221208153237832.png" alt="image-20221208153237832"></p>
<h2 id="从共享读取"><a href="#从共享读取" class="headerlink" title="从共享读取"></a>从共享读取</h2><p>现在，共享内存已加载，我们从使用一半线程切换到处理A和B中的每一个。我们需要开始组合这些值来计算构成C点的点积（处理每一行后，我们计算块中所有C值的部分积和和）。所以每个线程都将从A的共享行和B的共享行中读取。</p>
<p>除了FFMA之外，共享负载是这个实现的真正工作。我们对它们进行双重缓冲，因此延迟最小。但我们也希望确保我们没有bank冲突，因为我们需要尽快提供这些数据。如何在没有库冲突的情况下使用四元向量从共享加载？好吧，根据文档，只要所有访问都在32个字（128字节）以内，我们就可以了。在sgemm中，这是因为我们可以安排不同的线程同时从同一共享内存位置加载，并使用共享广播机制。然而，事实证明，Maxwell的文档是不完整的，尽管warp中的所有线程都在相同的128字节内，但仍有某些模式会导致库冲突。这样做可能是为了节省芯片。所以我们只需要找到一个可行的模式。</p>
<p>在128字节内，我们可以加载8个16字节的四元组。我们将使其成为从A和B的共享内存加载的模式。我们的共享内存块是4*64=256字节宽，因此为了加载另一半，我们将展开该负载到一个相隔32个单元的额外指令中。我们不必担心bank冲突。每个矩阵的这两个四字负载形成了我们想要的8寄存器块。通过在2D中组合这两种1D模式的负载，我们可以得到下面所示的共享内存映射。该模式还表示每个线程的64个寄存器在C子矩阵中的位置（绿色方块）。</p>
<p>现在我们有了基本信息，我们需要将其分成两个warp，然后映射这些warp中的线程id。直接方法是以简单的扫描模式向下或横向加载。这导致了神秘的bank冲突。但是，如果我们使用由thread号表示的锯齿形图案，它就会起作用。我还没有对所有的负载大小和模式进行详尽的搜索，以了解哪些是有效的，哪些是无效的，但如果Nvidia为Maxwell更新他们的文档来解释这一限制，那就太好了。</p>
<p>至于找出将threadId映射到我们想要的模式（下面的readAs和readBs）所需的逻辑，我有一个简单的技术。我只是打印出每个threadId的二进制表示形式和我希望它映射到的值。当您以这种方式可视化二进制时，很容易确定需要保留、丢弃或移动哪些位以使映射工作（前提是您选择了possble映射）。</p>
<p>我还应该提到我的插图是如何被解读的。黄色方块表示线程（或TLP），绿色方块表示第一个线程的ILP。你应该能够想象得到绿色正方形的图案，并将其移动到每个黄色正方形的顶部（保持绿色与黄色的相对位置）。这应该跨越整个内存空间，这是我们共享映射的目标：a中一条线的每个点都需要与B中一条线上的每个点配对。细黑线表示线程如何被分割成warp。下面的深绿色方块是为了说明我们稍后将要进行的warp同步洗牌中的一个步骤。</p>
<p>另一个值得注意的是，cublas在这里使用了更复杂的readAs/readBs映射，这实现了相同的效果，但需要花费更多的指令。这是我的代码对cublas的一个小改进。如果您提前知道共享加载限制，那么更复杂的模式甚至是有意义的。但似乎愚蠢而直接的方法最终找到了更简单的解决方案。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">readAs = ((tid &gt;&gt; 1) &amp; 7) &lt;&lt; 4;</span><br><span class="line">readBs = (((tid &amp; 0x30) &gt;&gt; 3) | (tid &amp; 1)) &lt;&lt; 4 + 2048;</span><br><span class="line"></span><br><span class="line">while (track0 &lt; end)</span><br><span class="line">&#123;</span><br><span class="line">    // Process each of our 8 lines from shared</span><br><span class="line">    for (j = 0; j &lt; 8; j++)</span><br><span class="line">    &#123;</span><br><span class="line">        // We fetch one line ahead while calculating the current line.</span><br><span class="line">        // Wrap the last line around to the first.</span><br><span class="line">        prefetch = (j + 1) % 8;</span><br><span class="line">        </span><br><span class="line">        // Use even/odd rows to implement our double buffer.</span><br><span class="line">        if (j &amp; 1)</span><br><span class="line">        &#123;</span><br><span class="line">            ld.shared.v4.f32 j0Ax00, [readAs + 4*(prefetch*64 + 0)];</span><br><span class="line">            ld.shared.v4.f32 j0By00, [readBs + 4*(prefetch*64 + 0)];</span><br><span class="line">            ld.shared.v4.f32 j0Ax32, [readAs + 4*(prefetch*64 + 32)];</span><br><span class="line">            ld.shared.v4.f32 j0By32, [readBs + 4*(prefetch*64 + 32)];</span><br><span class="line">        &#125;</span><br><span class="line">        else</span><br><span class="line">        &#123;</span><br><span class="line">            ld.shared.v4.f32 j1Ax00, [readAs + 4*(prefetch*64 + 0)];</span><br><span class="line">            ld.shared.v4.f32 j1By00, [readBs + 4*(prefetch*64 + 0)];</span><br><span class="line">            ld.shared.v4.f32 j1Ax32, [readAs + 4*(prefetch*64 + 32)];</span><br><span class="line">            ld.shared.v4.f32 j1By32, [readBs + 4*(prefetch*64 + 32)];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    // swap our shared memory buffers after reading out 8 lines</span><br><span class="line">    readAs ^= 4*16*64;</span><br><span class="line">    readBs ^= 4*16*64;</span><br><span class="line"></span><br><span class="line">    // Additional loop code omitted for clarity.</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>1D readAs（左侧）和readBs（顶部）在2D中组合以形成该线程块的C结果子矩阵：</p>
<p><img src="/img/image-20221208162657316.png" alt="image-20221208162657316"></p>
<h2 id="计算C：寄存器bank和重用"><a href="#计算C：寄存器bank和重用" class="headerlink" title="计算C：寄存器bank和重用"></a>计算C：寄存器bank和重用</h2><p>现在我们为线程填充了8个寄存器A和B，我们可以执行64个FFMA，这些FFMA构成了内核设计的核心工作。为了能够在全速和最低功率下计算这一点，我们需要考虑几个因素。主要是寄存器组和操作数重用。</p>
<p>Maxwell上有4个寄存器组，但与开普勒（也有4个组）不同的是，将bank分配给数字非常简单。Maxwell赋值只是寄存器数模4。在开普勒上，可以安排64条FFMA指令以消除所有存储体冲突。在麦克斯韦身上，这已经不可能了。然而，Maxwell提供了一些弥补这一点的方法，同时提供了显著减少寄存器组流量和总体芯片功耗的能力。这是操作数重用缓存。操作数重用缓存每个源操作数插槽有8个字节的数据。类似FFMA的指令有3个源操作数槽。每次发出指令时，都有一个标志可以用来指定是否要再次使用每个操作数。因此，在同一操作数槽中使用同一寄存器的下一条指令不必去寄存器组获取其值。通过此功能，您可以看到如何避免寄存器bank冲突。</p>
<p>因此，我们要采取的第一步是尽量减少操作数重用时必须隐藏的存储体冲突的数量。为此，我们需要显式选择要使用的寄存器。这是使用maxas作为汇编器的主要优点之一。ptxas在避免存储体冲突方面做得很好，但它并不完美，而且当涉及向量指令时，它做得特别糟糕（本例中的情况非常严重）。因此，我们将选择：</p>
<ul>
<li>0-63为C寄存器</li>
<li>64-71和80-87是矩阵A的双缓冲块寄存器</li>
<li>72-79和88-95是矩阵B的双缓冲块寄存器</li>
</ul>
<p>如果我们按照下面所示的8乘8矩阵排列，我们可以用每个寄存器的存储体索引为其着色。对于C寄存器，我们选择与相应的块寄存器不同的颜色。通过这种方式，您可以看到我们可以消除与C寄存器和阻塞寄存器的所有存储体冲突。这使得不可避免的16个存储体与阻塞寄存器本身发生冲突。这些以黑色显示：</p>
<p><img src="/img/image-20221208162949337.png" alt="image-20221208162949337"></p>
<p>如果没有重用缓存，这16个存储体冲突中的每一个都将导致计算中的1个时钟暂停。这将使我们的计算速度降低约20%（在520时钟循环中增加128个时钟）。但是，如果您使用—noruse标志组装sgemm代码，您将看到性能只会下降几百Gflop左右。如果你仔细阅读英伟达关于操作数收集器的专利，特别是如果你搜索涉及bank冲突的部分，这个谜团就迎刃而解了。它描述了一些缓解bank冲突的方法。很难说Maxwell是如何处理的，但这可能涉及到如何利用TLP来隐藏bank冲突延迟。因此，操作数收集器单独屏蔽存储体冲突的能力有限，但可能很快就会被淹没。通过使用持久的缓存而不仅仅是临时操作数缓冲区，硬件能够更有效地避免bank冲突暂停。它只需要汇编器使用重用标志来指导它，这样它就可以提前知道哪些寄存器值得缓存，以及在寄存器被写入时丢弃哪些寄存器。</p>
<p>优化设置重用标志的繁琐任务由maxas为您处理。留给我们的是以这样的方式对指令进行排序，以便最大限度地实现重用。最简单的排序是一个基本的双嵌套“for循环”，它将逐行遍历矩阵。这只有效地利用了重用缓存每个操作数8个字节中的4个字节，并且不会隐藏所有的存储体冲突。相反，如果您的扫描来回进行，则可以隐藏所有冲突并提高寄存器重用率（总体上为39%）。但最有效的模式是，在来回移动时，应用一个漩涡（47%的总重用率）。以下是按C寄存器号列出的FFMA指令顺序：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1, 0, 2, 3, 5, 4, 6, 7, 33, 32, 34, 35, 37, 36, 38, 39,</span><br><span class="line"></span><br><span class="line">45, 44, 46, 47, 41, 40, 42, 43, 13, 12, 14, 15, 9, 8, 10, 11,</span><br><span class="line"></span><br><span class="line">17, 16, 18, 19, 21, 20, 22, 23, 49, 48, 50, 51, 53, 52, 54, 55,</span><br><span class="line"></span><br><span class="line">61, 60, 62, 63, 57, 56, 58, 59, 29, 28, 30, 31, 25, 24, 26, 27</span><br></pre></td></tr></table></figure>
<p>您将注意到，所选漩涡尺寸在其中一个方向上的间距为2。此间距具有使C寄存器出现在交替存储体中的效果。我对这样做的原因的最佳猜测是极其微妙的。由于我们的内存指令与FFMA交错，并且这些指令没有其操作数寄存器的副本，因此它们可以在大约20个时钟周期内访问寄存器组。我们的C寄存器经常被弄脏，因此无法重复使用，所以我们总是从寄存器库中取出它们。因此，主要是这些寄存器会与我们的内存加载和存储指令发生延迟存储体冲突。可能不可能完全围绕这些银行冲突进行设计，但您可以减少它们的影响。通过在每条指令上交替使用C寄存器组，我们可以确保组冲突最多只能持续一个时钟。我运行了几个基准测试来检验这个假设，结果似乎是正确的。最后一个注意事项：使用所有四矢量加载和存储的另一个优点（除了效率更高之外）是减少了所需的内存指令数量，从而减少了延迟寄存器组冲突的机会。</p>
<p>鉴于我们知道内存操作数寄存器可能存在延迟存储体冲突，因此为这些操作数选择不同的存储体是值得尝试的。使用maxas，我们可以完全控制寄存器映射，您将在源代码中注意到，我们为track0-3、tex、readAs、readBs和writeS选择了非常特定的库。测试了这些库选择中的每一个，以最大化内核的flops性能。这是一个优化级别，我不确定cublas实现是否实现。我知道它犯的一个错误是，对于第一个FFMA，它选择了具有阻塞寄存器组冲突的C寄存器（3）。这防止了重用缓存隐藏该冲突的能力，因为之前没有将至少一个操作数加载到缓存中的指令。在GM204上，这个错误导致28 Gflops的性能损失。</p>
<p>使用FFMA的最后一个考虑是如何将它们与上述所有内存操作交织。要了解我在这里谈论的内容，请查看源代码的预处理版本。我们希望尽早使用双缓冲共享负载，以覆盖它们的延迟，因此我们将使用第一个FFMA开始双重发布它们。我们将用两条指令来分隔它们，因为内存单元似乎以一半的吞吐量最佳工作。我们将把纹理加载放在两组共享加载的中间。这样做是为了不让指令淹没内存单元。对于64线程实现，我们甚至将四个负载分成两组，并将它们放在不同的FFMA块中。我们将共享存储指令放置在尽可能低的位置，以使纹理加载有机会加载它们的操作数。我们不能将它们放在最后一个FFMA块中，因为这是我们开始为下一个循环迭代加载块寄存器的地方。</p>
<p>所有这些立场决定都经过了严格的测试，证明是最佳的。我应该注意，使用ptxas无法进行这些细粒度的排序和定位选择。事实上，ptxas倾向于优化我们的共享双缓冲加载方案。在选择寄存器组、优化操作数重用的指令排序和将内存指令精确放置在我们想要的位置之间，实现的性能可以达到理论性能的70%，而实现的性能则可以达到98%。</p>
<h2 id="warp同步无序映射"><a href="#warp同步无序映射" class="headerlink" title="warp同步无序映射"></a>warp同步无序映射</h2><p>在循环结束时，现在计算线程块的C子矩阵。所以现在是将结果存储回全局存储器的时候了。因为我们使用了来自共享的四矢量加载，所以我们的C值有点聚在一起，对于联合写入全局来说根本不是最佳的。我们可以直接将数据写出来，但我们可以做得更好。通过使用共享内存在同一warp的线程之间移动C寄存器，我们可以重新组织它以进行合并写入。您可能认为warp shuffle指令在这里最有效，但我们需要从不同的线程交换不同的寄存器，因此它不适合于此目的。</p>
<p>我们将把洗牌分成8块。上述共享内存映射上的深绿色线表示第一个块。另外7个将是C寄存器的后续垂直选择。因此，每个线程在共享内存中一次存储8个寄存器，然后立即再读取8个寄存器。但是，这些寄存器的排列方式使得我们的线程ID的重新映射可以以合并模式将数据存储到全局。因此，为了存储到共享，我们需要重新使用原始的共享内存映射，并在其中一个维度中将其从4个跨步单位折叠为一个。读取它的线程id映射将是32个值，步幅为1个单位。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tid31 = tid &amp; 31;</span><br><span class="line">tid32 = tid &amp; 32;</span><br><span class="line"></span><br><span class="line">// Remove the high bits if present from the last loop&apos;s xor.</span><br><span class="line">// Also remove the 2048 added onto readBs.</span><br><span class="line">readAs &amp;= 0x7ff;</span><br><span class="line">readBs &amp;= 0x7ff;</span><br><span class="line"></span><br><span class="line">// Write to shared using almost the same shared mapping as before but collapse readBs down to stride one.</span><br><span class="line">writeCs = (readBs / 4) * 64 + readAs;</span><br><span class="line"></span><br><span class="line">// Read out with a mapping amenable to coalesced global writes</span><br><span class="line">readCs = ((tid32 &lt;&lt; 3) + tid31) &lt;&lt; 2;</span><br></pre></td></tr></table></figure>
<p><img src="/img/image-20221208164843431.png" alt="image-20221208164843431"></p>
<h2 id="Warp-Shuffling和联合存储到全局"><a href="#Warp-Shuffling和联合存储到全局" class="headerlink" title="Warp Shuffling和联合存储到全局"></a>Warp Shuffling和联合存储到全局</h2><p>有了上述映射，我们现在可以输出C值。注意，我们不需要bar.sync在写入共享内存之前进行同步，因为这已经在我们的最后一个循环中完成了。还要注意，由于我们不在warp之间共享数据，所以在共享内存洗牌中，我们不需要在写入和读取之间同步。只有在存储到writeC完成后，才会进行从readC的读取。注意，这里增加的共享内存延迟大部分可以用TLP隐藏，而为扭曲同步洗牌增加的净时钟只有十几个左右。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">ldc4 = ldc * 4;</span><br><span class="line"></span><br><span class="line">cx = bx*64 + tid31;</span><br><span class="line">cy = by*64 + (tid32 &gt;&gt; 1);</span><br><span class="line"></span><br><span class="line">Cy00 = (cy*ldc + cx) * 4 + C;</span><br><span class="line">Cy04 = Cy00 + ldc4 * 4;</span><br><span class="line">Cy08 = Cy00 + ldc4 * 8;</span><br><span class="line">Cy12 = Cy00 + ldc4 * 12;</span><br><span class="line"></span><br><span class="line">foreach copy vertical line of 8 registers from C into .v4.f32 cs0 and cs4</span><br><span class="line">&#123;</span><br><span class="line">    // Feed the 8 registers through the warp shuffle before storing to global</span><br><span class="line">    st.shared.v4.f32 [writeCs + 4*00], cs0;</span><br><span class="line">    st.shared.v4.f32 [writeCs + 4*32], cs4;</span><br><span class="line"></span><br><span class="line">    ld.shared.f32 cs0, [readCs + 4*(0*64 + 00)];</span><br><span class="line">    ld.shared.f32 cs1, [readCs + 4*(0*64 + 32)];</span><br><span class="line">    ld.shared.f32 cs2, [readCs + 4*(1*64 + 00)];</span><br><span class="line">    ld.shared.f32 cs3, [readCs + 4*(1*64 + 32)];</span><br><span class="line">    ld.shared.f32 cs4, [readCs + 4*(2*64 + 00)];</span><br><span class="line">    ld.shared.f32 cs5, [readCs + 4*(2*64 + 32)];</span><br><span class="line">    ld.shared.f32 cs6, [readCs + 4*(3*64 + 00)];</span><br><span class="line">    ld.shared.f32 cs7, [readCs + 4*(3*64 + 32)];</span><br><span class="line"></span><br><span class="line">    st.global.f32 [Cy00 + 4*00], cs0;</span><br><span class="line">    st.global.f32 [Cy00 + 4*32], cs1;</span><br><span class="line">    st.global.f32 [Cy04 + 4*00], cs2;</span><br><span class="line">    st.global.f32 [Cy04 + 4*32], cs3;</span><br><span class="line">    st.global.f32 [Cy08 + 4*00], cs4;</span><br><span class="line">    st.global.f32 [Cy08 + 4*32], cs5;</span><br><span class="line">    st.global.f32 [Cy12 + 4*00], cs6;</span><br><span class="line">    st.global.f32 [Cy12 + 4*32], cs7;</span><br><span class="line"></span><br><span class="line">    Cy00 += ldc4;</span><br><span class="line">    Cy04 += ldc4;</span><br><span class="line">    Cy08 += ldc4;</span><br><span class="line">    Cy12 += ldc4;</span><br><span class="line"></span><br><span class="line">    // After processing forth set shift over to the stride 32 registers</span><br><span class="line">    if (4th iteration)</span><br><span class="line">    &#123;</span><br><span class="line">        Cy00 += ldc4 * 28;</span><br><span class="line">        Cy04 += ldc4 * 28;</span><br><span class="line">        Cy08 += ldc4 * 28;</span><br><span class="line">        Cy12 += ldc4 * 28;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在下图中，蓝色方块表示如何从Cy00、Cy04、Cy08和Cy12矩阵C偏移的8个状态构造绿线。它们的垂直放置的不是步幅32的部分是到循环迭代的映射，而不是空间位置。</p>
<p><img src="/img/image-20221208165042717.png" alt="image-20221208165042717"></p>
<p>呃……所以这是一个很高的水平。代码注释中甚至包含了较低级别的细节，特别是关于如何将内存访问与计算同步的细节。注释仅在256线程版本中找到。说到这里，下面我将展示四倍多的线程如何改变映射。</p>
<h1 id="SGEMM-256-Thread-Implementation"><a href="#SGEMM-256-Thread-Implementation" class="headerlink" title="SGEMM - 256 Thread Implementation"></a>SGEMM - 256 Thread Implementation</h1><h3 id="Loading-A-and-B"><a href="#Loading-A-and-B" class="headerlink" title="## Loading A and B"></a>## Loading A and B</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tid = threadId.x;</span><br><span class="line">blk = tid &gt;= 128 ? blockId.y : blockId.x;</span><br><span class="line">ldx = tid &gt;= 128 ? ldb/4     : lda/4;</span><br><span class="line">tex = tid &gt;= 128 ? texB      : texA;</span><br><span class="line">tid4   = (tid &gt;&gt; 5) &amp; 3</span><br><span class="line">tid31  = tid &amp; 31</span><br><span class="line">tid96  = tid &amp; 96</span><br><span class="line">tid128 = tid &amp; 128</span><br><span class="line"></span><br><span class="line">track0 = blk*128/4 + tid31 + (ldx * tid4)</span><br><span class="line">track4 = track0 + ldx*4;</span><br><span class="line"></span><br><span class="line">end = track0 + (k-8)*ldx;</span><br></pre></td></tr></table></figure>
<h2 id="Storing-to-Shared"><a href="#Storing-to-Shared" class="headerlink" title="Storing to Shared"></a>Storing to Shared</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">writeS  = tid31*4*4 + tid4*128*4;</span><br><span class="line">writeS += tid &gt;= 128 ? 4096 : 0;</span><br></pre></td></tr></table></figure>
<p><img src="/img/image-20221208165147533.png" alt="image-20221208165147533"></p>
<h2 id="Reading-from-Shared"><a href="#Reading-from-Shared" class="headerlink" title="Reading from Shared"></a>Reading from Shared</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">readAs = ((tid128 &gt;&gt; 4) | ((tid &gt;&gt; 1) &amp; 7)) &lt;&lt; 4;</span><br><span class="line">readBs  = (((tid &amp; 0x70) &gt;&gt; 3) | (tid &amp; 1)) &lt;&lt; 4 + 4096;</span><br></pre></td></tr></table></figure>
<p><img src="/img/image-20221208165203670.png" alt="image-20221208165203670"></p>
<h2 id="Warp-Synchronous-Shuffle"><a href="#Warp-Synchronous-Shuffle" class="headerlink" title="Warp Synchronous Shuffle"></a>Warp Synchronous Shuffle</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">readAs &amp;= 0xfff;</span><br><span class="line">readBs &amp;= 0xfff;</span><br><span class="line"></span><br><span class="line">writeCs = (readBs / 4) * 128 + readAs;</span><br><span class="line"></span><br><span class="line">readCs = ((tid96 &lt;&lt; 4) | tid31 | (tid128 &gt;&gt; 2)) &lt;&lt; 2;</span><br></pre></td></tr></table></figure>
<p><img src="/img/image-20221208165218383.png" alt="image-20221208165218383"></p>
<h2 id="Storing-to-Global"><a href="#Storing-to-Global" class="headerlink" title="Storing to Global"></a>Storing to Global</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ldc4 = ldc * 4;</span><br><span class="line"></span><br><span class="line">cx = bx*128 + tid31 | (tid128 &gt;&gt; 2);</span><br><span class="line">cy = by*128 + (tid96 &gt;&gt; 1);</span><br><span class="line"></span><br><span class="line">Cy00 = (cy*ldc + cx) * 4 + C;</span><br><span class="line">Cy04 = Cy00 + ldc4*4;</span><br><span class="line">Cy08 = Cy00 + ldc4*8;</span><br><span class="line">Cy12 = Cy00 + ldc4*12;</span><br></pre></td></tr></table></figure>
<p><img src="/img/image-20221208165238932.png" alt="image-20221208165238932"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/积累/" rel="tag"># 积累</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/11/11/tmux备忘/" rel="next" title="tmux使用备忘">
                <i class="fa fa-chevron-left"></i> tmux使用备忘
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/12/22/CUDA官方手册/" rel="prev" title="CUDA 编程手册">
                CUDA 编程手册 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="Hao Yu">
            
              <p class="site-author-name" itemprop="name">Hao Yu</p>
              <p class="site-description motion-element" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</p>
          </div>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">193</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">13</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>
        	<audio controls="controls" loop="loop" preload="auto" src="/resource/xiaomeihao.mp3">
	        </audio>
	

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuhao0102" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yuh18@mails.tsinghua.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#64-Thread-Implementation"><span class="nav-number">2.</span> <span class="nav-text">64 Thread Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#加载A和B，然后存储到共享"><span class="nav-number">2.1.</span> <span class="nav-text">加载A和B，然后存储到共享</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#从共享读取"><span class="nav-number">2.2.</span> <span class="nav-text">从共享读取</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#计算C：寄存器bank和重用"><span class="nav-number">2.3.</span> <span class="nav-text">计算C：寄存器bank和重用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#warp同步无序映射"><span class="nav-number">2.4.</span> <span class="nav-text">warp同步无序映射</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Warp-Shuffling和联合存储到全局"><span class="nav-number">2.5.</span> <span class="nav-text">Warp Shuffling和联合存储到全局</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SGEMM-256-Thread-Implementation"><span class="nav-number">3.</span> <span class="nav-text">SGEMM - 256 Thread Implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Loading-A-and-B"><span class="nav-number">3.0.1.</span> <span class="nav-text">## Loading A and B</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Storing-to-Shared"><span class="nav-number">3.1.</span> <span class="nav-text">Storing to Shared</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reading-from-Shared"><span class="nav-number">3.2.</span> <span class="nav-text">Reading from Shared</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Warp-Synchronous-Shuffle"><span class="nav-number">3.3.</span> <span class="nav-text">Warp Synchronous Shuffle</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Storing-to-Global"><span class="nav-number">3.4.</span> <span class="nav-text">Storing to Global</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="DvelopmentTarget">     
  </div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="false"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>

  
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_uv"> 
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  


  <script type="text/javascript" src="/js/src/love.js"></script>

</body>
</html>
