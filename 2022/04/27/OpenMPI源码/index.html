<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zn-ch">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="积累,">










<meta name="description" content="OpenMPI结构Open MPI 联合了四种MPI的不同实现：  LAM/MPI, LA/MPI (Los Alamos MPI) FT-MPI (Fault-Tolerant MPI) PACX-MPI  ArchitectureOpen MPI使用C语言编写，是一个非常庞大、复杂的代码库。2003的MPI 标准——MPI-2.0，定义了超过300个API接口。 之前的4个项目，每个项目都非常">
<meta name="keywords" content="积累">
<meta property="og:type" content="article">
<meta property="og:title" content="OpenMPI源码">
<meta property="og:url" content="http://yoursite.com/2022/04/27/OpenMPI源码/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="OpenMPI结构Open MPI 联合了四种MPI的不同实现：  LAM/MPI, LA/MPI (Los Alamos MPI) FT-MPI (Fault-Tolerant MPI) PACX-MPI  ArchitectureOpen MPI使用C语言编写，是一个非常庞大、复杂的代码库。2003的MPI 标准——MPI-2.0，定义了超过300个API接口。 之前的4个项目，每个项目都非常">
<meta property="og:locale" content="zn-ch">
<meta property="og:image" content="http://yoursite.com/img/ea15ad9d6b754529839246ccd79d44a3.awebp">
<meta property="og:image" content="http://yoursite.com/img/cddc2d92b0fa44eeb642d16b0a1a3c32.awebp">
<meta property="og:updated_time" content="2022-05-28T02:30:33.085Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="OpenMPI源码">
<meta name="twitter:description" content="OpenMPI结构Open MPI 联合了四种MPI的不同实现：  LAM/MPI, LA/MPI (Los Alamos MPI) FT-MPI (Fault-Tolerant MPI) PACX-MPI  ArchitectureOpen MPI使用C语言编写，是一个非常庞大、复杂的代码库。2003的MPI 标准——MPI-2.0，定义了超过300个API接口。 之前的4个项目，每个项目都非常">
<meta name="twitter:image" content="http://yoursite.com/img/ea15ad9d6b754529839246ccd79d44a3.awebp">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2022/04/27/OpenMPI源码/">





  <title>OpenMPI源码 | Hao Yu's blog</title>
  








 
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zn-ch">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hao Yu's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The program monkey was eaten by the siege lion.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/resume.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-mybetterhalf">
          <a href="/mybetterhalf/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            mybetterhalf
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/04/27/OpenMPI源码/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">OpenMPI源码</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2022-04-27T11:23:00+08:00">
                2022-04-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="OpenMPI结构"><a href="#OpenMPI结构" class="headerlink" title="OpenMPI结构"></a>OpenMPI结构</h1><p>Open MPI 联合了四种MPI的不同实现：</p>
<ul>
<li>LAM/MPI,</li>
<li>LA/MPI (Los Alamos MPI)</li>
<li>FT-MPI (Fault-Tolerant MPI)</li>
<li>PACX-MPI</li>
</ul>
<h2 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h2><p>Open MPI使用C语言编写，是一个非常庞大、复杂的代码库。2003的MPI 标准——MPI-2.0，定义了超过300个API接口。</p>
<p>之前的4个项目，每个项目都非常庞大。例如，LAM/MPI由超过1900个源码文件，代码量超过30W行。希望Open MPI尽可能的支持更多的特性、环境以及网络类型。因此Open MPI花了大量时间设计架构，主要专注于三件事情：</p>
<ul>
<li>将相近的功能划分在不同的抽象层</li>
<li>使用运行时可加载的插件以及运行时参数，来选择相同接口的不同实现</li>
<li>不允许抽象影响性能</li>
</ul>
<h2 id="Abstraction-Layer-Architecture"><a href="#Abstraction-Layer-Architecture" class="headerlink" title="Abstraction Layer Architecture"></a>Abstraction Layer Architecture</h2><p>Open MPi 可以分为三个主要的抽象层，自顶向下依次为：</p>
<ul>
<li>OMPI (Open MPI) (pronounced: oom-pee):<ul>
<li>由 MPI standard 所定义</li>
<li>暴露给上层应用的 API，由外部应用调用</li>
</ul>
</li>
<li>ORTE (Open MPI Run-Time Environment) (pronounced “or-tay”):<ul>
<li>MPI 的 run-time system<ul>
<li>launch, monitor, kill individual processes</li>
<li>Group individual processes into “jobs”</li>
</ul>
</li>
<li>重定向stdin、stdout、stderr</li>
<li>ORTE 进程管理方式：在简单的环境中，通过rsh或ssh 来launch 进程。而复杂环境(HPC专用)会有shceduler、resource manager等管理组件，面向多个用户进行公平的调度以及资源分配，ORTE支持多种管理环境，例如，orque/PBS Pro, SLURM, Oracle Grid Engine, and LSF.<ul>
<li>注意 ORTE 在 5.x 版本中被移除，进程管理模块被替换成了<a href="openpmix/prrte: PMIx Reference RunTime Environment (PRRTE">prrte</a> (github.com))</li>
</ul>
</li>
</ul>
</li>
<li>OPAL (Open, Portable Access Layer) (pronounced: o-pull): OPAL 是xOmpi的最底层<ul>
<li>只作用于单个进程</li>
<li>负责不同环境的可移植性</li>
<li>包含了一些通用功能（例如链表、字符串操作、debug控制等等）</li>
</ul>
</li>
</ul>
<p><img src="/img/ea15ad9d6b754529839246ccd79d44a3.awebp" alt></p>
<p>在代码目录中是以project的形式存在，也就是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ompi/</span><br><span class="line">├── ompi</span><br><span class="line">├── opal</span><br><span class="line">└── orte</span><br></pre></td></tr></table></figure></p>
<p>需要注意的时，考虑到性能因素，Open MPI 有中“旁路”机制（bypass），ORTE以及OMPI层，可以绕过OPAL，直接与操作系统（甚至是硬件）进行交互。例如OMPI会直接与网卡进行交互，从而达到最大的网络性能。</p>
<h2 id="Plugin-Architecture"><a href="#Plugin-Architecture" class="headerlink" title="Plugin Architecture"></a>Plugin Architecture</h2><p>为了在 Open MPI 中使用类似但是不同效果的功能，Open MPI 设计一套被称为<strong>Modular Component Architecture (MCA)</strong>的架构。在MCA架构中，为每一个抽象层（也就是OMPI、ORTE、OPAL）定义了多个framework，这里的framework类似于其他语言语境中的接口（interface），framework对于一个功能进行了抽象，而plugin就是对于一个framework的不同实现。每个 Plugin 都是以动态链接库（DSO，dynamic shared object）的形式存在。因此run time 能够动态的加载不同的plugin。</p>
<p>例如下图中 btl 是一个功能传输bytes的framework，它属于OMPI层，btl framework之下又包含针对不同网络类型的实现，例如 tcp、openib (InfiniBand)、sm (shared memory)、sm-cuda (shared memory for CUDA)<br><img src="/img/cddc2d92b0fa44eeb642d16b0a1a3c32.awebp" alt></p>
<h1 id="PML"><a href="#PML" class="headerlink" title="PML"></a>PML</h1><p>PML即P2P Management Layer，MPI基于这一层，基本所有的通信都是通过这一层实现的，它提供 MPI 层所需的 P2P 接口功能的 MCA 组件类型。 PML 是一个相对较薄的层，主要用于通过多种传输（字节传输层 (BTL) MCA 组件类型的实例）对消息进行分段和调度，如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">------------------------------------</span><br><span class="line">|                MPI               |</span><br><span class="line">------------------------------------</span><br><span class="line">|                PML               |</span><br><span class="line">------------------------------------</span><br><span class="line">| BTL (TCP) | BTL (SM) | BTL (...) |</span><br><span class="line">------------------------------------</span><br></pre></td></tr></table></figure></p>
<p>MCA 框架在库初始化期间选择单个 PML 组件。 最初，所有可用的 PML 都被加载（可能作为共享库）并调用它们的组件打开和初始化函数。 MCA 框架选择返回最高优先级的组件并关闭/卸载可能已打开的任何其他 PML 组件。</p>
<p>在初始化所有 MCA 组件之后，MPI/RTE 将对 PML 进行向下调用，以提供进程的初始列表（ompi_proc_t 实例）和更改通知（添加/删除）。PML 模块必须选择一组用于达到给定目的地的 BTL 组件。这些应缓存在挂在 ompi_proc_t 之外的 PML 特定数据结构上，也就是说PML层应该给它定义的一系列通信函数指针赋值，让PML层知道该调用哪些函数。然后，PML 应该应用调度算法（循环、加权分布等）来调度可用 BTL 上的消息传递。</p>
<h1 id="MTL"><a href="#MTL" class="headerlink" title="MTL"></a>MTL</h1><p>Matching Transport Layer匹配传输层 (MTL) 为通过支持硬件/库消息匹配的设备传输 MPI 点对点消息提供设备层支持。该层与 MTL PML 组件一起使用，以在给定架构上提供最低延迟和最高带宽。 上层不提供其他 PML 接口中的功能，例如消息分段、多设备支持和 NIC 故障转移。 通常，此接口不应用于传输层支持。 相反，应该使用 BTL 接口。 BTL 接口允许在多个用户之间进行多路复用（点对点、单面等），并提供了该接口中没有的许多功能（来自任意缓冲区的 RDMA、主动消息传递、合理的固定内存缓存等）</p>
<p>这应该是一个接口层，负责调用底层真正通信的函数。</p>
<p>阻塞发送（调用不应该返回，直到用户缓冲区可以再次使用）。此调用必须满足标准 MPI 语义，如 mode 参数中所要求的。有一个特殊的模式参数，MCA_PML_BASE_SEND_COMPLETE，它需要在函数返回之前本地完成。这是对集体惯例的优化，否则会导致基于广播的集体的性能退化。</p>
<p>Open MPI 是围绕非阻塞操作构建的。此功能适用于在不定期触发进度功能的情况下可能发生点对点之外的进展事件（例如，集体、I/O、单面）的网络。</p>
<p>虽然 MPI 不允许用户指定否定标签，但它们在 Open MPI 内部用于为集体操作提供独特的渠道。因此，如果使用否定标签，MTL <em>不会</em>导致错误。</p>
<p>非阻塞发送到对等方。此调用必须满足标准 MPI 语义，如 mode 参数中所要求的。有一个特殊的模式参数，MCA_PML_BASE_SEND_COMPLETE，它需要在请求被标记为完成之前本地完成。</p>
<p>PML 将处理请求的创建，将模块结构中请求的字节数直接放在 ompi_request_t 结构之后可用于 MTL。一旦可以安全地销毁请求（它已通过调用 REQUEST_FReE 或 TEST/WAIT 完成并释放），PML 将处理请求的适当销毁。当请求被标记为已完成时，MTL 应删除与请求关联的所有资源。</p>
<p>虽然 MPI 不允许用户指定否定标签，但它们在 Open MPI 内部用于为集体操作提供独特的渠道。因此，如果使用否定标签，MTL <em>不会</em>导致错误。</p>
<h1 id="OSC"><a href="#OSC" class="headerlink" title="OSC"></a>OSC</h1><p>One-sided Communication(OSC) 用于实现 MPI-2 标准的单向通信章节的接口。 在范围上类似于来自 MPI-1 的点对点通信的 PML。有以下几个主要函数：</p>
<ul>
<li>OSC component initialization：初始化给定的单边组件。 此函数应初始化任何组件级数据。组件框架不会延迟打开，因此应尽量减少在此功能期间分配的内存量。</li>
<li>OSC component finalization：结束给定的单边组件。 此函数应清除在 component_init() 期间分配的任何组件级数据。 它还应该清理在组件生命周期内创建的任何数据，包括任何未完成的模块。</li>
<li>OSC component query：查询给定info和comm，组件是否可以用于单边通信。 能够将组件用于窗口并不意味着该组件将被选中。 在此调用期间不应修改 win 参数，并且不应分配与此窗口关联的内存。</li>
<li>OSC component select：已选择此组件来为给定窗口提供单方面的服务。 win-&gt;w_osc_module 字段可以更新，内存可以与此窗口相关联。 该模块应在此函数返回后立即准备好使用，并且该模块负责在调用结束之前提供任何所需的集体同步。comm 是用户指定的通信器，因此适用正常的内部使用规则。 换句话说，如果您需要在窗口的生命周期内进行通信，则应在此函数期间调用 comm_dup()。</li>
</ul>
<h1 id="MPI-Init"><a href="#MPI-Init" class="headerlink" title="MPI_Init"></a>MPI_Init</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="keyword">char</span> FUNC_NAME[] = <span class="string">"MPI_Init"</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Init</span><span class="params">(<span class="keyword">int</span> *argc, <span class="keyword">char</span> ***argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line">    <span class="keyword">int</span> provided;</span><br><span class="line">    <span class="keyword">char</span> *env;</span><br><span class="line">    <span class="keyword">int</span> required = MPI_THREAD_SINGLE;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* check for environment overrides for required thread level.  If</span></span><br><span class="line"><span class="comment">       there is, check to see that it is a valid/supported thread level.</span></span><br><span class="line"><span class="comment">       If not, default to MPI_THREAD_MULTIPLE. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> != (env = getenv(<span class="string">"OMPI_MPI_THREAD_LEVEL"</span>))) &#123;</span><br><span class="line">        required = atoi(env);</span><br><span class="line">        <span class="keyword">if</span> (required &lt; MPI_THREAD_SINGLE || required &gt; MPI_THREAD_MULTIPLE) &#123;</span><br><span class="line">            required = MPI_THREAD_MULTIPLE;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查多线程相关的命令行参数</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Call the back-end initialization function (we need to put as</span></span><br><span class="line"><span class="comment">       little in this function as possible so that if it's profiled, we</span></span><br><span class="line"><span class="comment">       don't lose anything) 这个函数在下边了</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> != argc &amp;&amp; <span class="literal">NULL</span> != argv) &#123;</span><br><span class="line">        err = ompi_mpi_init(*argc, *argv, required, &amp;provided, <span class="literal">false</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        err = ompi_mpi_init(<span class="number">0</span>, <span class="literal">NULL</span>, required, &amp;provided, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Since we don't have a communicator to invoke an errorhandler on</span></span><br><span class="line"><span class="comment">       here, don't use the fancy-schmancy ERRHANDLER macros; they're</span></span><br><span class="line"><span class="comment">       really designed for real communicator objects.  Just use the</span></span><br><span class="line"><span class="comment">       back-end function directly. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">        <span class="keyword">return</span> ompi_errhandler_invoke(<span class="literal">NULL</span>, <span class="literal">NULL</span>,</span><br><span class="line">                                      OMPI_ERRHANDLER_TYPE_COMM,</span><br><span class="line">                                      err &lt;</span><br><span class="line">                                      <span class="number">0</span> ? ompi_errcode_get_mpi_code(err) :</span><br><span class="line">                                      err, FUNC_NAME);</span><br><span class="line">    &#125; <span class="comment">// 如果初始化函数返回的不是 MPI_SUCCESS， 就返回错误码</span></span><br><span class="line"></span><br><span class="line">    SPC_INIT(); <span class="comment">// 初始化调用函数的计时器</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>ompi_mpi_init</code>是真正mpi初始化的函数。内部设计的很精细，因为要考虑很多多线程同时操作的情况，在各个地方都加了锁。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_mpi_init</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv, <span class="keyword">int</span> requested, <span class="keyword">int</span> *provided,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">bool</span> reinit_ok)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line">    <span class="keyword">char</span> *error = <span class="literal">NULL</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_USING_INTERNAL_PMIX</span></span><br><span class="line">    <span class="keyword">char</span> *evar;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">bool</span> active;</span><br><span class="line">    <span class="keyword">bool</span> background_fence = <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">pmix_info_t</span> info[<span class="number">2</span>];</span><br><span class="line">    <span class="keyword">pmix_status_t</span> rc;</span><br><span class="line">    OMPI_TIMING_INIT(<span class="number">64</span>);</span><br><span class="line"></span><br><span class="line">    ompi_hook_base_mpi_init_top(argc, argv, requested, provided);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Ensure that we were not already initialized or finalized. */</span></span><br><span class="line">    <span class="keyword">int32_t</span> expected = OMPI_MPI_STATE_NOT_INITIALIZED;</span><br><span class="line">    <span class="keyword">int32_t</span> desired  = OMPI_MPI_STATE_INIT_STARTED;</span><br><span class="line">    opal_atomic_wmb(); <span class="comment">// 内存同步？</span></span><br><span class="line">    <span class="keyword">if</span> (!opal_atomic_compare_exchange_strong_32(&amp;ompi_mpi_state, &amp;expected,</span><br><span class="line">                                                desired)) &#123;</span><br><span class="line">        <span class="comment">// 此内置函数实现了原子比较和交换操作。这会将 ompi_mpi_state 的内容与 expected 的内容进行比较。</span></span><br><span class="line">        <span class="comment">// 如果相等，则该操作是将 desired 写入 ompi_mpi_state。</span></span><br><span class="line">        <span class="comment">// 如果它们不相等，操作是读取和 ompi_mpi_state 写入 expected。 </span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 避免多个进程/线程同时修改当前MPI状态</span></span><br><span class="line">        <span class="comment">// If we failed to atomically transition ompi_mpi_state from</span></span><br><span class="line">        <span class="comment">// NOT_INITIALIZED to INIT_STARTED, then someone else already</span></span><br><span class="line">        <span class="comment">// did that, and we should return.</span></span><br><span class="line">        <span class="keyword">if</span> (expected &gt;= OMPI_MPI_STATE_FINALIZE_STARTED) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-runtime.txt"</span>,</span><br><span class="line">                           <span class="string">"mpi_init: already finalized"</span>, <span class="literal">true</span>);</span><br><span class="line">            <span class="keyword">return</span> MPI_ERR_OTHER;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (expected &gt;= OMPI_MPI_STATE_INIT_STARTED) &#123;</span><br><span class="line">            <span class="comment">// In some cases (e.g., oshmem_shmem_init()), we may call</span></span><br><span class="line">            <span class="comment">// ompi_mpi_init() multiple times.  In such cases, just</span></span><br><span class="line">            <span class="comment">// silently return successfully once the initializing</span></span><br><span class="line">            <span class="comment">// thread has completed.</span></span><br><span class="line">            <span class="keyword">if</span> (reinit_ok) &#123;</span><br><span class="line">                <span class="keyword">while</span> (ompi_mpi_state &lt; OMPI_MPI_STATE_INIT_COMPLETED) &#123;</span><br><span class="line">                    usleep(<span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-runtime.txt"</span>,</span><br><span class="line">                           <span class="string">"mpi_init: invoked multiple times"</span>, <span class="literal">true</span>);</span><br><span class="line">            <span class="keyword">return</span> MPI_ERR_OTHER;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* deal with OPAL_PREFIX to ensure that an internal PMIx installation</span></span><br><span class="line"><span class="comment">     * is also relocated if necessary */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_USING_INTERNAL_PMIX</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> != (evar = getenv(<span class="string">"OPAL_PREFIX"</span>))) &#123;</span><br><span class="line">        opal_setenv(<span class="string">"PMIX_PREFIX"</span>, evar, <span class="literal">true</span>, &amp;environ);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    ompi_mpi_thread_level(requested, provided); <span class="comment">// 设置线程级别</span></span><br><span class="line"></span><br><span class="line">    ret = ompi_mpi_instance_init (*provided, &amp;ompi_mpi_info_null.info.super, MPI_ERRORS_ARE_FATAL, &amp;ompi_mpi_instance_default);</span><br><span class="line">    <span class="comment">// 创建一个新的MPI实例，</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">        error = <span class="string">"ompi_mpi_init: ompi_mpi_instance_init failed"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ompi_hook_base_mpi_init_top_post_opal(argc, argv, requested, provided);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* initialize communicator subsystem,</span></span><br><span class="line"><span class="comment">    communicator MPI_COMM_WORLD and MPI_COMM_SELF</span></span><br><span class="line"><span class="comment">    </span></span><br><span class="line"><span class="comment">    构建通信域结构体，保存进程数信息</span></span><br><span class="line"><span class="comment">    通过ompi_group_translate_ranks函数得到rank</span></span><br><span class="line"><span class="comment">    通过遍历找到通信域内与本进程对应的rank么</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS != (ret = ompi_comm_init_mpi3 ())) &#123;</span><br><span class="line">        error = <span class="string">"ompi_mpi_init: ompi_comm_init_mpi3 failed"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Bozo argument check */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == argv &amp;&amp; argc &gt; <span class="number">1</span>) &#123;</span><br><span class="line">        ret = OMPI_ERR_BAD_PARAM;</span><br><span class="line">        error = <span class="string">"argc &gt; 1, but argv == NULL"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* if we were not externally started, then we need to setup</span></span><br><span class="line"><span class="comment">     * some envars so the MPI_INFO_ENV can get the cmd name</span></span><br><span class="line"><span class="comment">     * and argv (but only if the user supplied a non-NULL argv!), and</span></span><br><span class="line"><span class="comment">     * the requested thread level</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == getenv(<span class="string">"OMPI_COMMAND"</span>) &amp;&amp; <span class="literal">NULL</span> != argv &amp;&amp; <span class="literal">NULL</span> != argv[<span class="number">0</span>]) &#123;</span><br><span class="line">        opal_setenv(<span class="string">"OMPI_COMMAND"</span>, argv[<span class="number">0</span>], <span class="literal">true</span>, &amp;environ);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == getenv(<span class="string">"OMPI_ARGV"</span>) &amp;&amp; <span class="number">1</span> &lt; argc) &#123;</span><br><span class="line">        <span class="keyword">char</span> *tmp;</span><br><span class="line">        tmp = opal_argv_join(&amp;argv[<span class="number">1</span>], <span class="string">' '</span>);</span><br><span class="line">        opal_setenv(<span class="string">"OMPI_ARGV"</span>, tmp, <span class="literal">true</span>, &amp;environ);</span><br><span class="line">        <span class="built_in">free</span>(tmp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> (OPAL_ENABLE_TIMING)</span></span><br><span class="line">    <span class="keyword">if</span> (OMPI_TIMING_ENABLED &amp;&amp; !opal_pmix_base_async_modex &amp;&amp;</span><br><span class="line">            opal_pmix_collect_all_data &amp;&amp; !ompi_singleton) &#123;</span><br><span class="line">        <span class="keyword">if</span> (PMIX_SUCCESS != (rc = PMIx_Fence(<span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="number">0</span>))) &#123;</span><br><span class="line">            ret = opal_pmix_convert_status(rc);</span><br><span class="line">            error = <span class="string">"timing: pmix-barrier-1 failed"</span>;</span><br><span class="line">            <span class="keyword">goto</span> error;</span><br><span class="line">        &#125;</span><br><span class="line">        OMPI_TIMING_NEXT(<span class="string">"pmix-barrier-1"</span>);</span><br><span class="line">        <span class="keyword">if</span> (PMIX_SUCCESS != (rc = PMIx_Fence(<span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="number">0</span>))) &#123;</span><br><span class="line">            ret = opal_pmix_convert_status(rc);</span><br><span class="line">            error = <span class="string">"timing: pmix-barrier-2 failed"</span>;</span><br><span class="line">            <span class="keyword">goto</span> error;</span><br><span class="line">        &#125;</span><br><span class="line">        OMPI_TIMING_NEXT(<span class="string">"pmix-barrier-2"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!ompi_singleton) &#123;</span><br><span class="line">        <span class="keyword">if</span> (opal_pmix_base_async_modex) &#123;</span><br><span class="line">            <span class="comment">/* if we are doing an async modex, but we are collecting all</span></span><br><span class="line"><span class="comment">             * data, then execute the non-blocking modex in the background.</span></span><br><span class="line"><span class="comment">             * All calls to modex_recv will be cached until the background</span></span><br><span class="line"><span class="comment">             * modex completes. If collect_all_data is false, then we skip</span></span><br><span class="line"><span class="comment">             * the fence completely and retrieve data on-demand from the</span></span><br><span class="line"><span class="comment">             * source node.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (opal_pmix_collect_all_data) &#123;</span><br><span class="line">                <span class="comment">/* execute the fence_nb in the background to collect</span></span><br><span class="line"><span class="comment">                 * the data */</span></span><br><span class="line">                background_fence = <span class="literal">true</span>;</span><br><span class="line">                active = <span class="literal">true</span>;</span><br><span class="line">                OPAL_POST_OBJECT(&amp;active);</span><br><span class="line">                PMIX_INFO_LOAD(&amp;info[<span class="number">0</span>], PMIX_COLLECT_DATA, &amp;opal_pmix_collect_all_data, PMIX_BOOL);</span><br><span class="line">                <span class="keyword">if</span>( PMIX_SUCCESS != (rc = PMIx_Fence_nb(<span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="number">0</span>,</span><br><span class="line">                                                        fence_release,</span><br><span class="line">                                                        (<span class="keyword">void</span>*)&amp;active))) &#123;</span><br><span class="line">                    ret = opal_pmix_convert_status(rc);</span><br><span class="line">                    error = <span class="string">"PMIx_Fence_nb() failed"</span>;</span><br><span class="line">                    <span class="keyword">goto</span> error;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* we want to do the modex - we block at this point, but we must</span></span><br><span class="line"><span class="comment">             * do so in a manner that allows us to call opal_progress so our</span></span><br><span class="line"><span class="comment">             * event library can be cycled as we have tied PMIx to that</span></span><br><span class="line"><span class="comment">             * event base */</span></span><br><span class="line">            active = <span class="literal">true</span>;</span><br><span class="line">            OPAL_POST_OBJECT(&amp;active);</span><br><span class="line">            PMIX_INFO_LOAD(&amp;info[<span class="number">0</span>], PMIX_COLLECT_DATA, &amp;opal_pmix_collect_all_data, PMIX_BOOL);</span><br><span class="line">            rc = PMIx_Fence_nb(<span class="literal">NULL</span>, <span class="number">0</span>, info, <span class="number">1</span>, fence_release, (<span class="keyword">void</span>*)&amp;active);</span><br><span class="line">            <span class="keyword">if</span>( PMIX_SUCCESS != rc) &#123;</span><br><span class="line">                ret = opal_pmix_convert_status(rc);</span><br><span class="line">                error = <span class="string">"PMIx_Fence() failed"</span>;</span><br><span class="line">                <span class="keyword">goto</span> error;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* cannot just wait on thread as we need to call opal_progress */</span></span><br><span class="line">            OMPI_LAZY_WAIT_FOR_COMPLETION(active);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OMPI_TIMING_NEXT(<span class="string">"modex"</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 把当前这两个通信域加进来</span></span><br><span class="line">    MCA_PML_CALL(add_comm(&amp;ompi_mpi_comm_world.comm));</span><br><span class="line">    MCA_PML_CALL(add_comm(&amp;ompi_mpi_comm_self.comm));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这是fault tolerant相关的结构</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_FT_MPI</span></span><br><span class="line">    <span class="comment">/* initialize the fault tolerant infrastructure (revoke, detector,</span></span><br><span class="line"><span class="comment">     * propagator) */</span></span><br><span class="line">    <span class="keyword">if</span>( ompi_ftmpi_enabled ) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *evmethod;</span><br><span class="line">        rc = ompi_comm_rbcast_init();</span><br><span class="line">        <span class="keyword">if</span>( OMPI_SUCCESS != rc ) <span class="keyword">return</span> rc;</span><br><span class="line">        rc = ompi_comm_revoke_init();</span><br><span class="line">        <span class="keyword">if</span>( OMPI_SUCCESS != rc ) <span class="keyword">return</span> rc;</span><br><span class="line">        rc = ompi_comm_failure_propagator_init();</span><br><span class="line">        <span class="keyword">if</span>( OMPI_SUCCESS != rc ) <span class="keyword">return</span> rc;</span><br><span class="line">        rc = ompi_comm_failure_detector_init();</span><br><span class="line">        <span class="keyword">if</span>( OMPI_SUCCESS != rc ) <span class="keyword">return</span> rc;</span><br><span class="line"></span><br><span class="line">        evmethod = event_base_get_method(opal_sync_event_base);</span><br><span class="line">        <span class="keyword">if</span>( <span class="number">0</span> == <span class="built_in">strcmp</span>(<span class="string">"select"</span>, evmethod) ) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-ft.txt"</span>, <span class="string">"module:event:selectbug"</span>, <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Dump all MCA parameters if requested</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (ompi_mpi_show_mca_params) &#123;</span><br><span class="line">        ompi_show_all_mca_params(ompi_mpi_comm_world.comm.c_my_rank,</span><br><span class="line">                                 ompi_process_info.num_procs,</span><br><span class="line">                                 ompi_process_info.nodename);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Do we need to wait for a debugger? */</span></span><br><span class="line">    ompi_rte_wait_for_debugger();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Next timing measurement */</span></span><br><span class="line">    OMPI_TIMING_NEXT(<span class="string">"modex-barrier"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!ompi_singleton) &#123;</span><br><span class="line">        <span class="comment">/* if we executed the above fence in the background, then</span></span><br><span class="line"><span class="comment">         * we have to wait here for it to complete. However, there</span></span><br><span class="line"><span class="comment">         * is no reason to do two barriers! */</span></span><br><span class="line">        <span class="keyword">if</span> (background_fence) &#123;</span><br><span class="line">            OMPI_LAZY_WAIT_FOR_COMPLETION(active);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!ompi_async_mpi_init) &#123;</span><br><span class="line">            <span class="comment">/* wait for everyone to reach this point - this is a hard</span></span><br><span class="line"><span class="comment">             * barrier requirement at this time, though we hope to relax</span></span><br><span class="line"><span class="comment">             * it at a later point */</span></span><br><span class="line">            <span class="keyword">bool</span> flag = <span class="literal">false</span>;</span><br><span class="line">            active = <span class="literal">true</span>;</span><br><span class="line">            OPAL_POST_OBJECT(&amp;active);</span><br><span class="line">            PMIX_INFO_LOAD(&amp;info[<span class="number">0</span>], PMIX_COLLECT_DATA, &amp;flag, PMIX_BOOL);</span><br><span class="line">            <span class="keyword">if</span> (PMIX_SUCCESS != (rc = PMIx_Fence_nb(<span class="literal">NULL</span>, <span class="number">0</span>, info, <span class="number">1</span>,</span><br><span class="line">                                                    fence_release, (<span class="keyword">void</span>*)&amp;active))) &#123;</span><br><span class="line">                ret = opal_pmix_convert_status(rc);</span><br><span class="line">                error = <span class="string">"PMIx_Fence_nb() failed"</span>;</span><br><span class="line">                <span class="keyword">goto</span> error;</span><br><span class="line">            &#125;</span><br><span class="line">            OMPI_LAZY_WAIT_FOR_COMPLETION(active);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* check for timing request - get stop time and report elapsed</span></span><br><span class="line"><span class="comment">       time if so, then start the clock again */</span></span><br><span class="line">    OMPI_TIMING_NEXT(<span class="string">"barrier"</span>);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_PROGRESS_THREADS == 0</span></span><br><span class="line">    <span class="comment">/* Start setting up the event engine for MPI operations.  Don't</span></span><br><span class="line"><span class="comment">       block in the event library, so that communications don't take</span></span><br><span class="line"><span class="comment">       forever between procs in the dynamic code.  This will increase</span></span><br><span class="line"><span class="comment">       CPU utilization for the remainder of MPI_INIT when we are</span></span><br><span class="line"><span class="comment">       blocking on RTE-level events, but may greatly reduce non-TCP</span></span><br><span class="line"><span class="comment">       latency. */</span></span><br><span class="line">    <span class="keyword">int</span> old_event_flags = opal_progress_set_event_flag(<span class="number">0</span>);</span><br><span class="line">    opal_progress_set_event_flag(old_event_flags | OPAL_EVLOOP_NONBLOCK);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* wire up the mpi interface, if requested.  Do this after the</span></span><br><span class="line"><span class="comment">       non-block switch for non-TCP performance.  Do before the</span></span><br><span class="line"><span class="comment">       polling change as anyone with a complex wire-up is going to be</span></span><br><span class="line"><span class="comment">       using the oob. </span></span><br><span class="line"><span class="comment">        预先执行一些MPI send recv，建立连接？</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS != (ret = ompi_init_preconnect_mpi())) &#123;</span><br><span class="line">        error = <span class="string">"ompi_mpi_do_preconnect_all() failed"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Init coll for the comms. This has to be after dpm_base_select,</span></span><br><span class="line"><span class="comment">       (since dpm.mark_dyncomm is not set in the communicator creation</span></span><br><span class="line"><span class="comment">       function else), but before dpm.dyncom_init, since this function</span></span><br><span class="line"><span class="comment">       might require collective for the CID allocation. </span></span><br><span class="line"><span class="comment">       设置集合通信相关的函数指针</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS !=</span><br><span class="line">        (ret = mca_coll_base_comm_select(MPI_COMM_WORLD))) &#123;</span><br><span class="line">        error = <span class="string">"mca_coll_base_comm_select(MPI_COMM_WORLD) failed"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS !=</span><br><span class="line">        (ret = mca_coll_base_comm_select(MPI_COMM_SELF))) &#123;</span><br><span class="line">        error = <span class="string">"mca_coll_base_comm_select(MPI_COMM_SELF) failed"</span>;</span><br><span class="line">        <span class="keyword">goto</span> error;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_FT_MPI</span></span><br><span class="line">    <span class="comment">/* start the failure detector */</span></span><br><span class="line">    <span class="keyword">if</span>( ompi_ftmpi_enabled ) &#123;</span><br><span class="line">        rc = ompi_comm_failure_detector_start();</span><br><span class="line">        <span class="keyword">if</span>( OMPI_SUCCESS != rc ) <span class="keyword">return</span> rc;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Check whether we have been spawned or not.  We introduce that</span></span><br><span class="line"><span class="comment">       at the very end, since we need collectives, datatypes, ptls</span></span><br><span class="line"><span class="comment">       etc. up and running here.... </span></span><br><span class="line"><span class="comment">        此例程检查应用程序是否已由另一个 MPI 应用程序生成，或者是否已独立启动。</span></span><br><span class="line"><span class="comment">        如果它已经产生，它建立父通信器。</span></span><br><span class="line"><span class="comment">        由于例程必须进行通信，因此它应该是 MPI_Init 的最后一步，以确保一切都已设置好。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS != (ret = ompi_dpm_dyn_init())) &#123;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Fall through */</span></span><br><span class="line"> error:</span><br><span class="line">    <span class="keyword">if</span> (ret != OMPI_SUCCESS) &#123;</span><br><span class="line">        <span class="comment">/* Only print a message if one was not already printed */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> != error &amp;&amp; OMPI_ERR_SILENT != ret) &#123;</span><br><span class="line">            <span class="keyword">const</span> <span class="keyword">char</span> *err_msg = opal_strerror(ret);</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-runtime.txt"</span>,</span><br><span class="line">                           <span class="string">"mpi_init:startup:internal-failure"</span>, <span class="literal">true</span>,</span><br><span class="line">                           <span class="string">"MPI_INIT"</span>, <span class="string">"MPI_INIT"</span>, error, err_msg, ret);</span><br><span class="line">        &#125;</span><br><span class="line">        ompi_hook_base_mpi_init_error(argc, argv, requested, provided);</span><br><span class="line">        OMPI_TIMING_FINALIZE;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* All done.  Wasn't that simple? */</span></span><br><span class="line">    opal_atomic_wmb();</span><br><span class="line">    opal_atomic_swap_32(&amp;ompi_mpi_state, OMPI_MPI_STATE_INIT_COMPLETED);</span><br><span class="line">    <span class="comment">// 原子性地设置标志位为已完成初始化</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Finish last measurement, output results</span></span><br><span class="line"><span class="comment">     * and clear timing structure */</span></span><br><span class="line">    OMPI_TIMING_NEXT(<span class="string">"barrier-finish"</span>);</span><br><span class="line">    OMPI_TIMING_OUT;</span><br><span class="line">    OMPI_TIMING_FINALIZE;</span><br><span class="line"></span><br><span class="line">    ompi_hook_base_mpi_init_bottom(argc, argv, requested, provided);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这里分别搞了两个communicator，分别是word和self，communicator有以下的状态，看英文就能看出来意思，通过位运算设置状态。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_INTER        0x00000001</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_NAMEISSET    0x00000002</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_INTRINSIC    0x00000004</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_DYNAMIC      0x00000008</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_ISFREED      0x00000010</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_INVALID      0x00000020</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_CART         0x00000100</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_GRAPH        0x00000200</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_DIST_GRAPH   0x00000400</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_PML_ADDED    0x00001000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_EXTRA_RETAIN 0x00004000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_MAPBY_NODE   0x00008000</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COMM_GLOBAL_INDEX 0x00010000</span></span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Comm-rank"><a href="#MPI-Comm-rank" class="headerlink" title="MPI_Comm_rank"></a>MPI_Comm_rank</h1><p>MPI_Comm_rank是获得进程在通信域的rank。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Comm_rank</span><span class="params">(MPI_Comm comm, <span class="keyword">int</span> *rank)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    MEMCHECKER(</span><br><span class="line">        memchecker_comm(comm);</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( MPI_PARAM_CHECK ) &#123;</span><br><span class="line">        OMPI_ERR_INIT_FINALIZE(FUNC_NAME);</span><br><span class="line">        <span class="comment">// 需要检查MPI是否已经初始化完成了，MPI通信域是不是合法的通信域，rank指针是否是空指针。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// MPI-2:4.12.4 明确指出 MPI_*_C2F 和 MPI_*_F2C 函数应将 MPI_COMM_NULL 视为有效的通信器</span></span><br><span class="line">        <span class="comment">// openmpi将 ompi_comm_invalid() 保留为原始编码——根据 MPI-1 定义，其中 MPI_COMM_NULL 是无效的通信域。</span></span><br><span class="line">        <span class="comment">// 因此，MPI_Comm_c2f() 函数调用 ompi_comm_invalid() 但也显式检查句柄是否为 MPI_COMM_NULL。</span></span><br><span class="line">        <span class="keyword">if</span> (ompi_comm_invalid (comm))</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERRHANDLER_NOHANDLE_INVOKE(MPI_ERR_COMM,</span><br><span class="line">                                          FUNC_NAME);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ( <span class="literal">NULL</span> == rank )</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERRHANDLER_INVOKE(comm, MPI_ERR_ARG,</span><br><span class="line">                                          FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    *rank = ompi_comm_rank((<span class="keyword">ompi_communicator_t</span>*)comm);</span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br></pre></td></tr></table></figure></p>
<p><code>ompi_comm_rank</code>这个函数主要是返回结构体<code>ompi_communicator_t</code>的变量，结构体<code>ompi_communicator_t</code>如下，包括了集合通信，笛卡尔结构相关的数据结构<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_communicator_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">opal_infosubscriber_t</span>      super;</span><br><span class="line">    <span class="keyword">opal_mutex_t</span>               c_lock; <span class="comment">/* 互斥锁，为了修改变量用的可能 */</span></span><br><span class="line">    <span class="keyword">char</span>  c_name[MPI_MAX_OBJECT_NAME]; <span class="comment">/* 比如MPI_COMM_WORLD之类的 */</span></span><br><span class="line">    <span class="keyword">ompi_comm_extended_cid_t</span>      c_contextid;</span><br><span class="line">    <span class="keyword">ompi_comm_extended_cid_block_t</span> c_contextidb;</span><br><span class="line">    <span class="keyword">uint32_t</span>                      c_index;</span><br><span class="line">    <span class="keyword">int</span>                           c_my_rank;</span><br><span class="line">    <span class="keyword">uint32_t</span>                      c_flags; <span class="comment">/* flags, e.g. intercomm,</span></span><br><span class="line"><span class="comment">                                              topology, etc. */</span></span><br><span class="line">    <span class="keyword">uint32_t</span>                      c_assertions; <span class="comment">/* info assertions */</span></span><br><span class="line">    <span class="keyword">int</span> c_id_available; <span class="comment">/* the currently available Cid for allocation</span></span><br><span class="line"><span class="comment">               to a child*/</span></span><br><span class="line">    <span class="keyword">int</span> c_id_start_index; <span class="comment">/* the starting index of the block of cids</span></span><br><span class="line"><span class="comment">                 allocated to this communicator*/</span></span><br><span class="line">    <span class="keyword">uint32_t</span> c_epoch;  <span class="comment">/* Identifier used to differenciate between two communicators</span></span><br><span class="line"><span class="comment">                          using the same c_contextid (not at the same time, obviously) */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">ompi_group_t</span>        *c_local_group;</span><br><span class="line">    <span class="keyword">ompi_group_t</span>       *c_remote_group;  <span class="comment">// 应该是存储了属于这个通信组的proc？</span></span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_communicator_t</span> *<span class="title">c_local_comm</span>;</span> <span class="comment">/* a duplicate of the</span></span><br><span class="line"><span class="comment">                                                 local communicator in</span></span><br><span class="line"><span class="comment">                                                 case the comm is an</span></span><br><span class="line"><span class="comment">                                                 inter-comm*/</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Attributes */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">opal_hash_table_t</span>       *<span class="title">c_keyhash</span>;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这些应该是笛卡尔结构相关的</span></span><br><span class="line">    <span class="comment">/**&lt; inscribing cube dimension */</span></span><br><span class="line">    <span class="keyword">int</span> c_cube_dim;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Standard information about the selected topology module (or NULL</span></span><br><span class="line"><span class="comment">       if this is not a cart, graph or dist graph communicator) */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mca_topo_base_module_t</span>* <span class="title">c_topo</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* index in Fortran &lt;-&gt; C translation array */</span></span><br><span class="line">    <span class="keyword">int</span> c_f_to_c_index;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> OMPI_WANT_PERUSE</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Place holder for the PERUSE events.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_peruse_handle_t</span>** <span class="title">c_peruse_handles</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Error handling.  This field does not have the "c_" prefix so</span></span><br><span class="line"><span class="comment">       that the OMPI_ERRHDL_* macros can find it, regardless of whether</span></span><br><span class="line"><span class="comment">       it's a comm, window, or file. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">ompi_errhandler_t</span>                  *error_handler;</span><br><span class="line">    <span class="keyword">ompi_errhandler_type_t</span>             errhandler_type;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Hooks for PML to hang things */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mca_pml_comm_t</span>  *<span class="title">c_pml_comm</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Hooks for MTL to hang things */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mca_mtl_comm_t</span>  *<span class="title">c_mtl_comm</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Collectives module interface and data */</span></span><br><span class="line">    <span class="keyword">mca_coll_base_comm_coll_t</span> *c_coll;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Non-blocking collective tag. These tags might be shared between</span></span><br><span class="line"><span class="comment">     * all non-blocking collective modules (to avoid message collision</span></span><br><span class="line"><span class="comment">     * between them in the case where multiple outstanding non-blocking</span></span><br><span class="line"><span class="comment">     * collective coexists using multiple backends).</span></span><br><span class="line"><span class="comment">     * 非阻塞的集合通信</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">opal_atomic_int32_t</span> c_nbc_tag;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* instance that this comm belongs to */</span></span><br><span class="line">    <span class="keyword">ompi_instance_t</span>* instance;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_FT_MPI</span></span><br><span class="line">    <span class="comment">/** MPI_ANY_SOURCE Failed Group Offset - OMPI_Comm_failure_get_acked */</span></span><br><span class="line">    <span class="keyword">int</span>                      any_source_offset;</span><br><span class="line">    <span class="comment">/** agreement caching info for topology and previous returned decisions */</span></span><br><span class="line">    <span class="keyword">opal_object_t</span>           *agreement_specific;</span><br><span class="line">    <span class="comment">/** Are MPI_ANY_SOURCE operations enabled? - OMPI_Comm_failure_ack */</span></span><br><span class="line">    <span class="keyword">bool</span>                     any_source_enabled;</span><br><span class="line">    <span class="comment">/** Has this communicator been revoked - OMPI_Comm_revoke() */</span></span><br><span class="line">    <span class="keyword">bool</span>                     comm_revoked;</span><br><span class="line">    <span class="comment">/** Force errors to collective pt2pt operations? */</span></span><br><span class="line">    <span class="keyword">bool</span>                     coll_revoked;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* OPAL_ENABLE_FT_MPI */</span></span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ompi_communicator_t</span> <span class="title">ompi_communicator_t</span>;</span></span><br></pre></td></tr></table></figure></p>
<p>保存属于这个通信组的进程，有四种方法。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Group structure</span></span><br><span class="line"><span class="comment"> * Currently we have four formats for storing the process pointers that are members</span></span><br><span class="line"><span class="comment"> * of the group.</span></span><br><span class="line"><span class="comment"> * PList: a dense format that stores all the process pointers of the group.</span></span><br><span class="line"><span class="comment"> * Sporadic: a sparse format that stores the ranges of the ranks from the parent group,</span></span><br><span class="line"><span class="comment"> *           that are included in the current group.</span></span><br><span class="line"><span class="comment"> * Strided: a sparse format that stores three integers that describe a red-black pattern</span></span><br><span class="line"><span class="comment"> *          that the current group is formed from its parent group.</span></span><br><span class="line"><span class="comment"> * Bitmap: a sparse format that maintains a bitmap of the included processes from the</span></span><br><span class="line"><span class="comment"> *         parent group. For each process that is included from the parent group</span></span><br><span class="line"><span class="comment"> *         its corresponding rank is set in the bitmap array.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">opal_object_t</span> super;    <span class="comment">/**&lt; base class */</span></span><br><span class="line">    <span class="keyword">int</span> grp_proc_count;     <span class="comment">/**&lt; number of processes in group */</span></span><br><span class="line">    <span class="keyword">int</span> grp_my_rank;        <span class="comment">/**&lt; rank in group */</span></span><br><span class="line">    <span class="keyword">int</span> grp_f_to_c_index;   <span class="comment">/**&lt; index in Fortran &lt;-&gt; C translation array */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_proc_t</span> **<span class="title">grp_proc_pointers</span>;</span></span><br><span class="line">                            <span class="comment">/**&lt; list of pointers to ompi_proc_t structures</span></span><br><span class="line"><span class="comment">                                 for each process in the group */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> grp_flags;     <span class="comment">/**&lt; flags, e.g. freed, cannot be freed etc.*/</span></span><br><span class="line">    <span class="comment">/** pointer to the original group when using sparse storage */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_t</span> *<span class="title">grp_parent_group_ptr</span>;</span></span><br><span class="line">    <span class="keyword">union</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_sporadic_data_t</span> <span class="title">grp_sporadic</span>;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_strided_data_t</span>  <span class="title">grp_strided</span>;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_bitmap_data_t</span>   <span class="title">grp_bitmap</span>;</span></span><br><span class="line">    &#125; sparse_data;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">ompi_instance_t</span> *grp_instance; <span class="comment">/**&lt; instance this group was allocated within */</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Abort"><a href="#MPI-Abort" class="headerlink" title="MPI_Abort"></a>MPI_Abort</h1><p><code>MPI_Abort</code>主要是打印错误信息后等待退出所有进程<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">ompi_mpi_abort(struct <span class="keyword">ompi_communicator_t</span>* comm,</span><br><span class="line">               <span class="keyword">int</span> errcode)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span> *host;</span><br><span class="line">    <span class="keyword">pid_t</span> pid = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Protection for recursive invocation */</span></span><br><span class="line">    <span class="keyword">if</span> (have_been_invoked) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">    have_been_invoked = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If MPI is initialized, we know we have a runtime nodename, so</span></span><br><span class="line"><span class="comment">       use that.  Otherwise, call opal_gethostname. */</span></span><br><span class="line">    <span class="keyword">if</span> (ompi_rte_initialized) &#123;</span><br><span class="line">        host = ompi_process_info.nodename;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        host = opal_gethostname();</span><br><span class="line">    &#125;</span><br><span class="line">    pid = getpid();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Should we print a stack trace?  Not aggregated because they</span></span><br><span class="line"><span class="comment">       might be different on all processes. */</span></span><br><span class="line">    <span class="keyword">if</span> (opal_abort_print_stack) &#123;</span><br><span class="line">        <span class="keyword">char</span> **messages;</span><br><span class="line">        <span class="keyword">int</span> len, i;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (OPAL_SUCCESS == opal_backtrace_buffer(&amp;messages, &amp;len)) &#123;</span><br><span class="line">            <span class="comment">// 调用了linux内部的backtrace函数打印调用栈，需要#include &lt;execinfo.h&gt;</span></span><br><span class="line">            <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; len; ++i) &#123;</span><br><span class="line">                <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"[%s:%05d] [%d] func:%s\n"</span>, host, (<span class="keyword">int</span>) pid,</span><br><span class="line">                        i, messages[i]);</span><br><span class="line">                fflush(<span class="built_in">stderr</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="built_in">free</span>(messages);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* This will print an message if it's unable to print the</span></span><br><span class="line"><span class="comment">               backtrace, so we don't need an additional "else" clause</span></span><br><span class="line"><span class="comment">               if opal_backtrace_print() is not supported. */</span></span><br><span class="line">            opal_backtrace_print(<span class="built_in">stderr</span>, <span class="literal">NULL</span>, <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Wait for a while before aborting */</span></span><br><span class="line">    opal_delay_abort();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If the RTE isn't setup yet/any more, then don't even try</span></span><br><span class="line"><span class="comment">       killing everyone.  Sorry, Charlie... */</span></span><br><span class="line">    <span class="keyword">int32_t</span> state = ompi_mpi_state;</span><br><span class="line">    <span class="keyword">if</span> (!ompi_rte_initialized) &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"[%s:%05d] Local abort %s completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!\n"</span>,</span><br><span class="line">                host, (<span class="keyword">int</span>) pid,</span><br><span class="line">                state &gt;= OMPI_MPI_STATE_FINALIZE_STARTED ?</span><br><span class="line">                <span class="string">"after MPI_FINALIZE started"</span> : <span class="string">"before MPI_INIT completed"</span>);</span><br><span class="line">        _exit(errcode == <span class="number">0</span> ? <span class="number">1</span> : errcode);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If OMPI is initialized and we have a non-NULL communicator,</span></span><br><span class="line"><span class="comment">       then try to kill just that set of processes */</span></span><br><span class="line">    <span class="keyword">if</span> (state &gt;= OMPI_MPI_STATE_INIT_COMPLETED &amp;&amp;</span><br><span class="line">        state &lt; OMPI_MPI_STATE_FINALIZE_PAST_COMM_SELF_DESTRUCT &amp;&amp;</span><br><span class="line">        <span class="literal">NULL</span> != comm) &#123;</span><br><span class="line">        try_kill_peers(comm, errcode); <span class="comment">/* kill only the specified groups, no return if it worked. */</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* We can fall through to here in a few cases:</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       1. The attempt to kill just a subset of peers via</span></span><br><span class="line"><span class="comment">          try_kill_peers() failed.</span></span><br><span class="line"><span class="comment">       2. MPI wasn't initialized, was already finalized, or we got a</span></span><br><span class="line"><span class="comment">          NULL communicator.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">       In all of these cases, the only sensible thing left to do is to</span></span><br><span class="line"><span class="comment">       kill the entire job.  Wah wah. */</span></span><br><span class="line">    ompi_rte_abort(errcode, <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Does not return - but we add a return to keep compiler warnings at bay*/</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Barrier"><a href="#MPI-Barrier" class="headerlink" title="MPI_Barrier"></a>MPI_Barrier</h1><p><code>MPI_Barrier</code>主要是检查参数之后调用<code>coll_barrier</code>。在两个进程的特例中，只有一个send-recv。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Barrier</span><span class="params">(MPI_Comm comm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> err = MPI_SUCCESS;</span><br><span class="line"></span><br><span class="line">  SPC_RECORD(OMPI_SPC_BARRIER, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  MEMCHECKER(</span><br><span class="line">    memchecker_comm(comm);</span><br><span class="line">  );</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Error checking */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (MPI_PARAM_CHECK) &#123;</span><br><span class="line">    OMPI_ERR_INIT_FINALIZE(FUNC_NAME);</span><br><span class="line">    <span class="keyword">if</span> (ompi_comm_invalid(comm)) &#123;</span><br><span class="line">      <span class="keyword">return</span> OMPI_ERRHANDLER_NOHANDLE_INVOKE(MPI_ERR_COMM, FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Intracommunicators: Only invoke the back-end coll module barrier</span></span><br><span class="line"><span class="comment">     function if there's more than one process in the communicator */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (OMPI_COMM_IS_INTRA(comm)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (ompi_comm_size(comm) &gt; <span class="number">1</span>) &#123;</span><br><span class="line">      err = comm-&gt;c_coll-&gt;coll_barrier(comm, comm-&gt;c_coll-&gt;coll_barrier_module);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Intercommunicators -- always invoke, because, by definition,</span></span><br><span class="line"><span class="comment">     there's always at least 2 processes in an intercommunicator. */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">      err = comm-&gt;c_coll-&gt;coll_barrier(comm, comm-&gt;c_coll-&gt;coll_barrier_module);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* All done */</span></span><br><span class="line"></span><br><span class="line">  OMPI_ERRHANDLER_RETURN(err, comm, err, FUNC_NAME);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>coll_barrier</code>应该是函数指针：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*<span class="keyword">mca_coll_base_module_barrier_fn_t</span>)</span></span></span><br><span class="line"><span class="function">  <span class="params">(struct <span class="keyword">ompi_communicator_t</span> *comm, struct <span class="keyword">mca_coll_base_module_2_4_0_t</span> *<span class="keyword">module</span>)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>函数指针可能的值有：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mca_coll_basic_barrier_inter_lin</span><br><span class="line">ompi_coll_base_barrier_intra_basic_linear</span><br><span class="line">mca_coll_basic_barrier_intra_log</span><br><span class="line"></span><br><span class="line">mca_scoll_basic_barrier</span><br><span class="line">mca_scoll_mpi_barrier</span><br><span class="line">scoll_null_barrier</span><br></pre></td></tr></table></figure></p>
<p>前三个是O(log(N))的，以<code>mca_coll_basic_barrier_intra_log</code>为例。这应该是将进程组织成树的形式，以位运算隐掉某一位来计算孩子进程号，通过send/recv空消息实现barrier。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span></span><br><span class="line">mca_coll_basic_barrier_intra_log(struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                                 <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line">    <span class="keyword">int</span> peer;</span><br><span class="line">    <span class="keyword">int</span> dim;</span><br><span class="line">    <span class="keyword">int</span> hibit;</span><br><span class="line">    <span class="keyword">int</span> mask;</span><br><span class="line">    <span class="keyword">int</span> size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">int</span> rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Send null-messages up and down the tree.  Synchronization at the</span></span><br><span class="line"><span class="comment">     * root (rank 0). */</span></span><br><span class="line"></span><br><span class="line">    dim = comm-&gt;c_cube_dim;</span><br><span class="line">    hibit = opal_hibit(rank, dim);</span><br><span class="line">    --dim;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Receive from children. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = dim, mask = <span class="number">1</span> &lt;&lt; i; i &gt; hibit; --i, mask &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">        peer = rank | mask;</span><br><span class="line">        <span class="keyword">if</span> (peer &lt; size) &#123;</span><br><span class="line">            err = MCA_PML_CALL(recv(<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, peer,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                    comm, MPI_STATUS_IGNORE));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">                <span class="keyword">return</span> err;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// children就是比我大的或者等于我的</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Send to and receive from parent. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rank &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        peer = rank &amp; ~(<span class="number">1</span> &lt;&lt; hibit);</span><br><span class="line">        err =</span><br><span class="line">            MCA_PML_CALL(send</span><br><span class="line">                         (<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, peer,</span><br><span class="line">                          MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                          MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">            <span class="keyword">return</span> err;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        err = MCA_PML_CALL(recv(<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, peer,</span><br><span class="line">                                MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                comm, MPI_STATUS_IGNORE));</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">            <span class="keyword">return</span> err;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// parent就是比自己小的，所以要把某一位变成0</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Send to children. */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = hibit + <span class="number">1</span>, mask = <span class="number">1</span> &lt;&lt; i; i &lt;= dim; ++i, mask &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        peer = rank | mask;</span><br><span class="line">        <span class="keyword">if</span> (peer &lt; size) &#123;</span><br><span class="line">            err = MCA_PML_CALL(send(<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, peer,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                    MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">                <span class="keyword">return</span> err;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* All done */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个直接是调用的allreduce，可省事了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *	barrier_inter_lin</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *	Function:	- barrier using O(log(N)) algorithm</span></span><br><span class="line"><span class="comment"> *	Accepts:	- same as MPI_Barrier()</span></span><br><span class="line"><span class="comment"> *	Returns:	- MPI_SUCCESS or error code</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">mca_coll_basic_barrier_inter_lin(struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                                 <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> rank;</span><br><span class="line">    <span class="keyword">int</span> result;</span><br><span class="line"></span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line">    <span class="keyword">return</span> comm-&gt;c_coll-&gt;coll_allreduce(&amp;rank, &amp;result, <span class="number">1</span>, MPI_INT, MPI_MAX,</span><br><span class="line">                                       comm, comm-&gt;c_coll-&gt;coll_allreduce_module);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>ompi_coll_base_barrier_intra_basic_linear</code>函数是从 BASIC coll 模块复制的，它不分割消息并且是简单的实现，但是对于一些少量节点和/或小数据大小，它们与基于树的分割操作一样快，因此可以选择这个。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_barrier_intra_basic_linear</span><span class="params">(struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, err, rank, size, line;</span><br><span class="line">    <span class="keyword">ompi_request_t</span>** requests = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">if</span>( <span class="number">1</span> == size )</span><br><span class="line">        <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* All non-root send &amp; receive zero-length message to root. */</span></span><br><span class="line">    <span class="keyword">if</span> (rank &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        err = MCA_PML_CALL(send (<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, <span class="number">0</span>,</span><br><span class="line">                                 MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                 MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">        err = MCA_PML_CALL(recv (<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, <span class="number">0</span>,</span><br><span class="line">                                 MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                 comm, MPI_STATUS_IGNORE));</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* The root collects and broadcasts the messages from all other process. */</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        requests = ompi_coll_base_comm_get_reqs(<span class="keyword">module</span>-&gt;base_data, size);</span><br><span class="line">        <span class="keyword">if</span>( <span class="literal">NULL</span> == requests ) &#123; err = OMPI_ERR_OUT_OF_RESOURCE; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; size; ++i) &#123;</span><br><span class="line">            err = MCA_PML_CALL(irecv(<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, MPI_ANY_SOURCE,</span><br><span class="line">                                     MCA_COLL_BASE_TAG_BARRIER, comm,</span><br><span class="line">                                     &amp;(requests[i])));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        err = ompi_request_wait_all( size<span class="number">-1</span>, requests+<span class="number">1</span>, MPI_STATUSES_IGNORE );</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line">        requests = <span class="literal">NULL</span>;  <span class="comment">/* we're done the requests array is clean */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; size; ++i) &#123;</span><br><span class="line">            err = MCA_PML_CALL(send(<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, i,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                    MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* All done */</span></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>double ring方法在很多MPI算法里都有，barrier里也有double ring的实现。向左右的进程发送和接收数据。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_barrier_intra_doublering</span><span class="params">(struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                             <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rank, size, err = <span class="number">0</span>, line = <span class="number">0</span>, left, right;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">if</span>( <span class="number">1</span> == size )</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,<span class="string">"ompi_coll_base_barrier_intra_doublering rank %d"</span>, rank));</span><br><span class="line"></span><br><span class="line">    left = ((size+rank<span class="number">-1</span>)%size);</span><br><span class="line">    right = ((rank+<span class="number">1</span>)%size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (rank &gt; <span class="number">0</span>) <span class="comment">/* receive message from the left */</span></span><br><span class="line">        err = MCA_PML_CALL(recv((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, left, MCA_COLL_BASE_TAG_BARRIER, comm, MPI_STATUS_IGNORE));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Send message to the right */</span></span><br><span class="line">    err = MCA_PML_CALL(send((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, right, MCA_COLL_BASE_TAG_BARRIER, MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* root needs to receive from the last node */</span></span><br><span class="line">    <span class="keyword">if</span> (rank == <span class="number">0</span>)</span><br><span class="line">        err = MCA_PML_CALL(recv((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, left, MCA_COLL_BASE_TAG_BARRIER, comm, MPI_STATUS_IGNORE));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Allow nodes to exit */</span></span><br><span class="line">    <span class="keyword">if</span> (rank &gt; <span class="number">0</span>) <span class="comment">/* post Receive from left */</span></span><br><span class="line">        err = MCA_PML_CALL(recv((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, left, MCA_COLL_BASE_TAG_BARRIER, comm, MPI_STATUS_IGNORE));</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="comment">/* send message to the right one */</span></span><br><span class="line">    err = MCA_PML_CALL(send((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, right, MCA_COLL_BASE_TAG_BARRIER, MCA_PML_BASE_SEND_SYNCHRONOUS, comm));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* rank 0 post receive from the last node */</span></span><br><span class="line">    <span class="keyword">if</span> (rank == <span class="number">0</span>)</span><br><span class="line">        err = MCA_PML_CALL(recv((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, left, MCA_COLL_BASE_TAG_BARRIER, comm, MPI_STATUS_IGNORE));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>还有一种先是把进程数调整到2的n次方，对于多余的进程先进行一次同步，再在进程之间两两交换通信，同样是根据位运算来的<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * To make synchronous, uses sync sends and sync sendrecvs</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_barrier_intra_recursivedoubling</span><span class="params">(struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                    <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rank, size, adjsize, err, line, mask, remote;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">if</span>( <span class="number">1</span> == size )</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"ompi_coll_base_barrier_intra_recursivedoubling rank %d"</span>,</span><br><span class="line">                 rank));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* do nearest power of 2 less than size calc */</span></span><br><span class="line">    adjsize = opal_next_poweroftwo(size);</span><br><span class="line">    adjsize &gt;&gt;= <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* if size is not exact power of two, perform an extra step */</span></span><br><span class="line">    <span class="keyword">if</span> (adjsize != size) &#123;</span><br><span class="line">        <span class="keyword">if</span> (rank &gt;= adjsize) &#123;</span><br><span class="line">            <span class="comment">/* send message to lower ranked node */</span></span><br><span class="line">            remote = rank - adjsize;</span><br><span class="line">            err = ompi_coll_base_sendrecv_zero(remote, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                               remote, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                               comm);</span><br><span class="line">            <span class="keyword">if</span> (err != MPI_SUCCESS) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;&#125;</span><br><span class="line"></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (rank &lt; (size - adjsize)) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* receive message from high level rank */</span></span><br><span class="line">            err = MCA_PML_CALL(recv((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, rank+adjsize,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_BARRIER, comm,</span><br><span class="line">                                    MPI_STATUS_IGNORE));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (err != MPI_SUCCESS) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* exchange messages */</span></span><br><span class="line">    <span class="keyword">if</span> ( rank &lt; adjsize ) &#123;</span><br><span class="line">        mask = <span class="number">0x1</span>;</span><br><span class="line">        <span class="keyword">while</span> ( mask &lt; adjsize ) &#123;</span><br><span class="line">            remote = rank ^ mask;</span><br><span class="line">            mask &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">if</span> (remote &gt;= adjsize) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* post receive from the remote node */</span></span><br><span class="line">            err = ompi_coll_base_sendrecv_zero(remote, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                               remote, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                               comm);</span><br><span class="line">            <span class="keyword">if</span> (err != MPI_SUCCESS) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* non-power of 2 case */</span></span><br><span class="line">    <span class="keyword">if</span> (adjsize != size) &#123;</span><br><span class="line">        <span class="keyword">if</span> (rank &lt; (size - adjsize)) &#123;</span><br><span class="line">            <span class="comment">/* send enter message to higher ranked node */</span></span><br><span class="line">            remote = rank + adjsize;</span><br><span class="line">            err = MCA_PML_CALL(send((<span class="keyword">void</span>*)<span class="literal">NULL</span>, <span class="number">0</span>, MPI_BYTE, remote,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                    MCA_PML_BASE_SEND_SYNCHRONOUS, comm));</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (err != MPI_SUCCESS) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;&#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>在不同间隔的进程之间进行交换，真的能实现barrier。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_barrier_intra_bruck</span><span class="params">(struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rank, size, distance, to, from, err, line = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">if</span>( <span class="number">1</span> == size )</span><br><span class="line">        <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"ompi_coll_base_barrier_intra_bruck rank %d"</span>, rank));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* exchange data with rank-2^k and rank+2^k */</span></span><br><span class="line">    <span class="keyword">for</span> (distance = <span class="number">1</span>; distance &lt; size; distance &lt;&lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        from = (rank + size - distance) % size;</span><br><span class="line">        to   = (rank + distance) % size;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* send message to lower ranked node */</span></span><br><span class="line">        err = ompi_coll_base_sendrecv_zero(to, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                           from, MCA_COLL_BASE_TAG_BARRIER,</span><br><span class="line">                                           comm);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Bcast"><a href="#MPI-Bcast" class="headerlink" title="MPI_Bcast"></a>MPI_Bcast</h1><p>bcast首先检查内存区是否不是空，再调用<code>coll_bcast</code>，同样是函数指针。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Bcast</span><span class="params">(<span class="keyword">void</span> *buffer, <span class="keyword">int</span> count, MPI_Datatype datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">              <span class="keyword">int</span> root, MPI_Comm comm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* .... 主要是检查通信域和buffer是否合法，略*/</span></span><br><span class="line">    err = comm-&gt;c_coll-&gt;coll_bcast(buffer, count, datatype, root, comm,</span><br><span class="line">                                  comm-&gt;c_coll-&gt;coll_bcast_module);</span><br><span class="line">    OMPI_ERRHANDLER_RETURN(err, comm, err, FUNC_NAME);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">int</span> <span class="params">(*<span class="keyword">mca_coll_base_module_bcast_init_fn_t</span>)</span></span></span><br><span class="line"><span class="function">  <span class="params">(<span class="keyword">void</span> *buff, </span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">int</span> count, </span></span></span><br><span class="line"><span class="function"><span class="params">   struct <span class="keyword">ompi_datatype_t</span> *datatype, </span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">   struct <span class="keyword">ompi_communicator_t</span> *comm, </span></span></span><br><span class="line"><span class="function"><span class="params">   struct <span class="keyword">ompi_info_t</span> *info, </span></span></span><br><span class="line"><span class="function"><span class="params">   <span class="keyword">ompi_request_t</span> ** request,</span></span></span><br><span class="line"><span class="function"><span class="params">   struct <span class="keyword">mca_coll_base_module_2_4_0_t</span> *<span class="keyword">module</span>)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>bcast主要以下几种：bcast相关的算法应该有：0: tuned, 1: binomial, 2: in_order_binomial, 3: binary, 4: pipeline, 5: chain, 6: linear<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_adapt_bcast</span><span class="params">(BCAST_ARGS)</span></span>;</span><br><span class="line">调用</span><br><span class="line"><span class="keyword">int</span> ompi_coll_adapt_ibcast</span><br><span class="line">调用</span><br><span class="line"><span class="keyword">int</span> ompi_coll_adapt_ibcast_generic</span><br></pre></td></tr></table></figure></p>
<p><code>ompi_coll_adapt_ibcast_generic</code>是底层的调用，首先创建temp_request，标明source，tag等。计算要bcast的数据的segment数，有个宏提供了一种计算段的最佳计数的通用方法（即可以适合指定 SEGSIZE 的完整数据类型的数量）。并在堆上给分配空间，以便其他函数访问。如果是根进程，则向所有子进程发送，否则向根进程接收。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_adapt_ibcast_generic</span><span class="params">(<span class="keyword">void</span> *buff, <span class="keyword">int</span> count, struct <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   struct <span class="keyword">ompi_communicator_t</span> *comm, <span class="keyword">ompi_request_t</span> ** request,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">mca_coll_base_module_t</span> * <span class="keyword">module</span>, <span class="keyword">ompi_coll_tree_t</span> * tree,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">size_t</span> seg_size)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j, rank, err;</span><br><span class="line">    <span class="comment">/* The min of num_segs and SEND_NUM or RECV_NUM, in case the num_segs is less than SEND_NUM or RECV_NUM */</span></span><br><span class="line">    <span class="keyword">int</span> min;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Number of datatype in a segment */</span></span><br><span class="line">    <span class="keyword">int</span> seg_count = count;</span><br><span class="line">    <span class="comment">/* Size of a datatype */</span></span><br><span class="line">    <span class="keyword">size_t</span> type_size;</span><br><span class="line">    <span class="comment">/* Real size of a segment */</span></span><br><span class="line">    <span class="keyword">size_t</span> real_seg_size;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> extent, lb;</span><br><span class="line">    <span class="comment">/* Number of segments */</span></span><br><span class="line">    <span class="keyword">int</span> num_segs;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">mca_pml_base_send_mode_t</span> sendmode = (mca_coll_adapt_component.adapt_ibcast_synchronous_send)</span><br><span class="line">                                        ? MCA_PML_BASE_SEND_SYNCHRONOUS : MCA_PML_BASE_SEND_STANDARD;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* The request passed outside */</span></span><br><span class="line">    <span class="keyword">ompi_coll_base_nbc_request_t</span> *temp_request = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">opal_mutex_t</span> *mutex;</span><br><span class="line">    <span class="comment">/* Store the segments which are received */</span></span><br><span class="line">    <span class="keyword">int</span> *recv_array = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="comment">/* Record how many isends have been issued for every child */</span></span><br><span class="line">    <span class="keyword">int</span> *send_array = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Atomically set up free list */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == mca_coll_adapt_component.adapt_ibcast_context_free_list) &#123;</span><br><span class="line">        <span class="keyword">opal_free_list_t</span>* fl = OBJ_NEW(<span class="keyword">opal_free_list_t</span>);</span><br><span class="line">        opal_free_list_init(fl,</span><br><span class="line">                            <span class="keyword">sizeof</span>(<span class="keyword">ompi_coll_adapt_bcast_context_t</span>),</span><br><span class="line">                            opal_cache_line_size,</span><br><span class="line">                            OBJ_CLASS(<span class="keyword">ompi_coll_adapt_bcast_context_t</span>),</span><br><span class="line">                            <span class="number">0</span>, opal_cache_line_size,</span><br><span class="line">                            mca_coll_adapt_component.adapt_context_free_list_min,</span><br><span class="line">                            mca_coll_adapt_component.adapt_context_free_list_max,</span><br><span class="line">                            mca_coll_adapt_component.adapt_context_free_list_inc,</span><br><span class="line">                            <span class="literal">NULL</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">        <span class="keyword">if</span>( !OPAL_ATOMIC_COMPARE_EXCHANGE_STRONG_PTR((<span class="keyword">opal_atomic_intptr_t</span> *)&amp;mca_coll_adapt_component.adapt_ibcast_context_free_list,</span><br><span class="line">                                                     &amp;(<span class="keyword">intptr_t</span>)&#123;<span class="number">0</span>&#125;, fl) ) &#123;</span><br><span class="line">            OBJ_RELEASE(fl);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Set up request */</span></span><br><span class="line">    temp_request = OBJ_NEW(<span class="keyword">ompi_coll_base_nbc_request_t</span>);</span><br><span class="line">    OMPI_REQUEST_INIT(&amp;temp_request-&gt;super, <span class="literal">false</span>);</span><br><span class="line">    temp_request-&gt;super.req_state = OMPI_REQUEST_ACTIVE;</span><br><span class="line">    temp_request-&gt;super.req_type = OMPI_REQUEST_COLL;</span><br><span class="line">    temp_request-&gt;super.req_free = ompi_coll_adapt_request_free;</span><br><span class="line">    temp_request-&gt;super.req_status.MPI_SOURCE = <span class="number">0</span>;</span><br><span class="line">    temp_request-&gt;super.req_status.MPI_TAG = <span class="number">0</span>;</span><br><span class="line">    temp_request-&gt;super.req_status.MPI_ERROR = <span class="number">0</span>;</span><br><span class="line">    temp_request-&gt;super.req_status._cancelled = <span class="number">0</span>;</span><br><span class="line">    temp_request-&gt;super.req_status._ucount = <span class="number">0</span>;</span><br><span class="line">    *request = (<span class="keyword">ompi_request_t</span>*)temp_request;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Set up mutex */</span></span><br><span class="line">    mutex = OBJ_NEW(<span class="keyword">opal_mutex_t</span>);</span><br><span class="line"></span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Determine number of elements sent per operation */</span></span><br><span class="line">    ompi_datatype_type_size(datatype, &amp;type_size);</span><br><span class="line">    COLL_BASE_COMPUTED_SEGCOUNT(seg_size, type_size, seg_count);</span><br><span class="line"></span><br><span class="line">    ompi_datatype_get_extent(datatype, &amp;lb, &amp;extent);</span><br><span class="line">    num_segs = (count + seg_count - <span class="number">1</span>) / seg_count;</span><br><span class="line">    real_seg_size = (<span class="keyword">ptrdiff_t</span>) seg_count *extent;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Set memory for recv_array and send_array, created on heap becasue they are needed to be accessed by other functions (callback functions) */</span></span><br><span class="line">    <span class="keyword">if</span> (num_segs != <span class="number">0</span>) &#123;</span><br><span class="line">        recv_array = (<span class="keyword">int</span> *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>) * num_segs);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tree-&gt;tree_nextsize != <span class="number">0</span>) &#123;</span><br><span class="line">        send_array = (<span class="keyword">int</span> *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">int</span>) * tree-&gt;tree_nextsize);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Set constant context for send and recv call back */</span></span><br><span class="line">    <span class="keyword">ompi_coll_adapt_constant_bcast_context_t</span> *con = OBJ_NEW(<span class="keyword">ompi_coll_adapt_constant_bcast_context_t</span>);</span><br><span class="line">    con-&gt;root = root;</span><br><span class="line">    con-&gt;count = count;</span><br><span class="line">    con-&gt;seg_count = seg_count;</span><br><span class="line">    con-&gt;datatype = datatype;</span><br><span class="line">    con-&gt;comm = comm;</span><br><span class="line">    con-&gt;real_seg_size = real_seg_size;</span><br><span class="line">    con-&gt;num_segs = num_segs;</span><br><span class="line">    con-&gt;recv_array = recv_array;</span><br><span class="line">    con-&gt;num_recv_segs = <span class="number">0</span>;</span><br><span class="line">    con-&gt;num_recv_fini = <span class="number">0</span>;</span><br><span class="line">    con-&gt;send_array = send_array;</span><br><span class="line">    con-&gt;num_sent_segs = <span class="number">0</span>;</span><br><span class="line">    con-&gt;mutex = mutex;</span><br><span class="line">    con-&gt;request = (<span class="keyword">ompi_request_t</span>*)temp_request;</span><br><span class="line">    con-&gt;tree = tree;</span><br><span class="line">    con-&gt;ibcast_tag = ompi_coll_base_nbc_reserve_tags(comm, num_segs);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT_VERBOSE((<span class="number">30</span>, mca_coll_adapt_component.adapt_output,</span><br><span class="line">                         <span class="string">"[%d]: Ibcast, root %d, tag %d\n"</span>, rank, root,</span><br><span class="line">                         con-&gt;ibcast_tag));</span><br><span class="line">    OPAL_OUTPUT_VERBOSE((<span class="number">30</span>, mca_coll_adapt_component.adapt_output,</span><br><span class="line">                         <span class="string">"[%d]: con-&gt;mutex = %p, num_children = %d, num_segs = %d, real_seg_size = %d, seg_count = %d, tree_adreess = %p\n"</span>,</span><br><span class="line">                         rank, (<span class="keyword">void</span> *) con-&gt;mutex, tree-&gt;tree_nextsize, num_segs,</span><br><span class="line">                         (<span class="keyword">int</span>) real_seg_size, seg_count, (<span class="keyword">void</span> *) con-&gt;tree));</span><br><span class="line"></span><br><span class="line">    OPAL_THREAD_LOCK(mutex);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If the current process is root, it sends segment to every children */</span></span><br><span class="line">    <span class="keyword">if</span> (rank == root) &#123;</span><br><span class="line">        <span class="comment">/* Handle the situation when num_segs &lt; SEND_NUM */</span></span><br><span class="line">        <span class="keyword">if</span> (num_segs &lt;= mca_coll_adapt_component.adapt_ibcast_max_send_requests) &#123;</span><br><span class="line">            min = num_segs;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            min = mca_coll_adapt_component.adapt_ibcast_max_send_requests;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Set recv_array, root has already had all the segments */</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; num_segs; i++) &#123;</span><br><span class="line">            recv_array[i] = i;</span><br><span class="line">        &#125;</span><br><span class="line">        con-&gt;num_recv_segs = num_segs;</span><br><span class="line">        <span class="comment">/* Set send_array, will send ompi_coll_adapt_ibcast_max_send_requests segments */</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; tree-&gt;tree_nextsize; i++) &#123;</span><br><span class="line">            send_array[i] = mca_coll_adapt_component.adapt_ibcast_max_send_requests;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">ompi_request_t</span> *send_req;</span><br><span class="line">        <span class="comment">/* Number of datatypes in each send */</span></span><br><span class="line">        <span class="keyword">int</span> send_count = seg_count;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; min; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i == (num_segs - <span class="number">1</span>)) &#123;</span><br><span class="line">                send_count = count - i * seg_count;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; tree-&gt;tree_nextsize; j++) &#123;</span><br><span class="line">                <span class="keyword">ompi_coll_adapt_bcast_context_t</span> *context =</span><br><span class="line">                    (<span class="keyword">ompi_coll_adapt_bcast_context_t</span> *) opal_free_list_wait(mca_coll_adapt_component.</span><br><span class="line">                                                                           adapt_ibcast_context_free_list);</span><br><span class="line">                context-&gt;buff = (<span class="keyword">char</span> *) buff + i * real_seg_size;</span><br><span class="line">                context-&gt;frag_id = i;</span><br><span class="line">                <span class="comment">/* The id of peer in in children_list */</span></span><br><span class="line">                context-&gt;child_id = j;</span><br><span class="line">                <span class="comment">/* Actural rank of the peer */</span></span><br><span class="line">                context-&gt;peer = tree-&gt;tree_next[j];</span><br><span class="line">                context-&gt;con = con;</span><br><span class="line">                OBJ_RETAIN(con);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">char</span> *send_buff = context-&gt;buff;</span><br><span class="line">                OPAL_OUTPUT_VERBOSE((<span class="number">30</span>, mca_coll_adapt_component.adapt_output,</span><br><span class="line">                                     <span class="string">"[%d]: Send(start in main): segment %d to %d at buff %p send_count %d tag %d\n"</span>,</span><br><span class="line">                                     rank, context-&gt;frag_id, context-&gt;peer,</span><br><span class="line">                                     (<span class="keyword">void</span> *) send_buff, send_count, con-&gt;ibcast_tag - i));</span><br><span class="line">                err =</span><br><span class="line">                    MCA_PML_CALL(isend</span><br><span class="line">                                 (send_buff, send_count, datatype, context-&gt;peer,</span><br><span class="line">                                  con-&gt;ibcast_tag - i, sendmode, comm,</span><br><span class="line">                                  &amp;send_req));</span><br><span class="line">                <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">                    <span class="keyword">return</span> err;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">/* Set send callback */</span></span><br><span class="line">                OPAL_THREAD_UNLOCK(mutex);</span><br><span class="line">                ompi_request_set_callback(send_req, send_cb, context);</span><br><span class="line">                OPAL_THREAD_LOCK(mutex);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* If the current process is not root, it receives data from parent in the tree. */</span></span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* Handle the situation when num_segs &lt; RECV_NUM */</span></span><br><span class="line">        <span class="keyword">if</span> (num_segs &lt;= mca_coll_adapt_component.adapt_ibcast_max_recv_requests) &#123;</span><br><span class="line">            min = num_segs;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            min = mca_coll_adapt_component.adapt_ibcast_max_recv_requests;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Set recv_array, recv_array is empty */</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; num_segs; i++) &#123;</span><br><span class="line">            recv_array[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* Set send_array to empty */</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; tree-&gt;tree_nextsize; i++) &#123;</span><br><span class="line">            send_array[i] = <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Create a recv request */</span></span><br><span class="line">        <span class="keyword">ompi_request_t</span> *recv_req;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Recevice some segments from its parent */</span></span><br><span class="line">        <span class="keyword">int</span> recv_count = seg_count;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; min; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (i == (num_segs - <span class="number">1</span>)) &#123;</span><br><span class="line">                recv_count = count - i * seg_count;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">ompi_coll_adapt_bcast_context_t</span> *context =</span><br><span class="line">                (<span class="keyword">ompi_coll_adapt_bcast_context_t</span> *) opal_free_list_wait(mca_coll_adapt_component.</span><br><span class="line">                                                                       adapt_ibcast_context_free_list);</span><br><span class="line">            context-&gt;buff = (<span class="keyword">char</span> *) buff + i * real_seg_size;</span><br><span class="line">            context-&gt;frag_id = i;</span><br><span class="line">            context-&gt;peer = tree-&gt;tree_prev;</span><br><span class="line">            context-&gt;con = con;</span><br><span class="line">            OBJ_RETAIN(con);</span><br><span class="line">            <span class="keyword">char</span> *recv_buff = context-&gt;buff;</span><br><span class="line">            OPAL_OUTPUT_VERBOSE((<span class="number">30</span>, mca_coll_adapt_component.adapt_output,</span><br><span class="line">                                 <span class="string">"[%d]: Recv(start in main): segment %d from %d at buff %p recv_count %d tag %d\n"</span>,</span><br><span class="line">                                 ompi_comm_rank(context-&gt;con-&gt;comm), context-&gt;frag_id,</span><br><span class="line">                                 context-&gt;peer, (<span class="keyword">void</span> *) recv_buff, recv_count,</span><br><span class="line">                                 con-&gt;ibcast_tag - i));</span><br><span class="line">            err =</span><br><span class="line">                MCA_PML_CALL(irecv</span><br><span class="line">                             (recv_buff, recv_count, datatype, context-&gt;peer,</span><br><span class="line">                              con-&gt;ibcast_tag - i, comm, &amp;recv_req));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">                <span class="keyword">return</span> err;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* Set receive callback */</span></span><br><span class="line">            OPAL_THREAD_UNLOCK(mutex);</span><br><span class="line">            ompi_request_set_callback(recv_req, recv_cb, context);</span><br><span class="line">            OPAL_THREAD_LOCK(mutex);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OPAL_THREAD_UNLOCK(mutex);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT_VERBOSE((<span class="number">30</span>, mca_coll_adapt_component.adapt_output,</span><br><span class="line">                         <span class="string">"[%d]: End of Ibcast\n"</span>, rank));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此外还找到了如下几个：</p>
<ul>
<li>ompi_coll_base_bcast_intra_basic_linear：root发送给所有其他进程</li>
<li>mca_coll_basic_bcast_log_intra：log复杂度的树形通信</li>
<li>ompi_coll_base_bcast_intra_generic：树形发送，根节点发送给中间节点，中间节点从根节点中接收，再发送给自己的子节点，叶子节点只负责接收</li>
<li>mca_coll_sm_bcast_intra：共享内存的bcast<ul>
<li>找到标志，memcpy，子进程感觉到完成了，再发送给子子进程</li>
<li>对于根，一般算法是等待一组段变得可用。一旦它可用，根通过将当前操作号和使用该集合的进程数写入标志来声明该集合。</li>
<li>然后根在这组段上循环；对于每个段，它将用户缓冲区的一个片段复制到共享数据段中，然后将数据大小写入其子控制缓冲区。</li>
<li>重复该过程，直到已写入所有片段。</li>
<li>对于非根，对于每组缓冲区，它们等待直到当前操作号出现在使用标志中（即，由根写入）。</li>
<li>然后对于每个段，它们等待一个非零值出现在它们的控制缓冲区中。如果他们有孩子，他们将数据从他们父母的共享数据段复制到他们的共享数据段，并将数据大小写入他们的每个孩子的控制缓冲区。</li>
<li>然后，他们将共享的数据段中的数据复制到用户的输出缓冲区中。</li>
<li>重复该过程，直到已接收到所有片段。如果他们没有孩子，他们直接将数据从父母的共享数据段复制到用户的输出缓冲区。</li>
</ul>
</li>
<li>mca_coll_sync_bcast<ul>
<li>加上了一些barrier</li>
</ul>
</li>
<li>ompi_coll_tuned_bcast_intra_dec_fixed<ul>
<li>根据消息大小，进程数选择算法执行bcast</li>
</ul>
</li>
<li>ompi_coll_base_bcast_intra_bintree：跟ompi_coll_base_bcast_intra_generic一样，树不一样</li>
<li>ompi_coll_base_bcast_intra_binomial：跟ompi_coll_base_bcast_intra_generic一样</li>
<li>ompi_coll_base_bcast_intra_knomial：树的子节点数不同，如果radix=2，子节点有1，2，4，8；radix=3，子节点有3，6，9这样。</li>
</ul>
<p>ompi_coll_base_bcast_intra_scatter_allgather：借助allgather实现bcast，例如，0和1一组，2和3一组，4和5一组，6和7一组，这样第一次就能实现每个进程里两个数据，第二次就是0，1，2，3一组，4，5，6，7一组，每个进程里4个，最后一次就每个进程里8个了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Time complexity: O(\alpha\log(p) + \beta*m((p-1)/p))</span></span><br><span class="line"><span class="comment"> *   Binomial tree scatter: \alpha\log(p) + \beta*m((p-1)/p)</span></span><br><span class="line"><span class="comment"> *   Recursive doubling allgather: \alpha\log(p) + \beta*m((p-1)/p)</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Example, p=8, count=8, root=0</span></span><br><span class="line"><span class="comment"> *    Binomial tree scatter      Recursive doubling allgather</span></span><br><span class="line"><span class="comment"> * 0: --+  --+  --+  [0*******]  &lt;-+ [01******]  &lt;--+   [0123****] &lt;--+</span></span><br><span class="line"><span class="comment"> * 1:   |   2|  &lt;-+  [*1******]  &lt;-+ [01******]  &lt;--|-+ [0123****] &lt;--+-+</span></span><br><span class="line"><span class="comment"> * 2:  4|  &lt;-+  --+  [**2*****]  &lt;-+ [**23****]  &lt;--+ | [0123****] &lt;--+-+-+</span></span><br><span class="line"><span class="comment"> * 3:   |       &lt;-+  [***3****]  &lt;-+ [**23****]  &lt;----+ [0123****] &lt;--+-+-+-+</span></span><br><span class="line"><span class="comment"> * 4: &lt;-+  --+  --+  [****4***]  &lt;-+ [****45**]  &lt;--+   [****4567] &lt;--+ | | |</span></span><br><span class="line"><span class="comment"> * 5:       2|  &lt;-+  [*****5**]  &lt;-+ [****45**]  &lt;--|-+ [****4567] &lt;----+ | |</span></span><br><span class="line"><span class="comment"> * 6:      &lt;-+  --+  [******6*]  &lt;-+ [******67]  &lt;--+ | [****4567] &lt;------+ |</span></span><br><span class="line"><span class="comment"> * 7:           &lt;-+  [*******7]  &lt;-+ [******67]  &lt;--|-+ [****4567] &lt;--------+</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_bcast_intra_scatter_allgather</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, struct <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">    struct <span class="keyword">ompi_communicator_t</span> *comm, <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">uint32_t</span> segsize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> err = MPI_SUCCESS;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> lb, extent;</span><br><span class="line">    <span class="keyword">size_t</span> datatype_size;</span><br><span class="line">    MPI_Status status;</span><br><span class="line">    ompi_datatype_get_extent(datatype, &amp;lb, &amp;extent);</span><br><span class="line">    ompi_datatype_type_size(datatype, &amp;datatype_size);</span><br><span class="line">    <span class="keyword">int</span> comm_size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">int</span> rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> vrank = (rank - root + comm_size) % comm_size;</span><br><span class="line">    <span class="keyword">int</span> recv_count = <span class="number">0</span>, send_count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> scatter_count = (count + comm_size - <span class="number">1</span>) / comm_size; <span class="comment">/* ceil(count / comm_size) */</span></span><br><span class="line">    <span class="keyword">int</span> curr_count = (rank == root) ? count : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Scatter by binomial tree: receive data from parent */</span></span><br><span class="line">    <span class="keyword">int</span> mask = <span class="number">0x1</span>;</span><br><span class="line">    <span class="keyword">while</span> (mask &lt; comm_size) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vrank &amp; mask) &#123;</span><br><span class="line">            <span class="keyword">int</span> parent = (rank - mask + comm_size) % comm_size;</span><br><span class="line">            <span class="comment">/* Compute an upper bound on recv block size */</span></span><br><span class="line">            recv_count = count - vrank * scatter_count;</span><br><span class="line">            <span class="keyword">if</span> (recv_count &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                curr_count = <span class="number">0</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/* Recv data from parent */</span></span><br><span class="line">                err = MCA_PML_CALL(recv((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)vrank * scatter_count * extent,</span><br><span class="line">                                        recv_count, datatype, parent,</span><br><span class="line">                                        MCA_COLL_BASE_TAG_BCAST, comm, &amp;status));</span><br><span class="line">                <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">                <span class="comment">/* Get received count */</span></span><br><span class="line">                curr_count = (<span class="keyword">int</span>)(status._ucount / datatype_size);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mask &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Scatter by binomial tree: send data to child processes */</span></span><br><span class="line">    mask &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (mask &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vrank + mask &lt; comm_size) &#123;</span><br><span class="line">            send_count = curr_count - scatter_count * mask;</span><br><span class="line">            <span class="keyword">if</span> (send_count &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> child = (rank + mask) % comm_size;</span><br><span class="line">                err = MCA_PML_CALL(send((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)scatter_count * (vrank + mask) * extent,</span><br><span class="line">                                        send_count, datatype, child,</span><br><span class="line">                                        MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                        MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">                <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">                curr_count -= send_count;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mask &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * Allgather by recursive doubling</span></span><br><span class="line"><span class="comment">     * Each process has the curr_count elems in the buf[vrank * scatter_count, ...]</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">int</span> rem_count = count - vrank * scatter_count;</span><br><span class="line">    curr_count = (scatter_count &lt; rem_count) ? scatter_count : rem_count;</span><br><span class="line">    <span class="keyword">if</span> (curr_count &lt; <span class="number">0</span>)</span><br><span class="line">        curr_count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    mask = <span class="number">0x1</span>;</span><br><span class="line">    <span class="keyword">while</span> (mask &lt; comm_size) &#123;</span><br><span class="line">        <span class="keyword">int</span> vremote = vrank ^ mask;</span><br><span class="line">        <span class="keyword">int</span> remote = (vremote + root) % comm_size;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> vrank_tree_root = ompi_rounddown(vrank, mask);</span><br><span class="line">        <span class="keyword">int</span> vremote_tree_root = ompi_rounddown(vremote, mask);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (vremote &lt; comm_size) &#123;</span><br><span class="line">            <span class="keyword">ptrdiff_t</span> send_offset = vrank_tree_root * scatter_count * extent;</span><br><span class="line">            <span class="keyword">ptrdiff_t</span> recv_offset = vremote_tree_root * scatter_count * extent;</span><br><span class="line">            recv_count = count - vremote_tree_root * scatter_count;</span><br><span class="line">            <span class="keyword">if</span> (recv_count &lt; <span class="number">0</span>)</span><br><span class="line">                recv_count = <span class="number">0</span>;</span><br><span class="line">            err = ompi_coll_base_sendrecv((<span class="keyword">char</span> *)buf + send_offset,</span><br><span class="line">                                          curr_count, datatype, remote,</span><br><span class="line">                                          MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                          (<span class="keyword">char</span> *)buf + recv_offset,</span><br><span class="line">                                          recv_count, datatype, remote,</span><br><span class="line">                                          MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                          comm, &amp;status, rank);</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">            recv_count = (<span class="keyword">int</span>)(status._ucount / datatype_size);</span><br><span class="line">            curr_count += recv_count;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * Non-power-of-two case: if process did not have destination process</span></span><br><span class="line"><span class="comment">         * to communicate with, we need to send him the current result.</span></span><br><span class="line"><span class="comment">         * Recursive halving algorithm is used for search of process.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (vremote_tree_root + mask &gt; comm_size) &#123;</span><br><span class="line">            <span class="keyword">int</span> nprocs_alldata = comm_size - vrank_tree_root - mask;</span><br><span class="line">            <span class="keyword">int</span> offset = scatter_count * (vrank_tree_root + mask);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> rhalving_mask = mask &gt;&gt; <span class="number">1</span>; rhalving_mask &gt; <span class="number">0</span>; rhalving_mask &gt;&gt;= <span class="number">1</span>) &#123;</span><br><span class="line">                vremote = vrank ^ rhalving_mask;</span><br><span class="line">                remote = (vremote + root) % comm_size;</span><br><span class="line">                <span class="keyword">int</span> tree_root = ompi_rounddown(vrank, rhalving_mask &lt;&lt; <span class="number">1</span>);</span><br><span class="line">                <span class="comment">/*</span></span><br><span class="line"><span class="comment">                 * Send only if:</span></span><br><span class="line"><span class="comment">                 * 1) current process has data: (vremote &gt; vrank) &amp;&amp; (vrank &lt; tree_root + nprocs_alldata)</span></span><br><span class="line"><span class="comment">                 * 2) remote process does not have data at any step: vremote &gt;= tree_root + nprocs_alldata</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                <span class="keyword">if</span> ((vremote &gt; vrank) &amp;&amp; (vrank &lt; tree_root + nprocs_alldata)</span><br><span class="line">                    &amp;&amp; (vremote &gt;= tree_root + nprocs_alldata)) &#123;</span><br><span class="line">                    err = MCA_PML_CALL(send((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)offset * extent,</span><br><span class="line">                                            recv_count, datatype, remote,</span><br><span class="line">                                            MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                            MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">                    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line"></span><br><span class="line">                &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((vremote &lt; vrank) &amp;&amp; (vremote &lt; tree_root + nprocs_alldata)</span><br><span class="line">                           &amp;&amp; (vrank &gt;= tree_root + nprocs_alldata)) &#123;</span><br><span class="line">                    err = MCA_PML_CALL(recv((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)offset * extent,</span><br><span class="line">                                            count, datatype, remote,</span><br><span class="line">                                            MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                            comm, &amp;status));</span><br><span class="line">                    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">                    recv_count = (<span class="keyword">int</span>)(status._ucount / datatype_size);</span><br><span class="line">                    curr_count += recv_count;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mask &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">cleanup_and_return:</span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ompi_coll_base_bcast_intra_scatter_allgather_ring：跟上边的一样，不过每个进程都是跟之前的进程交换<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Time complexity: O(\alpha(\log(p) + p) + \beta*m((p-1)/p))</span></span><br><span class="line"><span class="comment"> *   Binomial tree scatter: \alpha\log(p) + \beta*m((p-1)/p)</span></span><br><span class="line"><span class="comment"> *   Ring allgather: 2(p-1)(\alpha + m/p\beta)</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Example, p=8, count=8, root=0</span></span><br><span class="line"><span class="comment"> *    Binomial tree scatter      Ring allgather: p - 1 steps</span></span><br><span class="line"><span class="comment"> * 0: --+  --+  --+  [0*******]  [0******7] [0*****67] [0****567] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 1:   |   2|  &lt;-+  [*1******]  [01******] [01*****7] [01****67] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 2:  4|  &lt;-+  --+  [**2*****]  [*12*****] [012*****] [012****7] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 3:   |       &lt;-+  [***3****]  [**23****] [*123****] [0123****] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 4: &lt;-+  --+  --+  [****4***]  [***34***] [**234***] [*1234***] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 5:       2|  &lt;-+  [*****5**]  [****45**] [***345**] [**2345**] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 6:      &lt;-+  --+  [******6*]  [*****56*] [****456*] [***3456*] ... [01234567]</span></span><br><span class="line"><span class="comment"> * 7:           &lt;-+  [*******7]  [******67] [*****567] [****4567] ... [01234567]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_bcast_intra_scatter_allgather_ring</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, struct <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">int</span> root,</span></span></span><br><span class="line"><span class="function"><span class="params">    struct <span class="keyword">ompi_communicator_t</span> *comm, <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">uint32_t</span> segsize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> err = MPI_SUCCESS;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> lb, extent;</span><br><span class="line">    <span class="keyword">size_t</span> datatype_size;</span><br><span class="line">    MPI_Status status;</span><br><span class="line">    ompi_datatype_get_extent(datatype, &amp;lb, &amp;extent);</span><br><span class="line">    ompi_datatype_type_size(datatype, &amp;datatype_size);</span><br><span class="line">    <span class="keyword">int</span> comm_size = ompi_comm_size(comm);</span><br><span class="line">    <span class="keyword">int</span> rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> vrank = (rank - root + comm_size) % comm_size;</span><br><span class="line">    <span class="keyword">int</span> recv_count = <span class="number">0</span>, send_count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> scatter_count = (count + comm_size - <span class="number">1</span>) / comm_size; <span class="comment">/* ceil(count / comm_size) */</span></span><br><span class="line">    <span class="keyword">int</span> curr_count = (rank == root) ? count : <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Scatter by binomial tree: receive data from parent */</span></span><br><span class="line">    <span class="keyword">int</span> mask = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (mask &lt; comm_size) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vrank &amp; mask) &#123;</span><br><span class="line">            <span class="keyword">int</span> parent = (rank - mask + comm_size) % comm_size;</span><br><span class="line">            <span class="comment">/* Compute an upper bound on recv block size */</span></span><br><span class="line">            recv_count = count - vrank * scatter_count;</span><br><span class="line">            <span class="keyword">if</span> (recv_count &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                curr_count = <span class="number">0</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">/* Recv data from parent */</span></span><br><span class="line">                err = MCA_PML_CALL(recv((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)vrank * scatter_count * extent,</span><br><span class="line">                                        recv_count, datatype, parent,</span><br><span class="line">                                        MCA_COLL_BASE_TAG_BCAST, comm, &amp;status));</span><br><span class="line">                <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">                <span class="comment">/* Get received count */</span></span><br><span class="line">                curr_count = (<span class="keyword">int</span>)(status._ucount / datatype_size);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mask &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Scatter by binomial tree: send data to child processes */</span></span><br><span class="line">    mask &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (mask &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vrank + mask &lt; comm_size) &#123;</span><br><span class="line">            send_count = curr_count - scatter_count * mask;</span><br><span class="line">            <span class="keyword">if</span> (send_count &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> child = (rank + mask) % comm_size;</span><br><span class="line">                err = MCA_PML_CALL(send((<span class="keyword">char</span> *)buf + (<span class="keyword">ptrdiff_t</span>)scatter_count * (vrank + mask) * extent,</span><br><span class="line">                                        send_count, datatype, child,</span><br><span class="line">                                        MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                        MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">                <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">                curr_count -= send_count;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        mask &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Allgather by a ring algorithm */</span></span><br><span class="line">    <span class="keyword">int</span> left = (rank - <span class="number">1</span> + comm_size) % comm_size;</span><br><span class="line">    <span class="keyword">int</span> right = (rank + <span class="number">1</span>) % comm_size;</span><br><span class="line">    <span class="keyword">int</span> send_block = vrank;</span><br><span class="line">    <span class="keyword">int</span> recv_block = (vrank - <span class="number">1</span> + comm_size) % comm_size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; comm_size; i++) &#123;</span><br><span class="line">        recv_count = (scatter_count &lt; count - recv_block * scatter_count) ?</span><br><span class="line">                      scatter_count : count - recv_block * scatter_count;</span><br><span class="line">        <span class="keyword">if</span> (recv_count &lt; <span class="number">0</span>)</span><br><span class="line">            recv_count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">ptrdiff_t</span> recv_offset = recv_block * scatter_count * extent;</span><br><span class="line"></span><br><span class="line">        send_count = (scatter_count &lt; count - send_block * scatter_count) ?</span><br><span class="line">                      scatter_count : count - send_block * scatter_count;</span><br><span class="line">        <span class="keyword">if</span> (send_count &lt; <span class="number">0</span>)</span><br><span class="line">            send_count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">ptrdiff_t</span> send_offset = send_block * scatter_count * extent;</span><br><span class="line"></span><br><span class="line">        err = ompi_coll_base_sendrecv((<span class="keyword">char</span> *)buf + send_offset, send_count,</span><br><span class="line">                                      datatype, right, MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                      (<span class="keyword">char</span> *)buf + recv_offset, recv_count,</span><br><span class="line">                                      datatype, left, MCA_COLL_BASE_TAG_BCAST,</span><br><span class="line">                                      comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; <span class="keyword">goto</span> cleanup_and_return; &#125;</span><br><span class="line">        send_block = recv_block;</span><br><span class="line">        recv_block = (recv_block - <span class="number">1</span> + comm_size) % comm_size;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">cleanup_and_return:</span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Send"><a href="#MPI-Send" class="headerlink" title="MPI_Send"></a>MPI_Send</h1><p>经过了一系列错误检查之后，主要是<code>mca_pml.pml_send</code>这个函数<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Send</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype type, <span class="keyword">int</span> dest,</span></span></span><br><span class="line"><span class="function"><span class="params">             <span class="keyword">int</span> tag, MPI_Comm comm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc = MPI_SUCCESS;</span><br><span class="line"></span><br><span class="line">    SPC_RECORD(OMPI_SPC_SEND, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    MEMCHECKER(</span><br><span class="line">        memchecker_datatype(type);</span><br><span class="line">        memchecker_call(&amp;opal_memchecker_base_isdefined, buf, count, type);</span><br><span class="line">        memchecker_comm(comm);</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( MPI_PARAM_CHECK ) &#123;</span><br><span class="line">        OMPI_ERR_INIT_FINALIZE(FUNC_NAME);</span><br><span class="line">        <span class="keyword">if</span> (ompi_comm_invalid(comm)) &#123;</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERRHANDLER_NOHANDLE_INVOKE(MPI_ERR_COMM, FUNC_NAME);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (count &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            rc = MPI_ERR_COUNT;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (tag &lt; <span class="number">0</span> || tag &gt; mca_pml.pml_max_tag) &#123;</span><br><span class="line">            rc = MPI_ERR_TAG;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ompi_comm_peer_invalid(comm, dest) &amp;&amp;</span><br><span class="line">                   (MPI_PROC_NULL != dest)) &#123;</span><br><span class="line">            rc = MPI_ERR_RANK;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            OMPI_CHECK_DATATYPE_FOR_SEND(rc, type, count);</span><br><span class="line">            OMPI_CHECK_USER_BUFFER(rc, buf, type, count);</span><br><span class="line">        &#125;</span><br><span class="line">        OMPI_ERRHANDLER_CHECK(rc, comm, rc, FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_FT_MPI</span></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * An early check, so as to return early if we are communicating with</span></span><br><span class="line"><span class="comment">     * a failed process. This is not absolutely necessary since we will</span></span><br><span class="line"><span class="comment">     * check for this, and other, error conditions during the completion</span></span><br><span class="line"><span class="comment">     * call in the PML.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span>( OPAL_UNLIKELY(!ompi_comm_iface_p2p_check_proc(comm, dest, &amp;rc)) ) &#123;</span><br><span class="line">        OMPI_ERRHANDLER_RETURN(rc, comm, rc, FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_PROC_NULL == dest) &#123;</span><br><span class="line">        <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rc = MCA_PML_CALL(send(buf, count, type, dest, tag, MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">    OMPI_ERRHANDLER_RETURN(rc, comm, rc, FUNC_NAME);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>pml_send</code>函数主要有以下几个赋值：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mca_pml_cm_send</span><br><span class="line">mca_pml_monitoring_send</span><br><span class="line">mca_pml_ob1_send</span><br><span class="line">mca_pml_ucx_send</span><br><span class="line">mca_spml_ucx_send</span><br></pre></td></tr></table></figure></p>
<p>以第一个为例，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line">__opal_attribute_always_inline__ <span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span></span><br><span class="line">mca_pml_cm_send(<span class="keyword">const</span> <span class="keyword">void</span> *buf,</span><br><span class="line">                <span class="keyword">size_t</span> count,</span><br><span class="line">                <span class="keyword">ompi_datatype_t</span>* datatype,</span><br><span class="line">                <span class="keyword">int</span> dst,</span><br><span class="line">                <span class="keyword">int</span> tag,</span><br><span class="line">                <span class="keyword">mca_pml_base_send_mode_t</span> sendmode,</span><br><span class="line">                <span class="keyword">ompi_communicator_t</span>* comm)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> ret = OMPI_ERROR;</span><br><span class="line">    <span class="keyword">uint32_t</span> flags = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">ompi_proc_t</span> * ompi_proc;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(sendmode == MCA_PML_BASE_SEND_BUFFERED) &#123;</span><br><span class="line">        <span class="keyword">mca_pml_cm_hvy_send_request_t</span> *sendreq;</span><br><span class="line"></span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_ALLOC(sendreq, comm, dst, ompi_proc);</span><br><span class="line">        <span class="keyword">if</span> (OPAL_UNLIKELY(<span class="literal">NULL</span> == sendreq)) <span class="keyword">return</span> OMPI_ERR_OUT_OF_RESOURCE;</span><br><span class="line"></span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_INIT(sendreq, ompi_proc, comm, tag, dst, datatype, sendmode, <span class="literal">false</span>, <span class="literal">false</span>, buf, count, flags);</span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_START(sendreq, ret);</span><br><span class="line">        <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">            MCA_PML_CM_HVY_SEND_REQUEST_RETURN(sendreq);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        ompi_request_free( (<span class="keyword">ompi_request_t</span>**)&amp;sendreq );</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">opal_convertor_t</span> convertor;</span><br><span class="line">	OBJ_CONSTRUCT(&amp;convertor, <span class="keyword">opal_convertor_t</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> !(OPAL_ENABLE_HETEROGENEOUS_SUPPORT)</span></span><br><span class="line">	<span class="keyword">if</span> (opal_datatype_is_contiguous_memory_layout(&amp;datatype-&gt;super, count)) &#123;</span><br><span class="line"></span><br><span class="line">		convertor.remoteArch = ompi_mpi_local_convertor-&gt;remoteArch;</span><br><span class="line">		convertor.flags      = ompi_mpi_local_convertor-&gt;flags;</span><br><span class="line">		convertor.master     = ompi_mpi_local_convertor-&gt;master;</span><br><span class="line"></span><br><span class="line">		convertor.local_size = count * datatype-&gt;super.size;</span><br><span class="line">		convertor.pBaseBuf   = (<span class="keyword">unsigned</span> <span class="keyword">char</span>*)buf + datatype-&gt;super.true_lb;</span><br><span class="line">		convertor.count      = count;</span><br><span class="line">		convertor.pDesc      = &amp;datatype-&gt;super;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_CUDA_SUPPORT</span></span><br><span class="line">        <span class="comment">/* Switches off CUDA detection if</span></span><br><span class="line"><span class="comment">           MTL set MCA_MTL_BASE_FLAG_CUDA_INIT_DISABLE during init */</span></span><br><span class="line">        MCA_PML_CM_SWITCH_CUDA_CONVERTOR_OFF(flags, datatype, count);</span><br><span class="line">        convertor.flags      |= flags;</span><br><span class="line">        <span class="comment">/* Sets CONVERTOR_CUDA flag if CUDA buffer */</span></span><br><span class="line">        opal_convertor_prepare_for_send( &amp;convertor, &amp;datatype-&gt;super, count, buf );</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    &#125; <span class="keyword">else</span></span><br><span class="line">#endif</span><br><span class="line">	&#123;</span><br><span class="line">		ompi_proc = ompi_comm_peer_lookup(comm, dst);</span><br><span class="line"></span><br><span class="line">                MCA_PML_CM_SWITCH_CUDA_CONVERTOR_OFF(flags, datatype, count);</span><br><span class="line"></span><br><span class="line">		opal_convertor_copy_and_prepare_for_send(</span><br><span class="line">		ompi_proc-&gt;super.proc_convertor,</span><br><span class="line">			&amp;datatype-&gt;super, count, buf, flags,</span><br><span class="line">			&amp;convertor);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">        ret = OMPI_MTL_CALL(send(ompi_mtl,</span><br><span class="line">                                 comm,</span><br><span class="line">                                 dst,</span><br><span class="line">                                 tag,</span><br><span class="line">                                 &amp;convertor,</span><br><span class="line">                                 sendmode));</span><br><span class="line">	OBJ_DESTRUCT(&amp;convertor);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>因为这是简单的send，所以分为两种情况，第一种是有buffer，先分配request，初始化之后等待返回。<code>MCA_PML_CM_HVY_SEND_REQUEST_ALLOC</code>是分配一个request，request应该是<code>opal_free_list_wait</code>（只包括了有多线程情况下的<code>opal_free_list_wait_mt(fl);</code>和无多线程情况下的<code>opal_free_list_wait_st(fl)</code>的调用）函数分配的，并规定了完成后的回调函数<code>mca_pml_cm_send_request_completion</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_HVY_SEND_REQUEST_ALLOC(sendreq, comm, dst,           \</span></span><br><span class="line">                                          ompi_proc)                    \</span><br><span class="line">&#123;                                                                       \</span><br><span class="line">    sendreq = (<span class="keyword">mca_pml_cm_hvy_send_request_t</span>*)                          \</span><br><span class="line">        opal_free_list_wait (&amp;mca_pml_base_send_requests);              \</span><br><span class="line">    sendreq-&gt;req_send.req_base.req_pml_type = MCA_PML_CM_REQUEST_SEND_HEAVY; \</span><br><span class="line">    sendreq-&gt;req_mtl.ompi_req = (<span class="keyword">ompi_request_t</span>*) sendreq;              \</span><br><span class="line">    sendreq-&gt;req_mtl.completion_callback = mca_pml_cm_send_request_completion; \</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p>
<p>从一个栈结构里取出来一个proc<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> opal_free_list_item_t *<span class="title">opal_free_list_wait_st</span><span class="params">(<span class="keyword">opal_free_list_t</span> *fl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">opal_free_list_item_t</span> *item = (<span class="keyword">opal_free_list_item_t</span> *) opal_lifo_pop(&amp;fl-&gt;super);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">NULL</span> == item) &#123;</span><br><span class="line">        <span class="keyword">if</span> (fl-&gt;fl_max_to_alloc &lt;= fl-&gt;fl_num_allocated</span><br><span class="line">            || OPAL_SUCCESS != opal_free_list_grow_st(fl, fl-&gt;fl_num_per_alloc, &amp;item)) &#123;</span><br><span class="line">            <span class="comment">/* try to make progress */</span></span><br><span class="line">            opal_progress();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == item) &#123;</span><br><span class="line">            item = (<span class="keyword">opal_free_list_item_t</span> *) opal_lifo_pop(&amp;fl-&gt;super);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Blocking call to obtain an item from a free list.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> opal_free_list_item_t *<span class="title">opal_free_list_wait_mt</span><span class="params">(<span class="keyword">opal_free_list_t</span> *fl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">opal_free_list_item_t</span> *item = (<span class="keyword">opal_free_list_item_t</span> *) opal_lifo_pop_atomic(&amp;fl-&gt;super);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">NULL</span> == item) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!opal_mutex_trylock(&amp;fl-&gt;fl_lock)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (fl-&gt;fl_max_to_alloc &lt;= fl-&gt;fl_num_allocated</span><br><span class="line">                || OPAL_SUCCESS != opal_free_list_grow_st(fl, fl-&gt;fl_num_per_alloc, &amp;item)) &#123;</span><br><span class="line">                fl-&gt;fl_num_waiting++;</span><br><span class="line">                opal_condition_wait(&amp;fl-&gt;fl_condition, &amp;fl-&gt;fl_lock);</span><br><span class="line">                fl-&gt;fl_num_waiting--;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (<span class="number">0</span> &lt; fl-&gt;fl_num_waiting) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (<span class="number">1</span> == fl-&gt;fl_num_waiting) &#123;</span><br><span class="line">                        opal_condition_signal(&amp;fl-&gt;fl_condition);</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        opal_condition_broadcast(&amp;fl-&gt;fl_condition);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* If I wasn't able to get the lock in the begining when I finaly grab it</span></span><br><span class="line"><span class="comment">             * the one holding the lock in the begining already grow the list. I will</span></span><br><span class="line"><span class="comment">             * release the lock and try to get a new element until I succeed.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            opal_mutex_lock(&amp;fl-&gt;fl_lock);</span><br><span class="line">        &#125;</span><br><span class="line">        opal_mutex_unlock(&amp;fl-&gt;fl_lock);</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == item) &#123;</span><br><span class="line">            item = (<span class="keyword">opal_free_list_item_t</span> *) opal_lifo_pop_atomic(&amp;fl-&gt;super);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>回调函数<code>mca_pml_cm_send_request_completion</code>，主要是为了调用<code>MCA_PML_CM_THIN_SEND_REQUEST_PML_COMPLETE</code>的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">void</span></span><br><span class="line">mca_pml_cm_send_request_completion(struct <span class="keyword">mca_mtl_request_t</span> *mtl_request)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">mca_pml_cm_send_request_t</span> *base_request =</span><br><span class="line">        (<span class="keyword">mca_pml_cm_send_request_t</span>*) mtl_request-&gt;ompi_req;</span><br><span class="line">    <span class="keyword">if</span>( MCA_PML_CM_REQUEST_SEND_THIN == base_request-&gt;req_base.req_pml_type ) &#123;</span><br><span class="line">        MCA_PML_CM_THIN_SEND_REQUEST_PML_COMPLETE(((<span class="keyword">mca_pml_cm_thin_send_request_t</span>*) base_request));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_PML_COMPLETE(((<span class="keyword">mca_pml_cm_hvy_send_request_t</span>*) base_request));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The PML has completed a send request. Note that this request</span></span><br><span class="line"><span class="comment"> * may have been orphaned by the user or have already completed</span></span><br><span class="line"><span class="comment"> * at the MPI level.</span></span><br><span class="line"><span class="comment"> * This macro will never be called directly from the upper level, as it should</span></span><br><span class="line"><span class="comment"> * only be an internal call to the PML.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_THIN_SEND_REQUEST_PML_COMPLETE(sendreq)                   \</span></span><br><span class="line"><span class="keyword">do</span> &#123;                                                                         \</span><br><span class="line">    assert( <span class="literal">false</span> == sendreq-&gt;req_send.req_base.req_pml_complete );          \</span><br><span class="line">                                                                             \</span><br><span class="line">    <span class="keyword">if</span>( !REQUEST_COMPLETE(&amp;sendreq-&gt;req_send.req_base.req_ompi)) &#123;           \</span><br><span class="line">        <span class="comment">/* Should only be called for long messages (maybe synchronous) */</span>    \</span><br><span class="line">        ompi_request_complete(&amp;(sendreq-&gt;req_send.req_base.req_ompi), <span class="literal">true</span>); \</span><br><span class="line">    &#125;                                                                        \</span><br><span class="line">    sendreq-&gt;req_send.req_base.req_pml_complete = <span class="literal">true</span>;                      \</span><br><span class="line">                                                                             \</span><br><span class="line">    <span class="keyword">if</span>( sendreq-&gt;req_send.req_base.req_free_called ) &#123;                       \</span><br><span class="line">        MCA_PML_CM_THIN_SEND_REQUEST_RETURN( sendreq );                      \</span><br><span class="line">    &#125;                                                                        \</span><br><span class="line"> &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * The PML has completed a send request. Note that this request</span></span><br><span class="line"><span class="comment"> * may have been orphaned by the user or have already completed</span></span><br><span class="line"><span class="comment"> * at the MPI level.</span></span><br><span class="line"><span class="comment"> * This macro will never be called directly from the upper level, as it should</span></span><br><span class="line"><span class="comment"> * only be an internal call to the PML.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_HVY_SEND_REQUEST_PML_COMPLETE(sendreq)                          \</span></span><br><span class="line"><span class="keyword">do</span> &#123;                                                                               \</span><br><span class="line">    assert( <span class="literal">false</span> == sendreq-&gt;req_send.req_base.req_pml_complete );                \</span><br><span class="line">                                                                                   \</span><br><span class="line">    <span class="keyword">if</span> (sendreq-&gt;req_send.req_send_mode == MCA_PML_BASE_SEND_BUFFERED &amp;&amp;           \</span><br><span class="line">        sendreq-&gt;req_count &gt; <span class="number">0</span> ) &#123;                                                 \</span><br><span class="line">        mca_pml_base_bsend_request_free(sendreq-&gt;req_buff);                        \</span><br><span class="line">    &#125;                                                                              \</span><br><span class="line">                                                                                   \</span><br><span class="line">    <span class="keyword">if</span>( !REQUEST_COMPLETE(&amp;sendreq-&gt;req_send.req_base.req_ompi)) &#123;                 \</span><br><span class="line">        <span class="comment">/* the request may have already been marked complete by the MTL */</span>         \</span><br><span class="line">        ompi_request_complete(&amp;(sendreq-&gt;req_send.req_base.req_ompi), <span class="literal">true</span>);       \</span><br><span class="line">    &#125;                                                                              \</span><br><span class="line">    sendreq-&gt;req_send.req_base.req_pml_complete = <span class="literal">true</span>;                            \</span><br><span class="line">                                                                                   \</span><br><span class="line">    <span class="keyword">if</span>( sendreq-&gt;req_send.req_base.req_free_called ) &#123;                             \</span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_RETURN( sendreq );                             \</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;                                                                       \</span><br><span class="line">        <span class="keyword">if</span>(sendreq-&gt;req_send.req_base.req_ompi.req_persistent) &#123;                   \</span><br><span class="line">            <span class="comment">/* rewind convertor */</span>                                                 \</span><br><span class="line">            <span class="keyword">size_t</span> offset = <span class="number">0</span>;                                                     \</span><br><span class="line">            opal_convertor_set_position(&amp;sendreq-&gt;req_send.req_base.req_convertor, \</span><br><span class="line">                                        &amp;offset);                                  \</span><br><span class="line">        &#125;                                                                          \</span><br><span class="line">    &#125;                                                                              \</span><br><span class="line"> &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>分配完之后调用<code>MCA_PML_CM_HVY_SEND_REQUEST_INIT</code>进行初始化，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_HVY_SEND_REQUEST_INIT( sendreq,                      \</span></span><br><span class="line">                                          ompi_proc,                    \</span><br><span class="line">                                          comm,                         \</span><br><span class="line">                                          tag,                          \</span><br><span class="line">                                          dst,                          \</span><br><span class="line">                                          datatype,                     \</span><br><span class="line">                                          sendmode,                     \</span><br><span class="line">                                          persistent,                   \</span><br><span class="line">                                          blocking,                     \</span><br><span class="line">                                          buf,                          \</span><br><span class="line">                                          count,                        \</span><br><span class="line">                                          flags )                       \</span><br><span class="line">    <span class="keyword">do</span> &#123;                                                                \</span><br><span class="line">        OMPI_REQUEST_INIT(&amp;(sendreq-&gt;req_send.req_base.req_ompi),       \</span><br><span class="line">                          persistent);                                  \</span><br><span class="line">        sendreq-&gt;req_tag = tag;                                         \</span><br><span class="line">        sendreq-&gt;req_peer = dst;                                        \</span><br><span class="line">        sendreq-&gt;req_addr = buf;                                        \</span><br><span class="line">        sendreq-&gt;req_count = count;                                     \</span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_INIT_COMMON( (&amp;sendreq-&gt;req_send),  \</span><br><span class="line">                                             ompi_proc,                 \</span><br><span class="line">                                             comm,                      \</span><br><span class="line">                                             tag,                       \</span><br><span class="line">                                             datatype,                  \</span><br><span class="line">                                             sendmode,                  \</span><br><span class="line">                                             buf,                       \</span><br><span class="line">                                             count,                     \</span><br><span class="line">                                             flags )                    \</span><br><span class="line">        opal_convertor_get_packed_size(                                 \</span><br><span class="line">                             &amp;sendreq-&gt;req_send.req_base.req_convertor, \</span><br><span class="line">                                       &amp;sendreq-&gt;req_count );           \</span><br><span class="line">                                                                        \</span><br><span class="line">        sendreq-&gt;req_blocking = blocking;                               \</span><br><span class="line">        sendreq-&gt;req_send.req_base.req_pml_complete =                   \</span><br><span class="line">            (persistent ? <span class="literal">true</span>:<span class="literal">false</span>);                                  \</span><br><span class="line">    &#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_THIN_SEND_REQUEST_INIT( sendreq,                     \</span></span><br><span class="line">                                           ompi_proc,                   \</span><br><span class="line">                                           comm,                        \</span><br><span class="line">                                           tag,                         \</span><br><span class="line">                                           dst,                         \</span><br><span class="line">                                           datatype,                    \</span><br><span class="line">                                           sendmode,                    \</span><br><span class="line">                                           buf,                         \</span><br><span class="line">                                           count,                       \</span><br><span class="line">                                           flags )                      \</span><br><span class="line">    <span class="keyword">do</span> &#123;                                                                \</span><br><span class="line">        OMPI_REQUEST_INIT(&amp;(sendreq-&gt;req_send.req_base.req_ompi),       \</span><br><span class="line">                          <span class="literal">false</span>);                                       \</span><br><span class="line">        MCA_PML_CM_SEND_REQUEST_INIT_COMMON( (&amp;sendreq-&gt;req_send),      \</span><br><span class="line">                                             ompi_proc,                 \</span><br><span class="line">                                             comm,                      \</span><br><span class="line">                                             tag,                       \</span><br><span class="line">                                             datatype,                  \</span><br><span class="line">                                             sendmode,                  \</span><br><span class="line">                                             buf,                       \</span><br><span class="line">                                             count,                     \</span><br><span class="line">                                             flags);                    \</span><br><span class="line">        sendreq-&gt;req_send.req_base.req_pml_complete = <span class="literal">false</span>;            \</span><br><span class="line">    &#125; <span class="keyword">while</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>初始化完成之后开始执行send-request，并释放。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MCA_PML_CM_HVY_SEND_REQUEST_START(sendreq, ret)                              \</span></span><br><span class="line"><span class="keyword">do</span> &#123;                                                                                 \</span><br><span class="line">    ret = OMPI_SUCCESS;                                                              \</span><br><span class="line">    MCA_PML_CM_SEND_REQUEST_START_SETUP(&amp;(sendreq)-&gt;req_send);                       \</span><br><span class="line">    <span class="keyword">if</span> (sendreq-&gt;req_send.req_send_mode == MCA_PML_BASE_SEND_BUFFERED) &#123;             \</span><br><span class="line">        MCA_PML_CM_HVY_SEND_REQUEST_BSEND_ALLOC(sendreq, ret);                       \</span><br><span class="line">    &#125;                                                                                \</span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS == ret) &#123;                                                       \</span><br><span class="line">        ret = OMPI_MTL_CALL(isend(ompi_mtl,                                          \</span><br><span class="line">                                  sendreq-&gt;req_send.req_base.req_comm,               \</span><br><span class="line">                                  sendreq-&gt;req_peer,                                 \</span><br><span class="line">                                  sendreq-&gt;req_tag,                                  \</span><br><span class="line">                                  &amp;sendreq-&gt;req_send.req_base.req_convertor,         \</span><br><span class="line">                                  sendreq-&gt;req_send.req_send_mode,                   \</span><br><span class="line">                                  sendreq-&gt;req_blocking,                             \</span><br><span class="line">                                  &amp;sendreq-&gt;req_mtl));                               \</span><br><span class="line">        <span class="keyword">if</span>(OMPI_SUCCESS == ret &amp;&amp;                                                    \</span><br><span class="line">           sendreq-&gt;req_send.req_send_mode == MCA_PML_BASE_SEND_BUFFERED) &#123;          \</span><br><span class="line">            sendreq-&gt;req_send.req_base.req_ompi.req_status.MPI_ERROR = <span class="number">0</span>;            \</span><br><span class="line">            <span class="keyword">if</span>(!REQUEST_COMPLETE(&amp;sendreq-&gt;req_send.req_base.req_ompi)) &#123;            \</span><br><span class="line">                <span class="comment">/* request may have already been marked complete by the MTL */</span>       \</span><br><span class="line">                ompi_request_complete(&amp;(sendreq)-&gt;req_send.req_base.req_ompi, <span class="literal">true</span>); \</span><br><span class="line">            &#125;                                                                        \</span><br><span class="line">        &#125;                                                                            \</span><br><span class="line">    &#125;                                                                                \</span><br><span class="line"> &#125; <span class="keyword">while</span> (<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>否则，如果不是buffer类型的send，首先创建一个convertor（后边看，可能是在不同架构下进行通信的转换器），如果没有异构的支持，需要考虑传输的数据是不是连续的，支持异构的话就不需要额外考虑内存连续性。<code>OPAL_CUDA_SUPPORT</code>考虑了cuda的特点。</p>
<p><code>ompi_comm_peer_lookup</code>用于找到通信对方进程<code>ompi_proc_t</code>结构，原来找一个对方通信进程还需要加锁。它最终是调用了这个函数<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief Helper function for retreiving the proc of a group member in a dense group</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function exists to handle the translation of sentinel group members to real</span></span><br><span class="line"><span class="comment"> * ompi_proc_t's. If a sentinel value is found and allocate is true then this function</span></span><br><span class="line"><span class="comment"> * looks for an existing ompi_proc_t using ompi_proc_for_name which will allocate a</span></span><br><span class="line"><span class="comment"> * ompi_proc_t if one does not exist. If allocate is false then sentinel values translate</span></span><br><span class="line"><span class="comment"> * to NULL.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> struct ompi_proc_t *<span class="title">ompi_group_dense_lookup</span> <span class="params">(<span class="keyword">ompi_group_t</span> *group, <span class="keyword">const</span> <span class="keyword">int</span> peer_id, <span class="keyword">const</span> <span class="keyword">bool</span> allocate)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_proc_t</span> *proc;</span><br><span class="line"></span><br><span class="line">    proc = group-&gt;grp_proc_pointers[peer_id];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(ompi_proc_is_sentinel (proc))) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!allocate) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* replace sentinel value with an actual ompi_proc_t */</span></span><br><span class="line">        <span class="keyword">ompi_proc_t</span> *real_proc =</span><br><span class="line">            (<span class="keyword">ompi_proc_t</span> *) ompi_proc_for_name (ompi_proc_sentinel_to_name ((<span class="keyword">uintptr_t</span>) proc));</span><br><span class="line">            <span class="comment">// 在hash table里找proc</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (opal_atomic_compare_exchange_strong_ptr ((<span class="keyword">opal_atomic_intptr_t</span> *)(group-&gt;grp_proc_pointers + peer_id),</span><br><span class="line">                                                     (<span class="keyword">intptr_t</span> *) &amp;proc, (<span class="keyword">intptr_t</span>) real_proc)) &#123;</span><br><span class="line">            OBJ_RETAIN(real_proc);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        proc = real_proc;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> proc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>然后这样就可以调用<code>ompi_mtl-&gt;mtl_send</code>，主要是这个函数<code>ompi_mtl_psm2_send</code>，到了MTL层。send还有一种实现是调用了fabric库的操作，这个先不看了。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span></span><br><span class="line">ompi_mtl_psm2_send(struct <span class="keyword">mca_mtl_base_module_t</span>* mtl,</span><br><span class="line">                 struct <span class="keyword">ompi_communicator_t</span>* comm,</span><br><span class="line">                 <span class="keyword">int</span> dest,</span><br><span class="line">                 <span class="keyword">int</span> tag,</span><br><span class="line">                 struct <span class="keyword">opal_convertor_t</span> *convertor,</span><br><span class="line">                 <span class="keyword">mca_pml_base_send_mode_t</span> mode)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">psm2_error_t</span> err;</span><br><span class="line">    <span class="keyword">mca_mtl_psm2_request_t</span> mtl_psm2_request;</span><br><span class="line">    <span class="keyword">psm2_mq_tag_t</span> mqtag;</span><br><span class="line">    <span class="keyword">uint32_t</span> flags = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line">    <span class="keyword">size_t</span> length;</span><br><span class="line">    <span class="keyword">ompi_proc_t</span>* ompi_proc = ompi_comm_peer_lookup( comm, dest );</span><br><span class="line">    <span class="keyword">mca_mtl_psm2_endpoint_t</span>* psm2_endpoint = ompi_mtl_psm2_get_endpoint (mtl, ompi_proc);</span><br><span class="line"></span><br><span class="line">    assert(mtl == &amp;ompi_mtl_psm2.super);</span><br><span class="line"></span><br><span class="line">    PSM2_MAKE_MQTAG(comm-&gt;c_index, comm-&gt;c_my_rank, tag, mqtag);</span><br><span class="line"></span><br><span class="line">    ret = ompi_mtl_datatype_pack(convertor,</span><br><span class="line">                                 &amp;mtl_psm2_request.buf,</span><br><span class="line">                                 &amp;length,</span><br><span class="line">                                 &amp;mtl_psm2_request.free_after);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (length &gt;= <span class="number">1U</span>LL &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">uint32_t</span>) * <span class="number">8</span>) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mtl-psm2.txt"</span>,</span><br><span class="line">		    <span class="string">"message too big"</span>, <span class="literal">false</span>,</span><br><span class="line">		    length, <span class="number">1U</span>LL &lt;&lt; <span class="keyword">sizeof</span>(<span class="keyword">uint32_t</span>) * <span class="number">8</span>);</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 前边是pack</span></span><br><span class="line">    mtl_psm2_request.length = length;</span><br><span class="line">    mtl_psm2_request.convertor = convertor;</span><br><span class="line">    mtl_psm2_request.type = OMPI_mtl_psm2_ISEND;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OMPI_SUCCESS != ret) <span class="keyword">return</span> ret;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mode == MCA_PML_BASE_SEND_SYNCHRONOUS)</span><br><span class="line">	flags |= PSM2_MQ_FLAG_SENDSYNC;</span><br><span class="line"></span><br><span class="line">    err = psm2_mq_send2(ompi_mtl_psm2.mq,</span><br><span class="line">		      psm2_endpoint-&gt;peer_addr,</span><br><span class="line">		      flags,</span><br><span class="line">		      &amp;mqtag,</span><br><span class="line">		      mtl_psm2_request.buf,</span><br><span class="line">		      length);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mtl_psm2_request.free_after) &#123;</span><br><span class="line">	<span class="built_in">free</span>(mtl_psm2_request.buf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> err == PSM2_OK ? OMPI_SUCCESS : OMPI_ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>到了这里就没法继续追了，<code>psm2_mq_send2</code>是Performance Scaled Messaging 2里的函数，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">psm2_error_t psm2_mq_send2 (psm2_mq_t mq, psm2_epaddr_t dest,</span><br><span class="line">    uint32_t flags, psm2_mq_tag_t *stag, const void *buf, uint32_t len)</span><br></pre></td></tr></table></figure></p>
<p>发送阻塞 MQ 消息。 发送阻塞 MQ 消息的函数，该消息在本地完成，并且可以在返回时修改源数据。</p>
<p>Parameters:</p>
<ul>
<li>mq: Matched Queue handle.</li>
<li>dest: Destination EP address.</li>
<li>flags: Message flags, currently:<ul>
<li>PSM2_MQ_FLAG_SENDSYNC tells PSM2 to send the message synchronously, meaning that the message is not sent until the receiver acknowledges that it has matched the send with a receive buffer.</li>
</ul>
</li>
<li>stag: Message Send Tag pointer.</li>
<li>buf: Source buffer pointer.</li>
<li>len: Length of message starting at buf.</li>
</ul>
<h1 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h1><p>看代码里有tcp和rdma的实现，但是没找到怎么到tcp这块的，看到注释说是动态加载模块，可能是通过配置实现选择TCP或者RDMA的？以下缕一下TCP的执行过程。</p>
<p>从<code>btl_tcp_component.c</code>开始，这个结构保存了网络通信的信息，同时支持IPv4和IPv6，可以看到TCP通信时数据是以帧frag为单位的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mca_btl_tcp_component_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">mca_btl_base_component_3_0_0_t</span> super; <span class="comment">/**&lt; base BTL component */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> tcp_addr_count;              <span class="comment">/**&lt; total number of addresses */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> tcp_num_btls;      <span class="comment">/**&lt; number of interfaces available to the TCP component */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> tcp_num_links; <span class="comment">/**&lt; number of logical links per physical device */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mca_btl_tcp_module_t</span> **<span class="title">tcp_btls</span>;</span> <span class="comment">/**&lt; array of available BTL modules */</span></span><br><span class="line">    <span class="keyword">opal_list_t</span> local_ifs;                  <span class="comment">/**&lt; opal list of local opal_if_t interfaces */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_free_list_num;                  <span class="comment">/**&lt; initial size of free lists */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_free_list_max;                  <span class="comment">/**&lt; maximum size of free lists */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_free_list_inc;       <span class="comment">/**&lt; number of elements to alloc when growing free lists */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_endpoint_cache;      <span class="comment">/**&lt; amount of cache on each endpoint */</span></span><br><span class="line">    <span class="keyword">opal_proc_table_t</span> tcp_procs; <span class="comment">/**&lt; hash table of tcp proc structures */</span></span><br><span class="line">    <span class="keyword">opal_mutex_t</span> tcp_lock;       <span class="comment">/**&lt; lock for accessing module state */</span></span><br><span class="line">    <span class="keyword">opal_list_t</span> tcp_events;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">opal_event_t</span> tcp_recv_event;    <span class="comment">/**&lt; recv event for IPv4 listen socket */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_listen_sd;              <span class="comment">/**&lt; IPv4 listen socket for incoming connection requests */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">short</span> tcp_listen_port; <span class="comment">/**&lt; IPv4 listen port */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_port_min;               <span class="comment">/**&lt; IPv4 minimum port */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_port_range;             <span class="comment">/**&lt; IPv4 port range */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_IPV6</span></span><br><span class="line">    <span class="keyword">opal_event_t</span> tcp6_recv_event;    <span class="comment">/**&lt; recv event for IPv6 listen socket */</span></span><br><span class="line">    <span class="keyword">int</span> tcp6_listen_sd;              <span class="comment">/**&lt; IPv6 listen socket for incoming connection requests */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">short</span> tcp6_listen_port; <span class="comment">/**&lt; IPv6 listen port */</span></span><br><span class="line">    <span class="keyword">int</span> tcp6_port_min;               <span class="comment">/**&lt; IPv4 minimum port */</span></span><br><span class="line">    <span class="keyword">int</span> tcp6_port_range;             <span class="comment">/**&lt; IPv4 port range */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="comment">/* Port range restriction */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *tcp_if_include;   <span class="comment">/**&lt; comma seperated list of interface to include */</span></span><br><span class="line">    <span class="keyword">char</span> *tcp_if_exclude;   <span class="comment">/**&lt; comma seperated list of interface to exclude */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_sndbuf;         <span class="comment">/**&lt; socket sndbuf size */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_rcvbuf;         <span class="comment">/**&lt; socket rcvbuf size */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_disable_family; <span class="comment">/**&lt; disabled AF_family */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* free list of fragment descriptors */</span></span><br><span class="line">    <span class="keyword">opal_free_list_t</span> tcp_frag_eager;</span><br><span class="line">    <span class="keyword">opal_free_list_t</span> tcp_frag_max;</span><br><span class="line">    <span class="keyword">opal_free_list_t</span> tcp_frag_user;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> tcp_enable_progress_thread; <span class="comment">/** Support for tcp progress thread flag */</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">opal_event_t</span> tcp_recv_thread_async_event;</span><br><span class="line">    <span class="keyword">opal_mutex_t</span> tcp_frag_eager_mutex;</span><br><span class="line">    <span class="keyword">opal_mutex_t</span> tcp_frag_max_mutex;</span><br><span class="line">    <span class="keyword">opal_mutex_t</span> tcp_frag_user_mutex;</span><br><span class="line">    <span class="comment">/* Do we want to use TCP_NODELAY? */</span></span><br><span class="line">    <span class="keyword">int</span> tcp_not_use_nodelay;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* do we want to warn on all excluded interfaces</span></span><br><span class="line"><span class="comment">     * that are not found?</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">bool</span> report_all_unfound_interfaces;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p><code>mca_btl_tcp_module_t</code>是一个中间层，保存了tcp通信的每步需要调用的函数指针。以<code>mca_btl_tcp_send</code>为例记录调用历程。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">mca_btl_tcp_module_t</span> mca_btl_tcp_module =</span><br><span class="line">    &#123;.super =</span><br><span class="line">         &#123;</span><br><span class="line">             .btl_component = &amp;mca_btl_tcp_component.super,</span><br><span class="line">             .btl_add_procs = mca_btl_tcp_add_procs,</span><br><span class="line">             .btl_del_procs = mca_btl_tcp_del_procs,</span><br><span class="line">             .btl_finalize = mca_btl_tcp_finalize,</span><br><span class="line">             .btl_alloc = mca_btl_tcp_alloc,</span><br><span class="line">             .btl_free = mca_btl_tcp_free,</span><br><span class="line">             .btl_prepare_src = mca_btl_tcp_prepare_src,</span><br><span class="line">             .btl_send = mca_btl_tcp_send,</span><br><span class="line">             .btl_put = mca_btl_tcp_put,</span><br><span class="line">             .btl_dump = mca_btl_base_dump,</span><br><span class="line">             .btl_register_error = mca_btl_tcp_register_error_cb, <span class="comment">/* register error */</span></span><br><span class="line">         &#125;,</span><br><span class="line">     .tcp_endpoints_mutex = OPAL_MUTEX_STATIC_INIT&#125;;</span><br></pre></td></tr></table></figure></p>
<p><code>mca_btl_tcp_send</code>首先开启一个异步的发送过程，新建一个fragment，记录下每一个segment。put和get都是跟它差不多，最终都是调用的<code>mca_btl_tcp_endpoint_send</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Initiate an asynchronous send.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param btl (IN)         BTL module</span></span><br><span class="line"><span class="comment"> * @param endpoint (IN)    BTL addressing information</span></span><br><span class="line"><span class="comment"> * @param descriptor (IN)  Description of the data to be transfered</span></span><br><span class="line"><span class="comment"> * @param tag (IN)         The tag value used to notify the peer.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mca_btl_tcp_send</span><span class="params">(struct <span class="keyword">mca_btl_base_module_t</span> *btl, struct <span class="keyword">mca_btl_base_endpoint_t</span> *endpoint,</span></span></span><br><span class="line"><span class="function"><span class="params">                     struct <span class="keyword">mca_btl_base_descriptor_t</span> *descriptor, <span class="keyword">mca_btl_base_tag_t</span> tag)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">mca_btl_tcp_module_t</span> *tcp_btl = (<span class="keyword">mca_btl_tcp_module_t</span> *) btl;</span><br><span class="line">    <span class="keyword">mca_btl_tcp_frag_t</span> *frag = (<span class="keyword">mca_btl_tcp_frag_t</span> *) descriptor;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line">    frag-&gt;btl = tcp_btl;</span><br><span class="line">    frag-&gt;endpoint = endpoint;</span><br><span class="line">    frag-&gt;rc = <span class="number">0</span>;</span><br><span class="line">    frag-&gt;iov_idx = <span class="number">0</span>;</span><br><span class="line">    frag-&gt;iov_cnt = <span class="number">1</span>;</span><br><span class="line">    frag-&gt;iov_ptr = frag-&gt;iov;</span><br><span class="line">    frag-&gt;iov[<span class="number">0</span>].iov_base = (IOVBASE_TYPE *) &amp;frag-&gt;hdr;</span><br><span class="line">    frag-&gt;iov[<span class="number">0</span>].iov_len = <span class="keyword">sizeof</span>(frag-&gt;hdr);</span><br><span class="line">    frag-&gt;hdr.size = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; (<span class="keyword">int</span>) frag-&gt;base.des_segment_count; i++) &#123;</span><br><span class="line">        frag-&gt;hdr.size += frag-&gt;segments[i].seg_len;</span><br><span class="line">        frag-&gt;iov[i + <span class="number">1</span>].iov_len = frag-&gt;segments[i].seg_len;</span><br><span class="line">        frag-&gt;iov[i + <span class="number">1</span>].iov_base = (IOVBASE_TYPE *) frag-&gt;segments[i].seg_addr.pval;</span><br><span class="line">        frag-&gt;iov_cnt++;</span><br><span class="line">    &#125;</span><br><span class="line">    frag-&gt;hdr.base.tag = tag;</span><br><span class="line">    frag-&gt;hdr.type = MCA_BTL_TCP_HDR_TYPE_SEND;</span><br><span class="line">    frag-&gt;hdr.count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (endpoint-&gt;endpoint_nbo) &#123;</span><br><span class="line">        MCA_BTL_TCP_HDR_HTON(frag-&gt;hdr);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> mca_btl_tcp_endpoint_send(endpoint, frag);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>mca_btl_tcp_endpoint_send</code>尝试发送一个fragment，使用的是endpoint，看起来是一个tcp连接的抽象。如果TCP处于正在连接或者没连接的状态，就发起连接，同时把当前的frag放到list中，因为正在连接，所以没法进行通信。如果已经连接了，调用<code>mca_btl_tcp_frag_send</code>发送frag。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mca_btl_tcp_endpoint_send</span><span class="params">(<span class="keyword">mca_btl_base_endpoint_t</span> *btl_endpoint, <span class="keyword">mca_btl_tcp_frag_t</span> *frag)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">int</span> rc </span>= OPAL_SUCCESS;</span><br><span class="line"></span><br><span class="line">    OPAL_THREAD_LOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">    <span class="keyword">switch</span> (btl_endpoint-&gt;endpoint_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECTING:</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECT_ACK:</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CLOSED:</span><br><span class="line">        opal_list_append(&amp;btl_endpoint-&gt;endpoint_frags, (<span class="keyword">opal_list_item_t</span> *) frag);</span><br><span class="line">        frag-&gt;base.des_flags |= MCA_BTL_DES_SEND_ALWAYS_CALLBACK;</span><br><span class="line">        <span class="keyword">if</span> (btl_endpoint-&gt;endpoint_state == MCA_BTL_TCP_CLOSED) &#123;</span><br><span class="line">            rc = mca_btl_tcp_endpoint_start_connect(btl_endpoint);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_FAILED:</span><br><span class="line">        rc = OPAL_ERR_UNREACH;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECTED:</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == btl_endpoint-&gt;endpoint_send_frag) &#123;</span><br><span class="line">            <span class="keyword">if</span> (frag-&gt;base.des_flags &amp; MCA_BTL_DES_FLAGS_PRIORITY</span><br><span class="line">                &amp;&amp; mca_btl_tcp_frag_send(frag, btl_endpoint-&gt;endpoint_sd)) &#123;</span><br><span class="line">                <span class="comment">// 发送成功了应该</span></span><br><span class="line">                <span class="keyword">int</span> btl_ownership = (frag-&gt;base.des_flags &amp; MCA_BTL_DES_FLAGS_BTL_OWNERSHIP);</span><br><span class="line"></span><br><span class="line">                OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">                <span class="keyword">if</span> (frag-&gt;base.des_flags &amp; MCA_BTL_DES_SEND_ALWAYS_CALLBACK) &#123;</span><br><span class="line">                    frag-&gt;base.des_cbfunc(&amp;frag-&gt;btl-&gt;super, frag-&gt;endpoint, &amp;frag-&gt;base, frag-&gt;rc);</span><br><span class="line">                &#125;<span class="comment">// 回调函数</span></span><br><span class="line">                <span class="keyword">if</span> (btl_ownership) &#123;</span><br><span class="line">                    MCA_BTL_TCP_FRAG_RETURN(frag);</span><br><span class="line">                &#125;</span><br><span class="line">                MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">50</span>, btl_endpoint, <span class="literal">true</span>,</span><br><span class="line">                                          <span class="string">"complete send fragment [endpoint_send]"</span>);</span><br><span class="line">                <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                btl_endpoint-&gt;endpoint_send_frag = frag;</span><br><span class="line">                MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">true</span>,</span><br><span class="line">                                          <span class="string">"event_add(send) [endpoint_send]"</span>);</span><br><span class="line">                frag-&gt;base.des_flags |= MCA_BTL_DES_SEND_ALWAYS_CALLBACK;</span><br><span class="line">                MCA_BTL_TCP_ACTIVATE_EVENT(&amp;btl_endpoint-&gt;endpoint_send_event, <span class="number">0</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">true</span>,</span><br><span class="line">                                      <span class="string">"send fragment enqueued [endpoint_send]"</span>);</span><br><span class="line">            frag-&gt;base.des_flags |= MCA_BTL_DES_SEND_ALWAYS_CALLBACK;</span><br><span class="line">            opal_list_append(&amp;btl_endpoint-&gt;endpoint_frags, (<span class="keyword">opal_list_item_t</span> *) frag);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">    <span class="keyword">return</span> rc;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>建立TCP连接的函数，首先调用<code>socket</code>建立一个socket，并设置socket的buffer等属性。其次设置这个endpoint的回调函数，一般是设置<code>mca_btl_tcp_endpoint_recv_handler</code>和<code>mca_btl_tcp_endpoint_send_handler</code>，应该是在这个socket的某个行为已经完成后的回调。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">mca_btl_tcp_endpoint_start_connect</span><span class="params">(<span class="keyword">mca_btl_base_endpoint_t</span> *btl_endpoint)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc, flags;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_storage</span> <span class="title">endpoint_addr</span>;</span></span><br><span class="line">    <span class="comment">/* By default consider a IPv4 connection */</span></span><br><span class="line">    <span class="keyword">uint16_t</span> af_family = AF_INET;</span><br><span class="line">    <span class="keyword">opal_socklen_t</span> addrlen = <span class="keyword">sizeof</span>(struct sockaddr_in);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_IPV6</span></span><br><span class="line">    <span class="keyword">if</span> (AF_INET6 == btl_endpoint-&gt;endpoint_addr-&gt;addr_family) &#123;</span><br><span class="line">        af_family = AF_INET6;</span><br><span class="line">        addrlen = <span class="keyword">sizeof</span>(struct sockaddr_in6);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    assert(btl_endpoint-&gt;endpoint_sd &lt; <span class="number">0</span>);</span><br><span class="line">    btl_endpoint-&gt;endpoint_sd = socket(af_family, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (btl_endpoint-&gt;endpoint_sd &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        btl_endpoint-&gt;endpoint_retries++;</span><br><span class="line">        <span class="keyword">return</span> OPAL_ERR_UNREACH;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* setup socket buffer sizes */</span></span><br><span class="line">    mca_btl_tcp_set_socket_options(btl_endpoint-&gt;endpoint_sd);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* setup event callbacks </span></span><br><span class="line"><span class="comment">       只是使用了event_assign，把给定的event类型对象的每一个成员赋予一个指定的值</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    mca_btl_tcp_endpoint_event_init(btl_endpoint);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* setup the socket as non-blocking </span></span><br><span class="line"><span class="comment">       正如注释所言，只是调用了ioctlsocket设置socket的模式</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> ((flags = fcntl(btl_endpoint-&gt;endpoint_sd, F_GETFL, <span class="number">0</span>)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>, opal_process_info.nodename,</span><br><span class="line">                       getpid(), <span class="string">"fcntl(sd, F_GETFL, 0)"</span>, strerror(opal_socket_errno),</span><br><span class="line">                       opal_socket_errno);</span><br><span class="line">        <span class="comment">/* Upper layer will handler the error */</span></span><br><span class="line">        <span class="keyword">return</span> OPAL_ERR_UNREACH;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        flags |= O_NONBLOCK;</span><br><span class="line">        <span class="keyword">if</span> (fcntl(btl_endpoint-&gt;endpoint_sd, F_SETFL, flags) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(),</span><br><span class="line">                           <span class="string">"fcntl(sd, F_SETFL, flags &amp; O_NONBLOCK)"</span>, strerror(opal_socket_errno),</span><br><span class="line">                           opal_socket_errno);</span><br><span class="line">            <span class="comment">/* Upper layer will handler the error */</span></span><br><span class="line">            <span class="keyword">return</span> OPAL_ERR_UNREACH;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 把endpoint_address，可能是地址，转换成sockaddr_storage */</span></span><br><span class="line">    mca_btl_tcp_proc_tosocks(btl_endpoint-&gt;endpoint_addr, &amp;endpoint_addr);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 将套接字绑定到与此 btl 模块关联的地址之一。 这会将源 IP 设置为在 modex 中共享的地址之一，以便目标 rank 可以正确配对 btl 模块，即使在 Linux 可能对路由做一些意外的情况下 </span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (endpoint_addr.ss_family == AF_INET) &#123;</span><br><span class="line">        assert(<span class="literal">NULL</span> != &amp;btl_endpoint-&gt;endpoint_btl-&gt;tcp_ifaddr);</span><br><span class="line">        <span class="comment">// 将指定了通信协议的套接字文件与自己的IP和端口绑定起来，sd是socket的编号，tcp_ifaddr是之前转换的ip</span></span><br><span class="line">        <span class="comment">// int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen);</span></span><br><span class="line">        <span class="keyword">if</span> (bind(btl_endpoint-&gt;endpoint_sd, (struct sockaddr *) &amp;btl_endpoint-&gt;endpoint_btl-&gt;tcp_ifaddr, <span class="keyword">sizeof</span>(struct sockaddr_in)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            BTL_ERROR(............);</span><br><span class="line">            CLOSE_THE_SOCKET(btl_endpoint-&gt;endpoint_sd);</span><br><span class="line">            <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_IPV6</span></span><br><span class="line">    <span class="keyword">if</span> (endpoint_addr.ss_family == AF_INET6) &#123;</span><br><span class="line">        assert(<span class="literal">NULL</span> != &amp;btl_endpoint-&gt;endpoint_btl-&gt;tcp_ifaddr);</span><br><span class="line">        <span class="keyword">if</span> (bind(btl_endpoint-&gt;endpoint_sd, (struct sockaddr *) &amp;btl_endpoint-&gt;endpoint_btl-&gt;tcp_ifaddr, <span class="keyword">sizeof</span>(struct sockaddr_in6)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            BTL_ERROR(............);</span><br><span class="line">            CLOSE_THE_SOCKET(btl_endpoint-&gt;endpoint_sd);</span><br><span class="line">            <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> == connect(btl_endpoint-&gt;endpoint_sd, (struct sockaddr *) &amp;endpoint_addr, addrlen)) &#123;</span><br><span class="line">        <span class="comment">// 连接socket</span></span><br><span class="line">        <span class="comment">// int connect (int sockfd, struct sockaddr * serv_addr, int addrlen)</span></span><br><span class="line">        <span class="comment">/* send our globally unique process identifier to the endpoint */</span></span><br><span class="line">        <span class="keyword">if</span> ((rc = mca_btl_tcp_endpoint_send_connect_ack(btl_endpoint)) == OPAL_SUCCESS) &#123;</span><br><span class="line">            <span class="comment">// 最终是调用了send函数进行发送magic id的操作</span></span><br><span class="line">            btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_CONNECT_ACK;</span><br><span class="line">            MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">true</span>, <span class="string">"event_add(recv) [start_connect]"</span>);</span><br><span class="line">            opal_event_add(&amp;btl_endpoint-&gt;endpoint_recv_event, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (mca_btl_tcp_event_base == opal_sync_event_base) &#123;</span><br><span class="line">                <span class="comment">/* If no progress thread then raise the awarness of the default progress engine */</span></span><br><span class="line">                opal_progress_event_users_increment();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* We connected to the peer, but he close the socket before we got a chance to send our guid</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">1</span>, btl_endpoint, <span class="literal">true</span>, <span class="string">"dropped connection [start_connect]"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* non-blocking so wait for completion */</span></span><br><span class="line">        <span class="keyword">if</span> (opal_socket_errno == EINPROGRESS || opal_socket_errno == EWOULDBLOCK) &#123;</span><br><span class="line">            btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_CONNECTING;</span><br><span class="line">            MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">true</span>, <span class="string">"event_add(send) [start_connect]"</span>);</span><br><span class="line">            MCA_BTL_TCP_ACTIVATE_EVENT(&amp;btl_endpoint-&gt;endpoint_send_event, <span class="number">0</span>);</span><br><span class="line">            opal_output_verbose(<span class="number">30</span>, opal_btl_base_framework.framework_output,</span><br><span class="line">                                <span class="string">"btl:tcp: would block, so allowing background progress"</span>);</span><br><span class="line">            <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">char</span> *address;</span><br><span class="line">        address = opal_net_get_hostname((struct sockaddr *) &amp;endpoint_addr);</span><br><span class="line">        BTL_PEER_ERROR(btl_endpoint-&gt;endpoint_proc-&gt;proc_opal,</span><br><span class="line">                       (<span class="string">"Unable to connect to the peer %s on port %d: %s\n"</span>, address,</span><br><span class="line">                        ntohs(btl_endpoint-&gt;endpoint_addr-&gt;addr_port),</span><br><span class="line">                        strerror(opal_socket_errno)));</span><br><span class="line">    &#125;</span><br><span class="line">    btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">    mca_btl_tcp_endpoint_close(btl_endpoint);</span><br><span class="line">    <span class="keyword">return</span> OPAL_ERR_UNREACH;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>两个回调函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * A file descriptor is available/ready for recv. Check the state</span></span><br><span class="line"><span class="comment"> * of the socket and take the appropriate action.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mca_btl_tcp_endpoint_recv_handler</span><span class="params">(<span class="keyword">int</span> sd, <span class="keyword">short</span> flags, <span class="keyword">void</span> *user)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">mca_btl_base_endpoint_t</span> *btl_endpoint = (<span class="keyword">mca_btl_base_endpoint_t</span> *) user;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Make sure we don't have a race between a thread that remove the</span></span><br><span class="line"><span class="comment">     * recv event, and one event already scheduled.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (sd != btl_endpoint-&gt;endpoint_sd) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 这里有一个极其罕见的竞争条件，只能在初始化期间触发。</span></span><br><span class="line"><span class="comment">     * 如果两个进程同时启动它们的连接，则其中一个进程将不得不关闭它的前一个endpoint（从本地发送打开的那个）。</span></span><br><span class="line"><span class="comment">     * 结果它可能会进入 btl_endpoint_close 并尝试删除 recv_event。 </span></span><br><span class="line"><span class="comment">     * 此调用将返回 libevent，并且在多线程情况下将尝试锁定事件。 </span></span><br><span class="line"><span class="comment">     * 如果另一个线程注意到活动事件（这是可能的，因为在初始化期间将有 2 个套接字），</span></span><br><span class="line"><span class="comment">     * 一个线程可能会卡住试图锁定 endpoint_recv_lock（同时持有 event_base 锁），</span></span><br><span class="line"><span class="comment">     * 而另一个线程将尝试锁定 event_base 锁（同时持有 endpoint_recv 锁）。</span></span><br><span class="line"><span class="comment">     </span></span><br><span class="line"><span class="comment">      如果我们不能锁定这个互斥体，取消接收操作是可以的，它最终会很快再次触发。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (OPAL_THREAD_TRYLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">switch</span> (btl_endpoint-&gt;endpoint_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECT_ACK: &#123;</span><br><span class="line">        <span class="keyword">int</span> rc = mca_btl_tcp_endpoint_recv_connect_ack(btl_endpoint);</span><br><span class="line">        <span class="comment">// 如果还是MCA_BTL_TCP_CONNECT_ACK，说明可能还不用真的接收真实数据</span></span><br><span class="line">        <span class="comment">// 最终调用的是recv函数，接收标识符确认已经完成了连接</span></span><br><span class="line">        <span class="comment">// 把这个endpoint设置为MCA_BTL_TCP_CONNECTED</span></span><br><span class="line">        <span class="keyword">if</span> (OPAL_SUCCESS == rc) &#123;</span><br><span class="line">            <span class="comment">/* we are now connected. Start sending the data */</span></span><br><span class="line">            OPAL_THREAD_LOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">            mca_btl_tcp_endpoint_connected(btl_endpoint);</span><br><span class="line">            OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">            MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">true</span>, <span class="string">"connected"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (OPAL_ERR_BAD_PARAM == rc || OPAL_ERROR == rc) &#123;</span><br><span class="line">            <span class="comment">/* If we get a BAD_PARAM, it means that it probably wasn't</span></span><br><span class="line"><span class="comment">               an OMPI process on the other end of the socket (e.g.,</span></span><br><span class="line"><span class="comment">               the magic string ID failed). recv_connect_ack already cleaned</span></span><br><span class="line"><span class="comment">               up the socket. */</span></span><br><span class="line">            <span class="comment">/* If we get OPAL_ERROR, the other end closed the connection</span></span><br><span class="line"><span class="comment">             * because it has initiated a symetrical connexion on its end.</span></span><br><span class="line"><span class="comment">             * recv_connect_ack already cleaned up the socket. */</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">/* Otherwise, it probably *was* an OMPI peer process on</span></span><br><span class="line"><span class="comment">               the other end, and something bad has probably</span></span><br><span class="line"><span class="comment">               happened.  */</span></span><br><span class="line">            <span class="keyword">mca_btl_tcp_module_t</span> *m = btl_endpoint-&gt;endpoint_btl;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* Fail up to the PML */</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="literal">NULL</span> != m-&gt;tcp_error_cb) &#123;</span><br><span class="line">                m-&gt;tcp_error_cb(</span><br><span class="line">                    (<span class="keyword">mca_btl_base_module_t</span> *) m, MCA_BTL_ERROR_FLAGS_FATAL,</span><br><span class="line">                    btl_endpoint-&gt;endpoint_proc-&gt;proc_opal,</span><br><span class="line">                    <span class="string">"TCP ACK is neither SUCCESS nor ERR (something bad has probably happened)"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECTED: &#123;</span><br><span class="line">        <span class="comment">// 如果已经是MCA_BTL_TCP_CONNECTED状态了，执行接收</span></span><br><span class="line">        <span class="keyword">mca_btl_tcp_frag_t</span> *frag;</span><br><span class="line"></span><br><span class="line">        frag = btl_endpoint-&gt;endpoint_recv_frag;</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == frag) &#123;</span><br><span class="line">            <span class="keyword">if</span> (mca_btl_tcp_module.super.btl_max_send_size</span><br><span class="line">                &gt; mca_btl_tcp_module.super.btl_eager_limit) &#123;</span><br><span class="line">                MCA_BTL_TCP_FRAG_ALLOC_MAX(frag);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                MCA_BTL_TCP_FRAG_ALLOC_EAGER(frag);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 从opal_free_list_item_t表里找到一个需要接收的，之前好像有把消息加入到这里</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="literal">NULL</span> == frag) &#123;</span><br><span class="line">                OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock);</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            MCA_BTL_TCP_FRAG_INIT_DST(frag, btl_endpoint);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> MCA_BTL_TCP_ENDPOINT_CACHE</span></span><br><span class="line">        assert(<span class="number">0</span> == btl_endpoint-&gt;endpoint_cache_length);</span><br><span class="line">    data_still_pending_on_endpoint:</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* MCA_BTL_TCP_ENDPOINT_CACHE */</span></span></span><br><span class="line">        <span class="comment">/* check for completion of non-blocking recv on the current fragment */</span></span><br><span class="line">        <span class="keyword">if</span> (mca_btl_tcp_frag_recv(frag, btl_endpoint-&gt;endpoint_sd) == <span class="literal">false</span>) &#123;</span><br><span class="line">            <span class="comment">// 这个函数关键是readv，与之前的sendv对应，其他很多代码是处理接收了一部分frag或者接收失败的情况。</span></span><br><span class="line">            btl_endpoint-&gt;endpoint_recv_frag = frag;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            btl_endpoint-&gt;endpoint_recv_frag = <span class="literal">NULL</span>;</span><br><span class="line">            <span class="keyword">if</span> (MCA_BTL_TCP_HDR_TYPE_SEND == frag-&gt;hdr.type) &#123;</span><br><span class="line">                <span class="keyword">mca_btl_active_message_callback_t</span> *reg = mca_btl_base_active_message_trigger</span><br><span class="line">                                                         + frag-&gt;hdr.base.tag;</span><br><span class="line">                <span class="keyword">const</span> <span class="keyword">mca_btl_base_receive_descriptor_t</span> desc</span><br><span class="line">                    = &#123;.endpoint = btl_endpoint,</span><br><span class="line">                       .des_segments = frag-&gt;base.des_segments,</span><br><span class="line">                       .des_segment_count = frag-&gt;base.des_segment_count,</span><br><span class="line">                       .tag = frag-&gt;hdr.base.tag,</span><br><span class="line">                       .cbdata = reg-&gt;cbdata&#125;;</span><br><span class="line">                reg-&gt;cbfunc(&amp;frag-&gt;btl-&gt;super, &amp;desc);</span><br><span class="line">            &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> MCA_BTL_TCP_ENDPOINT_CACHE</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="number">0</span> != btl_endpoint-&gt;endpoint_cache_length) &#123;</span><br><span class="line">                <span class="comment">/* 如果还有数据在frag里的话，重用它</span></span><br><span class="line"><span class="comment">                 */</span></span><br><span class="line">                MCA_BTL_TCP_FRAG_INIT_DST(frag, btl_endpoint);</span><br><span class="line">                <span class="keyword">goto</span> data_still_pending_on_endpoint;</span><br><span class="line">            &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* MCA_BTL_TCP_ENDPOINT_CACHE */</span></span></span><br><span class="line">            MCA_BTL_TCP_FRAG_RETURN(frag);</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> MCA_BTL_TCP_ENDPOINT_CACHE</span></span><br><span class="line">        assert(<span class="number">0</span> == btl_endpoint-&gt;endpoint_cache_length);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* MCA_BTL_TCP_ENDPOINT_CACHE */</span></span></span><br><span class="line">        OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CLOSED:</span><br><span class="line">        <span class="comment">/* 这是一个线程安全问题。 </span></span><br><span class="line"><span class="comment">         * 由于允许多个线程生成事件，</span></span><br><span class="line"><span class="comment">         * 当我们到达 MPI_Finalize 的末尾时，</span></span><br><span class="line"><span class="comment">         * 我们最终会有多个线程执行接收回调。</span></span><br><span class="line"><span class="comment">         * 第一个将关闭连接，所有其他人都会抱怨。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_recv_lock);</span><br><span class="line">        BTL_ERROR((<span class="string">"invalid socket state(%d)"</span>, btl_endpoint-&gt;endpoint_state));</span><br><span class="line">        btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">        mca_btl_tcp_endpoint_close(btl_endpoint);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * A file descriptor is available/ready for send. Check the state</span></span><br><span class="line"><span class="comment"> * of the socket and take the appropriate action.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mca_btl_tcp_endpoint_send_handler</span><span class="params">(<span class="keyword">int</span> sd, <span class="keyword">short</span> flags, <span class="keyword">void</span> *user)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">mca_btl_tcp_endpoint_t</span> *btl_endpoint = (<span class="keyword">mca_btl_tcp_endpoint_t</span> *) user;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* if another thread is already here, give up */</span></span><br><span class="line">    <span class="keyword">if</span> (OPAL_THREAD_TRYLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock)) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">switch</span> (btl_endpoint-&gt;endpoint_state) &#123;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECTING:</span><br><span class="line">        mca_btl_tcp_endpoint_complete_connect(btl_endpoint);</span><br><span class="line">        <span class="comment">// 检查是否已经连接了socket，如果连上了，就发送进程标识符</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_CONNECTED:</span><br><span class="line">        <span class="comment">/* complete the current send */</span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">NULL</span> != btl_endpoint-&gt;endpoint_send_frag) &#123;</span><br><span class="line">            <span class="comment">// 如果一直有frag需要发送</span></span><br><span class="line">            <span class="keyword">mca_btl_tcp_frag_t</span> *frag = btl_endpoint-&gt;endpoint_send_frag;</span><br><span class="line">            <span class="keyword">int</span> btl_ownership = (frag-&gt;base.des_flags &amp; MCA_BTL_DES_FLAGS_BTL_OWNERSHIP);</span><br><span class="line"></span><br><span class="line">            assert(btl_endpoint-&gt;endpoint_state == MCA_BTL_TCP_CONNECTED);</span><br><span class="line">            <span class="keyword">if</span> (mca_btl_tcp_frag_send(frag, btl_endpoint-&gt;endpoint_sd) == <span class="literal">false</span>) &#123; </span><br><span class="line">                <span class="comment">// 发送，如果失败的话直接跳出去</span></span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* progress any pending sends 找到其他需要发送的frag 尝试发送*/</span></span><br><span class="line">            btl_endpoint-&gt;endpoint_send_frag = (<span class="keyword">mca_btl_tcp_frag_t</span> *) opal_list_remove_first(</span><br><span class="line">                &amp;btl_endpoint-&gt;endpoint_frags);</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* if required - update request status and release fragment */</span></span><br><span class="line">            OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">            assert(frag-&gt;base.des_flags &amp; MCA_BTL_DES_SEND_ALWAYS_CALLBACK);</span><br><span class="line">            <span class="keyword">if</span> (<span class="literal">NULL</span> != frag-&gt;base.des_cbfunc) &#123;</span><br><span class="line">                frag-&gt;base.des_cbfunc(&amp;frag-&gt;btl-&gt;super, frag-&gt;endpoint, &amp;frag-&gt;base, frag-&gt;rc);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (btl_ownership) &#123;</span><br><span class="line">                MCA_BTL_TCP_FRAG_RETURN(frag);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">/* if we fail to take the lock simply return. In the worst case the</span></span><br><span class="line"><span class="comment">             * send_handler will be triggered once more, and as there will be</span></span><br><span class="line"><span class="comment">             * nothing to send the handler will be deleted.</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line">            <span class="keyword">if</span> (OPAL_THREAD_TRYLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock)) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* if nothing else to do unregister for send event notifications */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == btl_endpoint-&gt;endpoint_send_frag) &#123;</span><br><span class="line">            MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">false</span>,</span><br><span class="line">                                      <span class="string">"event_del(send) [endpoint_send_handler]"</span>);</span><br><span class="line">            opal_event_del(&amp;btl_endpoint-&gt;endpoint_send_event);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> MCA_BTL_TCP_FAILED:</span><br><span class="line">        MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">1</span>, btl_endpoint, <span class="literal">true</span>,</span><br><span class="line">                                  <span class="string">"event_del(send) [endpoint_send_handler:error]"</span>);</span><br><span class="line">        opal_event_del(&amp;btl_endpoint-&gt;endpoint_send_event);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        BTL_ERROR((<span class="string">"invalid connection state (%d)"</span>, btl_endpoint-&gt;endpoint_state));</span><br><span class="line">        MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">1</span>, btl_endpoint, <span class="literal">true</span>,</span><br><span class="line">                                  <span class="string">"event_del(send) [endpoint_send_handler:error]"</span>);</span><br><span class="line">        opal_event_del(&amp;btl_endpoint-&gt;endpoint_send_event);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    OPAL_THREAD_UNLOCK(&amp;btl_endpoint-&gt;endpoint_send_lock);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这是检查socket是否连接的函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 检查连接状态。 如果连接失败，稍后将重试。 否则，将此进程标识符发送到新连接的套接字上的端点。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">mca_btl_tcp_endpoint_complete_connect</span><span class="params">(<span class="keyword">mca_btl_base_endpoint_t</span> *btl_endpoint)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> so_error = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">opal_socklen_t</span> so_length = <span class="keyword">sizeof</span>(so_error);</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_storage</span> <span class="title">endpoint_addr</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Delete the send event notification, as the next step is waiting for the ack</span></span><br><span class="line"><span class="comment">     * from the peer. Once this ack is received we will deal with the send notification</span></span><br><span class="line"><span class="comment">     * accordingly.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    opal_event_del(&amp;btl_endpoint-&gt;endpoint_send_event);</span><br><span class="line"></span><br><span class="line">    mca_btl_tcp_proc_tosocks(btl_endpoint-&gt;endpoint_addr, &amp;endpoint_addr);</span><br><span class="line">    <span class="comment">// 把内部的proc_addr-&gt;addr_union.addr_inet转成socket用的类型addr</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* check connect completion status */</span></span><br><span class="line">    <span class="keyword">if</span> (getsockopt(btl_endpoint-&gt;endpoint_sd, SOL_SOCKET, SO_ERROR, (<span class="keyword">char</span> *) &amp;so_error, &amp;so_length) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 获取socket的属性</span></span><br><span class="line">        btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">        mca_btl_tcp_endpoint_close(btl_endpoint);</span><br><span class="line">        <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (so_error == EINPROGRESS || so_error == EWOULDBLOCK) &#123;</span><br><span class="line">        <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (so_error != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (mca_btl_base_warn_peer_error || mca_btl_base_verbose &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">char</span> *msg;</span><br><span class="line">            <span class="built_in">free</span>(msg);</span><br><span class="line">        &#125;</span><br><span class="line">        btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">        mca_btl_tcp_endpoint_close(btl_endpoint);</span><br><span class="line">        <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (mca_btl_tcp_endpoint_send_connect_ack(btl_endpoint) == OPAL_SUCCESS) &#123;</span><br><span class="line">        <span class="comment">// 最终调用了send函数发送出去</span></span><br><span class="line">        btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_CONNECT_ACK;</span><br><span class="line">        opal_event_add(&amp;btl_endpoint-&gt;endpoint_recv_event, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">if</span> (mca_btl_tcp_event_base == opal_sync_event_base) &#123;</span><br><span class="line">            <span class="comment">/* If no progress thread then raise the awarness of the default progress engine */</span></span><br><span class="line">            opal_progress_event_users_increment();</span><br><span class="line">        &#125;</span><br><span class="line">        MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">10</span>, btl_endpoint, <span class="literal">false</span>, <span class="string">"event_add(recv) [complete_connect]"</span>);</span><br><span class="line">        <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">    MCA_BTL_TCP_ENDPOINT_DUMP(<span class="number">1</span>, btl_endpoint, <span class="literal">false</span>, <span class="string">" [complete_connect]"</span>);</span><br><span class="line">    btl_endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">    mca_btl_tcp_endpoint_close(btl_endpoint);</span><br><span class="line">    <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>经过了这么长一块总算建立好了连接，接下来是执行发送的函数，<code>writev</code>是将不连续的内存块写入地址中，这里的参数sd是socket的编号。可能出现没写完的情况，这时更新frag的iov_cnt。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">mca_btl_tcp_frag_send</span><span class="params">(<span class="keyword">mca_btl_tcp_frag_t</span> *frag, <span class="keyword">int</span> sd)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ssize_t</span> cnt;</span><br><span class="line">    <span class="keyword">size_t</span> i, num_vecs;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* non-blocking write, but continue if interrupted */</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        cnt = writev(sd, frag-&gt;iov_ptr, frag-&gt;iov_cnt);</span><br><span class="line">        <span class="keyword">if</span> (cnt &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">switch</span> (opal_socket_errno) &#123;</span><br><span class="line">            <span class="keyword">case</span> EINTR:</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            <span class="keyword">case</span> EWOULDBLOCK:</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">case</span> EFAULT:</span><br><span class="line">                BTL_ERROR((<span class="string">"mca_btl_tcp_frag_send: writev error (%p, %lu)\n\t%s(%lu)\n"</span>,</span><br><span class="line">                           frag-&gt;iov_ptr[<span class="number">0</span>].iov_base, (<span class="keyword">unsigned</span> <span class="keyword">long</span>) frag-&gt;iov_ptr[<span class="number">0</span>].iov_len,</span><br><span class="line">                           strerror(opal_socket_errno), (<span class="keyword">unsigned</span> <span class="keyword">long</span>) frag-&gt;iov_cnt));</span><br><span class="line">                <span class="comment">/* send_lock held by caller */</span></span><br><span class="line">                frag-&gt;endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">                mca_btl_tcp_endpoint_close(frag-&gt;endpoint);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                BTL_PEER_ERROR(frag-&gt;endpoint-&gt;endpoint_proc-&gt;proc_opal,</span><br><span class="line">                               (<span class="string">"mca_btl_tcp_frag_send: writev failed: %s (%d)"</span>,</span><br><span class="line">                                strerror(opal_socket_errno), opal_socket_errno));</span><br><span class="line">                <span class="comment">/* send_lock held by caller */</span></span><br><span class="line">                frag-&gt;endpoint-&gt;endpoint_state = MCA_BTL_TCP_FAILED;</span><br><span class="line">                mca_btl_tcp_endpoint_close(frag-&gt;endpoint);</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (cnt &lt; <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* if the write didn't complete - update the iovec state */</span></span><br><span class="line">    num_vecs = frag-&gt;iov_cnt;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; num_vecs; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cnt &gt;= (<span class="keyword">ssize_t</span>) frag-&gt;iov_ptr-&gt;iov_len) &#123;</span><br><span class="line">            cnt -= frag-&gt;iov_ptr-&gt;iov_len;</span><br><span class="line">            frag-&gt;iov_ptr++;</span><br><span class="line">            frag-&gt;iov_idx++;</span><br><span class="line">            frag-&gt;iov_cnt--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            frag-&gt;iov_ptr-&gt;iov_base = (<span class="keyword">opal_iov_base_ptr_t</span>)(</span><br><span class="line">                ((<span class="keyword">unsigned</span> <span class="keyword">char</span> *) frag-&gt;iov_ptr-&gt;iov_base) + cnt);</span><br><span class="line">            frag-&gt;iov_ptr-&gt;iov_len -= cnt;</span><br><span class="line">            OPAL_OUTPUT_VERBOSE((<span class="number">100</span>, opal_btl_base_framework.framework_output,</span><br><span class="line">                                 <span class="string">"%s:%d write %ld bytes on socket %d\n"</span>, __FILE__, __LINE__, cnt,</span><br><span class="line">                                 sd));</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (frag-&gt;iov_cnt == <span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>mca_btl_tcp_create</code>在给定设备（即 kindex）上查找未被 disable_family 选项禁用的地址。 如果没有，请跳过为此接口创建模块。 我们将地址存储在模块上，既可以在 modex 中发布，也可以用作该模块发送的所有数据包的源地址。 最好将 split_and_resolve 分开并将用于选择设备的地址传递给<code>mca_btl_tcp_create()</code>。 这是对多年来一直使用的逻辑的清理，但它没有涵盖的情况是（例如）仅在接口具有 10.0.0.1 和 10.1.0.1 的地址时指定 mca_btl_if_include 10.0.0.0/16； 绝对没有什么可以阻止此代码选择 10.1.0.1 作为在 modex 中发布并用于连接的代码。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> *  Create a btl instance and add to modules list.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">mca_btl_tcp_create</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> if_kindex, <span class="keyword">const</span> <span class="keyword">char</span> *if_name)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mca_btl_tcp_module_t</span> *<span class="title">btl</span>;</span></span><br><span class="line">    <span class="keyword">opal_if_t</span> *copied_interface, *selected_interface;</span><br><span class="line">    <span class="keyword">char</span> param[<span class="number">256</span>];</span><br><span class="line">    <span class="keyword">int</span> i, if_index;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_storage</span> <span class="title">addr</span>;</span></span><br><span class="line">    <span class="keyword">bool</span> found = <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    OPAL_LIST_FOREACH (selected_interface, &amp;opal_if_list, <span class="keyword">opal_if_t</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (if_kindex != selected_interface-&gt;if_kernel_index) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if_index = selected_interface-&gt;if_index;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">memcpy</span>((struct sockaddr *) &amp;addr, &amp;selected_interface-&gt;if_addr,</span><br><span class="line">               MIN(<span class="keyword">sizeof</span>(struct sockaddr_storage), <span class="keyword">sizeof</span>(selected_interface-&gt;if_addr)));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (addr.ss_family == AF_INET &amp;&amp; <span class="number">4</span> != mca_btl_tcp_component.tcp_disable_family) &#123;</span><br><span class="line">            found = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (addr.ss_family == AF_INET6 &amp;&amp; <span class="number">6</span> != mca_btl_tcp_component.tcp_disable_family) &#123;</span><br><span class="line">            found = <span class="literal">true</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 如果没找到就返回 */</span></span><br><span class="line">    <span class="keyword">if</span> (!found) &#123;</span><br><span class="line">        <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; (<span class="keyword">int</span>) mca_btl_tcp_component.tcp_num_links; i++) &#123;</span><br><span class="line">        btl = (struct <span class="keyword">mca_btl_tcp_module_t</span> *) <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">mca_btl_tcp_module_t</span>));</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == btl) &#123;</span><br><span class="line">            <span class="keyword">return</span> OPAL_ERR_OUT_OF_RESOURCE;</span><br><span class="line">        &#125;</span><br><span class="line">        copied_interface = OBJ_NEW(<span class="keyword">opal_if_t</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == copied_interface) &#123;</span><br><span class="line">            <span class="built_in">free</span>(btl);</span><br><span class="line">            <span class="keyword">return</span> OPAL_ERR_OUT_OF_RESOURCE;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">memcpy</span>(btl, &amp;mca_btl_tcp_module, <span class="keyword">sizeof</span>(mca_btl_tcp_module));</span><br><span class="line">        OBJ_CONSTRUCT(&amp;btl-&gt;tcp_endpoints, <span class="keyword">opal_list_t</span>);</span><br><span class="line">        OBJ_CONSTRUCT(&amp;btl-&gt;tcp_endpoints_mutex, <span class="keyword">opal_mutex_t</span>);</span><br><span class="line">        mca_btl_tcp_component.tcp_btls[mca_btl_tcp_component.tcp_num_btls++] = btl;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* initialize the btl */</span></span><br><span class="line">        <span class="comment">/* This index is used as a key for a hash table used for interface matching. */</span></span><br><span class="line">        btl-&gt;btl_index = mca_btl_tcp_component.tcp_num_btls - <span class="number">1</span>;</span><br><span class="line">        btl-&gt;tcp_ifkindex = (<span class="keyword">uint16_t</span>) if_kindex;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> MCA_BTL_TCP_STATISTICS</span></span><br><span class="line">        btl-&gt;tcp_bytes_recv = <span class="number">0</span>;</span><br><span class="line">        btl-&gt;tcp_bytes_sent = <span class="number">0</span>;</span><br><span class="line">        btl-&gt;tcp_send_handler = <span class="number">0</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;btl-&gt;tcp_ifaddr, &amp;addr, <span class="keyword">sizeof</span>(struct sockaddr_storage));</span><br><span class="line">        btl-&gt;tcp_ifmask = selected_interface-&gt;if_mask;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* allow user to specify interface bandwidth */</span></span><br><span class="line">        <span class="built_in">sprintf</span>(param, <span class="string">"bandwidth_%s"</span>, if_name);</span><br><span class="line">        mca_btl_tcp_param_register_uint(param, <span class="literal">NULL</span>, btl-&gt;super.btl_bandwidth, OPAL_INFO_LVL_5,</span><br><span class="line">                                        &amp;btl-&gt;super.btl_bandwidth);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* allow user to override/specify latency ranking */</span></span><br><span class="line">        <span class="built_in">sprintf</span>(param, <span class="string">"latency_%s"</span>, if_name);</span><br><span class="line">        mca_btl_tcp_param_register_uint(param, <span class="literal">NULL</span>, btl-&gt;super.btl_latency, OPAL_INFO_LVL_5,</span><br><span class="line">                                        &amp;btl-&gt;super.btl_latency);</span><br><span class="line">        <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            btl-&gt;super.btl_bandwidth &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">            btl-&gt;super.btl_latency &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">        <span class="comment">/* 注册一些参数 */</span></span><br><span class="line">        <span class="built_in">sprintf</span>(param, <span class="string">"bandwidth_%s:%d"</span>, if_name, i);</span><br><span class="line">        mca_btl_tcp_param_register_uint(param, <span class="literal">NULL</span>, btl-&gt;super.btl_bandwidth, OPAL_INFO_LVL_5,</span><br><span class="line">                                        &amp;btl-&gt;super.btl_bandwidth);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* allow user to override/specify latency ranking */</span></span><br><span class="line">        <span class="built_in">sprintf</span>(param, <span class="string">"latency_%s:%d"</span>, if_name, i);</span><br><span class="line">        mca_btl_tcp_param_register_uint(param, <span class="literal">NULL</span>, btl-&gt;super.btl_latency, OPAL_INFO_LVL_5,</span><br><span class="line">                                        &amp;btl-&gt;super.btl_latency);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Only attempt to auto-detect bandwidth and/or latency if it is 0.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * If detection fails to return anything other than 0, set a default</span></span><br><span class="line"><span class="comment">         * bandwidth and latency.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> == btl-&gt;super.btl_bandwidth) &#123;</span><br><span class="line">            <span class="comment">// 如果能用ethtool 的话使用这个工具自动监测带宽</span></span><br><span class="line">            <span class="keyword">unsigned</span> <span class="keyword">int</span> speed = opal_ethtool_get_speed(if_name);</span><br><span class="line">            btl-&gt;super.btl_bandwidth = (speed == <span class="number">0</span>) ? MCA_BTL_TCP_BTL_BANDWIDTH : speed;</span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                btl-&gt;super.btl_bandwidth &gt;&gt;= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* We have no runtime btl latency detection mechanism. Just set a default. */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> == btl-&gt;super.btl_latency) &#123;</span><br><span class="line">            btl-&gt;super.btl_latency = MCA_BTL_TCP_BTL_LATENCY;</span><br><span class="line">            <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                btl-&gt;super.btl_latency &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Add another entry to the local interface list */</span></span><br><span class="line">        opal_string_copy(copied_interface-&gt;if_name, if_name, OPAL_IF_NAMESIZE);</span><br><span class="line">        copied_interface-&gt;if_index = if_index;</span><br><span class="line">        copied_interface-&gt;if_kernel_index = btl-&gt;tcp_ifkindex;</span><br><span class="line">        copied_interface-&gt;af_family = btl-&gt;tcp_ifaddr.ss_family;</span><br><span class="line">        copied_interface-&gt;if_flags = selected_interface-&gt;if_flags;</span><br><span class="line">        copied_interface-&gt;if_speed = selected_interface-&gt;if_speed;</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;copied_interface-&gt;if_addr, &amp;btl-&gt;tcp_ifaddr, <span class="keyword">sizeof</span>(struct sockaddr_storage));</span><br><span class="line">        copied_interface-&gt;if_mask = selected_interface-&gt;if_mask;</span><br><span class="line">        copied_interface-&gt;if_bandwidth = btl-&gt;super.btl_bandwidth;</span><br><span class="line">        <span class="built_in">memcpy</span>(&amp;copied_interface-&gt;if_mac, &amp;selected_interface-&gt;if_mac,</span><br><span class="line">               <span class="keyword">sizeof</span>(copied_interface-&gt;if_mac));</span><br><span class="line">        copied_interface-&gt;ifmtu = selected_interface-&gt;ifmtu;</span><br><span class="line"></span><br><span class="line">        opal_list_append(&amp;mca_btl_tcp_component.local_ifs, &amp;(copied_interface-&gt;super));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>当引擎发现socket有连接事件是，调用这个函数进行accept，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">int accept ( int s , struct sockaddr *addr , socklen_t *addrlen ) ;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">参数</span></span><br><span class="line"><span class="comment"> 1. s : 是服务器端通过调用正确调用socket -&gt; bind -&gt; listen 函数之后的用于指向存放多个客户端缓冲</span></span><br><span class="line"><span class="comment">        队列缓冲区的套接字描述符</span></span><br><span class="line"><span class="comment"> 2. addr : 是用来保存发起连接请求的主机的地址与端口的结构体变量，就是存放服务器接收请求</span></span><br><span class="line"><span class="comment">        的客户端的网络地址与端口的结构体变量</span></span><br><span class="line"><span class="comment">3.  addrlen: 用来传入第二个参数类型长度</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">返回值：</span></span><br><span class="line"><span class="comment">  如果函数执行正确的话，将会返回新的套接字描述符，用于指向与当前通信的客户端交换数据的缓冲区的套接字描述符</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mca_btl_tcp_component_accept_handler</span><span class="params">(<span class="keyword">int</span> incoming_sd, <span class="keyword">short</span> ignored, <span class="keyword">void</span> *unused)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_IPV6</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in6</span> <span class="title">addr</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">addr</span>;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">        <span class="keyword">opal_socklen_t</span> addrlen = <span class="keyword">sizeof</span>(addr);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">mca_btl_tcp_event_t</span> *event;</span><br><span class="line">        <span class="keyword">int</span> sd = accept(incoming_sd, (struct sockaddr *) &amp;addr, &amp;addrlen);</span><br><span class="line">        <span class="keyword">if</span> (sd &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (opal_socket_errno == EINTR) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (opal_socket_errno != EAGAIN &amp;&amp; opal_socket_errno != EWOULDBLOCK) &#123;</span><br><span class="line">                opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"accept failed"</span>, <span class="literal">true</span>,</span><br><span class="line">                               opal_process_info.nodename, getpid(), opal_socket_errno,</span><br><span class="line">                               strerror(opal_socket_errno));</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mca_btl_tcp_set_socket_options(sd);</span><br><span class="line"></span><br><span class="line">        assert(<span class="literal">NULL</span> != mca_btl_tcp_event_base);</span><br><span class="line">        <span class="comment">/* wait for receipt of peers process identifier to complete this connection */</span></span><br><span class="line">        event = OBJ_NEW(<span class="keyword">mca_btl_tcp_event_t</span>);</span><br><span class="line">        opal_event_set(mca_btl_tcp_event_base, &amp;(event-&gt;event), sd, OPAL_EV_READ,</span><br><span class="line">                       mca_btl_tcp_component_recv_handler, event);</span><br><span class="line">        opal_event_add(&amp;event-&gt;event, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Event callback when there is data available on the registered</span></span><br><span class="line"><span class="comment"> * socket to recv. This callback is triggered only once per lifetime</span></span><br><span class="line"><span class="comment"> * for any socket, in the beginning when we setup the handshake</span></span><br><span class="line"><span class="comment"> * protocol.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">mca_btl_tcp_component_recv_handler</span><span class="params">(<span class="keyword">int</span> sd, <span class="keyword">short</span> flags, <span class="keyword">void</span> *user)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">mca_btl_tcp_event_t</span> *event = (<span class="keyword">mca_btl_tcp_event_t</span> *) user;</span><br><span class="line">    <span class="keyword">opal_process_name_t</span> guid;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_storage</span> <span class="title">addr</span>;</span></span><br><span class="line">    <span class="keyword">opal_socklen_t</span> addr_len = <span class="keyword">sizeof</span>(addr);</span><br><span class="line">    <span class="keyword">mca_btl_tcp_proc_t</span> *btl_proc;</span><br><span class="line">    <span class="keyword">bool</span> sockopt = <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">size_t</span> retval, len = <span class="built_in">strlen</span>(mca_btl_tcp_magic_id_string);</span><br><span class="line">    <span class="keyword">mca_btl_tcp_endpoint_hs_msg_t</span> hs_msg;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">timeval</span> <span class="title">save</span>, <span class="title">tv</span>;</span></span><br><span class="line">    <span class="keyword">socklen_t</span> rcvtimeo_save_len = <span class="keyword">sizeof</span>(save);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Note, Socket will be in blocking mode during intial handshake</span></span><br><span class="line"><span class="comment">     * hence setting SO_RCVTIMEO to say 2 seconds here to avoid waiting</span></span><br><span class="line"><span class="comment">     * forever when connecting to older versions (that reply to the</span></span><br><span class="line"><span class="comment">     * handshake with only the guid) or when the remote side isn't OMPI</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* get the current timeout value so we can reset to it */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> != getsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, (<span class="keyword">void</span> *) &amp;save, &amp;rcvtimeo_save_len)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ENOPROTOOPT == errno || EOPNOTSUPP == errno) &#123;</span><br><span class="line">            sockopt = <span class="literal">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(),</span><br><span class="line">                           <span class="string">"getsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, ...)"</span>,</span><br><span class="line">                           strerror(opal_socket_errno), opal_socket_errno);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        tv.tv_sec = <span class="number">2</span>;</span><br><span class="line">        tv.tv_usec = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> != setsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, &amp;tv, <span class="keyword">sizeof</span>(tv))) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(),</span><br><span class="line">                           <span class="string">"setsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, ...)"</span>,</span><br><span class="line">                           strerror(opal_socket_errno), opal_socket_errno);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OBJ_RELEASE(event);</span><br><span class="line">    retval = mca_btl_tcp_recv_blocking(sd, (<span class="keyword">void</span> *) &amp;hs_msg, <span class="keyword">sizeof</span>(hs_msg));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">     * 如果我们收到一条长度为零的消息，很可能我们同时连接到 Open MPI 对等进程 X，而对等方关闭了与我们的连接（有利于我们与它们的连接）。</span></span><br><span class="line"><span class="comment">     * 这不是错误 - 只需将其关闭并继续。</span></span><br><span class="line"><span class="comment">     * 同样，如果我们得到的字节数少于 sizeof(hs_msg)，它可能不是 Open MPI 对等体。</span></span><br><span class="line"><span class="comment">     * 但我们并不在意，因为对等方关闭了套接字。 所以只需关闭它并继续前进。 </span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (retval &lt; <span class="keyword">sizeof</span>(hs_msg)) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *peer = opal_fd_get_peer_name(sd);</span><br><span class="line">        opal_output_verbose(</span><br><span class="line">            <span class="number">20</span>, opal_btl_base_framework.framework_output,</span><br><span class="line">            <span class="string">"Peer %s closed socket without sending BTL TCP magic ID handshake (we received %d "</span></span><br><span class="line">            <span class="string">"bytes out of the expected %d) -- closing/ignoring this connection"</span>,</span><br><span class="line">            peer, (<span class="keyword">int</span>) retval, (<span class="keyword">int</span>) <span class="keyword">sizeof</span>(hs_msg));</span><br><span class="line">        <span class="built_in">free</span>((<span class="keyword">char</span> *) peer);</span><br><span class="line">        CLOSE_THE_SOCKET(sd);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 确认这个字符串是不是magic，来确认是不是openmpi的进程 */</span></span><br><span class="line">    guid = hs_msg.guid;</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> != <span class="built_in">strncmp</span>(hs_msg.magic_id, mca_btl_tcp_magic_id_string, len)) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">char</span> *peer = opal_fd_get_peer_name(sd);</span><br><span class="line">        opal_output_verbose(</span><br><span class="line">            <span class="number">20</span>, opal_btl_base_framework.framework_output,</span><br><span class="line">            <span class="string">"Peer %s send us an incorrect Open MPI magic ID string (i.e., this was not a "</span></span><br><span class="line">            <span class="string">"connection from the same version of Open MPI; expected \"%s\", received \"%s\")"</span>,</span><br><span class="line">            peer, mca_btl_tcp_magic_id_string, hs_msg.magic_id);</span><br><span class="line">        <span class="built_in">free</span>((<span class="keyword">char</span> *) peer);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* The other side probably isn't OMPI, so just hang up */</span></span><br><span class="line">        CLOSE_THE_SOCKET(sd);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (sockopt) &#123;</span><br><span class="line">        <span class="comment">/* reset RECVTIMEO option to its original state */</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> != setsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, &amp;save, <span class="keyword">sizeof</span>(save))) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(),</span><br><span class="line">                           <span class="string">"setsockopt(sd, SOL_SOCKET, SO_RCVTIMEO, ...)"</span>,</span><br><span class="line">                           strerror(opal_socket_errno), opal_socket_errno);</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OPAL_PROCESS_NAME_NTOH(guid);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* now set socket up to be non-blocking */</span></span><br><span class="line">    <span class="keyword">if</span> ((flags = fcntl(sd, F_GETFL, <span class="number">0</span>)) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>, opal_process_info.nodename,</span><br><span class="line">                       getpid(), <span class="string">"fcntl(sd, F_GETFL, 0)"</span>, strerror(opal_socket_errno),</span><br><span class="line">                       opal_socket_errno);</span><br><span class="line">        CLOSE_THE_SOCKET(sd);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        flags |= O_NONBLOCK;</span><br><span class="line">        <span class="keyword">if</span> (fcntl(sd, F_SETFL, flags) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"socket flag fail"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(),</span><br><span class="line">                           <span class="string">"fcntl(sd, F_SETFL, flags &amp; O_NONBLOCK)"</span>, strerror(opal_socket_errno),</span><br><span class="line">                           opal_socket_errno);</span><br><span class="line">            CLOSE_THE_SOCKET(sd);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* lookup the corresponding process */</span></span><br><span class="line">    btl_proc = mca_btl_tcp_proc_lookup(&amp;guid);</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == btl_proc) &#123;</span><br><span class="line">        opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"server accept cannot find guid"</span>, <span class="literal">true</span>,</span><br><span class="line">                       opal_process_info.nodename, getpid());</span><br><span class="line">        CLOSE_THE_SOCKET(sd);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* lookup peer address */</span></span><br><span class="line">    <span class="keyword">if</span> (getpeername(sd, (struct sockaddr *) &amp;addr, &amp;addr_len) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (ENOTCONN != opal_socket_errno) &#123;</span><br><span class="line">            opal_show_help(<span class="string">"help-mpi-btl-tcp.txt"</span>, <span class="string">"server getpeername failed"</span>, <span class="literal">true</span>,</span><br><span class="line">                           opal_process_info.nodename, getpid(), strerror(opal_socket_errno),</span><br><span class="line">                           opal_socket_errno);</span><br><span class="line">        &#125;</span><br><span class="line">        CLOSE_THE_SOCKET(sd);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* are there any existing peer instances willing to accept this connection */</span></span><br><span class="line">    (<span class="keyword">void</span>) mca_btl_tcp_proc_accept(btl_proc, (struct sockaddr *) &amp;addr, sd);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">char</span> *str = opal_fd_get_peer_name(sd);</span><br><span class="line">    opal_output_verbose(<span class="number">10</span>, opal_btl_base_framework.framework_output,</span><br><span class="line">                        <span class="string">"btl:tcp: now connected to %s, process %s"</span>, str,</span><br><span class="line">                        OPAL_NAME_PRINT(btl_proc-&gt;proc_opal-&gt;proc_name));</span><br><span class="line">    <span class="built_in">free</span>((<span class="keyword">char</span> *) str);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="RDMA"><a href="#RDMA" class="headerlink" title="RDMA"></a>RDMA</h1><p>以下缕一下RDMA的执行过程。支持RDMA的数据结构如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief osc rdma component structure</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_osc_rdma_component_t</span> &#123;</span></span><br><span class="line">    <span class="comment">/** Extend the basic osc component interface */</span></span><br><span class="line">    <span class="keyword">ompi_osc_base_component_t</span> super;</span><br><span class="line">    <span class="comment">/** lock access to modules */</span></span><br><span class="line">    <span class="keyword">opal_mutex_t</span> lock;</span><br><span class="line">    <span class="comment">/** cid -&gt; module mapping */</span></span><br><span class="line">    <span class="keyword">opal_hash_table_t</span> modules;</span><br><span class="line">    <span class="comment">/** free list of ompi_osc_rdma_frag_t structures */</span></span><br><span class="line">    <span class="keyword">opal_free_list_t</span> frags;</span><br><span class="line">    <span class="comment">/** Free list of requests */</span></span><br><span class="line">    <span class="keyword">opal_free_list_t</span> requests;</span><br><span class="line">    <span class="comment">/** RDMA component buffer size */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> buffer_size;</span><br><span class="line">    <span class="comment">/** List of requests that need to be freed */</span></span><br><span class="line">    <span class="keyword">opal_list_t</span> request_gc;</span><br><span class="line">    <span class="comment">/** List of buffers that need to be freed */</span></span><br><span class="line">    <span class="keyword">opal_list_t</span> buffer_gc;</span><br><span class="line">    <span class="comment">/** Maximum number of segments that can be attached to a dynamic window */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> max_attach;</span><br><span class="line">    <span class="comment">/** Default value of the no_locks info key for new windows */</span></span><br><span class="line">    <span class="keyword">bool</span> no_locks;</span><br><span class="line">    <span class="comment">/** Locking mode to use as the default for all windows */</span></span><br><span class="line">    <span class="keyword">int</span> locking_mode;</span><br><span class="line">    <span class="comment">/** Accumulate operations will only operate on a single intrinsic datatype */</span></span><br><span class="line">    <span class="keyword">bool</span> acc_single_intrinsic;</span><br><span class="line">    <span class="comment">/** Use network AMOs when available */</span></span><br><span class="line">    <span class="keyword">bool</span> acc_use_amo;</span><br><span class="line">    <span class="comment">/** Priority of the osc/rdma component */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> priority;</span><br><span class="line">    <span class="comment">/** directory where to place backing files */</span></span><br><span class="line">    <span class="keyword">char</span> *backing_directory;</span><br><span class="line">    <span class="comment">/** maximum count for network AMO usage */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> network_amo_max_count;</span><br><span class="line">    <span class="comment">/** memory alignmen to be used for new windows */</span></span><br><span class="line">    <span class="keyword">size_t</span> memory_alignment;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ompi_osc_rdma_component_t</span> <span class="title">ompi_osc_rdma_component_t</span>;</span></span><br></pre></td></tr></table></figure></p>
<p>每个 MPI 窗口都与单个 osc 模块相关联。 该结构存储与 osc/rdma 组件相关的数据。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_osc_rdma_module_t</span> &#123;</span></span><br><span class="line">    <span class="comment">/** Extend the basic osc module interface */</span></span><br><span class="line">    <span class="keyword">ompi_osc_base_module_t</span> super;</span><br><span class="line">    <span class="comment">/** pointer back to MPI window */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_win_t</span> *<span class="title">win</span>;</span></span><br><span class="line">    <span class="comment">/** Mutex lock protecting module data */</span></span><br><span class="line">    <span class="keyword">opal_mutex_t</span> lock;</span><br><span class="line">    <span class="comment">/** locking mode to use */</span></span><br><span class="line">    <span class="keyword">int</span> locking_mode;</span><br><span class="line">    <span class="comment">/* window configuration */</span></span><br><span class="line">    <span class="comment">/** value of same_disp_unit info key for this window */</span></span><br><span class="line">    <span class="keyword">bool</span> same_disp_unit;</span><br><span class="line">    <span class="comment">/** value of same_size info key for this window */</span></span><br><span class="line">    <span class="keyword">bool</span> same_size;</span><br><span class="line">    <span class="comment">/** passive-target synchronization will not be used in this window */</span></span><br><span class="line">    <span class="keyword">bool</span> no_locks;</span><br><span class="line">    <span class="keyword">bool</span> acc_single_intrinsic;</span><br><span class="line">    <span class="keyword">bool</span> acc_use_amo;</span><br><span class="line">    <span class="comment">/** whether the group is located on a single node */</span></span><br><span class="line">    <span class="keyword">bool</span> single_node;</span><br><span class="line">    <span class="comment">/** flavor of this window */</span></span><br><span class="line">    <span class="keyword">int</span> flavor;</span><br><span class="line">    <span class="comment">/** size of local window */</span></span><br><span class="line">    <span class="keyword">size_t</span> size;</span><br><span class="line">    <span class="comment">/** Local displacement unit. */</span></span><br><span class="line">    <span class="keyword">int</span> disp_unit;</span><br><span class="line">    <span class="comment">/** maximum count for network AMO usage */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> network_amo_max_count;</span><br><span class="line">    <span class="comment">/** global leader */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_peer_t</span> *leader;</span><br><span class="line">    <span class="comment">/** my peer structure */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_peer_t</span> *my_peer;</span><br><span class="line">    <span class="comment">/** pointer to free on cleanup (may be NULL) */</span></span><br><span class="line">    <span class="keyword">void</span> *free_after;</span><br><span class="line">    <span class="comment">/** local state structure (shared memory) */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_state_t</span> *state;</span><br><span class="line">    <span class="comment">/** node-level communication data (shared memory) */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *node_comm_info;</span><br><span class="line">    <span class="comment">/* only relevant on the lowest rank on each node (shared memory) */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_rank_data_t</span> *rank_array;</span><br><span class="line">    <span class="comment">/** communicator created with this window.  This is the cid used</span></span><br><span class="line"><span class="comment">     * in the component's modules mapping. */</span></span><br><span class="line">    <span class="keyword">ompi_communicator_t</span> *comm;</span><br><span class="line">    <span class="comment">/* temporary communicators for window initialization */</span></span><br><span class="line">    <span class="keyword">ompi_communicator_t</span> *local_leaders;</span><br><span class="line">    <span class="keyword">ompi_communicator_t</span> *shared_comm;</span><br><span class="line">    <span class="comment">/** node id of this rank */</span></span><br><span class="line">    <span class="keyword">int</span> node_id;</span><br><span class="line">    <span class="comment">/** number of nodes */</span></span><br><span class="line">    <span class="keyword">int</span> node_count;</span><br><span class="line">    <span class="comment">/** handle valid for local state (valid for local data for MPI_Win_allocate) */</span></span><br><span class="line">    <span class="keyword">mca_btl_base_registration_handle_t</span> *state_handle;</span><br><span class="line">    <span class="comment">/** registration handle for the window base (only used for MPI_Win_create) */</span></span><br><span class="line">    <span class="keyword">mca_btl_base_registration_handle_t</span> *base_handle;</span><br><span class="line">    <span class="comment">/** size of a region */</span></span><br><span class="line">    <span class="keyword">size_t</span> region_size;</span><br><span class="line">    <span class="comment">/** size of the state structure */</span></span><br><span class="line">    <span class="keyword">size_t</span> state_size;</span><br><span class="line">    <span class="comment">/** offset in the shared memory segment where the state array starts */</span></span><br><span class="line">    <span class="keyword">size_t</span> state_offset;</span><br><span class="line">    <span class="comment">/** memory alignmen to be used for new windows */</span></span><br><span class="line">    <span class="keyword">size_t</span> memory_alignment;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ********************* sync data ************************ */</span></span><br><span class="line">    <span class="comment">/** global sync object (PSCW, fence, lock all) */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_sync_t</span> all_sync;</span><br><span class="line">    <span class="comment">/** current group associate with pscw exposure epoch */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_group_t</span> *<span class="title">pw_group</span>;</span></span><br><span class="line">    <span class="comment">/** list of unmatched post messages */</span></span><br><span class="line">    <span class="keyword">opal_list_t</span>        pending_posts;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ********************* LOCK data ************************ */</span></span><br><span class="line">    <span class="comment">/** number of outstanding locks */</span></span><br><span class="line">    <span class="keyword">osc_rdma_counter_t</span> passive_target_access_epoch;</span><br><span class="line">    <span class="comment">/** origin side list of locks currently outstanding */</span></span><br><span class="line">    <span class="keyword">opal_hash_table_t</span> outstanding_locks;</span><br><span class="line">    <span class="comment">/** array of locks (small jobs) */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_sync_t</span> **outstanding_lock_array;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ******************* peer storage *********************** */</span></span><br><span class="line">    <span class="comment">/** hash table of allocated peers */</span></span><br><span class="line">    <span class="keyword">opal_hash_table_t</span> peer_hash;</span><br><span class="line">    <span class="comment">/** array of allocated peers (small jobs) */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_peer_t</span> **peer_array;</span><br><span class="line">    <span class="comment">/** lock for peer hash table/array */</span></span><br><span class="line">    <span class="keyword">opal_mutex_t</span> peer_lock;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* ******************* communication *********************** */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* </span></span><br><span class="line"><span class="comment">     * 我们目前支持两种操作模式，一个加速 btl（可以使用内存注册，可以使用 btl_flush() 和一个或多个备用 btl，</span></span><br><span class="line"><span class="comment">     * 它不能使用 flush() 或依赖内存注册。因为它是一个非此即彼的 情况下，我们使用联合来简化代码。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">bool</span> use_accelerated_btl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">union</span> &#123;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">            <span class="keyword">mca_btl_base_module_t</span> *accelerated_btl;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">            <span class="keyword">mca_btl_base_am_rdma_module_t</span> **alternate_am_rdmas;</span><br><span class="line">            <span class="keyword">uint8_t</span> alternate_btl_count;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/*</span></span><br><span class="line"><span class="comment">     * 选择的 BTL 是否需要内存注册？ 使用备用 BTL 时该字段为 false，使用加速 BTL 时的值取决于底层 BTL 的注册要求。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">bool</span> use_memory_registration;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">size_t</span> put_alignment;</span><br><span class="line">    <span class="keyword">size_t</span> get_alignment;</span><br><span class="line">    <span class="keyword">size_t</span> put_limit;</span><br><span class="line">    <span class="keyword">size_t</span> get_limit;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">uint32_t</span> atomic_flags;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** registered fragment used for locally buffered RDMA transfers */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_osc_rdma_frag_t</span> *<span class="title">rdma_frag</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/** registration handles for dynamically attached regions. These are not stored</span></span><br><span class="line"><span class="comment">     * in the state structure as it is entirely local. */</span></span><br><span class="line">    <span class="keyword">ompi_osc_rdma_handle_t</span> **dynamic_handles;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 共享内存段。 </span></span><br><span class="line"><span class="comment">     * 此段包含此节点的排名部分 -&gt; 节点映射数组、节点通信数据 (node_comm_info)、</span></span><br><span class="line"><span class="comment">     * 所有本地排名的状态和所有本地排名的数据（仅限 MPI_Win_allocate）</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">void</span> *segment_base;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** opal shared memory structure for the shared memory segment */</span></span><br><span class="line">    <span class="keyword">opal_shmem_ds_t</span> seg_ds;</span><br><span class="line">    <span class="comment">/* performance values */</span></span><br><span class="line">    <span class="comment">/** number of times a put had to be retried */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> put_retry_count;</span><br><span class="line">    <span class="comment">/** number of time a get had to be retried */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> get_retry_count;</span><br><span class="line">    <span class="comment">/** outstanding atomic operations */</span></span><br><span class="line">    <span class="keyword">opal_atomic_int32_t</span> pending_ops;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>这是rdma相关的一些函数，主要看<code>ompi_osc_rdma_get</code>和<code>ompi_osc_rdma_put</code><br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ompi_osc_base_module_t</span> ompi_osc_rdma_module_rdma_template = &#123;</span><br><span class="line">    .osc_win_attach = ompi_osc_rdma_attach,</span><br><span class="line">    .osc_win_detach  = ompi_osc_rdma_detach,</span><br><span class="line">    .osc_free = ompi_osc_rdma_free,</span><br><span class="line"></span><br><span class="line">    .osc_put = ompi_osc_rdma_put,</span><br><span class="line">    .osc_get = ompi_osc_rdma_get,</span><br><span class="line">    .osc_accumulate = ompi_osc_rdma_accumulate,</span><br><span class="line">    .osc_compare_and_swap = ompi_osc_rdma_compare_and_swap,</span><br><span class="line">    .osc_fetch_and_op = ompi_osc_rdma_fetch_and_op,</span><br><span class="line">    .osc_get_accumulate = ompi_osc_rdma_get_accumulate,</span><br><span class="line"></span><br><span class="line">    .osc_rput = ompi_osc_rdma_rput,</span><br><span class="line">    .osc_rget = ompi_osc_rdma_rget,</span><br><span class="line">    .osc_raccumulate = ompi_osc_rdma_raccumulate,</span><br><span class="line">    .osc_rget_accumulate = ompi_osc_rdma_rget_accumulate,</span><br><span class="line"></span><br><span class="line">    .osc_fence = ompi_osc_rdma_fence_atomic,</span><br><span class="line"></span><br><span class="line">    .osc_start = ompi_osc_rdma_start_atomic,</span><br><span class="line">    .osc_complete = ompi_osc_rdma_complete_atomic,</span><br><span class="line">    .osc_post = ompi_osc_rdma_post_atomic,</span><br><span class="line">    .osc_wait = ompi_osc_rdma_wait_atomic,</span><br><span class="line">    .osc_test = ompi_osc_rdma_test_atomic,</span><br><span class="line"></span><br><span class="line">    .osc_lock = ompi_osc_rdma_lock_atomic,</span><br><span class="line">    .osc_unlock = ompi_osc_rdma_unlock_atomic,</span><br><span class="line">    .osc_lock_all = ompi_osc_rdma_lock_all_atomic,</span><br><span class="line">    .osc_unlock_all = ompi_osc_rdma_unlock_all_atomic,</span><br><span class="line"></span><br><span class="line">    .osc_sync = ompi_osc_rdma_sync,</span><br><span class="line">    .osc_flush = ompi_osc_rdma_flush,</span><br><span class="line">    .osc_flush_all = ompi_osc_rdma_flush_all,</span><br><span class="line">    .osc_flush_local = ompi_osc_rdma_flush_local,</span><br><span class="line">    .osc_flush_local_all = ompi_osc_rdma_flush_local_all,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p><code>ompi_osc_rdma_get</code>输出一些log后，查找跟当前的source_rank相关的结构，之后的数据从source_rank里拿。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_osc_rdma_get</span> <span class="params">(<span class="keyword">void</span> *origin_addr, <span class="keyword">int</span> origin_count, <span class="keyword">ompi_datatype_t</span> *origin_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                       <span class="keyword">int</span> source_rank, <span class="keyword">ptrdiff_t</span> source_disp, <span class="keyword">int</span> source_count,</span></span></span><br><span class="line"><span class="function"><span class="params">                       <span class="keyword">ompi_datatype_t</span> *source_datatype, <span class="keyword">ompi_win_t</span> *win)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span> = GET_MODULE(win);</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_peer_t</span> *peer;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_sync_t</span> *sync;</span><br><span class="line"></span><br><span class="line">    OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"get: 0x%lx, %d, %s, %d, %d, %d, %s, %s"</span>, (<span class="keyword">unsigned</span> <span class="keyword">long</span>) origin_addr,</span><br><span class="line">                     origin_count, origin_datatype-&gt;name, source_rank, (<span class="keyword">int</span>) source_disp, source_count,</span><br><span class="line">                     source_datatype-&gt;name, win-&gt;w_name);</span><br><span class="line"></span><br><span class="line">    sync = ompi_osc_rdma_module_sync_lookup (<span class="keyword">module</span>, source_rank, &amp;peer);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(<span class="literal">NULL</span> == sync)) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_ERR_RMA_SYNC;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ompi_osc_rdma_get_w_req (sync, origin_addr, origin_count, origin_datatype, peer,</span><br><span class="line">                                    source_disp, source_count, source_datatype, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">ompi_osc_rdma_get_w_req</span> <span class="params">(<span class="keyword">ompi_osc_rdma_sync_t</span> *sync, <span class="keyword">void</span> *origin_addr, <span class="keyword">int</span> origin_count, <span class="keyword">ompi_datatype_t</span> *origin_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">ompi_osc_rdma_peer_t</span> *peer, <span class="keyword">ptrdiff_t</span> source_disp, <span class="keyword">int</span> source_count,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">ompi_datatype_t</span> *source_datatype, <span class="keyword">ompi_osc_rdma_request_t</span> *request)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span> = sync-&gt;<span class="keyword">module</span>;</span><br><span class="line">    <span class="keyword">mca_btl_base_registration_handle_t</span> *source_handle;</span><br><span class="line">    <span class="keyword">uint64_t</span> source_address;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> source_span, source_lb;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* short-circuit case */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> == origin_count || <span class="number">0</span> == source_count) &#123;</span><br><span class="line">        <span class="keyword">if</span> (request) &#123;</span><br><span class="line">            <span class="comment">// 释放结构，直接返回</span></span><br><span class="line">            ompi_osc_rdma_request_complete (request, MPI_SUCCESS);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 计算 count 个数据类型在内存中的跨度。</span></span><br><span class="line"><span class="comment">     * 此函数有助于为接收已键入的数据（例如用于 reduce 操作的数据）分配临时内存。</span></span><br><span class="line"><span class="comment">     * 这个跨度是 count 数据类型的内存布局中最小和最大字节之间的距离，</span></span><br><span class="line"><span class="comment">     * 换句话说，分配 count 所需的内存乘以数据类型，在开始和结束时没有间隙。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    source_span = opal_datatype_span(&amp;source_datatype-&gt;super, source_count, &amp;source_lb);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 找到与内存区域关联的远程段，返回的是远端地址</span></span><br><span class="line">    ret = osc_rdma_get_remote_segment (<span class="keyword">module</span>, peer, source_disp, source_span+source_lb,</span><br><span class="line">                                       &amp;source_address, &amp;source_handle);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* optimize self/local communication */</span></span><br><span class="line">    <span class="keyword">if</span> (ompi_osc_rdma_peer_local_base (peer)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ompi_osc_rdma_copy_local ((<span class="keyword">void</span> *) (<span class="keyword">intptr_t</span>) source_address, source_count, source_datatype,</span><br><span class="line">                                         origin_addr, origin_count, origin_datatype, request);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ompi_osc_rdma_master (sync, origin_addr, origin_count, origin_datatype, peer, source_address,</span><br><span class="line">                                 source_handle, source_count, source_datatype, request,</span><br><span class="line">                                 <span class="keyword">module</span>-&gt;get_limit, ompi_osc_rdma_get_contig, <span class="literal">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">osc_rdma_get_remote_segment</span> <span class="params">(<span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span>, <span class="keyword">ompi_osc_rdma_peer_t</span> *peer, <span class="keyword">ptrdiff_t</span> target_disp,</span></span></span><br><span class="line"><span class="function"><span class="params">                                               <span class="keyword">size_t</span> length, <span class="keyword">uint64_t</span> *remote_address, <span class="keyword">mca_btl_base_registration_handle_t</span> **remote_handle)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_region_t</span> *region;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_WIN_FLAVOR_DYNAMIC == <span class="keyword">module</span>-&gt;flavor) &#123;</span><br><span class="line">        ret = ompi_osc_rdma_find_dynamic_region (<span class="keyword">module</span>, peer, (<span class="keyword">uint64_t</span>) target_disp, length, &amp;region);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != ret) &#123;</span><br><span class="line">            OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_INFO, <span class="string">"could not retrieve region for %"</span> PRIx64 <span class="string">" from window rank %d"</span>,</span><br><span class="line">                             (<span class="keyword">uint64_t</span>) target_disp, peer-&gt;rank);</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        *remote_address = (<span class="keyword">uint64_t</span>) target_disp;</span><br><span class="line">        *remote_handle = (<span class="keyword">mca_btl_base_registration_handle_t</span> *) region-&gt;btl_handle_data;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">ompi_osc_rdma_peer_extended_t</span> *ex_peer = (<span class="keyword">ompi_osc_rdma_peer_extended_t</span> *) peer;</span><br><span class="line">        <span class="keyword">int</span> disp_unit = (<span class="keyword">module</span>-&gt;same_disp_unit) ? <span class="keyword">module</span>-&gt;disp_unit : ex_peer-&gt;disp_unit;</span><br><span class="line">        <span class="keyword">size_t</span> size = (<span class="keyword">module</span>-&gt;same_size) ? <span class="keyword">module</span>-&gt;size : (<span class="keyword">size_t</span>) ex_peer-&gt;size;</span><br><span class="line"></span><br><span class="line">        *remote_address = ex_peer-&gt;super.base + disp_unit * target_disp;</span><br><span class="line">        *remote_handle = ex_peer-&gt;super.base_handle;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_osc_rdma_find_dynamic_region</span> <span class="params">(<span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span>, <span class="keyword">ompi_osc_rdma_peer_t</span> *peer, <span class="keyword">uint64_t</span> base, <span class="keyword">size_t</span> len,</span></span></span><br><span class="line"><span class="function"><span class="params">				       <span class="keyword">ompi_osc_rdma_region_t</span> **region)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_peer_dynamic_t</span> *dy_peer = (<span class="keyword">ompi_osc_rdma_peer_dynamic_t</span> *) peer;</span><br><span class="line">    <span class="keyword">intptr_t</span> bound = (<span class="keyword">intptr_t</span>) base + len;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_region_t</span> *regions;</span><br><span class="line">    <span class="keyword">int</span> ret = OMPI_SUCCESS, region_count;</span><br><span class="line"></span><br><span class="line">    OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"locating dynamic memory region matching: &#123;%"</span> PRIx64 <span class="string">", %"</span> PRIx64 <span class="string">"&#125;"</span></span><br><span class="line">                     <span class="string">" (len %lu)"</span>, base, base + len, (<span class="keyword">unsigned</span> <span class="keyword">long</span>) len);</span><br><span class="line"></span><br><span class="line">    OPAL_THREAD_LOCK(&amp;<span class="keyword">module</span>-&gt;lock);</span><br><span class="line">    <span class="comment">// 需要看一些这个区域没有被加锁，获得一个排他锁，如果拿不到就一直循环等着</span></span><br><span class="line">    ompi_osc_rdma_lock_acquire_exclusive (<span class="keyword">module</span>, peer, offsetof (<span class="keyword">ompi_osc_rdma_state_t</span>, regions_lock));</span><br><span class="line">    <span class="comment">// 这个区域不是本地的区域</span></span><br><span class="line">    <span class="keyword">if</span> (!ompi_osc_rdma_peer_local_state (peer)) &#123;</span><br><span class="line">        ret = ompi_osc_rdma_refresh_dynamic_region (<span class="keyword">module</span>, dy_peer);</span><br><span class="line">            <span class="comment">/* 此函数的作用是本地的远程进程视图与远程窗口的内容保持同步。</span></span><br><span class="line"><span class="comment">             * 每次地址转换都会调用它，因为（当前）无法检测到附加区域是否已更改。</span></span><br><span class="line"><span class="comment">             * 为了减少读取的数据量，我们首先读取区域计数（其中包含一个 id）。</span></span><br><span class="line"><span class="comment">             * 如果这没有改变，则区域数据不会更新。</span></span><br><span class="line"><span class="comment">             * 如果附加区域列表已更改，则从对等方读取所有有效区域，同时保持其区域锁定。</span></span><br><span class="line"><span class="comment">             */</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != ret) &#123;</span><br><span class="line">            ompi_osc_rdma_lock_release_exclusive (<span class="keyword">module</span>, peer, offsetof (<span class="keyword">ompi_osc_rdma_state_t</span>, regions_lock));</span><br><span class="line">            <span class="keyword">return</span> ret;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        regions = dy_peer-&gt;regions;</span><br><span class="line">        region_count = dy_peer-&gt;region_count;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">ompi_osc_rdma_state_t</span> *peer_state = (<span class="keyword">ompi_osc_rdma_state_t</span> *) peer-&gt;state;</span><br><span class="line">        regions = (<span class="keyword">ompi_osc_rdma_region_t</span> *) peer_state-&gt;regions;</span><br><span class="line">        region_count = peer_state-&gt;region_count;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从排好序的regions里找到一个符合base地址+bound范围的块</span></span><br><span class="line">    <span class="comment">// 使用二分法在0到region_count-1范围内找</span></span><br><span class="line">    *region = ompi_osc_rdma_find_region_containing (regions, <span class="number">0</span>, region_count - <span class="number">1</span>, (<span class="keyword">intptr_t</span>) base, bound, <span class="keyword">module</span>-&gt;region_size, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">if</span> (!*region) &#123;</span><br><span class="line">        ret = OMPI_ERR_RMA_RANGE;</span><br><span class="line">    &#125;</span><br><span class="line">    OPAL_THREAD_UNLOCK(&amp;<span class="keyword">module</span>-&gt;lock);</span><br><span class="line">    ompi_osc_rdma_lock_release_exclusive (<span class="keyword">module</span>, peer, offsetof (<span class="keyword">ompi_osc_rdma_state_t</span>, regions_lock));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* round a matching region */</span></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>根据这个要获得的区域在本地或者远端，分别调用两个函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">ompi_osc_rdma_copy_local</span> <span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *source, <span class="keyword">int</span> source_count, <span class="keyword">ompi_datatype_t</span> *source_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">void</span> *target, <span class="keyword">int</span> target_count, <span class="keyword">ompi_datatype_t</span> *target_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     <span class="keyword">ompi_osc_rdma_request_t</span> *request)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line"></span><br><span class="line">    OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"performing local copy from %p -&gt; %p"</span>, source, target);</span><br><span class="line"></span><br><span class="line">    opal_atomic_mb ();</span><br><span class="line">    ret = ompi_datatype_sndrcv (source, source_count, source_datatype, target, target_count, target_datatype);</span><br><span class="line">    <span class="comment">// 处理pack和unpack，或者直接复制</span></span><br><span class="line">    <span class="keyword">if</span> (request) &#123;</span><br><span class="line">        ompi_osc_rdma_request_complete (request, ret);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span> <span class="title">ompi_osc_rdma_master</span> <span class="params">(<span class="keyword">ompi_osc_rdma_sync_t</span> *sync, <span class="keyword">void</span> *local_address, <span class="keyword">int</span> local_count,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">ompi_datatype_t</span> *local_datatype, <span class="keyword">ompi_osc_rdma_peer_t</span> *peer,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">uint64_t</span> remote_address, <span class="keyword">mca_btl_base_registration_handle_t</span> *remote_handle,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">int</span> remote_count, <span class="keyword">ompi_datatype_t</span> *remote_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">ompi_osc_rdma_request_t</span> *request, <span class="keyword">const</span> <span class="keyword">size_t</span> max_rdma_len,</span></span></span><br><span class="line"><span class="function"><span class="params">                                        <span class="keyword">const</span> <span class="keyword">ompi_osc_rdma_fn_t</span> rdma_fn, <span class="keyword">const</span> <span class="keyword">bool</span> alloc_reqs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> rdma_len;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> lb, extent;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line"></span><br><span class="line">    rdma_len = local_datatype-&gt;super.size * local_count;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* fast path for contiguous rdma */</span></span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(ompi_datatype_is_contiguous_memory_layout (local_datatype, local_count) &amp;&amp;</span><br><span class="line">                    ompi_datatype_is_contiguous_memory_layout (remote_datatype, remote_count) &amp;&amp;</span><br><span class="line">                    rdma_len &lt;= max_rdma_len)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == request &amp;&amp; alloc_reqs) &#123;</span><br><span class="line">            <span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span> = sync-&gt;<span class="keyword">module</span>;</span><br><span class="line">            OMPI_OSC_RDMA_REQUEST_ALLOC(<span class="keyword">module</span>, peer, request);</span><br><span class="line">            request-&gt;internal = <span class="literal">true</span>;</span><br><span class="line">            request-&gt;type = OMPI_OSC_RDMA_TYPE_RDMA;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* ignore failure here */</span></span><br><span class="line">        (<span class="keyword">void</span>) ompi_datatype_get_true_extent (local_datatype, &amp;lb, &amp;extent);</span><br><span class="line">        local_address = (<span class="keyword">void</span> *)((<span class="keyword">intptr_t</span>) local_address + lb);</span><br><span class="line"></span><br><span class="line">        (<span class="keyword">void</span>) ompi_datatype_get_true_extent (remote_datatype, &amp;lb, &amp;extent);</span><br><span class="line">        remote_address += lb;</span><br><span class="line"></span><br><span class="line">        OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"performing rdma on contiguous region. local: %p, "</span></span><br><span class="line">                         <span class="string">"remote: 0x%lx, length: %lu"</span>, local_address, (<span class="keyword">unsigned</span> <span class="keyword">long</span>) remote_address,</span><br><span class="line">                         rdma_len);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            ret = rdma_fn (sync, peer, remote_address, remote_handle, local_address, rdma_len, request);</span><br><span class="line">            <span class="keyword">if</span> (OPAL_LIKELY(OPAL_SUCCESS == ret)) &#123;</span><br><span class="line">                <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            ompi_osc_rdma_progress (sync-&gt;<span class="keyword">module</span>);</span><br><span class="line">        &#125; <span class="keyword">while</span> (<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> ompi_osc_rdma_master_noncontig (sync, local_address, local_count, local_datatype, peer, remote_address,</span><br><span class="line">                                           remote_handle, remote_count, remote_datatype, request,</span><br><span class="line">                                           max_rdma_len, rdma_fn, alloc_reqs);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * @brief 将 rdma 事务分解为连续区域</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @param[in] local_address    base of local region (source for put, destination for get)</span></span><br><span class="line"><span class="comment"> * @param[in] local_count      number of elements in local region</span></span><br><span class="line"><span class="comment"> * @param[in] local_datatype   datatype of local region</span></span><br><span class="line"><span class="comment"> * @param[in] peer             peer object for remote peer</span></span><br><span class="line"><span class="comment"> * @param[in] remote_address   base of remote region (destination for put, source for get)</span></span><br><span class="line"><span class="comment"> * @param[in] remote_handle    btl registration handle for remote region (must be valid for the entire region)</span></span><br><span class="line"><span class="comment"> * @param[in] remote_count     number of elements in remote region</span></span><br><span class="line"><span class="comment"> * @param[in] remote_datatype  datatype of remote region</span></span><br><span class="line"><span class="comment"> * @param[in] module           osc rdma module</span></span><br><span class="line"><span class="comment"> * @param[in] request          osc rdma request if used (can be NULL)</span></span><br><span class="line"><span class="comment"> * @param[in] max_rdma_len     maximum length of an rdma request (usually btl limitation)</span></span><br><span class="line"><span class="comment"> * @param[in] rdma_fn          function to use for contiguous rdma operations</span></span><br><span class="line"><span class="comment"> * @param[in] alloc_reqs       true if rdma_fn requires a valid request object (any allocated objects will be marked internal)</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * This function does the work of breaking a non-contiguous rdma transfer into contiguous components. It will</span></span><br><span class="line"><span class="comment"> * continue to submit rdma transfers until the entire region is transferred or a fatal error occurs.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">ompi_osc_rdma_master_noncontig</span> <span class="params">(<span class="keyword">ompi_osc_rdma_sync_t</span> *sync, <span class="keyword">void</span> *local_address, <span class="keyword">int</span> local_count, <span class="keyword">ompi_datatype_t</span> *local_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">ompi_osc_rdma_peer_t</span> *peer, <span class="keyword">uint64_t</span> remote_address,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">mca_btl_base_registration_handle_t</span> *remote_handle, <span class="keyword">int</span> remote_count,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">ompi_datatype_t</span> *remote_datatype, <span class="keyword">ompi_osc_rdma_request_t</span> *request, <span class="keyword">const</span> <span class="keyword">size_t</span> max_rdma_len,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">const</span> <span class="keyword">ompi_osc_rdma_fn_t</span> rdma_fn, <span class="keyword">const</span> <span class="keyword">bool</span> alloc_reqs)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_module_t</span> *<span class="keyword">module</span> = sync-&gt;<span class="keyword">module</span>;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">iovec</span> <span class="title">local_iovec</span>[<span class="title">OMPI_OSC_RDMA_DECODE_MAX</span>], <span class="title">remote_iovec</span>[<span class="title">OMPI_OSC_RDMA_DECODE_MAX</span>];</span></span><br><span class="line">    <span class="keyword">opal_convertor_t</span> local_convertor, remote_convertor;</span><br><span class="line">    <span class="keyword">uint32_t</span> local_iov_count, remote_iov_count;</span><br><span class="line">    <span class="keyword">uint32_t</span> local_iov_index, remote_iov_index;</span><br><span class="line">    <span class="comment">/* needed for opal_convertor_raw but not used */</span></span><br><span class="line">    <span class="keyword">size_t</span> local_size, remote_size, rdma_len;</span><br><span class="line">    <span class="keyword">ompi_osc_rdma_request_t</span> *subreq;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line">    <span class="keyword">bool</span> done;</span><br><span class="line"></span><br><span class="line">    subreq = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"scheduling rdma on non-contiguous datatype(s) or large region"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* prepare convertors for the source and target. these convertors will be used to determine the</span></span><br><span class="line"><span class="comment">     * contiguous segments within the source and target. */</span></span><br><span class="line">    OBJ_CONSTRUCT(&amp;remote_convertor, <span class="keyword">opal_convertor_t</span>);</span><br><span class="line">    ret = opal_convertor_copy_and_prepare_for_send (ompi_mpi_local_convertor, &amp;remote_datatype-&gt;super, remote_count,</span><br><span class="line">                                                    (<span class="keyword">void</span> *) (<span class="keyword">intptr_t</span>) remote_address, <span class="number">0</span>, &amp;remote_convertor);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OBJ_CONSTRUCT(&amp;local_convertor, <span class="keyword">opal_convertor_t</span>);</span><br><span class="line">    ret = opal_convertor_copy_and_prepare_for_send (ompi_mpi_local_convertor, &amp;local_datatype-&gt;super, local_count,</span><br><span class="line">                                                    local_address, <span class="number">0</span>, &amp;local_convertor);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 以上是转换器转换压缩</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (request) &#123;</span><br><span class="line">        <span class="comment">/* keep the request from completing until all the transfers have started */</span></span><br><span class="line">        request-&gt;outstanding_requests = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    local_iov_index = <span class="number">0</span>;</span><br><span class="line">    local_iov_count = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">/* decode segments of the remote data */</span></span><br><span class="line">        remote_iov_count = OMPI_OSC_RDMA_DECODE_MAX;</span><br><span class="line">        remote_iov_index = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* opal_convertor_raw returns true when it has reached the end of the data */</span></span><br><span class="line">        done = opal_convertor_raw (&amp;remote_convertor, remote_iovec, &amp;remote_iov_count, &amp;remote_size);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* loop on the target segments until we have exhaused the decoded source data */</span></span><br><span class="line">        <span class="keyword">while</span> (remote_iov_index != remote_iov_count) &#123;</span><br><span class="line">            <span class="keyword">if</span> (local_iov_index == local_iov_count) &#123;</span><br><span class="line">                <span class="comment">/* decode segments of the target buffer */</span></span><br><span class="line">                local_iov_count = OMPI_OSC_RDMA_DECODE_MAX;</span><br><span class="line">                local_iov_index = <span class="number">0</span>;</span><br><span class="line">                (<span class="keyword">void</span>) opal_convertor_raw (&amp;local_convertor, local_iovec, &amp;local_iov_count, &amp;local_size);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* we already checked that the target was large enough. this should be impossible */</span></span><br><span class="line">            assert (<span class="number">0</span> != local_iov_count);</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* determine how much to transfer in this operation */</span></span><br><span class="line">            rdma_len = opal_min(opal_min(local_iovec[local_iov_index].iov_len, remote_iovec[remote_iov_index].iov_len), max_rdma_len);</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* execute the get */</span></span><br><span class="line">            <span class="keyword">if</span> (!subreq &amp;&amp; alloc_reqs) &#123;</span><br><span class="line">                OMPI_OSC_RDMA_REQUEST_ALLOC(<span class="keyword">module</span>, peer, subreq);</span><br><span class="line">                subreq-&gt;internal = <span class="literal">true</span>;</span><br><span class="line">                subreq-&gt;type = OMPI_OSC_RDMA_TYPE_RDMA;</span><br><span class="line">                subreq-&gt;parent_request = request;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (request) &#123;</span><br><span class="line">                    (<span class="keyword">void</span>) OPAL_THREAD_ADD_FETCH32 (&amp;request-&gt;outstanding_requests, <span class="number">1</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!alloc_reqs) &#123;</span><br><span class="line">                subreq = request;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            ret = rdma_fn (sync, peer, (<span class="keyword">uint64_t</span>) (<span class="keyword">intptr_t</span>) remote_iovec[remote_iov_index].iov_base, remote_handle,</span><br><span class="line">                           local_iovec[local_iov_index].iov_base, rdma_len, subreq);</span><br><span class="line">            <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_SUCCESS != ret)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (OPAL_UNLIKELY(OMPI_ERR_OUT_OF_RESOURCE != ret)) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (request) &#123;</span><br><span class="line">                        ompi_osc_rdma_request_deref (request);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">if</span> (alloc_reqs) &#123;</span><br><span class="line">                        OMPI_OSC_RDMA_REQUEST_RETURN(subreq);</span><br><span class="line">                    &#125;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">/* something bad happened. need to figure out best way to handle rma errors */</span></span><br><span class="line">                    <span class="keyword">return</span> ret;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">/* progress and try again */</span></span><br><span class="line">                ompi_osc_rdma_progress (<span class="keyword">module</span>);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            subreq = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">/* adjust io vectors */</span></span><br><span class="line">            local_iovec[local_iov_index].iov_len -= rdma_len;</span><br><span class="line">            remote_iovec[remote_iov_index].iov_len -= rdma_len;</span><br><span class="line">            local_iovec[local_iov_index].iov_base = (<span class="keyword">void</span> *)((<span class="keyword">intptr_t</span>) local_iovec[local_iov_index].iov_base + rdma_len);</span><br><span class="line">            remote_iovec[remote_iov_index].iov_base = (<span class="keyword">void</span> *)((<span class="keyword">intptr_t</span>) remote_iovec[remote_iov_index].iov_base + rdma_len);</span><br><span class="line"></span><br><span class="line">            local_iov_index += (<span class="number">0</span> == local_iovec[local_iov_index].iov_len);</span><br><span class="line">            remote_iov_index += (<span class="number">0</span> == remote_iovec[remote_iov_index].iov_len);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (!done);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (request) &#123;</span><br><span class="line">        <span class="comment">/* release our reference so the request can complete */</span></span><br><span class="line">        ompi_osc_rdma_request_deref (request);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OSC_RDMA_VERBOSE(MCA_BASE_VERBOSE_TRACE, <span class="string">"finished scheduling rdma on non-contiguous datatype(s)"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* clean up convertors */</span></span><br><span class="line">    opal_convertor_cleanup (&amp;local_convertor);</span><br><span class="line">    OBJ_DESTRUCT(&amp;local_convertor);</span><br><span class="line">    opal_convertor_cleanup (&amp;remote_convertor);</span><br><span class="line">    OBJ_DESTRUCT(&amp;remote_convertor);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="UCX"><a href="#UCX" class="headerlink" title="UCX"></a>UCX</h1><p>因为在之前的报错里看到过UCX的字样，所以跟了一下<code>mca_pml_ucx_send</code>函数，底层是用了Unified Communication X库。先是找到代表dst进程的endpoint，再用两个函数实现send。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mca_pml_ucx_send</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count, <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">int</span> dst,</span></span></span><br><span class="line"><span class="function"><span class="params">                     <span class="keyword">int</span> tag, <span class="keyword">mca_pml_base_send_mode_t</span> mode,</span></span></span><br><span class="line"><span class="function"><span class="params">                     struct <span class="keyword">ompi_communicator_t</span>* comm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    ucp_ep_h ep;</span><br><span class="line"></span><br><span class="line">    PML_UCX_TRACE_SEND(<span class="string">"%s"</span>, buf, count, datatype, dst, tag, mode, comm,</span><br><span class="line">                       mode == MCA_PML_BASE_SEND_BUFFERED ? <span class="string">"bsend"</span> : <span class="string">"send"</span>);</span><br><span class="line"></span><br><span class="line">    ep = mca_pml_ucx_get_ep(comm, dst);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(<span class="literal">NULL</span> == ep)) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> SPC_ENABLE == 1</span></span><br><span class="line">    <span class="keyword">size_t</span> dt_size;</span><br><span class="line">    ompi_datatype_type_size(datatype, &amp;dt_size);</span><br><span class="line">    SPC_USER_OR_MPI(tag, dt_size*count,</span><br><span class="line">                    OMPI_SPC_BYTES_SENT_USER, OMPI_SPC_BYTES_SENT_MPI);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> HAVE_DECL_UCP_TAG_SEND_NBR</span></span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY((MCA_PML_BASE_SEND_BUFFERED != mode) &amp;&amp;</span><br><span class="line">                    (MCA_PML_BASE_SEND_SYNCHRONOUS != mode))) &#123;</span><br><span class="line">        <span class="keyword">return</span> mca_pml_ucx_send_nbr(ep, buf, count, datatype,</span><br><span class="line">                                    PML_UCX_MAKE_SEND_TAG(tag, comm));</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mca_pml_ucx_send_nb(ep, buf, count, datatype,</span><br><span class="line">                               mca_pml_ucx_get_datatype(datatype),</span><br><span class="line">                               PML_UCX_MAKE_SEND_TAG(tag, comm), mode);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>实现send的其中一个非阻塞函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">if</span> HAVE_DECL_UCP_TAG_SEND_NBR</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> __opal_attribute_always_inline__ <span class="keyword">int</span></span><br><span class="line">mca_pml_ucx_send_nbr(ucp_ep_h ep, <span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count,</span><br><span class="line">                     <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">ucp_tag_t</span> tag)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">/* coverity[bad_alloc_arithmetic] */</span></span><br><span class="line">    <span class="keyword">ucs_status_ptr_t</span> req = PML_UCX_REQ_ALLOCA();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> HAVE_DECL_UCP_TAG_SEND_NBX</span></span><br><span class="line">    <span class="keyword">pml_ucx_datatype_t</span> *op_data = mca_pml_ucx_get_op_data(datatype);</span><br><span class="line">    <span class="keyword">ucp_request_param_t</span> param   = &#123;</span><br><span class="line">        .op_attr_mask = UCP_OP_ATTR_FIELD_REQUEST |</span><br><span class="line">                        (op_data-&gt;op_param.send.op_attr_mask &amp; UCP_OP_ATTR_FIELD_DATATYPE) |</span><br><span class="line">                        UCP_OP_ATTR_FLAG_FAST_CMPL,</span><br><span class="line">        .datatype     = op_data-&gt;op_param.send.datatype,</span><br><span class="line">        .request      = req</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ucp_tag_send_nb和ucp_tag_send_nbx可能是一样的，因为手册里没有找到ucp_tag_send_nbx，所以可能是不同版本</span></span><br><span class="line">    <span class="comment">// 此例程将由本地地址缓冲区、大小计数和数据类型对象描述的消息发送到目标端点 ep。</span></span><br><span class="line">    <span class="comment">// 每条消息都与一个标签值相关联，该标签值用于在接收器上进行消息匹配。 </span></span><br><span class="line">    <span class="comment">// 该例程是非阻塞的，因此会立即返回，但是实际的发送操作可能会延迟。 当可以安全地重用源缓冲区时，发送操作被认为已完成。</span></span><br><span class="line">    <span class="comment">// 如果发送操作立即完成，则例程返回 UCS_OK 并且不调用回调函数 cb。</span></span><br><span class="line">    <span class="comment">// 如果操作没有立即完成并且没有报告错误，那么 UCP 库将安排在发送操作完成时调用回调 cb。</span></span><br><span class="line">    <span class="comment">// 所以这里没有wait，而且检测到错误就返回了</span></span><br><span class="line"></span><br><span class="line">    req = ucp_tag_send_nbx(ep, buf,</span><br><span class="line">                           mca_pml_ucx_get_data_size(op_data, count),</span><br><span class="line">                           tag, &amp;param);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(req == UCS_OK)) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (UCS_PTR_IS_ERR(req)) &#123;</span><br><span class="line">        PML_UCX_ERROR(<span class="string">"%s failed: %d, %s"</span>, __func__, UCS_PTR_STATUS(req),</span><br><span class="line">                      ucs_status_string(UCS_PTR_STATUS(req)));</span><br><span class="line">        <span class="keyword">return</span> OPAL_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    <span class="keyword">ucs_status_t</span> status;</span><br><span class="line">    status = ucp_tag_send_nbr(ep, buf, count,</span><br><span class="line">                              mca_pml_ucx_get_datatype(datatype), tag, req);</span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(status == UCS_OK)) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* 此例程提供了一种方便且有效的方式来实现阻塞发送模式。它还比 ucp_tag_send_nbr() 更快地完成请求，因为：</span></span><br><span class="line"><span class="comment">     * 它总是使用 uct_ep_am_bcopy() 将数据发送到集合阈值。</span></span><br><span class="line"><span class="comment">     * 它的集合阈值高于 ucp_tag_send_nb() 使用的阈值。阈值由 UCX_SEND_NBR_RNDV_THRESH 环境变量控制。</span></span><br><span class="line"><span class="comment">     * 它的请求处理更简单。没有回调，也不需要分配和释放请求。事实上，请求可以由调用者在堆栈上分配。</span></span><br><span class="line"><span class="comment">     * 此例程将由本地地址缓冲区、大小计数和数据类型对象描述的消息发送到目标端点 ep。每条消息都与一个标签值相关联，该标签值用于在接收器上进行消息匹配。</span></span><br><span class="line"><span class="comment">     * 该例程是非阻塞的，因此会立即返回，但是实际的发送操作可能会延迟。当可以安全地重用源缓冲区时，发送操作被认为已完成。如果发送操作立即完成，则例程返回 UCS_OK。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">     * 如果操作没有立即完成并且没有报告错误，那么 UCP 库将填充用户提供的请求并返回 UCS_INPROGRESS 状态。为了监控操作的完成，应该使用 ucp_request_check_status()。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    MCA_COMMON_UCX_WAIT_LOOP(req, ompi_pml_ucx.ucp_worker, <span class="string">"ucx send nbr"</span>, (<span class="keyword">void</span>)<span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure></p>
<p>实现send的其中一个阻塞函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">inline</span> __opal_attribute_always_inline__ <span class="keyword">int</span></span><br><span class="line">mca_pml_ucx_send_nb(ucp_ep_h ep, <span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count,</span><br><span class="line">                    <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">ucp_datatype_t</span> ucx_datatype,</span><br><span class="line">                    <span class="keyword">ucp_tag_t</span> tag, <span class="keyword">mca_pml_base_send_mode_t</span> mode)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">ompi_request_t</span> *req;</span><br><span class="line"></span><br><span class="line">    req = (<span class="keyword">ompi_request_t</span>*)mca_pml_ucx_common_send(ep, buf, count, datatype,</span><br><span class="line">                                                   mca_pml_ucx_get_datatype(datatype),</span><br><span class="line">                                                   tag, mode,</span><br><span class="line">                                                   mca_pml_ucx_send_completion_empty);</span><br><span class="line">    <span class="comment">// 应该是发送完之后一直等待，直到结束，因为有wait loop</span></span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(req == <span class="literal">NULL</span>)) &#123;</span><br><span class="line">        <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!UCS_PTR_IS_ERR(req)) &#123;</span><br><span class="line">        PML_UCX_VERBOSE(<span class="number">8</span>, <span class="string">"got request %p"</span>, (<span class="keyword">void</span>*)req);</span><br><span class="line">        MCA_COMMON_UCX_WAIT_LOOP(req, ompi_pml_ucx.ucp_worker, <span class="string">"ucx send"</span>, ucp_request_free(req));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        PML_UCX_ERROR(<span class="string">"ucx send failed: %s"</span>, ucs_status_string(UCS_PTR_STATUS(req)));</span><br><span class="line">        <span class="keyword">return</span> OMPI_ERROR;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>mca_pml_ucx_common_send根据mode调用三种函数：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> ucs_status_ptr_t <span class="title">mca_pml_ucx_common_send</span><span class="params">(ucp_ep_h ep, <span class="keyword">const</span> <span class="keyword">void</span> *buf,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">size_t</span> count,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">ompi_datatype_t</span> *datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">ucp_datatype_t</span> ucx_datatype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">ucp_tag_t</span> tag,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">mca_pml_base_send_mode_t</span> mode,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                       <span class="keyword">ucp_send_callback_t</span> cb)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(MCA_PML_BASE_SEND_BUFFERED == mode)) &#123;</span><br><span class="line">        <span class="keyword">return</span> mca_pml_ucx_bsend(ep, buf, count, datatype, tag);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (OPAL_UNLIKELY(MCA_PML_BASE_SEND_SYNCHRONOUS == mode)) &#123;</span><br><span class="line">        <span class="keyword">return</span> ucp_tag_send_sync_nb(ep, buf, count, ucx_datatype, tag, cb);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ucp_tag_send_nb(ep, buf, count, ucx_datatype, tag, cb);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ucp_tag_send_nb将由本地地址缓冲区、大小计数和数据类型对象描述的消息发送到目标端点 ep。 </span></span><br><span class="line">    <span class="comment">// 每条消息都与一个标签值相关联，该标签值用于在接收器上进行消息匹配。</span></span><br><span class="line">    <span class="comment">// 该例程是非阻塞的，因此会立即返回，但是实际的发送操作可能会延迟。</span></span><br><span class="line">    <span class="comment">// 当可以安全地重用源缓冲区时，发送操作被认为已完成。 如果发送操作立即完成，则例程返回 UCS_OK 并且不调用回调函数 cb。</span></span><br><span class="line">    <span class="comment">// 如果操作没有立即完成并且没有报告错误，那么 UCP 库将安排在发送操作完成时调用回调 cb。 换句话说，消息的完成可以通过返回码或回调来表示。</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// ucp_tag_send_sync_nb 与 ucp_tag_send_nb 相同，除了请求仅在消息上存在远程标记匹配后完成（这并不总是意味着远程接收已完成）。</span></span><br><span class="line">    <span class="comment">// 这个函数永远不会“就地”完成，并且总是返回一个请求句柄。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">ucs_status_ptr_t</span></span><br><span class="line">mca_pml_ucx_bsend(ucp_ep_h ep, <span class="keyword">const</span> <span class="keyword">void</span> *buf, <span class="keyword">size_t</span> count,</span><br><span class="line">                  <span class="keyword">ompi_datatype_t</span> *datatype, <span class="keyword">uint64_t</span> pml_tag)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">ompi_request_t</span> *req;</span><br><span class="line">    <span class="keyword">void</span> *packed_data;</span><br><span class="line">    <span class="keyword">size_t</span> packed_length;</span><br><span class="line">    <span class="keyword">size_t</span> offset;</span><br><span class="line">    <span class="keyword">uint32_t</span> iov_count;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">iovec</span> <span class="title">iov</span>;</span></span><br><span class="line">    <span class="keyword">opal_convertor_t</span> opal_conv;</span><br><span class="line"></span><br><span class="line">    OBJ_CONSTRUCT(&amp;opal_conv, <span class="keyword">opal_convertor_t</span>);</span><br><span class="line">    opal_convertor_copy_and_prepare_for_send(ompi_proc_local_proc-&gt;super.proc_convertor,</span><br><span class="line">                                             &amp;datatype-&gt;super, count, buf, <span class="number">0</span>,</span><br><span class="line">                                             &amp;opal_conv);</span><br><span class="line">    <span class="comment">// 设置convertor的fAdvance</span></span><br><span class="line"></span><br><span class="line">    opal_convertor_get_packed_size(&amp;opal_conv, &amp;packed_length);</span><br><span class="line"></span><br><span class="line">    packed_data = mca_pml_base_bsend_request_alloc_buf(packed_length);</span><br><span class="line">    <span class="comment">// 分配空间</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(<span class="literal">NULL</span> == packed_data)) &#123;</span><br><span class="line">        OBJ_DESTRUCT(&amp;opal_conv);</span><br><span class="line">        PML_UCX_ERROR(<span class="string">"bsend: failed to allocate buffer"</span>);</span><br><span class="line">        <span class="keyword">return</span> UCS_STATUS_PTR(OMPI_ERROR);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    iov_count    = <span class="number">1</span>;</span><br><span class="line">    iov.iov_base = packed_data;</span><br><span class="line">    iov.iov_len  = packed_length;</span><br><span class="line"></span><br><span class="line">    PML_UCX_VERBOSE(<span class="number">8</span>, <span class="string">"bsend of packed buffer %p len %zu"</span>, packed_data, packed_length);</span><br><span class="line">    offset = <span class="number">0</span>;</span><br><span class="line">    opal_convertor_set_position(&amp;opal_conv, &amp;offset);</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> &gt; opal_convertor_pack(&amp;opal_conv, &amp;iov, &amp;iov_count, &amp;packed_length)) &#123;</span><br><span class="line">        <span class="comment">// 获取到指针后使用memcpy</span></span><br><span class="line">        mca_pml_base_bsend_request_free(packed_data); <span class="comment">// 释放request</span></span><br><span class="line">        OBJ_DESTRUCT(&amp;opal_conv);</span><br><span class="line">        PML_UCX_ERROR(<span class="string">"bsend: failed to pack user datatype"</span>);</span><br><span class="line">        <span class="keyword">return</span> UCS_STATUS_PTR(OMPI_ERROR);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OBJ_DESTRUCT(&amp;opal_conv);</span><br><span class="line"></span><br><span class="line">    req = (<span class="keyword">ompi_request_t</span>*)ucp_tag_send_nb(ep, packed_data, packed_length,</span><br><span class="line">                                           ucp_dt_make_contig(<span class="number">1</span>), pml_tag,</span><br><span class="line">                                           mca_pml_ucx_bsend_completion);</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> == req) &#123;</span><br><span class="line">        <span class="comment">/* request was completed in place */</span></span><br><span class="line">        mca_pml_base_bsend_request_free(packed_data);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_UNLIKELY(UCS_PTR_IS_ERR(req))) &#123;</span><br><span class="line">        mca_pml_base_bsend_request_free(packed_data);</span><br><span class="line">        PML_UCX_ERROR(<span class="string">"ucx bsend failed: %s"</span>, ucs_status_string(UCS_PTR_STATUS(req)));</span><br><span class="line">        <span class="keyword">return</span> UCS_STATUS_PTR(OMPI_ERROR);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    req-&gt;req_complete_cb_data = packed_data;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="convertor"><a href="#convertor" class="headerlink" title="convertor"></a>convertor</h1><p>多次看到，可能是在不同架构下进行传输的转换器</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">opal_convertor_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">opal_object_t</span> super; <span class="comment">/**&lt; basic superclass */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> remoteArch; <span class="comment">/**&lt; the remote architecture */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> flags;      <span class="comment">/**&lt; the properties of this convertor */</span></span><br><span class="line">    <span class="keyword">size_t</span> local_size;   <span class="comment">/**&lt; overall length data on local machine, compared to bConverted */</span></span><br><span class="line">    <span class="keyword">size_t</span> remote_size;  <span class="comment">/**&lt; overall length data on remote machine, compared to bConverted */</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">opal_datatype_t</span> *pDesc;   <span class="comment">/**&lt; the datatype description associated with the convertor */</span></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">dt_type_desc_t</span> *use_desc; <span class="comment">/**&lt; the version used by the convertor (normal or optimized) */</span></span><br><span class="line">    <span class="keyword">opal_datatype_count_t</span> count;    <span class="comment">/**&lt; the total number of full datatype elements */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* --- cacheline boundary (64 bytes - if 64bits arch and !OPAL_ENABLE_DEBUG) --- */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> stack_size;              <span class="comment">/**&lt; size of the allocated stack */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *pBaseBuf;          <span class="comment">/**&lt; initial buffer as supplied by the user */</span></span><br><span class="line">    <span class="keyword">dt_stack_t</span> *pStack;               <span class="comment">/**&lt; the local stack for the actual conversion */</span></span><br><span class="line">    <span class="keyword">convertor_advance_fct_t</span> fAdvance; <span class="comment">/**&lt; pointer to the pack/unpack functions */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* --- cacheline boundary (96 bytes - if 64bits arch and !OPAL_ENABLE_DEBUG) --- */</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">opal_convertor_master_t</span> *<span class="title">master</span>;</span> <span class="comment">/**&lt; the master convertor */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* All others fields get modified for every call to pack/unpack functions */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> stack_pos;    <span class="comment">/**&lt; the actual position on the stack */</span></span><br><span class="line">    <span class="keyword">size_t</span> partial_length; <span class="comment">/**&lt; amount of data left over from the last unpack */</span></span><br><span class="line">    <span class="keyword">size_t</span> bConverted;     <span class="comment">/**&lt; # of bytes already converted */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* --- cacheline boundary (128 bytes - if 64bits arch and !OPAL_ENABLE_DEBUG) --- */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> checksum; <span class="comment">/**&lt; checksum computed by pack/unpack operation */</span></span><br><span class="line">    <span class="keyword">uint32_t</span> csum_ui1; <span class="comment">/**&lt; partial checksum computed by pack/unpack operation */</span></span><br><span class="line">    <span class="keyword">size_t</span> csum_ui2;   <span class="comment">/**&lt; partial checksum computed by pack/unpack operation */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* --- fields are no more aligned on cacheline --- */</span></span><br><span class="line">    <span class="keyword">dt_stack_t</span> static_stack[DT_STATIC_STACK_SIZE]; <span class="comment">/**&lt; local stack for small datatypes */</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_CUDA_SUPPORT</span></span><br><span class="line">    <span class="keyword">memcpy_fct_t</span> cbmemcpy; <span class="comment">/**&lt; memcpy or cuMemcpy */</span></span><br><span class="line">    <span class="keyword">void</span> *stream;          <span class="comment">/**&lt; CUstream for async copy */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>这是pack和unpack，应该是用于通信的时候数据压缩的：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return 0 if everything went OK and if there is still room before the complete</span></span><br><span class="line"><span class="comment"> *          conversion of the data (need additional call with others input buffers )</span></span><br><span class="line"><span class="comment"> *        1 if everything went fine and the data was completly converted</span></span><br><span class="line"><span class="comment"> *       -1 something wrong occurs.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int32_t</span> opal_convertor_pack(<span class="keyword">opal_convertor_t</span> *pConv, struct iovec *iov, <span class="keyword">uint32_t</span> *out_size,</span><br><span class="line">                            <span class="keyword">size_t</span> *max_data)</span><br><span class="line">&#123;</span><br><span class="line">    OPAL_CONVERTOR_SET_STATUS_BEFORE_PACK_UNPACK(pConv, iov, out_size, max_data);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(pConv-&gt;flags &amp; CONVERTOR_NO_OP)) &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * We are doing conversion on a contiguous datatype on a homogeneous</span></span><br><span class="line"><span class="comment">         * environment. The convertor contain minimal information, we only</span></span><br><span class="line"><span class="comment">         * use the bConverted to manage the conversion.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">uint32_t</span> i;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">char</span> *base_pointer;</span><br><span class="line">        <span class="keyword">size_t</span> pending_length = pConv-&gt;local_size - pConv-&gt;bConverted;</span><br><span class="line"></span><br><span class="line">        *max_data = pending_length;</span><br><span class="line">        opal_convertor_get_current_pointer(pConv, (<span class="keyword">void</span> **) &amp;base_pointer);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; *out_size; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (iov[i].iov_len &gt;= pending_length) &#123;</span><br><span class="line">                <span class="keyword">goto</span> complete_contiguous_data_pack;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (OPAL_LIKELY(<span class="literal">NULL</span> == iov[i].iov_base)) &#123;</span><br><span class="line">                iov[i].iov_base = (IOVBASE_TYPE *) base_pointer;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">#<span class="keyword">if</span> OPAL_CUDA_SUPPORT</span><br><span class="line">                MEMCPY_CUDA(iov[i].iov_base, base_pointer, iov[i].iov_len, pConv);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">                MEMCPY(iov[i].iov_base, base_pointer, iov[i].iov_len);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">            &#125;</span><br><span class="line">            pending_length -= iov[i].iov_len;</span><br><span class="line">            base_pointer += iov[i].iov_len;</span><br><span class="line">        &#125;</span><br><span class="line">        *max_data -= pending_length;</span><br><span class="line">        pConv-&gt;bConverted += (*max_data);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">complete_contiguous_data_pack:</span><br><span class="line">        iov[i].iov_len = pending_length;</span><br><span class="line">        <span class="keyword">if</span> (OPAL_LIKELY(<span class="literal">NULL</span> == iov[i].iov_base)) &#123;</span><br><span class="line">            iov[i].iov_base = (IOVBASE_TYPE *) base_pointer;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">#<span class="keyword">if</span> OPAL_CUDA_SUPPORT</span><br><span class="line">            MEMCPY_CUDA(iov[i].iov_base, base_pointer, iov[i].iov_len, pConv);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">            MEMCPY(iov[i].iov_base, base_pointer, iov[i].iov_len);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">        &#125;</span><br><span class="line">        pConv-&gt;bConverted = pConv-&gt;local_size;</span><br><span class="line">        *out_size = i + <span class="number">1</span>;</span><br><span class="line">        pConv-&gt;flags |= CONVERTOR_COMPLETED;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pConv-&gt;fAdvance(pConv, iov, out_size, max_data);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int32_t</span> opal_convertor_unpack(<span class="keyword">opal_convertor_t</span> *pConv, struct iovec *iov, <span class="keyword">uint32_t</span> *out_size,</span><br><span class="line">                              <span class="keyword">size_t</span> *max_data)</span><br><span class="line">&#123;</span><br><span class="line">    OPAL_CONVERTOR_SET_STATUS_BEFORE_PACK_UNPACK(pConv, iov, out_size, max_data);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (OPAL_LIKELY(pConv-&gt;flags &amp; CONVERTOR_NO_OP)) &#123;</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 我们正在同构环境中对连续数据类型进行转换。 转换器包含最少的信息，我们只使用 bConverted 来管理转换。</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="keyword">uint32_t</span> i;</span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">char</span> *base_pointer;</span><br><span class="line">        <span class="keyword">size_t</span> pending_length = pConv-&gt;local_size - pConv-&gt;bConverted;</span><br><span class="line"></span><br><span class="line">        *max_data = pending_length;</span><br><span class="line">        opal_convertor_get_current_pointer(pConv, (<span class="keyword">void</span> **) &amp;base_pointer);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; *out_size; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (iov[i].iov_len &gt;= pending_length) &#123;</span><br><span class="line">                <span class="keyword">goto</span> complete_contiguous_data_unpack;</span><br><span class="line">            &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_CUDA_SUPPORT</span></span><br><span class="line">            MEMCPY_CUDA(base_pointer, iov[i].iov_base, iov[i].iov_len, pConv);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">            MEMCPY(base_pointer, iov[i].iov_base, iov[i].iov_len);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">            pending_length -= iov[i].iov_len;</span><br><span class="line">            base_pointer += iov[i].iov_len;</span><br><span class="line">        &#125;</span><br><span class="line">        *max_data -= pending_length;</span><br><span class="line">        pConv-&gt;bConverted += (*max_data);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    complete_contiguous_data_unpack:</span><br><span class="line">        iov[i].iov_len = pending_length;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_CUDA_SUPPORT</span></span><br><span class="line">        MEMCPY_CUDA(base_pointer, iov[i].iov_base, iov[i].iov_len, pConv);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">        MEMCPY(base_pointer, iov[i].iov_base, iov[i].iov_len);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">        pConv-&gt;bConverted = pConv-&gt;local_size;</span><br><span class="line">        *out_size = i + <span class="number">1</span>;</span><br><span class="line">        pConv-&gt;flags |= CONVERTOR_COMPLETED;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pConv-&gt;fAdvance(pConv, iov, out_size, max_data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>用于在执行通信的时候进行准备，主要是设置fAdvance这个函数，用在上边的pack和unpack里：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int32_t</span> opal_convertor_prepare_for_send(<span class="keyword">opal_convertor_t</span> *convertor,</span><br><span class="line">                                        <span class="keyword">const</span> struct <span class="keyword">opal_datatype_t</span> *datatype, <span class="keyword">size_t</span> count,</span><br><span class="line">                                        <span class="keyword">const</span> <span class="keyword">void</span> *pUserBuf)</span><br><span class="line">&#123;</span><br><span class="line">    convertor-&gt;flags |= CONVERTOR_SEND;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_CUDA_SUPPORT</span></span><br><span class="line">    <span class="keyword">if</span> (!(convertor-&gt;flags &amp; CONVERTOR_SKIP_CUDA_INIT)) &#123;</span><br><span class="line">        mca_cuda_convertor_init(convertor, pUserBuf);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    OPAL_CONVERTOR_PREPARE(convertor, datatype, count, pUserBuf);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CHECKSUM)</span></span><br><span class="line">    <span class="keyword">if</span> (convertor-&gt;flags &amp; CONVERTOR_WITH_CHECKSUM) &#123;</span><br><span class="line">        <span class="keyword">if</span> (CONVERTOR_SEND_CONVERSION</span><br><span class="line">            == (convertor-&gt;flags &amp; (CONVERTOR_SEND_CONVERSION | CONVERTOR_HOMOGENEOUS))) &#123;</span><br><span class="line">            convertor-&gt;fAdvance = opal_pack_general_checksum;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (datatype-&gt;flags &amp; OPAL_DATATYPE_FLAG_CONTIGUOUS) &#123;</span><br><span class="line">                <span class="keyword">if</span> (((datatype-&gt;ub - datatype-&gt;lb) == (<span class="keyword">ptrdiff_t</span>) datatype-&gt;size)</span><br><span class="line">                    || (<span class="number">1</span> &gt;= convertor-&gt;count)) &#123;</span><br><span class="line">                    convertor-&gt;fAdvance = opal_pack_homogeneous_contig_checksum; <span class="comment">// 都是计算checksum的函数，例如crc码</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    convertor-&gt;fAdvance = opal_pack_homogeneous_contig_with_gaps_checksum;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                convertor-&gt;fAdvance = opal_generic_simple_pack_checksum;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">#endif <span class="comment">/* defined(CHECKSUM) */</span></span><br><span class="line">        <span class="keyword">if</span> (CONVERTOR_SEND_CONVERSION</span><br><span class="line">            == (convertor-&gt;flags &amp; (CONVERTOR_SEND_CONVERSION | CONVERTOR_HOMOGENEOUS))) &#123;</span><br><span class="line">            convertor-&gt;fAdvance = opal_pack_general;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (datatype-&gt;flags &amp; OPAL_DATATYPE_FLAG_CONTIGUOUS) &#123;</span><br><span class="line">                <span class="keyword">if</span> (((datatype-&gt;ub - datatype-&gt;lb) == (<span class="keyword">ptrdiff_t</span>) datatype-&gt;size)</span><br><span class="line">                    || (<span class="number">1</span> &gt;= convertor-&gt;count)) &#123;</span><br><span class="line">                    convertor-&gt;fAdvance = opal_pack_homogeneous_contig;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    convertor-&gt;fAdvance = opal_pack_homogeneous_contig_with_gaps;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                convertor-&gt;fAdvance = opal_generic_simple_pack;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(CHECKSUM)</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">return</span> OPAL_SUCCESS;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Recv"><a href="#MPI-Recv" class="headerlink" title="MPI_Recv"></a>MPI_Recv</h1><p>recv和send类似，最后都是调用<code>pml_recv</code>，<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Recv</span><span class="params">(<span class="keyword">void</span> *buf, <span class="keyword">int</span> count, MPI_Datatype type, <span class="keyword">int</span> source,</span></span></span><br><span class="line"><span class="function"><span class="params">             <span class="keyword">int</span> tag, MPI_Comm comm, MPI_Status *status)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rc = MPI_SUCCESS;</span><br><span class="line"></span><br><span class="line">    SPC_RECORD(OMPI_SPC_RECV, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    MEMCHECKER(</span><br><span class="line">        memchecker_datatype(type);</span><br><span class="line">        memchecker_call(&amp;opal_memchecker_base_isaddressable, buf, count, type);</span><br><span class="line">        memchecker_comm(comm);</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ( MPI_PARAM_CHECK ) &#123;</span><br><span class="line">        OMPI_ERR_INIT_FINALIZE(FUNC_NAME);</span><br><span class="line">        OMPI_CHECK_DATATYPE_FOR_RECV(rc, type, count);</span><br><span class="line">        OMPI_CHECK_USER_BUFFER(rc, buf, type, count);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (ompi_comm_invalid(comm)) &#123;</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERRHANDLER_NOHANDLE_INVOKE(MPI_ERR_COMM, FUNC_NAME);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (((tag &lt; <span class="number">0</span>) &amp;&amp; (tag != MPI_ANY_TAG)) || (tag &gt; mca_pml.pml_max_tag)) &#123;</span><br><span class="line">            rc = MPI_ERR_TAG;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((source != MPI_ANY_SOURCE) &amp;&amp;</span><br><span class="line">                   (MPI_PROC_NULL != source) &amp;&amp;</span><br><span class="line">                   ompi_comm_peer_invalid(comm, source)) &#123;</span><br><span class="line">            rc = MPI_ERR_RANK;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        OMPI_ERRHANDLER_CHECK(rc, comm, rc, FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// fault tolerance ......</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_PROC_NULL == source) &#123;</span><br><span class="line">        <span class="keyword">if</span> (MPI_STATUS_IGNORE != status) &#123;</span><br><span class="line">            OMPI_COPY_STATUS(status, ompi_request_empty.req_status, <span class="literal">false</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    rc = MCA_PML_CALL(recv(buf, count, type, source, tag, comm, status));</span><br><span class="line">    OMPI_ERRHANDLER_RETURN(rc, comm, rc, FUNC_NAME);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>pml_recv</code>主要有以下几个：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mca_pml_cm_recv</span><br><span class="line">mca_pml_ob1_recv</span><br><span class="line">mca_pml_ucx_recv</span><br><span class="line">mca_spml_ucx_recv</span><br><span class="line">mca_pml_monitoring_recv</span><br></pre></td></tr></table></figure></p>
<p>主要还是跟<code>mca_pml_cm_recv</code>。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">__opal_attribute_always_inline__ <span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">int</span></span><br><span class="line">mca_pml_cm_recv(<span class="keyword">void</span> *addr,</span><br><span class="line">                <span class="keyword">size_t</span> count,</span><br><span class="line">                <span class="keyword">ompi_datatype_t</span> * datatype,</span><br><span class="line">                <span class="keyword">int</span> src,</span><br><span class="line">                <span class="keyword">int</span> tag,</span><br><span class="line">                struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                <span class="keyword">ompi_status_public_t</span> * status)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> ret;</span><br><span class="line">    <span class="keyword">uint32_t</span> flags = <span class="number">0</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_HETEROGENEOUS_SUPPORT</span></span><br><span class="line">    <span class="keyword">ompi_proc_t</span> *ompi_proc;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line">    <span class="keyword">opal_convertor_t</span> convertor;</span><br><span class="line">    <span class="keyword">mca_pml_cm_request_t</span> req;</span><br><span class="line">    <span class="keyword">mca_mtl_request_t</span> *req_mtl = alloca(<span class="keyword">sizeof</span>(<span class="keyword">mca_mtl_request_t</span>) + ompi_mtl-&gt;mtl_request_size);</span><br><span class="line"></span><br><span class="line">    OBJ_CONSTRUCT(&amp;convertor, <span class="keyword">opal_convertor_t</span>);</span><br><span class="line">    req_mtl-&gt;ompi_req = &amp;req.req_ompi;</span><br><span class="line">    req_mtl-&gt;completion_callback = mca_pml_cm_recv_fast_completion;</span><br><span class="line"></span><br><span class="line">    req.req_pml_type = MCA_PML_CM_REQUEST_RECV_THIN;</span><br><span class="line">    req.req_free_called = <span class="literal">false</span>;</span><br><span class="line">    req.req_ompi.req_complete = <span class="literal">false</span>;</span><br><span class="line">    req.req_ompi.req_complete_cb = <span class="literal">NULL</span>;</span><br><span class="line">    req.req_ompi.req_state = OMPI_REQUEST_ACTIVE;</span><br><span class="line">    req.req_ompi.req_status.MPI_TAG = OMPI_ANY_TAG;</span><br><span class="line">    req.req_ompi.req_status.MPI_ERROR = OMPI_SUCCESS;</span><br><span class="line">    req.req_ompi.req_status._cancelled = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> OPAL_ENABLE_HETEROGENEOUS_SUPPORT</span></span><br><span class="line">    <span class="keyword">if</span>( MPI_ANY_SOURCE == src ) &#123;</span><br><span class="line">        ompi_proc = ompi_proc_local_proc;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        ompi_proc = ompi_comm_peer_lookup( comm, src );</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    MCA_PML_CM_SWITCH_CUDA_CONVERTOR_OFF(flags, datatype, count);</span><br><span class="line"></span><br><span class="line">    opal_convertor_copy_and_prepare_for_recv(</span><br><span class="line">	ompi_proc-&gt;super.proc_convertor,</span><br><span class="line">		&amp;(datatype-&gt;super),</span><br><span class="line">		count,</span><br><span class="line">		addr,</span><br><span class="line">                flags,</span><br><span class="line">		&amp;convertor );</span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line">    MCA_PML_CM_SWITCH_CUDA_CONVERTOR_OFF(flags, datatype, count);</span><br><span class="line"></span><br><span class="line">    opal_convertor_copy_and_prepare_for_recv(</span><br><span class="line">	ompi_mpi_local_convertor,</span><br><span class="line">		&amp;(datatype-&gt;super),</span><br><span class="line">		count,</span><br><span class="line">		addr,</span><br><span class="line">                flags,</span><br><span class="line">		&amp;convertor );</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">    ret = OMPI_MTL_CALL(irecv(ompi_mtl,</span><br><span class="line">                              comm,</span><br><span class="line">                              src,</span><br><span class="line">                              tag,</span><br><span class="line">                              &amp;convertor,</span><br><span class="line">                              req_mtl));</span><br><span class="line">    <span class="keyword">if</span>( OPAL_UNLIKELY(OMPI_SUCCESS != ret) ) &#123;</span><br><span class="line">	OBJ_DESTRUCT(&amp;convertor);</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ompi_request_wait_completion(&amp;req.req_ompi);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_STATUS_IGNORE != status) &#123;</span><br><span class="line">        OMPI_COPY_STATUS(status, req.req_ompi.req_status, <span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    ret = req.req_ompi.req_status.MPI_ERROR;</span><br><span class="line">    OBJ_DESTRUCT(&amp;convertor);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Allgather"><a href="#MPI-Allgather" class="headerlink" title="MPI_Allgather"></a>MPI_Allgather</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Allgather</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sendbuf, <span class="keyword">int</span> sendcount, MPI_Datatype sendtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">void</span> *recvbuf, <span class="keyword">int</span> recvcount, MPI_Datatype recvtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                  MPI_Comm comm)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line"></span><br><span class="line">    SPC_RECORD(OMPI_SPC_ALLGATHER, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    MEMCHECKER(</span><br><span class="line">        <span class="keyword">int</span> rank;</span><br><span class="line">        <span class="keyword">ptrdiff_t</span> ext;</span><br><span class="line"></span><br><span class="line">        rank = ompi_comm_rank(comm);</span><br><span class="line">        ompi_datatype_type_extent(recvtype, &amp;ext);</span><br><span class="line"></span><br><span class="line">        memchecker_datatype(recvtype);</span><br><span class="line">        memchecker_comm(comm);</span><br><span class="line">        <span class="comment">/* 检查发送缓冲区是否合法. */</span></span><br><span class="line">        <span class="keyword">if</span> (MPI_IN_PLACE == sendbuf) &#123;</span><br><span class="line">            memchecker_call(&amp;opal_memchecker_base_isdefined,</span><br><span class="line">                            (<span class="keyword">char</span> *)(recvbuf)+rank*recvcount*ext,</span><br><span class="line">                            recvcount, recvtype);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            memchecker_datatype(sendtype);</span><br><span class="line">            memchecker_call(&amp;opal_memchecker_base_isdefined, sendbuf, sendcount, sendtype);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">/* check whether the receive buffer is addressable. */</span></span><br><span class="line">        memchecker_call(&amp;opal_memchecker_base_isaddressable, recvbuf, recvcount, recvtype);</span><br><span class="line">    );</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_PARAM_CHECK) &#123;</span><br><span class="line">        err = MPI_SUCCESS;</span><br><span class="line">        OMPI_ERR_INIT_FINALIZE(FUNC_NAME);</span><br><span class="line">        <span class="keyword">if</span> (ompi_comm_invalid(comm)) &#123;</span><br><span class="line">          OMPI_ERRHANDLER_NOHANDLE_INVOKE(MPI_ERR_COMM, FUNC_NAME);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (MPI_DATATYPE_NULL == recvtype || <span class="literal">NULL</span> == recvtype) &#123;</span><br><span class="line">          err = MPI_ERR_TYPE;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (recvcount &lt; <span class="number">0</span>) &#123;</span><br><span class="line">          err = MPI_ERR_COUNT;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((MPI_IN_PLACE == sendbuf &amp;&amp; OMPI_COMM_IS_INTER(comm)) ||</span><br><span class="line">                   MPI_IN_PLACE == recvbuf) &#123;</span><br><span class="line">          <span class="keyword">return</span> OMPI_ERRHANDLER_INVOKE(comm, MPI_ERR_ARG, FUNC_NAME);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (MPI_IN_PLACE != sendbuf) &#123;</span><br><span class="line">            OMPI_CHECK_DATATYPE_FOR_SEND(err, sendtype, sendcount);</span><br><span class="line">        &#125;</span><br><span class="line">        OMPI_ERRHANDLER_CHECK(err, comm, err, FUNC_NAME);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 每个进程都必须给出相同的发送签名，这意味着如果有任何东西要发送用于内部通信器案例，每个人都必须给出一个 sendcount &gt; 0。</span></span><br><span class="line"><span class="comment">     * 但是，如果我们正在执行 IN_PLACE，请检查 recvcount，而不是 sendcount。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> ( OMPI_COMM_IS_INTRA(comm) ) &#123;</span><br><span class="line">       <span class="keyword">if</span> ((MPI_IN_PLACE != sendbuf &amp;&amp; <span class="number">0</span> == sendcount) ||</span><br><span class="line">            (<span class="number">0</span> == recvcount)) &#123;</span><br><span class="line">            <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">	   &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> ( OMPI_COMM_IS_INTER(comm) )&#123;</span><br><span class="line">        <span class="comment">/* 对于inter的通信器，通信模式不必是对称的。 具体来说，一组允许 sendcount=0，而另一组有一个有效的 sendcount。 因此，不做任何事情的唯一方法是如果 sendcount 和 recvcount 都为零 */</span></span><br><span class="line">	    <span class="keyword">if</span> ( <span class="number">0</span> == sendcount &amp;&amp; <span class="number">0</span> == recvcount ) &#123;</span><br><span class="line">	        <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">	    &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Invoke the coll component to perform the back-end operation */</span></span><br><span class="line"></span><br><span class="line">    err = comm-&gt;c_coll-&gt;coll_allgather(sendbuf, sendcount, sendtype,</span><br><span class="line">                                      recvbuf, recvcount, recvtype, comm,</span><br><span class="line">                                      comm-&gt;c_coll-&gt;coll_allgather_module);</span><br><span class="line">    OMPI_ERRHANDLER_RETURN(err, comm, err, FUNC_NAME);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>coll_allgather</code>有如下几个实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mca_coll_basic_allgather_inter</span><br><span class="line">ompi_coll_base_allgather_intra_basic_linear</span><br><span class="line">mca_coll_demo_allgather_intra</span><br><span class="line">mca_coll_demo_allgather_inter</span><br><span class="line">mca_coll_self_allgather_intra</span><br></pre></td></tr></table></figure></p>
<p><code>mca_coll_basic_allgather_inter</code>实现，应该是在两个域之间实现的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">mca_coll_basic_allgather_inter</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span></span></span><br><span class="line"><span class="function"><span class="params">                               struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                               <span class="keyword">void</span> *rbuf, <span class="keyword">int</span> rcount,</span></span></span><br><span class="line"><span class="function"><span class="params">                               struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                               struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                               <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> rank, root = <span class="number">0</span>, size, rsize, err, i, line;</span><br><span class="line">    <span class="keyword">char</span> *tmpbuf_free = <span class="literal">NULL</span>, *tmpbuf, *ptmp;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rextent, incr;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> gap, span;</span><br><span class="line">    <span class="keyword">ompi_request_t</span> *req;</span><br><span class="line">    <span class="keyword">ompi_request_t</span> **reqs = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    rsize = ompi_comm_remote_size(comm);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Algorithm:</span></span><br><span class="line"><span class="comment">     * - gather操作，聚集到远程组中的根（同时执行，这就是我们不能使用 coll_gather 的原因）。</span></span><br><span class="line"><span class="comment">     * - 在两个根之间交换温度结果</span></span><br><span class="line"><span class="comment">     * - 进程间广播（再次同时）。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Step one: gather operations: */</span></span><br><span class="line">    <span class="keyword">if</span> (rank != root) &#123;</span><br><span class="line">        <span class="comment">/* 把自己的数据发送给根进程 */</span></span><br><span class="line">        err = MCA_PML_CALL(send(sbuf, scount, sdtype, root,</span><br><span class="line">                                MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* receive a msg. from all other procs. */</span></span><br><span class="line">        err = ompi_datatype_get_extent(rdtype, &amp;rlb, &amp;rextent);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 初始化request数组 */</span></span><br><span class="line">        reqs = ompi_coll_base_comm_get_reqs(<span class="keyword">module</span>-&gt;base_data, rsize + <span class="number">1</span>);</span><br><span class="line">        <span class="keyword">if</span>( <span class="literal">NULL</span> == reqs ) &#123; line = __LINE__; err = OMPI_ERR_OUT_OF_RESOURCE; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 使用非阻塞通信实现两个根进程之间的交换 */</span></span><br><span class="line">        err = MCA_PML_CALL(isend(sbuf, scount, sdtype, <span class="number">0</span>,</span><br><span class="line">                                 MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                 MCA_PML_BASE_SEND_STANDARD,</span><br><span class="line">                                 comm, &amp;reqs[rsize]));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        err = MCA_PML_CALL(irecv(rbuf, rcount, rdtype, <span class="number">0</span>,</span><br><span class="line">                                 MCA_COLL_BASE_TAG_ALLGATHER, comm,</span><br><span class="line">                                 &amp;reqs[<span class="number">0</span>]));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 接收非根节点的信息 */</span></span><br><span class="line">        incr = rextent * rcount;</span><br><span class="line">        ptmp = (<span class="keyword">char</span> *) rbuf + incr;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; rsize; ++i, ptmp += incr) &#123;</span><br><span class="line">            err = MCA_PML_CALL(irecv(ptmp, rcount, rdtype, i,</span><br><span class="line">                                     MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                     comm, &amp;reqs[i]));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// wait，直到这个request结束，也是用while做</span></span><br><span class="line">        err = ompi_request_wait_all(rsize + <span class="number">1</span>, reqs, MPI_STATUSES_IGNORE);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Step 2: exchange the resuts between the root processes */</span></span><br><span class="line">        span = opal_datatype_span(&amp;sdtype-&gt;super, (<span class="keyword">int64_t</span>)scount * (<span class="keyword">int64_t</span>)size, &amp;gap);</span><br><span class="line">        tmpbuf_free = (<span class="keyword">char</span> *) <span class="built_in">malloc</span>(span);</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == tmpbuf_free) &#123; line = __LINE__; err = OMPI_ERR_OUT_OF_RESOURCE; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">        tmpbuf = tmpbuf_free - gap;</span><br><span class="line"></span><br><span class="line">        err = MCA_PML_CALL(isend(rbuf, rsize * rcount, rdtype, <span class="number">0</span>,</span><br><span class="line">                                 MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                 MCA_PML_BASE_SEND_STANDARD, comm, &amp;req));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        err = MCA_PML_CALL(recv(tmpbuf, size * scount, sdtype, <span class="number">0</span>,</span><br><span class="line">                                MCA_COLL_BASE_TAG_ALLGATHER, comm,</span><br><span class="line">                                MPI_STATUS_IGNORE));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">        err = ompi_request_wait( &amp;req, MPI_STATUS_IGNORE);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Step 3: 广播数据到远程组。 这在两个组中同时发生，因此我们不能使用 coll_bcast（这会死锁）。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (rank != root) &#123;</span><br><span class="line">        <span class="comment">/* post the recv */</span></span><br><span class="line">        err = MCA_PML_CALL(recv(rbuf, rsize * rcount, rdtype, <span class="number">0</span>,</span><br><span class="line">                                MCA_COLL_BASE_TAG_ALLGATHER, comm,</span><br><span class="line">                                MPI_STATUS_IGNORE));</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* Send the data to every other process in the remote group except to rank zero. which has it already. */</span></span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; rsize; i++) &#123;</span><br><span class="line">            err = MCA_PML_CALL(isend(tmpbuf, size * scount, sdtype, i,</span><br><span class="line">                                     MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                     MCA_PML_BASE_SEND_STANDARD,</span><br><span class="line">                                     comm, &amp;reqs[i - <span class="number">1</span>]));</span><br><span class="line">            <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        err = ompi_request_wait_all(rsize - <span class="number">1</span>, reqs, MPI_STATUSES_IGNORE);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> <span class="built_in">exit</span>; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">exit</span>:</span><br><span class="line">    <span class="keyword">if</span>( MPI_SUCCESS != err ) &#123;</span><br><span class="line">        OPAL_OUTPUT( (ompi_coll_base_framework.framework_output,<span class="string">"%s:%4d\tError occurred %d, rank %2d"</span>,</span><br><span class="line">                      __FILE__, line, err, rank) );</span><br><span class="line">        (<span class="keyword">void</span>)line;  <span class="comment">// silence compiler warning</span></span><br><span class="line">        <span class="keyword">if</span>( <span class="literal">NULL</span> != reqs ) ompi_coll_base_free_reqs(reqs, rsize+<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">NULL</span> != tmpbuf_free) &#123;</span><br><span class="line">        <span class="built_in">free</span>(tmpbuf_free);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>以下是几种allgather算法实现：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">allgather using O(log(N)) steps.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Bruck et al., "Efficient Algorithms for All-to-all Communications in Multiport Message-Passing Systems"</span></span><br><span class="line"><span class="comment"> * Memory requirements:  non-zero ranks require shift buffer to perform final</span></span><br><span class="line"><span class="comment"> *               step in the algorithm.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Example on 6 nodes:</span></span><br><span class="line"><span class="comment"> *   Initialization: 每个进程在 rbuf 的位置 0 处都有自己的缓冲区。 </span></span><br><span class="line"><span class="comment"> *                   这意味着如果用户为 sendbuf 指定了 MPI_IN_PLACE，</span></span><br><span class="line"><span class="comment"> *                   我们必须将我们的块从 recvbuf 复制到开始！</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [1]    [2]    [3]    [4]    [5]</span></span><br><span class="line"><span class="comment"> *   Step 0: 发给 (rank - 2^0), 从 (rank + 2^0) 接收</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [1]    [2]    [3]    [4]    [5]</span></span><br><span class="line"><span class="comment"> *         [1]    [2]    [3]    [4]    [5]    [0]</span></span><br><span class="line"><span class="comment"> *   Step 1: 发给 (rank - 2^1), 从 (rank + 2^1) 接收</span></span><br><span class="line"><span class="comment"> *           消息长度是从 0 到 2^1*block size，就是2倍的第一步</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [1]    [2]    [3]    [4]    [5]</span></span><br><span class="line"><span class="comment"> *         [1]    [2]    [3]    [4]    [5]    [0]</span></span><br><span class="line"><span class="comment"> *         [2]    [3]    [4]    [5]    [0]    [1]</span></span><br><span class="line"><span class="comment"> *         [3]    [4]    [5]    [0]    [1]    [2]</span></span><br><span class="line"><span class="comment"> *   Step 2: 发给 (rank - 2^2), 从 (rank + 2^2) 接收</span></span><br><span class="line"><span class="comment"> *           消息长度是剩下的所有块</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [1]    [2]    [3]    [4]    [5]</span></span><br><span class="line"><span class="comment"> *         [1]    [2]    [3]    [4]    [5]    [0]</span></span><br><span class="line"><span class="comment"> *         [2]    [3]    [4]    [5]    [0]    [1]</span></span><br><span class="line"><span class="comment"> *         [3]    [4]    [5]    [0]    [1]    [2]</span></span><br><span class="line"><span class="comment"> *         [4]    [5]    [0]    [1]    [2]    [3]</span></span><br><span class="line"><span class="comment"> *         [5]    [0]    [1]    [2]    [3]    [4]</span></span><br><span class="line"><span class="comment"> *    Finalization: 进行本地转移以在正确的位置获取数据</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [0]    [0]    [0]    [0]    [0]</span></span><br><span class="line"><span class="comment"> *         [1]    [1]    [1]    [1]    [1]    [1]</span></span><br><span class="line"><span class="comment"> *         [2]    [2]    [2]    [2]    [2]    [2]</span></span><br><span class="line"><span class="comment"> *         [3]    [3]    [3]    [3]    [3]    [3]</span></span><br><span class="line"><span class="comment"> *         [4]    [4]    [4]    [4]    [4]    [4]</span></span><br><span class="line"><span class="comment"> *         [5]    [5]    [5]    [5]    [5]    [5]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_allgather_intra_bruck</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                          <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>, rank, size, sendto, recvfrom, distance, blockcount, err = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rext;</span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"coll:base:allgather_intra_bruck rank %d"</span>, rank));</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent (rdtype, &amp;rlb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialization step:</span></span><br><span class="line"><span class="comment">       - if send buffer is not MPI_IN_PLACE, copy send buffer to block 0 of</span></span><br><span class="line"><span class="comment">       receive buffer, else</span></span><br><span class="line"><span class="comment">       - if rank r != 0, copy r^th block from receive buffer to block 0.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    tmprecv = (<span class="keyword">char</span>*) rbuf;</span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE != sbuf) &#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*) sbuf;</span><br><span class="line">        err = ompi_datatype_sndrcv(tmpsend, scount, sdtype, tmprecv, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="number">0</span> != rank) &#123;  <span class="comment">/* non root with MPI_IN_PLACE */</span></span><br><span class="line">        tmpsend = ((<span class="keyword">char</span>*)rbuf) + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        err = ompi_datatype_copy_content_same_ddt(rdtype, rcount, tmprecv, tmpsend);</span><br><span class="line">        <span class="keyword">if</span> (err &lt; <span class="number">0</span>) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Communication step:</span></span><br><span class="line"><span class="comment">       At every step i, rank r:</span></span><br><span class="line"><span class="comment">       - doubles the distance</span></span><br><span class="line"><span class="comment">       - sends message which starts at begining of rbuf and has size</span></span><br><span class="line"><span class="comment">       (blockcount * rcount) to rank (r - distance)</span></span><br><span class="line"><span class="comment">       - receives message of size blockcount * rcount from rank (r + distance)</span></span><br><span class="line"><span class="comment">       at location (rbuf + distance * rcount * rext)</span></span><br><span class="line"><span class="comment">       - blockcount doubles until last step when only the remaining data is</span></span><br><span class="line"><span class="comment">       exchanged.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    blockcount = <span class="number">1</span>;</span><br><span class="line">    tmpsend = (<span class="keyword">char</span>*) rbuf;</span><br><span class="line">    <span class="keyword">for</span> (distance = <span class="number">1</span>; distance &lt; size; distance&lt;&lt;=<span class="number">1</span>) &#123;</span><br><span class="line"></span><br><span class="line">        recvfrom = (rank + distance) % size;</span><br><span class="line">        sendto = (rank - distance + size) % size;</span><br><span class="line"></span><br><span class="line">        tmprecv = tmpsend + (<span class="keyword">ptrdiff_t</span>)distance * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (distance &lt;= (size &gt;&gt; <span class="number">1</span>)) &#123;</span><br><span class="line">            blockcount = distance;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            blockcount = size - distance;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Sendreceive</span></span><br><span class="line"><span class="comment">         * 如果是同一进程的话就是直接拷贝，否则执行recv-send-wait</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        err = ompi_coll_base_sendrecv(tmpsend, blockcount * rcount, rdtype,</span><br><span class="line">                                       sendto, MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       tmprecv, blockcount * rcount, rdtype,</span><br><span class="line">                                       recvfrom, MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Finalization step:</span></span><br><span class="line"><span class="comment">       除了0号进程, 重排数据:</span></span><br><span class="line"><span class="comment">       - 创建临时数组</span></span><br><span class="line"><span class="comment">       - copy blocks [0 .. (size - rank - 1)] from rbuf to shift buffer</span></span><br><span class="line"><span class="comment">       - move blocks [(size - rank) .. size] from rbuf to begining of rbuf</span></span><br><span class="line"><span class="comment">       - copy blocks from shift buffer starting at block [rank] in rbuf.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> != rank) &#123;</span><br><span class="line">        <span class="keyword">char</span> *free_buf = <span class="literal">NULL</span>, *shift_buf = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">ptrdiff_t</span> span, gap = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        span = opal_datatype_span(&amp;rdtype-&gt;super, (<span class="keyword">int64_t</span>)(size - rank) * rcount, &amp;gap);</span><br><span class="line"></span><br><span class="line">        free_buf = (<span class="keyword">char</span>*)<span class="built_in">calloc</span>(span, <span class="keyword">sizeof</span>(<span class="keyword">char</span>));</span><br><span class="line">        <span class="keyword">if</span> (<span class="literal">NULL</span> == free_buf) &#123;</span><br><span class="line">            line = __LINE__; err = OMPI_ERR_OUT_OF_RESOURCE; <span class="keyword">goto</span> err_hndl;</span><br><span class="line">        &#125;</span><br><span class="line">        shift_buf = free_buf - gap;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 1. copy blocks [0 .. (size - rank - 1)] from rbuf to shift buffer */</span></span><br><span class="line">        err = ompi_datatype_copy_content_same_ddt(rdtype, ((<span class="keyword">ptrdiff_t</span>)(size - rank) * (<span class="keyword">ptrdiff_t</span>)rcount),</span><br><span class="line">                                                  shift_buf, rbuf);</span><br><span class="line">        <span class="keyword">if</span> (err &lt; <span class="number">0</span>) &#123; line = __LINE__; <span class="built_in">free</span>(free_buf); <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 2. move blocks [(size - rank) .. size] from rbuf to the begining of rbuf */</span></span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*) rbuf + (<span class="keyword">ptrdiff_t</span>)(size - rank) * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        err = ompi_datatype_copy_content_same_ddt(rdtype, (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount,</span><br><span class="line">                                                  rbuf, tmpsend);</span><br><span class="line">        <span class="keyword">if</span> (err &lt; <span class="number">0</span>) &#123; line = __LINE__; <span class="built_in">free</span>(free_buf); <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* 3. copy blocks from shift buffer back to rbuf starting at block [rank]. */</span></span><br><span class="line">        tmprecv = (<span class="keyword">char</span>*) rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        err = ompi_datatype_copy_content_same_ddt(rdtype, (<span class="keyword">ptrdiff_t</span>)(size - rank) * (<span class="keyword">ptrdiff_t</span>)rcount,</span><br><span class="line">                                                  tmprecv, shift_buf);</span><br><span class="line">        <span class="keyword">if</span> (err &lt; <span class="number">0</span>) &#123; line = __LINE__; <span class="built_in">free</span>(free_buf); <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">free</span>(free_buf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line"></span><br><span class="line"> err_hndl:</span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,  <span class="string">"%s:%4d\tError occurred %d, rank %2d"</span>,</span><br><span class="line">                 __FILE__, line, err, rank));</span><br><span class="line">    (<span class="keyword">void</span>)line;  <span class="comment">// silence compiler warning</span></span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">allgather using O(log(N)) steps.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Recursive doubling algorithm for MPI_Allgather implementation. This algorithm is used in MPICH-2 for small- and medium-sized messages on power-of-two processes.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">当前的实现仅适用于二次幂个进程。 如果在非二次幂进程上调用此算法，则将调用布鲁克算法。这是蝶形的方法</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> * Example on 4 nodes:</span></span><br><span class="line"><span class="comment"> *   Initialization: everyone has its own buffer at location rank in rbuf</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3</span></span><br><span class="line"><span class="comment"> *         [0]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [1]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [2]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [ ]    [3]</span></span><br><span class="line"><span class="comment"> *   Step 0: exchange data with (rank ^ 2^0)</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3</span></span><br><span class="line"><span class="comment"> *         [0]    [0]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [1]    [1]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [2]    [2]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [3]    [3]</span></span><br><span class="line"><span class="comment"> *   Step 1: exchange data with (rank ^ 2^1) (if you can)</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3</span></span><br><span class="line"><span class="comment"> *         [0]    [0]    [0]    [0]</span></span><br><span class="line"><span class="comment"> *         [1]    [1]    [1]    [1]</span></span><br><span class="line"><span class="comment"> *         [2]    [2]    [2]    [2]</span></span><br><span class="line"><span class="comment"> *         [3]    [3]    [3]    [3]</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *       我们可以修改代码以使用与 MPICH-2 相同的实现：</span></span><br><span class="line"><span class="comment"> *        - 使用递归减半算法，在每一步结束时，确定是否有节点在该步骤中没有交换数据，并向它们发送适当的消息。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">ompi_coll_base_allgather_intra_recursivedoubling(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span><br><span class="line">                                                  struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span><br><span class="line">                                                  <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span><br><span class="line">                                                  struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span><br><span class="line">                                                  struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                                                  <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>, rank, size, pow2size, err;</span><br><span class="line">    <span class="keyword">int</span> remote, distance, sendblocklocation;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rext;</span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    pow2size = opal_next_poweroftwo (size);</span><br><span class="line">    pow2size &gt;&gt;=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 当前的实现只处理进程的二次幂。 如果该函数在非二次幂的进程数上调用，</span></span><br><span class="line"><span class="comment">     * 则打印警告并使用相同的参数调用 bruck allgather 算法。</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (pow2size != size) &#123;</span><br><span class="line">        OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                     <span class="string">"coll:base:allgather_intra_recursivedoubling WARNING: non-pow-2 size %d, switching to bruck algorithm"</span>,</span><br><span class="line">                     size));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> ompi_coll_base_allgather_intra_bruck(sbuf, scount, sdtype,</span><br><span class="line">                                                     rbuf, rcount, rdtype,</span><br><span class="line">                                                     comm, <span class="keyword">module</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"coll:base:allgather_intra_recursivedoubling rank %d, size %d"</span>,</span><br><span class="line">                 rank, size));</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent (rdtype, &amp;rlb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialization step:</span></span><br><span class="line"><span class="comment">       - if send buffer is not MPI_IN_PLACE, copy send buffer to block 0 of</span></span><br><span class="line"><span class="comment">       receive buffer</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE != sbuf) &#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*) sbuf;</span><br><span class="line">        tmprecv = (<span class="keyword">char</span>*) rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        err = ompi_datatype_sndrcv(tmpsend, scount, sdtype, tmprecv, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Communication step:</span></span><br><span class="line"><span class="comment">       At every step i, rank r:</span></span><br><span class="line"><span class="comment">       - exchanges message with rank remote = (r ^ 2^i).</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    sendblocklocation = rank;</span><br><span class="line">    <span class="keyword">for</span> (distance = <span class="number">0x1</span>; distance &lt; size; distance&lt;&lt;=<span class="number">1</span>) &#123;</span><br><span class="line">        remote = rank ^ distance;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (rank &lt; remote) &#123;</span><br><span class="line">            tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)sendblocklocation * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">            tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)(sendblocklocation + distance) * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)sendblocklocation * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">            tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)(sendblocklocation - distance) * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">            sendblocklocation -= distance;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Sendreceive */</span></span><br><span class="line">        err = ompi_coll_base_sendrecv(tmpsend, (<span class="keyword">ptrdiff_t</span>)distance * (<span class="keyword">ptrdiff_t</span>)rcount, rdtype,</span><br><span class="line">                                       remote, MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       tmprecv, (<span class="keyword">ptrdiff_t</span>)distance * (<span class="keyword">ptrdiff_t</span>)rcount, rdtype,</span><br><span class="line">                                       remote, MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">allgather using O(log(N)) steps.</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> * Description: 一种类似于 Bruck 的 allgather 算法的提议，但具有倒置的距离和不递减的交换数据大小.</span></span><br><span class="line"><span class="comment"> * Described in "Sparbit: a new logarithmic-cost and data locality-aware MPI Allgather algorithm".</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"> * Example on 6 nodes, with l representing the highest power of two smaller than N, in this case l =</span></span><br><span class="line"><span class="comment"> * 4 (more details can be found on the paper):</span></span><br><span class="line"><span class="comment"> *  Initial state</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [ ]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [1]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [2]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [ ]    [3]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [ ]    [ ]    [4]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [ ]    [ ]    [ ]    [5]</span></span><br><span class="line"><span class="comment"> *   Step 0: 每个进程将自己的块发送到进程 r + l 并从 r - l 接收另一个块。</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [ ]    [ ]    [ ]    [0]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [1]    [ ]    [ ]    [ ]    [1]</span></span><br><span class="line"><span class="comment"> *         [2]    [ ]    [2]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [3]    [ ]    [3]    [ ]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [4]    [ ]    [4]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [ ]    [ ]    [5]    [ ]    [5]</span></span><br><span class="line"><span class="comment"> *   Step 1: 每个进程将自己的块发送到进程 r + l/2 并从 r - l/2 接收另一个块。</span></span><br><span class="line"><span class="comment"> *   上一步接收到的块被忽略以避免未来的双重写入。</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [ ]    [0]    [ ]    [0]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [1]    [ ]    [1]    [ ]    [1]</span></span><br><span class="line"><span class="comment"> *         [2]    [ ]    [2]    [ ]    [2]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [3]    [ ]    [3]    [ ]    [3]</span></span><br><span class="line"><span class="comment"> *         [4]    [ ]    [4]    [ ]    [4]    [ ]</span></span><br><span class="line"><span class="comment"> *         [ ]    [5]    [ ]    [5]    [ ]    [5]</span></span><br><span class="line"><span class="comment"> *   Step 1: 每个进程将其拥有的所有数据（3 个块）发送到进程 r + l/4，</span></span><br><span class="line"><span class="comment"> *           并类似地从进程 r - l/4 接收所有数据。</span></span><br><span class="line"><span class="comment"> *    #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment"> *         [0]    [0]    [0]    [0]    [0]    [0]</span></span><br><span class="line"><span class="comment"> *         [1]    [1]    [1]    [1]    [1]    [1]</span></span><br><span class="line"><span class="comment"> *         [2]    [2]    [2]    [2]    [2]    [2]</span></span><br><span class="line"><span class="comment"> *         [3]    [3]    [3]    [3]    [3]    [3]</span></span><br><span class="line"><span class="comment"> *         [4]    [4]    [4]    [4]    [4]    [4]</span></span><br><span class="line"><span class="comment"> *         [5]    [5]    [5]    [5]    [5]    [5]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_allgather_intra_sparbit</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                  struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                  <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                  struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                  struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                                  <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">/* list of variable declaration */</span></span><br><span class="line">    <span class="keyword">int</span> rank = <span class="number">0</span>, comm_size = <span class="number">0</span>, comm_log = <span class="number">0</span>, exclusion = <span class="number">0</span>, data_expected = <span class="number">1</span>, transfer_count = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sendto, recvfrom, send_disp, recv_disp;</span><br><span class="line">    <span class="keyword">uint32_t</span> last_ignore, ignore_steps, distance = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> err = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rext;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    MPI_Request *requests = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    comm_size = ompi_comm_size(comm);</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent(rdtype, &amp;rlb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 如果未设置 MPI_IN_PLACE 条件，则将发送缓冲区复制到接收缓冲区以执行发送（所有数据都从 recv 缓冲区中提取和转发）</span></span><br><span class="line"><span class="comment">    /* tmprecv 和 tmpsend 用作抽象指针以简化发送和接收缓冲区的选择</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    tmprecv = (<span class="keyword">char</span> *) rbuf;</span><br><span class="line">    <span class="keyword">if</span>(MPI_IN_PLACE != sbuf)&#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span> *) sbuf; </span><br><span class="line">        err = ompi_datatype_sndrcv(tmpsend, scount, sdtype, tmprecv + (<span class="keyword">ptrdiff_t</span>) rank * rcount * rext, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    tmpsend = tmprecv;</span><br><span class="line"></span><br><span class="line">    requests = (MPI_Request *) <span class="built_in">malloc</span>(comm_size * <span class="keyword">sizeof</span>(MPI_Request));</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* calculate log2 of the total process count */</span></span><br><span class="line">    comm_log = <span class="built_in">ceil</span>(<span class="built_in">log</span>(comm_size)/<span class="built_in">log</span>(<span class="number">2</span>));</span><br><span class="line">    distance &lt;&lt;= comm_log - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    last_ignore = __builtin_ctz(comm_size);</span><br><span class="line">    ignore_steps = (~((<span class="keyword">uint32_t</span>) comm_size &gt;&gt; last_ignore) | <span class="number">1</span>) &lt;&lt; last_ignore;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* perform the parallel binomial tree distribution steps */</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; comm_log; ++i) &#123;</span><br><span class="line">       sendto = (rank + distance) % comm_size;  </span><br><span class="line">       recvfrom = (rank - distance + comm_size) % comm_size;  </span><br><span class="line">       exclusion = (distance &amp; ignore_steps) == distance;</span><br><span class="line"></span><br><span class="line">       <span class="keyword">for</span> (transfer_count = <span class="number">0</span>; transfer_count &lt; data_expected - exclusion; transfer_count++) &#123;</span><br><span class="line">           send_disp = (rank - <span class="number">2</span> * transfer_count * distance + comm_size) % comm_size;</span><br><span class="line">           recv_disp = (rank - (<span class="number">2</span> * transfer_count + <span class="number">1</span>) * distance + comm_size) % comm_size;</span><br><span class="line"></span><br><span class="line">           <span class="comment">/* 由于每个进程发送几个不连续的数据块，因此发送的每个块（因此每个发送和接收调用）都需要不同的标签。 */</span></span><br><span class="line">           <span class="comment">/* 由于基本 OpenMPI 只为 allgather 提供一个标签，我们被迫在 send 和 recv 调用中使用来自其他组件的标签空间 */</span></span><br><span class="line">           MCA_PML_CALL(isend(tmpsend + (<span class="keyword">ptrdiff_t</span>) send_disp * scount * rext, scount, rdtype, sendto, MCA_COLL_BASE_TAG_HCOLL_BASE - send_disp, MCA_PML_BASE_SEND_STANDARD, comm, requests + transfer_count));</span><br><span class="line">           MCA_PML_CALL(irecv(tmprecv + (<span class="keyword">ptrdiff_t</span>) recv_disp * rcount * rext, rcount, rdtype, recvfrom, MCA_COLL_BASE_TAG_HCOLL_BASE - recv_disp, comm, requests + data_expected - exclusion + transfer_count));</span><br><span class="line">       &#125;</span><br><span class="line">       ompi_request_wait_all(transfer_count * <span class="number">2</span>, requests, MPI_STATUSES_IGNORE);</span><br><span class="line"></span><br><span class="line">       distance &gt;&gt;= <span class="number">1</span>; </span><br><span class="line">       <span class="comment">/* calculates the data expected for the next step, based on the current number of blocks and eventual exclusions */</span></span><br><span class="line">       data_expected = (data_expected &lt;&lt; <span class="number">1</span>) - exclusion;</span><br><span class="line">       exclusion = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">free</span>(requests);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line"></span><br><span class="line">err_hndl:</span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,  <span class="string">"%s:%4d\tError occurred %d, rank %2d"</span>,</span><br><span class="line">                 __FILE__, line, err, rank));</span><br><span class="line">    (<span class="keyword">void</span>)line;  <span class="comment">// silence compiler warning</span></span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">allgather using O(N) steps.</span></span><br><span class="line"><span class="comment">allgather的环形算法。 在i步 ，rank r 接收来自 rank (r - 1) 的消息，其中包含来自 rank (r - i - 1) 的数据，并将包含来自 rank (r - i) 的数据的消息发送到 rank (r + 1)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_allgather_intra_ring</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                         <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>, rank, size, err, sendto, recvfrom, i, recvdatafrom, senddatafrom;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rext;</span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"coll:base:allgather_intra_ring rank %d"</span>, rank));</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent (rdtype, &amp;rlb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialization step:</span></span><br><span class="line"><span class="comment">       - if send buffer is not MPI_IN_PLACE, copy send buffer to appropriate block</span></span><br><span class="line"><span class="comment">       of receive buffer</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    tmprecv = (<span class="keyword">char</span>*) rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE != sbuf) &#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*) sbuf;</span><br><span class="line">        err = ompi_datatype_sndrcv(tmpsend, scount, sdtype, tmprecv, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Communication step:</span></span><br><span class="line"><span class="comment">       At every step i: 0 .. (P-1), rank r:</span></span><br><span class="line"><span class="comment">       - 从 [(r - 1 + size) % size] 接收数据，其中包含 [(r - i - 1 + size) % size] 的数据</span></span><br><span class="line"><span class="comment">       - 发送给下一个进程[(r + 1) % size]，其中包含 [(r - i + size) % size]的数据</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    sendto = (rank + <span class="number">1</span>) % size;</span><br><span class="line">    recvfrom  = (rank - <span class="number">1</span> + size) % size;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; size - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        recvdatafrom = (rank - i - <span class="number">1</span> + size) % size;</span><br><span class="line">        senddatafrom = (rank - i + size) % size;</span><br><span class="line"></span><br><span class="line">        tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)recvdatafrom * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)senddatafrom * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Sendreceive */</span></span><br><span class="line">        err = ompi_coll_base_sendrecv(tmpsend, rcount, rdtype, sendto,</span><br><span class="line">                                       MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       tmprecv, rcount, rdtype, recvfrom,</span><br><span class="line">                                       MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">allgather using N/2 steps (O(N))</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Neighbor Exchange algorithm for allgather. Described by Chen et.al. in </span></span><br><span class="line"><span class="comment">"Performance Evaluation of Allgather Algorithms on  Terascale Linux Cluster with Fast Ethernet",</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Rank r 与其中一个邻居交换消息，并在下一步进一步转发数据。算法仅适用于偶数进程。 对于奇数个进程，我们切换到环形算法。</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">Example on 6 nodes:</span></span><br><span class="line"><span class="comment">Initial state</span></span><br><span class="line"><span class="comment">  #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment">       [0]    [ ]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [1]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [2]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [ ]    [3]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [ ]    [ ]    [4]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [ ]    [ ]    [ ]    [5]</span></span><br><span class="line"><span class="comment"> Step 0:</span></span><br><span class="line"><span class="comment">  #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment">       [0]    [0]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [1]    [1]    [ ]    [ ]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [2]    [2]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [3]    [3]    [ ]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [ ]    [ ]    [4]    [4]</span></span><br><span class="line"><span class="comment">       [ ]    [ ]    [ ]    [ ]    [5]    [5]</span></span><br><span class="line"><span class="comment"> Step 1:</span></span><br><span class="line"><span class="comment">  #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment">       [0]    [0]    [0]    [ ]    [ ]    [0]</span></span><br><span class="line"><span class="comment">       [1]    [1]    [1]    [ ]    [ ]    [1]</span></span><br><span class="line"><span class="comment">       [ ]    [2]    [2]    [2]    [2]    [ ]</span></span><br><span class="line"><span class="comment">       [ ]    [3]    [3]    [3]    [3]    [ ]</span></span><br><span class="line"><span class="comment">       [4]    [ ]    [ ]    [4]    [4]    [4]</span></span><br><span class="line"><span class="comment">       [5]    [ ]    [ ]    [5]    [5]    [5]</span></span><br><span class="line"><span class="comment"> Step 2:</span></span><br><span class="line"><span class="comment">  #     0      1      2      3      4      5</span></span><br><span class="line"><span class="comment">       [0]    [0]    [0]    [0]    [0]    [0]</span></span><br><span class="line"><span class="comment">       [1]    [1]    [1]    [1]    [1]    [1]</span></span><br><span class="line"><span class="comment">       [2]    [2]    [2]    [2]    [2]    [2]</span></span><br><span class="line"><span class="comment">       [3]    [3]    [3]    [3]    [3]    [3]</span></span><br><span class="line"><span class="comment">       [4]    [4]    [4]    [4]    [4]    [4]</span></span><br><span class="line"><span class="comment">       [5]    [5]    [5]    [5]    [5]    [5]</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">ompi_coll_base_allgather_intra_neighborexchange(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span><br><span class="line">                                                 struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span><br><span class="line">                                                 <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span><br><span class="line">                                                 struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span><br><span class="line">                                                 struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                                                 <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>, rank, size, i, even_rank, err;</span><br><span class="line">    <span class="keyword">int</span> neighbor[<span class="number">2</span>], offset_at_step[<span class="number">2</span>], recv_data_from[<span class="number">2</span>], send_data_from;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rlb, rext;</span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_size(comm);</span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (size % <span class="number">2</span>) &#123;</span><br><span class="line">        OPAL_OUTPUT((ompi_coll_base_framework.framework_output, <span class="string">"coll:base:allgather_intra_neighborexchange WARNING: odd size %d, switching to ring algorithm"</span>, size));</span><br><span class="line">        <span class="keyword">return</span> ompi_coll_base_allgather_intra_ring(sbuf, scount, sdtype, rbuf, rcount, rdtype, comm, <span class="keyword">module</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent (rdtype, &amp;rlb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Initialization step:</span></span><br><span class="line"><span class="comment">       - if send buffer is not MPI_IN_PLACE, copy send buffer to appropriate block</span></span><br><span class="line"><span class="comment">       of receive buffer</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    tmprecv = (<span class="keyword">char</span>*) rbuf + (<span class="keyword">ptrdiff_t</span>)rank *(<span class="keyword">ptrdiff_t</span>) rcount * rext;</span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE != sbuf) &#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*) sbuf;</span><br><span class="line">        err = ompi_datatype_sndrcv(tmpsend, scount, sdtype, tmprecv, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Determine neighbors, order in which blocks will arrive, etc. */</span></span><br><span class="line">    even_rank = !(rank % <span class="number">2</span>);</span><br><span class="line">    <span class="keyword">if</span> (even_rank) &#123;</span><br><span class="line">        neighbor[<span class="number">0</span>] = (rank + <span class="number">1</span>) % size;</span><br><span class="line">        neighbor[<span class="number">1</span>] = (rank - <span class="number">1</span> + size) % size;</span><br><span class="line">        recv_data_from[<span class="number">0</span>] = rank;</span><br><span class="line">        recv_data_from[<span class="number">1</span>] = rank;</span><br><span class="line">        offset_at_step[<span class="number">0</span>] = (+<span class="number">2</span>);</span><br><span class="line">        offset_at_step[<span class="number">1</span>] = (<span class="number">-2</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        neighbor[<span class="number">0</span>] = (rank - <span class="number">1</span> + size) % size;</span><br><span class="line">        neighbor[<span class="number">1</span>] = (rank + <span class="number">1</span>) % size;</span><br><span class="line">        recv_data_from[<span class="number">0</span>] = neighbor[<span class="number">0</span>];</span><br><span class="line">        recv_data_from[<span class="number">1</span>] = neighbor[<span class="number">0</span>];</span><br><span class="line">        offset_at_step[<span class="number">0</span>] = (<span class="number">-2</span>);</span><br><span class="line">        offset_at_step[<span class="number">1</span>] = (+<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Communication loop:</span></span><br><span class="line"><span class="comment">       - First step is special: exchange a single block with neighbor[0].</span></span><br><span class="line"><span class="comment">       - Rest of the steps:</span></span><br><span class="line"><span class="comment">       根据偏移量更新recv_data_from，以及</span></span><br><span class="line"><span class="comment">       与适当的邻居交换两个块。</span></span><br><span class="line"><span class="comment">       发送位置成为先前的接收位置。</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)neighbor[<span class="number">0</span>] * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">    tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">    <span class="comment">/* Sendreceive */</span></span><br><span class="line">    err = ompi_coll_base_sendrecv(tmpsend, rcount, rdtype, neighbor[<span class="number">0</span>],</span><br><span class="line">                                   MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                   tmprecv, rcount, rdtype, neighbor[<span class="number">0</span>],</span><br><span class="line">                                   MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                   comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Determine initial sending location */</span></span><br><span class="line">    <span class="keyword">if</span> (even_rank) &#123;</span><br><span class="line">        send_data_from = rank;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        send_data_from = recv_data_from[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt; (size / <span class="number">2</span>); i++) &#123;</span><br><span class="line">        <span class="keyword">const</span> <span class="keyword">int</span> i_parity = i % <span class="number">2</span>;</span><br><span class="line">        recv_data_from[i_parity] =</span><br><span class="line">            (recv_data_from[i_parity] + offset_at_step[i_parity] + size) % size;</span><br><span class="line"></span><br><span class="line">        tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)recv_data_from[i_parity] * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)send_data_from * rcount * rext;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Sendreceive */</span></span><br><span class="line">        err = ompi_coll_base_sendrecv(tmpsend, (<span class="keyword">ptrdiff_t</span>)<span class="number">2</span> * (<span class="keyword">ptrdiff_t</span>)rcount, rdtype,</span><br><span class="line">                                       neighbor[i_parity],</span><br><span class="line">                                       MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       tmprecv, (<span class="keyword">ptrdiff_t</span>)<span class="number">2</span> * (<span class="keyword">ptrdiff_t</span>)rcount, rdtype,</span><br><span class="line">                                       neighbor[i_parity],</span><br><span class="line">                                       MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                       comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">        send_data_from = recv_data_from[i_parity];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> OMPI_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">ompi_coll_base_allgather_intra_two_procs</span><span class="params">(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="keyword">void</span>* rbuf, <span class="keyword">int</span> rcount,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              struct <span class="keyword">ompi_communicator_t</span> *comm,</span></span></span><br><span class="line"><span class="function"><span class="params">                                              <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> line = <span class="number">-1</span>, err, rank, remote;</span><br><span class="line">    <span class="keyword">char</span> *tmpsend = <span class="literal">NULL</span>, *tmprecv = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> rext, lb;</span><br><span class="line"></span><br><span class="line">    rank = ompi_comm_rank(comm);</span><br><span class="line"></span><br><span class="line">    OPAL_OUTPUT((ompi_coll_base_framework.framework_output,</span><br><span class="line">                 <span class="string">"ompi_coll_base_allgather_intra_two_procs rank %d"</span>, rank));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="number">2</span> != ompi_comm_size(comm)) &#123;</span><br><span class="line">        <span class="keyword">return</span> MPI_ERR_UNSUPPORTED_OPERATION;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    err = ompi_datatype_get_extent (rdtype, &amp;lb, &amp;rext);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Exchange data:</span></span><br><span class="line"><span class="comment">       - compute source and destinations</span></span><br><span class="line"><span class="comment">       - send receive data</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    remote  = rank ^ <span class="number">0x1</span>;</span><br><span class="line"></span><br><span class="line">    tmpsend = (<span class="keyword">char</span>*)sbuf;</span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE == sbuf) &#123;</span><br><span class="line">        tmpsend = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line">        scount = rcount;</span><br><span class="line">        sdtype = rdtype;</span><br><span class="line">    &#125;</span><br><span class="line">    tmprecv = (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)remote * (<span class="keyword">ptrdiff_t</span>)rcount * rext;</span><br><span class="line"></span><br><span class="line">    err = ompi_coll_base_sendrecv(tmpsend, scount, sdtype, remote,</span><br><span class="line">                                   MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                   tmprecv, rcount, rdtype, remote,</span><br><span class="line">                                   MCA_COLL_BASE_TAG_ALLGATHER,</span><br><span class="line">                                   comm, MPI_STATUS_IGNORE, rank);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Place your data in correct location if necessary */</span></span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE != sbuf) &#123;</span><br><span class="line">        err = ompi_datatype_sndrcv((<span class="keyword">char</span>*)sbuf, scount, sdtype,</span><br><span class="line">                                   (<span class="keyword">char</span>*)rbuf + (<span class="keyword">ptrdiff_t</span>)rank * (<span class="keyword">ptrdiff_t</span>)rcount * rext, rcount, rdtype);</span><br><span class="line">        <span class="keyword">if</span> (MPI_SUCCESS != err) &#123; line = __LINE__; <span class="keyword">goto</span> err_hndl;  &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> MPI_SUCCESS;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/* 线性函数是从 BASIC coll 模块复制的，它们不会对消息进行分段并且是简单的实现，</span></span><br><span class="line"><span class="comment"> * 但对于一些少量节点和/或小数据大小，它们与基于基/树的分段操作一样快</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *    Function:    - allgather using other MPI collections</span></span><br><span class="line"><span class="comment"> *    Accepts:    - same as MPI_Allgather()</span></span><br><span class="line"><span class="comment"> *    Returns:    - MPI_SUCCESS or error code</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">int</span></span><br><span class="line">ompi_coll_base_allgather_intra_basic_linear(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span><br><span class="line">                                             struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span><br><span class="line">                                             <span class="keyword">void</span> *rbuf,</span><br><span class="line">                                             <span class="keyword">int</span> rcount,</span><br><span class="line">                                             struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span><br><span class="line">                                             struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                                             <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line">    <span class="keyword">ptrdiff_t</span> lb, extent;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Handle MPI_IN_PLACE  -- note that rank 0 can use IN_PLACE</span></span><br><span class="line"><span class="comment">       natively, and we can just alias the right position in rbuf</span></span><br><span class="line"><span class="comment">       as sbuf and avoid using a temporary buffer if gather is</span></span><br><span class="line"><span class="comment">       implemented correctly */</span></span><br><span class="line">    <span class="keyword">if</span> (MPI_IN_PLACE == sbuf &amp;&amp; <span class="number">0</span> != ompi_comm_rank(comm)) &#123;</span><br><span class="line">        ompi_datatype_get_extent(rdtype, &amp;lb, &amp;extent);</span><br><span class="line">        sbuf = ((<span class="keyword">char</span>*) rbuf) + (ompi_comm_rank(comm) * extent * rcount);</span><br><span class="line">        sdtype = rdtype;</span><br><span class="line">        scount = rcount;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Gather and broadcast. */</span></span><br><span class="line"></span><br><span class="line">    err = comm-&gt;c_coll-&gt;coll_gather(sbuf, scount, sdtype,</span><br><span class="line">                                   rbuf, rcount, rdtype,</span><br><span class="line">                                   <span class="number">0</span>, comm, comm-&gt;c_coll-&gt;coll_gather_module);</span><br><span class="line">    <span class="keyword">if</span> (MPI_SUCCESS == err) &#123;</span><br><span class="line">        <span class="keyword">size_t</span> length = (<span class="keyword">ptrdiff_t</span>)rcount * ompi_comm_size(comm);</span><br><span class="line">        <span class="keyword">if</span>( length &lt; (<span class="keyword">size_t</span>)INT_MAX ) &#123;</span><br><span class="line">            err = comm-&gt;c_coll-&gt;coll_bcast(rbuf, (<span class="keyword">ptrdiff_t</span>)rcount * ompi_comm_size(comm), rdtype,</span><br><span class="line">                                          <span class="number">0</span>, comm, comm-&gt;c_coll-&gt;coll_bcast_module);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">ompi_datatype_t</span>* temptype;</span><br><span class="line">            ompi_datatype_create_contiguous(ompi_comm_size(comm), rdtype, &amp;temptype);</span><br><span class="line">            ompi_datatype_commit(&amp;temptype);</span><br><span class="line">            err = comm-&gt;c_coll-&gt;coll_bcast(rbuf, rcount, temptype,</span><br><span class="line">                                          <span class="number">0</span>, comm, comm-&gt;c_coll-&gt;coll_bcast_module);</span><br><span class="line">            ompi_datatype_destroy(&amp;temptype);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="MPI-Gather"><a href="#MPI-Gather" class="headerlink" title="MPI_Gather"></a>MPI_Gather</h1><p>首先检查缓冲区是否正确，通信域是否正确，是否跨通信域，如果没问题直接调用<code>coll_gather</code>，有如下几个实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mca_coll_basic_gather_inter</span><br><span class="line">ompi_coll_base_gather_intra_basic_linear</span><br><span class="line">mca_coll_self_gather_intra</span><br></pre></td></tr></table></figure></p>
<p>以下几个实现很简单：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span></span><br><span class="line">mca_coll_basic_gather_inter(<span class="keyword">const</span> <span class="keyword">void</span> *sbuf, <span class="keyword">int</span> scount,</span><br><span class="line">                            struct <span class="keyword">ompi_datatype_t</span> *sdtype,</span><br><span class="line">                            <span class="keyword">void</span> *rbuf, <span class="keyword">int</span> rcount,</span><br><span class="line">                            struct <span class="keyword">ompi_datatype_t</span> *rdtype,</span><br><span class="line">                            <span class="keyword">int</span> root, struct <span class="keyword">ompi_communicator_t</span> *comm,</span><br><span class="line">                            <span class="keyword">mca_coll_base_module_t</span> *<span class="keyword">module</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">int</span> err;</span><br><span class="line">    <span class="keyword">int</span> size;</span><br><span class="line">    <span class="keyword">char</span> *ptmp;</span><br><span class="line">    MPI_Aint incr;</span><br><span class="line">    MPI_Aint extent;</span><br><span class="line">    MPI_Aint lb;</span><br><span class="line"></span><br><span class="line">    size = ompi_comm_remote_size(comm);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (MPI_PROC_NULL == root) &#123;</span><br><span class="line">        <span class="comment">/* do nothing */</span></span><br><span class="line">        err = OMPI_SUCCESS;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (MPI_ROOT != root) &#123;</span><br><span class="line">        <span class="comment">/* Everyone but root sends data and returns. */</span></span><br><span class="line">        err = MCA_PML_CALL(send(sbuf, scount, sdtype, root,</span><br><span class="line">                                MCA_COLL_BASE_TAG_GATHER,</span><br><span class="line">                                MCA_PML_BASE_SEND_STANDARD, comm));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">/* I am the root, loop receiving the data. */</span></span><br><span class="line">        err = ompi_datatype_get_extent(rdtype, &amp;lb, &amp;extent);</span><br><span class="line">        <span class="keyword">if</span> (OMPI_SUCCESS != err) &#123;</span><br><span class="line">            <span class="keyword">return</span> OMPI_ERROR;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        incr = extent * rcount;</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">0</span>, ptmp = (<span class="keyword">char</span> *) rbuf; i &lt; size; ++i, ptmp += incr) &#123;</span><br><span class="line">            err = MCA_PML_CALL(recv(ptmp, rcount, rdtype, i,</span><br><span class="line">                                    MCA_COLL_BASE_TAG_GATHER,</span><br><span class="line">                                    comm, MPI_STATUS_IGNORE));</span><br><span class="line">            <span class="keyword">if</span> (MPI_SUCCESS != err) &#123;</span><br><span class="line">                <span class="keyword">return</span> err;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="Request结构"><a href="#Request结构" class="headerlink" title="Request结构"></a>Request结构</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Main top-level request struct definition</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_request_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">opal_free_list_item_t</span> super;                <span class="comment">/**&lt; Base type */</span></span><br><span class="line">    <span class="keyword">ompi_request_type_t</span> req_type;               <span class="comment">/**&lt; Enum indicating the type of the request */</span></span><br><span class="line">    <span class="keyword">ompi_status_public_t</span> req_status;            <span class="comment">/**&lt; Completion status */</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">void</span> *req_complete;                <span class="comment">/**&lt; Flag indicating wether request has completed */</span></span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">ompi_request_state_t</span> req_state;    <span class="comment">/**&lt; enum indicate state of the request */</span></span><br><span class="line">    <span class="keyword">bool</span> req_persistent;                        <span class="comment">/**&lt; flag indicating if the this is a persistent request */</span></span><br><span class="line">    <span class="keyword">int</span> req_f_to_c_index;                       <span class="comment">/**&lt; Index in Fortran &lt;-&gt; C translation array */</span></span><br><span class="line">    <span class="keyword">ompi_request_start_fn_t</span> req_start;          <span class="comment">/**&lt; Called by MPI_START and MPI_STARTALL */</span></span><br><span class="line">    <span class="keyword">ompi_request_free_fn_t</span> req_free;            <span class="comment">/**&lt; Called by free */</span></span><br><span class="line">    <span class="keyword">ompi_request_cancel_fn_t</span> req_cancel;        <span class="comment">/**&lt; Optional function to cancel the request */</span></span><br><span class="line">    <span class="keyword">ompi_request_complete_fn_t</span> req_complete_cb; <span class="comment">/**&lt; Called when the request is MPI completed */</span></span><br><span class="line">    <span class="keyword">void</span> *req_complete_cb_data;</span><br><span class="line">    <span class="keyword">ompi_mpi_object_t</span> req_mpi_object;           <span class="comment">/**&lt; Pointer to MPI object that created this request */</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ompi_predefined_request_t</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">ompi_request_t</span> <span class="title">request</span>;</span></span><br><span class="line">    <span class="keyword">char</span> padding[PREDEFINED_REQUEST_PAD - <span class="keyword">sizeof</span>(<span class="keyword">ompi_request_t</span>)];</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ompi_predefined_request_t</span> <span class="title">ompi_predefined_request_t</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 初始化一个请求。 这是一个避免函数调用开销的宏，因为它通常在关键性能路径中调用（因为请求可能被重用，我们可能必须多次初始化请求）。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_REQUEST_INIT(request, persistent)                  \</span></span><br><span class="line">    <span class="keyword">do</span> &#123;                                                        \</span><br><span class="line">        (request)-&gt;req_complete =                               \</span><br><span class="line">            (persistent) ? REQUEST_COMPLETED : REQUEST_PENDING; \</span><br><span class="line">        (request)-&gt;req_state = OMPI_REQUEST_INACTIVE;           \</span><br><span class="line">        (request)-&gt;req_persistent = (persistent);               \</span><br><span class="line">        (request)-&gt;req_complete_cb  = <span class="literal">NULL</span>;                     \</span><br><span class="line">        (request)-&gt;req_complete_cb_data = <span class="literal">NULL</span>;                 \</span><br><span class="line">    &#125; <span class="keyword">while</span> (<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> REQUEST_COMPLETE(req)        (REQUEST_COMPLETED == (req)-&gt;req_complete)</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 完成请求。 这是一个避免函数调用开销的宏，因为它通常在关键性能路径中调用（因为请求可能被重用，我们可能不得不多次完成一个请求）。</span></span><br><span class="line"><span class="comment"> * 当最终确定一个请求时，如果之前对该请求调用了 MPI_Request_f2c()，则该请求已添加到 f2c 表中，我们需要将其删除</span></span><br><span class="line"><span class="comment"> * 该函数只能从 MPI 层调用。 永远不要从 PML 调用它。</span></span><br><span class="line"><span class="comment"> * 它负责上层清理工作。 当用户调用 MPI_Request_free 时，我们应该释放所有 MPI 级别的资源，所以我们也必须调用这个函数。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_REQUEST_FINI(request)                                      \</span></span><br><span class="line"><span class="keyword">do</span> &#123;                                                                    \</span><br><span class="line">    (request)-&gt;req_state = OMPI_REQUEST_INVALID;                        \</span><br><span class="line">    <span class="keyword">if</span> (MPI_UNDEFINED != (request)-&gt;req_f_to_c_index) &#123;                 \</span><br><span class="line">        opal_pointer_array_set_item(&amp;ompi_request_f_to_c_table,         \</span><br><span class="line">                                    (request)-&gt;req_f_to_c_index, <span class="literal">NULL</span>); \</span><br><span class="line">        (request)-&gt;req_f_to_c_index = MPI_UNDEFINED;                    \</span><br><span class="line">    &#125;                                                                   \</span><br><span class="line">&#125; <span class="keyword">while</span> (<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * 除了在返回 MPI_ERR_IN_STATUS 的过程中，状态对象的 MPI_ERROR 字段永远不会被修改</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> OMPI_COPY_STATUS(pdst, src, is_err_in_status)                   \</span></span><br><span class="line"><span class="keyword">do</span> &#123;                                                                    \</span><br><span class="line">    <span class="keyword">if</span> (is_err_in_status) &#123;                                             \</span><br><span class="line">        *(pdst) = (src);                                                \</span><br><span class="line">    &#125;                                                                   \</span><br><span class="line">    <span class="keyword">else</span> &#123;                                                              \</span><br><span class="line">        (pdst)-&gt;MPI_TAG = (src).MPI_TAG;                                \</span><br><span class="line">        (pdst)-&gt;MPI_SOURCE = (src).MPI_SOURCE;                          \</span><br><span class="line">        (pdst)-&gt;_ucount = (src)._ucount;                                \</span><br><span class="line">        (pdst)-&gt;_cancelled = (src)._cancelled;                          \</span><br><span class="line">    &#125;                                                                   \</span><br><span class="line">&#125; <span class="keyword">while</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * request相关的函数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">ompi_request_fns_t</span> &#123;</span></span><br><span class="line">    <span class="keyword">ompi_request_test_fn_t</span>      req_test;</span><br><span class="line">    <span class="keyword">ompi_request_test_any_fn_t</span>  req_test_any;</span><br><span class="line">    <span class="keyword">ompi_request_test_all_fn_t</span>  req_test_all;</span><br><span class="line">    <span class="keyword">ompi_request_test_some_fn_t</span> req_test_some;</span><br><span class="line">    <span class="keyword">ompi_request_wait_fn_t</span>      req_wait;</span><br><span class="line">    <span class="keyword">ompi_request_wait_any_fn_t</span>  req_wait_any;</span><br><span class="line">    <span class="keyword">ompi_request_wait_all_fn_t</span>  req_wait_all;</span><br><span class="line">    <span class="keyword">ompi_request_wait_some_fn_t</span> req_wait_some;</span><br><span class="line">&#125; <span class="keyword">ompi_request_fns_t</span>;</span><br></pre></td></tr></table></figure>
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/积累/" rel="tag"># 积累</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/03/21/不同cpp版本的线程池/" rel="next" title="c++11/14、c++17/20 最简单的线程池">
                <i class="fa fa-chevron-left"></i> c++11/14、c++17/20 最简单的线程池
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/05/04/Linux网络编程/" rel="prev" title="Linux 网络编程">
                Linux 网络编程 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="Hao Yu">
            
              <p class="site-author-name" itemprop="name">Hao Yu</p>
              <p class="site-description motion-element" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</p>
          </div>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">141</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>
        	<audio controls="controls" loop="loop" preload="auto" src="/resource/xiaomeihao.mp3">
	        </audio>
	

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuhao0102" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yuh18@mails.tsinghua.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#OpenMPI结构"><span class="nav-number">1.</span> <span class="nav-text">OpenMPI结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Architecture"><span class="nav-number">1.1.</span> <span class="nav-text">Architecture</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Abstraction-Layer-Architecture"><span class="nav-number">1.2.</span> <span class="nav-text">Abstraction Layer Architecture</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Plugin-Architecture"><span class="nav-number">1.3.</span> <span class="nav-text">Plugin Architecture</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#PML"><span class="nav-number">2.</span> <span class="nav-text">PML</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MTL"><span class="nav-number">3.</span> <span class="nav-text">MTL</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#OSC"><span class="nav-number">4.</span> <span class="nav-text">OSC</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Init"><span class="nav-number">5.</span> <span class="nav-text">MPI_Init</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Comm-rank"><span class="nav-number">6.</span> <span class="nav-text">MPI_Comm_rank</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Abort"><span class="nav-number">7.</span> <span class="nav-text">MPI_Abort</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Barrier"><span class="nav-number">8.</span> <span class="nav-text">MPI_Barrier</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Bcast"><span class="nav-number">9.</span> <span class="nav-text">MPI_Bcast</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Send"><span class="nav-number">10.</span> <span class="nav-text">MPI_Send</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#TCP"><span class="nav-number">11.</span> <span class="nav-text">TCP</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RDMA"><span class="nav-number">12.</span> <span class="nav-text">RDMA</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#UCX"><span class="nav-number">13.</span> <span class="nav-text">UCX</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#convertor"><span class="nav-number">14.</span> <span class="nav-text">convertor</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Recv"><span class="nav-number">15.</span> <span class="nav-text">MPI_Recv</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Allgather"><span class="nav-number">16.</span> <span class="nav-text">MPI_Allgather</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#MPI-Gather"><span class="nav-number">17.</span> <span class="nav-text">MPI_Gather</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Request结构"><span class="nav-number">18.</span> <span class="nav-text">Request结构</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="DvelopmentTarget">     
  </div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="false"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>

  
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_uv"> 
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  


  

  


  <script type="text/javascript" src="/js/src/love.js"></script>

</body>
</html>
