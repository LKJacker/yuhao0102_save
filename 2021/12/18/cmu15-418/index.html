<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zn-ch">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="积累,">










<meta name="description" content="lecture 1指令级并行（ILP）  事实上，处理器确实利用并行执行使程序运行得更快，这对程序员来说是不可见的 想法：指令必须看起来是按程序顺序执行的。但处理器可以同时执行独立的指令，而不会影响程序的正确性 超标量执行：处理器在指令序列中动态查找独立指令并并行执行  下图是ILP的原理，第一行是三个可以并行的指令，之后只能串行。 ILP和处理器频率的提升已经很缓慢，所以并不能持续用这两种方法实">
<meta name="keywords" content="积累">
<meta property="og:type" content="article">
<meta property="og:title" content="CMU 15-418 笔记">
<meta property="og:url" content="http://yoursite.com/2021/12/18/cmu15-418/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="lecture 1指令级并行（ILP）  事实上，处理器确实利用并行执行使程序运行得更快，这对程序员来说是不可见的 想法：指令必须看起来是按程序顺序执行的。但处理器可以同时执行独立的指令，而不会影响程序的正确性 超标量执行：处理器在指令序列中动态查找独立指令并并行执行  下图是ILP的原理，第一行是三个可以并行的指令，之后只能串行。 ILP和处理器频率的提升已经很缓慢，所以并不能持续用这两种方法实">
<meta property="og:locale" content="zn-ch">
<meta property="og:image" content="http://yoursite.com/img/1639802194.png">
<meta property="og:image" content="http://yoursite.com/img/1639807892.png">
<meta property="og:image" content="http://yoursite.com/img/1639808193.png">
<meta property="og:image" content="http://yoursite.com/img/1639808590.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639808828.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639809521.png">
<meta property="og:image" content="http://yoursite.com/img/1639809905.png">
<meta property="og:image" content="http://yoursite.com/img/1639810240.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639810613.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639816043.png">
<meta property="og:image" content="http://yoursite.com/img/1639816915.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639817132.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639817978.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639819364.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639823726.png">
<meta property="og:image" content="http://yoursite.com/img/1639824277.png">
<meta property="og:image" content="http://yoursite.com/img/1639825906.png">
<meta property="og:image" content="http://yoursite.com/img/1639826639.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639827312.png">
<meta property="og:image" content="http://yoursite.com/img/1639828816.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639828860.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639829805.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639830087.png">
<meta property="og:image" content="http://yoursite.com/img/1639830216.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639830245.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639835717.png">
<meta property="og:image" content="http://yoursite.com/img/1639839915.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639840798.png">
<meta property="og:image" content="http://yoursite.com/img/1639844349.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639844935.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639845602.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639845791.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639845945.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639846029.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639846114.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639846224.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639880273.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639880425.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639880672.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639882716.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639883901.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639884148.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639884533.png">
<meta property="og:image" content="http://yoursite.com/img/1639886382.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639886607.png">
<meta property="og:image" content="http://yoursite.com/img/1639886794.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639888794.png">
<meta property="og:image" content="http://yoursite.com/img/1639888976.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639889381.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639891385.png">
<meta property="og:image" content="http://yoursite.com/img/1639892682.jpg">
<meta property="og:image" content="http://yoursite.com/img/1639893108.jpg">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:image" content="http://yoursite.com/img/">
<meta property="og:updated_time" content="2021-12-20T05:27:37.886Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CMU 15-418 笔记">
<meta name="twitter:description" content="lecture 1指令级并行（ILP）  事实上，处理器确实利用并行执行使程序运行得更快，这对程序员来说是不可见的 想法：指令必须看起来是按程序顺序执行的。但处理器可以同时执行独立的指令，而不会影响程序的正确性 超标量执行：处理器在指令序列中动态查找独立指令并并行执行  下图是ILP的原理，第一行是三个可以并行的指令，之后只能串行。 ILP和处理器频率的提升已经很缓慢，所以并不能持续用这两种方法实">
<meta name="twitter:image" content="http://yoursite.com/img/1639802194.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/12/18/cmu15-418/">





  <title>CMU 15-418 笔记 | Hao Yu's blog</title>
  








 
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zn-ch">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hao Yu's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The program monkey was eaten by the siege lion.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/resume.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-mybetterhalf">
          <a href="/mybetterhalf/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            mybetterhalf
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/12/18/cmu15-418/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CMU 15-418 笔记</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-18T12:00:00+08:00">
                2021-12-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="lecture-1"><a href="#lecture-1" class="headerlink" title="lecture 1"></a>lecture 1</h1><p>指令级并行（ILP）</p>
<ul>
<li>事实上，处理器确实利用并行执行使程序运行得更快，这对程序员来说是不可见的</li>
<li>想法：指令必须看起来是按程序顺序执行的。但处理器可以同时执行独立的指令，而不会影响程序的正确性</li>
<li>超标量执行：处理器在指令序列中动态查找独立指令并并行执行</li>
</ul>
<p>下图是ILP的原理，第一行是三个可以并行的指令，之后只能串行。<br><img src="/img/1639802194.png" alt></p>
<p>ILP和处理器频率的提升已经很缓慢，所以并不能持续用这两种方法实现并行加速。单指令流性能扩展率已降低（几乎为零）</p>
<h1 id="lecture-2"><a href="#lecture-2" class="headerlink" title="lecture 2"></a>lecture 2</h1><p>使用泰勒展开式计算<code>sin(x): sin(x)=x - x^3/3! + x^5/5! - x^7/7!+ ...</code>，对于N个浮点数数组的每个元素</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sinx</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> terms, <span class="keyword">float</span>* x, <span class="keyword">float</span>* result)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">        <span class="keyword">float</span> value = x[i];</span><br><span class="line">        <span class="keyword">float</span> numer = x[i] * x[i] * x[i];</span><br><span class="line">        <span class="keyword">int</span> denom = <span class="number">6</span>; <span class="comment">// 3!</span></span><br><span class="line">        <span class="keyword">int</span> sign = ‐<span class="number">1</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=terms; j++) </span><br><span class="line">        &#123;</span><br><span class="line">            value += sign * numer / denom;</span><br><span class="line">            numer *= x[i] * x[i]; </span><br><span class="line">            denom *= (<span class="number">2</span>*j+<span class="number">2</span>) * (<span class="number">2</span>*j+<span class="number">3</span>); </span><br><span class="line">            sign *= ­‐<span class="number">1</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        result[i] = value; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对中间的for循环中的每个<code>x[i]</code>，如果没有并行的话，每个指令都单步执行，在前三条指令中没有ILP。如果可能的话可以每个时钟解码/执行两个指令。<br><img src="/img/1639807892.png" alt></p>
<p>下图是Pentium 4的图，可以看到有两个简单指令解码器，就可以同时解码。<br><img src="/img/1639808193.png" alt></p>
<p>前多核处理器时代：大多数芯片晶体管用于执行有助于单个指令流快速运行的操作。</p>
<p>更多的晶体管=更大的缓存，更智能的无序逻辑，更智能的分支预测器，等等。（还有：更多晶体管→更小晶体管→更高的时钟频率）<br><img src="/img/1639808590.jpg" alt></p>
<p>在多核时代，有几个想法</p>
<ul>
<li>使用增加晶体管数向处理器添加更多内核</li>
<li>而不是使用晶体管来提高处理器逻辑的复杂性，从而加速单个指令流（例如，无序和推测性操作）</li>
</ul>
<p>如果有两个核，可以并行计算两个元素。可以使用更简单的内核：每个内核只有解码器、运算器、上下文等，没有cache和分支预测逻辑之类的，在运行单个指令流时都比我们原来的内核慢（例如，慢25%）。但是现在有两个核心：2×0.75=1.5（加速潜力！）<br><img src="/img/1639808828.jpg" alt></p>
<p>上边的计算程序没啥并行性，只能有一个线程执行，如果每个简单的核比正常的核慢25%，我们的程序在这样的核上只能有之前75%的性能。</p>
<p>可以使用pthreads实现并行性。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">void sinx(int N, int terms, float* x, float* result) </span><br><span class="line">&#123; </span><br><span class="line">    for (int i=0; i&lt;N; i++) </span><br><span class="line">    &#123; </span><br><span class="line">        float value = x[i]; </span><br><span class="line">        float numer = x[i] * x[i] * x[i]; </span><br><span class="line">        int denom = 6; // 3! </span><br><span class="line">        int sign = ‐1; </span><br><span class="line">        for (int j=1; j&lt;=terms; j++) </span><br><span class="line">        &#123;   </span><br><span class="line">            value += sign * numer / denom;</span><br><span class="line">            numer *= x[i] * x[i]; </span><br><span class="line">            denom *= (2*j+2) * (2*j+3); </span><br><span class="line">            sign *= -1; </span><br><span class="line">        &#125; </span><br><span class="line">        result[i] = value; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">typedef struct &#123; </span><br><span class="line">    int N; </span><br><span class="line">    int terms; </span><br><span class="line">    float* x; </span><br><span class="line">    float* result; </span><br><span class="line">&#125; my_args;</span><br><span class="line"></span><br><span class="line">void parallel_sinx(int N, int terms, float* x, float* result) </span><br><span class="line">&#123; </span><br><span class="line">     pthread_t thread_id; </span><br><span class="line">     my_args args; </span><br><span class="line">     args.N = N/2; </span><br><span class="line">     args.terms = terms; </span><br><span class="line">     args.x = x; </span><br><span class="line">     args.result = result; </span><br><span class="line">     pthread_create(&amp;thread_id, NULL, my_thread_start, &amp;args); // launch thread</span><br><span class="line">     sinx(N - args.N, terms, x + args.N, result + args.N); // do work</span><br><span class="line">    pthread_join(thread_id, NULL);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void my_thread_start(void* thread_arg) </span><br><span class="line">&#123; </span><br><span class="line">    my_args* thread_args = (my_args*)thread_arg; </span><br><span class="line">    sinx(args­‐&gt;N, args­‐&gt;terms, args‐&gt;x, args­‐&gt;result); // do work </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果有四个核，可以并行计算四个元素。<br><img src="/img/1639809521.png" alt></p>
<p>增加ALU以提高计算能力：分摊跨多个ALU管理指令流的成本/复杂性，改为SIMD单指令、多数据流，向所有ALU广播的相同指令，在所有ALU上并行执行指令。<br><img src="/img/1639809905.png" alt></p>
<p>矢量程序（使用AVX内部函数）使用256位向量寄存器上的向量指令同时处理八个数组元素。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;immintrin.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sinx</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> terms, <span class="keyword">float</span>* x, <span class="keyword">float</span>* result)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">float</span> three_fact = <span class="number">6</span>;  <span class="comment">// 3!</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i+=<span class="number">8</span>) </span><br><span class="line">    &#123; </span><br><span class="line">        __m256 origx = _mm256_load_ps(&amp;x[i]); </span><br><span class="line">        __m256 value = origx; </span><br><span class="line">        __m256 numer = _mm256_mul_ps(origx, _mm256_mul_ps(origx, origx)); </span><br><span class="line">        __m256 denom = _mm256_broadcast_ss(&amp;three_fact); </span><br><span class="line">        <span class="keyword">int</span> sign = <span class="number">-1</span>; </span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=terms; j++) </span><br><span class="line">        &#123;  </span><br><span class="line">            <span class="comment">// value += sign * numer / denom</span></span><br><span class="line">            __m256 tmp = _mm256_div_ps(_mm256_mul_ps(_mm256_set1ps(sign), numer), denom); </span><br><span class="line">            value = _mm256_add_ps(value, tmp); </span><br><span class="line">            numer = _mm256_mul_ps(numer, _mm256_mul_ps(origx, origx)); </span><br><span class="line">            denom = _mm256_mul_ps(denom, _mm256_broadcast_ss((<span class="number">2</span>*j+<span class="number">2</span>) * (<span class="number">2</span>*j+<span class="number">3</span>))); </span><br><span class="line">            sign *= ­‐<span class="number">1</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        _mm256_store_ps(&amp;result[i], value); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1639810240.jpg" alt></p>
<p>如果是有条件跳转的执行呢？不是所有的ALU执行相同的指令，会降低性能。经过了这一段if之后才会重新全速执行。<br><img src="/img/1639810613.jpg" alt></p>
<p>术语</p>
<ul>
<li>指令流一致性（“一致执行”）<ul>
<li>相同的指令序列适用于同时操作的所有元件</li>
<li>一致执行对于有效利用SIMD处理资源是必要的</li>
<li>由于每个内核都具有获取/解码不同指令流的能力，因此一致执行对于跨内核的高效并行不是必需的</li>
</ul>
</li>
<li>“发散”执行<ul>
<li>缺乏指令流的连贯性</li>
</ul>
</li>
<li>注意：不要将指令流一致性与“缓存一致性”（本课程后面的一个主要主题）混淆</li>
</ul>
<p>在现代CPU上执行SIMD</p>
<ul>
<li>SSE指令：128位操作：4x32位或2x64位（4宽浮点向量）</li>
<li>AVX指令：256位操作：8x32位或4x64位（8宽浮点向量）</li>
<li>指令由编译器生成<ul>
<li>程序员使用内部函数明确请求的并行性</li>
<li>使用并行语言语义传达的并行性（例如，forall）</li>
<li>通过循环依赖性分析推断出的并行性（困难的问题是，即使是最好的编译器也无法处理任意C/C++代码）</li>
</ul>
</li>
<li>术语：“显式SIMD”：SIMD并行化在编译时执行<ul>
<li>可以检查程序二进制文件并查看指令（vstoreps、vmulps等）</li>
</ul>
</li>
</ul>
<p>在许多现代GPU上执行SIMD</p>
<ul>
<li>“隐式SIMD”<ul>
<li>编译器生成标量二进制（标量指令）</li>
<li>但N个程序实例在处理器上“始终”一起运行</li>
<li>换句话说，硬件本身的接口是数据并行的</li>
<li>硬件（不是编译器）负责在SIMD ALU上的不同数据上同时执行来自多个实例的同一指令</li>
</ul>
</li>
<li>大多数现代GPU的SIMD宽度范围为8到32<ul>
<li>分支可能是一个大问题</li>
</ul>
</li>
</ul>
<p><img src="/img/1639816043.png" alt></p>
<p>摘要：并行执行</p>
<ul>
<li>现代处理器中几种形式的并行执行<ul>
<li>多核：使用多个处理核<ul>
<li>提供线程级并行：在每个内核上同时执行完全不同的指令流</li>
<li>软件决定何时创建线程（例如，通过pthreadsapi）</li>
</ul>
</li>
<li>SIMD：使用由同一指令流控制的多个ALU（在一个内核内）<ul>
<li>数据并行工作负载的高效设计：在多个ALU上摊销控制</li>
<li>矢量化可以由编译器（显式SIMD）完成，也可以在运行时由硬件完成</li>
<li>在执行之前已知没有依赖关系（通常由程序员声明，但可以由高级编译器通过循环分析推断）</li>
</ul>
</li>
<li>超标量：在指令流中利用ILP。并行处理来自同一指令流的不同指令（在内核内）<ul>
<li>硬件在执行过程中自动动态发现并行性（程序员不可见）</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>stalls:</p>
<ul>
<li>由于依赖于上一条指令，处理器无法运行指令流中的下一条指令时会“暂停”（stalls）。</li>
<li>访问内存是暂停的主要来源</li>
<li>内存访问时间约为100个周期<ul>
<li>内存“访问时间”是对延迟的度量</li>
</ul>
</li>
</ul>
<p>当数据驻留在缓存中时，处理器会高效运行，cache减少了stalls的时间长度（隐藏延迟）</p>
<ul>
<li>所有现代CPU都具有将数据预取到缓存中的逻辑<ul>
<li>动态分析程序的访问模式，预测它将很快访问什么</li>
</ul>
</li>
<li>减少暂停，因为访问时数据驻留在缓存中</li>
<li>注意：如果猜测错误，预取也会降低性能（占用带宽，污染缓存）</li>
</ul>
<p><img src="/img/1639816915.jpg" alt></p>
<p>多线程也能减少stalls：</p>
<ul>
<li>想法：在同一个内核上交错处理多个线程以隐藏暂停</li>
<li>与预取一样，多线程也是一种延迟<strong>隐藏</strong>技术，而不是一种减少延迟的技术</li>
</ul>
<p>面向吞吐量的系统的关键思想：潜在地增加任何一个线程完成工作的时间，以便在运行多个线程时提高总体系统吞吐量。在结束引起stalls的异常之后，此线程是可运行的，但处理器不会执行它，内核正在运行其他线程，需要等待操作系统进行调度。<br><img src="/img/1639817132.jpg" alt></p>
<p>存储执行上下文：有限资源下执行上下文的片上存储问题。如果有16个线程的话，将之前整个的context storage改为16个小块，存储每个线程的小工作上下文。<br><img src="/img/1639817978.jpg" alt></p>
<p>硬件支持的多线程</p>
<ul>
<li>Core管理多线程的执行上下文<ul>
<li>从可运行线程运行指令（处理器决定运行每个时钟运行的线程，而不是操作系统）</li>
<li>Core仍然拥有相同数量的ALU资源：多线程只在面临内存访问等高延迟操作时有助于更有效地使用它们</li>
</ul>
</li>
<li>交错多线程（又称时态多线程）<ul>
<li>每个时钟，内核选择一个线程，并从ALU上的线程运行一条指令</li>
</ul>
</li>
<li>同步多线程（SMT）<ul>
<li>每个时钟，内核从多个线程中选择指令在ALU上运行</li>
<li>超标量CPU设计的扩展</li>
<li>示例：英特尔超线程（每个核心2个线程）</li>
</ul>
</li>
</ul>
<p>GPU：面向吞吐量的处理器</p>
<ul>
<li>“回”字形黄色方框=SIMD功能单元，16个单元共享控制（每个时钟1个MUL-ADD）</li>
<li>两个取指/编码器，共32个SIMD功能单元</li>
<li>指令一次操作32条数据（称为“warp”）。</li>
<li>warp=发出32条宽向量指令的线程</li>
<li>多达48条warps同时交错</li>
<li>一个核心可同时处理1500多个元素</li>
<li>为什么warp是32个元素，只有16个SIMD ALU？<ul>
<li>这有点复杂：ALU的运行速度是芯片其他部分时钟频率的两倍。因此，每条解码指令在两个ALU时钟上运行在16个ALU上的32条数据上。（但对于程序员来说，它的行为类似于32宽的SIMD操作）</li>
</ul>
</li>
</ul>
<p><img src="/img/1639819364.jpg" alt></p>
<p>带宽是一项关键资源，高性能并行程序将：</p>
<ul>
<li>组织计算以减少从内存中提取数据的频率<ul>
<li>重用以前由同一线程加载的数据（传统的线程内时间局部性优化）</li>
<li>跨线程共享数据（线程间协作）</li>
</ul>
</li>
<li>减少请求数据的频率（相反，多做算术运算：它是“免费的”）<ul>
<li>有用术语：“算术强度”-指令流中数学运算与数据访问运算的比率</li>
<li>要点：为了有效利用现代处理器，程序必须具有较高的运算强度，也就是运算指令要大于取值指令的数量</li>
</ul>
</li>
</ul>
<p>总结</p>
<ul>
<li>所有现代处理器在不同程度上采用的三大理念<ul>
<li>使用多个处理核心<ul>
<li>更简单的内核（采用线程级并行而不是指令级并行）</li>
</ul>
</li>
<li>在多个ALU上摊销指令流处理（SIMD）<ul>
<li>以很少的额外成本提高计算能力</li>
</ul>
</li>
<li>使用多线程来更有效地利用处理资源（隐藏延迟、填充所有可用资源）</li>
</ul>
</li>
<li>由于现代芯片的高运算能力，许多并行应用程序（在CPU和GPU上）都有带宽瓶颈</li>
<li>GPU架构使用与CPU相同的吞吐量计算思想：但GPU将这些概念推向了极限</li>
</ul>
<p>总结：</p>
<ul>
<li>最开始普通的串行程序+普通的仅有（取指、ALU、上下文存储）三部分的处理器，</li>
<li>改进为有两套取指+ALU的超标量处理器，这样可以在单指令流中每个时钟同时执行两个没有依赖关系的指令</li>
<li>创建多线程程序的话，需要在一个处理器上设置两套（取指、ALU、上下文存储），每个核在每个时钟只执行一个指令</li>
<li>多线程+超标量，两个核+两套（取指、ALU、上下文存储）</li>
<li>四核处理器，四个核每个核一套（取指、ALU、上下文存储）</li>
<li>进化到SIMD时代，四个核每个核都有一个取指器，八个ALU执行运算，一个上下文存储器存储上下文。</li>
<li>在SIMD基础上增加多线程，每个核除了一个取指器，八个ALU，再来两个存放上下文的切换器。<ul>
<li>观察：内存操作有很长的延迟</li>
<li>解决方案：通过执行其他迭代的算术指令来隐藏一次迭代加载数据的延迟</li>
<li>多线程SIMD四核处理器：从每个核上的一条指令流中，每个时钟执行一条SIMD指令。但当遇到暂停时，可以切换到处理其他指令流。</li>
</ul>
</li>
<li>四个超标量、SIMD、多线程内核<ul>
<li>多线程、超标量、SIMD四核处理器：从每个核上的一条指令流中，每个时钟最多执行两条指令（在本例中：一条SIMD指令+一条标量指令）。当遇到暂停时，处理器可以切换到执行其他指令流。</li>
</ul>
</li>
<li>以上，上下文切换器提供了进行切换指令流的能力；有多个取指器的话能同时执行两个指令流</li>
</ul>
<p><img src="/img/1639823726.png" alt></p>
<p><img src="/img/1639824277.png" alt></p>
<h1 id="lecture-3"><a href="#lecture-3" class="headerlink" title="lecture 3"></a>lecture 3</h1><p>Intel SPMD Program Compiler (ISPC)</p>
<p>在ISPC上计算之前的<code>sin(x)</code>函数，<code>sin(x) = x - x^3/3! + x^5/5! - x^7/7! + ...</code></p>
<p>C++ code: main.cpp<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> “sinx_ispc.h”</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line"><span class="keyword">int</span> terms = <span class="number">5</span>; </span><br><span class="line"><span class="keyword">float</span>* x = <span class="keyword">new</span> <span class="keyword">float</span>[N]; </span><br><span class="line"><span class="keyword">float</span>* result = <span class="keyword">new</span> <span class="keyword">float</span>[N]; </span><br><span class="line"><span class="comment">// initialize x here </span></span><br><span class="line"><span class="comment">// execute ISPC code </span></span><br><span class="line">sinx(N, terms, x, result);</span><br></pre></td></tr></table></figure></p>
<p>ISPC code: sinx.ispc<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> <span class="keyword">void</span> <span class="title">sinx</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">int</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">int</span> terms, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">float</span>* x, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">float</span>* result)</span> </span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// assume N % programCount = 0 </span></span><br><span class="line">    <span class="keyword">for</span> (uniform <span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i+=programCount)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> idx = i + programIndex; </span><br><span class="line">        <span class="keyword">float</span> value = x[idx]; </span><br><span class="line">        <span class="keyword">float</span> numer = x[idx] * x[idx] * x[idx]; </span><br><span class="line">        uniform <span class="keyword">int</span> denom = <span class="number">6</span>;  <span class="comment">// 3! </span></span><br><span class="line">        uniform <span class="keyword">int</span> sign = <span class="number">-1</span>; </span><br><span class="line">        <span class="keyword">for</span> (uniform <span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=terms; j++) </span><br><span class="line">        &#123;  </span><br><span class="line">            value += sign * numer / denom </span><br><span class="line">            numer *= x[idx] * x[idx]; </span><br><span class="line">            denom *= (<span class="number">2</span>*j+<span class="number">2</span>) * (<span class="number">2</span>*j+<span class="number">3</span>); </span><br><span class="line">            sign *= ­‐<span class="number">1</span>; </span><br><span class="line">        &#125; </span><br><span class="line">        result[idx] = value; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>SPMD编程抽象：对ISPC函数的调用产生“一组”ISPC“程序实例”，所有实例同时运行ISPC代码，将数组元素“交错”分配给程序实例。返回后，所有实例都已完成。</p>
<p><img src="/img/1639825906.png" alt></p>
<p>ISPC关键字：</p>
<ul>
<li><code>programCount</code>：组中同时执行的实例数（统一值）</li>
<li><code>programIndex</code>：组中当前实例的id。（非均匀值：“变化”）</li>
<li><code>uniform</code>：类型修饰符。所有实例对此变量具有相同的值。它的使用纯粹是一种优化。不需要正确性。</li>
</ul>
<p>程序实例到循环迭代的交错分配<br><img src="/img/1639826639.jpg" alt></p>
<p>SPMD编程抽象：</p>
<ul>
<li>对ISPC函数的调用会产生一组ISPC“程序实例”</li>
<li>所有实例同时运行ISPC代码</li>
<li>返回后，所有实例都已完成</li>
</ul>
<p>ISPC编译器生成SIMD实现：</p>
<ul>
<li>组中的实例数是硬件的SIMD宽度（或SIMD宽度的小倍数）</li>
<li>ISPC编译器使用SIMD指令生成二进制（.o）</li>
<li>与常规文件一样的C++代码链接</li>
</ul>
<p>将元素“分块”分配给实例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> <span class="keyword">void</span> <span class="title">sinx</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">int</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">int</span> terms, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">float</span>* x, </span></span></span><br><span class="line"><span class="function"><span class="params">uniform <span class="keyword">float</span>* result)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="comment">// assume N % programCount = 0 </span></span><br><span class="line">    uniform <span class="keyword">int</span> count = N / programCount; </span><br><span class="line">    <span class="keyword">int</span> start = programIndex * count; </span><br><span class="line">    <span class="keyword">for</span> (uniform <span class="keyword">int</span> i=<span class="number">0</span>; i&lt;count; i++)</span><br><span class="line">    &#123; </span><br><span class="line">        <span class="keyword">int</span> idx = start + i; </span><br><span class="line">        <span class="keyword">float</span> value = x[idx]; </span><br><span class="line">        <span class="keyword">float</span> numer = x[idx] * x[idx] * x[idx]; </span><br><span class="line">        uniform <span class="keyword">int</span> denom = <span class="number">6</span>;  <span class="comment">// 3! </span></span><br><span class="line">        uniform <span class="keyword">int</span> sign = ‐<span class="number">1</span>; </span><br><span class="line">        <span class="keyword">for</span> (uniform <span class="keyword">int</span> j=<span class="number">1</span>; j&lt;=terms; j++) </span><br><span class="line">        &#123;  </span><br><span class="line">            value += sign * numer / denom </span><br><span class="line">            numer *= x[idx] * x[idx]; </span><br><span class="line">            denom *= (j+<span class="number">3</span>) * (j+<span class="number">4</span>); </span><br><span class="line">            sign *= ‐<span class="number">1</span>; </span><br><span class="line">        &#125;</span><br><span class="line">        result[idx] = value; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1639827312.png" alt></p>
<p>第一个版本是轮转的方式，使用<code>_mm_load_ps1</code>SSE指令为四个实例分别分配值，这四个元素在内存中是连续的，因此很高效。但是分块的方式在每次为四个实例分配值的时候，会按照“0，4，8，12”、“1，5，9，13”的方式分配，现在涉及内存中的四个非连续值。需要执行“gather”指令（gather是一种更复杂、更昂贵的SIMD指令：在2013年开始作为AVX2的一部分提供）</p>
<p>使用foreach提高抽象级别：foreach是关键的ISPC语言构造</p>
<ul>
<li>foreach声明并行循环迭代<ul>
<li>表示：这些是团队中的实例必须协同执行的迭代</li>
</ul>
</li>
<li>ISPC实现将迭代分配给组中的程序实例<ul>
<li>当前ISPC实现将执行静态交错分配</li>
</ul>
</li>
</ul>
<p>错误的sum 规约<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> uniform <span class="keyword">float</span> <span class="title">sumall1</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">int</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span>* x)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    uniform <span class="keyword">float</span> sum = <span class="number">0.0f</span>; </span><br><span class="line">    foreach (i = <span class="number">0</span> ... N) </span><br><span class="line">    &#123; </span><br><span class="line">       sum += x[i]; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> sum; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>正确的sum 规约<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> uniform <span class="keyword">float</span> <span class="title">sumall2</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">int</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span>* x)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    uniform <span class="keyword">float</span> sum; </span><br><span class="line">    <span class="keyword">float</span> partial = <span class="number">0.0f</span>; </span><br><span class="line">    foreach (i = <span class="number">0</span> ... N) </span><br><span class="line">    &#123; </span><br><span class="line">        partial += x[i]; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// from ISPC math library </span></span><br><span class="line">    sum = reduce_add(partial); </span><br><span class="line">    <span class="keyword">return</span> sum; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>sum的类型为<code>uniform float</code>（所有程序实例都有一个变量副本），<code>x[i]</code>不是统一表达式（每个程序实例的值不同）结果：编译时类型错误。</p>
<p>并行计算所有数组元素的总和。每个实例累积一个私有部分和（无通信）。</p>
<p>使用<code>reduce_add()</code>通信原语将部分和相加。结果是所有程序实例的总和相同（<code>reduce_add()</code>返回一个统一的浮点数）。</p>
<p>下面的ISPC代码将以类似于下面的手写C+AVX intrinsics实现的方式执行<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> uniform <span class="keyword">float</span> <span class="title">sumall2</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">int</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span>* x)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    uniform <span class="keyword">float</span> sum; </span><br><span class="line">    <span class="keyword">float</span> partial = <span class="number">0.0f</span>; </span><br><span class="line">    foreach (i = <span class="number">0</span> ... N) </span><br><span class="line">    &#123; </span><br><span class="line">        partial += x[i]; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// from ISPC math library </span></span><br><span class="line">    sum = reduce_add(partial); </span><br><span class="line">    <span class="keyword">return</span> sum; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">sumall2</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span>* x)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">float</span> tmp[<span class="number">8</span>];  <span class="comment">// assume 16­‐byte alignment </span></span><br><span class="line">    __mm256 partial = _mm256_broadcast_ss(<span class="number">0.0f</span>); </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i+=<span class="number">8</span>) </span><br><span class="line">        partial = _mm256_add_ps(partial, _mm256_load_ps(&amp;x[i]));</span><br><span class="line">    _mm256_store_ps(tmp, partial); </span><br><span class="line">    <span class="keyword">float</span> sum = <span class="number">0.f</span>; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">8</span>; i++) </span><br><span class="line">        sum += tmp[i];</span><br><span class="line">    <span class="keyword">return</span> sum; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>ISPC task</p>
<ul>
<li>ISPC组抽象由单核上的SIMD指令实现。</li>
<li>ISPC包含另一个抽象：用于实现多核执行的“task”。</li>
</ul>
<p>用pthreads表示并行性<br><img src="/img/1639828816.jpg" alt></p>
<p>用ISPC表示并行性：</p>
<ul>
<li>用于指定同时执行（真正的并行性）</li>
<li>用于指定独立工作（可能并行）</li>
</ul>
<p><img src="/img/1639828860.jpg" alt></p>
<p>三种通信模式</p>
<ol>
<li>共享地址空间</li>
<li>消息传递</li>
<li>数据并行</li>
</ol>
<p>共享地址空间模型（抽象）：</p>
<ul>
<li>线程通过读/写共享变量进行通信</li>
<li>共享变量就像一个大公告板<ul>
<li>任何线程都可以读取或写入共享变量</li>
</ul>
</li>
</ul>
<p>两个线程如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">int x = 0;</span><br><span class="line">spawn_thread(foo, &amp;x);</span><br><span class="line">x = 1;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">void foo(int* x) &#123; </span><br><span class="line">while (x == 0) &#123;&#125; </span><br><span class="line">    print x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/img/1639829805.jpg" alt></p>
<p>同步原语也是共享变量：例如锁<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> x = <span class="number">0</span>;</span><br><span class="line">Lock my_lock; </span><br><span class="line">spawn_thread(foo, &amp;x, &amp;my_lock); </span><br><span class="line">mylock.lock(); </span><br><span class="line">x++; </span><br><span class="line">mylock.unlock();</span><br></pre></td></tr></table></figure></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">foo</span><span class="params">(<span class="keyword">int</span>* x, lock* my_lock)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    my_lock‐&gt;lock();</span><br><span class="line">    x++; </span><br><span class="line">    my_lock­‐&gt;unlock(); </span><br><span class="line">    print x; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>共享地址空间模型（抽象）</p>
<ul>
<li>线程通过以下方式进行通信：<ul>
<li>读取/写入共享变量<ul>
<li>线程间通信隐含在内存操作中</li>
<li>线程1存储到X</li>
<li>稍后，线程2读取X（并观察线程1对值的更新）</li>
</ul>
</li>
<li>操作同步原语<ul>
<li>例如，通过使用锁确保相互排斥</li>
</ul>
</li>
</ul>
</li>
<li>这是顺序编程的自然扩展<ul>
<li>事实上，到目前为止，我们在课堂上的所有讨论都假设有一个共享的地址空间！</li>
</ul>
</li>
</ul>
<p>共享地址空间的硬件实现：每个处理器可以直接访问任何内存地址。<br><img src="/img/1639830087.png" alt></p>
<p>非统一内存访问（NUMA）</p>
<ul>
<li>所有处理器都可以访问任何内存位置，但是内存访问的成本（延迟和/或带宽）对于不同的处理器是不同的<ul>
<li>在系统中保持统一访问时间的问题：可扩展性<ul>
<li>好：开销是一致的，坏：它们是一致的坏（内存是一致的远）</li>
</ul>
</li>
<li>NUMA设计更具可扩展性<ul>
<li>对本地内存的低延迟访问</li>
<li>为本地内存提供高带宽</li>
</ul>
</li>
</ul>
</li>
<li>开销是程序员为性能调优所做的工作增加<ul>
<li>发现、利用局部性对性能非常重要（希望大多数内存访问都指向本地内存）</li>
</ul>
</li>
</ul>
<p><img src="/img/1639830216.jpg" alt></p>
<p>下面的图中对x的访问，如果x在1-4核上，访问开销远远小于5-8核。<br><img src="/img/1639830245.jpg" alt></p>
<p>消息传递（实现）</p>
<ul>
<li>流行软件库：MPI（消息传递接口）</li>
<li>硬件不需要实现系统范围的加载和存储来执行消息传递程序（只需要能够传递消息）</li>
</ul>
<p>ISPC中的数据并行</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ISPC code:</span></span><br><span class="line"><span class="function"><span class="keyword">export</span> <span class="keyword">void</span> <span class="title">absolute_value</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">int</span> N,</span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">float</span>* x,</span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">float</span>* y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    foreach(i = <span class="number">0</span> ... N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; <span class="number">0</span> &amp;&amp; x[i] &lt; <span class="number">0</span>)</span><br><span class="line">            y[i<span class="number">-1</span>] = x[i];</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            y[i] = x[i]; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将循环体视为函数，foreach构造是一个映射。给定此程序，可以将该程序视为将循环体映射到数组X和Y的每个元素上。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// main C++ code: </span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line"><span class="keyword">float</span>* x = <span class="keyword">new</span> <span class="keyword">float</span>[N]; </span><br><span class="line"><span class="keyword">float</span>* y = <span class="keyword">new</span> <span class="keyword">float</span>[N]; </span><br><span class="line"><span class="comment">// initialize N elements of x here </span></span><br><span class="line">absolute_value(N, x, y);</span><br></pre></td></tr></table></figure></p>
<p>但如果我们想说得更准确一些：该系列不是一流的ISPC概念。它是由程序如何实现数组索引逻辑隐式定义的。</p>
<p>这个程序是不确定的！循环体的多次迭代可能写入同一内存位置。数据并行模型（foreach）没有规定迭代发生的顺序，模型不提供用于细粒度互斥/同步的原语）。它不是为了帮助程序员用这种结构编写程序。</p>
<p>一种更“合适”的数据并行方法<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; x(N);  <span class="comment">// define collection </span></span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; y(N);  <span class="comment">// define collection </span></span><br><span class="line"><span class="comment">// initialize N elements of x here </span></span><br><span class="line"><span class="comment">// map function absolute_value onto </span></span><br><span class="line"><span class="comment">// streams (collections) x, y </span></span><br><span class="line">absolute_value(x, y);</span><br><span class="line"></span><br><span class="line"><span class="comment">// kernel: </span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">absolute_value</span><span class="params">(<span class="keyword">float</span> x, <span class="keyword">float</span> y)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">if</span> (x &lt; <span class="number">0</span>) </span><br><span class="line">        y = ‐x; </span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        y = x; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>注意：这不是ISPC语法（更多的是Kayvon编造的语法），以这种函数形式表示的数据并行性有时被称为流编程模型。</p>
<ul>
<li>stream：元素的集合。元素可以独立处理</li>
<li>kernel：没有副作用的函数。对集合进行元素操作</li>
</ul>
<p>gather/scatter：两个关键的数据并行通信原语</p>
<p>把absolute_value映射到gather产生的流上：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; input(N); </span><br><span class="line">stream&lt;<span class="keyword">int</span>&gt; indices; </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; tmp_input(N);   </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; output(N); </span><br><span class="line">stream_gather(input, indices, tmp_input);</span><br><span class="line">absolute_value(tmp_input, output);</span><br></pre></td></tr></table></figure></p>
<p>用ISPC 等价于:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> <span class="keyword">void</span> <span class="title">absolute_value</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span>* input, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">float</span>* output, </span></span></span><br><span class="line"><span class="function"><span class="params">   uniform <span class="keyword">int</span>* indices)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    foreach (i = <span class="number">0</span> ... n) </span><br><span class="line">    &#123; </span><br><span class="line">        <span class="keyword">float</span> tmp = input[indices[i]]; </span><br><span class="line">        <span class="keyword">if</span> (tmp &lt; <span class="number">0</span>) </span><br><span class="line">            output[i] = ‐tmp; </span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">            output[i] = tmp; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>把absolute_value映射到scatter的值上：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; input(N); </span><br><span class="line">stream&lt;<span class="keyword">int</span>&gt; indices; </span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; tmp_output(N);</span><br><span class="line">stream&lt;<span class="keyword">float</span>&gt; output(N); </span><br><span class="line">absolute_value(input, tmp_output); </span><br><span class="line">stream_scatter(tmp_output, indices, output);</span><br></pre></td></tr></table></figure></p>
<p>用ISPC等价于：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">export</span> <span class="keyword">void</span> <span class="title">absolute_value</span><span class="params">( </span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">float</span> N, </span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">float</span>* input, </span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">float</span>* output, </span></span></span><br><span class="line"><span class="function"><span class="params">    uniform <span class="keyword">int</span>* indices)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    foreach (i = <span class="number">0</span> ... n) </span><br><span class="line">    &#123; </span><br><span class="line">        <span class="keyword">if</span> (input[i] &lt; <span class="number">0</span>) </span><br><span class="line">            output[indices[i]] = ‐input[i]; </span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">            output[indices[i]] = input[i]; </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>gather操作：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gather(R1, R0, mem_base);</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1639835717.png" alt></p>
<p>概要：数据并行模型</p>
<ul>
<li>基本结构：将函数映射到大量数据集合上<ul>
<li>功能性：无副作用执行</li>
<li>不同函数调用之间没有通信（允许以任何顺序调度调用，包括并行调度）</li>
</ul>
</li>
<li>实际上，这就是许多简单程序的工作原理</li>
<li>但是许多现代面向性能的数据并行语言并不严格执行这种结构<ul>
<li>ISPC、OpenCL、CUDA等。</li>
<li>他们选择命令式C风格语法的灵活性/熟悉性，而不是功能更强大的形式的安全性：这是他们采用命令式C风格的关键</li>
<li>观点：功能性思维是很好的，但编程系统确实应该采用结构来促进实现高性能的实现，而不是阻碍它们</li>
</ul>
</li>
</ul>
<p>现代实践：混合编程模型</p>
<ul>
<li>在集群的多核节点内使用共享地址空间编程，在节点之间使用消息传递<ul>
<li>在实践中非常非常普遍</li>
<li>使用共享地址空间的便利性（在节点内）可以有效地实现，需要在其他地方进行显式通信</li>
</ul>
</li>
<li>数据并行编程模型支持内核中的共享内存式同步原语<ul>
<li>允许有限形式的迭代间通信（如CUDA、OpenCL）</li>
</ul>
</li>
<li>CUDA/OpenCL使用数据并行模型扩展到多个内核，但采用共享地址空间模型，允许在同一内核上运行的线程进行通信。</li>
</ul>
<h1 id="lecture-4"><a href="#lecture-4" class="headerlink" title="lecture 4"></a>lecture 4</h1><p>如何创建一个并行程序</p>
<ul>
<li>剖分</li>
<li>分配给线程/进程<ul>
<li>负载平衡，可以动态/静态分配</li>
</ul>
</li>
<li>编排依赖关系</li>
<li>在并行机器上并行执行，通信</li>
</ul>
<p>阿姆达尔定律：依赖性限制了并行性带来的最大加速比</p>
<ul>
<li>运行顺序程序。。。</li>
<li>设S=固有顺序的顺序执行部分（依赖项阻止并行执行）</li>
<li>然后是并行执行带来的最大加速≤ 1/S</li>
</ul>
<p>一个使用pthread的例子，进行了任务的划分：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span> </span><br><span class="line">    <span class="keyword">int</span> N, terms; </span><br><span class="line">    <span class="keyword">float</span>* x, *result; </span><br><span class="line">&#125; my_args; </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">parallel_sinx</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span> terms, <span class="keyword">float</span>* x, <span class="keyword">float</span>* result)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    <span class="keyword">pthread_t</span> thread_id; </span><br><span class="line">    my_args args; </span><br><span class="line">    args.N = N/<span class="number">2</span>; </span><br><span class="line">    args.terms = terms; </span><br><span class="line">    args.x = x; </span><br><span class="line">    args.result = result; </span><br><span class="line">    <span class="comment">// launch second thread, do work on first half of array </span></span><br><span class="line">    pthread_create(&amp;thread_id, <span class="literal">NULL</span>, my_thread_start, &amp;args);</span><br><span class="line">    <span class="comment">// do work on second half of array in main thread</span></span><br><span class="line">    sinx(N ‐ args.N, terms, x + args.N, result + args.N);</span><br><span class="line">    pthread_join(thread_id, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">my_thread_start</span><span class="params">(<span class="keyword">void</span>* thread_arg)</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    my_args* thread_args = (my_args*)thread_arg; </span><br><span class="line">    sinx(args‐&gt;N, args‐&gt;terms, args‐&gt;x, args‐&gt;result); <span class="comment">// do work </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>循环迭代分解任务</p>
<ul>
<li>静态分配</li>
<li>以块的方式（一个连续的部分）将迭代各步分配给pthreads（数组的前半部分分配给派生线程，后半部分分配给主线程）</li>
</ul>
<p>使用ISPC task进行动态分配：ISPC在运行时将任务分配给工作线程</p>
<ul>
<li>分配策略：完成当前任务后，工作线程检查列表并为自己分配下一个未完成的任务。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">void foo(uniform float* input, </span><br><span class="line">         uniform float* output, </span><br><span class="line">         uniform int N) </span><br><span class="line">&#123; </span><br><span class="line">    // create a bunch of tasks</span><br><span class="line">    launch[100] my_ispc_task(input, output, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编排Orchestration</p>
<ul>
<li>涉及：<ul>
<li>结构化通信</li>
<li>如有必要，添加同步以保留依赖项</li>
<li>在内存中组织数据结构</li>
<li>调度任务</li>
</ul>
</li>
<li>目标：降低通信/同步成本，保留数据引用的位置，减少开销等。</li>
<li>机器细节会影响许多决策<ul>
<li>如果同步比较昂贵，可能会少用</li>
</ul>
</li>
</ul>
<p>映射到硬件</p>
<ul>
<li>将“线程”（“工作线程”）映射到硬件执行单元</li>
<li>示例1：操作系统映射<ul>
<li>例如，将pthread映射到CPU核心上的硬件执行上下文</li>
</ul>
</li>
<li>示例2：编译器的映射<ul>
<li>将ISPC程序实例映射到向量指令通道</li>
</ul>
</li>
<li>示例3：硬件映射<ul>
<li>将CUDA线程块映射到GPU内核</li>
</ul>
</li>
<li>一些有趣的映射决策：<ul>
<li>将相关线程（协作线程）放在同一处理器上（最大化本地性、数据共享、最小化通信/同步成本）</li>
<li>将不相关的线程放在同一个处理器上（一个可能是带宽受限的，另一个可能是计算受限的），以更有效地使用机器</li>
</ul>
</li>
</ul>
<p>共享地址空间表达式</p>
<ul>
<li>程序员负责同步</li>
<li>通用同步原语：<ul>
<li>锁（提供互斥）：一次仅在关键区域中有一个线程</li>
<li>barrier：等待线程到达此点<ul>
<li>barrier是表示依赖关系的一种保守方式</li>
<li>barrier将计算分为几个阶段</li>
<li>在barrier开始后的任何线程中的任何计算之前，barrier之前所有线程的所有计算都已完成</li>
</ul>
</li>
</ul>
</li>
<li>保持原子性的机制<ul>
<li>锁定/解锁关键部分周围的互斥锁</li>
<li>硬件支持的原子读修改写操作的内部函数</li>
<li>有些语言对代码块的原子性具有一流的支持<code>atmoic</code></li>
</ul>
</li>
</ul>
<h1 id="lecture-5"><a href="#lecture-5" class="headerlink" title="lecture 5"></a>lecture 5</h1><p>GPU结构和CUDA编程</p>
<p>在CPU上，操作系统把程序加载到内存中，选择CPU的执行上下文，执行中断，加载上下文，运行。在GPU上，</p>
<p>NVIDIA Tesla architecture（2007）</p>
<ul>
<li>第一个GPU硬件的非图形特定（“计算模式”）接口（GeForce 8xxx系列GPU）</li>
<li>应用程序可以在GPU内存中分配缓冲区，并将数据复制到缓冲区或从缓冲区复制数据</li>
<li>应用程序（通过图形驱动程序）为GPU提供单一内核二进制程序</li>
<li>应用程序告诉GPU以SPMD模式“运行N个实例”</li>
</ul>
<p>CUDA程序由并发线程的层次结构组成，线程ID可以是三维的（下面的2D示例）。多维线程ID对于自然为N-D的问题非常方便。</p>
<p><img src="/img/1639839915.jpg" alt></p>
<p>基本的CUDA语法：</p>
<ul>
<li>主机和设备执行的代码是被程序员人为分开的</li>
<li>host代码：串行执行<ul>
<li>在CPU上作为普通C/C++应用程序的一部分运行</li>
<li>最后一行代码大量启动多个CUDA线程，“启动CUDA线程块网格”，调用在所有线程终止时返回</li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> Nx = <span class="number">12</span>; </span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> Ny = <span class="number">6</span>;</span><br><span class="line"><span class="function">dim3 <span class="title">threadsPerBlock</span><span class="params">(<span class="number">4</span>, <span class="number">3</span>, <span class="number">1</span>)</span></span>; </span><br><span class="line"><span class="function">dim3 <span class="title">numBlocks</span><span class="params">(Nx/threadsPerBlock.x, </span></span></span><br><span class="line"><span class="function"><span class="params">               Ny/threadsPerBlock.y, <span class="number">1</span>)</span></span>; </span><br><span class="line"><span class="comment">// assume A, B, C are allocated Nx x Ny float arrays </span></span><br><span class="line"><span class="comment">// this call will trigger execution of 72 CUDA threads:</span></span><br><span class="line"><span class="comment">// 6 thread blocks of 12 threads each  </span></span><br><span class="line">matrixAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C);</span><br></pre></td></tr></table></figure>
<ul>
<li>设备内核函数(device kernel function)的SPMD执行：<ul>
<li>每个线程从其在其块中的位置（threadIdx）和其块在网格中的位置（blockIdx）计算其整个网格线程id。</li>
<li>device代码：内核函数（<code>__global__</code>表示CUDA内核函数）在GPU上运行</li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">device__ <span class="keyword">float</span> <span class="title">doubleValue</span><span class="params">(<span class="keyword">float</span> x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span> * x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// kernel definition </span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">matrixAdd</span><span class="params">(<span class="keyword">float</span> A[Ny][Nx], </span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">float</span> B[Ny][Nx], </span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">float</span> C[Ny][Nx])</span> </span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">   <span class="keyword">int</span> i = blockIdx.x * blockDim.x + threadIdx.x; </span><br><span class="line">   <span class="keyword">int</span> j = blockIdx.y * blockDim.y + threadIdx.y; </span><br><span class="line">   C[j][i] = A[j][i] + doubleValue(B[j][i]);</span><br></pre></td></tr></table></figure>
<p>SPMD线程数在程序中是显式的，内核调用的数量不是由数据的大小决定。</p>
<p>CUDA中GPU设备的内存和CPU的内存是完全分开的，需要数据时用<code>cudaMemcpy</code>从CPU中拷到GPU上。</p>
<p>CUDA中有三种不同的内存</p>
<ul>
<li>每个线程自己的内存，只能被线程读写</li>
<li>每个block自己的内存，能被block中所有的线程读写</li>
<li>全局内存，能被所有的线程读写。</li>
</ul>
<p>举例子：1D卷积：<code>output[i] = (input[i] + input[i+1] + input[i+2]) / 3.f</code><br><img src="/img/1639840798.png" alt></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THREADS_PER_BLK 128</span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convolve</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span>* input, <span class="keyword">float</span>* output)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">int</span> index = blockIdx.x * blockDim.x + threadIdx.x; <span class="comment">// thread local variable </span></span><br><span class="line">    <span class="keyword">float</span> result = <span class="number">0.0f</span>; <span class="comment">// thread-­‐local variable </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">3</span>; i++) <span class="comment">// each thread computes result for one element</span></span><br><span class="line">        result += input[index + i]; </span><br><span class="line">    output[index] = result / <span class="number">3.f</span>; <span class="comment">// write result to global memory</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>host上的代码：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> N = <span class="number">1024</span> * <span class="number">1024</span> </span><br><span class="line">cudaMalloc(&amp;devInput, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * (N+<span class="number">2</span>) ); <span class="comment">// allocate array in device memory </span></span><br><span class="line">cudaMalloc(&amp;devOutput, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N); <span class="comment">// allocate array in device memory </span></span><br><span class="line"><span class="comment">// property initialize contents of devInput here ... </span></span><br><span class="line">convolve&lt;&lt;&lt;N/THREADS_PER_BLK, THREADS_PER_BLK&gt;&gt;&gt;(N, devInput, devOutput);</span><br></pre></td></tr></table></figure></p>
<p>每个输出元素一个线程：在每个块共享内存中暂存输入数据<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THREADS_PER_BLK 128 </span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convolve</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span>* input, <span class="keyword">float</span>* output)</span> </span>&#123; </span><br><span class="line">    __shared__ <span class="keyword">float</span> support[THREADS_PER_BLK+<span class="number">2</span>];           <span class="comment">// per-­‐block allocation</span></span><br><span class="line">    <span class="keyword">int</span> index = blockIdx.x * blockDim.x + threadIdx.x; <span class="comment">// thread local variable </span></span><br><span class="line">    support[threadIdx.x] = input[index]; </span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x &lt; <span class="number">2</span>) &#123; </span><br><span class="line">        support[THREADS_PER_BLK + threadIdx.x] = input[index+THREADS_PER_BLK];</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="comment">// 所有线程协同地将块的支持区域从全局内存加载到共享内存中（总共130条加载指令，而不是3*128条加载指令）</span></span><br><span class="line"></span><br><span class="line">    __syncthreads(); <span class="comment">// barrier (all threads in block)</span></span><br><span class="line">    <span class="keyword">float</span> result = <span class="number">0.0f</span>;   <span class="comment">// thread-­‐local variable </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">3</span>; i++)</span><br><span class="line">        result += support[threadIdx.x + i]; </span><br><span class="line">    output[index] = result / <span class="number">3.f</span>; <span class="comment">// write result to global memory</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>CUDA同步结构</p>
<ul>
<li><code>__syncthread()</code><ul>
<li>屏障：等待块中的所有线程到达该点</li>
</ul>
</li>
<li>原子操作<ul>
<li>例如，<code>float atomicAdd(float* addr, float amount)</code></li>
<li>全局内存和共享内存变量上的原子操作</li>
</ul>
</li>
<li>主机/设备同步<ul>
<li>内核返回时跨越所有线程的隐式屏障</li>
</ul>
</li>
</ul>
<p>CUDA摘要</p>
<ul>
<li>执行：线程层次结构<ul>
<li>大量启动多个线程</li>
<li>两级层次结构：线程被分组到线程块中</li>
</ul>
</li>
<li>分布式地址空间<ul>
<li>用于在主机和设备地址空间之间复制的内置memcpy原语</li>
<li>三种不同类型的设备地址空间</li>
<li>分为三个层级的内存：每个线程、每个块（“共享”）或每个程序（“全局”）</li>
</ul>
</li>
<li>线程块中线程的屏障同步原语</li>
<li>用于附加同步的原子原语（共享和全局变量）</li>
</ul>
<p>启动超过100万个CUDA线程（超过8K个线程块）<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THREADS_PER_BLK 128 </span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">convolve</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span>* input, <span class="keyword">float</span>* output)</span> </span>&#123; </span><br><span class="line">__shared__ <span class="keyword">float</span> support[THREADS_PER_BLK+<span class="number">2</span>];  <span class="comment">// per-­‐block allocation</span></span><br><span class="line">    <span class="keyword">int</span> index = blockIdx.x * blockDim.x + threadIdx.x; <span class="comment">// thread local var</span></span><br><span class="line">    support[threadIdx.x] = input[index]; </span><br><span class="line">    <span class="keyword">if</span> (threadIdx.x &lt; <span class="number">2</span>) &#123; </span><br><span class="line">        support[THREADS_PER_BLK+threadIdx.x] = input[index+THREADS_PER_BLK];   </span><br><span class="line">    &#125; </span><br><span class="line">    __syncthreads(); </span><br><span class="line">    <span class="keyword">float</span> result = <span class="number">0.0f</span>;   <span class="comment">// thread-­‐local variable </span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">3</span>; i++)</span><br><span class="line">        result += support[threadIdx.x + i]; </span><br><span class="line">    output[index] = result / <span class="number">3.f</span>; </span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">// host code ////////////////////////////////////////////////////// </span></span><br><span class="line"><span class="keyword">int</span> N = <span class="number">1024</span> * <span class="number">1024</span>; </span><br><span class="line">cudaMalloc(&amp;devInput, N+<span class="number">2</span>);   <span class="comment">// allocate array in device memory </span></span><br><span class="line">cudaMalloc(&amp;devOutput, N);    <span class="comment">// allocate array in device memory </span></span><br><span class="line"><span class="comment">// property initialize contents of devInput here ... </span></span><br><span class="line">convolve&lt;&lt;&lt;N/THREADS_PER_BLK, THREADS_PER_BLK&gt;&gt;&gt;(N, devInput, devOutput);</span><br></pre></td></tr></table></figure></p>
<p>8k个线程blocks分布在Grid上，blocks所需资源：（包含在已编译的内核二进制文件中）</p>
<ul>
<li>128线程</li>
<li>520字节的共享内存</li>
<li>（128 x B）字节的本地内存</li>
</ul>
<p>从主机中执行的启动命令<code>launch(blockDim, convolve)</code></p>
<ul>
<li>主要CUDA假设：线程块执行可以以任何顺序执行（块之间没有依赖关系）</li>
<li>GPU实现使用尊重资源需求的动态调度策略将线程块（“工作”）映射到内核</li>
</ul>
<p><img src="/img/1639844349.jpg" alt></p>
<p>我们常见设计模式的另一个实例：</p>
<ul>
<li>最佳实践：创建足够的worker来“填充”并行机，不再：<ul>
<li>每个并行执行资源（例如，CPU核心、核心执行上下文）一个worker thread</li>
<li>每个核心可能需要N个工作线程（其中N足够大，可以隐藏内存/IO延迟）</li>
<li>为每个worker预先分配资源</li>
<li>动态地将任务分配给工作线程（对许多任务重用分配）</li>
</ul>
</li>
<li>其他例子：<ul>
<li>ISPC执行发射任务的情况</li>
<li>为CPU上的每个超线程创建一个pthread。线程在程序的其余部分保持活动状态</li>
<li>线程数是内核数的函数，而不是未完成请求数的函数</li>
</ul>
</li>
</ul>
<p><img src="/img/1639844935.jpg" alt></p>
<p>回想一下，CUDA内核作为SPMD程序执行。在NVIDIA GPU上，32个CUDA线程组共享一个指令流。这些组织被称为“warp”。</p>
<p><code>convolve</code>线程块由4个warp执行（4个warp x 32个线程/warp = 每个block 128个CUDA线程）（WAPS是一个重要的GPU实现细节，但不是CUDA抽象！）</p>
<p>每个时钟时SMX核心操作：</p>
<ul>
<li>从驻留在SMM core上的64个线程中选择最多四个可运行的warp（线程级并行）</li>
<li>每个warp最多选择两条可运行指令（指令级并行）</li>
</ul>
<p>运行GPU的流程：</p>
<ul>
<li><code>convolve</code>的运行需要：<ul>
<li>每个线程block必须执行128个线程</li>
<li>每个线程block必须分配130*sizeof(float)=520Bytes内存</li>
<li>让我们假设数组大小N非常大，因此主机端内核启动会生成数千个线程块。</li>
<li><code>#define THREADS_PER_BLK 128</code></li>
<li><code>convolve&lt;&lt;&lt;N/THREADS_PER_BLK,  THREADS_PER_BLK&gt;&gt;&gt;(N, input_array, output_array);</code></li>
</ul>
</li>
<li>步骤1：主机向CUDA设备（GPU）发送命令（“执行此内核”）</li>
</ul>
<p><img src="/img/1639845602.jpg" alt></p>
<ul>
<li>步骤2：调度器将块0映射到核心0（为128个线程和520字节的共享存储保留执行上下文）</li>
<li>步骤3：调度器继续将块映射到可用的执行上下文（显示交错映射）</li>
</ul>
<p><img src="/img/1639845791.jpg" alt></p>
<ul>
<li>步骤3：调度器继续将块映射到可用的执行上下文（显示交错映射）。一个内核上只能容纳两个线程块（第三个线程块无法容纳，因为共享存储不足3 x 520字节&gt;1.5 KB）</li>
</ul>
<p><img src="/img/1639845945.jpg" alt></p>
<ul>
<li>步骤4：线程块0在核心0上完成</li>
</ul>
<p><img src="/img/1639846029.jpg" alt></p>
<ul>
<li>步骤5：在核心0上调度块4（映射到执行上下文0-127）</li>
<li>步骤6：线程块2在核心0上完成</li>
<li>步骤7：线程块5在核心0上调度（映射到执行上下文128-255）</li>
</ul>
<p><img src="/img/1639846114.jpg" alt></p>
<p>复习：什么是“warp”？</p>
<ul>
<li>warp是NVIDIA GPU上的CUDA实现细节</li>
<li>在现代NVIDIA硬件上，线程块中32个CUDA线程组使用32宽SIMD执行同时执行。<ul>
<li>这32个逻辑CUDA线程共享一个指令流，因此由于执行不一致，性能可能会受到影响。</li>
<li>此映射类似于ISPC在一个组中运行程序实例的方式。</li>
</ul>
</li>
<li>共享一个指令流的32个线程组称为warp。<ul>
<li>在thread block 中，thread0-31落在同一warp中（thread32-63等也落在同一warp中）</li>
<li>因此，包含256个CUDA线程的线程块映射到8个warp。</li>
<li>我们上次讨论的GTX 980中的每个“SMM”核心都能够调度和交错执行多达64个warp。</li>
<li>因此，“SMM”内核能够并发执行多个CUDA线程块。</li>
</ul>
</li>
</ul>
<p>在这个虚构的NVIDIA GPU示例中：Core维护12个warp的上下文，并选择一个warp来运行每个时钟<br><img src="/img/1639846224.jpg" alt></p>
<p>为什么为block中的所有线程分配执行上下文？</p>
<ul>
<li>假设一个线程块有256个CUDA线程</li>
<li>假设一个虚构的SMM内核，在硬件中只有4个可并行执行的warp（如上图所示）</li>
<li>为什么不运行四个warp（线程0-127）以完成，然后运行下四个warp（线程128-255）以完成，以便执行整个线程块？</li>
</ul>
<p>因为CUDA内核可能会在块中的线程之间创建依赖关系。</p>
<ul>
<li>最简单的例子是<code>__syncthreads()</code></li>
<li>当存在依赖项时，系统不能以任何顺序执行块中的线程。</li>
<li>CUDA语义：块中的线程同时运行。如果块中的线程是可运行的，那么它最终将运行！（没有deadlock）</li>
</ul>
<p>CUDA抽象的实现</p>
<ul>
<li>系统可以按任何顺序安排线程块<ul>
<li>系统假定块之间没有依赖关系</li>
<li>逻辑并发</li>
</ul>
</li>
<li>同一块中的CUDA线程不会同时运行<ul>
<li>当块开始执行时，所有线程都在运行（这些语义对系统施加调度约束）</li>
<li>CUDA线程块本身就是一个SPMD程序（类似于一组ISPC程序实例）</li>
<li>线程块中的线程是并发的、协作的“工作线程”</li>
</ul>
</li>
<li>CUDA实施：<ul>
<li>GPU warp具有类似于ISPC实例组的性能特征（但与ISPC实例组不同，warp概念不存在于编程模型）</li>
<li>线程块中的所有warp都调度到同一个内核上，允许通过共享内存变量进行高带宽/低延迟通信</li>
<li>当块中的所有线程完成时，块资源（共享内存分配、warp执行上下文）将可用于下一个块</li>
</ul>
</li>
</ul>
<p>CUDA摘要</p>
<ul>
<li>执行语义<ul>
<li>将问题划分为线程块符合数据并行模型的精神（旨在与机器无关：系统将块调度到任意数量的核上）</li>
<li>线程块中的线程实际上是并发运行的（它们必须并发运行，因为它们相互协作）</li>
<li>单线程块内部：SPMD共享地址空间编程</li>
<li>这些执行模式之间存在细微但显著的差异。</li>
</ul>
</li>
<li>内存语义<ul>
<li>分布式地址空间：主机/设备存储器</li>
<li>设备内存中的线程本地/块共享/全局变量</li>
<li>加载/存储在它们之间移动数据（因此将本地/共享/全局内存视为不同的地址空间是正确的）</li>
</ul>
</li>
<li>主要实施细节：<ul>
<li>线程块中的线程被调度到同一GPU内核上，以允许通过共享内存进行快速通信</li>
<li>线程块中的线程被分组为warp，以便在GPU硬件上执行SIMD</li>
</ul>
</li>
</ul>
<h1 id="lecture-6"><a href="#lecture-6" class="headerlink" title="lecture 6"></a>lecture 6</h1><p>高性能编程</p>
<ul>
<li>优化并行程序的性能是一个优化分解、分配和编排选择的迭代过程</li>
<li>关键目标<ul>
<li>将工作负载平衡到可用的执行资源上</li>
<li>减少通信（避免停顿）</li>
<li>减少额外的工作（开销），以提高并行性、管理分配、减少通信等。</li>
</ul>
</li>
</ul>
<p>平衡各进程间的工作量</p>
<ul>
<li>理想情况下：所有处理器在程序执行期间都在计算（它们同时计算，同时完成部分工作）</li>
<li>回顾阿姆达尔定律：<ul>
<li>少量的负载不平衡就能显著限制最大加速比</li>
<li>P4多做20%的工作→P4完成所需时间延长20%→并行程序的20%运行是串行执行，就很严重了。</li>
</ul>
</li>
</ul>
<p><img src="/img/1639880273.jpg" alt></p>
<p>静态赋值</p>
<ul>
<li>线程的工作分配是预先确定的<ul>
<li>不一定在编译时确定（分配算法可能取决于运行时参数，如输入数据大小、线程数等）</li>
</ul>
</li>
<li>示例：为每个线程分配相等数量的网格单元<ul>
<li>我们讨论了两种静态工作分配（分块和交替）</li>
</ul>
</li>
<li>静态赋值的良好特性：简单，基本上零运行时开销（在本例中：实现赋值的额外工作是一点索引的计算）</li>
</ul>
<p><img src="/img/1639880425.jpg" alt></p>
<p>静态分配何时适用？</p>
<ul>
<li>当工作的成本（执行时间）和工作量是可预测的（这样程序员就可以提前完成一个好的任务）</li>
<li>当工作是可预测的，但不是所有的工作都有相同的开销</li>
<li>当已知执行时间统计信息时（例如，平均成本相同）</li>
</ul>
<p>“半静态”分配</p>
<ul>
<li>工作成本在短期内是可预测的<ul>
<li>想法：最近的过去很好地预测了不久的将来</li>
</ul>
</li>
<li>应用程序定期配置应用程序并重新调整分配<ul>
<li>对于重新调整之间的间隔，分配是“静态”的</li>
</ul>
</li>
<li>自适应网格：网格随着对象移动或流过对象的更改而更改，但更改速度较慢（颜色表示网格部分已分配给处理器）</li>
<li>粒子模拟：粒子在模拟过程中移动时重新分布（如果运动缓慢，则不需要经常进行重新分布）</li>
</ul>
<p><img src="/img/1639880672.jpg" alt></p>
<p>动态分配：程序在运行时动态确定分配，以确保负载分布均匀。（任务的执行时间或任务总数是不可预测的。）</p>
<p>顺序程序（独立循环迭代）<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line"><span class="keyword">int</span>* x = <span class="keyword">new</span> <span class="keyword">int</span>[N]; </span><br><span class="line"><span class="keyword">bool</span>* prime = <span class="keyword">new</span> <span class="keyword">bool</span>[N]; </span><br><span class="line"><span class="comment">// initialize elements of x here</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) </span><br><span class="line">&#123; </span><br><span class="line">    <span class="comment">// unknown execution time </span></span><br><span class="line">    is_prime[i] = test_primality(x[i]); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>并行程序（多线程执行SPMD，共享地址空间模型）<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> N = <span class="number">1024</span>; </span><br><span class="line"><span class="comment">// assume allocations are only executed by 1 thread</span></span><br><span class="line"><span class="keyword">int</span>* x = <span class="keyword">new</span> <span class="keyword">int</span>[N]; </span><br><span class="line"><span class="keyword">bool</span>* is_prime = <span class="keyword">new</span> <span class="keyword">bool</span>[N];</span><br><span class="line"><span class="comment">// initialize elements of x here</span></span><br><span class="line">LOCK counter_lock; </span><br><span class="line"><span class="keyword">int</span> counter = <span class="number">0</span>; <span class="comment">// shared variable</span></span><br><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123; </span><br><span class="line">    <span class="keyword">int</span> i; </span><br><span class="line">    lock(counter_lock); </span><br><span class="line">    i = counter++; </span><br><span class="line">    unlock(counter_lock);</span><br><span class="line">    <span class="keyword">if</span> (i &gt;= N) </span><br><span class="line">        <span class="keyword">break</span>; </span><br><span class="line">    is_prime[i] = test_primality(x[i]); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>使用工作队列的动态分配</p>
<ul>
<li>子问题（也称为“任务”、“工作”）</li>
<li>共享工作队列：要做的工作的列表（现在，让我们假设每个工作都是独立的）</li>
<li>工作线程：从共享工作队列中提取数据，在创建新工作时将其推送到队列中</li>
</ul>
<p>在分配任务时，如果是一个元素就分配一次的话，可能具有良好的工作负载平衡（许多小任务），但是可能导致高同步成本（关键部分的序列化）。因此可以每多少个元素成为一个任务，降低同步或者加锁的开销。</p>
<p>选择任务大小</p>
<ul>
<li>拥有比处理器多得多的任务非常有用（许多小任务通过动态分配实现良好的工作负载平衡）</li>
<li>但希望尽可能少的任务，以最大限度地减少<ul>
<li>鼓励大粒度任务</li>
</ul>
</li>
<li>理想的粒度取决于许多因素，必须了解您的工作负载和您的机器</li>
</ul>
<p>如果某些任务比其他任务更耗时，不平衡问题的一种可能解决方案：</p>
<ul>
<li>将工作划分为大量较小的任务<ul>
<li>希望最长的任务相对于总执行时间变得更短</li>
<li>可能会增加同步开销</li>
<li>可能不可能（也许长任务基本上是连续的）</li>
</ul>
</li>
<li>另一个解决方案：智能调度<ul>
<li>先安排长任务</li>
<li>执行长任务的线程执行的总体任务较少，但与其他线程的工作量大致相同。</li>
<li>需要一些工作量方面的知识（一些成本的可预测性）</li>
</ul>
</li>
</ul>
<p>使用一组分布式队列减少同步开销（避免所有work在单个工作队列上同步），工作线程需要：</p>
<ul>
<li>从自己的工作队列中提取数据</li>
<li>将新工作推送到自己的工作队列</li>
<li>当本地工作队列为空时从另一个工作队列窃取工作</li>
</ul>
<p><img src="/img/1639882716.jpg" alt></p>
<p>分布式工作队列</p>
<ul>
<li>窃取期间会发生代价高昂的同步/通信<ul>
<li>但并非每次线程都有新的工作</li>
<li>只有在确保良好负载平衡的必要情况下才会发生抢夺</li>
</ul>
</li>
<li>导致局部性增加（好事啊）<ul>
<li>常见情况：线程处理它们创建的任务（生产者-消费者位置）</li>
</ul>
</li>
<li>实施挑战<ul>
<li>偷谁的？</li>
<li>偷多少？</li>
<li>如何检测程序终止？</li>
<li>确保本地队列访问速度快（同时保持互斥）</li>
</ul>
</li>
</ul>
<p>总结</p>
<ul>
<li>挑战：实现良好的工作负载平衡<ul>
<li>希望所有处理器始终工作（否则，资源将处于空闲状态！）</li>
<li>但我们需要低成本的解决方案来实现这一平衡</li>
<li>最小化计算开销（例如，调度/分配逻辑）</li>
<li>最小化同步成本</li>
</ul>
</li>
<li>静态分配与动态分配<ul>
<li>尽可能使用有关工作负载的预先知识，以减少负载不平衡和任务管理/同步成本（在极限情况下，如果系统知道一切，则使用完全静态分配）</li>
</ul>
</li>
</ul>
<p>通用并行编程模式</p>
<ul>
<li>线程并行性的显式管理：<ul>
<li>每个执行单元（或每个所需并发量）创建一个线程</li>
<li>下面的示例：带有pthreads的C代码</li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">thread_args</span> &#123;</span> </span><br><span class="line">    <span class="keyword">float</span>* A; </span><br><span class="line">    <span class="keyword">float</span>* B; </span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">int</span> thread_id[MAX_THREADS]; </span><br><span class="line">thread_args args; </span><br><span class="line">args.A = A; </span><br><span class="line">args.B = B; </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;num_cores; i++) &#123; </span><br><span class="line">    pthread_create(&amp;thread_id[i], <span class="literal">NULL</span>, myFunctionFoo, &amp;args); </span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;num_cores; i++) &#123; </span><br><span class="line">    pthread_join(&amp;thread_id[i]); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>考虑分治算法<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sort elements from ‘begin’ up to (but not including) ‘end’ </span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quick_sort</span><span class="params">(<span class="keyword">int</span>* begin, <span class="keyword">int</span>* end)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">if</span> (begin &gt;= end-­‐<span class="number">1</span>)  </span><br><span class="line">        <span class="keyword">return</span>; </span><br><span class="line">    <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="comment">// choose partition key and partition elements </span></span><br><span class="line">        <span class="comment">// by key, return position of key as `middle` </span></span><br><span class="line">        <span class="keyword">int</span>* middle = partition(begin, end);  </span><br><span class="line">        quick_sort(begin, middle); </span><br><span class="line">        quick_sort(middle+<span class="number">1</span>, last); </span><br><span class="line">        <span class="comment">// independent work</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>fork-join模式</p>
<ul>
<li>表示分治算法固有的独立工作的自然方式</li>
<li>本课程的代码示例将使用Cilk Plus<ul>
<li>C++语言扩展</li>
<li>最初由麻省理工学院开发，现在改为开放标准（在GCC、英特尔ICC中）</li>
</ul>
</li>
</ul>
<p><code>cilk_spawn foo(args)</code>：</p>
<ul>
<li>语义：调用<code>foo</code>，但与标准函数调用不同，调用方可以继续异步执行<code>foo</code>。</li>
</ul>
<p><code>cilk_sync</code>：</p>
<ul>
<li>语义：当前函数生成的所有调用完成时返回。</li>
<li>注意：在包含<code>cilk_sync</code>的每个函数的末尾都有一个隐式<code>cilk_barrier</code>（暗示：当cilk函数返回时，与该函数相关的所有工作都已完成）</li>
</ul>
<p>基本Cilk示例<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo() and bar() may run in parallel</span></span><br><span class="line"><span class="function">cilk_spawn <span class="title">foo</span><span class="params">()</span></span>; </span><br><span class="line">bar(); </span><br><span class="line">cilk_sync;</span><br></pre></td></tr></table></figure></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo() and bar() may run in parallel </span></span><br><span class="line"><span class="function">cilk_spawn <span class="title">foo</span><span class="params">()</span></span>; </span><br><span class="line"><span class="function">cilk_spawn <span class="title">bar</span><span class="params">()</span></span>; </span><br><span class="line">cilk_sync;</span><br></pre></td></tr></table></figure>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// foo, bar, fizz, buzz, may run in parallel </span></span><br><span class="line"><span class="function">cilk_spawn <span class="title">foo</span><span class="params">()</span></span>; </span><br><span class="line"><span class="function">cilk_spawn <span class="title">bar</span><span class="params">()</span></span>; </span><br><span class="line"><span class="function">cilk_spawn <span class="title">fizz</span><span class="params">()</span></span>; </span><br><span class="line">buzz(); </span><br><span class="line">cilk_sync;</span><br></pre></td></tr></table></figure>
<p><img src="/img/1639883901.jpg" alt></p>
<p>Cilk Plus中的并行快速排序</p>
<p>如果问题规模足够小，则按顺序排序（生成的开销超过了潜在并行化的好处）<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quick_sort</span><span class="params">(<span class="keyword">int</span>* begin, <span class="keyword">int</span>* end)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">if</span> (begin &gt;= end -­‐ PARALLEL_CUTOFF) </span><br><span class="line">        <span class="built_in">std</span>::sort(begin, end); </span><br><span class="line">    <span class="keyword">else</span> &#123; </span><br><span class="line">        <span class="keyword">int</span>* middle = partition(begin, end);  </span><br><span class="line">        <span class="function">cilk_spawn <span class="title">quick_sort</span><span class="params">(begin, middle)</span></span>; </span><br><span class="line">        quick_sort(middle+<span class="number">1</span>, last); </span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1639884148.jpg" alt></p>
<p>编写fork-join程序</p>
<ul>
<li>主要思想：使用<code>cilk_spawn</code>向系统公开独立工作（潜在并行性）</li>
<li>回忆并行编程的经验法则<ul>
<li>需要至少和并行执行能力一样多的工作（例如，程序可能产生至少和内核一样多的工作）</li>
<li>需要更多的独立工作而不是执行能力，以便在核心上实现所有工作的良好工作负载平衡</li>
<li>“并行松弛”=独立工作与机器并行执行能力的比率（实际上，~8是一个很好的比率）</li>
<li>但是不要做太多的独立工作，这样工作的粒度就太小了（太多的松弛会导致管理细粒度工作的开销）</li>
</ul>
</li>
</ul>
<p>调度fork-join程序</p>
<ul>
<li>考虑非常简单的调度器：<ul>
<li>使用<code>pthread_create</code>为每个<code>cilk_sync</code>启动pthread</li>
<li>将<code>cilk_sync</code>转换为适当的<code>pthread_join</code>调用</li>
</ul>
</li>
<li>潜在的性能问题？<ul>
<li>重量级spawn操作</li>
<li>并发运行的线程比内核多得多</li>
<li>上下文切换开销</li>
<li>工作集比需要的工作集大，缓存位置少</li>
</ul>
</li>
</ul>
<p>以下程序的工作步骤？<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cilk_spawn <span class="title">foo</span><span class="params">()</span></span>;</span><br><span class="line">bar(); </span><br><span class="line">cilk_sync;</span><br></pre></td></tr></table></figure></p>
<ul>
<li>每线程工作队列存储“要做的工作”<ul>
<li>到达<code>cilk_spawn foo()</code>后，线程将后续工作（<code>bar()</code>）放入其工作队列，并开始执行<code>foo()</code></li>
</ul>
</li>
<li>空闲线程从繁忙线程“窃取”工作<ul>
<li>空闲线程在忙线程的队列中查找工作</li>
<li>如果线程1处于空闲状态（也就是说，它自己的队列中没有工作），那么它会在线程0的队列中查找要做的工作</li>
<li>空闲线程将工作从繁忙线程的队列移动到自己的队列</li>
<li>空闲线程开始执行任务。</li>
</ul>
</li>
</ul>
<p><img src="/img/1639884533.png" alt></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;N; i++) &#123;</span><br><span class="line">    <span class="function">cilk_spawn <span class="title">foo</span><span class="params">(i)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line">cilk_sync;</span><br></pre></td></tr></table></figure>
<ul>
<li>先运行后续工作<ul>
<li>调用线程在执行任何迭代之前生成所有迭代的工作</li>
<li>思考：调用图的宽度优先遍历。O(N)生成工作的空间（最大空间）</li>
<li>如果没有窃取，执行顺序与删除<code>cilk_spawn</code>的程序非常不同</li>
</ul>
</li>
<li>先运行孩子线程<ul>
<li>调用线程只创建一个要窃取的项（表示所有剩余迭代的延续）</li>
<li>若并没有发生窃取，线程将继续从工作队列中弹出后续，将新的后续排入队列（更新后的值为i）</li>
<li>执行顺序与删除spawn的程序相同。</li>
<li>思考：调用图的深度优先遍历</li>
<li>若后续被窃取，则线程将生成并执行下一次迭代</li>
<li>排队继续，i前进1</li>
<li>可以证明具有T线程的系统的工作队列存储不超过单线程执行的堆栈存储的T倍</li>
</ul>
</li>
</ul>
<p>实现工作窃取：每个工作线程实现一个dequeue</p>
<ul>
<li>作为dequeue实现的工作队列（双端队列）<ul>
<li>本地线程从“尾部”（底部）推动/弹出</li>
<li>远程线程从“头”（顶部）窃取</li>
<li>存在有效的无锁出列实现</li>
</ul>
</li>
<li>空闲线程随机选择要尝试从中窃取的线程</li>
<li>从出列的顶端窃取工作<ul>
<li>减少与本地线程的争用：本地线程访问的出列部分与窃取线程访问的出列部分不同！</li>
<li>窃取在调用树开始方向的工作：这是一个“更大”的工作，因此执行窃取的成本在未来较长的计算时间内摊销</li>
<li>最大化局部性：（结合运行子级优先策略）局部线程在调用树的局部部分工作</li>
</ul>
</li>
</ul>
<p><img src="/img/1639886382.jpg" alt><br><img src="/img/1639886607.png" alt></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">recursive_for</span><span class="params">(<span class="keyword">int</span> start, <span class="keyword">int</span> end)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">while</span> (start &lt;= end -­‐ GRANULARITY) &#123; </span><br><span class="line">        <span class="keyword">int</span> mid = (end -­‐ start) / <span class="number">2</span>; </span><br><span class="line">        <span class="function">cilk_spawn <span class="title">recursive_for</span><span class="params">(start, mid)</span></span>; </span><br><span class="line">        start = mid; </span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=start; i&lt;end; i++) </span><br><span class="line">        foo(i); </span><br><span class="line">&#125; </span><br><span class="line">recursive_for(<span class="number">0</span>, N);</span><br></pre></td></tr></table></figure>
<p><img src="/img/1639886794.jpg" alt></p>
<p>两种sync的实现方法</p>
<ul>
<li>“暂停”加入策略<ul>
<li>启动fork的线程必须执行同步，因此，它将等待所有生成的工作完成，在这种情况下，线程0是启动fork的线程，它也将等待所有其他线程完成工作后继续执行之后的任务</li>
</ul>
</li>
<li>贪心<ul>
<li>当启动fork的线程处于空闲状态时，它看起来会窃取新的工作</li>
<li>到达连接点的最后一个线程在同步后继续执行</li>
</ul>
</li>
</ul>
<h1 id="lecture-7"><a href="#lecture-7" class="headerlink" title="lecture 7"></a>lecture 7</h1><p>关于消息传递示例的说明</p>
<ul>
<li>计算<ul>
<li>数组索引相对于本地地址空间（而不是全局网格坐标）</li>
</ul>
</li>
<li>通讯：<ul>
<li>通过发送和接收消息来执行</li>
<li>批量传输：一次传输整行（而不是单个元素）</li>
</ul>
</li>
<li>同步：<ul>
<li>通过发送和接收消息来执行</li>
</ul>
</li>
<li>为方便起见，消息传递库通常包括更高级的原语（通过发送和接收实现）</li>
</ul>
<p>同步（阻塞）发送和接收</p>
<ul>
<li><code>send()</code>：当发送方收到消息数据驻留在接收方地址空间的确认时，调用返回</li>
<li><code>recv()</code>：当接收到的消息中的数据复制到接收方的地址空间并将确认发送回发送方时，调用返回</li>
</ul>
<p>call SEND(foo)：</p>
<ul>
<li>将数据从发送方地址空间中的缓冲区“foo”复制到网络缓冲区</li>
<li>send message</li>
<li>receive ack</li>
<li>SEND()返回</li>
</ul>
<p>Call RECV(bar)：</p>
<ul>
<li>接收消息</li>
<li>将数据复制到接收方地址空间的缓冲区“bar”中</li>
<li>send ack</li>
<li>RECV()返回</li>
</ul>
<p>非阻塞异步发送/接收</p>
<ul>
<li><code>send()</code>：调用立即返回<ul>
<li>调用线程无法修改提供给send()的缓冲区，因为消息处理与线程执行同时发生</li>
<li>调用线程可以在等待消息发送时执行其他工作</li>
</ul>
</li>
<li><code>recv()</code>：发布打算在将来接收的内容，立即返回<ul>
<li>使用<code>checksend()</code>、<code>checkrecv()</code>确定发送/接收的实际状态</li>
<li>调用线程可以在等待接收消息时执行其他工作</li>
</ul>
</li>
</ul>
<p>一种简单的非流水线通信模型：<code>T(n) = T0 + n/B</code></p>
<ul>
<li>T(n)=传输时间（操作的总延迟）</li>
<li>T0=启动延迟（例如，直到第一位到达目的地的时间）</li>
<li>n=操作中传输的字节数</li>
<li>B=传输速率（链路带宽）</li>
</ul>
<p>如果处理器仅在上一条消息发送完成后发送下一条消息，“有效带宽”=<code>n/T(n)</code>，有效带宽取决于传输大小（大传输分摊启动延迟）。</p>
<p>比较通用的通信开销模型：总通信时间=开销+占用率+网络延迟</p>
<ul>
<li>开销（处理器在通信上花费的时间，调用API，缓冲区拷贝等）</li>
<li>占用率（数据通过系统最慢组件的时间）</li>
<li>网络延迟（所有其他）</li>
</ul>
<p><img src="/img/1639888794.png" alt></p>
<p>流水线通信：</p>
<ul>
<li>当网络忙时，消息被缓冲，直到之前的数据发送完</li>
<li>由于网络缓冲区已满，发送者无法发送其他数据</li>
</ul>
<p><img src="/img/1639888976.jpg" alt></p>
<p>通信计算比</p>
<ul>
<li>通信量（bytes）/计算量（指令数）</li>
<li>如果分母是计算的执行时间，则比率给出代码的平均带宽要求</li>
<li>“运算强度”=1/通信与计算比率</li>
<li>高效利用现代并行处理器需要高运算强度（低通信计算比），因为计算能力与可用带宽的比率很高</li>
</ul>
<p>良好的剖分可以减少固有的通信开销（增加运算强度）</p>
<ul>
<li>一个是N/P，另一个是1/2</li>
</ul>
<p><img src="/img/1639889381.jpg" alt></p>
<p>人为通信</p>
<ul>
<li>固有通信：基本上必须在处理器之间移动的信息，以执行给定分配的算法（假设无限容量缓存、最小粒度传输等）</li>
<li>人为通信：所有其他通信（人为通信源于系统实现的实际细节）</li>
<li>系统可能具有最小的传输粒度（结果：系统必须传输比所需更多的数据）<ul>
<li>程序加载一个4字节浮点值，但必须从内存传输整个64字节缓存线（通信量比需要多16倍）</li>
</ul>
</li>
<li>系统可能具有导致不必要通信的操作规则：<ul>
<li>程序存储16个连续的4字节浮点值，因此整个64字节缓存线从内存加载，然后存储到内存中（开销为2倍）</li>
</ul>
</li>
<li>数据在分布式内存中的位置不佳（数据不在访问最多的处理器附近）</li>
<li>有限的复制容量（同一数据多次传输到处理器，因为缓存太小，无法在访问之间保留）</li>
</ul>
<p>通过融合循环改进时间局部性</p>
<p>下面的程序中的两个函数，都先执行两个load，再执行一个数学运算，进行一次store（计算强度=1/3），总的计算强度就是1/3。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">float</span>* A, <span class="keyword">float</span>* B, <span class="keyword">float</span>* C)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) </span><br><span class="line">        C[i] = A[i] + B[i];</span><br><span class="line">&#125; </span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">mul</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">float</span>* A, <span class="keyword">float</span>* B, <span class="keyword">float</span>* C)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)</span><br><span class="line">        C[i] = A[i] * B[i];</span><br><span class="line">&#125; </span><br><span class="line"><span class="keyword">float</span>* A, *B, *C, *D, *E, *tmp1, *tmp2; </span><br><span class="line"><span class="comment">// assume arrays are allocated here </span></span><br><span class="line"><span class="comment">// compute E = D + ((A + B) * C) </span></span><br><span class="line">add(n, A, B, tmp1); </span><br><span class="line">mul(n, tmp1, C, tmp2); </span><br><span class="line">add(n, tmp2, D, E);</span><br></pre></td></tr></table></figure></p>
<p>四个load，每3个数学运算一个load（计算强度=3/5）<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">fused</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">float</span>* A, <span class="keyword">float</span>* B, <span class="keyword">float</span>* C, <span class="keyword">float</span>* D, <span class="keyword">float</span>* E)</span> </span>&#123; </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++) </span><br><span class="line">       `E[i] = D[i] + (A[i] + B[i]) * C[i];     </span><br><span class="line">&#125; </span><br><span class="line"><span class="comment">// compute E = D + (A + B) * C </span></span><br><span class="line">fused(n, A, B, C, D, E);</span><br></pre></td></tr></table></figure></p>
<p>上面的代码更加模块化（例如，基于数组的数学库，如Python中的Numaray）。下面的代码执行得更好。</p>
<p>通过共享数据提高算法强度</p>
<ul>
<li>利用共享：将在同一数据上运行的任务放在同一位置<ul>
<li>在同一处理器上同时调度在同一数据结构上工作的线程</li>
<li>减少固有的通信</li>
</ul>
</li>
<li>示例：CUDA的线程块<ul>
<li>CUDA程序中用于本地化相关处理的抽象</li>
<li>块中的线程经常协作执行操作（利用CUDA共享内存快速访问/同步）</li>
<li>因此，GPU实现总是在同一GPU内核上调度来自同一块的线程</li>
</ul>
</li>
</ul>
<p>利用空间局部性</p>
<ul>
<li>通信的粒度可能很重要，因为它可能会引入伪通信<ul>
<li>通信/数据传输的粒度</li>
<li>缓存一致性的粒度</li>
</ul>
</li>
</ul>
<p>通信粒度导致的人为通信</p>
<ul>
<li>假设：通信粒度是cache line，cache line包含四个元素</li>
<li>良好的空间局部性，便于对上下行的非局部访问</li>
<li>对左右列的非本地访问的空间局部性较差</li>
<li>本质上需要来自左右邻域的一个元素，但系统必须通信四个元素。</li>
</ul>
<p><img src="/img/1639891385.png" alt></p>
<p>竞争：</p>
<ul>
<li>资源可以在给定吞吐量（单位时间内的事务数）下执行操作<ul>
<li>内存、通信链路、服务器等。</li>
</ul>
</li>
<li>当在一个小的时间窗口内对一个资源发出许多请求时（该资源是一个“热点”），就会发生争用</li>
<li>示例：CUDA中的内存系统争用</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> THREADS_PER_BLK 128 </span></span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">my_cuda_program</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">float</span>* input, <span class="keyword">float</span>* output)</span></span></span><br><span class="line"><span class="function"></span>&#123; </span><br><span class="line">    __shared__ <span class="keyword">float</span> local_data[THREADS_PER_BLK];</span><br><span class="line">    <span class="keyword">int</span> index = blockIdx.x * blockDim.x + threadIdx.x; </span><br><span class="line">    <span class="comment">// COOPERATIVELY LOAD DATA HERE</span></span><br><span class="line">    local_data[threadIdx.x] = input[index];</span><br><span class="line">    <span class="comment">// WAIT FOR ALL LOADS TO COMPLETE</span></span><br><span class="line">    __syncthreads(); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>所有线程都会访问内存，因此没有线程可以运行，因为所有线程要么正在访问内存，要么在屏障处被阻塞。</p>
<p>一般来说，CUDA编程时的一个好的经验法则是确保调整线程块的大小，以便GPU可以在每个GPU内核上安装几个线程块。（这允许一个线程块中的线程覆盖分配给同一内核的另一个块中线程的延迟。）</p>
<p>示例：在大型并行机（例如GPU）上创建粒子网格数据结构，这一般用在N-body问题上，也有其他的方法<br><img src="/img/1639892682.jpg" alt></p>
<p>解决方案1：在cell上并行化</p>
<ul>
<li>一个可能的答案是按cell剖分：对于每个cell，独立计算其中的粒子（消除争用，因为不需要同步）</li>
<li>并行性不足：只有16个并行任务，但需要数千个独立任务才能有效利用GPU）</li>
<li>工作效率低下：在单元中执行粒子计算的次数是顺序算法的16倍</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span> cell_lists[<span class="number">16</span>];      <span class="comment">// 2D array of lists </span></span><br><span class="line"><span class="keyword">for</span> each cell c           <span class="comment">// in parallel </span></span><br><span class="line">    <span class="keyword">for</span> each particle p    <span class="comment">// sequentially </span></span><br><span class="line">        <span class="keyword">if</span> (p is within c) </span><br><span class="line">            append p to cell_lists[c]</span><br></pre></td></tr></table></figure>
<p>解决方案2：在粒子上并行化</p>
<ul>
<li>另一个答案：为每个CUDA线程指定一个粒子。线程计算包含粒子的单元，然后原子地更新列表。</li>
<li>大规模争用：数千个线程争用更新单个共享数据结构的权限</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span> cell_list[<span class="number">16</span>]; <span class="comment">// 2D array of lists  </span></span><br><span class="line">lock cell_list_lock;  </span><br><span class="line"><span class="keyword">for</span> each particle p <span class="comment">//  in  parallel  </span></span><br><span class="line">    c = compute cell containing p</span><br><span class="line">    lock(cell_list_lock)</span><br><span class="line">    append p to cell_list[c]</span><br><span class="line">    unlock(cell_list_lock)</span><br></pre></td></tr></table></figure>
<p>解决方案3：使用更细粒度的锁</p>
<ul>
<li>通过使用每cell锁缓解单个全局锁的争用<ul>
<li>假设粒子在二维空间中均匀分布~比解决方案2少16倍的争用</li>
</ul>
</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">list</span> cell_list[<span class="number">16</span>];     <span class="comment">// 2D array of lists </span></span><br><span class="line">lock cell_list_lock[<span class="number">16</span>]; </span><br><span class="line"><span class="keyword">for</span> each particle p             <span class="comment">// in parallel </span></span><br><span class="line">    c = compute cell containing p </span><br><span class="line">    lock(cell_list_lock[c]) </span><br><span class="line">    append p to cell_list[c] </span><br><span class="line">    unlock(cell_list_lock[c])</span><br></pre></td></tr></table></figure>
<p>解决方案4：计算部分结果+合并</p>
<ul>
<li>另一个答案是：并行生成N个“部分”网格，然后合并<ul>
<li>示例：创建N个线程块（至少与SMX内核的线程块数量相同）</li>
<li>线程块中的所有线程更新相同的网格</li>
<li>支持更快的同步：争用减少了N倍，而且同步成本更低，因为它是在块本地变量上执行的（在CUDA共享内存中）</li>
<li>需要额外的工作：在计算结束时合并N个网格</li>
<li>需要额外的内存占用：存储N个列表网格，而不是1个</li>
</ul>
</li>
</ul>
<p><img src="/img/1639893108.jpg" alt></p>
<p>解决方案5：数据并行方法</p>
<ul>
<li>步骤1：计算每个粒子被哪个cell包含（对输入粒子是平行处理的）</li>
<li>步骤2：按cell序号对结果排序（基于排序排列的粒子索引数组）</li>
<li>步骤3：查找每个cell的开始/结束（基于粒子索引元素的平行）</li>
<li>此解决方案保持了大量并行性，并消除了细粒度同步的需要。。。以对数据进行排序和额外传递为代价（额外BW）</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cell = grid_index[index] </span><br><span class="line"><span class="keyword">if</span> (index == <span class="number">0</span>)</span><br><span class="line">    cell_starts[cell] = index;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span> (cell != grid_index[index-­‐<span class="number">1</span>]) &#123; </span><br><span class="line">    cell_starts[cell] = index;</span><br><span class="line">    cell_ends[grid_index[index-­‐<span class="number">1</span>]] = index; </span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (index == numParticles-­‐<span class="number">1</span>) <span class="comment">// special case for last cell </span></span><br><span class="line">    cell_ends[cell] = index+<span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<p>降低通信成本</p>
<ul>
<li>减少与发送方/接收方的通信开销<ul>
<li>发送更少的消息，使消息更大（分摊开销）</li>
<li>将许多小消息合并成大消息</li>
</ul>
</li>
<li>减少延迟<ul>
<li>应用程序编写器：重新构造代码以利用局部性</li>
<li>硬件实现者：改进通信架构</li>
</ul>
</li>
<li>减少争用<ul>
<li>复制争用资源（例如，本地副本、细粒度锁）</li>
<li>错开对竞争资源的访问</li>
</ul>
</li>
<li>增加通信/计算重叠<ul>
<li>应用程序编写器：使用异步通信（例如，异步消息）</li>
<li>硬件实现者：流水线、多线程、预取、无序执行</li>
<li>在应用程序中需要额外的并发性（并发性大于执行单元的数量）</li>
</ul>
</li>
</ul>
<p>总结：优化通信</p>
<ul>
<li>固有的通信<ul>
<li>考虑到问题是如何分解的，工作是如何分配的，固有的通信是最基本的</li>
<li>人为通信取决于机器实现细节（通常与固有通信对性能同样重要）</li>
</ul>
</li>
<li>提高程序性能<ul>
<li>识别和利用位置：减少通信（增加运算强度）</li>
<li>减少开销（更少、更大的消息）</li>
<li>减少争用</li>
<li>最大化通信和处理的重叠（隐藏延迟，以免产生成本）</li>
</ul>
</li>
</ul>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>
<p><img src="/img/" alt></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/积累/" rel="tag"># 积累</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/12/17/cs267/" rel="next" title="CS267 并行计算应用课程笔记">
                <i class="fa fa-chevron-left"></i> CS267 并行计算应用课程笔记
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/12/19/在Linux中使用线程/" rel="prev" title="在Linux中使用线程">
                在Linux中使用线程 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="Hao Yu">
            
              <p class="site-author-name" itemprop="name">Hao Yu</p>
              <p class="site-description motion-element" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</p>
          </div>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">351</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>
        	<audio controls="controls" loop="loop" preload="auto" src="/resource/xiaomeihao.mp3">
	        </audio>
	

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuhao0102" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yuh18@mails.tsinghua.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-1"><span class="nav-number">1.</span> <span class="nav-text">lecture 1</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2"><span class="nav-number">2.</span> <span class="nav-text">lecture 2</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-3"><span class="nav-number">3.</span> <span class="nav-text">lecture 3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-4"><span class="nav-number">4.</span> <span class="nav-text">lecture 4</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-5"><span class="nav-number">5.</span> <span class="nav-text">lecture 5</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-6"><span class="nav-number">6.</span> <span class="nav-text">lecture 6</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-7"><span class="nav-number">7.</span> <span class="nav-text">lecture 7</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="DvelopmentTarget">     
  </div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="false"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>

  
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_uv"> 
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  


  <script type="text/javascript" src="/js/src/love.js"></script>

</body>
</html>
