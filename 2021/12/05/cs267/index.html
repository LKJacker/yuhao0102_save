<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zn-ch">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">



  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-simple.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hao Yu's blog">










<meta name="description" content="lecture 2单处理器上大部分性能被浪费，主要是因为数据迁移时间太久。 编译器管理内存和寄存器，进行寄存器分配，决定什么时候load/store，什么时候重用。编译器通过图染色的方式决定寄存器重用。 编译器的优化：  循环展开、合并、重排 删除死代码 指令重排来实现指令流水、提高寄存器重用 代码强度降低，比如把乘法变成移位  多级cache： - 片上cache更快，但是更小。 - 更大的ca">
<meta name="keywords" content="HPC PC IA">
<meta property="og:type" content="article">
<meta property="og:title" content="Hao Yu&#39;s blog">
<meta property="og:url" content="http://yoursite.com/2021/12/05/cs267/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="lecture 2单处理器上大部分性能被浪费，主要是因为数据迁移时间太久。 编译器管理内存和寄存器，进行寄存器分配，决定什么时候load/store，什么时候重用。编译器通过图染色的方式决定寄存器重用。 编译器的优化：  循环展开、合并、重排 删除死代码 指令重排来实现指令流水、提高寄存器重用 代码强度降低，比如把乘法变成移位  多级cache： - 片上cache更快，但是更小。 - 更大的ca">
<meta property="og:locale" content="zn-ch">
<meta property="og:image" content="http://yoursite.com/img/1638434520.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638547987.png">
<meta property="og:image" content="http://yoursite.com/img/1638438675.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638446298.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638451987.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638543408.png">
<meta property="og:image" content="http://yoursite.com/img/1638584546.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638588722.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638588598.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638590925.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638599104.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638600585.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638601045.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638601080.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638684331.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638684798.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638688009.png">
<meta property="og:image" content="http://yoursite.com/img/1638690323.png">
<meta property="og:image" content="http://yoursite.com/img/1638690838.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638691213.jpg">
<meta property="og:image" content="http://yoursite.com/img/1638692558.jpg">
<meta property="og:updated_time" content="2021-12-05T14:52:30.102Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hao Yu&#39;s blog">
<meta name="twitter:description" content="lecture 2单处理器上大部分性能被浪费，主要是因为数据迁移时间太久。 编译器管理内存和寄存器，进行寄存器分配，决定什么时候load/store，什么时候重用。编译器通过图染色的方式决定寄存器重用。 编译器的优化：  循环展开、合并、重排 删除死代码 指令重排来实现指令流水、提高寄存器重用 代码强度降低，比如把乘法变成移位  多级cache： - 片上cache更快，但是更小。 - 更大的ca">
<meta name="twitter:image" content="http://yoursite.com/img/1638434520.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2021/12/05/cs267/">





  <title> | Hao Yu's blog</title>
  








 
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zn-ch">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hao Yu's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The program monkey was eaten by the siege lion.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/resume.pdf" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-mybetterhalf">
          <a href="/mybetterhalf/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br>
            
            mybetterhalf
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/12/05/cs267/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline"></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-12-05T22:52:30+08:00">
                2021-12-05
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="lecture-2"><a href="#lecture-2" class="headerlink" title="lecture 2"></a>lecture 2</h1><p>单处理器上大部分性能被浪费，主要是因为数据迁移时间太久。</p>
<p>编译器管理内存和寄存器，进行寄存器分配，决定什么时候load/store，什么时候重用。编译器通过图染色的方式决定寄存器重用。</p>
<p>编译器的优化：</p>
<ul>
<li>循环展开、合并、重排</li>
<li>删除死代码</li>
<li>指令重排来实现指令流水、提高寄存器重用</li>
<li>代码强度降低，比如把乘法变成移位</li>
</ul>
<p>多级cache：</p>
<pre><code>- 片上cache更快，但是更小。
- 更大的cache有延迟，硬件需要更长的时间来检查地址，更多关联度也会延长时间
- 可以利用第四级cache作为被置换出的cache的cache
</code></pre><p>其他的cache包括：寄存器，TLB等。</p>
<p>处理内存延迟：</p>
<pre><code>- 在小而快的内存中保存数据并重用
- 将一整块数据存入内存并使用
- 程序利用向量化实现一条指令进行多次读或写
- 程序预取或者延迟写
</code></pre><p>blocking或者tiling是提高cache性能的好办法，使用分治将问题分割到适合cache的大小。</p>
<p>SSE、SSE2：适合16bytes的类型，比如4个float、2个double或者16个byte。可以并行执行加、乘。但是需要对齐，连续。</p>
<p>矩阵是2维数组，在存储上需要根据cache的特性存储，Fortran是列优先，对cache不友好。采用分块的方法进行并行化，存在理论上的最优化分块方法。这种算法就需要在递归时适当地切割。</p>
<p><img src="/img/1638434520.jpg" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">func C = RMM(A, B, n)</span><br><span class="line">    if n = 1</span><br><span class="line">        C = A * B</span><br><span class="line">    else &#123;</span><br><span class="line">        C11 = RMM(A11, B11, n/2) + RMM(A12, B21, n/2);</span><br><span class="line">        C12 = RMM(A11, B12, n/2) + RMM(A12, B22, n/2);</span><br><span class="line">        C21 = RMM(A21, B11, n/2) + RMM(A22, B21, n/2);</span><br><span class="line">        C22 = RMM(A21, B12, n/2) + RMM(A22, B22, n/2);</span><br><span class="line">    &#125;</span><br><span class="line">    return</span><br></pre></td></tr></table></figure>
<p>递归的数据分布，可以提高数据局部性，最小化内存延迟，例如画Z字的方式，或者看“cache oblivious algorithm”。好处是可以在任何cache大小下实现较好的性能，不好的是计算index很困难。</p>
<p>删除假的依赖，比如使用局部变量，进行指令重排：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a[i] = b[i] + c;</span><br><span class="line">a[i+<span class="number">1</span>] = b[i+<span class="number">1</span>] * d;</span><br></pre></td></tr></table></figure></p>
<p>可能会有假的数据依赖，借助局部变量改成<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">float</span> f1 = b[i];</span><br><span class="line"><span class="keyword">float</span> f2 = b[i+<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">a[i] = f1 + c;</span><br><span class="line">a[i+<span class="number">1</span>] = f2 * d;</span><br></pre></td></tr></table></figure></p>
<p>或者对频繁使用的变量进行预先加载，使寄存器中保持有变量。</p>
<p>循环展开促进指令级并行，提高流水线性能，或者向量化。</p>
<p>再设计数据结构时注意cache局部性，比如多使用struct。</p>
<p>strassen’s矩阵乘法，将8次乘+4次加优化到7次乘+18次加，能做到O(n^2.81)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Let M = | m11 m12| = |a11 a12| |b11 b12|</span><br><span class="line">        | m21 m22|   |a21 a22| |b21 b22|</span><br><span class="line"></span><br><span class="line">Let p1 = (a12 - a22) * (b21 + b22)</span><br><span class="line">    p2 = (a11 + a22) * (b11 + b22)</span><br><span class="line">    p3 = (a11 - a21) * (b11 + b12)</span><br><span class="line">    p4 = (a11 + a12) * b22</span><br><span class="line">    p5 = a11 * (b12 - b22)</span><br><span class="line">    p6 = a22 * (b21 - b11)</span><br><span class="line">    p7 = (a21 + a22) * b11</span><br><span class="line"></span><br><span class="line">Then m11 = p1 + p2 - p4 + p6</span><br><span class="line">     m12 = p4 + p5</span><br><span class="line">     m21 = p6 + p7</span><br><span class="line">     m22 = p2 - p3 + p5 - p7</span><br></pre></td></tr></table></figure></p>
<p>其他一些矩阵矩阵乘算法：</p>
<ul>
<li>世界纪录是O(n^2.37548)</li>
<li>2.37548 reduced to 2.37293<ul>
<li>Virginia Vassilevska Williams, UC Berkeley &amp; Stanford, 2011</li>
</ul>
</li>
<li>2.37293 reduced to 2.37286<ul>
<li>Francois Le Gall, 2014</li>
</ul>
</li>
<li>大概能做到O(n^2+e)<ul>
<li>Cohn, Umans, Kleinberg, 2003</li>
</ul>
</li>
</ul>
<p>CNN在计算什么？<br><img src="/img/1638547987.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for k=1:K, for h=1:H, for w=1:W, for r=1:R,</span><br><span class="line">    for s=1:S, for c=1:C, for b=1:B</span><br><span class="line">        Out(k, h, w, b) += Image(r+w, s+h, c, b) * Filter( k, r, s, c )</span><br></pre></td></tr></table></figure>
<h1 id="lecture-3"><a href="#lecture-3" class="headerlink" title="lecture 3"></a>lecture 3</h1><p>几种并行的模型<br><img src="/img/1638438675.jpg" alt></p>
<p>如何并行化下边的程序，每一个y依赖于前一个：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">y[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> i = <span class="number">1</span> : n</span><br><span class="line">    y[i] = y[i<span class="number">-1</span>] + x[i];</span><br></pre></td></tr></table></figure></p>
<p>这个图应该是以树形计算前缀和的示意图，最上边是原始数组，中间是逐次计算两两和，最下边是最终结果。<br><img src="/img/1638446298.jpg" alt></p>
<h1 id="lecture-4"><a href="#lecture-4" class="headerlink" title="lecture 4"></a>lecture 4</h1><p>SIMD：数据并行的语言非常成功，不规则的数据（稀疏矩阵乘向量）比较适配，但是不规则的计算（分治、递归等）不太行。</p>
<p>共享内存多处理器时代，出现了一些共享内存模型，POSIX Threads、OpenMP等</p>
<p>集群时代，出现了MPI。</p>
<p>每个线程有一些私有变量，如本地栈。也有一些共享的变量，如通过malloc的变量，静态变量等。线程通过读写共享变量实现数据通信。</p>
<p>pthreads是POSIX线程接口，用来创建和同步线程，但是没有对通信的显示支持，因为共享内存是隐式的。<code>pthread_join</code>意思是等待，直到线程结束。创建线程的开销是不能被忽略的，因为涉及了系统调用。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">pthread_create</span><span class="params">(<span class="keyword">pthread_t</span>*, <span class="keyword">const</span> <span class="keyword">pthread_attr_t</span>*, <span class="keyword">void</span> *(*)(<span class="keyword">void</span>*), <span class="keyword">void</span>*)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">pthread_t</span> threads[<span class="number">16</span>];</span><br><span class="line">    <span class="keyword">int</span> tn;</span><br><span class="line">    <span class="keyword">for</span> (tn = <span class="number">0</span>; tn &lt; <span class="number">16</span>; tn ++)</span><br><span class="line">        pthread_create(&amp;threads[tn], <span class="literal">NULL</span>, function, <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">for</span> (tn = <span class="number">0</span>; tn &lt; <span class="number">16</span>; tn ++)</span><br><span class="line">        pthread_join(threads[tn], <span class="literal">NULL</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>数据竞争即为各个线程竞争同一个变量。</p>
<p>mutexes是互斥锁。当线程需要访问一个变量时，需要加锁。信号量允许k个线程同时访问资源，适用于有限个资源的时候。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">pthread_mutex_t</span> amutex = PTHREAD_MUTEX_INITIALIZER;</span><br><span class="line"><span class="comment">// or pthread_mitex_init(&amp;amutex, NULL);</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">pthread_mutex_lock</span><span class="params">(amutex)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">pthread_mutex_unlock</span><span class="params">(amutex)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>POSIX线程基于OS，可以被多种语言使用，但是创建线程的开销大，数据竞争的bug也有很多。</p>
<p>openmp有C/C++和Fortran的接口：</p>
<ul>
<li>预处理指令</li>
<li>库函数</li>
<li>环境变量</li>
</ul>
<p>它是一个方便的线程级内存共享编程工具，允许把程序分成穿兴趣和并行区，而不是纯线程。也不需要进行栈的管理，提供了同步命令。</p>
<p>最经常用的OpenMP命令如下：<br><img src="/img/1638451987.jpg" alt></p>
<p>OpenMP的基本语法：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp construct [clause [clause]...]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel private(x) </span></span><br><span class="line">&#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;omp.h&gt;</span></span></span><br></pre></td></tr></table></figure></p>
<p>OpenMP使用的是fork-join模型，主线程派生一系列线程，等待子线程结束后继续执行，遇到需要多线程的代码块时再fork线程。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span> A[<span class="number">1000</span>];</span><br><span class="line">omp_set_num_threads(<span class="number">4</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">int</span> id = omp_get_thread_num();</span><br><span class="line">    pooh(id, A);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>各个线程共享A数组，但是每个线程都有一个id变量。</p>
<p>可以通过<code>omp_get_thread_num</code>请求创建多少个线程，但不是你要创建多少线程就是多少线程，一旦请求了一个数量的线程数并创建，系统就不会减少这个数量。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">long</span> num_steps = <span class="number">100000</span>;</span><br><span class="line"><span class="keyword">double</span> step;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> pi, sum = <span class="number">0.0</span>;</span><br><span class="line">    step = <span class="number">1.0</span>/(<span class="keyword">double</span>)num_steps;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> i, id, nthreads;</span><br><span class="line">        <span class="keyword">double</span> x;</span><br><span class="line">        id = omp_get_thread_num();</span><br><span class="line">        nthrds = omp_get_num_threads();</span><br><span class="line">        <span class="keyword">if</span> (id == <span class="number">0</span>)</span><br><span class="line">            nthreads = nthrds;</span><br><span class="line">        <span class="keyword">for</span> (i = id; i &lt; num_steps; i += nthrds) &#123;</span><br><span class="line">            x = (i+<span class="number">0.5</span>) / step;</span><br><span class="line">            sum[id] += <span class="number">4</span> / (<span class="number">1.0</span> + x*x);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; nthreads; i ++)</span><br><span class="line">        pi += step * sum[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每个处理器有自己的多级cache，多处理器系统中存在cache一致性问题。内存中的一个数字被放到处理器P1的cache中，又被放到P2的cache中，如果P1修改了数字，P2是不知道的，这样就不一致了。写回策略中，数据被写回是取决于什么时候，被哪个处理器写回的。</p>
<p>使用cache一致性协议来写回，但是在多处理器中并不具有可扩展性。</p>
<p>内存总线是一个广播的机制，cache中保存着它们存在哪个地址，cache控制器监控着总线上的所有cache事务，一个事务是一个相关的事务，如果涉及的cache行在本地处理器的cache中。</p>
<p>如果独立的数据元素碰巧位于同一个缓存行上，每次更新都会导致缓存行在线程之间“来回晃动”……这称为“假共享”。</p>
<p>如果将标量提升到数组以支持创建 SPMD 程序，则数组元素在内存中是连续的，因此共享缓存行导致可扩展性较差。解决方案：填充数组，以便您使用的元素位于不同的缓存行上。</p>
<p>同步用于施加顺序约束并保护对共享数据的访问，包括：</p>
<ul>
<li>互斥区</li>
<li>barrier</li>
</ul>
<p>被互斥区包裹起来的部分每次只能有一个线程访问，barrier是直到所有线程都到这个barrier了才一起往下执行。</p>
<p>for循环可以被并行化，其中的i是默认私有的，各个线程等到for循环完成后再一起执行：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp for</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i ++) &#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>schedule命令决定了任务怎么映射到每个进程。有static和dynamic两种，static是静态的，在编译时决定；dynamic会动态调度或者从任务队列中分配，在执行过程中决定。</p>
<p>reduction即规约，进行最大、最小、平均等操作。每一个列表中的变量会被复制到每个线程，并初始化，对局部变量进行操作，局部变量再规约到主线程。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for reduction (+:ave)</span></span><br></pre></td></tr></table></figure></p>
<p>因为barrier很耗时，而for循环结束之前都会有一个默认的barrier，所以可以在for循环之前使用nowait实现不barrier。</p>
<p>可以针对不同变量选择不同的共享策略，比如：shared、private(为变量创建一个本地拷贝，且不初始化，且原来的全局变量不变)、firstprivate。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for private(tmp)</span></span><br><span class="line"><span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; <span class="number">1000</span>; j ++)</span><br><span class="line">    tmp += j;</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">"%d\n"</span>, tmp); <span class="comment">// tmp为0</span></span><br></pre></td></tr></table></figure></p>
<p>default(none)强制您为出现在范围内的变量定义存储属性……如果失败，编译器会报错。可以将default子句放在parallel 和parallel + workshare 结构上。j和y没有规定存储策略，编译器会报错。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for default(none) reduction(*:x)</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i ++)</span><br><span class="line">    <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; <span class="number">3</span>; j ++)</span><br><span class="line">        x += foobar(i, j, y);</span><br></pre></td></tr></table></figure></p>
<p>tasks是一系列独立的work，由执行代码和计算的数据组成，线程被分配执行每个task的工作。</p>
<p>下例中组成一个task的二叉树，直到一个task之前的所有task被完成，这个task才能被完成。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">fib</span><span class="params">(<span class="keyword">int</span> n)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> x, y;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; <span class="number">2</span>) <span class="keyword">return</span> n;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp task shared(x);</span></span><br><span class="line">    x = fib(n<span class="number">-1</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp task shared(y);</span></span><br><span class="line">    y = fib(n<span class="number">-2</span>);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp taskwait;</span></span><br><span class="line">    <span class="keyword">return</span> x+y;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> NM = <span class="number">5000</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> omp single</span></span><br><span class="line">        fib(NM);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>single表示这个代码块只能被一个线程执行，这个代码块之后有一个默认的barrier。</p>
<p>flush操作</p>
<ul>
<li>定义一个序列点，在该点线程强制执行一致的内存视图。</li>
<li>对于其他线程可见并与刷新操作（flush-set）相关联的变量<ul>
<li>编译器不能在刷新周围进行刷新集的加载/存储：</li>
<li>该线程之前对flush-set 的所有读/写都已完成</li>
<li>没有发生此线程对刷新集的后续读/写</li>
<li>刷新集中的变量从临时存储移动到共享内存。</li>
<li>刷新后刷新集中变量的读取从共享内存加载</li>
</ul>
</li>
</ul>
<h1 id="lecture-5"><a href="#lecture-5" class="headerlink" title="lecture 5"></a>lecture 5</h1><p>使用性能模型或工具，以预测架构的性能。需要假定运行时间与需要的运算、数据移动的次数相关，其中，数据移动的次数更相关，因为需要理解cache的行为。</p>
<p>串行机器在访问内存时会遇到延迟，而并行机器在同步、点对点通信、规约时会遇到延迟，所以可以使用算法的依赖链进行分类。通信的时间取决于多种因素：CPU负载、延迟、数据吞吐量、带宽等。</p>
<p>可以用多种方法建模性能，前三个是roofline模型，中间两个是LogCAche模型，后三个是LogGPa模型：</p>
<ul>
<li>浮点数操作：Flop/s</li>
<li>cache数据操作：GB/s</li>
<li>DRAM数据操作：GB/s</li>
<li>总线数据移动：PCIe带宽</li>
<li>Depth：OMP嵌套深度</li>
<li>MPI数据大小：带宽</li>
<li>MPI发送/等待比例：网络延迟</li>
</ul>
<p>很多模型都追踪延迟来预测性能，延迟隐藏衍生出多种方法，例如乱序执行（硬件发现并行性），硬件预取（硬件自动家在数据），大规模线程并行（独立的线程提高并行）。</p>
<p>roofline模型是基于吞吐的模型，追踪比例而不是时间。</p>
<p>现在CPU采用多种方法来增加浮点效率。比如使用fused multiply add来使乘法和加法在同一个流水线中，使用向量指令。</p>
<p>三种方法来提高性能：增加片上性能（比如让编译器进行向量化），增加内存带宽（NUMA），最小化数据移动。</p>
<h1 id="lecture-6"><a href="#lecture-6" class="headerlink" title="lecture 6"></a>lecture 6</h1><p>并行化和数据局部性都对性能很重要，因为数据迁移是很费劲的。很多对象是独立于其他对象来操作的，更多的是依赖于与之相邻的对象，其依赖关系很简单。</p>
<p>同时讲了一些计算域剖分的问题，减少通信的同时实现局部性。</p>
<p>并行图计算：如果两个进程的图相连，则需要交互，他的数据结构与一般的图算法不一样，将图剖分到各个节点上，平均分布实现均衡，同时最小化节点之间边的关系减少通信。</p>
<p>粒子系统模拟需要实现每个粒子受到的作用和对其他粒子的作用，这就需要通信，通常是对整个区域进行剖分，区域之间进行halo交换。第一个挑战就是在处理区域边界上的粒子碰撞，第二个挑战是如果粒子成簇状分布的话会不均衡，为了减少不均衡，对空间也采取不均衡划分，采用k-d树的形式对粒子进行划分。</p>
<p>远域强迫指的是每个进程都跟其他进程的粒子进行作用，采用循环的方式进行数据通信，最中每个进程得到所有其他进程的数据。如果使用树形剖分的话，将每一簇粒子看成一个整体，降低复杂度。</p>
<p>假定ODE是<code>x(t) = f(x) = A * x(t)</code>，A是一个稀疏矩阵，显式方法可以转化成一个近似的稀疏矩阵乘，隐式方法可以转化成一个线性方程。另外还有直接方法，做LU分解，迭代方法（Jacobi、Successive over-relaxation、Conjugate Gradient）等。</p>
<p>稀疏矩阵向量乘：稀疏矩阵可以只保存非0元，CSR方法是最简单的方法，对稀疏矩阵m*n，一个指针数组有m个元素，每个元素代表着第i行所有元素的起始位置。val数组和ind数组保存着实际的元素。<br><img src="/img/1638543408.png" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for each row i</span><br><span class="line">    for k = ptr[i] to ptr[i+1]-1 do</span><br><span class="line">        y[i] = y[i] + val[k] * x[ind[k]];</span><br></pre></td></tr></table></figure>
<p>如果要并行化，需要知道，哪个进程拥有<code>y[i]</code>、<code>x[i]</code>、<code>A[i,j]</code>，和哪个进程应该计算最终的<code>y[i] = sum(from 1 to n) A[i,j] * x[j]</code>。</p>
<p>首先将下标1到n进行剖分，对于进程k，它存储了每一个下标i的<code>y[i]</code>、<code>x[i]</code>、<code>A[i,...]</code>，同时计算了<code>y[i] = (row i of A) * x</code>，这里需要通信了。</p>
<p>能否将矩阵重排，使所有非零元素都在对角块上？这样所有运算都可以在本地完成。重排的目标</p>
<ul>
<li>平衡负载（如何测量负载？）。<ul>
<li>大约相等数量的非零值（不一定是行）</li>
</ul>
</li>
<li>平衡存储（每个处理器存储多少？）。<ul>
<li>大约相等数量的非零值</li>
</ul>
</li>
<li>尽量减少通信<ul>
<li>最小化对角块外的非零值</li>
<li>相关优化标准是移动对角线附近的非零值</li>
</ul>
</li>
<li>改进寄存器和缓存重用<ul>
<li>在小的垂直块中将非零值分组以便源 (x) 元素加载到缓存或寄存器中可以重用（时间局部性）</li>
<li>在小的水平块中分组非零值，以便靠近源 (x)中的元素可以命中cache（空间局部性）</li>
</ul>
</li>
<li>其他算法出于其他原因对行/列重新排序<ul>
<li>在高斯消元后减少矩阵中的非零值</li>
<li>提高数值稳定性</li>
</ul>
</li>
</ul>
<p>图的并行化和矩阵并行化类似。</p>
<p>自适应网格加密：并行化基于patches。</p>
<p>非结构网格的挑战：</p>
<ul>
<li>如何首先生成它们<ul>
<li>从对象的几何描述开始</li>
<li>三角化</li>
<li>3D 更难！</li>
</ul>
</li>
<li>如何划分它们<ul>
<li>ParMetis，一个并行图分区器</li>
</ul>
</li>
<li>如何设计迭代求解器<ul>
<li>PETSc，一种用于科学计算的便携式可扩展工具包</li>
<li>Prometheus，一个用于有限元问题的多重网格求解器</li>
</ul>
</li>
<li>如何设计直接求解器<ul>
<li>SuperLU，并行稀疏高斯消除</li>
</ul>
</li>
</ul>
<h1 id="lecture-7"><a href="#lecture-7" class="headerlink" title="lecture 7"></a>lecture 7</h1><p>CPU中有取指、解码、ALU、运行上下文、乱序控制逻辑、指令预测、数据预取、cache等模块。第一个优化的方法是取消让单指令流跑得更快的部分，只剩下取指、解码、ALU运行上下文模块，多个线程共享指令流。第二个方法，让多个ALU共享取指令部分，共享部分运行上下文。</p>
<p>如果遇到了分支，那么不是所有的ALU都运行相同的分支，会遇到暂停，通过切换来隐藏延迟。</p>
<ul>
<li>使用许多精简的内核并行运行；</li>
<li>核心打包大量 ALU；</li>
<li>通过交错执行来避免延迟停滞；<ul>
<li>当一组停滞时，切换到工作准备就绪的另一组</li>
</ul>
</li>
</ul>
<p>SIMD单指令流多数据流架构充分使用了数据并行，并行暴露于用户和编译器。SIMD的发展如下：<br><code>MMS（8*8 bit int）</code> —&gt; <code>SSE（4*32 bit FP）</code> —&gt; <code>SSE2（2*64 bit FP）</code> —&gt; <code>SSE3（hroizontal ops）</code> —&gt; <code>SSSE3</code> —&gt; <code>SSE4.1</code> —&gt; <code>SSE4.2</code> —&gt; <code>AVX（8*32 bit FP）</code> —&gt; <code>AVX+FMA（3 operand）</code> —&gt; <code>AVX2（256 bit int ops）</code> —&gt; <code>AVX-512（512 bit）</code></p>
<p>GPU使用的是单指令流多线程（SIMT），每个线程有自己的寄存器组，且可能执行不同的流程，单指令流可以在多个地址上执行。</p>
<ul>
<li>低占用率会大大降低性能。</li>
<li>控制流分散会大大降低性能。</li>
<li>同步选项非常有限</li>
</ul>
<p>CUDA是用于SIMT的模型，具有可扩展性。</p>
<p>block有id，每个块内共享内存，可以是1、2、3维；block内有thread，thread有自己的寄存器和私有内存，可以是1、2、3维。2/3维只是组织方式，通过一维手段同样可以达到2/3维的效果。<br><img src="/img/1638584546.jpg" alt></p>
<p>CUDA的线程是独立运行的，有他自己的程序计数器（PC）、变量寄存器、处理器状态位等，不会内定如何调度。线程可能会被映射到GPU上，成为物理线程；也可能在多核CPU下，1 block=1个物理线程，成为虚拟线程。</p>
<p><img src="/img/1638588722.jpg" alt></p>
<p>CUDA支持：</p>
<ul>
<li>线程并行<ul>
<li>每线程都是独立运行的</li>
</ul>
</li>
<li>数据并行</li>
<li>任务并行<ul>
<li>不同block是独立的</li>
<li>独立的核运行不同的流</li>
</ul>
</li>
</ul>
<p>线程被分到不同的block中，同一个block中的线程可以合作，不同block的线程不能合作。不同的block之间可以协调但是不能同步，容易死锁；可以进行多种交互。</p>
<ol>
<li>在GPU上为数据分配空间</li>
<li>创建CPU上的数据</li>
<li>数据复制到GPU上</li>
<li>调用kernel程序来运行GPU</li>
<li>结果数据从GPU拷贝到CPU</li>
<li>释放GPU的空间</li>
<li>释放CPU的空间</li>
</ol>
<p>三种不同的函数：</p>
<ul>
<li><code>__device__ float DFunc()</code>运行在Device上，只能从Device上调用</li>
<li><code>__global__ void kernel()</code>运行在Device上，只能从host上调用，只能返回void</li>
<li><code>__host__ float HFunc()</code>运行在host上，只能从host上调用</li>
</ul>
<p>简单的调用：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CUDA Kernel function to add the elements</span></span><br><span class="line"><span class="comment">// of two arrays on the GPU</span></span><br><span class="line">__global__</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">float</span> *a, <span class="keyword">float</span> *b, <span class="keyword">float</span> *c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = blockId.x * blockDim.x + threadId.x;</span><br><span class="line">    c[i] = a[i] + b[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// Run N/256 blocks of 256 threads each</span></span><br><span class="line">    vecAdd&lt;&lt;&lt;N/<span class="number">256</span>, <span class="number">256</span>&gt;&gt;&gt;(d_a, d_b, d_c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>数据管理：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 256*1024</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">float</span> *h_a = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    <span class="keyword">float</span> *h_b = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    <span class="keyword">float</span> *h_c = <span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">float</span> *d_a, *d_b, *d_c;</span><br><span class="line">    cudaMalloc(&amp;d_a, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMalloc(&amp;d_b, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMalloc(&amp;d_c, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(d_a, h_a, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line">    cudaMemcpy(d_b, h_b, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N);</span><br><span class="line"></span><br><span class="line">    vecAdd&lt;&lt;&lt;cell(N/<span class="number">256</span>), <span class="number">256</span>&gt;&gt;&gt;(d_a, d_b, d_c);</span><br><span class="line">    cudaMemcpy(h_c, d_c, <span class="keyword">sizeof</span>(<span class="keyword">float</span>) * N, cudaMemcpyDeviceToHost);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>CUDA程序一般都要求具有大量并行性，同时局部性也很重要，因为GPU没有能够隐藏延迟的硬件。</p>
<p>每个线程和block都有自己专属的私有内存，而各个kernel之间有共享的全局内存。</p>
<p>同步：</p>
<ul>
<li>一个block中的线程可能会互相同步</li>
<li>block可以通过原子内存操作来协调运行<ul>
<li>例如通过一个共享的自增队列指针</li>
</ul>
</li>
<li>互相依赖的kernel可能有隐式的barrier</li>
</ul>
<p>访问同一个内存地址会造成冲突，变成顺序的访问。连续的32位字被分配给连续的地址。对全局内存也会有这种问题，从Fermi架构开始，全局内存地址会被hash，从而全局地址冲突不会再发生。</p>
<p>每一个load指令都会带来一系列对齐且连续的内存，称为页。硬件自动将从一个warp的不同线程发出的请求合并到同一个page。</p>
<p>以下代码启动256个线程计算数组和。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="comment">// GPU function to add the elements of two arrays</span></span><br><span class="line">__global__</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">float</span> *x, <span class="keyword">float</span> *y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> index = threadIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = index; i &lt; n; i += stride)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> N = <span class="number">1</span>&lt;&lt;<span class="number">20</span>; <span class="comment">// 1M elements</span></span><br><span class="line">    <span class="keyword">float</span> *x, *y;</span><br><span class="line">    cudaMallocManaged(&amp;x, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">    cudaMallocManaged(&amp;y, N*<span class="keyword">sizeof</span>(<span class="keyword">float</span>));</span><br><span class="line">    <span class="comment">// initialize x and y arrays on the host</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++) &#123;</span><br><span class="line">        x[i] = <span class="number">1.0f</span>;</span><br><span class="line">        y[i] = <span class="number">2.0f</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Run kernel on 1M elements on the GPU</span></span><br><span class="line">    add&lt;&lt;&lt;<span class="number">1</span>, <span class="number">256</span>&gt;&gt;&gt;(N, x, y);</span><br><span class="line">    cudaDeviceSynchronize();</span><br><span class="line">    <span class="comment">// … for space, remove error checking/free</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>如果想用更多的线程的话：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">float</span> *x, <span class="keyword">float</span> *y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> index = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = index; i &lt; n; i += stride)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>更多指的是<code>numBlocks * blockSize</code>：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> blockSize = <span class="number">256</span>;</span><br><span class="line"><span class="keyword">int</span> numBlocks = (N + blockSize - <span class="number">1</span>) / blockSize;</span><br><span class="line">add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1638588598.jpg" alt></p>
<h1 id="lecture-9"><a href="#lecture-9" class="headerlink" title="lecture 9"></a>lecture 9</h1><p>互联网络的特性：</p>
<ul>
<li>直径：给定一对节点之间最短路径的最大值（在所有节点对上）。</li>
<li>延迟：多久能到达一个节点，即发送和接收时间之间的延迟<ul>
<li>不同体系结构的延迟往往差异很大</li>
<li>供应商经常报告硬件延迟（连线时间）</li>
<li>应用程序程序员关心软件延迟（用户程序到用户程序）</li>
<li>观察结果：<ul>
<li>网络设计的延迟相差1-2个数量级</li>
<li>源/目标成本下的软件/硬件开销占主导地位（1s-10s usecs）</li>
<li>硬件延迟随距离变化（每跳10s-100s纳秒），但与开销相比较小</li>
<li>延迟是包含许多小消息的程序的关键</li>
</ul>
</li>
</ul>
</li>
<li>带宽：单位时间内能传输多少数据<ul>
<li>对大消息的传输很重要</li>
</ul>
</li>
<li>对分带宽：将网络分成相同两部分的最小切割上的带宽<ul>
<li>对所有进程都需要和其他进程通信的算法很重要</li>
</ul>
</li>
</ul>
<p>设计网络的参数：</p>
<ul>
<li>拓扑结构<ul>
<li>crossbar、ring、2-D、3-D、超立方、树形、butterfly</li>
<li>参见高等计算机体系结构课程</li>
</ul>
</li>
<li>路由算法<ul>
<li>all east-west then all north-south</li>
</ul>
</li>
<li>发送策略<ul>
<li>circuit：对整个信息使用全部链路</li>
<li>packet：信息拆分成单独的消息发送</li>
</ul>
</li>
<li>流量控制<ul>
<li>消息暂时存储在buffer中、数据重新路由等</li>
</ul>
</li>
</ul>
<p>dragonflies：</p>
<ul>
<li>利用光互连（在机房机柜之间）和电气网络（机柜内部）之间的成本和性能差距<ul>
<li>光纤（光纤）更昂贵，但较长时带宽更高</li>
<li>电力（铜）网络更便宜，短路时更快</li>
</ul>
</li>
<li>在层次结构中组合：<ul>
<li>使用全对全链路将多个组连接在一起，即每个组至少有一个直接连接到其他组的链路。</li>
<li>每个组内的拓扑可以是任何拓扑。</li>
</ul>
</li>
<li>使用随机路由算法</li>
<li>结果：程序员可以（通常）忽略拓扑，获得良好的性能</li>
<li>在虚拟化动态环境中非常重要</li>
<li>缺点：性能可变</li>
</ul>
<p><img src="/img/1638590925.jpg" alt></p>
<p>在负载平衡的情况下，最小路由工作得很好，在大量的流量模式中可能会造成灾难性的后果。</p>
<p>随机化思想：对于路由器Rs上的每个数据包，并发送至另一组Rd中的路由器，首先将其路由到中间组。</p>
<p>发送消息的时间大概是：<code>T = latency+n*cost_per_word = latency + n / bandwidth</code>，也叫做<code>Time = α + n * β</code>。通常α远大于β。一个长消息比多个短消息更划算，同时需要较大的计算-通信比。</p>
<p>MPI：进程可以被分组，每个消息必须以一个上下文发送/接收。一个分组+上下文共同组成一个通信域。</p>
<p>MPI消息数据可以用一个（地址，数量，类型）三元组描述，有如下类型：</p>
<ul>
<li>预先定义的语言相关类型</li>
<li>某类型的连续数组</li>
<li>一个数据块</li>
<li>一些块数据</li>
<li>随机类型的数据</li>
</ul>
<p>MPI消息发送时会跟上一个用户定义的tag，来协助识别消息。</p>
<p>只有mpi_send时等待完成，或者mpi_send后返回，recv时在某个时间段等待，才能避免创建buffer。</p>
<p>MPI非阻塞操作返回request<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">MPI_Request request;</span><br><span class="line">MPI_Status status;</span><br><span class="line"></span><br><span class="line">MPI_Isend(start, count, datatype, dest, tag, comm, &amp;request);</span><br><span class="line">MPI_Irecv(start, count, datatype, dest, tag, comm, &amp;request);</span><br><span class="line">MPI_Wait(&amp;request, &amp;status);</span><br></pre></td></tr></table></figure></p>
<p>可以通过测试来等待：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MPI_Test(&amp;request, &amp;flag, &amp;status);</span><br></pre></td></tr></table></figure></p>
<p>在未完成通信时访问缓冲区是未定义的</p>
<p>可以同时等待多个：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">MPI_Waitall(count, array_of_requests,array_of_statuses)</span><br><span class="line">MPI_Waitany(count, array_of_requests, &amp;index, &amp;status)</span><br><span class="line">MPI_Waitsome(count, array_of_requests, array_of indices, array_of_statuses)</span><br></pre></td></tr></table></figure></p>
<p>MPI提供多种发送消息的模式：</p>
<ul>
<li>同步模式（MPI_Ssend）：在匹配的接收开始之前，发送不会完成。（不安全程序死锁。）</li>
<li>缓冲模式（MPI_Bsend）：用户向系统提供一个缓冲区供其使用。用户分配足够的内存使不安全的程序安全。</li>
<li>就绪模式（MPI_Rsend）：用户保证已发布匹配的接收。<ul>
<li>允许访问快速协议</li>
<li>如果匹配接收未发布，则未定义行为</li>
</ul>
</li>
</ul>
<p>集合操作：包括broadcast、gather/scatter，allgather、alltoall、reduce、scan。</p>
<p>MXX是一个MPI的库，基于MPI在交换不规则数据的时候以下的几种复杂操作：</p>
<ul>
<li>交换不规则数据时麻烦<ul>
<li>交换数量</li>
<li>拷贝数据</li>
<li>分配空间</li>
<li>交换实际数据</li>
</ul>
</li>
<li>创建派生的非PDO类型</li>
<li>将用户定义函数映射给MPI</li>
</ul>
<p>而MXX只要如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// lets take some pairs and find the one with the max second element</span></span><br><span class="line"><span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">double</span>&gt; v = ...;</span><br><span class="line"><span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">double</span>&gt; min_pair = mxx::allreduce(v, [](<span class="keyword">const</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">double</span>&gt;&amp; x, <span class="keyword">const</span> <span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">double</span>&gt;&amp; y) &#123;</span><br><span class="line">    <span class="keyword">return</span> x.second &gt; y.second ? x : y;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>SUMMA：可扩展矩阵乘法<br><img src="/img/1638599104.jpg" alt></p>
<p>C(I, J) = C(I, J) + ∑k(A(I, k) * B(k, J))，其中I，J代表一个进程所有的行列，k是单独的一行或列，或者一块。</p>
<p>对于每个k（0和n-1之间），</p>
<ul>
<li>部分K行的所有者沿其进程列广播该行</li>
<li>部分K列的所有者沿其进程行广播该列</li>
</ul>
<p>完整算法：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">在每个进程P(i, j)：</span><br><span class="line">    对于k=0…n-1</span><br><span class="line">        在第i行中广播A（A_i）的第k列</span><br><span class="line">        在第j列中广播B（B_j）的第k行</span><br><span class="line">        C += 外积（a_i，b_j）</span><br></pre></td></tr></table></figure></p>
<p>如果是<code>P^(1/2)</code>*<code>P^(1/2)</code>剖分：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">For k=0 to n/b-1</span><br><span class="line">    for all i = 1 to P^(1/2)</span><br><span class="line">        owner of A[i,k] broadcasts it to whole processor row (using binary tree)</span><br><span class="line">    for all j = 1 to P^(1/2)</span><br><span class="line">        owner of B[k,j] broadcasts it to whole processor column (using bin. tree)</span><br><span class="line">    Receive A[i,k] into Acol</span><br><span class="line">    Receive B[k,j] into Brow</span><br><span class="line">    C_myproc = C_myproc + Acol * Brow</span><br></pre></td></tr></table></figure></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SUMMA</span><span class="params">(<span class="keyword">double</span> *mA, <span class="keyword">double</span> *mB, <span class="keyword">double</span> *mc, <span class="keyword">int</span> p_c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> row_color = rank / p_c; <span class="comment">// p_c = sqrt(p) for simplicity</span></span><br><span class="line">    MPI_Comm row_comm;</span><br><span class="line">    MPI_Comm_split(MPI_COMM_WORLD, row_color, rank, &amp;row_comm);</span><br><span class="line">    <span class="keyword">int</span> col_color = rank % p_c;</span><br><span class="line">    MPI_Comm col_comm;</span><br><span class="line">    MPI_Comm_split(MPI_COMM_WORLD, col_color, rank, &amp;col_comm);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; p_c; ++k) &#123;</span><br><span class="line">        <span class="keyword">if</span> (col_color == k) <span class="built_in">memcpy</span>(Atemp, mA, size);</span><br><span class="line">        <span class="keyword">if</span> (row_color == k) <span class="built_in">memcpy</span>(Btemp, mB, size);</span><br><span class="line">        MPI_Bcast(Atemp, size, MPI_DOUBLE, k, row_comm);</span><br><span class="line">        MPI_Bcast(Btemp, size, MPI_DOUBLE, k, col_comm);</span><br><span class="line">        SimpleDGEMM(Atemp, Btemp, mc, N/p, N/p, N/p);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>int MPI_Comm_split(MPI_Comm Comm, int color, int key, MPI_Comm* newcomm)</code>中MPI的内部算法：</p>
<ol>
<li>使用<code>MPI_Allgather</code>从每个进程获取颜色和键</li>
<li>统计相同颜色的进程数；创建一个具有这么多进程的通信器。如果此进程将<code>MPI_UNDEFINED</code>为颜色，请创建一个具有单个成员的进程。</li>
<li>使用键对列组进行排序</li>
</ol>
<ul>
<li>颜色：控制newcomm的分配</li>
<li>键：控制newcomm内的rank分配</li>
</ul>
<p>MPI内建的集合操作：</p>
<ul>
<li><code>MPI_MAX</code>：Maximum</li>
<li><code>MPI_MIN</code>：Minimum</li>
<li><code>MPI_PROD</code>：Product</li>
<li><code>MPI_SUM</code>：Sum</li>
<li><code>MPI_LAND</code>：Logical and</li>
<li><code>MPI_LOR</code>：Logical or</li>
<li><code>MPI_LXOR</code>：Logical exclusive or</li>
<li><code>MPI_BAND</code>：Binary and</li>
<li><code>MPI_BOR</code>：Binary or</li>
<li><code>MPI_BXOR</code>：Binary exclusive or</li>
<li><code>MPI_MAXLOC</code>：Maximum and location</li>
<li><code>MPI_MINLOC</code>：Minimum and location</li>
</ul>
<p>集合操作实现的示例：MPI_AllReduce</p>
<ol>
<li>所有进程必须接收相同的结果向量；</li>
<li>必须按照规范顺序m0 + m1 + … + mp-1进行归约（如果操作不是可交换的）；</li>
<li>对于结果向量的所有元素，不严格要求使用相同的规约顺序和括号，但应努力做到这一点。</li>
</ol>
<p>复杂度下界：<br><img src="/img/1638600585.jpg" alt></p>
<p>MPI_AllGather有几种实现：</p>
<ol>
<li>环算法：在0时刻，发送你自己的数据；在t时刻，把你在t-1时刻收到的数据发给你右边，从你左边接收新的数据；利用了带宽，但是有很高的延迟。在数据很大的时候使用，反而比下边的算法快很多，减少数据拷贝，降低通信次数，且只跟邻居通信。</li>
<li>递归算法：在t时刻，进程i与进程<code>i+2^t</code>交换现有的所有数据，形成通信树结构。</li>
<li>bruck算法；在t时刻，进程i从<code>i+2^t</code>接受所有的数据，发送它自己所有的数据给<code>i+2^t</code>。该过程在lg(p)次后结束，在最后一次，仅收发最上边（p-2^(lg(p))）个数据。同时需要租后进行顺序调整。</li>
</ol>
<p><img src="/img/1638601045.jpg" alt><br><img src="/img/1638601080.jpg" alt></p>
<p>SUMMA in MPI<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SUMMA</span><span class="params">(<span class="keyword">double</span> *mA, <span class="keyword">double</span> *mB, <span class="keyword">double</span> *mc, <span class="keyword">int</span> p_c)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> row_color = rank / p_c; <span class="comment">// p_c = sqrt(p) for simplicity</span></span><br><span class="line">    MPI_Comm row_comm;</span><br><span class="line">    MPI_Comm_split(MPI_COMM_WORLD, row_color, rank, &amp;row_comm);</span><br><span class="line">    <span class="keyword">int</span> col_color = rank % p_c;</span><br><span class="line">    MPI_Comm col_comm;</span><br><span class="line">    MPI_Comm_split(MPI_COMM_WORLD, col_color, rank, &amp;col_comm);</span><br><span class="line">    <span class="keyword">double</span> *mA1, *mA2, *mB1, *mB2;</span><br><span class="line">    colsplit(mA, mA1, mA2); <span class="comment">// split mA by the middle column</span></span><br><span class="line">    rowsplit(mB, mB1, mB2); <span class="comment">// split mA by the middle row</span></span><br><span class="line">    <span class="keyword">if</span> (col_color == <span class="number">0</span>) <span class="built_in">memcpy</span>(Atemp1, mA1, size)</span><br><span class="line">    <span class="keyword">if</span> (row_color == <span class="number">0</span>) <span class="built_in">memcpy</span>(Btemp1, mB1, size);</span><br><span class="line">    MPI_Request reqs1[<span class="number">2</span>];</span><br><span class="line">    MPI_Request reqs2[<span class="number">2</span>];</span><br><span class="line">    MPI_Ibcast(Atemp1, size, MPI_DOUBLE, k, row_comm, &amp;reqs1[<span class="number">0</span>]);</span><br><span class="line">    MPI_Ibcast(Btemp1, size, MPI_DOUBLE, k, col_comm, &amp;reqs1[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; p_c<span class="number">-1</span>; ++ k) &#123;</span><br><span class="line">        <span class="keyword">if</span> (col_color == k) <span class="built_in">memcpy</span>(Atemp2, mA2, size);</span><br><span class="line">        <span class="keyword">if</span> (row_color == k) <span class="built_in">memcpy</span>(Btemp2, mB2, size);</span><br><span class="line">        MPI_Ibcast(Atemp2,size,MPI_DOUBLE,k,row_comm,&amp;reqs2[<span class="number">0</span>]);</span><br><span class="line">        MPI_Ibcast(Btemp2,size,MPI_DOUBLE,k,col_comm,&amp;reqs2[<span class="number">1</span>]);</span><br><span class="line">        MPI_Waitall(reqs1, MPI_STATUS_IGNORE);</span><br><span class="line">        SimpleDGEMM (Atemp1, Btemp1, mC, N/p, N/p, N/p);</span><br><span class="line">        <span class="keyword">if</span> (col_color == k) <span class="built_in">memcpy</span>(Atemp1, mA1, size);</span><br><span class="line">        <span class="keyword">if</span> (row_color == k) <span class="built_in">memcpy</span>(Btemp1, mB1, size);</span><br><span class="line">        MPI_Ibcast(Atemp1,size,MPI_DOUBLE,k,row_comm,&amp;reqs1[<span class="number">0</span>]);</span><br><span class="line">        MPI_Ibcast(Btemp1,size,MPI_DOUBLE,k,col_comm,&amp;reqs1[<span class="number">1</span>]);</span><br><span class="line">        MPI_Waitall(reqs2, MPI_STATUS_IGNORE);</span><br><span class="line">        SimpleDGEMM (Atemp2, Btemp2, mC, N/p, N/p, N/p);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (col_color == p<span class="number">-1</span>) <span class="built_in">memcpy</span>(Atemp2, mA2, size);</span><br><span class="line">    <span class="keyword">if</span> (row_color == p<span class="number">-1</span>) <span class="built_in">memcpy</span>(Btemp2, mB2, size);</span><br><span class="line">    MPI_Ibcast(Atemp2,size,MPI_DOUBLE,k,row_comm,&amp;reqs2[<span class="number">0</span>]);</span><br><span class="line">    MPI_Ibcast(Btemp2,size,MPI_DOUBLE,k,col_comm,&amp;reqs2[<span class="number">1</span>]);</span><br><span class="line">    MPI_Waitall(reqs1, MPI_STATUS_IGNORE);</span><br><span class="line">    SimpleDGEMM (Atemp1, Btemp1, mC, N/p, N/p, N/p);</span><br><span class="line">    MPI_Waitall(reqs2, MPI_STATUS_IGNORE);</span><br><span class="line">    SimpleDGEMM (Atemp2, Btemp2, mC, N/p, N/p, N/p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>MPI描述进程之间的并行性（使用单独的地址空间）Thread并行性在进程内提供共享内存模型</p>
<ul>
<li>OpenMP和pthread是常见的模型</li>
<li>OpenMP为循环级并行提供了方便的功能。线程由编译器根据用户指令创建和管理。</li>
<li>pthread提供了更复杂、更动态的方法。Thread由用户显式创建和管理。</li>
</ul>
<p>在仅MPI编程中，每个MPI进程都有一个程序计数器。在MPI+线程混合编程中，可以同时执行多个线程。所有线程共享所有MPI对象（通讯器、请求）。MPI实施可能需要采取措施确保MPI堆栈的状态一致。</p>
<p>MPI的四个线程安全级别：MPI定义了四个线程安全级别</p>
<ul>
<li><code>MPI_THREAD_SINGLE</code>：应用程序中只存在一个线程</li>
<li><code>MPI_THREAD_FUNNELED</code>：多线程，但只有主线程进行MPI调用（调用<code>MPI_Init_thread</code>的调用）</li>
<li><code>MPI_THREAD_SERIALIZED</code>：多线程，但一次只能有一个线程进行MPI调用</li>
<li><code>MPI_THREAD_MULTIPLE</code>：多线程，任何线程都可以在任何时候（有一些限制以避免竞争）</li>
</ul>
<p>MPI定义了<code>MPI_Init</code>的替代方案：<code>MPI_Init_thread(requested, provided)</code></p>
<pre><code>- 应用程序给出了它所需要的级别；MPI实现提供了它所支持的级别
</code></pre><p><code>MPI_THREAD_SINGLE</code>时没有线程<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> buf[<span class="number">100</span>];</span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">        compute(buf[i]);</span><br><span class="line">    <span class="comment">/* Do MPI stuff */</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>MPI_THREAD_FUNNELED</code>时所有MPI调用都是主线程在调用，在OpenMP并行区域外。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> buf[<span class="number">100</span>], provided;</span><br><span class="line">    MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_FUNNELED, &amp;provided);</span><br><span class="line">    <span class="keyword">if</span> (provided &lt; MPI_THREAD_FUNNELED)</span><br><span class="line">        MPI_Abort(MPI_COMM_WORLD, <span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++)</span><br><span class="line">        compute(buf[i]);</span><br><span class="line">    <span class="comment">/* Do MPI stuff */</span></span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>MPI_THREAD_SERIALIZED</code>一次只能有一个线程调用MPI函数，这被critical regions保证。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> buf[<span class="number">100</span>], provided;</span><br><span class="line">    MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_SERIALIZED, &amp;provided);</span><br><span class="line">    <span class="keyword">if</span> (provided &lt; MPI_THREAD_SERIALIZED)</span><br><span class="line">        MPI_Abort(MPI_COMM_WORLD, <span class="number">1</span>);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        compute(buf[i]);</span><br><span class="line">        <span class="meta">#<span class="meta-keyword">pragma</span> omp critical</span></span><br><span class="line">        <span class="comment">/* Do MPI stuff */</span></span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>MPI_THREAD_MULTIPLE</code>任何线程都可以随时进行MPI调用（不受限制）<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> buf[<span class="number">100</span>], provided;</span><br><span class="line">    MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_MULTIPLE, &amp;provided);</span><br><span class="line">    <span class="keyword">if</span> (provided &lt; MPI_THREAD_MULTIPLE)</span><br><span class="line">        MPI_Abort(MPI_COMM_WORLD, <span class="number">1</span>);</span><br><span class="line">    <span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">        compute(buf[i]);</span><br><span class="line">        <span class="comment">/* Do MPI stuff */</span></span><br><span class="line">    &#125;</span><br><span class="line">    MPI_Finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>实现不需要支持高于<code>MPI_THREAD_SINGLE</code>的级别；也就是说，实现不需要是线程安全的。</p>
<p>调用<code>MPI_Init</code>（而不是<code>MPI_Init_thread</code>）的程序应假定只支持<code>MPI_THREAD_SINGLE</code>。不调用<code>MPI_Init_thread</code>的线程化MPI程序是不正确的程序。</p>
<p><code>MPI_THREAD_MULTIPLE</code>的约定</p>
<ul>
<li>排序：当多个线程同时进行MPI调用时，结果将是，调用在某些情况下按某些顺序执行</li>
<li>在每个线程内维护顺序</li>
<li>用户必须确保在同一个comm上进行集体操作，窗口或文件句柄在线程之间的顺序正确<ul>
<li>例如，不能在一个线程上调用广播，在另一个线程上调用reduce</li>
</ul>
</li>
<li>当线程处于同一位置时，用户有责任防止冲突MPI调用<ul>
<li>例如，从一个线程访问信息对象并将其从另一线程释放。</li>
</ul>
</li>
<li>阻塞：阻塞MPI调用将只阻塞调用线程，不会阻止其他线程运行或执行MPI</li>
</ul>
<p>一个正确的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              Proc 0            Proc 1</span><br><span class="line">Thread1   MPI_Recv(src=1)   MPI_Recv(src=0)</span><br><span class="line">Thread2   MPI_Send(dst=1)   MPI_Send(dst=0)</span><br></pre></td></tr></table></figure></p>
<p>一个不正确的例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">              Proc 0            Proc 1</span><br><span class="line">Thread1  MPI_Bcast(comm)   MPI_Bcast(comm)</span><br><span class="line">Thread2  MPI_Barrier(comm)   MPI_Barrier(comm)</span><br></pre></td></tr></table></figure></p>
<p>P0和P1可以有不同的Bcast和Barrier顺序</p>
<p>在这里，用户必须使用某种类型的同步，以确保线程1或线程2在两个进程上都首先得到调度，否则Bcast可能与同一comm上的Barrier匹配，这在MPI中是不允许的。</p>
<p>单边通信模型的基本思想是将数据移动与进程同步解耦</p>
<ul>
<li>应能够在不要求远程进程同步的情况下移动数据</li>
<li>每个进程向其他进程公开其内存的一部分</li>
<li><p>其他进程可以直接读取或写入该内存</p>
</li>
<li><p>创建公共内存</p>
<ul>
<li>默认情况下，进程使用的任何内存都是只有本地可访问</li>
<li>分配内存后，用户必须进行显式MPI调用，以将内存区域声明为可远程访问<ul>
<li>远程可访问内存的MPI术语是一个“窗口”</li>
<li>一组进程共同创建一个“窗口”</li>
</ul>
</li>
<li>一旦内存区域被声明为可远程访问，窗口中的所有进程都可以向该内存读/写数据，而无需与目标进程显式同步</li>
</ul>
</li>
<li><p>窗口创建存在四种模式</p>
<ul>
<li><code>MPI_WIN_CREATE</code>：您已经有一个分配的缓冲区，您希望远程访问该缓冲区</li>
<li><code>MPI_WIN_ALLOCATE</code>：您希望创建一个缓冲区并直接使其可远程访问</li>
<li><code>MPI_WIN_CREATE_DYNAMIC</code>：您还没有缓冲区，但将来会有缓冲区，且您可能希望在窗口中动态添加/删除缓冲区</li>
<li><code>MPI_WIN_ALLOCATE_SHARED</code>：您希望同一节点上的多个进程共享一个缓冲区</li>
</ul>
</li>
</ul>
<p><code>MPI_WIN_ALLOCATE</code>：在RMA窗口中创建一个远端可访问的内存区域<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">MPI_Win_allocate</span><span class="params">(MPI_Aint size, <span class="keyword">int</span> disp_unit,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Info info, MPI_Comm comm, <span class="keyword">void</span> *baseptr,</span></span></span><br><span class="line"><span class="function"><span class="params">    MPI_Win *win)</span></span></span><br></pre></td></tr></table></figure></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> ** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> *a; MPI_Win win;</span><br><span class="line">    MPI_Init(&amp;argc, &amp;argv);</span><br><span class="line">    <span class="comment">/* collectively create remote accessible memory in a window */</span></span><br><span class="line">    MPI_Win_allocate(<span class="number">1000</span>*<span class="keyword">sizeof</span>(<span class="keyword">int</span>), <span class="keyword">sizeof</span>(<span class="keyword">int</span>), MPI_INFO_NULL, MPI_COMM_WORLD, &amp;a, &amp;win);</span><br><span class="line">    <span class="comment">/* Array ‘a’ is now accessible from all processes in MPI_COMM_WORLD */</span></span><br><span class="line">    MPI_Win_free(&amp;win);</span><br><span class="line">    MPI_Finalize(); </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MPI提供了在远程可访问内存区域中读取、写入和原子修改数据的能力：</p>
<ul>
<li><code>MPI_PUT</code></li>
<li><code>MPI_GET</code></li>
<li><code>MPI_ACCUMULATE</code></li>
<li><code>MPI_GET_ACCUMULATE</code></li>
<li><code>MPI_COMPARE_AND_SWAP</code></li>
<li><code>MPI_FETCH_AND_OP</code></li>
</ul>
<p>RMA同步模型</p>
<ul>
<li>RMA数据访问模型<ul>
<li>何时允许进程读取/写入远程可访问内存？</li>
<li>进程X写入的数据何时可供进程Y读取？</li>
<li>RMA同步模型定义了这些语义</li>
</ul>
</li>
<li>MPI提供的三种同步模型：<ul>
<li>Fence（主动目标）</li>
<li>启动后完全等待（通用活动目标）</li>
<li>锁定/解锁（被动目标）</li>
</ul>
</li>
<li>数据访问发生在“epochs”内<ul>
<li>访问时间：包含一组由源进程发出的操作</li>
<li>曝光时间：允许远程进程更新目标窗口</li>
<li>epochs定义了顺序和完成语义</li>
<li>同步模型提供了建立epochs的机制</li>
</ul>
</li>
</ul>
<p>被动目标同步</p>
<ul>
<li>开始/结束被动模式<ul>
<li>目标进程不进行相应的MPI调用</li>
<li>可以启动多个被动目标事件到不同的进程</li>
<li>不允许同一进程的并发（影响线程）</li>
</ul>
</li>
<li>锁<ul>
<li>共享：其他使用共享的进程可以同时访问</li>
<li>独占：没有其他进程可以同时访问</li>
</ul>
</li>
</ul>
<p>共享内存和消息传递各有优缺点，共享内存更容易并行，容易竞争，且更容易陷入假共享之类的；消息传递需要做更多的工作，但是不容易死锁，具有很高的扩展性。</p>
<p>全局地址空间中，线程可以直接读写远端数据，给通信实现提供了方便。因此需要一种方式来命名全局空间。（以下使用UPC方式）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">shared int *p = upc_malloc(4);</span><br><span class="line">shared int a[12];</span><br></pre></td></tr></table></figure></p>
<p>如果需要单边通信：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a[i] = ...; *p = ...; upc_mem_put(...);</span><br><span class="line">... = a[i]; ... = *p; upc_mem_get(...);</span><br></pre></td></tr></table></figure></p>
<h1 id="lecture-11"><a href="#lecture-11" class="headerlink" title="lecture 11"></a>lecture 11</h1><p>PGAS编程的目标</p>
<ul>
<li>应用：不规则代码的方便编程<ul>
<li>图</li>
<li>哈希表</li>
<li>稀疏矩阵</li>
<li>自适应（分层）网格</li>
</ul>
</li>
<li>机器：在计算机上显示最佳可用性能<ul>
<li>小消息的低延迟</li>
<li>即使对于中等大小的消息，带宽也很高</li>
<li>高注入速率（消息数/秒）</li>
<li>最小化软件开销并匹配硬件</li>
</ul>
</li>
</ul>
<p>UPC++与MPI类似，也是SPMD程序，使用GASNet库通信。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;upcxx/upcxx.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    upcxx::init();</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"Hello from "</span> &lt;&lt; upcxx::rank_me() &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    upcxx::finalize();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>用UPC++计算π如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    upcxx::init();</span><br><span class="line">    <span class="keyword">int</span> hits, trials = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> pi;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (argc != <span class="number">2</span>) trials = <span class="number">1000000</span>;</span><br><span class="line">    <span class="keyword">else</span> trials = atoi(argv[<span class="number">1</span>]);</span><br><span class="line"></span><br><span class="line">    generator.seed(upcxx::rank_me()*<span class="number">17</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; trials; i++) hits += hit();</span><br><span class="line">    pi = <span class="number">4.0</span>*hits/trials;</span><br><span class="line">    <span class="built_in">cout</span> &lt;&lt; <span class="string">"PI estimated to "</span> &lt;&lt; pi &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    upcxx::finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>一般的C++变量和对象在每个线程的私有内存空间分配。共享空间的变量需要用<code>new_</code>显式分配，用<code>delete_</code>释放，共享内存可以被远端进程访问：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">global_ptr&lt;<span class="keyword">int</span>&gt; gptr = new_&lt;<span class="keyword">int</span>&gt;(rank_me());</span><br></pre></td></tr></table></figure></p>
<p>如果需要广播：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">global_ptr&lt;<span class="keyword">int</span>&gt; gptr =</span><br><span class="line">    broadcast(new_&lt;<span class="keyword">int</span>&gt;(<span class="number">24</span>),<span class="number">0</span>).wait();</span><br></pre></td></tr></table></figure></p>
<p>future类型的变量有一个状态位，标志是否准备好，等待future类型就绪使用户可以实现异步操作。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">future&lt;T&gt; f1 = rget(gptr1); <span class="comment">// asynchronous op</span></span><br><span class="line">future&lt;T&gt; f2 = rget(gptr2);</span><br><span class="line"><span class="keyword">bool</span> ready = f1.ready(); <span class="comment">// non-blocking poll</span></span><br><span class="line"><span class="keyword">if</span> !ready … <span class="comment">// unrelated work...</span></span><br><span class="line">T t = f1.wait(); <span class="comment">// waits if not ready</span></span><br></pre></td></tr></table></figure></p>
<p>单边通信如下，同时支持不连续内存数据：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">future&lt;T&gt; rget(global_ptr&lt;T&gt; src);</span><br><span class="line">future&lt;&gt; rput(T val, global_ptr&lt;T&gt; dst);</span><br></pre></td></tr></table></figure></p>
<p>同步操作：</p>
<ul>
<li>Barrier: block until all other threads arrive<br>barrier();</li>
<li>Asynchronous barriers</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">future&lt;&gt; f =</span><br><span class="line">    barrier_async(); <span class="comment">// this thread is ready for barrier</span></span><br><span class="line"><span class="comment">// do computation unrelated to barrier</span></span><br><span class="line">wait(f); <span class="comment">// wait for others to be ready</span></span><br></pre></td></tr></table></figure>
<p>UPC++有一部分集合操作，都是异步的<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; future &lt;T&gt;</span><br><span class="line">broadcast (T &amp;&amp; value , <span class="keyword">intrank_t</span> root);</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; future &lt;T&gt;</span><br><span class="line">broadcast (T * buffer, <span class="built_in">std</span>::<span class="keyword">size_t</span> count,</span><br><span class="line"><span class="keyword">intrank_t</span> sender);</span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T, <span class="keyword">typename</span> BinaryOp&gt;</span><br><span class="line">future &lt;T&gt; reduce_all (T &amp;&amp; value, BinaryOp &amp;&amp;op);</span><br></pre></td></tr></table></figure></p>
<p>远端过程调用：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">future&lt;R&gt; rpc(<span class="keyword">intrank_t</span> r,</span><br><span class="line">F func, Args&amp;&amp;... args);</span><br></pre></td></tr></table></figure></p>
<p>在进程r执行<code>func(args...)</code>并返回结果，R是返回类型。<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> hits = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> **argv)</span> </span>&#123;</span><br><span class="line">    init();</span><br><span class="line">    <span class="keyword">int</span> trials = atoi(argv[<span class="number">1</span>]);</span><br><span class="line">    <span class="keyword">int</span> my_trials = (trials+rank_me())/rank_n();</span><br><span class="line">    generator.seed(rank_me()*<span class="number">17</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; my_trials; i++) &#123;</span><br><span class="line">        rpc(<span class="number">0</span>, [](<span class="keyword">int</span> hit) &#123; hits += hit; &#125;, hit()).wait();</span><br><span class="line">    &#125;</span><br><span class="line">    barrier();</span><br><span class="line">    <span class="keyword">if</span> (rank_me() == <span class="number">0</span>)</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"PI estimated to "</span> &lt;&lt; <span class="number">4.0</span>*hits/trials;</span><br><span class="line">    finalize();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h1 id="lecture-12"><a href="#lecture-12" class="headerlink" title="lecture 12"></a>lecture 12</h1><p>mapreduce模型：</p>
<ul>
<li>每条记录是一个（key, value）</li>
<li>map：<code>(K[in], V[in]) --&gt; list(K[inter], V[inter])</code></li>
<li>reduce：<code>(K[inter], list(V[inter])) --&gt; list(K[out], V[out])</code></li>
</ul>
<p>MapReduce着眼于更高级的数据并行，自动进行数据通信等，关注容错。</p>
<h1 id="lecture-13"><a href="#lecture-13" class="headerlink" title="lecture 13"></a>lecture 13</h1><p>BLAS(1)：对于向量的15个操作，对O(1)的数据做O(1)的操作。对于<code>y = a * x + y</code>这种需要2n的计算和3n的读写的操作，计算强度为2/3，读写更多，且不能向量化，所以出现了BLAS(2)，主要针对矩阵-向量对进行25种操作，对O(2)的数据做O(2)的操作。BLAS(3)，主要针对矩阵-矩阵对进行9种操作，对O(2)的数据做O(3)的操作，计算强度为(2n^3)/(4n^2)=n/2。LAPACK在BLAS是并行的时候才并行。</p>
<p>为什么要避免通信：</p>
<ul>
<li>在DRAM间移动数据很费时；</li>
<li>算法运行时间由:<ul>
<li>flops * time_per_flop</li>
<li>words moved / bandwidth</li>
<li>messages * latency</li>
<li>组成，后两项是通信时间</li>
<li>latency是最久的</li>
</ul>
</li>
<li>需要将线性代数组织起来以免通信</li>
</ul>
<p>blocked matrix multiply：<code>C = A*B</code>。将A、B和C切分成<code>b*b</code>，再分到每个进程，当b=1时退化成原始的矩阵乘。总共需要<code>(n/b)^3 * 4b^2 = 4 * n^3 / b</code>次读写，当(3*b^2)=cache时最小化。</p>
<p>对于矩阵乘的n^3算法，</p>
<ul>
<li>串行算法， 且缓存为M<ul>
<li>数据从主存中移动的下界为W (n^3 / M^(1/2) )</li>
<li>假定使用分块或者cache敏感的算法</li>
</ul>
</li>
<li>P个进程的并行算法<ul>
<li>M是每个进程的内存</li>
<li>数据从主存中移动的下界为W((n^3/p) / M^(1/2) )</li>
<li>如果M = 3n^2/p (每个矩阵的一份拷贝之和)，下界为W (n^2 /p^(1/2) )</li>
</ul>
</li>
</ul>
<p>算法的目标：</p>
<ul>
<li>尽量减少移动的数据</li>
<li>尽量减少发送的信息<ul>
<li>需要新的数据结构</li>
</ul>
</li>
<li>多个内存层次结构中最小化用量</li>
<li>当矩阵适合最快的内存时，运算/通信最少</li>
</ul>
<p>多种不同的矩阵剖分方法：</p>
<ul>
<li>1D剖分</li>
<li>1D循环剖分</li>
<li>1D列块循环</li>
<li>对应1D的行剖分</li>
<li>2D剖分</li>
<li>2D循环剖分</li>
</ul>
<p><img src="/img/1638684331.jpg" alt></p>
<p>并行矩阵-向量乘：计算<code>y = y + A * x</code>，使用1D行剖分，A(i)是n/p个进程i拥有的行，x(i)和y(i)类似，也是进程i拥有的数据。</p>
<p>对于每个进程：广播x(i)，计算y(i)=A(i)<em>x。整个算法使用了`y(i) = y(i) + A(i) </em> x = y(i) + ∑(j) A(i,j)*x(j)`。</p>
<p>如果使用列剖分，减少了x的广播，但是增加了一步规约操作。2D块剖分使用了广播和规约，但都是对一个进程子集，通信开销会小一些。<br><img src="/img/1638684798.jpg" alt></p>
<p>并行矩阵乘法：使用1D剖分且没有广播：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">C(myproc) = C(myproc) + A(myproc)*B(myproc,myproc)</span><br><span class="line">for i = 0 to p-1</span><br><span class="line">    for j = 0 to p-1 except i</span><br><span class="line">        if (myproc == i) send A(i) to processor j</span><br><span class="line">        if (myproc == j)</span><br><span class="line">            receive A(i) from processor i</span><br><span class="line">            C(myproc) = C(myproc) + A(i)*B(i,myproc)</span><br><span class="line">        barrier</span><br></pre></td></tr></table></figure></p>
<p>Cost of inner loop:</p>
<ul>
<li>computation: <code>2*n*(n/p)^2 = 2*n^3/p^2</code></li>
<li>communication: <code>a + b*n^2 /p</code></li>
</ul>
<p>Running time = <code>(p*(p-1) + 1)*computation + p*(p-1)*communication</code> = <code>2*n^3 + p^2*a + p*n^2*b</code></p>
<p>缺点是每次迭代只有一对进程是活跃的，只有i进程在计算。</p>
<p>改进：相邻的进程对可以同时通信：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Copy A(myproc) into Tmp</span><br><span class="line">C(myproc) = C(myproc) + Tmp*B(myproc , myproc)</span><br><span class="line">for j = 1 to p-1</span><br><span class="line">Send Tmp to processor myproc+1 mod p</span><br><span class="line">Receive Tmp from processor myproc-1 mod p</span><br><span class="line">C(myproc) = C(myproc) + Tmp*B( myproc-j mod p , myproc)</span><br></pre></td></tr></table></figure></p>
<ul>
<li>可能需要双倍的buffer</li>
<li>代码中没有考虑可能的死锁</li>
<li>Time of inner loop = <code>2*(a + b*n^2/p) + 2*n*(n/p)^2</code></li>
<li>Total Time = <code>2*n* (n/p)^2 + (p-1) * Time of inner loop</code> = <code>2*n^3/p + 2*p*a + 2*b*n^2</code></li>
</ul>
<p><code>A(myproc)</code>必须得发给每一个进程，最少开销<code>(p-1)*cost of sending n*(n/p) words</code></p>
<p>并行效率 = <code>2*n^3 / (p * Total Time)</code> = <code>1/(1 + a * p^2/(2*n^3) + b * p/(2*n) )</code> = <code>1/ (1 + O(p/n))</code>，当n/p增加时负责度降低。</p>
<p>如果是2.5D矩阵乘：各个进程拥有<code>cn^2 / P</code>数据，总共数据组织成<code>(P/c)^(1/2) * (P/c)^(1/2) * c</code>网格。最开始进程P(i,j,0)拥有A(i,j)和B(i,j)，每一个数组大小为<code>n(c/P)^(1/2)*n(c/P)^(1/2)</code>。</p>
<ul>
<li>进程P(i,j,0)广播A(i,j)和B(i,j)给P(i,j,k)</li>
<li>k阶的进程执行SUMMA</li>
<li>在k方向上对结果<code>∑(m) A(i,m)*B(m,j)</code>规约，所以P(i,j,0)拥有了C(i,j)。</li>
</ul>
<p>为了求解Ax=b，进行高斯消去。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">… for each column i</span><br><span class="line">… zero it out below the diagonal by adding multiples of row i to later rows</span><br><span class="line">for i = 1 to n-1</span><br><span class="line">    … for each row j below row i</span><br><span class="line">    A(j,i) = A(j,i) / A(i,i);</span><br><span class="line">    for j = i+1 to n</span><br><span class="line">        for k = i+1 to n</span><br><span class="line">            A(j,k) = A(j,k) - A(j,i) * A(i,k)</span><br></pre></td></tr></table></figure></p>
<p><img src="/img/1638688009.png" alt></p>
<p>高斯消去实际上也是求了一个LU分解，<code>A=L*U</code>，在求解方程<code>A*x=b</code>时</p>
<ul>
<li>使用高斯消去分解A=L*U</li>
<li>求解L*y=b</li>
<li>求解U*x=y</li>
<li>因此<code>A*x = (L*U)*x = L*(U*x) = L*y = b</code></li>
</ul>
<p>当矩阵A比较小或者有0时，可能会得到错误的结果。因此需要交换把A(i,i)变成一列里最大的，GEPP（Gaussian Elimination with Partial Pivoting）。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">for i = 1 to n-1</span><br><span class="line">    find and record k where |A(k,i)| = max&#123;i ≤ j ≤ n&#125; |A(j,i)|</span><br><span class="line">    … i.e. largest entry in rest of column i</span><br><span class="line">    if |A(k,i)| = 0</span><br><span class="line">        exit with a warning that A is singular, or nearly so</span><br><span class="line">    elseif k ≠ i</span><br><span class="line">        swap rows i and k of A</span><br><span class="line">    end if</span><br><span class="line">    A(i+1:n,i) = A(i+1:n,i) / A(i,i) … each |quotient| ≤ 1</span><br><span class="line">    A(i+1:n,i+1:n) = A(i+1:n , i+1:n ) - A(i+1:n , i) * A(i , i+1:n)</span><br></pre></td></tr></table></figure></p>
<p>以上算法计算<code>A=P*L*U</code>，这是数值上很稳定的。</p>
<p>分块用于计算矩阵乘法，但是在这里由于数据依赖更多很难分块。使用“delayed updates”，将多个连续矩阵的更新保存到跟踪矩阵，之后在一个BLAS3（matmul）操作中同时应用多个更新。</p>
<p>首先要选择一个适当的“b”，这个b应该足够小，使包含b列的子矩阵能够满足cache的大小需要，同时应该足够大以使算法更快。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">for ib = 1 to n-1 step b … Process matrix b columns at a time</span><br><span class="line">    end = ib + b-1 … Point to end of block of b columns</span><br><span class="line">    apply BLAS2 version of GEPP to get A(ib:n , ib:end) = P&apos; * L&apos; * U&apos;</span><br><span class="line">    … let LL denote the strict lower triangular part of A(ib:end , ib:end) + I</span><br><span class="line">    A(ib:end , end+1:n) = LL^(-1) * A(ib:end , end+1:n) … update next b rows of U</span><br><span class="line">    A(end+1:n , end+1:n ) = A(end+1:n , end+1:n ) - A(end+1:n , ib:end) * A(ib:end , end+1:n)</span><br><span class="line">        … apply delayed updates with single matrix-multiply</span><br><span class="line">        … with inner dimension b</span><br></pre></td></tr></table></figure>
<p><img src="/img/1638690323.png" alt></p>
<p>白色部分已经完成，只对中间部分处理。中间的小矩形为LL。贴上代码：<br><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line">      <span class="function"><span class="keyword">SUBROUTINE</span></span> SGETRF( M, N, A, LDA, IPIV, INFO )</span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     .. Scalar Arguments ..</span></span><br><span class="line"><span class="comment">!     INTEGER            INFO, LDA, M, N</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. Array Arguments ..</span></span><br><span class="line"><span class="comment">!     INTEGER            IPIV( * )</span></span><br><span class="line"><span class="comment">!     REAL               A( LDA, * )</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  Purpose</span></span><br><span class="line"><span class="comment">!  =======</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  SGETRF computes an LU factorization of a general M-by-N matrix A</span></span><br><span class="line"><span class="comment">!  using partial pivoting with row interchanges.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  The factorization has the form</span></span><br><span class="line"><span class="comment">!     A = P * L * U</span></span><br><span class="line"><span class="comment">!  where P is a permutation matrix, L is lower triangular with unit</span></span><br><span class="line"><span class="comment">!  diagonal elements (lower trapezoidal if m &gt; n), and U is upper</span></span><br><span class="line"><span class="comment">!  triangular (upper trapezoidal if m &lt; n).</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  This is the right-looking Level 3 BLAS version of the algorithm.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  Arguments</span></span><br><span class="line"><span class="comment">!  =========</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  M       (input) INTEGER</span></span><br><span class="line"><span class="comment">!          The number of rows of the matrix A.  M &gt;= 0.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  N       (input) INTEGER</span></span><br><span class="line"><span class="comment">!          The number of columns of the matrix A.  N &gt;= 0.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  A       (input/output) REAL array, dimension (LDA,N)</span></span><br><span class="line"><span class="comment">!          On entry, the M-by-N matrix to be factored.</span></span><br><span class="line"><span class="comment">!          On exit, the factors L and U from the factorization</span></span><br><span class="line"><span class="comment">!          A = P*L*U; the unit diagonal elements of L are not stored.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  LDA     (input) INTEGER</span></span><br><span class="line"><span class="comment">!          The leading dimension of the array A.  LDA &gt;= max(1,M).</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  IPIV    (output) INTEGER array, dimension (min(M,N))</span></span><br><span class="line"><span class="comment">!          The pivot indices; for 1 &lt;= i &lt;= min(M,N), row i of the</span></span><br><span class="line"><span class="comment">!          matrix was interchanged with row IPIV(i).</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  INFO    (output) INTEGER</span></span><br><span class="line"><span class="comment">!          = 0:  successful exit</span></span><br><span class="line"><span class="comment">!          &lt; 0:  if INFO = -i, the i-th argument had an illegal value</span></span><br><span class="line"><span class="comment">!          &gt; 0:  if INFO = i, U(i,i) is exactly zero. The factorization</span></span><br><span class="line"><span class="comment">!                has been completed, but the factor U is exactly</span></span><br><span class="line"><span class="comment">!                singular, and division by zero will occur if it is used</span></span><br><span class="line"><span class="comment">!                to solve a system of equations.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!  =====================================================================</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     .. Parameters ..</span></span><br><span class="line"><span class="comment">!     REAL               ONE</span></span><br><span class="line"><span class="comment">!     PARAMETER          ( ONE = 1.0E+0 )</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. Local Scalars ..</span></span><br><span class="line"><span class="comment">!     INTEGER            I, IINFO, J, JB, NB</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. External Subroutines ..</span></span><br><span class="line"><span class="comment">!     EXTERNAL           SGEMM, SGETF2, SLASWP, STRSM, XERBLA</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. External Functions ..</span></span><br><span class="line"><span class="comment">!     INTEGER            ILAENV</span></span><br><span class="line"><span class="comment">!     EXTERNAL           ILAENV</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. Intrinsic Functions ..</span></span><br><span class="line"><span class="comment">!     INTRINSIC          MAX, MIN</span></span><br><span class="line"><span class="comment">!     ..</span></span><br><span class="line"><span class="comment">!     .. Executable Statements ..</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     Test the input parameters.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">      INFO = <span class="number">0</span></span><br><span class="line">      <span class="keyword">IF</span>( M.LT<span class="number">.0</span> ) <span class="keyword">THEN</span></span><br><span class="line">         INFO = -<span class="number">1</span></span><br><span class="line">      <span class="keyword">ELSE</span> <span class="keyword">IF</span>( N.LT<span class="number">.0</span> ) <span class="keyword">THEN</span></span><br><span class="line">         INFO = -<span class="number">2</span></span><br><span class="line">      <span class="keyword">ELSE</span> <span class="keyword">IF</span>( LDA.LT.<span class="built_in">MAX</span>( <span class="number">1</span>, M ) ) <span class="keyword">THEN</span></span><br><span class="line">         INFO = -<span class="number">4</span></span><br><span class="line">      <span class="keyword">END</span> <span class="keyword">IF</span></span><br><span class="line">      <span class="keyword">IF</span>( INFO.NE<span class="number">.0</span> ) <span class="keyword">THEN</span></span><br><span class="line">         <span class="keyword">CALL</span> XERBLA( <span class="string">'SGETRF'</span>, -INFO )</span><br><span class="line">         <span class="keyword">RETURN</span></span><br><span class="line">      <span class="keyword">END</span> <span class="keyword">IF</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     Quick return if possible</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">      <span class="keyword">IF</span>( M.EQ<span class="number">.0</span> .OR. N.EQ<span class="number">.0</span> )</span><br><span class="line">     $   <span class="keyword">RETURN</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     Determine the block size for this environment.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">      NB = ILAENV( <span class="number">1</span>, <span class="string">'SGETRF'</span>, <span class="string">' '</span>, M, N, -<span class="number">1</span>, -<span class="number">1</span> )</span><br><span class="line">      <span class="keyword">IF</span>( NB.LE<span class="number">.1</span> .OR. NB.GE.<span class="built_in">MIN</span>( M, N ) ) <span class="keyword">THEN</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!        Use unblocked code.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">         <span class="keyword">CALL</span> SGETF2( M, N, A, LDA, IPIV, INFO )</span><br><span class="line">      <span class="keyword">ELSE</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!        Use blocked code.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">         <span class="keyword">DO</span> <span class="number">20</span> J = <span class="number">1</span>, <span class="built_in">MIN</span>( M, N ), NB</span><br><span class="line">            JB = <span class="built_in">MIN</span>( <span class="built_in">MIN</span>( M, N )-J+<span class="number">1</span>, NB )</span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!           Factor diagonal and subdiagonal blocks and test for exact</span></span><br><span class="line"><span class="comment">!           singularity.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">            <span class="keyword">CALL</span> SGETF2( M-J+<span class="number">1</span>, JB, A( J, J ), LDA, IPIV( J ), IINFO )</span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!           Adjust INFO and the pivot indices.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">            <span class="keyword">IF</span>( INFO.EQ<span class="number">.0</span> .AND. IINFO.GT<span class="number">.0</span> )</span><br><span class="line">     $         INFO = IINFO + J - <span class="number">1</span></span><br><span class="line">            <span class="keyword">DO</span> <span class="number">10</span> I = J, <span class="built_in">MIN</span>( M, J+JB-<span class="number">1</span> )</span><br><span class="line">               IPIV( I ) = J - <span class="number">1</span> + IPIV( I )</span><br><span class="line">   <span class="number">10</span>       <span class="keyword">CONTINUE</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!           Apply interchanges to columns 1:J-1.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">            <span class="keyword">CALL</span> SLASWP( J-<span class="number">1</span>, A, LDA, J, J+JB-<span class="number">1</span>, IPIV, <span class="number">1</span> )</span><br><span class="line"><span class="comment">!</span></span><br><span class="line">            <span class="keyword">IF</span>( J+JB.LE.N ) <span class="keyword">THEN</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!              Apply interchanges to columns J+JB:N.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">               <span class="keyword">CALL</span> SLASWP( N-J-JB+<span class="number">1</span>, A( <span class="number">1</span>, J+JB ), LDA, J, J+JB-<span class="number">1</span>,</span><br><span class="line">     $                      IPIV, <span class="number">1</span> )</span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!              Compute block row of U.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">               <span class="keyword">CALL</span> STRSM( <span class="string">'Left'</span>, <span class="string">'Lower'</span>, <span class="string">'No transpose'</span>, <span class="string">'Unit'</span>, JB,</span><br><span class="line">     $                     N-J-JB+<span class="number">1</span>, ONE, A( J, J ), LDA, A( J, J+JB ),</span><br><span class="line">     $                     LDA )</span><br><span class="line">               <span class="keyword">IF</span>( J+JB.LE.M ) <span class="keyword">THEN</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!                 Update trailing submatrix.</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">                  <span class="keyword">CALL</span> SGEMM( <span class="string">'No transpose'</span>, <span class="string">'No transpose'</span>, M-J-JB+<span class="number">1</span>,</span><br><span class="line">     $                        N-J-JB+<span class="number">1</span>, JB, -ONE, A( J+JB, J ), LDA,</span><br><span class="line">     $                        A( J, J+JB ), LDA, ONE, A( J+JB, J+JB ),</span><br><span class="line">     $                        LDA )</span><br><span class="line">               <span class="keyword">END</span> <span class="keyword">IF</span></span><br><span class="line">            <span class="keyword">END</span> <span class="keyword">IF</span></span><br><span class="line">   <span class="number">20</span>    <span class="keyword">CONTINUE</span></span><br><span class="line">      <span class="keyword">END</span> <span class="keyword">IF</span></span><br><span class="line">      <span class="keyword">RETURN</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line"><span class="comment">!     End of SGETRF</span></span><br><span class="line"><span class="comment">!</span></span><br><span class="line">      <span class="keyword">END</span></span><br></pre></td></tr></table></figure></p>
<p>在二维剖分中进行高斯消去：<br><img src="/img/1638690838.jpg" alt><br><img src="/img/1638691213.jpg" alt></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">for ib = 1 to n-1 step b</span><br><span class="line">    end = min(ib + b -1, n)</span><br><span class="line">    for i = ib to end</span><br><span class="line">        (1) find pivot row k, column broadcast</span><br><span class="line">        (2) swap rows k and i in block column, broadcast row k</span><br><span class="line">        (3) A(i+1:n, i) = A(i+1:n, i) / A(i,i)</span><br><span class="line">        (4) A(i+1:n, i+1:end) -= A(i+1:n, i)*A(i,1+1:end)</span><br><span class="line">    end for</span><br><span class="line">    (5) broadcast all swap information right and left</span><br><span class="line">    (6) apply all rows swap to other column</span><br><span class="line">    (7) broadcast LL right</span><br><span class="line">    (8) A(ib:end, end+1:n) = LL / A(ib:end, end+1:n)</span><br><span class="line">    (9) broadcast A(ib:end, end+1:n) down</span><br><span class="line">    (10) broadcast A(end+1:n, ib:end) right</span><br><span class="line">    (11) eliminate A(end+1:n, end+1:n)</span><br><span class="line">    // matrix multiply of green = green - blue * pink</span><br></pre></td></tr></table></figure>
<h1 id="lecture-15"><a href="#lecture-15" class="headerlink" title="lecture 15"></a>lecture 15</h1><p>compressed sparse row (CSR)存储：</p>
<ul>
<li>大小为<code>nnz=非零值个数</code>（val）数组</li>
<li>大小为<code>nnz</code>的每个非零值的列索引数组</li>
<li>大小为<code>n=行数</code>的行起始指针数组</li>
</ul>
<p>其他常用格式（加分块）</p>
<ul>
<li>压缩稀疏列（CSC）</li>
<li>坐标（COO）：每个非零元素的行+列索引（易于构建）</li>
</ul>
<p><img src="/img/1638692558.jpg" alt></p>
<p>SpMV with CSR算法对y的重用很多，但是对x的重用不足。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for each row i:</span><br><span class="line">    for k = ptr[i] to ptr[i+1] - 1 do</span><br><span class="line">        y[i] = y[i] + val[k] * x[ind[k]]</span><br></pre></td></tr></table></figure></p>
<p>可能的优化：</p>
<ul>
<li>把k循环展开，需要知道这一行有多少非零元素</li>
<li>把y[i]挪出for循环</li>
<li>压缩ind[i]，需要知道非零元素出现的规律</li>
<li>重用x，需要很好的非零元素出现规律</li>
<li>cache：需要知道非零元在附近的行</li>
<li>register：需要知道这些非零元存在哪里</li>
</ul>
<p>SpMV可以利用分块，不需要使用index存储每一个非零元，而是使用1个列序号存储非零r-c块？</p>
<p>Optimizations for SpMV</p>
<ul>
<li>Register blocking (RB): up to 4x over CSR</li>
<li>Variable block splitting: 2.1x over CSR, 1.8x over RB</li>
<li>Diagonals: 2x over CSR</li>
<li>Reordering to create dense structure + splitting: 2x over CSR</li>
<li>Symmetry: 2.8x over CSR, 2.6x over RB</li>
<li>Cache blocking: 2.8x over CSR</li>
<li>Multiple vectors (SpMM): 7x over CSR</li>
<li>And combinations…</li>
</ul>
<p>Sparse triangular solve</p>
<ul>
<li>Hybrid sparse/dense data structure: 1.8x over CSR</li>
</ul>
<p>SpMV的行并行：对x的访问是随机的，而且没有线程之间的依赖关系，所以没有竞争/锁。剖分的话就根据非零元素的个数进行分割。与列并行相比，都是对y的随机读写，列并行需要同步操作。将行与列结合起来有更多并行性。</p>
<p>优化总结：</p>
<ul>
<li>NUMA-非统一内存访问<ul>
<li>将子矩阵固定到分配给它们的核心附近的内存中</li>
</ul>
</li>
<li>预取-值、索引和/或向量<ul>
<li>对预取距离进行彻底搜索</li>
</ul>
</li>
<li>矩阵压缩-不仅仅是寄存器分块（BCSR）<ul>
<li>32或16位索引，子矩阵的块坐标格式</li>
</ul>
</li>
<li>缓存阻塞<ul>
<li>矩阵的2D分区，因此所需的x、y部分适合缓存</li>
</ul>
</li>
</ul>
<p>分布式SpMV的并行性：</p>
<ul>
<li>y=A*x，其中A是稀疏矩阵</li>
<li>行并行性（y和A）<ul>
<li>跨处理器复制x</li>
<li>或者只交换必要的元素</li>
<li>非零是否聚集在一起，例如，接近对角线？</li>
</ul>
</li>
<li>列并行性（x和A）<ul>
<li>在所有处理器上设置临时y=[0, …]；</li>
<li>更新该信息；并跨处理器添加reduce</li>
</ul>
</li>
<li>p很大和非零一致时的二维并行性<ul>
<li>将处理器划分为p1 x p2（例如，方形网格）</li>
<li>使用混合行和列并行性</li>
<li>非零元素聚集时的负载平衡不良</li>
</ul>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/12/04/解读raft/" rel="next" title="解读Raft">
                <i class="fa fa-chevron-left"></i> 解读Raft
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/12/06/有趣的cache测量数据/" rel="prev" title="有趣的cache测量数据">
                有趣的cache测量数据 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/header.jpg" alt="Hao Yu">
            
              <p class="site-author-name" itemprop="name">Hao Yu</p>
              <p class="site-description motion-element" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</p>
          </div>
          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">348</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">14</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>
        	<audio controls="controls" loop="loop" preload="auto" src="/resource/xiaomeihao.mp3">
	        </audio>
	

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/yuhao0102" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yuh18@mails.tsinghua.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-2"><span class="nav-number">1.</span> <span class="nav-text">lecture 2</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-3"><span class="nav-number">2.</span> <span class="nav-text">lecture 3</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-4"><span class="nav-number">3.</span> <span class="nav-text">lecture 4</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-5"><span class="nav-number">4.</span> <span class="nav-text">lecture 5</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-6"><span class="nav-number">5.</span> <span class="nav-text">lecture 6</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-7"><span class="nav-number">6.</span> <span class="nav-text">lecture 7</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-9"><span class="nav-number">7.</span> <span class="nav-text">lecture 9</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-11"><span class="nav-number">8.</span> <span class="nav-text">lecture 11</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-12"><span class="nav-number">9.</span> <span class="nav-text">lecture 12</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-13"><span class="nav-number">10.</span> <span class="nav-text">lecture 13</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#lecture-15"><span class="nav-number">11.</span> <span class="nav-text">lecture 15</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>
  <div id="DvelopmentTarget">     
  </div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart" aria-hidden="false"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>

  
</div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_uv"> 
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  


  <script type="text/javascript" src="/js/src/love.js"></script>

</body>
</html>
