<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Linux虚拟地址空间布局]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[在多任务操作系统中，每个进程都运行在属于自己的内存沙盘中。这个沙盘就是虚拟地址空间(Virtual Address Space)，在32位模式下它是一个4GB的内存地址块。在Linux系统中, 内核进程和用户进程所占的虚拟内存比例是1:3，而Windows系统为2:2(通过设置Large-Address-Aware Executables标志也可为1:3)。这并不意味着内核使用那么多物理内存，仅表示它可支配这部分地址空间，根据需要将其映射到物理内存。 虚拟地址通过页表(Page Table)映射到物理内存，页表由操作系统维护并被处理器引用。内核空间在页表中拥有较高特权级，因此用户态程序试图访问这些页时会导致一个页错误(page fault)。在Linux中，内核空间是持续存在的，并且在所有进程中都映射到同样的物理内存。内核代码和数据总是可寻址，随时准备处理中断和系统调用。与此相反，用户模式地址空间的映射随进程切换的发生而不断变化。 Linux进程在虚拟内存中的标准内存段布局如下图所示： 其中，用户地址空间中的蓝色条带对应于映射到物理内存的不同内存段，灰白区域表示未映射的部分。这些段只是简单的内存地址范围，与Intel处理器的段没有关系。 上图中Random stack offset和Random mmap offset等随机值意在防止恶意程序。Linux通过对栈、内存映射段、堆的起始地址加上随机偏移量来打乱布局，以免恶意程序通过计算访问栈、库函数等地址。execve(2)负责为进程代码段和数据段建立映射，真正将代码段和数据段的内容读入内存是由系统的缺页异常处理程序按需完成的。另外，execve(2)还会将BSS段清零。 用户进程部分分段存储内容如下表所示(按地址递减顺序)： 名称 存储内容 栈 局部变量、函数参数、返回地址等 堆 动态分配的内存 BSS段 未初始化或初值为0的全局变量和静态局部变量 数据段 已初始化且初值非0的全局变量和静态局部变量 代码段 可执行代码、字符串字面值、只读变量 在将应用程序加载到内存空间执行时，操作系统负责代码段、数据段和BSS段的加载，并在内存中为这些段分配空间。栈也由操作系统分配和管理；堆由程序员自己管理，即显式地申请和释放空间。 BSS段、数据段和代码段是可执行程序编译时的分段，运行时还需要栈和堆。 以下详细介绍各个分段的含义。 内核空间内核总是驻留在内存中，是操作系统的一部分。内核空间为内核保留，不允许应用程序读写该区域的内容或直接调用内核代码定义的函数。 栈(stack)栈又称堆栈，由编译器自动分配释放，行为类似数据结构中的栈(先进后出)。堆栈主要有三个用途： 为函数内部声明的非静态局部变量(C语言中称“自动变量”)提供存储空间。 记录函数调用过程相关的维护性信息，称为栈帧(Stack Frame)或过程活动记录(Procedure Activation Record)。它包括函数返回地址，不适合装入寄存器的函数参数及一些寄存器值的保存。除递归调用外，堆栈并非必需。因为编译时可获知局部变量，参数和返回地址所需空间，并将其分配于BSS段。 临时存储区，用于暂存长算术表达式部分计算结果或alloca()函数分配的栈内内存。 持续地重用栈空间有助于使活跃的栈内存保持在CPU缓存中，从而加速访问。进程中的每个线程都有属于自己的栈。向栈中不断压入数据时，若超出其容量就会耗尽栈对应的内存区域，从而触发一个页错误。此时若栈的大小低于堆栈最大值RLIMIT_STACK(通常是8M)，则栈会动态增长，程序继续运行。映射的栈区扩展到所需大小后，不再收缩。 Linux中ulimit -s命令可查看和设置堆栈最大值，当程序使用的堆栈超过该值时, 发生栈溢出(Stack Overflow)，程序收到一个段错误(Segmentation Fault)。注意，调高堆栈容量可能会增加内存开销和启动时间。 堆栈既可向下增长(向内存低地址)也可向上增长, 这依赖于具体的实现。本文所述堆栈向下增长。 堆栈的大小在运行时由内核动态调整。 内存映射段(mmap)此处，内核将硬盘文件的内容直接映射到内存, 任何应用程序都可通过Linux的mmap()系统调用或Windows的CreateFileMapping()/MapViewOfFile()请求这种映射。内存映射是一种方便高效的文件I/O方式， 因而被用于装载动态共享库。用户也可创建匿名内存映射，该映射没有对应的文件, 可用于存放程序数据。在 Linux中，若通过malloc()请求一大块内存，C运行库将创建一个匿名内存映射，而不使用堆内存。”大块” 意味着比阈值 MMAP_THRESHOLD还大，缺省为128KB，可通过mallopt()调整。 该区域用于映射可执行文件用到的动态链接库。在Linux 2.4版本中，若可执行文件依赖共享库，则系统会为这些动态库在从0x40000000开始的地址分配相应空间，并在程序装载时将其载入到该空间。在Linux 2.6内核中，共享库的起始地址被往上移动至更靠近栈区的位置。 从进程地址空间的布局可以看到，在有共享库的情况下，留给堆的可用空间还有两处：一处是从.bss段到0x40000000，约不到1GB的空间；另一处是从共享库到栈之间的空间，约不到2GB。这两块空间大小取决于栈、共享库的大小和数量。这样来看，是否应用程序可申请的最大堆空间只有2GB？事实上，这与Linux内核版本有关。在上面给出的进程地址空间经典布局图中，共享库的装载地址为0x40000000，这实际上是Linux kernel 2.6版本之前的情况了，在2.6版本里，共享库的装载地址已经被挪到靠近栈的位置，即位于0xBFxxxxxx附近，因此，此时的堆范围就不会被共享库分割成2个“碎片”，故kernel 2.6的32位Linux系统中，malloc申请的最大内存理论值在2.9GB左右。 堆(heap)堆用于存放进程运行时动态分配的内存段，可动态扩张或缩减。堆中内容是匿名的，不能按名字直接访问，只能通过指针间接访问。当进程调用malloc(C)/new(C++)等函数分配内存时，新分配的内存动态添加到堆上(扩张)；当调用free(C)/delete(C++)等函数释放内存时，被释放的内存从堆中剔除(缩减) 。 分配的堆内存是经过字节对齐的空间，以适合原子操作。堆管理器通过链表管理每个申请的内存，由于堆申请和释放是无序的，最终会产生内存碎片。堆内存一般由应用程序分配释放，回收的内存可供重新使用。若程序员不释放，程序结束时操作系统可能会自动回收。 堆的末端由break指针标识，当堆管理器需要更多内存时，可通过系统调用brk()和sbrk()来移动break指针以扩张堆，一般由系统自动调用。 使用堆时经常出现两种问题：1) 释放或改写仍在使用的内存(“内存破坏”)；2)未释放不再使用的内存(“内存泄漏”)。当释放次数少于申请次数时，可能已造成内存泄漏。泄漏的内存往往比忘记释放的数据结构更大，因为所分配的内存通常会圆整为下个大于申请数量的2的幂次(如申请212B，会圆整为256B)。 堆不同于数据结构中的”堆”，其行为类似链表。 【扩展阅读】栈和堆的区别 ①管理方式：栈由编译器自动管理；堆由程序员控制，使用方便，但易产生内存泄露。 ②生长方向：栈向低地址扩展(即”向下生长”)，是连续的内存区域；堆向高地址扩展(即”向上生长”)，是不连续的内存区域。这是由于系统用链表来存储空闲内存地址，自然不连续，而链表从低地址向高地址遍历。 ③空间大小：栈顶地址和栈的最大容量由系统预先规定(通常默认2M或10M)；堆的大小则受限于计算机系统中有效的虚拟内存，32位Linux系统中堆内存可达2.9G空间。 ④存储内容：栈在函数调用时，首先压入主调函数中下条指令(函数调用语句的下条可执行语句)的地址，然后是函数实参，然后是被调函数的局部变量。本次调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的指令地址，程序由该点继续运行下条可执行语句。堆通常在头部用一个字节存放其大小，堆用于存储生存期与函数调用无关的数据，具体内容由程序员安排。 ⑤分配方式：栈可静态分配或动态分配。静态分配由编译器完成，如局部变量的分配。动态分配由alloca函数在栈上申请空间，用完后自动释放。堆只能动态分配且手工释放。 ⑥分配效率：栈由计算机底层提供支持：分配专门的寄存器存放栈地址，压栈出栈由专门的指令执行，因此效率较高。堆由函数库提供，机制复杂，效率比栈低得多。Windows系统中VirtualAlloc可直接在进程地址空间中分配一块内存，快速且灵活。 ⑦分配后系统响应：只要栈剩余空间大于所申请空间，系统将为程序提供内存，否则报告异常提示栈溢出。 操作系统为堆维护一个记录空闲内存地址的链表。当系统收到程序的内存分配申请时，会遍历该链表寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点空间分配给程序。若无足够大小的空间(可能由于内存碎片太多)，有可能调用系统功能去增加程序数据段的内存空间，以便有机会分到足够大小的内存，然后进行返回。，大多数系统会在该内存空间首地址处记录本次分配的内存大小，供后续的释放函数(如free/delete)正确释放本内存空间。 此外，由于找到的堆结点大小不一定正好等于申请的大小，系统会自动将多余的部分重新放入空闲链表中。 ⑧碎片问题：栈不会存在碎片问题，因为栈是先进后出的队列，内存块弹出栈之前，在其上面的后进的栈内容已弹出。而频繁申请释放操作会造成堆内存空间的不连续，从而造成大量碎片，使程序效率降低。 可见，堆容易造成内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和内核态切换，内存申请的代价更为昂贵。所以栈在程序中应用最广泛，函数调用也利用栈来完成，调用过程中的参数、返回地址、栈基指针和局部变量等都采用栈的方式存放。所以，建议尽量使用栈，仅在分配大量或大块内存空间时使用堆。 使用栈和堆时应避免越界发生，否则可能程序崩溃或破坏程序堆、栈结构，产生意想不到的后果。 BSS段BSS(Block Started by Symbol)段中通常存放程序中以下符号： 未初始化的全局变量和静态局部变量 初始值为0的全局变量和静态局部变量(依赖于编译器实现) 未定义且初值不为0的符号(该初值即common block的大小) C语言中，未显式初始化的静态分配变量被初始化为0(算术类型)或空指针(指针类型)。由于程序加载时，BSS会被操作系统清零，所以未赋初值或初值为0的全局变量都在BSS中。BSS段仅为未初始化的静态分配变量预留位置，在目标文件中并不占据空间，这样可减少目标文件体积。但程序运行时需为变量分配内存空间，故目标文件必须记录所有未初始化的静态分配变量大小总和(通过start_bss和end_bss地址写入机器代码)。当加载器(loader)加载程序时，将为BSS段分配的内存初始化为0。在嵌入式软件中，进入main()函数之前BSS段被C运行时系统映射到初始化为全零的内存(效率较高)。 注意，尽管均放置于BSS段，但初值为0的全局变量是强符号，而未初始化的全局变量是弱符号。若其他地方已定义同名的强符号(初值可能非0)，则弱符号与之链接时不会引起重定义错误，但运行时的初值可能并非期望值(会被强符号覆盖)。因此，定义全局变量时，若只有本文件使用，则尽量使用static关键字修饰；否则需要为全局变量定义赋初值(哪怕0值)，保证该变量为强符号，以便链接时发现变量名冲突，而不是被未知值覆盖。 某些编译器将未初始化的全局变量保存在common段，链接时再将其放入BSS段。在编译阶段可通过-fno-common选项来禁止将未初始化的全局变量放入common段。 此外，由于目标文件不含BSS段，故程序烧入存储器(Flash)后BSS段地址空间内容未知。U-Boot启动过程中，将U-Boot的Stage2代码(通常位于lib_xxxx/board.c文件)搬迁(拷贝)到SDRAM空间后必须人为添加清零BSS段的代码，而不可依赖于Stage2代码中变量定义时赋0值。 【扩展阅读】BSS历史 BSS(Block Started by Symbol，以符号开始的块)一词最初是UA-SAP汇编器(United Aircraft Symbolic Assembly Program)中的伪指令，用于为符号预留一块内存空间。该汇编器由美国联合航空公司于20世纪50年代中期为IBM 704大型机所开发。 后来该词被作为关键字引入到了IBM 709和7090/94机型上的标准汇编器FAP(Fortran Assembly Program)，用于定义符号并且为该符号预留指定字数的未初始化空间块。 在采用段式内存管理的架构中(如Intel 80x86系统)，BSS段通常指用来存放程序中未初始化全局变量的一块内存区域，该段变量只有名称和大小却没有值。程序开始时由系统初始化清零。 BSS段不包含数据，仅维护开始和结束地址，以便内存能在运行时被有效地清零。BSS所需的运行时空间由目标文件记录，但BSS并不占用目标文件内的实际空间，即BSS节段应用程序的二进制映象文件中并不存在。 数据段(Data)数据段通常用于存放程序中已初始化且初值不为0的全局变量和静态局部变量。数据段属于静态内存分配(静态存储区)，可读可写。 数据段保存在目标文件中(在嵌入式系统里一般固化在镜像文件中)，其内容由程序初始化。例如，对于全局变量int gVar = 10，必须在目标文件数据段中保存10这个数据，然后在程序加载时复制到相应的内存。 数据段与BSS段的区别如下： BSS段不占用物理文件尺寸，但占用内存空间；数据段占用物理文件，也占用内存空间。对于大型数组如int ar0[10000] = {1, 2, 3, …}和int ar1[10000]，ar1放在BSS段，只记录共有10000*4个字节需要初始化为0，而不是像ar0那样记录每个数据1、2、3…，此时BSS为目标文件所节省的磁盘空间相当可观。 当程序读取数据段的数据时，系统会出发缺页故障，从而分配相应的物理内存；当程序读取BSS段的数据时，内核会将其转到一个全零页面，不会发生缺页故障，也不会为其分配相应的物理内存。 运行时数据段和BSS段的整个区段通常称为数据区。某些资料中“数据段”指代数据段 + BSS段 + 堆。 代码段(text)代码段也称正文段或文本段，通常用于存放程序执行代码(即CPU执行的机器指令)。一般C语言执行语句都编译成机器代码保存在代码段。通常代码段是可共享的，因此频繁执行的程序只需要在内存中拥有一份拷贝即可。代码段通常属于只读，以防止其他程序意外地修改其指令(对该段的写操作将导致段错误)。某些架构也允许代码段为可写，即允许修改程序。 代码段指令根据程序设计流程依次执行，对于顺序指令，只会执行一次(每个进程)；若有反复，则需使用跳转指令；若进行递归，则需要借助栈来实现。 代码段指令中包括操作码和操作对象(或对象地址引用)。若操作对象是立即数(具体数值)，将直接包含在代码中；若是局部数据，将在栈区分配空间，然后引用该数据地址；若位于BSS段和数据段，同样引用该数据地址。 代码段最容易受优化措施影响。 保留区位于虚拟地址空间的最低部分，未赋予物理地址。任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。 它并不是一个单一的内存区域，而是对地址空间中受到操作系统保护而禁止用户进程访问的地址区域的总称。大多数操作系统中，极小的地址通常都是不允许访问的，如NULL。C语言将无效指针赋值为0也是出于这种考虑，因为0地址上正常情况下不会存放有效的可访问数据。 在32位X86架构的Linux系统中，用户进程可执行程序一般从虚拟地址空间0x08048000开始加载。该加载地址由ELF文件头决定，可通过自定义链接器脚本覆盖链接器默认配置，进而修改加载地址。0x08048000以下的地址空间通常由C动态链接库、动态加载器ld.so和内核VDSO(内核提供的虚拟共享库)等占用。通过使用mmap系统调用，可访问0x08048000以下的地址空间。 通过cat /proc/self/maps命令查看加载表如下： 【扩展阅读】分段的好处 进程运行过程中，代码指令根据流程依次执行，只需访问一次(当然跳转和递归可能使代码执行多次)；而数据(数据段和BSS段)通常需要访问多次，因此单独开辟空间以方便访问和节约空间。具体解释如下： 当程序被装载后，数据和指令分别映射到两个虚存区域。数据区对于进程而言可读写，而指令区对于进程只读。两区的权限可分别设置为可读写和只读。以防止程序指令被有意或无意地改写。 现代CPU具有极为强大的缓存(Cache)体系，程序必须尽量提高缓存命中率。指令区和数据区的分离有利于提高程序的局部性。现代CPU一般数据缓存和指令缓存分离，故程序的指令和数据分开存放有利于提高CPU缓存命中率。 当系统中运行多个该程序的副本时，其指令相同，故内存中只须保存一份该程序的指令部分。若系统中运行数百进程，通过共享指令将节省大量空间(尤其对于有动态链接的系统)。其他只读数据如程序里的图标、图片、文本等资源也可共享。而每个副本进程的数据区域不同，它们是进程私有的。 此外，临时数据及需要再次使用的代码在运行时放入栈区中，生命周期短。全局数据和静态数据可能在整个程序执行过程中都需要访问，因此单独存储管理。堆区由用户自由分配，以便管理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统编程之文件与IO]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8EIO%2F</url>
    <content type="text"><![CDATA[文件描述符、open，close什么是IO？输入/输出是主存和外部设备之间拷贝数据的过程设备-&gt;内存（输入操作）内存-&gt;设备（输出操作） 高级I/O：ANSI C提供的标准I/O库称为高级I/O，通常也称为带缓冲的I/O低级I/O：通常也称为不带缓冲的I/O 文件描述符：fd对于Linux而言，所有对设备或文件的操作都是通过文件描述符进行的。当打开或者创建一个文件的时候，内核向进程返回一个文件描述符（非负整数）。后续对文件的操作只需通过该文件描述符，内核记录有关这个打开文件的信息。一个进程启动时，默认打开了3个文件，标准输入、标准输出、标准错误，对应文件描述符是0（STDIN_FILENO）、1（STDOUT_FILENO）、2（STDERR_FILENO）,这些常量定义在unistd.h头文件中。C库函数中与之对应的是：stdin,stdout,stderr,不过这三个是FILE指针类型。 文件描述符与文件指针相互转换可以通过以下两个函数实现： fileno：将文件指针转换为文件描述符12#include &lt;stdio.h&gt;int fileno(FILE *stream) 测试程序：12345678910#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;fileno(stdin) = %d\n&quot;, fileno(stdin)); printf(&quot;fileno(stdout) = %d\n&quot;, fileno(stdout)); printf(&quot;fileno(stderr) = %d\n&quot;, fileno(stderr)); return 0;&#125; fdopen：将文件描述符转换为文件指针12#include &lt;stdio.h&gt;FILE *fdopen(int fd, const char *mode) //mode :r,w,r+,w+,a,a+ 文件系统调用open系统调用有几种方法可以获得允许访问文件的文件描述符。最常用的是使用open（）（打开）系统调用 函数原型123456#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt;int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode); 参数 path ：文件的名称，可以包含（绝对和相对）路径 flags：文件打开模式 mode：用来规定对该文件的所有者，文件的用户组及系 统中其他用户的访问权限 返回值打开成功，返回文件描述符；打开失败，返回－1 文件打开方式：O_EXCL表示：当O_EXCL|O_CREAT时，若文件存在，则打开失败，不存在，则打开成功 访问权限： open系统调用的几点说明：可以利用按位逻辑加(bitwise-OR)(|)对打开方式的标志值进行组合。如打开一个新文件：1#define NEWFILE (O_WRONLY|O_CREAT|O_TRUNC) 对访问权限位进行访问所用到的标识符，均可以通过12#include &lt;sys/stat.h&gt; 访问到,同样可以通过|运算来对访问权限进行组合也可以直接给出数字表示如0655#define MODE755 (S_IRWXU|S_IRGRP|S_IXGRP|S_IROTH|S_IXOTH) 注：文件的访问权限是根据：umask&amp;~mode得出来的，例如umask=0022,mode = 0655 则访问权限为：644 测试程序：12345678910111213141516171819202122232425262728#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)int main(void)&#123; umask(0); int fd; fd = open(&quot;test.txt&quot;, O_WRONLY | O_CREAT, 0666); if (fd == -1) ERR_EXIT(&quot;open error&quot;); printf(&quot;open succ\n&quot;); return 0;&#125; 测试结果一：采用默认的umask值 测试结果二：重新设置umask值 close系统调用为了重新利用文件描述符，用close()系统调用释放打开的文件描述符 函数原型：12#include &lt;unistd.h&gt;int close(int fd); 函数参数：-fd ：要关闭的文件的文件描述符 返回值如果出现错误，返回-1调用成功返回0 注：若没有显示调用close()，当程序退出时也会关闭文件 creat系统调用为了维持与早期的UNIX系统的向后兼容性，Linux也提供可选的创建文件的系统调用，它称为creat()。现代的linux内核很少采用creat创建文件，因为open可以完成创建功能 函数原型：1int creat(const char *path, mode_t mode)； 参数12path ：文件的名称，可以包含（绝对和相对）路径mode: 用来规定对该文件的所有者，文件的用户组及系 统中其他用户的访问权限 返回值打开成功，返回文件描述符；打开失败，返回－1 在UNIX的早期版本中，open()系统调用仅仅存在两个参数的形式。如文件不存在，它就不能打开这些文件。文件的创建则由单独的系统调用creat()完成。在Linux及所有UNIX的近代版本中，creat()系统调用是多余的。 creat()调用1fd = creat(file, mode)； 完全等价于近代的open()调用1fd = open(file, O_WRONLY | O_CREAT | O_TRUNC, mode)； 系统调用read和writeread系统调用一旦有了与一个打开文件描述相连的文件描述符，只要该文件是用O_RDONLY或O_RDWR标志打开的，就可以用read()系统调用从该文件中读取字节 函数原型：12#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count); 参数fd ：想要读的文件的文件描述符buf ： 指向内存块的指针，从文件中读取来的字节放到这个内存块中count ： 从该文件复制到buf中的字节个数 返回值如果出现错误，返回-1读文件结束，返回0否则返回从该文件复制到规定的缓冲区中的字节数 write系统调用用write()系统调用将数据写到一个文件中 函数原型：12#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count); 函数参数： fd：要写入的文件的文件描述符 buf：指向内存块的指针，从这个内存块中读取数据写入 到文件中 count：要写入文件的字节个数 返回值如果出现错误，返回-1 注:write并非真正写入磁盘,而是先写入内存缓冲区,待缓冲区满或进行刷新操作后才真正写入磁盘,若想实时写入磁盘可调用int fsync(int fd);或在open时flags加上O_SYNC 利用read和write进行文件拷贝 程序代码:12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#define EXIT_ERR(m) \do&#123;\ perror(m);\ exit(EXIT_FAILURE);\&#125;while(0)int main(int argc, char **argv)&#123; int infd; int outfd; if(argc != 3)&#123; fprintf(stderr,&quot;usage:%s src des\n&quot;,argv[0]); exit(EXIT_FAILURE); &#125; if((infd = open(argv[1],O_RDONLY)) == -1) EXIT_ERR(&quot;open error&quot;); if((outfd = open(argv[2],O_WRONLY|O_CREAT|O_TRUNC,0644)) == -1) EXIT_ERR(&quot;OPEN ERROR&quot;); char buf[1024]; int n; while((n = read(infd, buf, 1024)) &gt; 0 )&#123; write(outfd, buf, n); &#125; close(infd); close(outfd); return 0;&#125; 结果： 利用lseek()创建空洞文件lseek（）系统调用功能说明：通过指定相对于开始位置、当前位置或末尾位置的字节数来重定位 curp，这取决于 lseek() 函数中指定的位置 函数原型：1234#include &lt;sys/types.h&gt; #include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence); 参数说明： fd：文件描述符 offset：偏移量，该值可正可负，负值为向前移 whence：搜索的起始位置，有三个选项： SEEK_SET: 当前位置为文件的开头，新位置为偏移量大小 SEEK_CUR: 当前位置为文件指针位置，新位置为当前位置加上偏移量大小 SEEK_END: 当前位置为文件结尾，新位置为偏移量大小 返回值：文件新的偏移值 利用lseek（）产生空洞文件（hole）说明：seek()函数允许将文件偏移量设置为超出文件末尾（但这不会改变文件的大小）。 如果此时稍后写入数据，则后续读取间隙中的数据（“空洞”）将返回空字节（’\0’），直到数据实际写入间隙。 程序代码：123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)int main(void)&#123; int fd; int ret; fd = open(&quot;hole.txt&quot;,O_WRONLY|O_CREAT|O_TRUNC,0644); if(fd == -1) ERR_EXIT(&quot;open error&quot;); write(fd,&quot;hello&quot;,5); ret = lseek(fd,1024*1024*1024,SEEK_CUR); if(ret == -1) ERR_EXIT(&quot;lseek error&quot;); write(fd,&quot;world&quot;,5); close(fd); return 0;&#125; 测试结果：程序创建一个hole文件，然后写入”hello”字符，在利用lseek系统调用从当前位置偏移到102410241024之后再写入”world”字符，ls显示文件大小为1.1G，实际上它并没有占用这么多的磁盘空间，du表明hole文件只有8k，系统只是存储一些信息，用它来表示有多少个\0，当我们用cat查看文件内容时只看到hello，由于文件太大最后的world太后以致看不到，但当我们用od命令查看时，可以发现有好多个\0。 目录访问相关系统调用目录操作相关的系统调用mkdir和rmdir系统调用12345678filename: mk_rm_dir.c #include &lt;sys/stat.h&gt; int mkdir(const char *path, mode_t mode); return: S 0 F -1 note: mode权限至少要有执行权限。 1234567#include &lt;unistd.h&gt; int rmdir(const char *pathname); return: S 0 F -1 note: pathname目录必须是空目录。 实例12345678910111213141516#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;stdio.h&gt;#include &lt;assert.h&gt;#define MODE (S_IRUSR | S_IWUSR | S_IXUSR | S_IXGRP | S_IXOTH)int main(int argc, char *argv[])&#123; char *pname; assert(argc == 2); pname = argv[1]; assert(mkdir(pname, MODE) == 0); printf(&quot;create %s successful!\n&quot;, pname); assert(rmdir(pname) == 0); printf(&quot;rm %s\n&quot;, pname); return 0;&#125; 测试：1[qtlldr@qtldr editing]./mkrmdirtestdircreatetestdirsuccessful!rmtestdir[qtlldr@qtldrediting] chdir, getcwd系统调用12345#include &lt;unistd.h&gt; int chdir(const char *pathname); return: S 0 F -1 12345#include &lt;unistd.h&gt; char *getpwd(char *buf, size_t size); return: S buf F NULL buf是缓冲地址，size是buf的长度。该缓冲必须有足够的长度以容纳绝对路径名加上一个null终止符。 实例123456789101112131415#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;assert.h&gt;#define BUFSIZE (50)int main(void)&#123; char buf[BUFSIZE]; memset((void *)buf, &apos;\0&apos;, sizeof buf); assert(chdir(&quot;/tmp&quot;) == 0); printf(&quot;chdir to /tmp successful\n&quot;); assert(getcwd(buf, BUFSIZE) != NULL); printf(&quot;now the directory is %s\n&quot;, buf); return 0;&#125; 测试：1[qtlldr@qtldr editing]./chgetdirchdirto/tmpsuccessfulnowthedirectoryis/tmp[qtlldr@qtldrediting] opendir, closedir, readdir,12345678#include &lt;sys/type.s&gt; #include &lt;dirent.h&gt; DIR *opendir(const char *dirname); return: S DIR指针 F NULL note: DIR是一种目录结构，类似FILE。 12345678910#include &lt;sys/types.h&gt; #include &lt;dirent.h&gt; struct dirent *readir(DIR *dirp); return: S 一个指向保存目录流下一个目录项的dirent指针 F NULL note: struct dirent &#123; char d_name[NAME + 1]; /* \0结尾的文件名 */ &#125; 到达目录尾或出错返回NULL，但是到达目录尾不会设置errno，出错则设置。如果在readir的同时有其他进程在目录中创建或者删除文件爱你，readdir不保证能列处该目录中所有文件。123456#include &lt;sys/types.h&gt; #include &lt;dirent.h&gt; int closedir(DIR *dirp); return: S 0 F -1 printdir 输出目录文件或者统计目录中的文件数目语法： printdir [option] &lt;files…&gt;选项： -l 输出目录下的文件名 -c 统计目录下的文件 -d n 指定最大层次，最大为30默认行为： 如果没有指定选项，那么只输出该目录下的文件名123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define INDENT_DEPTH (4) /* 列举文件时的缩进数 */#define DEPTH_MAX (30) /* 递归便利的最大层次 */#define HELPFILE (&quot;help.txt&quot;)typedef int count_t;struct nfiletype &#123; count_t ndir; count_t nreg; count_t nchr; count_t nfifo; count_t nsock; count_t nchar; count_t nblock; count_t nlink; count_t ntotol; count_t nunknow;&#125;;/*记录各个类型文件的数目*/int DEPTH = 20; /* 递归层级限制 */int idepth_count = 1;int idepth_print = 1;static struct nfiletype *count_files(const char *pathname, struct nfiletype *nfile);static void printdir(const char *pathname, int indent);int main(int argc, char **argv)&#123; int opt; int depth_opt; int count_flag = 0; int print_flag = 0; char *parg = NULL; struct nfiletype nfiles = &#123;0&#125;; int fd_help; char buf_help[BUFSIZ]; int nread_help; char *filename_help = HELPFILE; while ((opt = getopt(argc, argv, &quot;lhd:c&quot;)) != -1) &#123; switch (opt) &#123; case &apos;l&apos;: print_flag = 1; break; case &apos;c&apos;: count_flag = 1; break; case &apos;d&apos;: depth_opt = strtol(optarg, NULL, 10); DEPTH = depth_opt &lt;= DEPTH_MAX ? depth_opt: DEPTH; break; case &apos;:&apos;: printf(&quot;option needs a value\n&quot;); break; case &apos;?&apos;: printf(&quot;unknown option :%c\n&quot;, optopt); break; case &apos;h&apos;: fd_help = open(filename_help, O_RDONLY); if (fd_help != -1) &#123; while ((nread_help = read(fd_help, buf_help, BUFSIZ)) &gt; 0) &#123; write(1, buf_help, nread_help); &#125; close(fd_help); &#125; else &#123; fprintf(stderr, &quot;open %s failed!\n&quot;, filename_help); &#125; return 0; &#125; &#125; /* 如果没有选项，那么默认是打印目录 */ if (!print_flag &amp;&amp; !count_flag) print_flag = 1; for( ; optind &lt; argc; optind++) &#123; parg = argv[optind]; if (print_flag) &#123; //printf(&quot;DEBUG-- printdir --%s\n&quot;, parg); printdir(parg, 4); &#125; if (count_flag) &#123; memset((void *)&amp;nfiles, &apos;\0&apos;, sizeof nfiles); //printf(&quot;DEBUG-- count_files--%s\n&quot;, parg); count_files(parg, &amp;nfiles); printf(&quot;In the %s there are :\n&quot;, parg); printf(&quot; directory %d\n&quot;, nfiles.ndir); printf(&quot; regular file %d\n&quot;, nfiles.nreg); printf(&quot; specal character file %d\n&quot;, nfiles.nchr); printf(&quot; special block file %d\n&quot;, nfiles.nblock); printf(&quot; fifo file %d\n&quot;, nfiles.nfifo); printf(&quot; sock file %d\n&quot;, nfiles.nsock); printf(&quot; link file %d\n&quot;, nfiles.nlink); printf(&quot; unknown file %d\n&quot;, nfiles.nunknow); printf(&quot;Total %d\n&quot;, nfiles.ntotol); &#125; &#125; return 0;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* *function: 对该目录下的文件类型进行统计 * input arg: * pathname:目录名指针 * nfile:记录文件类型数目的结构体指针 * return： * 记录文件类型数目的结构体指针 */static struct nfiletype *count_files(const char *pathname, struct nfiletype *nfile)&#123; DIR *dp; struct dirent *entry; struct stat statbuf; //printf(&quot;DEBUG-- in count_files -- %s\n&quot;, pathname); /* 层次控制 */ if (idepth_count &gt; DEPTH) return NULL; idepth_count++; if ((dp = opendir(pathname)) == NULL) &#123; fprintf(stderr, &quot;can not open %s\n&quot;, pathname); return NULL; &#125; chdir(pathname); while ((entry = readdir(dp)) != NULL) &#123; /* 跳过 . 和 .. */ if (strcmp(entry-&gt;d_name, &quot;.&quot;) == 0 || strcmp(entry-&gt;d_name, &quot;..&quot;) == 0) continue; /* 取得文件信息 */ if (lstat(entry-&gt;d_name, &amp;statbuf) == -1) &#123; fprintf(stderr, &quot;can not test the %s&apos;s type\n&quot;, entry-&gt;d_name); return NULL; &#125; /* 统计文件数目 */ if (S_ISDIR(statbuf.st_mode)) &#123; /* 是目录就递归吧 */ //printf(&quot;DEBUG -- directory %s\n&quot;, entry-&gt;d_name); count_files(entry-&gt;d_name, nfile); nfile-&gt;ndir++; &#125; else if (S_ISREG(statbuf.st_mode)) &#123; //printf(&quot;DEBUG -- regular file %s\n&quot;, entry-&gt;d_name); nfile-&gt;nreg++; &#125; else if (S_ISCHR(statbuf.st_mode)) nfile-&gt;nchr++; else if (S_ISBLK(statbuf.st_mode)) nfile-&gt;nblock++; else if (S_ISLNK(statbuf.st_mode)) nfile-&gt;nlink++; else if (S_ISFIFO(statbuf.st_mode)) nfile-&gt;nfifo++; else if (S_ISSOCK(statbuf.st_mode)) nfile-&gt;nsock++; else nfile-&gt;nunknow++; nfile-&gt;ntotol++; &#125; chdir(&quot;..&quot;); closedir(dp); return nfile; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041 /*nblock; *function:列出目录中的文件nlink; *input arg:ntotol; * pathname: 目录名 *return: * void */static void printdir(const char *pathname, int indent)&#123; DIR *dp; struct dirent *entry; struct stat statbuf; /* 层次控制 */ if (idepth_print &gt; DEPTH) return ; idepth_print++; if ((dp = opendir(pathname)) == NULL) &#123; fprintf(stderr, &quot;can not open %s\n&quot;, pathname); return ; &#125; chdir(pathname); while ((entry = readdir(dp)) != NULL) &#123; /* 跳过 . 和 .. */ if (strcmp(entry-&gt;d_name, &quot;.&quot;) == 0 || strcmp(entry-&gt;d_name, &quot;..&quot;) == 0) continue; if (lstat(entry-&gt;d_name, &amp;statbuf) == -1) &#123; fprintf(stderr, &quot;can not test the %s&apos;s type\n&quot;, entry-&gt;d_name); return ; &#125; if (S_ISDIR(statbuf.st_mode)) &#123; /* 是目录就递归吧 */ printf(&quot;%*s%s/\n&quot;, indent,&quot; &quot;, entry-&gt;d_name); printdir(entry-&gt;d_name, indent + INDENT_DEPTH); &#125; else &#123; printf(&quot;%*s%s\n&quot;, indent,&quot; &quot;, entry-&gt;d_name); &#125; &#125; chdir(&quot;..&quot;); closedir(dp);&#125; stat（）系统调用获取文件信息stat()获取文件元数据stat系统调用原型：12345#include &lt;sys/stat.h&gt;int stat(const char *path, struct stat *buf); int fstat(int fd, struct stat *buf); int lstat(const char *path, struct stat *buf); 123456789101112131415struct stat &#123; dev_t st_dev; /* ID of device containing file ：该文件所属设备的设备号，设备号包括主设备和和次设备号，dev_t是16位整数，高8位表示主设备号，低8位表示次设备号*/ ino_t st_ino; /* inode number */ mode_t st_mode; /* protection ：包含文件访问权限信息及文件类型*/ nlink_t st_nlink; /* number of hard links */ uid_t st_uid; /* user ID of owner */ gid_t st_gid; /* group ID of owner */ dev_t st_rdev; /* device ID (if special file)：如果该文件是特殊文件即设备文件，则表示设备号 */ off_t st_size; /* total size, in bytes */ blksize_t st_blksize; /* blocksize for file system I/O */ blkcnt_t st_blocks; /* number of 512B blocks allocated ：分配的块数量*/ time_t st_atime; /* time of last access */ time_t st_mtime; /* time of last modification */ time_t st_ctime; /* time of last status change：如修改文件的权限 */ &#125;; 文件类型有两种方式获得： 1.通过以下的一些宏进行验证：m为struct stat中得st_mode字段1234567S_ISREG(m) is it a regular file?S_ISDIR(m) directory?S_ISCHR(m) character device?S_ISBLK(m) block device?S_ISFIFO(m) FIFO (named pipe)?S_ISLNK(m) symbolic link? (Not in POSIX.1-1996.)S_ISSOCK(m) socket? (Not in POSIX.1-1996.) 2.利用struct stat中得st_mode字段与S_IFMT进行与运算：mode&amp;S_IFMT，然后将得到的结果与下列的常量比较，相等就是The following flags are defined for the st_mode field:12345678S_IFMT 0170000 bit mask for the file type bit fields S_IFSOCK 0140000 socket S_IFLNK 0120000 symbolic link S_IFREG 0100000 regular file S_IFBLK 0060000 block device S_IFDIR 0040000 directory S_IFCHR 0020000 character device S_IFIFO 0010000 FIFO 文件访问权限获得：利用struct stat中得st_mode字段与S_IFMT进行与运算：mode&amp;S_IFMT，然后将得到的结果与下列的常量比较，相等就是12345678910111213141516S_IFMT 0170000 bit mask for the file type bit fields S_ISUID 0004000 set UID bit S_ISGID 0002000 set-group-ID bit (see below) S_ISVTX 0001000 sticky bit (see below) S_IRWXU 00700 mask for file owner permissions S_IRUSR 00400 owner has read permission S_IWUSR 00200 owner has write permission S_IXUSR 00100 owner has execute permission S_IRWXG 00070 mask for group permissions S_IRGRP 00040 group has read permission S_IWGRP 00020 group has write permission S_IXGRP 00010 group has execute permission S_IRWXO 00007 mask for permissions for others (not in group) S_IROTH 00004 others have read permission S_IWOTH 00002 others have write permission S_IXOTH 00001 others have execute permission 示例程序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)#define MAJOR(a) (int)((unsigned short)a &gt;&gt; 8) //高8位：主设备号#define MINOR(a) (int)((unsigned short)a &amp; 0xFF)//低8位：次设备号int filetype(struct stat *buf);void fileperm(struct stat *buf, char *perm);int main(int argc, char *argv[])&#123; if (argc != 2) &#123; fprintf(stderr, &quot;Usage %s file\n&quot;, argv[0]); exit(EXIT_FAILURE); &#125; struct stat sbuf; printf(&quot;Filename:%s\n&quot;, argv[1]); if (lstat(argv[1], &amp;sbuf) == -1) ERR_EXIT(&quot;stat error&quot;); printf(&quot;File number:major %d,minor %d inode %d\n&quot;, MAJOR(sbuf.st_dev), MINOR(sbuf.st_dev), (int)sbuf.st_ino); if (filetype(&amp;sbuf)) &#123; printf(&quot;Device number:major %d,minor %d\n&quot;, MAJOR(sbuf.st_rdev), MINOR(sbuf.st_rdev)); &#125; char perm[11] = &#123;0&#125;; fileperm(&amp;sbuf, perm); printf(&quot;File permission bits=%o %s\n&quot;, sbuf.st_mode &amp; 07777, perm); return 0;&#125;int filetype(struct stat *buf)&#123; int flag = 0; printf(&quot;Filetype:&quot;); mode_t mode; mode = buf-&gt;st_mode; switch (mode &amp; S_IFMT) &#123; case S_IFSOCK: printf(&quot;socket\n&quot;); break; case S_IFLNK: printf(&quot;symbolic link\n&quot;); break; case S_IFREG: printf(&quot;regular file\n&quot;); break; case S_IFBLK: printf(&quot;block device\n&quot;); flag = 1; //该文件为设备文件 break; case S_IFDIR: printf(&quot;directory\n&quot;); break; case S_IFCHR: printf(&quot;character device\n&quot;); flag = 1; break; case S_IFIFO: printf(&quot;FIFO\n&quot;); break; default: printf(&quot;unknown file type\n&quot;); break; &#125; return flag;&#125;void fileperm(struct stat *buf, char *perm)&#123; strcpy(perm, &quot;----------&quot;); perm[0] = &apos;?&apos;; mode_t mode; mode = buf-&gt;st_mode; switch (mode &amp; S_IFMT) &#123; case S_IFSOCK: perm[0] = &apos;s&apos;; break; case S_IFLNK: perm[0] = &apos;l&apos;; break; case S_IFREG: perm[0] = &apos;-&apos;; break; case S_IFBLK: perm[0] = &apos;b&apos;; break; case S_IFDIR: perm[0] = &apos;d&apos;; break; case S_IFCHR: perm[0] = &apos;c&apos;; break; case S_IFIFO: perm[0] = &apos;p&apos;; break; &#125; if (mode &amp; S_IRUSR) perm[1] = &apos;r&apos;; if (mode &amp; S_IWUSR) perm[2] = &apos;w&apos;; if (mode &amp; S_IXUSR) perm[3] = &apos;x&apos;; if (mode &amp; S_IRGRP) perm[4] = &apos;r&apos;; if (mode &amp; S_IWGRP) perm[5] = &apos;w&apos;; if (mode &amp; S_IXGRP) perm[6] = &apos;x&apos;; if (mode &amp; S_IROTH) perm[7] = &apos;r&apos;; if (mode &amp; S_IWOTH) perm[8] = &apos;w&apos;; if (mode &amp; S_IXOTH) perm[9] = &apos;x&apos;; perm[10] = &apos;\0&apos;;&#125; 运行结果：]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程同步之POSIX信号量]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8BPOSIX%E4%BF%A1%E5%8F%B7%E9%87%8F%2F</url>
    <content type="text"><![CDATA[POSIX信号量是属于POSIX标准系统接口定义的实时扩展部分。在SUS（Single UNIX Specification）单一规范中，定义的XSI IPC中也同样定义了人们通常称为System V信号量的系统接口。信号量作为进程间同步的工具是很常用的一种同步IPC类型。 在《UNIX网络编程 卷2：进程间通信》的前言第二页与第1版的区别中作者提到“POSIX IPC函数时大势所趋，因为他们比System V中的相应部分更具有优势”，这里所说的优势我还得慢慢领会呀。。。&lt;T_T&gt; 信号量是一种用于不同进程间进行同步的工具，当然对于进程安全的对于线程也肯定是安全的，所以信号量也理所当然可以用于同一进程内的不同线程的同步。 有了互斥量和条件变量还提供信号量的原因是：信号量的主要目的是提供一种进程间同步的方式。这种同步的进程可以共享也可以不共享内存区。虽然信号量的意图在于进程间的同步，互斥量和条件变量的意图在于线程间同步，但信号量也可用于线程间同步，互斥量和条件变量也可通过共享内存区进行进程间同步。但应该根据具体应用考虑到效率和易用性进行具体的选择。 POSIX信号量的操作POSIX信号量有两种：有名信号量和无名信号量，无名信号量也被称作基于内存的信号量。有名信号量通过IPC名字进行进程间的同步，而无名信号量如果不是放在进程间的共享内存区中，是不能用来进行进程间同步的，只能用来进行线程同步。 POSIX信号量有三种操作： （1）创建一个信号量。创建的过程还要求初始化信号量的值。 根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为： 二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。（2）等待一个信号量（wait）。该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。这整个操作必须是一个原子操作。该操作还经常被称为P操作（荷兰语Proberen，意为：尝试）。 （3）挂出一个信号量（post）。该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。该操作也必须是一个原子操作。该操作还经常被称为V操作（荷兰语Verhogen，意为：增加） 下面演示经典的生产者消费者问题，单个生产者和消费者共享一个缓冲区； 下面是生产者和消费者同步的伪代码： 12345678910//信号量的初始化get = 0;//表示可读资源的数目put = 1;//表示可写资源的数目 //生产者进程 //消费者进程for(; ;)&#123; for(; ;)&#123;Sem_wait(put); Sem_wait(get);写共享缓冲区； 读共享缓冲区；Sem_post(get); Sem_post(put);&#125; &#125; 上面的代码大致流程如下：当生产者和消费者开始都运行时，生产者获取put信号量，此时put为1表示有资源可用，生产者进入共享缓冲区，进行修改。而消费者获取get信号量，而此时get为0，表示没有资源可读，于是消费者进入等待序列，直到生产者生产出一个数据，然后生产者通过挂出get信号量来通知等待的消费者，有数据可以读。很多时候信号量和互斥量，条件变量三者都可以在某种应用中使用，那这三者的差异有哪些呢，下面列出了这三者之间的差异： 互斥量必须由给它上锁的线程解锁。而信号量不需要由等待它的线程进行挂出，可以在其他进程进行挂出操作。互斥量要么被锁住，要么是解开状态，只有这两种状态。而信号量的值可以支持多个进程成功进行wait操作。信号量的挂出操作总是被记住，因为信号量有一个计数值，挂出操作总会将该计数值加1，然而当向条件变量发送一个信号时，如果没有线程等待在条件变量，那么该信号会丢失。 POSIX信号量函数接口POSIX信号量的函数接口如下图所示： 有名信号量的创建和删除123456#include &lt;semaphore.h&gt; sem_t *sem_open(const char *name, int oflag);sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value); //成功返回信号量指针，失败返回SEM_FAILED sem_open用于创建或打开一个信号量，信号量是通过name参数即信号量的名字来进行标识的。关于POSX IPC的名字可以参考《UNIX网络编程 卷2：进程间通信》P14。 oflag参数可以为：0，O_CREAT，O_EXCL。如果为0表示打开一个已存在的信号量，如果为O_CREAT，表示如果信号量不存在就创建一个信号量，如果存在则打开被返回。此时mode和value需要指定。如果为O_CREAT | O_EXCL，表示如果信号量已存在会返回错误。 mode参数用于创建信号量时，表示信号量的权限位，和open函数一样包括：S_IRUSR，S_IWUSR，S_IRGRP，S_IWGRP，S_IROTH，S_IWOTH。 value表示创建信号量时，信号量的初始值。12345#include &lt;semaphore.h&gt; int sem_close(sem_t *sem);int sem_unlink(const char *name); //成功返回0，失败返回-1 sem_close用于关闭打开的信号量。当一个进程终止时，内核对其上仍然打开的所有有名信号量自动执行这个操作。调用sem_close关闭信号量并没有把它从系统中删除它，POSIX有名信号量是随内核持续的。即使当前没有进程打开某个信号量它的值依然保持。直到内核重新自举或调用sem_unlink()删除该信号量。 sem_unlink用于将有名信号量立刻从系统中删除，但信号量的销毁是在所有进程都关闭信号量的时候。 信号量的P操作12345678910#include &lt;semaphore.h&gt; int sem_wait (sem_t *sem); #ifdef __USE_XOPEN2Kint sem_timedwait(sem_t *sem, const struct timespec *abs_timeout);#endif int sem_trywait (sem_t * sem); //成功返回0，失败返回-1 sem_wait()用于获取信号量，首先会测试指定信号量的值，如果大于0，就会将它减1并立即返回，如果等于0，那么调用线程会进入睡眠，指定信号量的值大于0.sem_trywait和sem_wait的差别是，当信号量的值等于0的，调用线程不会阻塞，直接返回，并标识EAGAIN错误。 sem_timedwait和sem_wait的差别是当信号量的值等于0时，调用线程会限时等待。当等待时间到后，信号量的值还是0，那么就会返回错误。其中struct timespec *abs_timeout是一个绝对时间，具体可以参考条件变量关于等待时间的使用 信号量的V操作1234#include &lt;semaphore.h&gt; int sem_post(sem_t *sem); //成功返回0，失败返回-1 当一个线程使用完某个信号量后，调用sem_post，使该信号量的值加1，如果有等待的线程，那么会唤醒等待的一个线程。 获取当前信号量的值1234#include &lt;semaphore.h&gt; int sem_getvalue(sem_t *sem, int *sval); //成功返回0，失败返回-1 该函数返回当前信号量的值，通过sval输出参数返回，如果当前信号量已经上锁（即同步对象不可用），那么返回值为0，或为负数，其绝对值就是等待该信号量解锁的线程数。 下面测试在Linux下的信号量是否会出现负值：123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt; #include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt; using namespace std; #define SEM_NAME &quot;/sem_name&quot; sem_t *pSem; void * testThread (void *ptr)&#123; sem_wait(pSem); sleep(10); sem_close(pSem);&#125; int main()&#123; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); pthread_t pid; int semVal; for (int i = 0; i &lt; 7; ++i) &#123; pthread_create(&amp;pid, NULL, testThread, NULL); sleep(1); sem_getvalue(pSem, &amp;semVal); cout&lt;&lt;&quot;semaphore value:&quot;&lt;&lt;semVal&lt;&lt;endl; &#125; sem_close(pSem); sem_unlink(SEM_NAME);&#125; 执行结果如下：1234567semaphore value:4semaphore value:3semaphore value:2semaphore value:1semaphore value:0semaphore value:0semaphore value:0 这说明在Linux 2.6.18中POSIX信号量是不会出现负值的。 无名信号量的创建和销毁123456#include &lt;semaphore.h&gt; int sem_init(sem_t *sem, int pshared, unsigned int value); //若出错则返回-1int sem_destroy(sem_t *sem); //成功返回0，失败返回-1 sem_init()用于无名信号量的初始化。无名信号量在初始化前一定要在内存中分配一个sem_t信号量类型的对象，这就是无名信号量又称为基于内存的信号量的原因。 sem_init()第一个参数是指向一个已经分配的sem_t变量。第二个参数pshared表示该信号量是否由于进程间通步，当pshared = 0，那么表示该信号量只能用于进程内部的线程间的同步。当pshared != 0，表示该信号量存放在共享内存区中，使使用它的进程能够访问该共享内存区进行进程同步。第三个参数value表示信号量的初始值。 这里需要注意的是，无名信号量不使用任何类似O_CREAT的标志，这表示sem_init()总是会初始化信号量的值，所以对于特定的一个信号量，我们必须保证只调用sem_init()进行初始化一次，对于一个已初始化过的信号量调用sem_init()的行为是未定义的。如果信号量还没有被某个线程调用还好，否则基本上会出现问题。 使用完一个无名信号量后，调用sem_destroy摧毁它。这里要注意的是：摧毁一个有线程阻塞在其上的信号量的行为是未定义的。 有名和无名信号量的持续性有名信号量是随内核持续的。当有名信号量创建后，即使当前没有进程打开某个信号量它的值依然保持。直到内核重新自举或调用sem_unlink()删除该信号量。 无名信号量的持续性要根据信号量在内存中的位置： 如果无名信号量是在单个进程内部的数据空间中，即信号量只能在进程内部的各个线程间共享，那么信号量是随进程的持续性，当进程终止时它也就消失了。如果无名信号量位于不同进程的共享内存区，因此只要该共享内存区仍然存在，该信号量就会一直存在。所以此时无名信号量是随内核的持续性。 信号量的继承和销毁继承对于有名信号量在父进程中打开的任何有名信号量在子进程中仍是打开的。即下面代码是正确的：123456789sem_t *pSem;pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); if(fork() == 0)&#123; //... sem_wait(pSem); //...&#125; 对于无名信号量的继承要根据信号量在内存中的位置： 如果无名信号量是在单个进程内部的数据空间中，那么信号量就是进程数据段或者是堆栈上，当fork产生子进程后，该信号量只是原来的一个拷贝，和之前的信号量是独立的。下面是测试代码：123456789101112131415161718192021222324252627282930int main()&#123; sem_t mSem; sem_init(&amp;mSem, 0, 3); int val; sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_wait(&amp;mSem); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; if(fork() == 0) &#123; sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_wait(&amp;mSem); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; exit(0); &#125; sleep(1); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl;&#125; 测试结果如下：12345parent:semaphore value:3parent:semaphore value:2child:semaphore value:2child:semaphore value:1parent:semaphore value:2 如果无名信号量位于不同进程的共享内存区，那么fork产生的子进程中的信号量仍然会存在该共享内存区，所以该信号量仍然保持着之前的状态。 销毁对于有名信号量，当某个持有该信号量的进程没有解锁该信号量就终止了，内核并不会将该信号量解锁。这跟记录锁不一样。 对于无名信号量，如果信号量位于进程内部的内存空间中，当进程终止后，信号量也就不存在了，无所谓解锁了。如果信号量位于进程间的共享内存区中，当进程终止后，内核也不会将该信号量解锁。 下面是测试代码：123456789101112131415161718192021222324int main()&#123; sem_t *pSem; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); int val; sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; if(fork() == 0) &#123; sem_wait(pSem); sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; exit(0); &#125; sleep(1); sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_unlink(SEM_NAME);&#125; 下面是测试结果：123parent:semaphore value:5child:semaphore value:4parent:semaphore value:4 信号量代码测试对于有名信号量在父进程中打开的任何有名信号量在子进程中仍是打开的。即下面代码是正确的： 对于信号量用于进程间同步的代码的测试，我没有采用经典的生产者和消费者问题，原因是这里会涉及到共享内存的操作。我只是简单的用一个同步文件操作的例子进行描述。 在下面的测试代码中，POSIX有名信号量初始值为2，允许两个进程获得文件的操作权限。代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt; #include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt; using namespace std; #define SEM_NAME &quot;/sem_name&quot; void semTest(int flag)&#123; sem_t *pSem; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 2); sem_wait(pSem); ofstream fileStream(&quot;./test.txt&quot;, ios_base::app); for (int i = 0; i &lt; 5; ++i) &#123; sleep(1); fileStream&lt;&lt;flag; fileStream&lt;&lt;&apos; &apos;&lt;&lt;flush; &#125; sem_post(pSem); sem_close(pSem);&#125; int main()&#123; for (int i = 1; i &lt;= 3; ++i) &#123; if (fork() == 0) &#123; semTest(i); sleep(1); exit(0); &#125; &#125;&#125; 程序的运行结果，“./test.txt”文件的内容如下：12//./test.txt1 2 1 2 1 2 1 2 1 2 3 3 3 3 3]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPC通信:Posix消息队列]]></title>
    <url>%2F2019%2F05%2F18%2FLinux_IPC%E9%80%9A%E4%BF%A1_Posix%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[消息队列可以认为是一个链表。进程（线程）可以往里写消息，也可以从里面取出消息。一个进程可以往某个消息队列里写消息，然后终止，另一个进程随时可以从消息队列里取走这些消息。这里也说明了，消息队列具有随内核的持续性，也就是系统不重启，消息队列永久存在。 创建（并打开）、关闭、删除一个消息队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; //头文件#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; /* 函数说明：函数创建或打开一个消息队列 返回值：成功返回消息队列描述符，失败返回-1，错误原因存于errno中 */ posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; /* 函数说明：关闭一个打开的消息队列，表示本进程不再对该消息队列读写 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; /* 函数说明：删除一个消息队列，好比删除一个文件，其他进程再也无法访问 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译并执行：123456root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c/tmp/ccZ9cTxo.o: In function `main&apos;:crtmq.c:(.text+0x31): undefined reference to `mq_open&apos;crtmq.c:(.text+0x60): undefined reference to `mq_close&apos;crtmq.c:(.text+0x8f): undefined reference to `mq_unlink&apos;collect2: ld returned 1 exit status 因为mq_XXX()函数不是标准库函数，链接时需要指定；库-lrt；12root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./crtmq 最后程序并没有删除消息队列（消息队列有随内核持续性），如再次执行该程序则会给出错误信息：12root@linux:/mnt/hgfs/C_libary# ./crtmq 创建MQ失败: File exit(0) 编译这个程序需要注意几点： 消息队列的名字最好使用“/”打头，并且只有一个“/”的名字。否则可能出现移植性问题；（还需保证在根目录有写权限,为了方便我在root权限下测试） 创建成功的消息队列不一定能看到，使用一些方法也可以看到，本文不做介绍； 消息队列的名字有如此规定，引用《UNIX网络编程 卷2》的相关描述： mq_open,sem_open,shm_open这三个函数的第一个参数是一个IPC名字，它可能是某个文件系统中的一个真正存在的路径名，也可能不是。Posix.1是这样描述Posix IPC名字的。1)它必须符合已有的路径名规则（最多由PATH_MAX个字节构成，包括结尾的空字节）2)如果它以斜杠开头，那么对这些函数的不同调用将访问同一个队列，否则效果取决于实现（也就是效果没有标准化）3)名字中的额外的斜杠符的解释由实现定义（同样是没有标准化） 因此，为便于移植起见，Posix IPC名字必须以一个斜杠打头，并且不能再包含任何其他斜杠符。 IPC通信:Posix消息队列读,写创建消息队列的程序:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; //头文件#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; /* 函数说明：函数创建或打开一个消息队列 返回值：成功返回消息队列描述符，失败返回-1，错误原因存于errno中 */ posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; /* 函数说明：关闭一个打开的消息队列，表示本进程不再对该消息队列读写 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; #if 0 /* 函数说明：删除一个消息队列，好比删除一个文件，其他进程再也无法访问 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0;#endif &#125; 编译并执行：12root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./crtmq 程序并没有删除消息队列（消息队列有随内核持续性），如再次执行该程序则会给出错误信息：12root@linux:/mnt/hgfs/C_libary# ./crtmq 创建MQ失败: File exit(0) 向消息队列写消息的程序： 消息队列的读写主要使用下面两个函数：12345678910111213141516/*头文件*/#include &lt;mqueue.h&gt; /*返回：若成功则为消息中字节数，若出错则为-1 */ int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len, unsigned msg_prio); /*返回：若成功则为0， 若出错则为-1*/ ssize_t mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len, unsigned *msg_prio); /*消息队列属性结构体*/struct mq_attr &#123; long mq_flags; /* Flags: 0 or O_NONBLOCK */ long mq_maxmsg; /* Max. # of messages on queue */ long mq_msgsize; /* Max. message size (bytes) */ long mq_curmsgs; /* # of messages currently in queue */ &#125;; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; /*向消息队列发送消息，消息队列名及发送的信息通过参数传递*/ int main(int argc, char *argv[]) &#123; mqd_t mqd; char *ptr; size_t len; unsigned int prio; int rc; if(argc != 4) &#123; printf(&quot;Usage: sendmq &lt;name&gt; &lt;bytes&gt; &lt;priority&gt;\n&quot;); exit(1); &#125; len = atoi(argv[2]); prio = atoi(argv[3]); //只写模式找开消息队列 mqd = mq_open(argv[1], O_WRONLY); if(-1 == mqd) &#123; perror(&quot;打开消息队列失败&quot;); exit(1); &#125; // 动态申请一块内存 ptr = (char *) calloc(len, sizeof(char)); if(NULL == ptr) &#123; perror(&quot;申请内存失败&quot;); mq_close(mqd); exit(1); &#125; /*向消息队列写入消息，如消息队列满则阻塞，直到消息队列有空闲时再写入*/ rc = mq_send(mqd, ptr, len, prio); if(rc &lt; 0) &#123; perror(&quot;写入消息队列失败&quot;); mq_close(mqd); exit(1); &#125; // 释放内存 free(ptr); return 0; &#125; 编译并执行：12345root@linux:/mnt/hgfs/C_libary# gcc -o sendmq sendmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 15root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 16root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 17root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 18 上面先后向消息队列“/tmp”写入了四条消息，因为先前创建的消息队列只允许存放3条消息，本次第四次写入时程序会阻塞。直到有另外进程从消息队列取走消息后本次写入才成功返回。 读消息队列：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; /*读取某消息队列,消息队列名通过参数传递*/ int main(int argc, char *argv[]) &#123; mqd_t mqd; struct mq_attr attr; char *ptr; unsigned int prio; size_t n; int rc; if(argc != 2) &#123; printf(&quot;Usage: readmq &lt;name&gt;\n&quot;); exit(1); &#125; /*只读模式打开消息队列*/ mqd = mq_open(argv[1], O_RDONLY); if(mqd &lt; 0) &#123; perror(&quot;打开消息队列失败&quot;); exit(1); &#125; // 取得消息队列属性，根据mq_msgsize动态申请内存 rc = mq_getattr(mqd, &amp;attr); if(rc &lt; 0) &#123; perror(&quot;取得消息队列属性失败&quot;); exit(1); &#125; /*动态申请保证能存放单条消息的内存*/ ptr = calloc(attr.mq_msgsize, sizeof(char)); if(NULL == ptr) &#123; printf(&quot;动态申请内存失败\n&quot;); mq_close(mqd); exit(1); &#125; /*接收一条消息*/ n = mq_receive(mqd, ptr, attr.mq_msgsize, &amp;prio); if(n &lt; 0) &#123; perror(&quot;读取失败&quot;); mq_close(mqd); free(ptr); exit(1); &#125; printf(&quot;读取 %ld 字节\n 优先级为 %u\n&quot;, (long)n, prio); return 0; &#125; 编译并执行：12345678910111213141516root@linux:/mnt/hgfs/C_libary# vi readmq.croot@linux:/mnt/hgfs/C_libary# vi readmq.croot@linux:/mnt/hgfs/C_libary# gcc -o readmq readmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 18root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 17root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 16root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 15root@linux:/mnt/hgfs/C_libary# ./readmq /tmp 程序执行五次，第一次执行完，先前阻塞在写处的程序成功返回。第五次执行，因为消息队列已经为空，程序阻塞。直到另外的进程向消息队列写入一条消息。另外，还可以看出Posix消息队列每次读出的都是消息队列中优先级最高的消息。 IPC通信:Posix消息队列的属性设置 Posix消息队列的属性使用如下结构存放：1234567struct mq_attr &#123; long mq_flags; /*阻塞标志位，0为非阻塞(O_NONBLOCK)*/ long mq_maxmsg; /*队列所允许的最大消息条数*/ long mq_msgsize; /*每条消息的最大字节数*/ long mq_curmsgs; /*队列当前的消息条数*/ &#125;; 队列可以在创建时由mq_open()函数的第四个参数指定mq_maxmsg，mq_msgsize。 如创建时没有指定则使用默认值，一旦创建，则不可再改变。队列可以在创建后由mq_setattr()函数设置mq_flags123456789#include &lt;mqueue.h&gt; /*取得消息队列属性，放到mqstat地fh*/ int mq_getattr(mqd_t mqdes, struct mq_attr *mqstat); /*设置消息队列属性，设置值由mqstat提供，原先值写入omqstat*/ int mq_setattr(mqd_t mqdes, const struct mq_attr *mqstat, struct mq_attr *omqstat); 均返回：若成功则为0，若出错为-1 程序获取和设置消息队列的默认属性：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; struct mq_attr mqattr; // 创建默认属性的消息队列 posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; // 获取消息队列的默认属性 rc = mq_getattr(posixmq, &amp;mqattr); if(-1 == rc) &#123; perror(&quot;获取消息队列属性失败&quot;); exit(1); &#125; printf(&quot;队列阻塞标志位：%ld\n&quot;, mqattr.mq_flags); printf(&quot;队列允许最大消息数：%ld\n&quot;, mqattr.mq_maxmsg); printf(&quot;队列消息最大字节数：%ld\n&quot;, mqattr.mq_msgsize); printf(&quot;队列当前消息条数：%ld\n&quot;, mqattr.mq_curmsgs); rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译并执行：1234567root@linux:/mnt/hgfs/C_libary# gcc -o attrmq attrmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./attrmq队列阻塞标志位：0队列允许最大消息数：10队列消息最大字节数：8192队列当前消息条数：0root@linux:/mnt/hgfs/C_libary# 设置消息队列的属性：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; struct mq_attr mqattr; // 创建默认属性的消息队列 mqattr.mq_maxmsg = 5; // 注意不能超过系统最大限制 mqattr.mq_msgsize = 8192; //posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, &amp;mqattr); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; mqattr.mq_flags = 0; mq_setattr(posixmq, &amp;mqattr, NULL);// mq_setattr()只关注mq_flags，adw // 获取消息队列的属性 rc = mq_getattr(posixmq, &amp;mqattr); if(-1 == rc) &#123; perror(&quot;获取消息队列属性失败&quot;); exit(1); &#125; printf(&quot;队列阻塞标志位：%ld\n&quot;, mqattr.mq_flags); printf(&quot;队列允许最大消息数：%ld\n&quot;, mqattr.mq_maxmsg); printf(&quot;队列消息最大字节数：%ld\n&quot;, mqattr.mq_msgsize); printf(&quot;队列当前消息条数：%ld\n&quot;, mqattr.mq_curmsgs); rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译运行：123456root@linux:/mnt/hgfs/C_libary# gcc -o setattrmq setattrmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./setattrmq队列阻塞标志位：0队列允许最大消息数：5队列消息最大字节数：8192队列当前消息条数：0]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程间通信—使用共享内存]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A-%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[什么是共享内存顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存。共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常安排为同一段物理内存。进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址，就好像它们是由用C语言函数malloc分配的内存一样。而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。 特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取。所以我们通常需要用其他的机制来同步对共享内存的访问，例如前面说到的信号量。有关信号量的更多内容，可以查阅我的另一篇文章：Linux进程间通信——使用信号量 共享内存的使得与信号量一样，在Linux中也提供了一组函数接口用于使用共享内存，而且使用共享共存的接口还与信号量的非常相似，而且比使用信号量的接口来得简单。它们声明在头文件 sys/shm.h中。 shmget函数该函数用来创建共享内存，它的原型为：1int shmget(key_t key, size_t size, int shmflg); 第一个参数，与信号量的semget函数一样，程序需要提供一个参数key（非0整数），它有效地为共享内存段命名，shmget函数成功时返回一个与key相关的共享内存标识符（非负整数），用于后续的共享内存函数。调用失败返回-1. 不相关的进程可以通过该函数的返回值访问同一共享内存，它代表程序可能要使用的某个资源，程序对所有共享内存的访问都是间接的，程序先通过调用shmget函数并提供一个键，再由系统生成一个相应的共享内存标识符（shmget函数的返回值），只有shmget函数才直接使用信号量键，所有其他的信号量函数使用由semget函数返回的信号量标识符。 第二个参数，size以字节为单位指定需要共享的内存容量 第三个参数，shmflg是权限标志，它的作用与open函数的mode参数一样，如果要想在key标识的共享内存不存在时，创建它的话，可以与IPC_CREAT做或操作。共享内存的权限标志与文件的读写权限一样，举例来说，0644,它表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。 shmat函数第一次创建完共享内存时，它还不能被任何进程访问，shmat函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。它的原型如下：1void *shmat(int shm_id, const void *shm_addr, int shmflg); 第一个参数，shm_id是由shmget函数返回的共享内存标识。第二个参数，shm_addr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址。第三个参数，shm_flg是一组标志位，通常为0。 调用成功时返回一个指向共享内存第一个字节的指针，如果调用失败返回-1. shmdt函数该函数用于将共享内存从当前进程中分离。注意，将共享内存分离并不是删除它，只是使该共享内存对当前进程不再可用。它的原型如下：int shmdt(const void *shmaddr);参数shmaddr是shmat函数返回的地址指针，调用成功时返回0，失败时返回-1. shmctl函数与信号量的semctl函数一样，用来控制共享内存，它的原型如下：int shmctl(int shm_id, int command, struct shmid_ds *buf);第一个参数，shm_id是shmget函数返回的共享内存标识符。 第二个参数，command是要采取的操作，它可以取下面的三个值 ： IPC_STAT：把shmid_ds结构中的数据设置为共享内存的当前关联值，即用共享内存的当前关联值覆盖shmid_ds的值。 IPC_SET：如果进程有足够的权限，就把共享内存的当前关联值设置为shmid_ds结构中给出的值 IPC_RMID：删除共享内存段 第三个参数，buf是一个结构指针，它指向共享内存模式和访问权限的结构。shmid_ds结构至少包括以下成员：123456struct shmid_ds&#123; uid_t shm_perm.uid; uid_t shm_perm.gid; mode_t shm_perm.mode;&#125;; 使用共享内存进行进程间通信说了这么多，又到了实战的时候了。下面就以两个不相关的进程来说明进程间如何通过共享内存来进行通信。其中一个文件shmread.c创建共享内存，并读取其中的信息，另一个文件shmwrite.c向共享内存中写入数据。为了方便操作和数据结构的统一，为这两个文件定义了相同的数据结构，定义在文件shmdata.c中。结构shared_use_st中的written作为一个可读或可写的标志，非0：表示可读，0表示可写，text则是内存中的文件。 shmdata.h的源代码如下：123456789101112#ifndef _SHMDATA_H_HEADER#define _SHMDATA_H_HEADER #define TEXT_SZ 2048 struct shared_use_st&#123; int written;//作为一个标志，非0：表示可读，0表示可写 char text[TEXT_SZ];//记录写入和读取的文本&#125;; #endif 源文件shmread.c的源代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/shm.h&gt;#include &quot;shmdata.h&quot; int main()&#123; int running = 1;//程序是否继续运行的标志 void *shm = NULL;//分配的共享内存的原始首地址 struct shared_use_st *shared;//指向shm int shmid;//共享内存标识符 //创建共享内存 shmid = shmget((key_t)1234, sizeof(struct shared_use_st), 0666|IPC_CREAT); if(shmid == -1) &#123; fprintf(stderr, &quot;shmget failed\n&quot;); exit(EXIT_FAILURE); &#125; //将共享内存连接到当前进程的地址空间 shm = shmat(shmid, 0, 0); if(shm == (void*)-1) &#123; fprintf(stderr, &quot;shmat failed\n&quot;); exit(EXIT_FAILURE); &#125; printf(&quot;\nMemory attached at %X\n&quot;, (int)shm); //设置共享内存 shared = (struct shared_use_st*)shm; shared-&gt;written = 0; while(running)//读取共享内存中的数据 &#123; //没有进程向共享内存定数据有数据可读取 if(shared-&gt;written != 0) &#123; printf(&quot;You wrote: %s&quot;, shared-&gt;text); sleep(rand() % 3); //读取完数据，设置written使共享内存段可写 shared-&gt;written = 0; //输入了end，退出循环（程序） if(strncmp(shared-&gt;text, &quot;end&quot;, 3) == 0) running = 0; &#125; else//有其他进程在写数据，不能读取数据 sleep(1); &#125; //把共享内存从当前进程中分离 if(shmdt(shm) == -1) &#123; fprintf(stderr, &quot;shmdt failed\n&quot;); exit(EXIT_FAILURE); &#125; //删除共享内存 if(shmctl(shmid, IPC_RMID, 0) == -1) &#123; fprintf(stderr, &quot;shmctl(IPC_RMID) failed\n&quot;); exit(EXIT_FAILURE); &#125; exit(EXIT_SUCCESS);&#125; 源文件shmwrite.c的源代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/shm.h&gt;#include &quot;shmdata.h&quot; int main()&#123; int running = 1; void *shm = NULL; struct shared_use_st *shared = NULL; char buffer[BUFSIZ + 1];//用于保存输入的文本 int shmid; //创建共享内存 shmid = shmget((key_t)1234, sizeof(struct shared_use_st), 0666|IPC_CREAT); if(shmid == -1) &#123; fprintf(stderr, &quot;shmget failed\n&quot;); exit(EXIT_FAILURE); &#125; //将共享内存连接到当前进程的地址空间 shm = shmat(shmid, (void*)0, 0); if(shm == (void*)-1) &#123; fprintf(stderr, &quot;shmat failed\n&quot;); exit(EXIT_FAILURE); &#125; printf(&quot;Memory attached at %X\n&quot;, (int)shm); //设置共享内存 shared = (struct shared_use_st*)shm; while(running)//向共享内存中写数据 &#123; //数据还没有被读取，则等待数据被读取,不能向共享内存中写入文本 while(shared-&gt;written == 1) &#123; sleep(1); printf(&quot;Waiting...\n&quot;); &#125; //向共享内存中写入数据 printf(&quot;Enter some text: &quot;); fgets(buffer, BUFSIZ, stdin); strncpy(shared-&gt;text, buffer, TEXT_SZ); //写完数据，设置written使共享内存段可读 shared-&gt;written = 1; //输入了end，退出循环（程序） if(strncmp(buffer, &quot;end&quot;, 3) == 0) running = 0; &#125; //把共享内存从当前进程中分离 if(shmdt(shm) == -1) &#123; fprintf(stderr, &quot;shmdt failed\n&quot;); exit(EXIT_FAILURE); &#125; sleep(2); exit(EXIT_SUCCESS);&#125; 再来看看运行的结果： 分析： 程序shmread创建共享内存，然后将它连接到自己的地址空间。在共享内存的开始处使用了一个结构struct_use_st。该结构中有个标志written，当共享内存中有其他进程向它写入数据时，共享内存中的written被设置为0，程序等待。当它不为0时，表示没有进程对共享内存写入数据，程序就从共享内存中读取数据并输出，然后重置设置共享内存中的written为0，即让其可被shmwrite进程写入数据。 程序shmwrite取得共享内存并连接到自己的地址空间中。检查共享内存中的written，是否为0，若不是，表示共享内存中的数据还没有被完，则等待其他进程读取完成，并提示用户等待。若共享内存的written为0，表示没有其他进程对共享内存进行读取，则提示用户输入文本，并再次设置共享内存中的written为1，表示写完成，其他进程可对共享内存进行读操作。 关于前面的例子的安全性讨论这个程序是不安全的，当有多个程序同时向共享内存中读写数据时，问题就会出现。可能你会认为，可以改变一下written的使用方式，例如，只有当written为0时进程才可以向共享内存写入数据，而当一个进程只有在written不为0时才能对其进行读取，同时把written进行加1操作，读取完后进行减1操作。这就有点像文件锁中的读写锁的功能。咋看之下，它似乎能行得通。但是这都不是原子操作，所以这种做法是行不能的。试想当written为0时，如果有两个进程同时访问共享内存，它们就会发现written为0，于是两个进程都对其进行写操作，显然不行。当written为1时，有两个进程同时对共享内存进行读操作时也是如些，当这两个进程都读取完是，written就变成了-1. 要想让程序安全地执行，就要有一种进程同步的进制，保证在进入临界区的操作是原子操作。例如，可以使用前面所讲的信号量来进行进程的同步。因为信号量的操作都是原子性的。 使用共享内存的优缺点 优点：我们可以看到使用共享内存进行进程间的通信真的是非常方便，而且函数的接口也简单，数据的共享还使进程间的数据不用传送，而是直接访问内存，也加快了程序的效率。同时，它也不像匿名管道那样要求通信的进程有一定的父子关系。 缺点：共享内存没有提供同步的机制，这使得我们在使用共享内存进行进程间通信时，往往要借助其他的手段来进行进程间的同步工作。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程通信之POSIX共享内存]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%E4%B9%8BPOSIX%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/anonymalias/article/details/9938865 Linux下个各种进程间的通信方式：管道，FIFO，消息队列，他们的共同特点就是通过内核来进行通信（假设POSIX消息队列也是在内核中实现的，因为POSIX标准并没有限定它的实现方式）。向管道，FIFO，消息队列写入数据需要把数据从进程复制到内核，从这些IPC读取数据的时候又需要把数据从内核复制到进程。所以这种IPC方式往往需要2次在进程和内核之间进行数据的复制，即进程间的通信必须借助内核来传递。如下图所示： 共享内存也是一种IPC，它是目前可用IPC中最快的，它是使用方式是将同一个内存区映射到共享它的不同进程的地址空间中，这样这些进程间的通信就不再需要通过内核，只需对该共享的内存区域进程操作就可以了，和其他IPC不同的是，共享内存的使用需要用户自己进行同步操作。下图是共享内存区IPC的通信， mmap系列函数简介mmap函数主要的功能就是将文件或设备映射到调用进程的地址空间中，当使用mmap映射文件到进程后,就可以直接操作这段虚拟地址进行文件的读写等操作,不必再调用read，write等系统调用。在很大程度上提高了系统的效率和代码的简洁性。 使用mmap函数的主要目的是： 对普通文件提供内存映射I/O，可以提供无亲缘进程间的通信； 提供匿名内存映射，以供亲缘进程间进行通信。 对shm_open创建的POSIX共享内存区对象进程内存映射，以供无亲缘进程间进行通信。 下面是mmap函数的接口以及说明：123#include &lt;sys/mman.h&gt;void *mmap(void *start, size_t len, int prot, int flags, int fd, off_t offset); //成功返回映射到进程地址空间的起始地址，失败返回MAP_FAILED start：指定描述符fd应被映射到的进程地址空间内的起始地址，它通常被设置为空指针NULL，这告诉内核自动选择起始地址，该函数的返回值即为fd映射到内存区的起始地址。 len：映射到进程地址空间的字节数，它从被映射文件开头的第offset个字节处开始，offset通常被设置为0。如下图是内存映射文件的一个例子： prot：内存映射区的保护由该参数来设定，通常由以下几个值组合而成： PROT_READ：数据可读； ROT_WRITE：数据可写； ROT_EXEC：数据可执行； PROT_NONE：数据不可访问； flags：设置内存映射区的类型标志，POSIX标志定义了以下三个标志： MAP_SHARED：该标志表示，调用进程对被映射内存区的数据所做的修改对于共享该内存区的所有进程都可见，而且确实改变其底层的支撑对象（一个文件对象或是一个共享内存区对象）。 AP_PRIVATE：调用进程对被映射内存区的数据所做的修改只对该进程可见，而不改变其底层支撑对象。 AP_FIXED：该标志表示准确的解释start参数，一般不建议使用该标志，对于可移植的代码，应该把start参数置为NULL，且不指定MAP_FIXED标志。 上面三个标志是在POSIX.1-2001标准中定义的，其中MAP_SHARED和MAP_PRIVATE必须选择一个。在Linux中也定义了一些非标准的标志，例如MAP_ANONYMOUS（MAP_ANON），MAP_LOCKED等，具体参考Linux手册。 fd：有效的文件描述符。如果设定了MAP_ANONYMOUS（MAP_ANON）标志，在Linux下面会忽略fd参数，而有的系统实现如BSD需要置fd为-1； offset：相对文件的起始偏移。 mmap成功后，可以关闭fd，一般也是这么做的，这对该内存映射没有任何影响。从进程的地址空间中删除一个映射关系，需要用到下面的函数：123#include &lt;sys/mman.h&gt;int munmap(void *start, size_t len); //成功返回0，出错返回-1 start：被映射到的进程地址空间的内存区的起始地址，即mmap返回的地址。len：映射区的大小。 对于一个MAP_SHARED的内存映射区，内核的虚拟内存算法会保持内存映射文件和内存映射区的同步，也就是说，对于内存映射文件所对应内存映射区的修改，内核会在稍后的某个时刻更新该内存映射文件。如果我们希望硬盘上的文件内容和内存映射区中的内容实时一致，那么我们就可以调用msync开执行这种同步：123#include &lt;sys/mman.h&gt;int msync(void *start, size_t len, int flags); //成功返回0，出错返回-1 start：被映射到的进程地址空间的内存区的起始地址，即mmap返回的地址。len：映射区的大小。flags：同步标志，有一下三个标志： MS_ASYNC：异步写，一旦写操作由内核排入队列，就立刻返回； MS_SYNC：同步写，要等到写操作完成后才返回。 MS_INVALIDATE：使该文件的其他内存映射的副本全部失效。 mmap内存映射区的大小Linux下的内存是采用页式管理机制。通过mmap进行内存映射，内核生成的映射区的大小都是以页面大小PAGESIZE为单位，即为PAGESIZE的整数倍。如果mmap映射的长度不是页面大小的整数倍，那么多余空间也会被闲置浪费。 下面可以查看Linux的页面大小12345678#include &lt;iostream&gt;#include &lt;unistd.h&gt; int main()&#123; std::cout&lt;&lt;&quot;page size:&quot;&lt;&lt;sysconf(_SC_PAGE_SIZE)&lt;&lt;std::endl; return 0;&#125; 输出结果是：1page size:4096 那么下面对映射文件的大小和映射长度的不同情况进行讨论。 (1)映射文件的大小和映射长度相同123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cerrno&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main(int argc, char **argv)&#123; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; if (ftruncate(fd, 5000) &lt; 0) &#123; cout&lt;&lt;&quot;change file size failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; close(fd); return -1; &#125; char *memPtr; memPtr = (char *)mmap(NULL, 5000, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; cout&lt;&lt;&quot;[0]:&quot;&lt;&lt;(int)memPtr[0]&lt;&lt;endl; cout&lt;&lt;&quot;[4999]:&quot;&lt;&lt;(int)memPtr[4999]&lt;&lt;endl; cout&lt;&lt;&quot;[5000]:&quot;&lt;&lt;(int)memPtr[5000]&lt;&lt;endl; cout&lt;&lt;&quot;[8191]:&quot;&lt;&lt;(int)memPtr[8191]&lt;&lt;endl; cout&lt;&lt;&quot;[8192]:&quot;&lt;&lt;(int)memPtr[8192]&lt;&lt;endl; cout&lt;&lt;&quot;[4096 * 3 - 1]:&quot;&lt;&lt;(int)memPtr[4096 * 3 - 1]&lt;&lt;endl; cout&lt;&lt;&quot;[4096 * 3]:&quot;&lt;&lt;(int)memPtr[4096 * 3]&lt;&lt;endl; return 0;&#125; 执行结果如下：1234567[0]:0[4999]:0[5000]:0[8191]:0[8192]:91[4096 * 3 - 1]:0Segmentation fault 用下图来分析执行结果： 由执行结果可以看到，能够完整的访问到前三页，在访问第四页的时候会产生SIGSEGV信号，发生Segmentation fault段越界访问错误。按照《UNIX 网络编程 卷2：进程间通信》中P257的讲解，内核会为该内存映射两个页面，访问前两个页面不会有问题，但访问第三个页面会产生SIGSEGV错误信号。这个差异具体应该是底层实现有关，留待以后研究。 (2)映射文件的大小小于映射长度 在上面代码的基础上，修改mmap内存映射还是部分的第二个参数，如下：1memPtr = (char *)mmap(NULL, 4096 * 3, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); 执行结果如下：12345[0]:0[4999]:0[5000]:0[8191]:0Bus error 再修改访问代码，访问偏移4096*3以后的内存映射去，结果的情况是123[4096 * 3]:91[4096 * 4 - 1]:0Segmentation fault // memPtr[4096*4] 用下图来分析执行结果： 该执行结果和之前的映射文件大小和映射长度相同的情况有比较大的区别，在访问内存映射区内部但超出底层支撑对象的大小的区域部分会产生SIGBUS错误信息，产生生BUS error错误，但访问第四页不会出问题，访问第四页以后的内存区就会产生 SIGSEGV错误信息。按照《UNIX 网络编程 卷2：进程间通信》中P258的讲解，访问第三个页面以后的内存会产生SIGSEGV错误信号。这个差异具体应该是底层实现有关，留待以后研究。 mmap实现进程间通信下面将介绍mmap本身提供的进程间通信的两种方式，分别用于无亲缘和亲缘进程间的通信。 （1）通过匿名内存映射提供亲缘进程间的通信 我们可以通过在父进程fork之前指定MAP_SHARED调用mmap，通过映射一个文件来实现父子进程间的通信，POSIX保证了父进程的内存映射关系保留到子进程中，父子进程对内存映射区的修改双方都可以看到。 在Linux 2.4以后，mmap提供匿名内存映射机制，即将mmap的flags参数指定为：MAP_SHARED | MAP_ANON。这样就彻底避免了内存映射文件的创建和打开，简化了对文件的操作。匿名内存映射机制的目的就是为了提供一个穿越父子进程间的内存映射区，很方便的提供了亲缘进程间的通信，下面是测试代码：123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cerrno&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; int main(int argc, char **argv)&#123; int *memPtr; memPtr = (int *) mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANON, 0, 0); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; *memPtr = 0; if (fork() == 0) &#123; *memPtr = 1; cout&lt;&lt;&quot;child:set memory &quot;&lt;&lt;*memPtr&lt;&lt;endl; exit(0); &#125; sleep(1); cout&lt;&lt;&quot;parent:memory value &quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; 执行结果如下：12child:set memory 1parent:memory value 1 （2）通过内存映射文件提供无亲缘进程间的通信 通过在不同进程间对同一内存映射文件进行映射，来进行无亲缘进程间的通信，如下测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//process 1#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main()&#123; int *memPtr; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; ftruncate(fd, sizeof(int)); memPtr = (int *)mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; *memPtr = 111; cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; send:&quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; //process 2#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main()&#123; int *memPtr; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; memPtr = (int *)mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; receive:&quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; 执行结果如下：1234# ./send process:12711 send:111# ./recv process:12712 receive:111 上面的代码都没进行同步操作，在实际的使用过程要考虑到进程间的同步，通常会用信号量来进行共享内存的同步。 基于mmap的POSIX共享内存上面介绍了通过内存映射文件进行进程间的通信的方式，现在要介绍的是通过POSIX共享内存区对象进行进程间的通信。POSIX共享内存使用方法有以下两个步骤： 通过shm_open创建或打开一个POSIX共享内存对象；然后调用mmap将它映射到当前进程的地址空间；和通过内存映射文件进行通信的使用上差别在于mmap描述符参数获取方式不一样：通过open或shm_open。如下图所示： POSIX共享内存区对象的特殊操作函数就只有创建（打开）和删除两个函数，其他对共享内存区对象的操作都是通过已有的函数进行的。12345#include &lt;sys/mman.h&gt;int shm_open(const char *name, int oflag, mode_t mode); //成功返回非负的描述符，失败返回-1int shm_unlink(const char *name); //成功返回0，失败返回-1 shm_open用于创建一个新的共享内存区对象或打开一个已经存在的共享内存区对象。 name：POSIX IPC的名字，前面关于POSIX进程间通信都已讲过关于POSIX IPC的规则，这里不再赘述。 oflag：操作标志，包含：O_RDONLY，O_RDWR，O_CREAT，O_EXCL，O_TRUNC。其中O_RDONLY和O_RDWR标志必须且仅能存在一项。 mode：用于设置创建的共享内存区对象的权限属性。和open以及其他POSIX IPC的xxx_open函数不同的是，该参数必须一直存在，如果oflag参数中没有O_CREAT标志，该位可以置0； shm_unlink用于删除一个共享内存区对象，跟其他文件的unlink以及其他POSIX IPC的删除操作一样，对象的析构会到对该对象的所有引用全部关闭才会发生。 POSIX共享内存和POSIX消息队列，有名信号量一样都是具有随内核持续性的特点。 下面是通过POSIX共享内存进行通信的测试代码，代码中通过POSIX信号量来进行进程间的同步操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//process 1#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;semaphore.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define SHM_NAME &quot;/memmap&quot;#define SHM_NAME_SEM &quot;/memmap_sem&quot; char sharedMem[10]; int main()&#123; int fd; sem_t *sem; fd = shm_open(SHM_NAME, O_RDWR | O_CREAT, 0666); sem = sem_open(SHM_NAME_SEM, O_CREAT, 0666, 0); if (fd &lt; 0 || sem == SEM_FAILED) &#123; cout&lt;&lt;&quot;shm_open or sem_open failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; ftruncate(fd, sizeof(sharedMem)); char *memPtr; memPtr = (char *)mmap(NULL, sizeof(sharedMem), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); char msg[] = &quot;yuki...&quot;; memmove(memPtr, msg, sizeof(msg)); cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; send:&quot;&lt;&lt;memPtr&lt;&lt;endl; sem_post(sem); sem_close(sem); return 0;&#125; //process 2#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;semaphore.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define SHM_NAME &quot;/memmap&quot;#define SHM_NAME_SEM &quot;/memmap_sem&quot; int main()&#123; int fd; sem_t *sem; fd = shm_open(SHM_NAME, O_RDWR, 0); sem = sem_open(SHM_NAME_SEM, 0); if (fd &lt; 0 || sem == SEM_FAILED) &#123; cout&lt;&lt;&quot;shm_open or sem_open failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; struct stat fileStat; fstat(fd, &amp;fileStat); char *memPtr; memPtr = (char *)mmap(NULL, fileStat.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); sem_wait(sem); cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; recv:&quot;&lt;&lt;memPtr&lt;&lt;endl; sem_close(sem); return 0;&#125; 程序的执行结果如下：1234# ./send process:13719 send:yuki...# ./recv process:13720 recv:yuki... 在Linux 2.6.18中，对于POSIX信号量和共享内存的名字会在/dev/shm下建立对应的路径名，例如上面的测试代码，会生成如下的路径名：1234# ll /dev/shm/total 8-rw-r--r-- 1 root root 10 Aug 13 00:28 memmap-rw-r--r-- 1 root root 32 Aug 13 00:28 sem.memmap_sem]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux线程的信号量同步]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[信号量和互斥锁(mutex)的区别：互斥锁只允许一个线程进入临界区，而信号量允许多个线程同时进入临界区。 不多做解释，要使用信号量同步，需要包含头文件semaphore.h。 主要用到的函数： int sem_init(sem_t *sem, int pshared, unsigned int value);，其中sem是要初始化的信号量，pshared表示此信号量是在进程间共享还是线程间共享，value是信号量的初始值。 int sem_destroy(sem_t *sem);,其中sem是要销毁的信号量。只有用sem_init初始化的信号量才能用sem_destroy销毁。 int sem_wait(sem_t *sem);：等待信号量，如果信号量的值大于0,将信号量的值减1,立即返回。如果信号量的值为0,则线程阻塞。相当于P操作。成功返回0,失败返回-1。 int sem_post(sem_t *sem);：释放信号量，让信号量的值加1。相当于V操作。 下列的代码演示了如何用信号量同步，模拟一个窗口服务系统。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* @purpose: 基于信号量的多线程同步，操作系统原理中的P,V操作 * @author: jollywing@foxmail.com * @create: 2015-03-20 Fri * */#include &lt;pthread.h&gt;#include &lt;semaphore.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/* @Scene: 某行业营业厅同时只能服务两个顾客。 * 有多个顾客到来，每个顾客如果发现服务窗口已满，就等待， * 如果有可用的服务窗口，就接受服务。 *//* 将信号量定义为全局变量，方便多个线程共享 */sem_t sem;/* 每个线程要运行的例程 */void * get_service(void *thread_id)&#123; /* 注意：立即保存thread_id的值，因为thread_id是对主线程中循环变量i的引用，它可能马上被修改 */ int customer_id = *((int *)thread_id); if(sem_wait(&amp;sem) == 0) &#123; usleep(100); /* service time: 100ms */ printf(&quot;customer %d receive service ...\n&quot;, customer_id); sem_post(&amp;sem); &#125;&#125;#define CUSTOMER_NUM 10int main(int argc, char *argv[])&#123; /* 初始化信号量，初始值为2，表示有两个顾客可以同时接收服务 */ /* @prototype: int sem_init(sem_t *sem, int pshared, unsigned int value); */ /* pshared: if pshared == 0, the semaphore is shared among threads of a process * otherwise the semaphore is shared between processes. */ sem_init(&amp;sem, 0, 2); /* 为每个顾客定义一个线程id, pthread_t 其实是unsigned long int */ pthread_t customers[CUSTOMER_NUM]; int i, ret; /* 为每个顾客生成一个线程 */ for(i = 0; i &lt; CUSTOMER_NUM; i++)&#123; int customer_id = i; ret = pthread_create(&amp;customers[i], NULL, get_service, &amp;customer_id); if(ret != 0)&#123; perror(&quot;pthread_create&quot;); exit(1); &#125; else &#123; printf(&quot;Customer %d arrived.\n&quot;, i); &#125; usleep(10); &#125; /* 等待所有顾客的线程结束 */ /* 注意：这地方不能再用i做循环变量，因为可能线程中正在访问i的值 */ int j; for(j = 0; j &lt; CUSTOMER_NUM; j++) &#123; pthread_join(customers[j], NULL); &#125; /* Only a semaphore that has been initialized by sem_init(3) * should be destroyed using sem_destroy().*/ sem_destroy(&amp;sem); return 0;&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基数排序]]></title>
    <url>%2F2019%2F05%2F18%2F%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/lemon_tree12138/article/details/51695211 数据背景在基数排序中，我们不能再只用一位数的序列来列举示例了。一位数的序列对基数排序来说就是一个计数排序。这里我们列举无序序列 T = [ 2314, 5428, 373, 2222, 17 ] 排序原理上面说到基数排序不需要进行元素的比较与交换。如果你有一些算法的功底，或者丰富的项目经验，我想你可能已经想到了这可能类似于一些“打表”或是哈希的做法。而计数排序则是打表或是哈希思想最简单的实现。 计数排序计数排序的核心思想是，构建一个足够大的数组 hashArray[]，数组大小需要保证能够把所有元素都包含在这个数组上 。假设我们有无序序列 T = [ 2314, 5428, 373, 2222, 17 ]首先初始化数组 hashArray[] 为一个全零数组。当然，在 Java 里，这一步就不需要了，因为默认就是零了。在对序列 T 进行排序时，只要依次读取序列 T 中的元素，并修改数组 hashArray[] 中把元素值对应位置上的值即可。这一句有一些绕口。打个比方，我们要把 T[0] 映射到 hashArray[] 中，就是 hashArray[T[0]] = 1. 也就是 hashArray[2314] = 1. 如果序列 T 中有两个相同元素，那么在 hashArray 的相应位置上的值就是 2。下图是计数排序的原理图：（假设有无序序列：[ 5, 8, 9, 1, 4, 2, 9, 3, 7, 1, 8, 6, 2, 3, 4, 0, 8 ]） 基数排序原理图上面的计数排序只是一个引导，好让你可以循序渐进地了解基数排序。 上面这幅图，或许你已经在其他的博客里见到过。这是一个很好的引导跟说明。在基数排序里，我们需要一个很大的二维数组，二维数组的大小是 （10 * n）。10 代表的是我们每个元素的每一位都有 10 种可能，也就是 10 进制数。在上图中，我们是以每个数的个位来代表这个数，于是，5428 就被填充到了第 8 个桶中了。下次再进行填充的时候，就是以十位进行填充，比如 5428 在此时，就会选择以 2 来代表它。 算法优化在算法的原理中，我们是以一张二维数组的表来存储这些无序的元素。使用二维数组有一个很明显的不足就是二维数组太过稀疏。数组的利用率为 10%。在寻求优化的路上，我们想到一种可以压缩空间的方法，且时间复杂度并没有偏离得太厉害。那就是设计了两个辅助数组，一个是 count[]，一个是 bucket[]。count 用于记录在某个桶中的最后一个元素的下标，然后再把原数组中的元素计算一下它应该属于哪个“桶”，并修改相应位置的 count 值。直到最大数的最高位也被添加到桶中，或者说，当所有的元素都被被在第 0 个桶中，基数排序就结束了。优化后的原理图如下： 算法实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import org.algorithm.array.sort.interf.Sortable;/** * &lt;p&gt; * 基数排序/桶排序 * &lt;/p&gt; * 2016年1月19日 * * @author &lt;a href=&quot;http://weibo.com/u/5131020927&quot;&gt;Q-WHai&lt;/a&gt; * @see &lt;a href=&quot;http://blog.csdn.net/lemon_tree12138&quot;&gt;http://blog.csdn.net/lemon_tree12138&lt;/a&gt; * @version 0.1.1 */public class RadixSort implements Sortable &#123; @Override public int[] sort(int[] array) &#123; if (array == null) &#123; return null; &#125; int maxLength = maxLength(array); return sortCore(array, 0, maxLength); &#125; private int[] sortCore(int[] array, int digit, int maxLength) &#123; if (digit &gt;= maxLength) &#123; return array; &#125; final int radix = 10; // 基数 int arrayLength = array.length; int[] count = new int[radix]; int[] bucket = new int[arrayLength]; // 统计将数组中的数字分配到桶中后，各个桶中的数字个数 for (int i = 0; i &lt; arrayLength; i++) &#123; count[getDigit(array[i], digit)]++; &#125; // 将各个桶中的数字个数，转化成各个桶中最后一个数字的下标索引 for (int i = 1; i &lt; radix; i++) &#123; count[i] = count[i] + count[i - 1]; &#125; // 将原数组中的数字分配给辅助数组 bucket for (int i = arrayLength - 1; i &gt;= 0; i--) &#123; int number = array[i]; int d = getDigit(number, digit); bucket[count[d] - 1] = number; count[d]--; &#125; return sortCore(bucket, digit + 1, maxLength); &#125; /* * 一个数组中最大数字的位数 * * @param array * @return */ private int maxLength(int[] array) &#123; int maxLength = 0; int arrayLength = array.length; for (int i = 0; i &lt; arrayLength; i++) &#123; int currentLength = length(array[i]); if (maxLength &lt; currentLength) &#123; maxLength = currentLength; &#125; &#125; return maxLength; &#125; /* * 计算一个数字共有多少位 * * @param number * @return */ private int length(int number) &#123; return String.valueOf(number).length(); &#125; /* * 获取 x 这个数的 d 位数上的数字 * 比如获取 123 的 0 位数,结果返回 3 * * @param x * @param d * @return */ private int getDigit(int x, int d) &#123; int a[] = &#123; 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000 &#125;; return ((x / a[d]) % 10); &#125;&#125; 基数排序过程图如果我们的无序是 T = [ 2314, 5428, 373, 2222, 17 ]，那么其排序的过程就如下两幅所示。基数排序过程图-1基数排序过程图-2]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的三种实现方式]]></title>
    <url>%2F2019%2F05%2F18%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[分布式锁的三种实现方式 zookeeper实现原理：基于zookeeper瞬时有序节点实现的分布式锁，其主要逻辑如下（该图来自于IBM网站）。大致思想即为：每个客户端对某个功能加锁时，在zookeeper上的与该功能对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 优点锁安全性高，zk可持久化 缺点性能开销比较高。因为其需要动态产生、销毁瞬时节点来实现锁功能。 实现可以直接采用zookeeper第三方库curator即可方便地实现分布式锁。以下为基于curator实现的zk分布式锁核心代码：123456789101112131415161718192021@Override public boolean tryLock(LockInfo info) &#123; InterProcessMutex mutex = getMutex(info); int tryTimes = info.getTryTimes(); long tryInterval = info.getTryInterval(); boolean flag = true;// 代表是否需要重试 while (flag &amp;&amp; --tryTimes &gt;= 0) &#123; try &#123; if (mutex.acquire(info.getWaitLockTime(), TimeUnit.MILLISECONDS)) &#123; LOGGER.info(LogConstant.DST_LOCK + &quot;acquire lock successfully!&quot;); flag = false; break; &#125; &#125; catch (Exception e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;acquire lock error!&quot;, e); &#125; finally &#123; checkAndRetry(flag, tryInterval, tryTimes); &#125; &#125; return !flag;// 最后还需要重试，说明没拿到锁 &#125; 1234567891011121314151617181920@Override public boolean releaseLock(LockInfo info) &#123; InterProcessMutex mutex = getMutex(info); int tryTimes = info.getTryTimes(); long tryInterval = info.getTryInterval(); boolean flag = true;// 代表是否需要重试 while (flag &amp;&amp; --tryTimes &gt;= 0) &#123; try &#123; mutex.release(); LOGGER.info(LogConstant.DST_LOCK + &quot;release lock successfully!&quot;); flag = false; break; &#125; catch (Exception e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;release lock error!&quot;, e); &#125; finally &#123; checkAndRetry(flag, tryInterval, tryTimes); &#125; &#125; return !flag;// 最后还需要重试，说明没拿到锁 &#125; 1234567891011121314151617181920212223242526/** * 获取锁。此处需要加同步，concurrentHashmap无法避免此处的同步问题 * @param info 锁信息 * @return 锁实例 */ private synchronized InterProcessMutex getMutex(LockInfo info) &#123; InterProcessReadWriteLock lock = null; if (locksCache.get(info.getLock()) != null) &#123; lock = locksCache.get(info.getLock()); &#125; else &#123; lock = new InterProcessReadWriteLock(client, BASE_DIR + info.getLock()); locksCache.put(info.getLock(), lock); &#125; InterProcessMutex mutex = null; switch (info.getIsolate()) &#123; case READ: mutex = lock.readLock(); break; case WRITE: mutex = lock.writeLock(); break; default: throw new IllegalArgumentException(); &#125; return mutex; &#125; 12345678910111213141516/** * 判断是否需要重试 * @param flag 是否需要重试标志 * @param tryInterval 重试间隔 * @param tryTimes 重试次数 */ private void checkAndRetry(boolean flag, long tryInterval, int tryTimes) &#123; try &#123; if (flag) &#123; Thread.sleep(tryInterval); LOGGER.info(LogConstant.DST_LOCK + &quot;retry getting lock! now retry time left: &quot; + tryTimes); &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;retry interval thread interruptted!&quot;, e); &#125; &#125; memcached分布式锁实现原理：memcached带有add函数，利用add函数的特性即可实现分布式锁。add和set的区别在于：如果多线程并发set，则每个set都会成功，但最后存储的值以最后的set的线程为准。而add的话则相反，add会添加第一个到达的值，并返回true，后续的添加则都会返回false。利用该点即可很轻松地实现分布式锁。 优点并发高效。 缺点 memcached采用列入LRU置换策略，所以如果内存不够，可能导致缓存中的锁信息丢失。 memcached无法持久化，一旦重启，将导致信息丢失。 redis分布式锁redis分布式锁即可以结合zk分布式锁锁高度安全和memcached并发场景下效率很好的优点，可以利用jedis客户端实现。参考http://blog.csdn.net/java2000_wl/article/details/8740911]]></content>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十三）：内存管理之进程地址空间]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 进程地址空间由进程可寻址的虚拟内存组成，Linux 的虚拟地址空间为0~4G字节（注：本节讲述均以32为为例）。Linux内核将这 4G 字节的空间分为两部分。将最高的 1G 字节(从虚拟地址0xC0000000到0xFFFFFFFF)，供内核使用，称为“内核空间”。而将较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)，供各个进程使用，称为“用户空间” 。因为每个进程可以通过系统调用进入内核。因此，Linux 内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4G 字节的虚拟空间。 尽管一个进程可以寻址4G的虚拟内存，但就不代表它就有权限访问所有的地址空间，虚拟内存空间必须映射到某个物理存储空间(内存或磁盘空间)，才真正地可以被使用。进程只能访问合法的地址空间，如果一个进程访问了不合法的地址空间，内核就会终止该进程，并返回“段错误”。虚拟内存的合法地址空间在哪而呢？我们先来看看进程虚拟地址空间的划分： 其中堆栈安排在虚拟地址空间顶部，数据段和代码段分布在虚拟地址空间底部，空洞部分就是进程运行时可以动态分布的空间，包括映射内核地址空间内容、动态申请地址空间、共享库的代码或数据等。在虚拟地址空间中，只有那些映射到物理存储空间的地址才是合法的地址空间。每一片合法的地址空间片段都对应一个独立的虚拟内存区域（VMA，virtual memory areas ），而进程的进程地址空间就是由这些内存区域组成。Linux 采用了复杂的数据结构来跟踪进程的虚拟地址，进程地址空间使用内存描述符结构体来表示，内存描述符由mm_struct结构体表示，该结构体表示在&lt;include/linux/mm_types.h&gt;文件中：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889struct mm_struct &#123; struct vm_area_struct * mmap; /* list of VMAs */ struct rb_root mm_rb; struct vm_area_struct * mmap_cache; /* last find_vma result */ unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); void (*unmap_area) (struct mm_struct *mm, unsigned long addr); unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ unsigned long cached_hole_size; /* if non-zero, the largest hole below free_area_cache */ unsigned long free_area_cache; /* first hole of size cached_hole_size or larger */ pgd_t * pgd; atomic_t mm_users; /* How many users with user space? */ atomic_t mm_count; /* How many references to &quot;struct mm_struct&quot; (users count as 1) */ int map_count; /* number of VMAs */ struct rw_semaphore mmap_sem; spinlock_t page_table_lock; /* Protects page tables and some counters */ struct list_head mmlist; /* List of maybe swapped mm&apos;s. These are globally strung * together off init_mm.mmlist, and are protected * by mmlist_lock */ /* Special counters, in some configurations protected by the * page_table_lock, in other configurations by being atomic. */ mm_counter_t _file_rss; mm_counter_t _anon_rss; unsigned long hiwater_rss; /* High-watermark of RSS usage */ unsigned long hiwater_vm; /* High-water virtual memory usage */ unsigned long total_vm, locked_vm, shared_vm, exec_vm; unsigned long stack_vm, reserved_vm, def_flags, nr_ptes; unsigned long start_code, end_code, start_data, end_data; unsigned long start_brk, brk, start_stack; unsigned long arg_start, arg_end, env_start, env_end; unsigned long saved_auxv[AT_VECTOR_SIZE]; /* for /proc/PID/auxv */ struct linux_binfmt *binfmt; cpumask_t cpu_vm_mask; /* Architecture-specific MM context */ mm_context_t context; /* Swap token stuff */ /* * Last value of global fault stamp as seen by this process. * In other words, this value gives an indication of how long * it has been since this task got the token. * Look at mm/thrash.c */ unsigned int faultstamp; unsigned int token_priority; unsigned int last_interval; unsigned long flags; /* Must use atomic bitops to access the bits */ struct core_state *core_state; /* coredumping support */#ifdef CONFIG_AIO spinlock_t ioctx_lock; struct hlist_head ioctx_list;#endif#ifdef CONFIG_MM_OWNER /* * &quot;owner&quot; points to a task that is regarded as the canonical * user/owner of this mm. All of the following must be true in * order for it to be changed: * * current == mm-&gt;owner * current-&gt;mm != mm * new_owner-&gt;mm == mm * new_owner-&gt;alloc_lock is held */ struct task_struct *owner;#endif #ifdef CONFIG_PROC_FS /* store ref to file /proc/&lt;pid&gt;/exe symlink points to */ struct file *exe_file; unsigned long num_exe_file_vmas;#endif#ifdef CONFIG_MMU_NOTIFIER struct mmu_notifier_mm *mmu_notifier_mm;#endif&#125;; 该结构体中第一行成员mmap就是内存区域，用结构体struct vm_area_struct来表示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* * This struct defines a memory VMM memory area. There is one of these * per VM-area/task. A VM area is any part of the process virtual memory * space that has a special rule for the page-fault handlers (ie a shared * library, the executable area etc). */struct vm_area_struct &#123; struct mm_struct * vm_mm; /* The address space we belong to. */ unsigned long vm_start; /* Our start address within vm_mm. */ unsigned long vm_end; /* The first byte after our end address within vm_mm. */ /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next; pgprot_t vm_page_prot; /* Access permissions of this VMA. */ unsigned long vm_flags; /* Flags, see mm.h. */ struct rb_node vm_rb; /* * For areas with an address space and backing store, * linkage into the address_space-&gt;i_mmap prio tree, or * linkage to the list of like vmas hanging off its node, or * linkage of vma in the address_space-&gt;i_mmap_nonlinear list. */ union &#123; struct &#123; struct list_head list; void *parent; /* aligns with prio_tree_node parent */ struct vm_area_struct *head; &#125; vm_set; struct raw_prio_tree_node prio_tree_node; &#125; shared; /* * A file&apos;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma * list, after a COW of one of the file pages. A MAP_SHARED vma * can only be in the i_mmap tree. An anonymous MAP_PRIVATE, stack * or brk vma (with NULL file) can only be in an anon_vma list. */ struct list_head anon_vma_node; /* Serialized by anon_vma-&gt;lock */ struct anon_vma *anon_vma; /* Serialized by page_table_lock */ /* Function pointers to deal with this struct. */ const struct vm_operations_struct *vm_ops; /* Information about our backing store: */ unsigned long vm_pgoff; /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */ struct file * vm_file; /* File we map to (can be NULL). */ void * vm_private_data; /* was vm_pte (shared mem) */ unsigned long vm_truncate_count;/* truncate_count or restart_addr */ #ifndef CONFIG_MMU struct vm_region *vm_region; /* NOMMU mapping region */#endif#ifdef CONFIG_NUMA struct mempolicy *vm_policy; /* NUMA policy for the VMA */#endif&#125;; vm_area_struct结构体描述了进程地址空间内连续区间上的一个独立内存范围，每一个内存区域都使用该结构体表示，每一个结构体以双向链表的形式连接起来。除链表结构外,Linux 还利用红黑树mm_rb来组织 vm_area_struct。通过这种树结构，Linux 可以快速定位某个虚拟内存地址。 该结构体中成员vm_start和vm_end表示内存区间的首地址和尾地址，两个值相减就是内存区间的长度。 成员vm_mm则指向其属于的进程地址空间结构体。所以两个不同的进程将同一个文件映射到自己的地址空间中，他们分别都会有一个vm_area_struct结构体来标识自己的内存区域。两个共享地址空间的线程则只有一个vm_area_struct结构体来标识，因为他们使用的是同一个进程地址空间。 vm_flags标识内存区域所包含的页面的行为和信息，反映内核处理页面所需要遵守的行为准则。 可以使用cat /proc/PID/maps命令和pmap命令查看给定进程空间和其中所含的内存区域。以笔者系统上进程号为17192的进程为例。12345678910111213141516# cat /proc/17192/maps //显示该进程地址空间中全部内存区域001e3000-00201000 r-xp 00000000 fd:00 789547 /lib/ld-2.12.so00201000-00202000 r--p 0001d000 fd:00 789547 /lib/ld-2.12.so00202000-00203000 rw-p 0001e000 fd:00 789547 /lib/ld-2.12.so00209000-00399000 r-xp 00000000 fd:00 789548 /lib/libc-2.12.so00399000-0039a000 ---p 00190000 fd:00 789548 /lib/libc-2.12.so0039a000-0039c000 r--p 00190000 fd:00 789548 /lib/libc-2.12.so0039c000-0039d000 rw-p 00192000 fd:00 789548 /lib/libc-2.12.so0039d000-003a0000 rw-p 00000000 00:00 008048000-08049000 r-xp 00000000 fd:00 1191771 /home/allen/Myprojects/blog/conn_user_kernel/test/a.out08049000-0804a000 rw-p 00000000 fd:00 1191771 /home/allen/Myprojects/blog/conn_user_kernel/test/a.outb7755000-b7756000 rw-p 00000000 00:00 0b776d000-b776e000 rw-p 00000000 00:00 0b776e000-b776f000 r-xp 00000000 00:00 0 [vdso]bfc9f000-bfcb4000 rw-p 00000000 00:00 0 [stack]# 1234567891011121314151617# pmap 1719217192: ./a.out001e3000 120K r-x-- /lib/ld-2.12.so //本行和下面两行为动态链接程序ld.so的代码段、数据段、bss段00201000 4K r---- /lib/ld-2.12.so00202000 4K rw--- /lib/ld-2.12.so00209000 1600K r-x-- /lib/libc-2.12.so //本行和下面为C库中libc.so的代码段、数据段和bss段00399000 4K ----- /lib/libc-2.12.so0039a000 8K r---- /lib/libc-2.12.so0039c000 4K rw--- /lib/libc-2.12.so0039d000 12K rw--- [ anon ]08048000 4K r-x-- /home/allen/Myprojects/blog/conn_user_kernel/test/a.out //可执行对象的代码段08049000 4K rw--- /home/allen/Myprojects/blog/conn_user_kernel/test/a.out //可执行对象的数据段b7755000 4K rw--- [ anon ]b776d000 4K rw--- [ anon ]b776e000 4K r-x-- [ anon ]bfc9f000 84K rw--- [ stack ] //堆栈段 total 1860K 结构体中vm_ops域指定内存区域相关操作函数表，内核使用表中方法操作VMA，操作函数表由vm_operations_struct结构体表示，定义在&lt;include/linux/mm.h&gt;文件中：1234567891011121314151617181920212223/* * These are the virtual MM functions - opening of an area, closing and * unmapping it (needed to keep files on disk up-to-date etc), pointer * to the functions called when a no-page or a wp-page exception occurs. */struct vm_operations_struct &#123; void (*open)(struct vm_area_struct * area); //指定内存区域被加载到一个地址空间时函数被调用 void (*close)(struct vm_area_struct * area); //指定内存区域从地址空间删除时函数被调用 int (*fault)(struct vm_area_struct *vma, struct vm_fault *vmf); //没有出现在物理内存中的页面被访问时，页面故障处理调用该函数 /* notification that a previously read-only page is about to become * writable, if an error is returned it will cause a SIGBUS */ int (*page_mkwrite)(struct vm_area_struct *vma, struct vm_fault *vmf); /* called by access_process_vm when get_user_pages() fails, typically * for use by special VMAs that can switch between memory and hardware */ int (*access)(struct vm_area_struct *vma, unsigned long addr, void *buf, int len, int write);#ifdef CONFIG_NUMA ......#endif&#125;; 在内核中，给定一个属于某个进程的虚拟地址，要求找到其所属的区间以及vma_area_struct结构，这通过find_vma()来实现，这种搜索通过红-黑树进行。该函数定义于&lt;mm/mmap.c&gt;中：123456789101112131415161718192021222324252627282930313233343536/* Look up the first VMA which satisfies addr &lt; vm_end, NULL if none. */struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)&#123; struct vm_area_struct *vma = NULL; if (mm) &#123; /* 首先检查最近使用的内存区域，看缓存的VMA是否包含所需地址 */ /* (命中录接近35%.) */ vma = mm-&gt;mmap_cache; //如果缓存中不包含未包含希望的VMA，该函数搜索红-黑树。 if (!(vma &amp;&amp; vma-&gt;vm_end &gt; addr &amp;&amp; vma-&gt;vm_start &lt;= addr)) &#123; struct rb_node * rb_node; rb_node = mm-&gt;mm_rb.rb_node; vma = NULL; while (rb_node) &#123; struct vm_area_struct * vma_tmp; vma_tmp = rb_entry(rb_node, struct vm_area_struct, vm_rb); if (vma_tmp-&gt;vm_end &gt; addr) &#123; vma = vma_tmp; if (vma_tmp-&gt;vm_start &lt;= addr) break; rb_node = rb_node-&gt;rb_left; &#125; else rb_node = rb_node-&gt;rb_right; &#125; if (vma) mm-&gt;mmap_cache = vma; &#125; &#125; return vma;&#125; 当某个程序的映像开始执行时,可执行映像必须装入到进程的虚拟地址空间。如果该进程用到了任何一个共享库,则共享库也必须装入到进程的虚拟地址空间。由此可看出，Linux并不将映像装入到物理内存，相反，可执行文件只是被连接到进程的虚拟地址空间中。随着程序的运行，被引用的程序部分会由操作系统装入到物理内存，这种将映像链接到进程地址空间的方法被称为“内存映射”。 当可执行映像映射到进程的虚拟地址空间时，将产生一组 vm_area_struct 结构来描述虚拟内存区间的起始点和终止点，每个 vm_area_struct 结构代表可执行映像的一部分，可能是可执行代码，也可能是初始化的变量或未初始化的数据，这些都是在函数 do_mmap()中来实现的。随着 vm_area_struct 结构的生成，这些结构所描述的虚拟内存区间上的标准操作函数也由 Linux 初始化。123456789101112static inline unsigned long do_mmap(struct file *file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flag, unsigned long offset)&#123; unsigned long ret = -EINVAL; if ((offset + PAGE_ALIGN(len)) &lt; offset) goto out; if (!(offset &amp; ~PAGE_MASK)) ret = do_mmap_pgoff(file, addr, len, prot, flag, offset &gt;&gt; PAGE_SHIFT);out: return ret;&#125; 该函数会将一个新的地址区间加入到进程的地址空间中。定义于&lt;include/linux/mm.h&gt;。函数中参数的含义： file:表示要映射的文件。 offset\:文件内的偏移量，因为我们并不是一下子全部映射一个文件,可能只是映射文件的一部分,off 就表示那部分的起始位置。 len:要映射的文件部分的长度。 addr:虚拟空间中的一个地址,表示从这个地址开始查找一个空闲的虚拟区。 prot: 这个参数指定对这个虚拟区所包含页的存取权限。可能的标志有 PROT_READ、PROT_WRITE、PROT_EXEC 和 PROT_NONE。前 3 个标志与标志 VM_READ、VM_WRITE 及 VM_EXEC的意义一样。PROT_NONE 表示进程没有以上 3 个存取权限中的任意一个。 flag:这个参数指定虚拟区的其他标志。 该函数调用 do_mmap_pgoff()函数，该函数做内存映射的主要工作，该函数比较长，详细实现可查看&lt;mm/mmap.c&gt;文件。由于文件到虚存的映射仅仅是建立了一种映射关系，虚存页面到物理页面之间的映射还没有建立。当某个可执行映象映射到进程虚拟内存中并开始执行时，因为只有很少一部分虚拟内存区间装入到了物理内存，很可能会遇到所访问的数据不在物理内存。这时，处理器将向 Linux 报告一个页故障及其对应的故障原因，内核必须从磁盘映像或交换文件(此页被换出)中将其装入物理内存，这就是请页机制。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十二）：内存管理之slab分配器]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8Bslab%E5%88%86%E9%85%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 上一节最后说到对于小内存区的请求，如果采用伙伴系统来进行分配，则会在页内产生很多空闲空间无法使用，因此产生slab分配器来处理对小内存区（几十或几百字节）的请求。Linux中引入Slab的主要目的是为了减少对伙伴算法的调用次数。 内核经常反复使用某一内存区。例如，只要内核创建一个新的进程，就要为该进程相关的数据结构（task_struct、打开文件对象等）分配内存区。当进程结束时，收回这些内存区。因为进程的创建和撤销非常频繁，linux把那些频繁使用的页面保存在高速缓存中并重新使用。 slab分配器基于对象进行管理，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就分配一个空闲对象出去，而当要释放时，将其重新保存在slab分配器中，而不是直接返回给伙伴系统。对于频繁请求的对象，创建适当大小的专用对象来处理。对于不频繁的对象，用一系列几何分布大小的对象来处理（详见通用对象）。 slab分配模式把对象分组放进缓冲区，为缓冲区的组织和管理与硬件高速缓存的命中率密切相关，因此，Slab缓冲区并非由各个对象直接构成，而是由一连串的“大块（Slab）”构成，而每个大块中则包含了若干个同种类型的对象，这些对象或已被分配，或空闲。实际上，缓冲区就是主存中的一片区域，把这片区域划分为多个块，每块就是一个Slab，每个Slab由一个或多个页面组成，每个Slab中存放的就是对象。 slab相关数据结构： 缓冲区数据结构使用kmem_cache结构来表示。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374struct kmem_cache &#123;/* 1) per-cpu data, touched during every alloc/free */ struct array_cache *array[NR_CPUS];/* 2) Cache tunables. Protected by cache_chain_mutex */ unsigned int batchcount; unsigned int limit; unsigned int shared; unsigned int buffer_size; u32 reciprocal_buffer_size;/* 3) touched by every alloc &amp; free from the backend */ unsigned int flags; /* constant flags */ unsigned int num; /* # of objs per slab */ /* 4) cache_grow/shrink */ /* order of pgs per slab (2^n) */ unsigned int gfporder; /* force GFP flags, e.g. GFP_DMA */ gfp_t gfpflags; size_t colour; /* cache colouring range */ unsigned int colour_off; /* colour offset */ struct kmem_cache *slabp_cache; unsigned int slab_size; unsigned int dflags; /* dynamic flags */ /* constructor func */ void (*ctor)(void *obj); /* 5) cache creation/removal */ const char *name; struct list_head next; /* 6) statistics */#ifdef CONFIG_DEBUG_SLAB unsigned long num_active; unsigned long num_allocations; unsigned long high_mark; unsigned long grown; unsigned long reaped; unsigned long errors; unsigned long max_freeable; unsigned long node_allocs; unsigned long node_frees; unsigned long node_overflow; atomic_t allochit; atomic_t allocmiss; atomic_t freehit; atomic_t freemiss; /* * If debugging is enabled, then the allocator can add additional * fields and/or padding to every object. buffer_size contains the total * object size including these internal fields, the following two * variables contain the offset to the user object and its size. */ int obj_offset; int obj_size;#endif /* CONFIG_DEBUG_SLAB */ /* * We put nodelists[] at the end of kmem_cache, because we want to size * this array to nr_node_ids slots instead of MAX_NUMNODES * (see kmem_cache_init()) * We still use [MAX_NUMNODES] and not [1] or [0] because cache_cache * is statically defined, so we reserve the max number of nodes. */ struct kmem_list3 *nodelists[MAX_NUMNODES]; /* * Do not add fields after nodelists[] */&#125;; 其中struct kmem_list3结构体链接slab，共享高速缓存，其定义如下:12345678910111213141516/* * The slab lists for all objects. */struct kmem_list3 &#123; struct list_head slabs_partial; /* partial list first, better asm code */ struct list_head slabs_full; struct list_head slabs_free; unsigned long free_objects; unsigned int free_limit; unsigned int colour_next; /* Per-node cache coloring */ spinlock_t list_lock; struct array_cache *shared; /* shared per node */ struct array_cache **alien; /* on other nodes */ unsigned long next_reap; /* updated without locking */ int free_touched; /* updated without locking */&#125;; 该结构包含三个链表：slabs_partial、slabs_full、slabs_free，这些链表包含缓冲区所有slab，slab描述符struct slab用于描述每个slab：123456789101112131415/* * struct slab * * Manages the objs in a slab. Placed either at the beginning of mem allocated * for a slab, or allocated from an general cache. * Slabs are chained into three list: fully used, partial, fully free slabs. */struct slab &#123; struct list_head list; unsigned long colouroff; void *s_mem; /* including colour offset */ unsigned int inuse; /* num of objs active in slab */ kmem_bufctl_t free; unsigned short nodeid;&#125;; 一个新的缓冲区使用如下函数创建：1struct kmem_cache *kmem_cache_create (const char *name, size_t size, size_t align, unsigned long flags, void (*ctor)(void *)); 函数创建成功会返回一个指向所创建缓冲区的指针；撤销一个缓冲区调用如下函数：1void kmem_cache_destroy(struct kmem_cache *cachep)； 上面两个函数都不能在中断上下文中使用，因为它可能睡眠。在创建来缓冲区之后，可以通过下列函数获取对象：1234567891011121314151617/** * kmem_cache_alloc - Allocate an object * @cachep: The cache to allocate from. * @flags: See kmalloc(). * * Allocate an object from this cache. The flags are only relevant * if the cache has no available objects. */void *kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags)&#123; void *ret = __cache_alloc(cachep, flags, __builtin_return_address(0)); trace_kmem_cache_alloc(_RET_IP_, ret, obj_size(cachep), cachep-&gt;buffer_size, flags); return ret;&#125; 该函数从给点缓冲区cachep中返回一个指向对象的指针。如果缓冲区的所有slab中都没有空闲对象，那么slab层必须通过kmem_getpages()获取新的页，参数flags传递给_get_free_pages()。1static void *kmem_getpages(struct kmem_cache *cachep, gfp_t flags, int nodeid)； 释放对象使用如下函数：123456789101112131415161718192021/** * kmem_cache_free - Deallocate an object * @cachep: The cache the allocation was from. * @objp: The previously allocated object. * * Free an object which was previously allocated from this * cache. */void kmem_cache_free(struct kmem_cache *cachep, void *objp)&#123; unsigned long flags; local_irq_save(flags); debug_check_no_locks_freed(objp, obj_size(cachep)); if (!(cachep-&gt;flags &amp; SLAB_DEBUG_OBJECTS)) debug_check_no_obj_freed(objp, obj_size(cachep)); __cache_free(cachep, objp); local_irq_restore(flags); trace_kmem_cache_free(_RET_IP_, objp);&#125; 如果你要频繁的创建很多相同类型的对象，就要当考虑使用slab高速缓存区。 实际上上一节所讲kmalloc()函数也是使用slab分配器分配的。123456789101112131415161718192021222324252627282930313233343536static __always_inline void *kmalloc(size_t size, gfp_t flags)&#123; struct kmem_cache *cachep; void *ret; if (__builtin_constant_p(size)) &#123; int i = 0; if (!size) return ZERO_SIZE_PTR; #define CACHE(x) \ if (size &lt;= x) \ goto found; \ else \ i++;#include &lt;linux/kmalloc_sizes.h&gt;#undef CACHE return NULL;found:#ifdef CONFIG_ZONE_DMA if (flags &amp; GFP_DMA) cachep = malloc_sizes[i].cs_dmacachep; else#endif cachep = malloc_sizes[i].cs_cachep; ret = kmem_cache_alloc_notrace(cachep, flags); trace_kmalloc(_THIS_IP_, ret, size, slab_buffer_size(cachep), flags); return ret; &#125; return __kmalloc(size, flags);&#125; kfree函数实现如下：1234567891011121314151617181920212223242526/** * kfree - free previously allocated memory * @objp: pointer returned by kmalloc. * * If @objp is NULL, no operation is performed. * * Don&apos;t free memory not originally allocated by kmalloc() * or you will run into trouble. */void kfree(const void *objp)&#123; struct kmem_cache *c; unsigned long flags; trace_kfree(_RET_IP_, objp); if (unlikely(ZERO_OR_NULL_PTR(objp))) return; local_irq_save(flags); kfree_debugcheck(objp); c = virt_to_cache(objp); debug_check_no_locks_freed(objp, obj_size(c)); debug_check_no_obj_freed(objp, obj_size(c)); __cache_free(c, (void *)objp); local_irq_restore(flags);&#125; 最后，结合上一节，看看分配函数的选择：如果需要连续的物理页，就可以使用某个低级页分配器或kmalloc()。如果想从高端内存进行分配，使用alloc_pages()。如果不需要物理上连续的页，而仅仅是虚拟地址上连续的页，那么就是用vmalloc。如果要创建和销毁很多大的数据结构，那么考虑建立slab高速缓存。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十一）：内存管理之页的分配与回收]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E9%A1%B5%E7%9A%84%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 内存管理单元（MMU）负责将管理内存，在把虚拟地址转换为物理地址的硬件的时候是按页为单位进行处理，从虚拟内存的角度来看，页就是内存管理中的最小单位。页的大小与体系结构有关，在 x86 结构中一般是4KB（32位）或者8KB（64位）。通过 getconf 命令可以查看系统的page的大小：12345# getconf -a | grep PAGEPAGESIZE 4096PAGE_SIZE 4096_AVPHYS_PAGES 230873_PHYS_PAGES 744957 内核中的每个物理页用struct page结构表示，结构定义于文件&lt;include/linux/mm_types.h&gt;：123456789101112131415161718192021222324252627282930313233343536373839struct page &#123; unsigned long flags; /*页的状态*/ atomic_t _count; /* 页引用计数 */ union &#123; atomic_t _mapcount; /* 已经映射到mms的pte的个数*/ struct &#123; /* */ u16 inuse; u16 objects; &#125;; &#125;; union &#123; struct &#123; unsigned long private; struct address_space *mapping; &#125;;#if USE_SPLIT_PTLOCKS spinlock_t ptl;#endif struct kmem_cache *slab; /* 指向slab层 */ struct page *first_page; /* Compound tail pages */ &#125;; union &#123; pgoff_t index; /* Our offset within mapping. */ void *freelist; /* SLUB: freelist req. slab lock */ &#125;; struct list_head lru; /* 将页关联起来的链表项 */ #if defined(WANT_PAGE_VIRTUAL) void *virtual; /* Kernel virtual address (NULL if not kmapped, ie. highmem) */#endif /* WANT_PAGE_VIRTUAL */#ifdef CONFIG_WANT_PAGE_DEBUG_FLAGS unsigned long debug_flags; /* Use atomic bitops on this */#endif #ifdef CONFIG_KMEMCHECK void *shadow;#endif&#125;; 内核使用这一结构来管理系统中所有的页，因为内核需要知道一个该页是否被分配，是被谁拥有的等信息。 由于ISA总线的DMA处理器有严格的限制，只能对物理内存前16M寻址，内核线性地址空间只有1G,CPU不能直接访问所有的物理内存。这样就导致有一些内存不能永久地映射在内核空间上。所以在linux中，把页分为不同的区，使用区来对具有相似特性的页进行分组。分组如下（以x86-32为例）： 区域 用途 ZONE_DMA 小于16M内存页框，这个区包含的页用来执行DMA操作。 ZONE_NORMAL 16M~896M内存页框，个区包含的都是能正常映射的页。 ZONE_HIGHMEM 大于896M内存页框，这个区包”高端内存”，其中的页能不永久地映射到内核地址空间。 linux 把系统的页划分区，形成不同的内存池，这样就可以根据用途进行分配了。 每个区都用struct zone表示，定义于&lt;include/linux/mmzone.h&gt;中。该结构体较大，详细结构体信息可以查看源码文件。 linux提供了几个以页为单位分配释放内存的接口，定义于&lt;include/linux/gfp.h&gt;中。分配内存主要有以下方法： —|—alloc_page(gfp_mask)|只分配一页，返回指向页结构的指针alloc_pages(gfp_mask, order)|分配 2^order 个页，返回指向第一页页结构的指针get_free_page(gfp_mask)|只分配一页，返回指向其逻辑地址的指针 get_free_pages(gfp_mask, order)|分配 2^order 个页，返回指向第一页逻辑地址的指针get_zeroed_page(gfp_mask)|只分配一页，让其内容填充为0，返回指向其逻辑地址的指针 alloc_函数返回的是内存的物理地址，get_ 函数返回内存物理地址映射后的逻辑地址。如果无须直接操作物理页结构体的话，一般使用 get_*函数。 释放页的函数有：123externvoid__free_pages( struct page *page, unsignedintorder); externvoidfree_pages(unsigned longaddr, unsigned intorder); externvoidfree_hot_page( struct page *page); 当需要以页为单位的连续物理页时，可以使用上面这些分配页的函数，对于常用以字节为单位的分配来说，内核提供来kmalloc()函数。 kmalloc()函数和用户空间一族函数类似，它可以以字节为单位分配内存，对于大多数内核分配来说，kmalloc函数用得更多。1void *kmalloc(size_t size, gfp_t gfp_mask)； 参数中有个 gfp_mask 标志，这个标志是控制分配内存时必须遵守的一些规则。gfp_mask 标志有3类： 行为标志 ：控制分配内存时，分配器的一些行为，如何分配所需内存。 区标志 ：控制内存分配在那个区(ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM 之类)。 类型标志 ：由上面2种标志组合而成的一些常用的场景。 行为标志主要有以下几种： 行为标志 描述 __GFP_WAIT 分配器可以睡眠 __GFP_HIGH 分配器可以访问紧急事件缓冲池 __GFP_IO 分配器可以启动磁盘I/O __GFP_FS 分配器可以启动文件系统I/O __GFP_COLD 分配器应该使用高速缓存中快要淘汰出去的页 __GFP_NOWARN 分配器将不打印失败警告 __GFP_REPEAT 分配器在分配失败时重复进行分配，但是这次分配还存在失败的可能 __GFP_NOFALL 分配器将无限的重复进行分配。分配不能失败 __GFP_NORETRY 分配器在分配失败时不会重新分配 __GFP_NO_GROW 由slab层内部使用 __GFP_COMP 添加混合页元数据，在 hugetlb 的代码内部使用 标志主要有以下3种： 区标志 描述 __GFP_DMA 从 ZONE_DMA 分配 __GFP_DMA32 只在 ZONE_DMA32 分配 ，和 ZONE_DMA 类似，该区包含的页也可以进行DMA操作 __GFP_HIGHMEM 从 ZONE_HIGHMEM 或者 ZONE_NORMAL 分配，优先从 ZONE_HIGHMEM 分配，如果 ZONE_HIGHMEM 没有多余的页则从 ZONE_NORMAL 分配 类型标志是编程中最常用的，在使用标志时，应首先看看类型标志中是否有合适的，如果没有，再去自己组合 行为标志和区标志。 类型标志 描述 实际标志 GFP_ATOMIC 这个标志用在中断处理程序，下半部，持有自旋锁以及其他不能睡眠的地方 __GFP_HIGH GFP_NOWAIT 与 GFP_ATOMIC 类似，不同之处在于，调用不会退给紧急内存池。这就增加了内存分配失败的可能性 0 GFP_NOIO 这种分配可以阻塞，但不会启动磁盘I/O。这个标志在不能引发更多磁盘I/O时能阻塞I/O代码，可能会导致递归 __GFP_WAIT GFP_NOFS 这种分配在必要时可能阻塞，也可能启动磁盘I/O，但不会启动文件系统操作。这个标志在你不能再启动另一个文件系统的操作时，用在文件系统部分的代码中 (__GFP_WAIT｜ __GFP_IO) GFP_KERNEL 这是常规的分配方式，可能会阻塞。这个标志在睡眠安全时用在进程上下文代码中。为了获得调用者所需的内存，内核会尽力而为。这个标志应当为首选标志 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ) GFP_USER 这是常规的分配方式，可能会阻塞。用于为用户空间进程分配内存时 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ) GFP_HIGHUSER 从 ZONE_HIGHMEM 进行分配，可能会阻塞。用于为用户空间进程分配内存 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ｜__GFP_HIGHMEM) GFP_DMA 从 ZONE_DMA 进行分配。需要获取能供DMA使用的内存的设备驱动程序使用这个标志。通常与以上的某个标志组合在一起使用。 __GFP_DMA 以上各种类型标志的使用场景总结： 场景 相应标志 进程上下文，可以睡眠 使用 GFP_KERNEL 进程上下文，不可以睡眠 使用 GFP_ATOMIC，在睡眠之前或之后以 GFP_KERNEL 执行内存分配 中断处理程序 使用 GFP_ATOMIC 软中断 使用 GFP_ATOMIC tasklet 使用 GFP_ATOMIC 需要用于DMA的内存，可以睡眠 使用 (GFP_DMA｜GFP_KERNEL) 需要用于DMA的内存，不可以睡眠 使用 (GFP_DMA｜GFP_ATOMIC)，或者在睡眠之前执行内存分配 kmalloc 所对应的释放内存的方法为：1void kfree(const void *)； vmalloc()也可以按字节来分配内存。1void *vmalloc(unsigned long size) 和kmalloc是一样的作用，不同在于前者分配的内存虚拟地址是连续的，而物理地址则无需连续。kmalloc()可以保证在物理地址上都是连续的，虚拟地址当然也是连续的。vmalloc()函数只确保页在虚拟机地址空间内是连续的。它通过分配非联系的物理内存块，再“修正”页表，把内存映射到逻辑地址空间的连续区域中，就能做到这点。但很显然这样会降低处理性能，因为内核不得不做“拼接”的工作。所以这也是为什么不得已才使用 vmalloc()的原因 。 vmalloc()可能睡眠，不能从中断上下文中进行调用，也不能从其他不允许阻塞的情况下进行调用。释放时必须使用vfree()。1void vfree(const void *)； 对于内存页面的管理，通常是先在虚存空间中分配一个虚存区间，然后才根据需要为此区间分配相应的物理页面并建立起映射，也就是说，虚存区间的分配在前，而物理页面的分配在后。但由于频繁的请求和释放不同大小的连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页框，由此产生的问题是：即使有足够的空闲页框可以满足请求，但当要分配一个大块的连续页框时，无法满足请求。这就是著名的内存管理问题：外碎片问题。Linux采用著名的伙伴（Buddy）系统算法来解决外碎片问题。 把所有的空闲页框分组为11个块链表。每个块链表包含大小为1,2,4,8,16,32,64,128,256,512，1024个的页框。伙伴系统算法原理为： 假设请求一个256个页框的块，先在256个页框的链表内检查是否有一个空闲的块。如果没有这样的块，算法会查找下一个更大的块，在512个页框的链表中找一个空闲块。如果存在这样的块，内核就把512的页框分成两半，一半用作满足请求，另一半插入256个页框的链表中。如果512个页框的块链表也没有空闲块，就继续找更大的块，1024个页框的块。如果这样的块存在，内核把1024个页框的256个页框用作请求，然后从剩余的768个中拿出512个插入512个页框的链表中，把最后256个插入256个页框的链表中。 页框块的释放过程如下： 如果两个块具有相同的大小：a，并且他们的物理地址连续那么这两个块成为伙伴，内核就会试图把大小为a的一对空闲伙伴块合并为一个大小为2a的单独块。该算法还是迭代的，如果合并成功的话，它还会试图合并2a的块。 管理分区数据结构struct zone_struct中，涉及到空闲区数据结构。123456struct free_area free_area[MAX_ORDER]; struct free_area &#123; struct list_head free_list[MIGRATE_TYPES]; unsigned long nr_free; &#125;; 采用伙伴算法分配内存时，每次至少分配一个页面。但当请求分配的内存大小为几十个字节或几百个字节时应该如何处理？如何在一个页面中分配小的内存区，小内存区的分配所产生的内碎片又如何解决？slab的分配模式可以解决该问题，下一节我们将开始分析slab分配器。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十）：内核同步]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 如同linux应用一样，内核的共享资源也要防止并发，因为如果多个执行线程同时访问和操作数据有可能发生各个线程之间相互覆盖共享数据的情况。 在linux只是单一处理器的时候，只有在中断发生或内核请求重新调度执行另一个任务时，数据才可能会并发访问。但自从内核开始支持对称多处理器之后，内核代码可以同时运行在多个处理器上，如果此时不加保护，运行在多个处理器上的代码完全可能在同一时刻并发访问共享数据。 一般把访问和操作共享数据的代码段称作临界区，为了避免在临界区中发生并发访问，程序员必须保证临界区代码原子执行，也就是要么全部执行，要么不执行。如果两个执行线程在同一个临界区同时执行，就发生了竞态（race conditions），避免并发防止竞态就是所谓的同步。 在linux内核中造成并发的原因主要有如下:中断 – 中断几乎可以在任何时刻异步发生，也就可能随时打断当前正在执行的代码。软中断和tasklet – 内核能在任何时刻唤醒或调度软中断和tasklet，打断当前正在执行的代码。内核抢占 – 因为内核具有抢占性，所以内核中的任务可能会被另一任务抢占。睡眠及与用户空间的同步 – 在内核执行的进程可能会睡眠，这就会唤醒调度程序，从而导致调度一个新的用户进程执行。对称多处理 – 两个或多个处理器可以同时执行代码。（真并发） 通过锁可以防止并发执行，并且保护临界区不受竞态影响。任何执行线程要访问临界区代码时首先先获得锁，这样当后面另外的执行线程要访问临界区时就不能再获得该锁，这样临界区就禁止后来执行线程访问。linux自身实现了多种不同的锁机制，各种锁各有差别，区别主要在于当锁被争用时，有些会简单地执行等待，而有些锁会使当前任务睡眠直到锁可用为止。本节将会分析各锁的使用和实现。但是使用锁也会带来副作用，锁使得线程按串行方式对资源进行访问，所以使用锁无疑会降低系统性能；并且锁使用不当还会造成死锁。 下面来看一下linux下同步的方法，包括原子操作、自旋锁、信号量等方式。 原子操作该操作是其它同步方法的基础，原子操作可以保证指令以原子的方式执行，执行过程不会被打断。linux内核提供了两组原子操作接口：原子整数操作和原子位操作。 针对整数的原子操作只能对atomic_t类型的数据进行处理。该类类型定义与文件&lt;include/linux/types.h&gt;:123typedef struct &#123; volatile int counter;&#125; atomic_t; 下面举例说明原子操作的用法：定义一个atomic_c类型的数据很简单，还可以定义时给它设定初值：1234(1) atomic_t u; /*定义 u*/(2) atomic_t v = ATOMIC_INIT(0) /*定义 v 并把它初始化为0*/ 对其操作：123456789(1) atomic_set(&amp;v,4)/* v = 4 ( 原子地)*/(2) atomic_add(2,&amp;v)/* v = v + 2 = 6 (原子地) */(3) atomic_inc(&amp;v) /* v = v + 1 =7（原子地)*/ 如果需要将atomic_t转换成int型，可以使用atomic_read()来完成：1printk(“%d\n”,atomic_read(&amp;v)); /* 会打印7*/ 原子整数操作最常见的用途就是实现计数器。使用复杂的锁机制来保护一个单纯的计数器是很笨拙的，所以，开发者最好使用atomic_inc()和atomic_dec()这两个相对来说轻便一点的操作。还可以用原子整数操作原子地执行一个操作并检查结果。一个常见的例子是原子的减操作和检查。1int atomic_dec_and_test(atomic_t *v) 这个函数让给定的原子变量减1，如果结果为0，就返回1；否则返回0。特定体系结构的所有原子整数操作可以在文件&lt;arch/x86/include/asm/atomic.h&gt;中找到。如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344#ifndef _ASM_X86_ATOMIC_32_H#define _ASM_X86_ATOMIC_32_H #include &lt;linux/compiler.h&gt;#include &lt;linux/types.h&gt;#include &lt;asm/processor.h&gt;#include &lt;asm/cmpxchg.h&gt; #define ATOMIC_INIT(i) &#123; (i) &#125; static inline int atomic_read(const atomic_t *v)&#123; return v-&gt;counter;&#125; static inline void atomic_set(atomic_t *v, int i)&#123; v-&gt;counter = i;&#125; static inline void atomic_add(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;addl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i));&#125; static inline void atomic_sub(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;subl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i));&#125; static inline int atomic_sub_and_test(int i, atomic_t *v)&#123; unsigned char c; asm volatile(LOCK_PREFIX &quot;subl %2,%0; sete %1&quot; : &quot;+m&quot; (v-&gt;counter), &quot;=qm&quot; (c) : &quot;ir&quot; (i) : &quot;memory&quot;); return c;&#125;...... 除了原子整数之外，内核还提供了一组针对位操作的函数，这些操作也是和体系结构相关的。例如在x86下set_bit实现如下：12345678910111213static __always_inline voidset_bit(unsigned int nr, volatile unsigned long *addr)&#123; if (IS_IMMEDIATE(nr)) &#123; asm volatile(LOCK_PREFIX &quot;orb %1,%0&quot; : CONST_MASK_ADDR(nr, addr) : &quot;iq&quot; ((u8)CONST_MASK(nr)) : &quot;memory&quot;); &#125; else &#123; asm volatile(LOCK_PREFIX &quot;bts %1,%0&quot; : BITOP_ADDR(addr) : &quot;Ir&quot; (nr) : &quot;memory&quot;); &#125;&#125; 原子操作是对普通内存地址指针进行的操作，只要指针指向了任何你希望的数据，你就可以对它进行操作。原子位操作(以x86为例)相关函数定义在文件&lt;arch/x86/include/asm/bitops.h&gt;中。 自旋锁不是所有的临界区都是像增加或减少变量这么简单，有的时候临界区可能会跨越多个函数，这这时就需要使用更为复杂的同步方法——锁。linux内核中最常见的锁是自旋锁，自旋锁最多只能被一个可执行线程持有，如果一个可执行线程视图获取一个已经被持有的锁，那么该线程将会一直进行忙循环等待锁重新可用。在任意时候，自旋锁都可以防止多余一个执行线程同时进入临界区。由于自旋忙等过程是很费时间的，所以自旋锁不应该被长时间持有。 自旋锁相关方法如下： 方法 spinlock中的定义 定义spin lock并初始化 DEFINE_SPINLOCK() 动态初始化spin lock spin_lock_init() 获取指定的spin lock spin_lock() 获取指定的spin lock同时disable本CPU中断 spin_lock_irq() 保存本CPU当前的irq状态，disable本CPU中断并获取指定的spin lock spin_lock_irqsave() 获取指定的spin lock同时disable本CPU的bottom half spin_lock_bh() 释放指定的spin lock spin_unlock() 释放指定的spin lock同时enable本CPU中断 spin_lock_irq() 释放指定的spin lock同时恢复本CPU的中断状态 spin_lock_irqsave() 获取指定的spin lock同时enable本CPU的bottom half spin_unlock_bh() 尝试去获取spin lock，如果失败，不会spin，而是返回非零值 spin_trylock() 判断spin lock是否是locked，如果其他的thread已经获取了该lock，那么返回非零值，否则返回0 spin_is_locked() 自旋锁的实现和体系结构密切相关，代码通常通过汇编实现。与体系结构相关的部分定义在&lt;asm/spinlock.h&gt;,实际需要用到的接口定义在文件&lt;linux/spinlock.h&gt;中。一个实际的锁的类型为spinlock_t，定义在文件&lt;include/linux/spinlock_types.h&gt;中:12345678910111213typedef struct &#123; raw_spinlock_t raw_lock;#ifdef CONFIG_GENERIC_LOCKBREAK unsigned int break_lock;#endif#ifdef CONFIG_DEBUG_SPINLOCK unsigned int magic, owner_cpu; void *owner;#endif#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125; spinlock_t; 自旋锁基本使用形式如下：1234DEFINE_SPINLOCK(lock);spin_lock(&amp;lock);/* 临界区 */spin_unlock(&amp;lock); 实际上有 4 个函数可以加锁一个自旋锁:12345void spin_lock(spinlock_t *lock);void spin_lock_irq(spinlock_t *lock); //相当于spin_lock() + local_irq_disable()。void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);//禁止中断(只在本地处理器)在获得自旋锁之前; 之前的中断状态保存在 flags里。相当于spin_lock() + local_irq_save()。void spin_lock_bh(spinlock_t *lock); //获取锁之前禁止软件中断, 但是硬件中断留作打开的，相当于spin_lock() + local_bh_disable()。 也有 4 个方法来释放一个自旋锁; 你用的那个必须对应你用来获取锁的函数.1234void spin_unlock(spinlock_t *lock);void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);void spin_unlock_irq(spinlock_t *lock);void spin_unlock_bh(spinlock_t *lock); 下面看一下DEFINE_SPINLOCK()、spin_lock_init()、spin_lock()、spin_lock_irqsave()的实现：1#define DEFINE_SPINLOCK(x) spinlock_t x = __SPIN_LOCK_UNLOCKED(x) 123# define spin_lock_init(lock) \ do &#123; *(lock) = SPIN_LOCK_UNLOCKED; &#125; while (0)#endif spin_lock:1234567891011#define spin_lock(lock) _spin_lock(lock)void __lockfunc _spin_lock(spinlock_t *lock)&#123; __spin_lock(lock);&#125;static inline void __spin_lock(spinlock_t *lock)&#123; preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); LOCK_CONTENDED(lock, _raw_spin_trylock, _raw_spin_lock);&#125; spin_lock_irqsave:123456789101112131415161718192021222324#define spin_lock_irqsave(lock, flags) \ do &#123; \ typecheck(unsigned long, flags); \ flags = _spin_lock_irqsave(lock); \ &#125; while (0)unsigned long __lockfunc _spin_lock_irqsave(spinlock_t *lock)&#123; return __spin_lock_irqsave(lock);&#125;static inline unsigned long __spin_lock_irqsave(spinlock_t *lock)&#123; unsigned long flags; local_irq_save(flags); //spin_lock的实现没有禁止本地中断这一步 preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); #ifdef CONFIG_LOCKDEP LOCK_CONTENDED(lock, _raw_spin_trylock, _raw_spin_lock);#else _raw_spin_lock_flags(lock, &amp;flags);#endif return flags;&#125; 读写自旋锁一种比自旋锁粒度更小的锁机制,它保留了“自旋”的概念,但是在写操作方面,只能最多有1个写进程,在读操作方面,同时可以有多个读执行单元。当然,读和写也不能同时进行。读者写者锁有一个类型 rwlock_t, 在&lt;linux/spinlokc.h&gt;中定义. 它们可以以 2 种方式被声明和被初始化:静态方式：1rwlock_t my_rwlock = RW_LOCK_UNLOCKED; 动态方式：12rwlock_t my_rwlock;rwlock_init(&amp;my_rwlock); 可用函数的列表现在应当看来相当类似。 对于读者, 有下列函数可用:12345678void read_lock(rwlock_t *lock);void read_lock_irqsave(rwlock_t *lock, unsigned long flags);void read_lock_irq(rwlock_t *lock);void read_lock_bh(rwlock_t *lock);void read_unlock(rwlock_t *lock);void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);void read_unlock_irq(rwlock_t *lock);void read_unlock_bh(rwlock_t *lock); 对于写存取的函数是类似的:123456789void write_lock(rwlock_t *lock);void write_lock_irqsave(rwlock_t *lock, unsigned long flags);void write_lock_irq(rwlock_t *lock);void write_lock_bh(rwlock_t *lock);int write_trylock(rwlock_t *lock);void write_unlock(rwlock_t *lock);void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);void write_unlock_irq(rwlock_t *lock);void write_unlock_bh(rwlock_t *lock); 在与下半部配合使用时，锁机制必须要小心使用。由于下半部可以抢占进程上下文的代码，所以当下半部和进程上下文共享数据时，必须对进程上下文的共享数据进行保护，所以需要加锁的同时还要禁止下半部执行。同样的，由于中断处理器可以抢占下半部，所以如果中断处理器程序和下半部共享数据，那么就必须在获取恰当的锁的同时还要禁止中断。 同类的tasklet不可能同时运行，所以对于同类tasklet中的共享数据不需要保护，但是当数据被两个不同种类的tasklet共享时，就需要在访问下半部中的数据前先获得一个普通的自旋锁。由于同种类型的两个软中断也可以同时运行在一个系统的多个处理器上，所以被软中断共享的数据必须得到锁的保护。 信号量一个被占有的自旋锁使得请求它的线程循环等待而不会睡眠，这很浪费处理器时间，所以自旋锁使用段时间占有的情况。linux提供另外的同步方式可以在锁争用时让请求线程睡眠，直到锁重新可用时在唤醒它，这样处理器就不必循环等待，可以去执行其它代码。这种方式就是即将讨论的信号量。 信号量是一种睡眠锁，如果有一个任务试图获得一个已经被占用的信号量时，信号量会将其放入一个等待队列，然后睡眠。当持有的信号量被释放后，处于等待队列中的那个任务将被唤醒，并获得信号量。信号量比自旋锁提供了更好的处理器利用率，因为没有把时间花费在忙等带上。但是信号量也会有一定的开销，被阻塞的线程换入换出有两次明显的上下文切换，这样的开销比自旋锁要大的多。 如果需要在自旋锁和信号量中做出选择，应该根据锁被持有的时间长短做判断，如果加锁时间不长并且代码不会休眠，利用自旋锁是最佳选择。相反，如果加锁时间可能很长或者代码在持有锁有可能睡眠，那么最好使用信号量来完成加锁功能。信号量一个有用特性就是它可以同时允许任意数量的锁持有者，而自旋锁在一个时刻最多允许一个任务持有它。信号量同时允许的持有者数量可以在声明信号量时指定，当为1时，成为互斥信号量，否则成为计数信号量。 信号量的实现与体系结构相关，信号量使用struct semaphore类型用来表示信号量，定义于文件&lt;include/linux/semaphore.h&gt;中:12345struct semaphore &#123; spinlock_t lock; unsigned int count; struct list_head wait_list;&#125;; 信号量初始化方法有如下:方法一:12345678struct semaphore sem; void sema_init(struct semaphore *sem, int val);//初始化信号量,并设置信号量 sem 的值为 val。 static inline void sema_init(struct semaphore *sem, int val)&#123; static struct lock_class_key __key; *sem = (struct semaphore) __SEMAPHORE_INITIALIZER(*sem, val); lockdep_init_map(&amp;sem-&gt;lock.dep_map, &quot;semaphore-&gt;lock&quot;, &amp;__key, 0);&#125; 方法二:1DECLARE_MUTEX(name); 定义一个名为 name 的信号量并初始化为1。其实现为:12#define DECLARE_MUTEX(name) \ struct semaphore name = __SEMAPHORE_INITIALIZER(name, 1) 方法三:1234#define init_MUTEX(sem) sema_init(sem, 1) //以不加锁状态动态创建信号量#define init_MUTEX_LOCKED(sem) sema_init(sem, 0) //以加锁状态动态创建信号量 信号量初始化后就可以使用了，使用信号量主要有如下方法:12345678910void down(struct semaphore * sem);//该函数用于获得信号量 sem，它会导致睡眠，因此不能在中断上下文使用; int down_interruptible(struct semaphore * sem);//该函数功能与 down 类似，不同之处为，因为 down()而进入睡眠状态的进程不能被信号打断，但因为 down_interruptible()而进入睡眠状态的进程能被信号打断，信号也会导致该函数返回，这时候函数的返回值非 0; int down_trylock(struct semaphore * sem);//该函数尝试获得信号量sem，如果能够立刻获得，它就获得该信号量并返回0， 否则,返回非0值。它不会导致调用者睡眠，可以在中断上下文使用。up(struct semaphore * sem); //释放指定信号量，如果睡眠队列不空，则唤醒其中一个队列。 信号量一般这样使用：12345678/* 定义信号量 DECLARE_MUTEX(mount_sem); //down(&amp;mount_sem);/* 获取信号量，保护临界区，信号量被占用之后进入不可中断睡眠状态down_interruptible(&amp;mount_sem);/* 获取信号量，保护临界区，信号量被占用之后进入不可中断睡眠状态. . . critical section /* 临界区 . . . up(&amp;mount_sem);/* 释放信号量 下面看一下这些函数的实现：down():123456789101112131415void down(struct semaphore *sem)&#123; unsigned long flags; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(sem-&gt;count &gt; 0)) sem-&gt;count--; else __down(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125;static noinline void __sched __down(struct semaphore *sem)&#123; __down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);&#125; down_interruptible():123456789101112131415161718int down_interruptible(struct semaphore *sem)&#123; unsigned long flags; int result = 0; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(sem-&gt;count &gt; 0)) sem-&gt;count--; else result = __down_interruptible(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags); return result;&#125;static noinline int __sched __down_interruptible(struct semaphore *sem)&#123; return __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);&#125; down_trylock():12345678910111213int down_trylock(struct semaphore *sem)&#123; unsigned long flags; int count; spin_lock_irqsave(&amp;sem-&gt;lock, flags); count = sem-&gt;count - 1; if (likely(count &gt;= 0)) sem-&gt;count = count; spin_unlock_irqrestore(&amp;sem-&gt;lock, flags); return (count &lt; 0);&#125; up():12345678910111213141516171819void up(struct semaphore *sem)&#123; unsigned long flags; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(list_empty(&amp;sem-&gt;wait_list))) sem-&gt;count++; else __up(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125;static noinline void __sched __up(struct semaphore *sem)&#123; struct semaphore_waiter *waiter = list_first_entry(&amp;sem-&gt;wait_list, struct semaphore_waiter, list); list_del(&amp;waiter-&gt;list); waiter-&gt;up = 1; wake_up_process(waiter-&gt;task);&#125; 正如自旋锁一样，信号量也有区分读写访问的可能，读写信号量在内核中使用rw_semaphore结构表示，x86体系结构定义在&lt;arch/x86/include/asm/rwsem.h&gt;文件中：12345678struct rw_semaphore &#123; signed long count; spinlock_t wait_lock; struct list_head wait_list;#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125;; 读写信号量的使用方法和信号量类似，其操作函数有如下:123456789DECLARE_RWSEM(name) //声明名为name的读写信号量，并初始化它。void init_rwsem(struct rw_semaphore *sem); //对读写信号量sem进行初始化。void down_read(struct rw_semaphore *sem); //读者用来获取sem，若没获得时，则调用者睡眠等待。void up_read(struct rw_semaphore *sem); //读者释放sem。int down_read_trylock(struct rw_semaphore *sem); //读者尝试获取sem，如果获得返回1，如果没有获得返回0。可在中断上下文使用。void down_write(struct rw_semaphore *sem); //写者用来获取sem，若没获得时，则调用者睡眠等待。int down_write_trylock(struct rw_semaphore *sem); //写者尝试获取sem，如果获得返回1，如果没有获得返回0。可在中断上下文使用void up_write(struct rw_semaphore *sem); //写者释放sem。void downgrade_write(struct rw_semaphore *sem); //把写者降级为读者。 互斥体除了信号量之外，内核拥有一个更简单的且可睡眠的锁，那就是互斥体。互斥体的行为和计数是1的信号量类似，其接口简单，实现更高效。 互斥体在内核中使用mutex表示，定义于&lt;include/linux/mutex.h&gt;：1234567struct mutex &#123; /* 1: unlocked, 0: locked, negative: locked, possible waiters */ atomic_t count; spinlock_t wait_lock; struct list_head wait_list; ......&#125;; 静态定义mutex：1DEFINE_MUTEX(name); 实现如下：123456789#define DEFINE_MUTEX(mutexname) \ struct mutex mutexname = __MUTEX_INITIALIZER(mutexname) #define __MUTEX_INITIALIZER(lockname) \ &#123; .count = ATOMIC_INIT(1) \ , .wait_lock = __SPIN_LOCK_UNLOCKED(lockname.wait_lock) \ , .wait_list = LIST_HEAD_INIT(lockname.wait_list) \ __DEBUG_MUTEX_INITIALIZER(lockname) \ __DEP_MAP_MUTEX_INITIALIZER(lockname) &#125; 动态定义mutex：123456789101112131415161718mutex_init(&amp;mutex);# define mutex_init(mutex) \do &#123; \ static struct lock_class_key __key; \ \ __mutex_init((mutex), #mutex, &amp;__key); \&#125; while (0) void__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)&#123; atomic_set(&amp;lock-&gt;count, 1); spin_lock_init(&amp;lock-&gt;wait_lock); INIT_LIST_HEAD(&amp;lock-&gt;wait_list); mutex_clear_owner(lock); debug_mutex_init(lock, name, key);&#125; 锁定和解锁如下：12345678910111213141516171819202122232425262728293031mutex_lock(&amp;mutex);/* 临界区 */mutex_unlock(&amp;mutex);void __sched mutex_lock(struct mutex *lock)&#123; might_sleep(); /* * The locking fastpath is the 1-&gt;0 transition from * &apos;unlocked&apos; into &apos;locked&apos; state. */ __mutex_fastpath_lock(&amp;lock-&gt;count, __mutex_lock_slowpath); mutex_set_owner(lock);&#125; void __sched mutex_unlock(struct mutex *lock)&#123; /* * The unlocking fastpath is the 0-&gt;1 transition from &apos;locked&apos; * into &apos;unlocked&apos; state: */#ifndef CONFIG_DEBUG_MUTEXES /* * When debugging is enabled we must not clear the owner before time, * the slow path will always be taken, and that clears the owner field * after verifying that it was indeed current. */ mutex_clear_owner(lock);#endif __mutex_fastpath_unlock(&amp;lock-&gt;count, __mutex_unlock_slowpath);&#125; 其他mutex方法:12int mutex_trylock(struct mutex *); //视图获取指定互斥体，成功返回1；否则返回0。int mutex_is_locked(struct mutex *lock); //判断锁是否被占用，是返回1，否则返回0。 使用mutex时，要注意一下：mutex的使用技术永远是1；在同一上下文中上锁解锁；当进程持有一个mutex时，进程不可退出；mutex不能在中断或下半部中使用。 抢占禁止在前面章节讲进程管理的时候听到过内核抢占，由于内核可抢占，内核中的进程随时都可能被另外一个具有更高优先权的进程打断，这也就意味着一个任务与被抢占的任务可能会在同一个临界区运行。所以才有本节前面自旋锁来避免竞态的发生，自旋锁有禁止内核抢占的功能。但像每cpu变量的数据只能被一个处理器访问，可以不需要使用锁来保护，如果没有使用锁，内核又是抢占式的，那么新调度的任务就可能访问同一个变量。这个时候就可以通过禁止内核抢占来避免竞态的发生，禁止内核抢占使用preetmpt_disable()函数，这是一个可以嵌套调用的函数，可以使用任意次。每次调用都必须有一个相应的preempt_enable()调用，当最后一次preempt_enable()被调用时，内核抢占才重新启用。内核抢占相关函数如下：123456789101112preempt_enable() //内核抢占计数preempt_count减1preempt_disable() //内核抢占计数preempt_count加1，当该值降为0时检查和执行被挂起的需要调度的任务preempt_enable_no_resched()//内核抢占计数preempt_count减1，但不立即抢占式调度preempt_check_resched () //如果必要进行调度preempt_count() //返回抢占计数preempt_schedule() //内核抢占时的调度程序的入口点 以preempt_enable()为例，看一下其实现：123456789101112131415161718192021222324252627282930313233343536373839404142#define preempt_enable() \do &#123; \ preempt_enable_no_resched(); \ barrier(); \ // 加内存屏障，阻止gcc编译器对内存进行优化 preempt_check_resched(); \&#125; while (0)#define preempt_enable_no_resched() \do &#123; \ barrier(); \ dec_preempt_count(); \&#125; while (0)#define dec_preempt_count() sub_preempt_count(1)# define sub_preempt_count(val) do &#123; preempt_count() -= (val); &#125; while (0) //此处减少抢占计数 #define preempt_check_resched() \do &#123; \ if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \ preempt_schedule(); \&#125; while (0) asmlinkage void __sched preempt_schedule(void)&#123; struct thread_info *ti = current_thread_info(); /* * If there is a non-zero preempt_count or interrupts are disabled, * we do not want to preempt the current task. Just return.. */ if (likely(ti-&gt;preempt_count || irqs_disabled())) return; do &#123; add_preempt_count(PREEMPT_ACTIVE); schedule(); sub_preempt_count(PREEMPT_ACTIVE); /* * Check again in case we missed a preemption opportunity * between schedule and now. */ barrier(); &#125; while (need_resched());]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（九）：进程调度]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B9%9D%EF%BC%89%EF%BC%9A%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 linux为多任务系统，正常情况下都存在成百上千个任务。由于linux提供抢占式的多任务模式，所以linux能同时并发地交互执行多个进程，而调度程序将决定哪一个进程投入运行、何时运行、以及运行多长时间。调度程序是像linux这样的多任务操作系统的基础， 只有通过调度程序的合理调度，系统资源才能最大限度地发挥作用，多进程才会有并发执行的效果。当系统中可运行的进程数目比处理器的个数多，就注定在某一时刻有一些进程不能执行，这些不能执行的进程在等待执行。调度程序的基本工作就是停止一个进程的运行，再在这些等待执行的进程中选择一个来执行。 调度程序停止一个进程的运行，再选择一个另外进程的动作开始运行的动作被称作抢占（preemption）。一个进程在被抢占之前能够运行的时间是预先设置好的，这个预先设置好的时间就是进程的的时间片（timeslice）。时间片就是分配给每个可运行进程的处理器时间段，它表明进程在被抢占前所能持续运行时间。 处理器的调度策略决定调度程序在何时让什么进程投入运行。调度策略通常需要在进程响应迅速(相应时间短)和进程吞吐量高之间寻找平衡。所以调度程序通常采用一套非常复杂的算法来决定最值得运行的进程投入运行。调度算法中最基本的一类当然就是基于优先级的调度，也就是说优先级高的先运行，相同优先级的按轮转式进行调度。优先级高 的进程使用的时间片也长。调度程序总是选择时间片未用尽且优先级最高的进程运行。这句话就是说用户和系统可以通过设置进程的优先级来响应系统的调度。基于此，linux设计上一套动态优先级的调度方法。一开始，先为进程设置一个基本的优先级，然而它允许调度程序根据需要来加减优先级。linux内核提供了两组独立的优先级范围。第一种是nice值，范围从-20到19，默认为0。nice值越大优先级越小。另外nice值也用来决定分配给进程时间片的长短。linux下通过命令可以查看进程对应nice值，如下：12345678910111213141516171819$ ps -elF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 725 ? ? 00:00:01 init 1 S 0 2 0 0 80 0 - 0 ? ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 ? ? 00:00:01 migration/0 1 S 0 4 2 0 80 0 - 0 ? ? 00:00:00 ksoftirqd/0 1 S 0 9 2 0 80 0 - 0 ? ? 00:00:00 ksoftirqd/1......1 S 0 39 2 0 85 5 - 0 ? ? 00:00:00 ksmd ......1 S 0 156 2 0 75 -5 - 0 ? ? 00:00:00 kslowd000 1 S 0 157 2 0 75 -5 - 0 ? ? 00:00:00 kslowd001 ...... 4 S 499 2951 1 0 81 1 - 6276 ? ? 00:00:00 rtkit-daemon ...... 第二种范围是实时优先级，默认范围是从0到99。任何实时的优先级都高于普通优先级。 进程执行时，它会根据具体情况改变状态，进程状态是调度和对换的依据。Linux 将进程状态分为五种： TASK_RUNNING 、TASK_INTERRUPTIBLE 、TASK_UNINTERRUPTIBLE、TASK_STOPPED和TASK_ZOMBILE。进程的状态随着进程的调度发生改变 。 状态 TASK_RUNNING 可运行 TASK_INTERRUPTIBLE 可中断的等待状态 TASK_UNINTERRUPTIBLE 不可中断的等待状态 TASK_STOPPED 停止状态 TASK_TRACED 被跟踪状态 TASK_RUNNING （运行）：无论进程是否正在占用 CPU ，只要具备运行条件，都处于该状态。 Linux 把处于该状态的所有 PCB 组织成一个可运行队列 run_queue ，调度程序从这个队列中选择进程运行。事实上， Linux 是将就绪态和运行态合并为了一种状态。 TASK_INTERRUPTIBLE （可中断阻塞）： Linux 将阻塞态划分成 TASK_INTERRUPTIBLE 、 TASK_UNINTERRUPTIBLE 、 TASK_STOPPED 三种不同的状态。处于 TASK_INTERRUPTIBLE 状态的进程在资源有效时被唤醒，也可以通过信号或定时中断唤醒。 TASK_UNINTERRUPTIBLE （不可中断阻塞）：另一种阻塞状态，处于该状态的进程只有当资源有效时被唤醒，不能通过信号或定时中断唤醒。在执行ps命令时，进程状态为D且不能被杀死。 TASK_STOPPED （停止）：第三种阻塞状态，处于该状态的进程只能通过其他进程的信号才能唤醒。 TASK_TRACED （被跟踪）：进程正在被另一个进程监视，比如在调试的时候。 我们在设置这些状态的时候是可以直接用语句进行的比如：p—&gt;state = TASK_RUNNING。同时内核也会使用set_task_state()和set_current_state()函数来进行。 Linux调度器是以模块方式提供的，这样允许不同类型的进程可以有针对性地选择调度算法。完全公平调度（CFS）是针对普通进程的调度类，CFS采用的方法是对时间片分配方式进行根本性的重新设计，完全摒弃时间片而是分配给进程一个处理器使用比重。通过这种方式，CFS确保了进程调度中能有恒定的公平性，而将切换频率置于不断变动之中。 与Linux 2.6之前调度器不同，2.6版本内核的CFS没有将任务维护在链表式的运行队列中，它抛弃了active/expire数组，而是对每个CPU维护一个以时间为顺序的红黑树。该树方法能够良好运行的原因在于： 红黑树可以始终保持平衡，这意味着树上没有路径比任何其他路径长两倍以上。 由于红黑树是二叉树，查找操作的时间复杂度为O(log n)。但是除了最左侧查找以外，很难执行其他查找，并且最左侧的节点指针始终被缓存。 对于大多数操作（插入、删除、查找等），红黑树的执行时间为O(log n)，而以前的调度程序通过具有固定优先级的优先级数组使用 O(1)。O(log n) 行为具有可测量的延迟，但是对于较大的任务数无关紧要。Molnar在尝试这种树方法时，首先对这一点进行了测试。 红黑树可通过内部存储实现，即不需要使用外部分配即可对数据结构进行维护。 要实现平衡，CFS使用“虚拟运行时”表示某个任务的时间量。任务的虚拟运行时越小，意味着任务被允许访问服务器的时间越短，其对处理器的需求越高。 CFS还包含睡眠公平概念以便确保那些目前没有运行的任务（例如，等待 I/O）在其最终需要时获得相当份额的处理器。由于篇幅原因，这里不详细讲解CFS的实现。 对于实时进程， Linux 采用了两种调度策略，即先来先服务调度（ First-In, First-Out ， FIFO ）和时间片轮转调度（ Round Robin ， RR ）。因为实时进程具有一定程度的紧迫性，所以衡量一个实时进程是否应该运行， Linux 采用了一个比较固定的标准。 下面是调度相关的一些数据结构：调度实体：struct sched_entity12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364struct sched_entity &#123; struct load_weight load; /* for load-balancing */ struct rb_node run_node; struct list_head group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 last_wakeup; u64 avg_overlap; u64 nr_migrations; u64 start_runtime; u64 avg_wakeup; u64 avg_running; #ifdef CONFIG_SCHEDSTATS u64 wait_start; u64 wait_max; u64 wait_count; u64 wait_sum; u64 iowait_count; u64 iowait_sum; u64 sleep_start; u64 sleep_max; s64 sum_sleep_runtime; u64 block_start; u64 block_max; u64 exec_max; u64 slice_max; u64 nr_migrations_cold; u64 nr_failed_migrations_affine; u64 nr_failed_migrations_running; u64 nr_failed_migrations_hot; u64 nr_forced_migrations; u64 nr_forced2_migrations; u64 nr_wakeups; u64 nr_wakeups_sync; u64 nr_wakeups_migrate; u64 nr_wakeups_local; u64 nr_wakeups_remote; u64 nr_wakeups_affine; u64 nr_wakeups_affine_attempts; u64 nr_wakeups_passive; u64 nr_wakeups_idle;#endif #ifdef CONFIG_FAIR_GROUP_SCHED struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq &quot;owned&quot; by this entity/group: */ struct cfs_rq *my_q;#endif&#125;; 该结构在./linux/include/linux/sched.h中，表示一个可调度实体（进程，进程组，等等）。它包含了完整的调度信息，用于实现对单个任务或任务组的调度。调度实体可能与进程没有关联。这里包括负载权重load、对应的红黑树结点run_node、虚拟运行时vruntime（表示进程的运行时间，并作为红黑树的索引）、开始执行时间、最后唤醒时间、各种统计数据、用于组调度的CFS运行队列信息cfs_rq，等等。 调度类：struct sched_class该调度类也在sched.h中，是对调度器操作的面向对象抽象，协助内核调度程序的各种工作。调度类是调度器管理器的核心，每种调度算法模块需要实现struct sched_class建议的一组函数。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051struct sched_class &#123; const struct sched_class *next; void (*enqueue_task) (struct rq *rq, struct task_struct *p, int wakeup); void (*dequeue_task) (struct rq *rq, struct task_struct *p, int sleep); void (*yield_task) (struct rq *rq); void (*check_preempt_curr) (struct rq *rq, struct task_struct *p, int flags); struct task_struct * (*pick_next_task) (struct rq *rq); void (*put_prev_task) (struct rq *rq, struct task_struct *p); #ifdef CONFIG_SMP int (*select_task_rq)(struct task_struct *p, int sd_flag, int flags); unsigned long (*load_balance) (struct rq *this_rq, int this_cpu, struct rq *busiest, unsigned long max_load_move, struct sched_domain *sd, enum cpu_idle_type idle, int *all_pinned, int *this_best_prio); int (*move_one_task) (struct rq *this_rq, int this_cpu, struct rq *busiest, struct sched_domain *sd, enum cpu_idle_type idle); void (*pre_schedule) (struct rq *this_rq, struct task_struct *task); void (*post_schedule) (struct rq *this_rq); void (*task_wake_up) (struct rq *this_rq, struct task_struct *task); void (*set_cpus_allowed)(struct task_struct *p, const struct cpumask *newmask); void (*rq_online)(struct rq *rq); void (*rq_offline)(struct rq *rq);#endif void (*set_curr_task) (struct rq *rq); void (*task_tick) (struct rq *rq, struct task_struct *p, int queued); void (*task_new) (struct rq *rq, struct task_struct *p); void (*switched_from) (struct rq *this_rq, struct task_struct *task, int running); void (*switched_to) (struct rq *this_rq, struct task_struct *task, int running); void (*prio_changed) (struct rq *this_rq, struct task_struct *task, int oldprio, int running); unsigned int (*get_rr_interval) (struct task_struct *task); #ifdef CONFIG_FAIR_GROUP_SCHED void (*moved_group) (struct task_struct *p);#endif&#125;; 其中的主要函数： enqueue_task：当某个任务进入可运行状态时，该函数将得到调用。它将调度实体（进程）放入红黑树中，并对 nr_running 变量加 1。从前面“Linux进程管理”的分析中可知，进程创建的最后会调用该函数。 dequeue_task：当某个任务退出可运行状态时调用该函数，它将从红黑树中去掉对应的调度实体，并从 nr_running 变量中减 1。 yield_task：在 compat_yield sysctl 关闭的情况下，该函数实际上执行先出队后入队；在这种情况下，它将调度实体放在红黑树的最右端。 check_preempt_curr：该函数将检查当前运行的任务是否被抢占。在实际抢占正在运行的任务之前，CFS 调度程序模块将执行公平性测试。这将驱动唤醒式（wakeup）抢占。 pick_next_task：该函数选择接下来要运行的最合适的进程。 load_balance：每个调度程序模块实现两个函数，load_balance_start() 和 load_balance_next()，使用这两个函数实现一个迭代器，在模块的load_balance例程中调用。内核调度程序使用这种方法实现由调度模块管理的进程的负载平衡。 set_curr_task：当任务修改其调度类或修改其任务组时，将调用这个函数。 task_tick：该函数通常调用自 time tick 函数；它可能引起进程切换。这将驱动运行时（running）抢占。 调度类的引入是接口和实现分离的设计典范，你可以实现不同的调度算法（例如普通进程和实时进程的调度算法就不一样），但由于有统一的接口，使得调度策略 被模块化，一个Linux调度程序可以有多个不同的调度策略。调度类显著增强了内核调度程序的可扩展性。每个任务都属于一个调度类，这决定了任务将如何调 度。 调度类定义一个通用函数集，函数集定义调度器的行为。例如，每个调度器提供一种方式，添加要调度的任务、调出要运行的下一个任务、提供给调度器等等。每个 调度器类都在一对一连接的列表中彼此相连，使类可以迭代（例如， 要启用给定处理器的禁用）。注意，将任务函数加入队列或脱离队列只需从特定调度结构中加入或移除任务。 核心函数 pick_next_task 选择要执行的下一个任务（取决于调度类的具体策略）。 sched_rt.c, sched_fair.c, sched_idletask.c等（都在kernel/目录下）就是不同的调度算法实现。不要忘了调度类是任务结构本身的一部分（参见 task_struct）。这一点简化了任务的操作，无论其调度类如何。因为进程描述符中有sched_class引用，这样就可以直接通过进程描述符来 调用调度类中的各种操作。在调度类中，随着调度域的增加，其功能也在增加。 这些域允许您出于负载平衡和隔离的目的将一个或多个处理器按层次关系分组。 一个或多个处理器能够共享调度策略（并在其之间保持负载平衡），或实现独立的调度策略。 可运行队列：struct rq调度程序每次在进程发生切换时，都要从可运行队列中选取一个最佳的进程来运行。Linux内核使用rq数据结构（以前的内核中该结构为 runqueue）表示一个可运行队列信息（也就是就绪队列），每个CPU都有且只有一个这样的结构。该结构在kernel/sched.c中，不仅描述 了每个处理器中处于可运行状态（TASK_RUNNING），而且还描述了该处理器的调度信息。如下：12345678910111213141516171819202122232425262728293031323334struct rq &#123; /* runqueue lock: */ spinlock_t lock; unsigned long nr_running; #define CPU_LOAD_IDX_MAX 5 unsigned long cpu_load[CPU_LOAD_IDX_MAX]; /* capture load from *all* tasks on this cpu: */ struct load_weight load; unsigned long nr_load_updates; u64 nr_switches; u64 nr_migrations_in; struct cfs_rq cfs; struct rt_rq rt; unsigned long nr_uninterruptible; struct task_struct *curr, *idle; unsigned long next_balance; struct mm_struct *prev_mm; u64 clock; atomic_t nr_iowait; /* calc_load related fields */ unsigned long calc_load_update; long calc_load_active; ......&#125;; 进程调度的入口点是函数schedule()，该函数调用pick_next_task()，pick_next_task()会以优先级为序，从高到低，一次检查每一个调度类，且从最高优先级的调度类中，选择最高优先级的进程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899asmlinkage void __sched schedule(void)&#123; struct task_struct *prev, *next; unsigned long *switch_count; struct rq *rq; int cpu; need_resched: preempt_disable(); cpu = smp_processor_id(); rq = cpu_rq(cpu); rcu_sched_qs(cpu); prev = rq-&gt;curr; switch_count = &amp;prev-&gt;nivcsw; release_kernel_lock(prev);need_resched_nonpreemptible: schedule_debug(prev); if (sched_feat(HRTICK)) hrtick_clear(rq); spin_lock_irq(&amp;rq-&gt;lock); update_rq_clock(rq); clear_tsk_need_resched(prev); if (prev-&gt;state &amp;&amp; !(preempt_count() &amp; PREEMPT_ACTIVE)) &#123; if (unlikely(signal_pending_state(prev-&gt;state, prev))) prev-&gt;state = TASK_RUNNING; else deactivate_task(rq, prev, 1); switch_count = &amp;prev-&gt;nvcsw; &#125; pre_schedule(rq, prev); if (unlikely(!rq-&gt;nr_running)) idle_balance(cpu, rq); put_prev_task(rq, prev); &lt;strong&gt;next = pick_next_task(rq); //&lt;span&gt;&lt;span&gt;&lt;span style=&quot;font-size:14px;&quot;&gt;//挑选最高优先级别的任务&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; if (likely(prev != next)) &#123; sched_info_switch(prev, next); perf_event_task_sched_out(prev, next, cpu); rq-&gt;nr_switches++; rq-&gt;curr = next; ++*switch_count; context_switch(rq, prev, next); /* unlocks the rq */ /* * the context switch might have flipped the stack from under * us, hence refresh the local variables. */ cpu = smp_processor_id(); rq = cpu_rq(cpu); &#125; else spin_unlock_irq(&amp;rq-&gt;lock); post_schedule(rq); if (unlikely(reacquire_kernel_lock(current) &lt; 0)) goto need_resched_nonpreemptible; preempt_enable_no_resched(); if (need_resched()) goto need_resched;&#125;static inline struct task_struct *pick_next_task(struct rq *rq)&#123; const struct sched_class *class; struct task_struct *p; /* * Optimization: we know that if all tasks are in * the fair class we can call that function directly: */ if (likely(rq-&gt;nr_running == rq-&gt;cfs.nr_running)) &#123; p = fair_sched_class.pick_next_task(rq); if (likely(p)) return p; &#125;//从最高优先级类开始，遍历每一个调度类。每一个调度类都实现了pick_next_task，他会返回指向下一个可运行进程的指针，没有时返回NULL。 class = sched_class_highest; for ( ; ; ) &#123; p = class-&gt;pick_next_task(rq); if (p) return p; /* * Will never be NULL as the idle class always * returns a non-NULL p: */ class = class-&gt;next; &#125;&#125; 被阻塞（休眠）的进程处于不可执行状态，是不能被调度的。进程休眠一般是由于等待一些事件，内核首先把自己标记成休眠状态，从可执行红黑树中移出，放入等待队列，然后调用schedule()选择和执行一个其他进程。唤醒的过程刚好相反，进程设置为可执行状态，然后从等待队列中移到可执行红黑树中。 等待队列是由等待某些事件发生的进程组成的简单链表。内核用wake_queue_head_t来代表队列。进程把自己放入等待队列中并设置成不可执状态。当等待队列相关事件发生时，队列上进程会被唤醒。函数inotify_read()是实现等待队列的一个典型用法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static ssize_t inotify_read(struct file *file, char __user *buf, size_t count, loff_t *pos)&#123; struct fsnotify_group *group; struct fsnotify_event *kevent; char __user *start; int ret; DEFINE_WAIT(wait); start = buf; group = file-&gt;private_data; while (1) &#123; //进程的状态变更为TASK_INTERRUPTIBLE或TASK_UNINTERRUPTIBLE。 prepare_to_wait(&amp;group-&gt;notification_waitq, &amp;wait, TASK_INTERRUPTIBLE); mutex_lock(&amp;group-&gt;notification_mutex); kevent = get_one_event(group, count); mutex_unlock(&amp;group-&gt;notification_mutex); if (kevent) &#123; ret = PTR_ERR(kevent); if (IS_ERR(kevent)) break; ret = copy_event_to_user(group, kevent, buf); fsnotify_put_event(kevent); if (ret &lt; 0) break; buf += ret; count -= ret; continue; &#125; ret = -EAGAIN; if (file-&gt;f_flags &amp; O_NONBLOCK) break; ret = -EINTR; if (signal_pending(current)) break; if (start != buf) break; schedule(); &#125; finish_wait(&amp;group-&gt;notification_waitq, &amp;wait); if (start != buf &amp;&amp; ret != -EFAULT) ret = buf - start; return ret;&#125; 唤醒是通过wake_up()进行。她唤醒指定的等待队列上 的所有进程。它调用try_to_wake_up,该函数负责将进程设置为TASK_RUNNING状态，调用active_task()将此进程放入可 执行队列，如果被唤醒进程的优先级比当前正在执行的进程的优先级高，还要设置need_resched标志。 上下文切换，就是从一个可执行进程切换到另一个可执行进程，由定义在kernel/sched.c的context_switch函数负责处理。每当一个新的进程被选出来准备投入运行的时候，schedule就会调用该函数。它主要完成如下两个工作： 调用定义在include/asm/mmu_context.h中的switch_mm()。该函数负责把虚拟内存从上一个进程映射切换到新进程中。 调用定义在include/asm/system.h的switch_to()，该函数负责从上一个进程的处理器状态切换到新进程的处理器状态，这包括保存，恢复栈信息和寄存器信息。 内核也必须知道什么时候调用schedule(),单靠用户 代码显示调用schedule(),他们可能就会永远地执行下去，相反，内核提供了一个need_resched标志来表明是否需要重新执行一次调度。当 某个进程耗尽它的时间片时，scheduler_tick()就会设置这个标志，当一个优先级高的进程进入可执行状态的时 候，try_to_wake_up()也会设置这个标志。内核检查该标志，确认其被设置，调用schedule()来切换到一个新的进程。该标志对内核来讲是一个信息，它表示应当有其他进程应当被运行了。 用于访问和操作need_resched的函数： set_tsk_need_resched(task) 设置指定进程中的need_resched标志clear_tsk_need_resched(task) 清除指定进程中的nedd_resched标志need_resched() 检查need_resched标志的值，如果被设置就返回真，否则返回 再返回用户空间以及从中断返回的时候，内核也会检查 need_resched标志，如果已被设置，内核会在继续执行之前调用该调度程序。最后，每个进程都包含一个need_resched标志，这是因为访 问进程描述符内的数值要比访问一个全局变量要快(因为current宏速度很快并且描述符通常都在高速缓存中)。在2.6内核中，他被移到了 thread_info结构体里。 用户抢占发生在一下情况： 从系统调用返回时； 从终端处理程序返回用户空间时。 内核抢占发生在: 中断处理正在执行，且返回内核空间前； 内核代码再一次具有可抢占性的时候； 内核任务显示调用schedule()函数； 内核中的任务阻塞的时候。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（八）：进程管理分析]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 进程其实就是程序的执行时的实例，是处于执行期的程序。在linux内核中，进程列表被存放在一个双向循环链表中，链表中每一项都是类型为task_struct的结构，该结构称作进程描述符，进程描述符包含一个具体进程的所有信息，这个结构就是我们在操作系统中所说的PCB（Process Control Block）。该结构定义于&lt;include/linux/sched.h&gt;文件中：12345678910111213141516171819202122 struct task_struct &#123; volatile long state; /* -1 unrunnable, 0 runnable, &gt;0 stopped */ void *stack; atomic_t usage; unsigned int flags; /* per process flags, defined below */ unsigned int ptrace; int lock_depth; /* BKL lock depth */ ...... int prio, static_prio, normal_prio; unsigned int rt_priority; const struct sched_class *sched_class; struct sched_entity se; struct sched_rt_entity rt; ...... struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */ struct list_head children; /* list of my children */ struct list_head sibling; /* linkage in my parent&apos;s children list */ ......&#125;; 该结构体中包含的数据可以完整的描述一个正在执行的程序：打开的文件、进程的地址空间、挂起的信号、进程的状态、以及其他很多信息。\ 在系统运行过程中，进程频繁切换，所以我们需要一种方式能够快速获得当前进程的task_struct，于是进程内核堆栈底部存放着struct thread_info。该结构中有一个成员指向当前进程的task_struct。在x86上，struct thread_info在文件&lt;arch/x86/include/asm/thread_info.h&gt;中定义：12345678910111213141516171819 struct thread_info &#123; struct task_struct *task; /* 该指针存放的是指向该任务实际task_struct的指针 */ struct exec_domain *exec_domain; /* execution domain */ __u32 flags; /* low level flags */ __u32 status; /* thread synchronous flags */ __u32 cpu; /* current CPU */ int preempt_count; /* 0 =&gt; preemptable, &lt;0 =&gt; BUG */ mm_segment_t addr_limit; struct restart_block restart_block; void __user *sysenter_return;#ifdef CONFIG_X86_32 unsigned long previous_esp; /* ESP of the previous stack in case of nested (IRQ) stacks */ __u8 supervisor_stack[0];#endif int uaccess_err;&#125;; 使用current宏就可以获得当前进程的进程描述符。 每一个进程都有一个父进程，每个进程管理自己的子进程。每个进程都是init进程的子进程，init进程在内 核系统启动的最后阶段启动init进程，该进程读取系统的初始化脚本并执行其他相关程序，最终完成系统启动的整个过程。每个进程有0个或多个子进程，进程间的关系存放在进程描述符中。task_struct中有一个parent的指针，指向其父进程；还有个children的指针指向其子进程的链表。所以，对于当前进程，可以通过current宏来获得父进程和子进程的进程描述符。下面程序打印当前进程、父进程信息和所有子进程信息：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;linux/module.h&gt; #include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt; #include &lt;linux/sched.h&gt; void sln_taskstruct_do(void)&#123; struct task_struct *cur, *parent, *task; struct list_head *first_child, *child_list, *cur_chd; //获取当前进程信息 cur = current; printk(KERN_ALERT&quot;Current: %s[%d]\n&quot;, cur-&gt;comm, cur-&gt;pid); //获取父进程信息 parent = current-&gt;parent; printk(KERN_ALERT&quot;Parent: %s[%d]\n&quot;, parent-&gt;comm, parent-&gt;pid); //获取所有祖先进程信息 for (task = cur; task != &amp;init_task; task = task-&gt;parent) &#123; printk(KERN_ALERT&quot;ancestor: %s[%d]\n&quot;, task-&gt;comm, task-&gt;pid); &#125; //获取所有子进程信息 child_list = &amp;cur-&gt;children; first_child = &amp;cur-&gt;children; for (cur_chd = child_list-&gt;next; cur_chd != first_child; cur_chd = cur_chd-&gt;next) &#123; task = list_entry(child_list, struct task_struct, sibling); printk(KERN_ALERT&quot;Children: %s[%d]\n&quot;, task-&gt;comm, task-&gt;pid); &#125; &#125; static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_taskstruct_do(); return 0;&#125; static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__);&#125; module_init(sln_init);module_exit(sln_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 执行结果如下：12345678 # insmod task.ko===sln_init===Current: insmod[4315]Parent: bash[4032]ancestor: insmod[4315]ancestor: bash[4032]ancestor: login[2563]ancestor: init[1] linux操作系统提供产生进程的机制，在Linux下的fork()使用写时拷贝(copy-on-write)页实现。这种技术原理是：内存并不复制整个进程地址空间，而是让父进程和子进程共享同一拷贝，只有在需要写入的时候，数据才会被复制。也就是资源的复制只是发生在需要写入的时候才进行，在此之前都是以只读的方式共享。 linux通过clone()系统调用实现fork()，然后clone()去调用do_fork()，do_fork()完成创建中大部分工作。库函数vfork()、__clone()都根据各自需要的参数标志去调用clone()。fork()的实际开销就是复制父进程的页表以及给子进程创建唯一的进程描述符。用户空间的fork()经过系统调用进入内核，在内核中对应的处理函数为sys_fork()，定义于&lt;arch/x86/kernel/process.c&gt;文件中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354int sys_fork(struct pt_regs *regs) &#123; return do_fork(SIGCHLD, regs-&gt;sp, regs, 0, NULL, NULL);&#125; long do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr)&#123; struct task_struct *p; int trace = 0; long nr; ...... p = copy_process(clone_flags, stack_start, regs, stack_size, child_tidptr, NULL, trace); ...... return nr;&#125; static struct task_struct *copy_process(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace)&#123; int retval; struct task_struct *p; int cgroup_callbacks_done = 0; if ((clone_flags &amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS)) return ERR_PTR(-EINVAL); /* * Thread groups must share signals as well, and detached threads * can only be started up within the thread group. */ if ((clone_flags &amp; CLONE_THREAD) &amp;&amp; !(clone_flags &amp; CLONE_SIGHAND)) return ERR_PTR(-EINVAL); /* * Shared signal handlers imply shared VM. By way of the above, * thread groups also imply shared VM. Blocking this case allows * for various simplifications in other code. */ if ((clone_flags &amp; CLONE_SIGHAND) &amp;&amp; !(clone_flags &amp; CLONE_VM)) return ERR_PTR(-EINVAL); /* * Siblings of global init remain as zombies on exit since they are * not reaped by their parent (swapper). To solve this and to avoid * multi-rooted process trees, prevent global and container-inits * from creating siblings. */ if ((clone_flags &amp; CLONE_PARENT) &amp;&amp; current-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE) return ERR_PTR(-EINVAL); retval = security_task_create(clone_flags); if (retval) goto fork_out; retval = -ENOMEM; p = dup_task_struct(current); if (!p) goto fork_out; ftrace_graph_init_task(p); rt_mutex_init_task(p);#ifdef CONFIG_PROVE_LOCKING DEBUG_LOCKS_WARN_ON(!p-&gt;hardirqs_enabled); DEBUG_LOCKS_WARN_ON(!p-&gt;softirqs_enabled);#endif retval = -EAGAIN; if (atomic_read(&amp;p-&gt;real_cred-&gt;user-&gt;processes) &gt;= p-&gt;signal-&gt;rlim[RLIMIT_NPROC].rlim_cur) &#123; if (!capable(CAP_SYS_ADMIN) &amp;&amp; !capable(CAP_SYS_RESOURCE) &amp;&amp; p-&gt;real_cred-&gt;user != INIT_USER) goto bad_fork_free; &#125; retval = copy_creds(p, clone_flags); if (retval &lt; 0) goto bad_fork_free; /* * If multiple threads are within copy_process(), then this check * triggers too late. This doesn&apos;t hurt, the check is only there * to stop root fork bombs. */ retval = -EAGAIN; if (nr_threads &gt;= max_threads) goto bad_fork_cleanup_count; if (!try_module_get(task_thread_info(p)-&gt;exec_domain-&gt;module)) goto bad_fork_cleanup_count; p-&gt;did_exec = 0; delayacct_tsk_init(p); /* Must remain after dup_task_struct() */ copy_flags(clone_flags, p); INIT_LIST_HEAD(&amp;p-&gt;children); INIT_LIST_HEAD(&amp;p-&gt;sibling); rcu_copy_process(p); p-&gt;vfork_done = NULL; spin_lock_init(&amp;p-&gt;alloc_lock); init_sigpending(&amp;p-&gt;pending); p-&gt;utime = cputime_zero; p-&gt;stime = cputime_zero; p-&gt;gtime = cputime_zero; p-&gt;utimescaled = cputime_zero; p-&gt;stimescaled = cputime_zero; p-&gt;prev_utime = cputime_zero; p-&gt;prev_stime = cputime_zero; p-&gt;default_timer_slack_ns = current-&gt;timer_slack_ns; task_io_accounting_init(&amp;p-&gt;ioac); acct_clear_integrals(p); posix_cpu_timers_init(p); p-&gt;lock_depth = -1; /* -1 = no lock */ do_posix_clock_monotonic_gettime(&amp;p-&gt;start_time); p-&gt;real_start_time = p-&gt;start_time; monotonic_to_bootbased(&amp;p-&gt;real_start_time); p-&gt;io_context = NULL; p-&gt;audit_context = NULL; cgroup_fork(p);#ifdef CONFIG_NUMA p-&gt;mempolicy = mpol_dup(p-&gt;mempolicy); if (IS_ERR(p-&gt;mempolicy)) &#123; retval = PTR_ERR(p-&gt;mempolicy); p-&gt;mempolicy = NULL; goto bad_fork_cleanup_cgroup; &#125; mpol_fix_fork_child_flag(p);#endif#ifdef CONFIG_TRACE_IRQFLAGS p-&gt;irq_events = 0;#ifdef __ARCH_WANT_INTERRUPTS_ON_CTXSW p-&gt;hardirqs_enabled = 1;#else p-&gt;hardirqs_enabled = 0;#endif p-&gt;hardirq_enable_ip = 0; p-&gt;hardirq_enable_event = 0; p-&gt;hardirq_disable_ip = _THIS_IP_; p-&gt;hardirq_disable_event = 0; p-&gt;softirqs_enabled = 1; p-&gt;softirq_enable_ip = _THIS_IP_; p-&gt;softirq_enable_event = 0; p-&gt;softirq_disable_ip = 0; p-&gt;softirq_disable_event = 0; p-&gt;hardirq_context = 0; p-&gt;softirq_context = 0;#endif#ifdef CONFIG_LOCKDEP p-&gt;lockdep_depth = 0; /* no locks held yet */ p-&gt;curr_chain_key = 0; p-&gt;lockdep_recursion = 0;#endif#ifdef CONFIG_DEBUG_MUTEXES p-&gt;blocked_on = NULL; /* not blocked yet */#endif p-&gt;bts = NULL; p-&gt;stack_start = stack_start; /* Perform scheduler related setup. Assign this task to a CPU. */ sched_fork(p, clone_flags); retval = perf_event_init_task(p); if (retval) goto bad_fork_cleanup_policy; if ((retval = audit_alloc(p))) goto bad_fork_cleanup_policy; /* copy all the process information */ if ((retval = copy_semundo(clone_flags, p))) goto bad_fork_cleanup_audit; if ((retval = copy_files(clone_flags, p))) goto bad_fork_cleanup_semundo; if ((retval = copy_fs(clone_flags, p))) goto bad_fork_cleanup_files; if ((retval = copy_sighand(clone_flags, p))) goto bad_fork_cleanup_fs; if ((retval = copy_signal(clone_flags, p))) goto bad_fork_cleanup_sighand; if ((retval = copy_mm(clone_flags, p))) goto bad_fork_cleanup_signal; if ((retval = copy_namespaces(clone_flags, p))) goto bad_fork_cleanup_mm; if ((retval = copy_io(clone_flags, p))) goto bad_fork_cleanup_namespaces; retval = copy_thread(clone_flags, stack_start, stack_size, p, regs); if (retval) goto bad_fork_cleanup_io; if (pid != &amp;init_struct_pid) &#123; retval = -ENOMEM; pid = alloc_pid(p-&gt;nsproxy-&gt;pid_ns); if (!pid) goto bad_fork_cleanup_io; if (clone_flags &amp; CLONE_NEWPID) &#123; retval = pid_ns_prepare_proc(p-&gt;nsproxy-&gt;pid_ns); if (retval &lt; 0) goto bad_fork_free_pid; &#125; &#125; p-&gt;pid = pid_nr(pid); p-&gt;tgid = p-&gt;pid; if (clone_flags &amp; CLONE_THREAD) p-&gt;tgid = current-&gt;tgid; if (current-&gt;nsproxy != p-&gt;nsproxy) &#123; retval = ns_cgroup_clone(p, pid); if (retval) goto bad_fork_free_pid; &#125; p-&gt;set_child_tid = (clone_flags &amp; CLONE_CHILD_SETTID) ? child_tidptr : NULL; /* * Clear TID on mm_release()? */ p-&gt;clear_child_tid = (clone_flags &amp; CLONE_CHILD_CLEARTID) ? child_tidptr: NULL;#ifdef CONFIG_FUTEX p-&gt;robust_list = NULL;#ifdef CONFIG_COMPAT p-&gt;compat_robust_list = NULL;#endif INIT_LIST_HEAD(&amp;p-&gt;pi_state_list); p-&gt;pi_state_cache = NULL;#endif /* * sigaltstack should be cleared when sharing the same VM */ if ((clone_flags &amp; (CLONE_VM|CLONE_VFORK)) == CLONE_VM) p-&gt;sas_ss_sp = p-&gt;sas_ss_size = 0; /* * Syscall tracing should be turned off in the child regardless * of CLONE_PTRACE. */ clear_tsk_thread_flag(p, TIF_SYSCALL_TRACE);#ifdef TIF_SYSCALL_EMU clear_tsk_thread_flag(p, TIF_SYSCALL_EMU);#endif clear_all_latency_tracing(p); /* ok, now we should be set up.. */ p-&gt;exit_signal = (clone_flags &amp; CLONE_THREAD) ? -1 : (clone_flags &amp; CSIGNAL); p-&gt;pdeath_signal = 0; p-&gt;exit_state = 0; /* * Ok, make it visible to the rest of the system. * We dont wake it up yet. */ p-&gt;group_leader = p; INIT_LIST_HEAD(&amp;p-&gt;thread_group); /* Now that the task is set up, run cgroup callbacks if * necessary. We need to run them before the task is visible * on the tasklist. */ cgroup_fork_callbacks(p); cgroup_callbacks_done = 1; /* Need tasklist lock for parent etc handling! */ write_lock_irq(&amp;tasklist_lock); /* * The task hasn&apos;t been attached yet, so its cpus_allowed mask will * not be changed, nor will its assigned CPU. * * The cpus_allowed mask of the parent may have changed after it was * copied first time - so re-copy it here, then check the child&apos;s CPU * to ensure it is on a valid CPU (and if not, just force it back to * parent&apos;s CPU). This avoids alot of nasty races. */ p-&gt;cpus_allowed = current-&gt;cpus_allowed; p-&gt;rt.nr_cpus_allowed = current-&gt;rt.nr_cpus_allowed; if (unlikely(!cpu_isset(task_cpu(p), p-&gt;cpus_allowed) || !cpu_online(task_cpu(p)))) set_task_cpu(p, smp_processor_id()); /* CLONE_PARENT re-uses the old parent */ if (clone_flags &amp; (CLONE_PARENT|CLONE_THREAD)) &#123; p-&gt;real_parent = current-&gt;real_parent; p-&gt;parent_exec_id = current-&gt;parent_exec_id; &#125; else &#123; p-&gt;real_parent = current; p-&gt;parent_exec_id = current-&gt;self_exec_id; &#125; spin_lock(¤t-&gt;sighand-&gt;siglock); /* * Process group and session signals need to be delivered to just the * parent before the fork or both the parent and the child after the * fork. Restart if a signal comes in before we add the new process to * it&apos;s process group. * A fatal signal pending means that current will exit, so the new * thread can&apos;t slip out of an OOM kill (or normal SIGKILL). */ recalc_sigpending(); if (signal_pending(current)) &#123; spin_unlock(¤t-&gt;sighand-&gt;siglock); write_unlock_irq(&amp;tasklist_lock); retval = -ERESTARTNOINTR; goto bad_fork_free_pid; &#125; if (clone_flags &amp; CLONE_THREAD) &#123; atomic_inc(¤t-&gt;signal-&gt;count); atomic_inc(¤t-&gt;signal-&gt;live); p-&gt;group_leader = current-&gt;group_leader; list_add_tail_rcu(&amp;p-&gt;thread_group, &amp;p-&gt;group_leader-&gt;thread_group); &#125; if (likely(p-&gt;pid)) &#123; list_add_tail(&amp;p-&gt;sibling, &amp;p-&gt;real_parent-&gt;children); tracehook_finish_clone(p, clone_flags, trace); if (thread_group_leader(p)) &#123; if (clone_flags &amp; CLONE_NEWPID) p-&gt;nsproxy-&gt;pid_ns-&gt;child_reaper = p; p-&gt;signal-&gt;leader_pid = pid; tty_kref_put(p-&gt;signal-&gt;tty); p-&gt;signal-&gt;tty = tty_kref_get(current-&gt;signal-&gt;tty); attach_pid(p, PIDTYPE_PGID, task_pgrp(current)); attach_pid(p, PIDTYPE_SID, task_session(current)); list_add_tail_rcu(&amp;p-&gt;tasks, &amp;init_task.tasks); __get_cpu_var(process_counts)++; &#125; attach_pid(p, PIDTYPE_PID, pid); nr_threads++; &#125; total_forks++; spin_unlock(¤t-&gt;sighand-&gt;siglock); write_unlock_irq(&amp;tasklist_lock); proc_fork_connector(p); cgroup_post_fork(p); perf_event_fork(p); return p;bad_fork_free_pid: if (pid != &amp;init_struct_pid) free_pid(pid);bad_fork_cleanup_io: put_io_context(p-&gt;io_context);bad_fork_cleanup_namespaces: exit_task_namespaces(p);bad_fork_cleanup_mm: if (p-&gt;mm) mmput(p-&gt;mm);bad_fork_cleanup_signal: if (!(clone_flags &amp; CLONE_THREAD)) __cleanup_signal(p-&gt;signal);bad_fork_cleanup_sighand: __cleanup_sighand(p-&gt;sighand);bad_fork_cleanup_fs: exit_fs(p); /* blocking */bad_fork_cleanup_files: exit_files(p); /* blocking */bad_fork_cleanup_semundo: exit_sem(p);bad_fork_cleanup_audit: audit_free(p);bad_fork_cleanup_policy: perf_event_free_task(p);#ifdef CONFIG_NUMA mpol_put(p-&gt;mempolicy);bad_fork_cleanup_cgroup:#endif cgroup_exit(p, cgroup_callbacks_done); delayacct_tsk_free(p); module_put(task_thread_info(p)-&gt;exec_domain-&gt;module);bad_fork_cleanup_count: atomic_dec(&amp;p-&gt;cred-&gt;user-&gt;processes); exit_creds(p);bad_fork_free: free_task(p);fork_out: return ERR_PTR(retval);&#125; 上面执行完以后，回到do_fork()函数，如果copy_process()函数成功返回。新创建的子进程被唤醒并让其投入运行。内核有意选择子进程先运行。因为一般子进程都会马上调用exec()函数，这样可以避免写时拷贝的额外开销。如果父进程首先执行的话，有可能会开始向地址空间写入。 线程机制提供了在同一程序内共享内存地址空间运行的一组线程。线程机制支持并发程序设计技术，可以共享打开的文件和其他资源。如果你的系统是多核心的，那多线程技术可保证系统的真正并行。在linux中，并没有线程这个概念，linux中所有的线程都当作进程来处理，换句话说就是在内核中并没有什么特殊的结构和算法来表示线程。在linux中，线程仅仅是一个使用共享资源的进程。每个线程都拥有一个隶属于自己的task_struct。所以说线程本质上还是进程，只不过该进程可以和其他一些进程共享某些资源信息。 内核有时需要在后台执行一些操作，这种任务可以通过内核线程完成，内核线程独立运行在内核空间的标准进程。内核线程和普通的进程间的区别在于内核线程没有独立的地址空间。它们只在讷河空间运行，从来不切换到用户空间去。内核进程和普通进程一样，可以被调度，也可以被抢占。内核线程也只能由其它内核线程创建，内核是通过从kthreadd内核进程中衍生出所有新的内核线程来自动处理这一点的。在内核中创建一个的内核线程方法如下：123struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...) 该函数实现如下：12345678910111213141516171819202122232425262728struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...)&#123; struct kthread_create_info create; create.threadfn = threadfn; create.data = data; init_completion(&amp;create.done); spin_lock(&amp;kthread_create_lock); list_add_tail(&amp;create.list, &amp;kthread_create_list); spin_unlock(&amp;kthread_create_lock); wake_up_process(kthreadd_task); wait_for_completion(&amp;create.done); if (!IS_ERR(create.result)) &#123; struct sched_param param = &#123; .sched_priority = 0 &#125;; va_list args; va_start(args, namefmt); vsnprintf(create.result-&gt;comm, sizeof(create.result-&gt;comm), namefmt, args); va_end(args); /* * root may have changed our (kthreadd&apos;s) priority or CPU mask. * The kernel thread should not inherit these properties. */ sched_setscheduler_nocheck(create.result, SCHED_NORMAL, ¶m); set_cpus_allowed_ptr(create.result, cpu_all_mask); &#125; 新的任务是由kthread内核进程通过clone()系统调用而创建的。新的进程将运行threadfn函数，给其传递参数data，新的进程名称为namefmt，新创建的进程处于不可运行状态，需要调用wake_up_process()明确的唤醒它，否则它不会主动运行。也可以通过调用kthread_run()来创建一个进程并让它运行起来。12345678#define kthread_run(threadfn, data, namefmt, ...) \ (&#123; \ struct task_struct *__k \ = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__); \ if (!IS_ERR(__k)) \ wake_up_process(__k); \ __k; \&#125;) kthread_run其实就是创建了一个内核线程并且唤醒了。内核线程启动后就一直运行直到调用do_exit()退出或者内核的其他部分调用kthread_stop()退出。1int kthread_stop(struct task_struct *k); 下面为一个使用内核线程的示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;linux/module.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt;#include &lt;linux/sched.h&gt; //schdule_timeout()#include &lt;linux/kthread.h&gt;struct task_struct *sln_task;int sln_kthread_func(void *arg)&#123; while (!kthread_should_stop()) &#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); set_current_state(TASK_INTERRUPTIBLE); schedule_timeout(2*HZ); &#125; return 0;&#125;void sln_init_do(void)&#123; int data = 9527; sln_task = kthread_create(sln_kthread_func, &amp;data, &quot;sln_kthread_task&quot;); if (IS_ERR(sln_task)) &#123; printk(KERN_ALERT&quot;kthread_create() failed!\n&quot;); return; &#125; wake_up_process(sln_task);&#125;void sln_exit_do(void)&#123; if (NULL != sln_task) &#123; kthread_stop(sln_task); sln_task = NULL; &#125;&#125;static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_init_do(); return 0;&#125;static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_exit_do();&#125;module_init(sln_init);module_exit(sln_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 既然有进程的创建，那就有进程的终结，终结时内核必须释放它所占有的资源。内核终结时，大部分任务都是靠do_exit()（定义于）来完成。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109NORET_TYPE void do_exit(long code)&#123; struct task_struct *tsk = current; int group_dead; profile_task_exit(tsk); WARN_ON(atomic_read(&amp;tsk-&gt;fs_excl)); //不可在中断上下文中使用该函数 if (unlikely(in_interrupt())) panic(&quot;Aiee, killing interrupt handler!&quot;); if (unlikely(!tsk-&gt;pid)) panic(&quot;Attempted to kill the idle task!&quot;); tracehook_report_exit(&amp;code); validate_creds_for_do_exit(tsk); /* * We&apos;re taking recursive faults here in do_exit. Safest is to just * leave this task alone and wait for reboot. */ if (unlikely(tsk-&gt;flags &amp; PF_EXITING)) &#123; printk(KERN_ALERT &quot;Fixing recursive fault but reboot is needed!\n&quot;); //设置PF_EXITING:表示进程正在退出 tsk-&gt;flags |= PF_EXITPIDONE; set_current_state(TASK_UNINTERRUPTIBLE); schedule(); &#125; exit_irq_thread(); exit_signals(tsk); /* sets PF_EXITING */ /* * tsk-&gt;flags are checked in the futex code to protect against * an exiting task cleaning up the robust pi futexes. */ smp_mb(); spin_unlock_wait(&amp;tsk-&gt;pi_lock); if (unlikely(in_atomic())) printk(KERN_INFO &quot;note: %s[%d] exited with preempt_count %d\n&quot;, current-&gt;comm, task_pid_nr(current), preempt_count()); acct_update_integrals(tsk); group_dead = atomic_dec_and_test(&amp;tsk-&gt;signal-&gt;live); if (group_dead) &#123; hrtimer_cancel(&amp;tsk-&gt;signal-&gt;real_timer); exit_itimers(tsk-&gt;signal); if (tsk-&gt;mm) setmax_mm_hiwater_rss(&amp;tsk-&gt;signal-&gt;maxrss, tsk-&gt;mm); &#125; acct_collect(code, group_dead); if (group_dead) tty_audit_exit(); if (unlikely(tsk-&gt;audit_context)) audit_free(tsk); tsk-&gt;exit_code = code; taskstats_exit(tsk, group_dead); //调用__exit_mm()函数放弃进程占用的mm_struct,如果没有别的进程使用它们即没被共享，就彻底释放它们 exit_mm(tsk); if (group_dead) acct_process(); trace_sched_process_exit(tsk); exit_sem(tsk); //调用sem_exit()函数。如果进程排队等候IPC信号，它则离开队列 //分别递减文件描述符，文件系统数据等的引用计数。当引用计数的值为0时，就代表没有进程在使用这些资源，此时就释放 exit_files(tsk); exit_fs(tsk); check_stack_usage(); exit_thread(); cgroup_exit(tsk, 1); if (group_dead &amp;&amp; tsk-&gt;signal-&gt;leader) disassociate_ctty(1); module_put(task_thread_info(tsk)-&gt;exec_domain-&gt;module); proc_exit_connector(tsk); /* * Flush inherited counters to the parent - before the parent * gets woken up by child-exit notifications. */ perf_event_exit_task(tsk);//调用exit_notify()向父进程发送信号，将子进程的父进程重新设置为线程组中的其他线程或init进程，并把进程状态设为TASK_ZOMBIE. exit_notify(tsk, group_dead);#ifdef CONFIG_NUMA mpol_put(tsk-&gt;mempolicy); tsk-&gt;mempolicy = NULL;#endif#ifdef CONFIG_FUTEX if (unlikely(current-&gt;pi_state_cache)) kfree(current-&gt;pi_state_cache);#endif /* * Make sure we are holding no locks: */ debug_check_no_locks_held(tsk); /* * We can do this unlocked here. The futex code uses this flag * just to verify whether the pi state cleanup has been done * or not. In the worst case it loops once more. */ tsk-&gt;flags |= PF_EXITPIDONE; if (tsk-&gt;io_context) exit_io_context(); if (tsk-&gt;splice_pipe) __free_pipe_info(tsk-&gt;splice_pipe); validate_creds_for_do_exit(tsk); preempt_disable(); exit_rcu(); /* causes final put_task_struct in finish_task_switch(). */ tsk-&gt;state = TASK_DEAD; schedule(); //调用schedule()切换到其他进程 BUG(); /* Avoid &quot;noreturn function does return&quot;. */ for (;;) cpu_relax(); /* For when BUG is null */&#125; 进程终结时所需的清理工作和进程描述符的删除被分开执行，这样尽管在调用了do_exit()之后，线程已经僵死不能允许情况下，系统还是保留了它的进程描述符。在父进程获得已经终结的子进程信息后，子进程的task_struct结构才被释放。linux中有一系列wait()函数，这些函数都是基于系统调用wait4()实现的。它的动作就是挂起调用它的进程直到其中的一个子进程退出，此时函数会返回该退出子进程的PID。 最终释放进程描述符时，会调用release_task()。123456789101112131415161718192021222324252627282930313233void release_task(struct task_struct * p)&#123; struct task_struct *leader; int zap_leader;repeat: tracehook_prepare_release_task(p); /* don&apos;t need to get the RCU readlock here - the process is dead and * can&apos;t be modifying its own credentials */ atomic_dec(&amp;__task_cred(p)-&gt;user-&gt;processes); proc_flush_task(p); write_lock_irq(&amp;tasklist_lock); tracehook_finish_release_task(p); __exit_signal(p); //释放目前僵死进程所使用的所有剩余资源，并进行统计记录 zap_leader = 0; leader = p-&gt;group_leader; //如果进程是线程组最后一个进程，并且领头进程已经死掉，那么就通知僵死的领头进程的父进程 if (leader != p &amp;&amp; thread_group_empty(leader) &amp;&amp; leader-&gt;exit_state == EXIT_ZOMBIE)&#123; BUG_ON(task_detached(leader)); do_notify_parent(leader, leader-&gt;exit_signal); zap_leader = task_detached(leader); if (zap_leader) leader-&gt;exit_state = EXIT_DEAD; &#125; write_unlock_irq(&amp;tasklist_lock); release_thread(p); call_rcu(&amp;p-&gt;rcu, delayed_put_task_struct); p = leader; if (unlikely(zap_leader)) goto repeat;&#125; 子进程不一定能保证在父进程前边退出，所以必须要有机制来保证子进程在这种情况下能找到一个新的父进程。否则的话，这些成为孤儿的进程就会在退出时永远处于僵死状态，白白的耗费内存。解决这个问题的办法，就是给子进程在当前线程组内找一个线程作为父亲。一旦系统给进程成功地找到和设置了新的父进程，就不会再有出现驻留僵死进程的危险了，init进程会例行调用wait()来等待子进程，清除所有与其相关的僵死进程。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（七）：内核定时器和定时执行]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E5%AE%9A%E6%97%B6%E5%99%A8%E5%92%8C%E5%AE%9A%E6%97%B6%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 前面章节说到了把工作推后到除现在以外的时间执行的机制是下半部机制，但是当你需要将工作推后到某个确定的时间段之后执行，使用定时器是很好的选择。 上一节内核时间管理中讲到内核在始终中断发生执行定时器，定时器作为软中断在下半部上下文中执行。时钟中断处理程序会执行update_process_times函数，在该函数中运行run_local_timers()函数来标记一个软中断去处理所有到期的定时器。如下：123456789101112131415161718void update_process_times(int user_tick)&#123; struct task_struct *p = current; int cpu = smp_processor_id(); /* Note: this timer irq context must be accounted for as well. */ account_process_tick(p, user_tick); run_local_timers(); rcu_check_callbacks(cpu, user_tick); printk_tick(); scheduler_tick(); run_posix_cpu_timers(p);&#125;void run_local_timers(void)&#123; hrtimer_run_queues(); raise_softirq(TIMER_SOFTIRQ); softlockup_tick();&#125; 在分析定时器的实现之前我们先来看一看使用内核定时器的一个实例，示例如下:12345678910111213141516171819202122232425262728293031323334#include &lt;linux/module.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt;#include &lt;linux/timer.h&gt;#include &lt;linux/delay.h&gt;struct timer_list sln_timer;void sln_timer_do(unsigned long l)&#123; mod_timer(&amp;sln_timer, jiffies + HZ); printk(KERN_ALERT&quot;param: %ld, jiffies: %ld\n&quot;, l, jiffies);&#125;void sln_timer_set(void)&#123; init_timer(&amp;sln_timer); sln_timer.expires = jiffies + HZ; //1s sln_timer.function = sln_timer_do; sln_timer.data = 9527; add_timer(&amp;sln_timer);&#125;static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_timer_set(); return 0;&#125;static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); del_timer(&amp;sln_timer);&#125;module_init(sln_init);module_exit(sln_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;allen&quot;); 该示例作用是每秒钟打印出当前系统jiffies的值。 内核定时器由结构timer_list表示，定义在文件&lt;include/linux/timer.h&gt;中。123456789101112131415struct timer_list &#123; struct list_head entry; unsigned long expires; void (*function)(unsigned long); unsigned long data; struct tvec_base *base;#ifdef CONFIG_TIMER_STATS void *start_site; char start_comm[16]; int start_pid;#endif#ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map;#endif&#125;; 如示例，内核提供部分操作接口来简化管理定时器，第一步、定义一个定时器：struct timer_list sln_timer;第二步、初始化定时器数据结构的内部值。1init_timer(&amp;sln_timer);//初始化定时器 12345678910111213141516171819202122#define init_timer(timer)\ init_timer_key((timer), NULL, NULL)void init_timer_key(struct timer_list *timer, const char *name, struct lock_class_key *key)&#123; debug_init(timer); __init_timer(timer, name, key);&#125;static void __init_timer(struct timer_list *timer, const char *name, struct lock_class_key *key)&#123; timer-&gt;entry.next = NULL; timer-&gt;base = __raw_get_cpu_var(tvec_bases);#ifdef CONFIG_TIMER_STATS timer-&gt;start_site = NULL; timer-&gt;start_pid = -1; memset(timer-&gt;start_comm, 0, TASK_COMM_LEN);#endif lockdep_init_map(&amp;timer-&gt;lockdep_map, name, key, 0);&#125; 第三步、填充timer_list结构中需要的值：123sln_timer.expires = jiffies + HZ; //1s后执行 sln_timer.function = sln_timer_do; //执行函数sln_timer.data = 9527; sln_timer.expires表示超时时间，它以节拍为单位的绝对计数值。如果当前jiffies计数等于或大于sln_timer.expires的值，那么sln_timer.function所指向的处理函数sln_timer_do就会执行，并且该函数还要使用长整型参数sln_timer.dat。void sln_timer_do(unsigned long l)； 第四步、激活定时器：1add_timer(&amp;sln_timer); //向内核注册定时器 这样定时器就可以运行了。add_timer()的实现如下：12345void add_timer(struct timer_list *timer)&#123; BUG_ON(timer_pending(timer)); mod_timer(timer, timer-&gt;expires);&#125; add_timer()调用了mod_timer()。mod_timer()用于修改定时器超时时间。1mod_timer(&amp;sln_timer, jiffies + HZ); 由于add_timer()是通过调用mod_timer()来激活定时器，所以也可以直接使用mod_timer()来激活定时器，如果定时器已经初始化但没有激活，mod_timer()也会激活它。 如果需要在定时器超时前停止定时器，使用del_timer()函数来完成。1del_timer(&amp;sln_timer); 该函数实现如下：1234567891011121314151617181920212223242526272829int del_timer(struct timer_list *timer)&#123; struct tvec_base *base; unsigned long flags; int ret = 0; timer_stats_timer_clear_start_info(timer); if (timer_pending(timer)) &#123; base = lock_timer_base(timer, &amp;flags); if (timer_pending(timer)) &#123; detach_timer(timer, 1); if (timer-&gt;expires == base-&gt;next_timer &amp;&amp; !tbase_get_deferrable(timer-&gt;base)) base-&gt;next_timer = base-&gt;timer_jiffies; ret = 1; &#125; spin_unlock_irqrestore(&amp;base-&gt;lock, flags); &#125; return ret;&#125;static inline void detach_timer(struct timer_list *timer, int clear_pending)&#123; struct list_head *entry = &amp;timer-&gt;entry; debug_deactivate(timer); __list_del(entry-&gt;prev, entry-&gt;next); if (clear_pending) entry-&gt;next = NULL; entry-&gt;prev = LIST_POISON2;&#125; 当使用del_timer()返回后，定时器就不会再被激活，但在多处理器机器上定时器上定时器中断可能已经在其他处理器上运行了，所以删除定时器时需要等待可能在其他处理器上运行的定时器处理I程序都退出，这时就要使用del_timer_sync()函数执行删除工作：1del_timer_sync(&amp;sln_timer); 该函数不能在中断上下文中使用。该函数详细实现如下：123456789101112131415161718192021222324252627282930313233343536int del_timer_sync(struct timer_list *timer)&#123;#ifdef CONFIG_LOCKDEP unsigned long flags; local_irq_save(flags); lock_map_acquire(&amp;timer-&gt;lockdep_map); lock_map_release(&amp;timer-&gt;lockdep_map); local_irq_restore(flags);#endif for (;;) &#123; //一直循环，直到删除timer成功再退出 int ret = try_to_del_timer_sync(timer); if (ret &gt;= 0) return ret; cpu_relax(); &#125;&#125;int try_to_del_timer_sync(struct timer_list *timer)&#123; struct tvec_base *base; unsigned long flags; int ret = -1; base = lock_timer_base(timer, &amp;flags); if (base-&gt;running_timer == timer) goto out; ret = 0; if (timer_pending(timer)) &#123; detach_timer(timer, 1); if (timer-&gt;expires == base-&gt;next_timer &amp;&amp; !tbase_get_deferrable(timer-&gt;base)) base-&gt;next_timer = base-&gt;timer_jiffies; ret = 1; &#125;out: spin_unlock_irqrestore(&amp;base-&gt;lock, flags); return ret;&#125; 一般情况下应该使用del_timer_sync()函数代替del_timer()函数，因为无法确定在删除定时器时，他是否在其他处理器上运行。为了防止这种情况的发生，应该调用del_timer_sync()函数而不是del_timer()函数。否则，对定时器执行删除操作后，代码会继续执行，但它有可能会去操作在其它处理器上运行的定时器正在使用的资源，因而造成并发访问，所有优先使用删除定时器的同步方法。 除了使用定时器来推迟任务到指定时间段运行之外，还有其他的方法处理延时请求。有的方法会在延迟任务时挂起处理器，有的却不会。实际上也没有方法能够保证实际的延迟时间刚好等于指定的延迟时间。 最简单的 延迟方法是忙等待，该方法实现起来很简单，只需要在循环中不断旋转直到希望的时钟节拍数耗尽。比如：123unsigned long delay = jiffies+10; //延迟10个节拍while(time_before(jiffies,delay)) ； 这种方法当代码等待时，处理器只能在原地旋转等待，它不会去处理其他任何任务。最好在任务等待时，允许内核重新调度其它任务执行。将上面代码修改如下：123unsigned long delay = jiffies+10; //10个节拍while(time_before(jiffies,delay)) cond_resched(); 看一下cond_resched()函数具体实现代码：1234567891011121314151617181920#define cond_resched() (&#123; \ __might_sleep(__FILE__, __LINE__, 0); \ _cond_resched(); \&#125;) int __sched _cond_resched(void)&#123; if (should_resched()) &#123; __cond_resched(); return 1; &#125; return 0;&#125; static void __cond_resched(void) &#123; add_preempt_count(PREEMPT_ACTIVE); schedule(); //最终还是调用schedule()函数来重新调度其它程序运行 sub_preempt_count(PREEMPT_ACTIVE);&#125; 函数cond_resched()将重新调度一个新程序投入运行，但它只有在设置完need_resched标志后才能生效。换句话说，就是系统中存在更重要的任务需要运行。再由于该方法需要调用调度程序，所以它不能在中断上下文中使用—-只能在进程上下文中使用。事实上，所有延迟方法在进程上下文中使用，因为中断处理程序都应该尽可能快的执行。另外，延迟执行不管在哪种情况下都不应该在持有锁时或者禁止中断时发生。 有时内核需要更短的延迟，甚至比节拍间隔还要短。这时可以使用内核提供的ms、ns、us级别的延迟函数。123void udelay(unsigned long usecs); //arch/x86/include/asm/delay.hvoid ndelay(unsigned long nsecs); //arch/x86/include/asm/delay.hvoid mdelay(unsigned long msecs); udelay()使用忙循环将任务延迟指定的ms后执行,其依靠执行数次循环达到延迟效果，mdelay()函数是通过udelay()函数实现，如下：1234#define mdelay(n) (\ (__builtin_constant_p(n) &amp;&amp; (n)&lt;=MAX_UDELAY_MS) ? udelay((n)*1000) : \ (&#123;unsigned long __ms=(n); while (__ms--) udelay(1000);&#125;))#endif udelay()函数仅能在要求的延迟时间很短的情况下执行，而在高速机器中时间很长的延迟会造成溢出。对于较长的延迟，mdelay()工作良好。 schedule_timeout()函数是更理想的延迟执行方法。该方法会让需要延迟执行的任务睡眠到指定的延迟时间耗尽后再重新运行。但该方法也不能保证睡眠时间正好等于指定的延迟时间，只能尽量是睡眠时间接近指定的延迟时间。当指定的时间到期后，内核唤醒被延迟的任务并将其重新放回运行队列。用法如下：12set_current_state(TASK_INTERRUPTIBLE); //将任务设置为可中断睡眠状态schedule_timeout(s*HZ); //小睡一会儿，“s”秒后唤醒 唯一的参数是延迟的相对时间，单位是jiffies，上例中将相应的任务推入可中断睡眠队列，睡眠s秒。在调用函数schedule_timeout之前，不要要将任务设置成可中断或不和中断的一种，否则任务不会休眠。这个函数需要调用调度程序，所以调用它的代码必须保证能够睡眠，简而言之，调用代码必须处于进程上下文中，并且不能持有锁。 事实上schedule_timeout()函数的实现就是内核定时器的一个简单应用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455signed long __sched schedule_timeout(signed long timeout)&#123; struct timer_list timer; unsigned long expire; switch (timeout) &#123; case MAX_SCHEDULE_TIMEOUT: /* * These two special cases are useful to be comfortable * in the caller. Nothing more. We could take * MAX_SCHEDULE_TIMEOUT from one of the negative value * but I&apos; d like to return a valid offset (&gt;=0) to allow * the caller to do everything it want with the retval. */ schedule(); goto out; default: /* * Another bit of PARANOID. Note that the retval will be * 0 since no piece of kernel is supposed to do a check * for a negative retval of schedule_timeout() (since it * should never happens anyway). You just have the printk() * that will tell you if something is gone wrong and where. */ if (timeout &lt; 0) &#123; printk(KERN_ERR &quot;schedule_timeout: wrong timeout &quot; &quot;value %lx\n&quot;, timeout); dump_stack(); current-&gt;state = TASK_RUNNING; goto out; &#125; &#125; expire = timeout + jiffies; //下一行代码设置了超时执行函数process_timeout()。 setup_timer_on_stack(&amp;timer, process_timeout, (unsigned long)current); __mod_timer(&amp;timer, expire, false, TIMER_NOT_PINNED); //激活定时器 schedule(); //调度其他新任务 del_singleshot_timer_sync(&amp;timer); /* Remove the timer from the object tracker */ destroy_timer_on_stack(&amp;timer); timeout = expire - jiffies; out: return timeout &lt; 0 ? 0 : timeout;&#125;当定时器超时时，process_timeout()函数被调用：static void process_timeout(unsigned long __data) &#123; wake_up_process((struct task_struct *)__data);&#125; 当任务被重新调度时，将返回代码进入睡眠前的位置继续执行，位置正好在schedule()处。 进程上下文的代码为了等待特定时间发生，可以将自己放入等待队列。但是，等待队列上的某个任务可能既在等待一个特定事件到来，又在等待一个特定时间到期，就看谁来得更快。这种情况下，代码可以简单的使用scedule_timeout()函数代替schedule()函数，这样一来，当希望指定时间到期后，任务都会被唤醒，当然，代码需要检查被唤醒的原因，有可能是被事件唤醒，也有可能是因为延迟的时间到期，还可能是因为接收到了信号，然后执行相应的操作。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（六）：内核时钟中断]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E6%97%B6%E9%92%9F%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 内核中很多函数是基于时间驱动的，其中有些函数需要周期或定期执行。比如有的每秒执行100次，有的在等待一个相对时间之后执行。除此之外，内核还必须管理系统运行的时间日期。 周期性产生的时间都是有系统定时器驱动的，系统定时器是一种可编程硬件芯片，它可以以固定频率产生中断，该中断就是所谓的定时器中断，其所对应的中断处理程序负责更新系统时间，也负责执行需要周期性运行的任务。 系统定时器以某种频率自行触发时钟中断，该频率可以通过编程预定，称作节拍率。当时钟中断发生时，内核就通过一种特殊的中断处理器对其进行处理。内核知道连续两次时钟中断的间隔时间，该间隔时间就称为节拍。内核就是靠这种已知的时钟中断间隔来计算实际时间和系统运行时间的。内核通过控制时钟中断维护实际时间，另外内核也为用户提供一组系统调用获取实际日期和实际时间。时钟中断对才操作系统的管理来说十分重要，系统更新运行时间、更新实际时间、均衡调度程序中个处理器上运行队列、检查进程是否用尽时间片等工作都利用时钟中断来周期执行。 系统定时器频率是通过静态预定义的，也就是HZ，体系结构不同，HZ的值也不同。内核在&lt;asm/param.h&gt;文件中定义，在x86上时钟中断频率为100HZ，也就是说在i386处理上每秒时钟中断100次。 linux内核众多子系统都依赖时钟中断工作，所以是时钟中断频率的选择必须考虑频率所有子系统的影响。提高节拍就使得时钟中断产生的更频繁，中断处理程序就会更加频繁的执行，这样就提高了时间驱动时间的准确度，误差更小。如HZ=100，那么时钟每10ms中断一次，周期事件每10ms运行一次，如果HZ=1000，那么周期事件每1ms就会运行一次，这样依赖定时器的系统调用能够以更高的精度运行。既然提高时钟中断频率这么好，那为何要将HZ设置为100呢？因为提高时钟中断频率也会产生副作用，中断频率越高，系统的负担就增加了，处理器需要花时间来执行中断处理程序，中断处理器占用cpu时间越多。这样处理器执行其他工作的时间及越少，并且还会打乱处理器高速缓存。所以选择时钟中断频率时要考虑多方面，要取得各方面的折中的一个合适频率。 内核有一个全局变量jiffies，该变量用来记录系统起来以后产生的节拍总数。系统启动是，该变量被设置为0，此后每产生一次时钟中断就增加该变量的值。jiffies每一秒增加的值就是HZ。jiffies定义于头文件&lt;include/linux/jiffies.h&gt;中：1extern unsigned long volatile __jiffy_data jiffies; 对于32位unsigned long，可以存放最大值为4294967295，所以当节拍数达到最大值后还要继续增加的话，它的值就会回到0值。内核提供了四个宏（位于文件&lt;include/linux/jiffies.h&gt;中）来比较节拍数，这些宏可以正确处理节拍计数回绕情况。12345678910#define time_after(a,b) \ (typecheck(unsigned long, a) &amp;&amp; \ typecheck(unsigned long, b) &amp;&amp; \ ((long)(b) - (long)(a) &lt; 0))#define time_before(a,b) time_after(b,a)#define time_after_eq(a,b) \ (typecheck(unsigned long, a) &amp;&amp; \ typecheck(unsigned long, b) &amp;&amp; \ ((long)(a) - (long)(b) &gt;= 0))#define time_before_eq(a,b) time_after_eq(b,a) 下面示例来打印出当前系统启动后经过的jiffies以及秒数：12345678910111213141516171819#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/jiffies.h&gt; //jiffies#include &lt;asm/param.h&gt; //HZstatic int __init jiffies_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); printk(KERN_ALERT&quot;Current ticks is: %lu, seconds: %lu\n&quot;, jiffies, jiffies/HZ); return 0;&#125;static void __exit jiffies_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__);&#125;module_init(jiffies_init);module_exit(jiffies_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 执行输出结果为：123# insmod jfs.ko===jiffies_init===Current ticks is: 10106703, seconds: 10106 时钟中断发生时，会触发时钟中断处理程序，始终中断处理程序部分和体系结构相关，下面简单分析一下x86体系的处理：时钟的初始化在time_init()中，在start_kernel()中调用time_init()，如下：123456asmlinkage void __init start_kernel(void)&#123; ...... time_init(); ......&#125; 下面分析一下time_init()的实现，该函数位于文件&lt;arch/x86/kernel/time.c&gt;中：12345678910void __init time_init(void) &#123; late_time_init = x86_late_time_init;&#125; static __init void x86_late_time_init(void)&#123; x86_init.timers.timer_init(); // tsc_init();&#125; 结构体x86_init位于arch/x86/kernel/x86_init.c中12345678struct x86_init_ops x86_init __initdata = &#123; ...... .timers = &#123; .setup_percpu_clockev&gt;--= setup_boot_APIC_clock, .tsc_pre_init = x86_init_noop, .timer_init = hpet_time_init, &#125;&#125; 默认timer初始化函数为：123456void __init hpet_time_init(void) &#123; if (!hpet_enable()) setup_pit_timer(); setup_default_timer_irq();&#125; 函数setup_default_timer_irq();注册中断处理函数：12345678910void __init setup_default_timer_irq(void) &#123; setup_irq(0, &amp;irq0);&#125; static struct irqaction irq0 = &#123; .handler = timer_interrupt, .flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER, .name = &quot;timer&quot;&#125;; 对应的中断处理函数为:timer_interrupt():12345678910111213141516171819202122232425262728static irqreturn_t timer_interrupt(int irq, void *dev_id) &#123; /* Keep nmi watchdog up to date */ inc_irq_stat(irq0_irqs); /* Optimized out for !IO_APIC and x86_64 */ if (timer_ack) &#123; /* * Subtle, when I/O APICs are used we have to ack timer IRQ * manually to deassert NMI lines for the watchdog if run * on an 82489DX-based system. */ spin_lock(&amp;i8259A_lock); outb(0x0c, PIC_MASTER_OCW3); /* Ack the IRQ; AEOI will end it automatically. */ inb(PIC_MASTER_POLL); spin_unlock(&amp;i8259A_lock); &#125; //在此处调用体系无关的时钟处理例程 global_clock_event-&gt;event_handler(global_clock_event); /* MCA bus quirk: Acknowledge irq0 by setting bit 7 in port 0x61 */ if (MCA_bus) outb_p(inb_p(0x61)| 0x80, 0x61); return IRQ_HANDLED;&#125; 时钟例程在系统启动时start_kernel()函数中调用tick_init()初始化：12345（位于文件kernel/time/tick-common.c）void __init tick_init(void)&#123; clockevents_register_notifier(&amp;tick_notifier);&#125; tick_notifier定义如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384static struct notifier_block tick_notifier = &#123; .notifier_call = tick_notify,&#125;; static int tick_notify(struct notifier_block *nb, unsigned long reason, void *dev)&#123; switch (reason) &#123; ...... case CLOCK_EVT_NOTIFY_RESUME: tick_resume(); break; default: break; &#125; return NOTIFY_OK;&#125; static void tick_resume(void)&#123; struct tick_device *td = &amp;__get_cpu_var(tick_cpu_device); unsigned long flags; int broadcast = tick_resume_broadcast(); spin_lock_irqsave(&amp;tick_device_lock, flags); clockevents_set_mode(td-&gt;evtdev, CLOCK_EVT_MODE_RESUME); if (!broadcast) &#123; if (td-&gt;mode == TICKDEV_MODE_PERIODIC) tick_setup_periodic(td-&gt;evtdev, 0); else tick_resume_oneshot(); &#125; spin_unlock_irqrestore(&amp;tick_device_lock, flags);&#125; /* * Setup the device for a periodic tick */void tick_setup_periodic(struct clock_event_device *dev, int broadcast)&#123; tick_set_periodic_handler(dev, broadcast); ......&#125; /* * 根据broadcast设置周期性的处理函数（kernel/time/tick-broadcast.c）,这里就设置了始终中断函数timer_interrupt中调用的时钟处理例程 */void tick_set_periodic_handler(struct clock_event_device *dev, int broadcast)&#123; if (!broadcast) dev-&gt;event_handler = tick_handle_periodic; else dev-&gt;event_handler = tick_handle_periodic_broadcast;&#125; /* * ，以tick_handle_periodic为例，每一个始终节拍都调用该处理函数，而该处理过程中，主要处理工作处于tick_periodic()函数中。 */void tick_handle_periodic(struct clock_event_device *dev)&#123; int cpu = smp_processor_id(); ktime_t next; tick_periodic(cpu); if (dev-&gt;mode != CLOCK_EVT_MODE_ONESHOT) return; next = ktime_add(dev-&gt;next_event, tick_period); for (;;) &#123; if (!clockevents_program_event(dev, next, ktime_get())) return; if (timekeeping_valid_for_hres()) tick_periodic(cpu); next = ktime_add(next, tick_period); &#125;&#125; tick_periodic()函数主要有以下工作：下面来看分析一下该函数：123456789101112131415161718/* * Periodic tick */static void tick_periodic(int cpu)&#123; if (tick_do_timer_cpu == cpu) &#123; write_seqlock(&amp;xtime_lock); /* 记录下一个节拍事件 */ tick_next_period = ktime_add(tick_next_period, tick_period); do_timer(1); write_sequnlock(&amp;xtime_lock); &#125; update_process_times(user_mode(get_irq_regs()));//更新所耗费的各种节拍数 profile_tick(CPU_PROFILING);&#125; 其中函数do_timer()(位于kernel/timer.c中)对jiffies_64做增加操作：123456void do_timer(unsigned long ticks)&#123; jiffies_64 += ticks; update_wall_time(); //更新墙上时钟 calc_global_load(); //更新系统平均负载统计值&#125; update_process_times更新所耗费的各种节拍数。12345678910111213void update_process_times(int user_tick)&#123; struct task_struct *p = current; int cpu = smp_processor_id(); /* Note: this timer irq context must be accounted for as well. */ account_process_tick(p, user_tick); run_local_timers(); rcu_check_callbacks(cpu, user_tick); printk_tick(); scheduler_tick(); run_posix_cpu_timers(p);&#125; 函数run_local_timers()会标记一个软中断去处理所有到期的定时器。123456void run_local_timers(void)&#123; hrtimer_run_queues(); raise_softirq(TIMER_SOFTIRQ); softlockup_tick();&#125; 在时钟中断处理函数time_interrupt()函数调用体系结构无关的时钟处理例程完成之后，返回到与体系结构的相关的中断处理函数中。以上所有的工作每一次时钟中断都会运行，也就是说如果HZ=100，那么时钟中断处理程序每一秒就会运行100次。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（五）：下半部机制之工作队列及几种机制的选择]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E5%8F%8A%E5%87%A0%E7%A7%8D%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 工作队列是下半部的另外一种将工作推后执行形式。和软中断、tasklet不同，工作队列将工作推后交由一个内核线程去执行，并且该下半部总会在进程上下文中执行。这样，工作队列允许重新调度甚至是睡眠。 所以，如果推后执行的任务需要睡眠，就选择工作队列。如果不需要睡眠，那就选择软中断或tasklet。工作队列是唯一能在进程上下文中运行的下半部实现机制，也只有它才可以睡眠。 工作队列子系统是一个用于创建内核线程的接口，通过它创建的进程负责执行由内核其他部分排到队列里的任务。它创建的这些内核线程称作工作者线程。工作队列可以让你的驱动程序创建一个专门的工作者线程来处理需要推后的工作。不过，工作队列子系统提供了一个缺省的工作者线程来处理这些工作。因此，工作队列最基本的表现形式就转变成一个把需要推后执行的任务交给特定的通用线程这样一种接口。缺省的工作线程叫做event/n.每个处理器对应一个线程，这里的n代表了处理器编号。除非一个驱动程序或者子系统必须建立一个属于自己的内核线程，否则最好还是使用缺省线程。使用下面命令可以看到默认event工作者线程，每个处理器对应一个线程：123# ps x | grep event | grep -v grep 9 ? S 0:00 [events/0] 10 ? S 0:00 [events/1] 工作者线程使用workqueue_struct结构表示（位于&lt;kernel/workqueue.c&gt;中）：1234567891011121314151617181920212223struct workqueue_struct &#123; struct cpu_workqueue_struct *cpu_wq; //该数组每一项对应系统中的一个处理器 struct list_head list; const char *name; int singlethread; int freezeable; /* Freeze threads during suspend */ int rt;#ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map;#endif&#125;每个处理器，每个工作者线程对应对应一个cpu_workqueue_struct结构体（位于&lt;kernel/workqueue.c&gt;中）：struct cpu_workqueue_struct &#123; spinlock_t lock; //保护该结构 struct list_head worklist; //工作列表 wait_queue_head_t more_work; //等待队列，其中的工作者线程因等待而处于睡眠状态 struct work_struct *current_work; struct workqueue_struct *wq; //关联工作队列结构 struct task_struct *thread; // 关联线程,指向结构中工作者线程的进程描述符指针&#125; ____cacheline_aligned; 每个工作者线程类型关联一个自己的workqueue_struct，在该结构体里面，给每个线程分配一个cpu_workqueue_struct ，因而也就是给每个处理器分配一个，因为每个处理器都有一个该类型的工作者线程。 所有的工作者线程都是使用普通的内核线程实现的，他们都要执行worker_thread()函数。在它初始化完以后，这个函数执行一个死循环执行一个循环并开始休眠，当有操作被插入到队列的时候，线程就会被唤醒，以便执行这些操作。当没有剩余的时候，它又会继续休眠。工作由work_struct（位于&lt;kernel/workqueue.c&gt;中）结构表示：1234567struct work_struct &#123; atomic_long_t data;...... struct list_head entry;//连接所有链表 work_func_t func;.....&#125;; 当一个工作线程被唤醒时，它会执行它的链表上的所有工作。工作一旦执行完毕，它就将相应的work_struct对象从链表上移去，当链表不再有对象时，它就继续休眠。woker_thread()函数如下：1234567891011121314151617181920212223242526272829static int worker_thread(void *__cwq)&#123; struct cpu_workqueue_struct *cwq = __cwq; DEFINE_WAIT(wait); if (cwq-&gt;wq-&gt;freezeable) set_freezable(); for (;;) &#123; //线程将自己设置为休眠状态并把自己加入等待队列 prepare_to_wait(&amp;cwq-&gt;more_work, &amp;wait, TASK_INTERRUPTIBLE); if (!freezing(current) &amp;&amp; !kthread_should_stop() &amp;&amp; list_empty(&amp;cwq-&gt;worklist)) schedule();//如果工作对列是空的，线程调用schedule()函数进入睡眠状态 finish_wait(&amp;cwq-&gt;more_work, &amp;wait); try_to_freeze(); //如果链表有对象，线程就将自己设为运行态，脱离等待队列 if (kthread_should_stop()) break; //再次调用run_workqueue()执行推后的工作 run_workqueue(cwq); &#125; return 0;&#125; 之后由run_workqueue()函数来完成实际推后到此的工作：1234567891011121314151617181920212223242526272829303132static void run_workqueue(struct cpu_workqueue_struct *cwq) &#123; spin_lock_irq(&amp;cwq-&gt;lock); while (!list_empty(&amp;cwq-&gt;worklist)) &#123; //链表不为空时，选取下一个节点对象 struct work_struct *work = list_entry(cwq-&gt;worklist.next, struct work_struct, entry); //获取希望执行的函数func及其参数data work_func_t f = work-&gt;func;...... trace_workqueue_execution(cwq-&gt;thread, work); cwq-&gt;current_work = work; //把该结点从链表上解下来 list_del_init(cwq-&gt;worklist.next); spin_unlock_irq(&amp;cwq-&gt;lock); BUG_ON(get_wq_data(work) != cwq); //将待处理标志位pending清0 work_clear_pending(work); lock_map_acquire(&amp;cwq-&gt;wq-&gt;lockdep_map); lock_map_acquire(&amp;lockdep_map); //执行函数 f(work); lock_map_release(&amp;lockdep_map); lock_map_release(&amp;cwq-&gt;wq-&gt;lockdep_map); ...... spin_lock_irq(&amp;cwq-&gt;lock); cwq-&gt;current_work = NULL; &#125; spin_unlock_irq(&amp;cwq-&gt;lock);&#125; 系统允许有多种类型工作者线程存在，默认情况下内核只有event这一种类型的工作者线程，每个工作者线程都由一个cpu_workqueue_struct 结构体表示，大部分情况下，驱动程序都使用现存的默认工作者线程。 工作队列的使用很简单。可以使用缺省的events任务队列，也可以创建新的工作者线程。第一步、创建需要推后完成的工作。12DECLARE_WORK(name,void (*func)(void *),void *data); //编译时静态创建INIT_WORK(struct work_struct *work, void (*func)(void *)); //运行时动态创建 第二步、编写队列处理函数，处理函数会由工作者线程执行，因此，函数会运行在进程上下文中，默认情况下，允许相应中断，并且不持有锁。如果需要，函数可以睡眠。需要注意的是，尽管处理函数运行在进程上下文中，但它不能访问用户空间，因为内核线程在用户空间没有相应的内存映射。函数原型如下：1void work_hander(void *data); 第三步、调度工作队列。调用schedule_work(&amp;work)；work马上就会被调度，一旦其所在的处理器上的工作者线程被唤醒，它就会被执行。当然如果不想快速执行，而是想延迟一段时间执行，调用schedule_delay_work(&amp;work,delay);delay是要延迟的时间节拍。默认工作者线程的调度函数其实就是做了一层封装，减少了 默认工作者线程的参数输入，如下：123456789int schedule_work(struct work_struct *work)&#123; return queue_work(keventd_wq, work);&#125; int schedule_delayed_work(struct delayed_work *dwork, unsigned long delay) &#123; return queue_delayed_work(keventd_wq, dwork, delay);&#125; 第四步、刷新操作，插入队列的工作会在工作者线程下一次被唤醒的时候执行。有时，在继续下一步工作之前，你必须保证一些操作已经执行完毕等等。由于这些原因，内核提供了一个用于刷新指定工作队列的函数：1void flush_scheduled_work(void); 这个函数会一直等待，直到队列中所有的对象都被执行后才返回。在等待所有待处理的工作执行的时候，该函数会进入休眠状态，所以只能在进程上下文中使用它。需要说明的是，该函数并不取消任何延迟执行的工作。取消延迟执行的工作应该调用：int cancel_delayed_work(struct work_struct *work);这个函数可以取消任何与work_struct 相关挂起的工作。下面为一个示例：12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt; #include &lt;linux/workqueue.h&gt; //work_strcut //struct work_struct ws;struct delayed_work dw; void workqueue_func(struct work_struct *ws) //处理函数&#123; printk(KERN_ALERT&quot;Hello, this is shallnet!\n&quot;);&#125; static int __init kwq_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); //INIT_WORK(&amp;ws, workqueue_func); //建需要推后完成的工作 //schedule_work(&amp;ws); //调度工作 INIT_DELAYED_WORK(&amp;dw, workqueue_func); schedule_delayed_work(&amp;dw, 10000); return 0;&#125; static void __exit kwq_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); flush_scheduled_work();&#125; module_init(kwq_init);module_exit(kwq_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 上面的操作是使用缺省的工作队列，下面来看一下创建一个新的工作队列是如何操作的？ 创建一个新的工作队列和与之相应的工作者线程，方法很简单，使用如下函数：1struct workqueue_struct *create_workqueue(const char *name); name是新内核线程的名字。比如缺省events队列的创建是这样使用的：12struct workqueue_struct *keventd_wq；kevent_wq = create_workqueue(&quot;event&quot;); 这样就创建了所有的工作者线程，每个处理器都有一个。然后调用如下函数进行调度：12int queue_work(struct workqueue_struct *wq, struct work_struct *work);int queue_delayed_work(struct workqueue_struct *wq,struct delayed_work *work,unsigned long delay); 最后可以调用flush_workqueue(struct workqueue_struct *wq);刷新指定工作队列。下面为自定义新的工作队列的示例：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/workqueue.h&gt; //work_strcut struct workqueue_struct *sln_wq = NULL;//struct work_struct ws;struct delayed_work dw; void workqueue_func(struct work_struct *ws)&#123; printk(KERN_ALERT&quot;Hello, this is shallnet!\n&quot;);&#125; static int __init kwq_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_wq = create_workqueue(&quot;sln_wq&quot;); //创建名为sln_wq的工作队列 //INIT_WORK(&amp;ws, workqueue_func); //queue_work(sln_wq, &amp;ws); INIT_DELAYED_WORK(&amp;dw, workqueue_func); // queue_delayed_work(sln_wq, &amp;dw, 10000); // return 0;&#125; static void __exit kwq_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); flush_workqueue(sln_wq);&#125; module_init(kwq_init);module_exit(kwq_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 使用ps可以查看到名为sln_wq的工作者线程。 在当前2.6.32版本中，我们讲了三种下半部机制：软中断、tasklet、工作队列。其中tasklet基于软中断，而工作队列靠内核线程实现。 使用软中断必须要确保共享数据的安全，因为相同类别的软中断可能在不同处理器上同时执行。在对于时间要求是否严格和执行频率很高的应用，或准备利用每一处理器上的变量或类型情形，可以考虑使用软中断，如网络子系统。 tasklet接口简单，可以动态创建，且两个通知类型的tasklet不能同时执行，所以实现起来较简单。驱动程序应该尽量选择tasklet而不是软中断。 工作队列工作于进程上下文，易于使用。由于牵扯到内核线程或上下文的切换，可能开销较大。如果你需要把任务推后到进程上下文中，或你需要休眠，那就只有使用工作队列了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（四）：下半部机制之tasklet]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8Btasklet%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 tasklet是利用软中断实现的一种下半部机制。tasklet相比于软中断，其接口更加简单方便，锁保护要求较低。tasklet由tasklet_struct结构体表示：12345678struct tasklet_struct&#123; struct tasklet_struct *next; //链表中下一个tasklet unsigned long state; //tasklet状态 atomic_t count; //引用计数 void (*func)(unsigned long); //tasklet处理函数 unsigned long data; //给tasklet处理函数的参数&#125;; tasklet还分为了高优先级tasklet与一般tasklet，前面分析软中断时softirq_init()注册的两个tasklet软中断。12345678void __init softirq_init(void)&#123; ...... //此处注册两个软中断 open_softirq(TASKLET_SOFTIRQ, tasklet_action); open_softirq(HI_SOFTIRQ, tasklet_hi_action); ......&#125; 其处理函数分别为 tasklet_action()和tasklet_hi_action()。 tasklet_action()函数实现为：1234567891011121314151617181920212223242526272829303132333435static void tasklet_action(struct softirq_action *a)&#123; struct tasklet_struct *list; local_irq_disable(); list = __get_cpu_var(tasklet_vec).head; __get_cpu_var(tasklet_vec).head = NULL; __get_cpu_var(tasklet_vec).tail = &amp;__get_cpu_var(tasklet_vec).head; local_irq_enable(); while (list) &#123; struct tasklet_struct *t = list; list = list-&gt;next; if (tasklet_trylock(t)) &#123; if (!atomic_read(&amp;t-&gt;count)) &#123; //t-&gt;count为零才会调用task_struct里的函数 if (!test_and_clear_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) BUG(); t-&gt;func(t-&gt;data); //设置了TASKLET_STATE_SCHED标志才会被遍历到链表上对应的函数 tasklet_unlock(t); continue; &#125; tasklet_unlock(t); &#125; local_irq_disable(); t-&gt;next = NULL; *__get_cpu_var(tasklet_vec).tail = t; __get_cpu_var(tasklet_vec).tail = &amp;(t-&gt;next); __raise_softirq_irqoff(TASKLET_SOFTIRQ); local_irq_enable(); &#125;&#125; tasklet_hi_action函数实现类似12345678910111213141516171819202122232425262728293031323334static void tasklet_hi_action(struct softirq_action *a)&#123; struct tasklet_struct *list; local_irq_disable(); list = __get_cpu_var(tasklet_hi_vec).head; __get_cpu_var(tasklet_hi_vec).head = NULL; __get_cpu_var(tasklet_hi_vec).tail = &amp;__get_cpu_var(tasklet_hi_vec).head; local_irq_enable(); while (list) &#123; struct tasklet_struct *t = list; list = list-&gt;next; if (tasklet_trylock(t)) &#123; if (!atomic_read(&amp;t-&gt;count)) &#123; if (!test_and_clear_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) BUG(); t-&gt;func(t-&gt;data); tasklet_unlock(t); continue; &#125; tasklet_unlock(t); &#125; local_irq_disable(); t-&gt;next = NULL; *__get_cpu_var(tasklet_hi_vec).tail = t; __get_cpu_var(tasklet_hi_vec).tail = &amp;(t-&gt;next); __raise_softirq_irqoff(HI_SOFTIRQ); local_irq_enable(); &#125;&#125; 这两个函数主要是做了如下动作： 禁止中断，并为当前处理器检索tasklet_vec或tasklet_hi_vec链表。 将当前处理器上的该链表设置为NULL,达到清空的效果。 运行相应中断。 循环遍历获得链表上的每一个待处理的tasklet。 如果是多处理器系统，通过检查TASKLET_STATE_RUN来判断这个tasklet是否正在其他处理器上运行。如果它正在运行，那么现在就不要执行，跳 到下一个待处理的tasklet去。 如果当前这个tasklet没有执行，将其状态设置为TASKLETLET_STATE_RUN,这样别的处理器就不会再去执行它了。 检查count值是否为0，确保tasklet没有被禁止。如果tasklet被禁止，则跳到下一个挂起的tasklet去。 现在可以确定这个tasklet没有在其他地方执行，并且被我们设置为执行状态，这样它在其他部分就不会被执行，并且引用计数器为0，现在可以执行tasklet的处理程序了。 重复执行下一个tasklet，直至没有剩余的等待处理的tasklets。 一般情况下，都是用tasklet来实现下半部，tasklet可以动态创建、使用方便、执行速度快。下面来看一下如何创建自己的tasklet呢？第一步，声明自己的tasklet。既可以静态也可以动态创建，这取决于选择是想有一个对tasklet的直接引用还是间接引用。静态创建方法(直接引用)，可以使用下列两个宏的一个(在linux/interrupt.h中定义)：12DECLARE_TASKLET(name,func,data)DECLARE_TASKLET_DISABLED(name,func,data) 这两个宏的实现为：12345#define DECLARE_TASKLET(name, func, data) \struct tasklet_struct name = &#123; NULL, 0, ATOMIC_INIT(0), func, data &#125; #define DECLARE_TASKLET_DISABLED(name, func, data) \struct tasklet_struct name = &#123; NULL, 0, ATOMIC_INIT(1), func, data &#125; 这两个宏之间的区别在于引用计数器的初始值不同，前面一个把创建的tasklet的引用计数器设置为0，使其处于激活状态，另外一个将其设置为1，处于禁止状态。而动态创建(间接引用)的方式如下：1tasklet_init(t,tasklet_handler,dev); 其实现代码为：123456789void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data)&#123; t-&gt;next = NULL; t-&gt;state = 0; atomic_set(&amp;t-&gt;count, 0); t-&gt;func = func; t-&gt;data = data;&#125; 第二步，编写tasklet处理程序。tasklet处理函数类型是void tasklet_handler(unsigned long data)。因为是靠软中断实现，所以tasklet不能休眠，也就是说不能在tasklet中使用信号量或者其他什么阻塞式的函数。由于tasklet 运行时允许响应中断，所以必须做好预防工作，如果新加入的tasklet和中断处理程序之间共享了某些数据额的话。两个相同的tasklet绝不能同时执 行，如果新加入的tasklet和其他的tasklet或者软中断共享了数据，就必须要进行适当地锁保护。 第三步，调度自己的tasklet。调用tasklet_schedule()（或tasklet_hi_schedule()）函数，tasklet就会进入挂起状态以便执行。如果在还没有得到运行机会之前，如果有一个相同的tasklet又被调度了，那么它仍然只会运行一次。如果这时已经开始运行，那么这个新的tasklet会被重新调度并再次运行。一种优化策略是一个tasklet总在调度它的处理器上执行。 调用tasklet_disable()来禁止某个指定的 tasklet，如果该tasklet当前正在执行，这个函数会等到它执行完毕再返回。调用tasklet_disable_nosync()也是来禁止 的，只是不用在返回前等待tasklet执行完毕，这么做不太安全，因为没法估计该tasklet是否仍在执行。 tasklet_enable()激活一个tasklet。可以使用tasklet_kill()函数从挂起的对列中去掉一个tasklet。这个函数会 首先等待该tasklet执行完毕，然后再将其移去。当然，没有什么可以阻止其他地方的代码重新调度该tasklet。由于该函数可能会引起休眠，所以禁止在中断上下文中使用它。 下面来看一下函数tasklet_schedule的实现：123456789101112131415161718192021222324static inline void tasklet_schedule(struct tasklet_struct *t)&#123;//检查tasklet的状态是否为TASKLET_STATE_SCHED.如果是，说明tasklet已经被调度过了，函数返回。 if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) __tasklet_schedule(t);&#125; void __tasklet_schedule(struct tasklet_struct *t)&#123; unsigned long flags; //保存中断状态，然后禁止本地中断。在执行tasklet代码时，这么做能够保证处理器上的数据不会弄乱。 local_irq_save(flags); //把需要调度的tasklet加到每个处理器一个的tasklet_vec链表或task_hi_vec链表的表头上去。 t-&gt;next = NULL; *__get_cpu_var(tasklet_vec).tail = t; __get_cpu_var(tasklet_vec).tail = &amp;(t-&gt;next); //唤起TASKLET_SOFTIRQ或HI_SOFTIRQ软中断，这样在下一次调用do_softirq()时就会执行该tasklet。 raise_softirq_irqoff(TASKLET_SOFTIRQ); //恢复中断到原状态并返回。 local_irq_restore(flags);&#125; tasklet_hi_schedule()函数的实现细节类似。 对于软中断，内核会选择几个特殊的实际进行处理(常见的是中 断处理程序返回时)。软中断被触发的频率有时会很好，而且还可能会自行重复触发，这带来的结果就是用户空间的进程无法获得足够的处理器时间，因为处于饥饿 状态。同时，如果单纯的对重复触发的软中断采取不立即处理的策略也是无法接受的。 内核选中的方案是不会立即处理重新触发的软中断，作为改进， 当大量软中断出现的时候，内核会唤醒一组内核线程来处理这些负载。这些线程在最低优先级上运行(nice值为19)。这种这种方案能够保证在软中断负担很 重的时候用户程序不会因为得不到处理时间而处理饥饿状态。相应的，也能保证“过量”的软中断终究会得到处理。最后，在空闲系统上，这个方案同样表现良好， 软中断处理得非常迅速(因为仅存的内存线程肯定会马上调度)。为了保证只要有空闲的处理器，它们就会处理软中断，所以给每个处理器都分配一个这样的线程。 所有线程的名字都叫做ksoftirad/n，区别在于n，它对应的是处理器的编号。一旦该线程被初始化，它就会执行类似下面这样的死循环：12345678910111213for(;;)&#123; if(!softirq_pending(cpu))//softirq_pending()负责发现是否有待处理的软中断 schedule(); //没有待处理软中断就唤起调度程序选择其他可执行进程投入运行 set_current_state(TASK_RUNNING); while(softirq_pending(cpu))&#123; do_softirq();//有待处理的软中断，ksoftirq调用do_softirq()去处理他。 if(need_resched()) //如果有必要的话，每次软中断完成之后调用schedule函数让其他重要进程得到处理机会 schedule(); &#125; //当所有需要执行的操作都完成以后，该内核线程将自己设置为 TASK_INTERRUPTIBLE状态 set_current_state(TASK_INTERRUPTIBLE);&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（三）：下半部机制之软中断]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8B%E8%BD%AF%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 中断处理程序以异步方式执行，其会打断其他重要代码，其运行时该中断同级的其他中断会被屏蔽，并且当前处理器上所有其他中断都有可能会被屏蔽掉，还有中断处理程序不能阻塞，所以中断处理需要尽快结束。由于中断处理程序的这些缺陷，导致了中断处理程序只是整个硬件中断处理流程的一部分，对于那些对时间要求不高的任务，留给中断处理流程的另外一部分，也就是本节要讲的中断处理流程的下半部。 那哪些工作由中断处理程序完成，哪些工作留给下半部来执行呢？其实上半部和下半部的工作划分不存在某种严格限制，这主要取决于驱动程序开发者自己的判断，一般最好能将中断处理程序执行时间缩短到最小。中断处理程序几乎都需要通过操作硬件对中断的到达进行确认，有时还会做对时间非常敏感的工作（如拷贝数据），其余的工作基本上留给下半部来处理，下半部就是执行与中断处理密切相关但中断处理程序本身不执行的工作。一般对时间非常敏感、和硬件相关、要保证不被其它中断(特别是相同的中断)打断的这些任务放在中断处理程序中执行，其他任务考虑放在下半部执行。 那下半部什么时候执行呢？下半部不需要指定明确执行时间，只要把任务推迟一点，让它们在系统不太忙且中断恢复后执行就可以了，而且执行期间可以相应所有中断。 上半部只能通过中断处理程序实现，而下半部可以有多种机制来实现，在2.6.32版本中，有三种不同形式的下半部实现机制：软中断、tasklet、工作队列。下面来看一下这三种下半部的实现。 软中断在start_kernerl()函数中，系统初始化软中断。12345678910111213asmlinkage void __init start_kernel(void)&#123; char * command_line; extern struct kernel_param __start___param[], __stop___param[]; smp_setup_processor_id();...... softirq_init();//初始化软中断...... /* Do the rest non-__init&apos;ed, we&apos;re now alive */ rest_init();&#125; 在softirq_init()中会注册两个常用类型的软中断, 具体代码如下（位于kernel/softirq.c）:1234567891011121314151617181920void __init softirq_init(void)&#123; int cpu; for_each_possible_cpu(cpu) &#123; int i; per_cpu(tasklet_vec, cpu).tail = &amp;per_cpu(tasklet_vec, cpu).head; per_cpu(tasklet_hi_vec, cpu).tail = &amp;per_cpu(tasklet_hi_vec, cpu).head; for (i = 0; i &lt; NR_SOFTIRQS; i++) INIT_LIST_HEAD(&amp;per_cpu(softirq_work_list[i], cpu)); &#125; register_hotcpu_notifier(&amp;remote_softirq_cpu_notifier); //此处注册两个软中断 open_softirq(TASKLET_SOFTIRQ, tasklet_action); open_softirq(HI_SOFTIRQ, tasklet_hi_action);&#125; 注册函数open_softirq()参数含义:nr:软中断类型 action:软中断处理函数1234void open_softirq(int nr, void (*action)(struct softirq_action *))&#123; softirq_vec[nr].action = action;&#125; softirq_action结构表示软中断，定义在&lt;include/linux/interrupt.h&gt;1234struct softirq_action&#123; void (*action)(struct softirq_action *);&#125; 文件&lt;kernel/softirq.c&gt;中定义了32个该结构体的数组：1static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp; 每注册一个软中断都会占该数组一个位置，因此系统中最多有32个软中断。从上面的代码中,我们可以看到:open_softirq()中.其实就是对softirq_vec数组的nr项赋值.softirq_vec是一个32元素的数组,实际上linux内核只使用了几项：123456789101112131415161718192021/* PLEASE, avoid to allocate new softirqs, if you need not _really_ high frequency threaded job scheduling. For almost all the purposes tasklets are more than enough. F.e. all serial device BHs et al. should be converted to tasklets, not to softirqs. */ enum&#123; HI_SOFTIRQ=0, TIMER_SOFTIRQ, NET_TX_SOFTIRQ, NET_RX_SOFTIRQ, BLOCK_SOFTIRQ, BLOCK_IOPOLL_SOFTIRQ, TASKLET_SOFTIRQ, SCHED_SOFTIRQ, HRTIMER_SOFTIRQ, RCU_SOFTIRQ, /* Preferable RCU should always be the last softirq */ NR_SOFTIRQS&#125;; 那么软中断注册完成之后，什么时候触发软中断处理函数执行呢？通常情况下，软中断会在中断处理程序返回前标记它，使其在稍后合适的时候被执行。在下列地方，待处理的软中断会被检查和执行： 处理完一个硬件中断以后； 在ksoftirqd内核线程中； 在那些显示检查和执行待处理的软中断的代码中，如网络子系统中。 无论如何，软中断会在do_softirq()（位于&lt;kernel/softirq.c&gt;中）中执行，如果有待处理的软中断，do_softirq会循环遍历每一个，调用他们的软中断处理程序。12345678910111213asmlinkage void do_softirq(void) &#123; __u32 pending; unsigned long flags; //如果在硬件中断环境中就退出，软中断不可以在硬件中断上下文或者是在软中断环境中使用，使用in_interrupt()来防止软中断嵌套，和抢占硬中断环境。 if (in_interrupt()) return; //禁止本地中断 local_irq_save(flags); pending = local_softirq_pending(); //如果有软中断要处理，则进入__do_softirq() if (pending) __do_softirq(); local_irq_restore(flags); &#125; 下面看一下__do_softirq()的实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859asmlinkage void __do_softirq(void)&#123; struct softirq_action *h; __u32 pending; int max_restart = MAX_SOFTIRQ_RESTART; int cpu; pending = local_softirq_pending(); //pending用于保留待处理软中断32位位图 account_system_vtime(current); __local_bh_disable((unsigned long)__builtin_return_address(0)); lockdep_softirq_enter(); cpu = smp_processor_id();restart: /* Reset the pending bitmask before enabling irqs */ set_softirq_pending(0); local_irq_enable(); h = softirq_vec; do &#123; if (pending &amp; 1) &#123; //如果pending第n位被设置为1，那么处理第n位对应类型的软中断 int prev_count = preempt_count(); kstat_incr_softirqs_this_cpu(h - softirq_vec); trace_softirq_entry(h, softirq_vec); h-&gt;action(h); //执行软中断处理函数 trace_softirq_exit(h, softirq_vec); if (unlikely(prev_count != preempt_count())) &#123; printk(KERN_ERR &quot;huh, entered softirq %td %s %p&quot; &quot;with preempt_count %08x,&quot; &quot; exited with %08x?\n&quot;, h - softirq_vec, softirq_to_name[h - softirq_vec], h-&gt;action, prev_count, preempt_count()); preempt_count() = prev_count; &#125; rcu_bh_qs(cpu); &#125; h++; pending &gt;&gt;= 1; //pending右移一位，循环检查其每一位 &#125; while (pending); //直到pending变为0，pending最多32位，所以循环最多执行32次。 local_irq_disable(); pending = local_softirq_pending(); if (pending &amp;&amp; --max_restart) goto restart; if (pending) wakeup_softirqd(); lockdep_softirq_exit(); account_system_vtime(current); _local_bh_enable();&#125; 使用软中断必须要在编译期间静态注册，一般只有像网络这样对性能要求高的情况才使用软中断，文章前面我们也看到，系统中注册的软中断就那么几个。大部分时候，使用下半部另外一种机制tasklet的情况更多一些，tasklet可以动态的注册，可以被看作是一种性能和易用性之间寻求平衡的一种产物。事实上，大部分驱动程序都是用tasklet来实现他们的下半部。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（二）：硬中断及中断处理]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%A1%AC%E4%B8%AD%E6%96%AD%E5%8F%8A%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 操作系统负责管理硬件设备，为了使系统和硬件设备的协同工作不降低机器性能，系统和硬件的通信使用中断的机制，也就是让硬件在需要的时候向内核发出信号，这样使得内核不用去轮询设备而导致做很多无用功。 中断使得硬件可以发出通知给处理器，硬件设备生成中断的时候并不考虑与处理器的时钟同步，中断可以随时产生。也就是说，内核随时可能因为新到来的中断而被打断。当接收到一个中断后，中断控制器会给处理器发送一个电信号，处理器检测到该信号便中断自己当前工作而处理中断。 在响应一个中断时，内核会执行一个函数，该函数叫做中断处理程序或中断服务例程（ISR）。中断处理程序运行与中断上下文，中断上下文中执行的代码不可阻塞，应该快速执行，这样才能保证尽快恢复被中断的代码的执行。中断处理程序是管理硬件驱动的驱动程序的组成部分，如果设备使用中断，那么相应的驱动程序就注册一个中断处理程序。 在驱动程序中,通常使用request_irq()来注册中断处理程序。该函数在文件&lt;include/linux/interrupt.h&gt;中声明：123extern int __must_checkrequest_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev); 第一个参数为要分配的中断号；第二个参数为指向中断处理程序的指针；第三个参数为中断处理标志。该函数实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384static inline int __must_checkrequest_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev)&#123; return request_threaded_irq(irq, handler, NULL, flags, name, dev);&#125; int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id)&#123; struct irqaction *action; struct irq_desc *desc; int retval; /* * handle_IRQ_event() always ignores IRQF_DISABLED except for * the _first_ irqaction (sigh). That can cause oopsing, but * the behavior is classified as &quot;will not fix&quot; so we need to * start nudging drivers away from using that idiom. */ if ((irqflags &amp; (IRQF_SHARED|IRQF_DISABLED)) == (IRQF_SHARED|IRQF_DISABLED)) &#123; pr_warning( &quot;IRQ %d/%s: IRQF_DISABLED is not guaranteed on shared IRQs\n&quot;, irq, devname); &#125;#ifdef CONFIG_LOCKDEP /* * Lockdep wants atomic interrupt handlers: */ irqflags |= IRQF_DISABLED;#endif /* * Sanity-check: shared interrupts must pass in a real dev-ID, * otherwise we&apos;ll have trouble later trying to figure out * which interrupt is which (messes up the interrupt freeing * logic etc). */ if ((irqflags &amp; IRQF_SHARED) &amp;&amp; !dev_id) return -EINVAL; desc = irq_to_desc(irq); if (!desc) return -EINVAL; if (desc-&gt;status &amp; IRQ_NOREQUEST) return -EINVAL; if (!handler) &#123; if (!thread_fn) return -EINVAL; handler = irq_default_primary_handler; &#125; //分配一个irqaction action = kzalloc(sizeof(struct irqaction), GFP_KERNEL); if (!action) return -ENOMEM; action-&gt;handler = handler; action-&gt;thread_fn = thread_fn; action-&gt;flags = irqflags; action-&gt;name = devname; action-&gt;dev_id = dev_id; chip_bus_lock(irq, desc); //将创建并初始化完在的action加入desc retval = __setup_irq(irq, desc, action); chip_bus_sync_unlock(irq, desc); if (retval) kfree(action);#ifdef CONFIG_DEBUG_SHIRQ if (irqflags &amp; IRQF_SHARED) &#123; /* * It&apos;s a shared IRQ -- the driver ought to be prepared for it * to happen immediately, so let&apos;s make sure.... * We disable the irq to make sure that a &apos;real&apos; IRQ doesn&apos;t * run in parallel with our fake. */ unsigned long flags; disable_irq(irq); local_irq_save(flags); handler(irq, dev_id); local_irq_restore(flags); enable_irq(irq); &#125;#endif return retval;&#125; 下面看一下中断处理程序的实例，以rtc驱动程序为例，代码位于&lt;drivers/char/rtc.c&gt;中。当RTC驱动装载时，rtc_init()函数会被调用来初始化驱动程序，包括注册中断处理函数：12345678910/* * XXX Interrupt pin #7 in Espresso is shared between RTC and * PCI Slot 2 INTA# (and some INTx# in Slot 1). */if (request_irq(rtc_irq, rtc_interrupt, IRQF_SHARED, &quot;rtc&quot;, (void *)&amp;rtc_port)) &#123; rtc_has_irq = 0; printk(KERN_ERR &quot;rtc: cannot register IRQ %d\n&quot;, rtc_irq); return -EIO;&#125; 处理程序函数rtc_interrupt()：123456789101112131415161718192021222324252627282930313233343536373839404142/* * A very tiny interrupt handler. It runs with IRQF_DISABLED set, * but there is possibility of conflicting with the set_rtc_mmss() * call (the rtc irq and the timer irq can easily run at the same * time in two different CPUs). So we need to serialize * accesses to the chip with the rtc_lock spinlock that each * architecture should implement in the timer code. * (See ./arch/XXXX/kernel/time.c for the set_rtc_mmss() function.) */static irqreturn_t rtc_interrupt(int irq, void *dev_id)&#123; /* * Can be an alarm interrupt, update complete interrupt, * or a periodic interrupt. We store the status in the * low byte and the number of interrupts received since * the last read in the remainder of rtc_irq_data. */ spin_lock(&amp;rtc_lock); //保证rtc_irq_data不被SMP机器上其他处理器同时访问 rtc_irq_data += 0x100; rtc_irq_data &amp;= ~0xff; if (is_hpet_enabled()) &#123; /* * In this case it is HPET RTC interrupt handler * calling us, with the interrupt information * passed as arg1, instead of irq. */ rtc_irq_data |= (unsigned long)irq &amp; 0xF0; &#125; else &#123; rtc_irq_data |= (CMOS_READ(RTC_INTR_FLAGS) &amp; 0xF0); &#125; if (rtc_status &amp; RTC_TIMER_ON) mod_timer(&amp;rtc_irq_timer, jiffies + HZ/rtc_freq + 2*HZ/100); spin_unlock(&amp;rtc_lock); /* Now do the rest of the actions */ spin_lock(&amp;rtc_task_lock); //避免rtc_callback出现系统情况，RTC驱动允许注册一个回调函数在每个RTC中断到来时执行。 if (rtc_callback) rtc_callback-&gt;func(rtc_callback-&gt;private_data); spin_unlock(&amp;rtc_task_lock); wake_up_interruptible(&amp;rtc_wait); kill_fasync(&amp;rtc_async_queue, SIGIO, POLL_IN); return IRQ_HANDLED;&#125; 在内核中，中断的旅程开始于预定义入口点，这类似于系统调用。对于每条中断线，处理器都会跳到对应的一个唯一的位置。这样，内核就可以知道所接收中断的IRQ号了。初始入口点只是在栈中保存这个号，并存放当前寄存器的值(这些值属于被中断的任务)；然后，内核调用函数do_IRQ().从这里开始，大多数中断处理代码是用C写的。do_IRQ()的声明如下：1unsigned int do_IRQ(struct pt_regs regs) 因为C的调用惯例是要把函数参数放在栈的顶部，因此pt_regs结构包含原始寄存器的值，这些值是以前在汇编入口例程中保存在栈上的。中断的值也会得以保存，所以，do_IRQ()可以将它提取出来，X86的代码为：1int irq = regs.orig_eax &amp; 0xff 计算出中断号后，do_IRQ()对所接收的中断进行应答，禁止这条线上的中断传递。在普通的PC机器上，这些操作是由mask_and_ack_8259A()来完成的，该函数由do_IRQ()调用。接下来，do_IRQ()需要确保在这条中断线上有一个有效的处理程序，而且这个程序已经启动但是当前没有执行。如果这样的话， do_IRQ()就调用handle_IRQ_event()来运行为这条中断线所安装的中断处理程序，函数位于&lt;kernel/irq/handle.c&gt;:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * handle_IRQ_event - irq action chain handler * @irq: the interrupt number * @action: the interrupt action chain for this irq * * Handles the action chain of an irq event */ irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action)&#123; irqreturn_t ret, retval = IRQ_NONE; unsigned int status = 0; //如果没有设置IRQF_DISABLED，将CPU中断打开，应该尽量避免中断关闭情况，本地中断关闭情况下会导致中断丢失。 if (!(action-&gt;flags &amp; IRQF_DISABLED)) local_irq_enable_in_hardirq(); do &#123; //遍历运行中断处理程序 trace_irq_handler_entry(irq, action); ret = action-&gt;handler(irq, action-&gt;dev_id); trace_irq_handler_exit(irq, action, ret); switch (ret) &#123; case IRQ_WAKE_THREAD: /* * Set result to handled so the spurious check * does not trigger. */ ret = IRQ_HANDLED; /* * Catch drivers which return WAKE_THREAD but * did not set up a thread function */ if (unlikely(!action-&gt;thread_fn)) &#123; warn_no_thread(irq, action); break; &#125; /* * Wake up the handler thread for this * action. In case the thread crashed and was * killed we just pretend that we handled the * interrupt. The hardirq handler above has * disabled the device interrupt, so no irq * storm is lurking. */ if (likely(!test_bit(IRQTF_DIED, &amp;action-&gt;thread_flags))) &#123; set_bit(IRQTF_RUNTHREAD, &amp;action-&gt;thread_flags); wake_up_process(action-&gt;thread); &#125; /* Fall through to add to randomness */ case IRQ_HANDLED: status |= action-&gt;flags; break; default: break; &#125; retval |= ret; action = action-&gt;next; &#125; while (action); if (status &amp; IRQF_SAMPLE_RANDOM) add_interrupt_randomness(irq); local_irq_disable();//关中断 return retval;&#125; 前面说到中断应该尽快执行完，以保证被中断代码可以尽快的恢复执行。但事实上中断通常有很多工作要做，包括应答、重设硬件、数据拷贝、处理请求、发送请求等。为了求得平衡，内核把中断处理工作分成两半，中断处理程序是上半部——接收到中断就开始执行。能够稍后完成的工作推迟到下半部操作，下半部在合适的时机被开中段执行。例如网卡收到数据包时立即发出中断，内核执行网卡已注册的中断处理程序，此处工作就是通知硬件拷贝最新的网络数据包到内存，然后将控制权交换给系统之前被中断的任务，其他的如处理和操作数据包等任务被放到随后的下半部中去执行。下一节我们将了解中断处理的下半部。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（一）：系统调用]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】一般情况下进程不能访问内核所占内存空间也不能调用内核函数。为了和用户空间上运行的进程进行交互，内核提供了一组接口。透过该接口，应用程序可以访问硬件设备和其他操作系统资源。这组接口在应用程序和内核之间扮演了使者的角色，应用程序发送各种请求，而内核负责满足这些请求(或者让应用程序暂时搁置)。系统调用就是用户空间应用程序和内核提供的服务之间的一个接口。 系统调用在用户空间进程和硬件设备之间添加了一个中间层，其为用户空间提供了一种统一的硬件的抽象接口，保证了系统的稳定和安全，使用户程序具有可移植性。例如fork(),read(), write()等用户程序可以使用的函数都是系统调用。 用户空间的程序无法直接执行内核代码。它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。那么应用程序应该以何种方式通知系统，系统如何切换到内核态？ 其实这种改变是通过软中断来实现。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。x86系统上的软中断由int产生。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并执行0x80号异常处理程序。此时的异常处理程序实际上就是系统调用处理程序，该处理程序的名字为system_call,它与硬件体系结构紧密相关。对于x86-32系统来说，该处理程序位于arch/x86/kernel/entry_32.S文件中,代码为：1234567891011121314151617181920212223242526...... # system call handler stubENTRY(system_call) RING0_INT_FRAME # can&apos;t unwind into user space anyway pushl %eax # save orig_eax CFI_ADJUST_CFA_OFFSET 4 SAVE_ALL GET_THREAD_INFO(%ebp) # system call tracing in operation / emulation testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp) jnz syscall_trace_entry cmpl $(nr_syscalls), %eax jae syscall_badsyssyscall_call: call *sys_call_table(,%eax,4) //此处执行相应的系统调用 movl %eax,PT_EAX(%esp) # store the return valuesyscall_exit: LOCKDEP_SYS_EXIT DISABLE_INTERRUPTS(CLBR_ANY) # make sure we don&apos;t miss an interrupt # setting need_resched or sigpending # between sampling and the iret TRACE_IRQS_OFF movl TI_flags(%ebp), %ecx testl $_TIF_ALLWORK_MASK, %ecx # current-&gt;work jne syscall_exit_work ...... 在Linux中，每个系统调用被赋予一个系统调用号。这样，通过这个独一无二的号就可以关联系统调用。当用户空间的进程执行一个系统调用的时候，这个系统调用号就被用来指明到底是要执行哪个系统调用。进程不会提及系统调用的名称。系统调用号定义文件以及形式如下：1234567891011121314$ cat ./arch/x86/include/asm/unistd.h#ifdef __KERNEL__ # ifdef CONFIG_X86_32# include &quot;unistd_32.h&quot;# else# include &quot;unistd_64.h&quot;# endif#else# ifdef __i386__# include &quot;unistd_32.h&quot;# else# include &quot;unistd_64.h&quot;# endif#endif 12345678910111213141516171819202122232425262728293031# cat arch/x86/include/asm/unistd_32.h#ifndef _ASM_X86_UNISTD_32_H#define _ASM_X86_UNISTD_32_H/* * This file contains the system call numbers. */#define __NR_restart_syscall 0#define __NR_exit 1#define __NR_fork 2#define __NR_read 3#define __NR_write 4#define __NR_open 5#define __NR_close 6#define __NR_waitpid 7#define __NR_creat 8#define __NR_link 9#define __NR_unlink 10#define __NR_execve 11#define __NR_chdir 12#define __NR_time 13#define __NR_mknod 14#define __NR_chmod 15#define __NR_lchown 16#define __NR_break 17#define __NR_oldstat 18#define __NR_lseek 19#define __NR_getpid 20#define __NR_mount 21...... 系统调用号相当关键，一旦分配就不能再有任何变更，否则编译好的应用程序就会崩溃。Linux有一个“未实现”系统调用sys_ni_syscall()，它除了返回一ENOSYS外不做任何其他工作，这个错误号就是专门针对无效的系统调用而设的。 因为所有的系统调用陷入内核的方式都一样，所以仅仅是陷入内核空间是不够的。因此必须把系统调用号一并传给内核。在x86上，系统调用号是通过eax寄存器传递给内核的。在陷人内核之前，用户空间就把相应系统调用所对应的号放入eax中了。这样系统调用处理程序一旦运行，就可以从eax中得到数据。其他体系结构上的实现也都类似。 内核记录了系统调用表中的所有已注册过的系统调用的列表，存储在sys_call_table中。它与体系结构有关，32位x86一般定义在arch/x86/kernel/syscall_table_32.s文件中。这个表中为每一个有效的系统调用指定了惟一的系统调用号。sys_call_table是一张由指向实现各种系统调用的内核函数的函数指针组成的表。syscall_table_32.s文件如下：1234567891011121314151617181920212223242526ENTRY(sys_call_table) .long sys_restart_syscall /* 0 - old &quot;setup()&quot; system call, used for restarting */ .long sys_exit .long ptregs_fork .long sys_read .long sys_write .long sys_open /* 5 */ .long sys_close .long sys_waitpid .long sys_creat .long sys_link .long sys_unlink /* 10 */ .long ptregs_execve ...... .long sys_timerfd_settime /* 325 */ .long sys_timerfd_gettime .long sys_signalfd4 .long sys_eventfd2 .long sys_epoll_create1 .long sys_dup3 /* 330 */ .long sys_pipe2 .long sys_inotify_init1 .long sys_preadv .long sys_pwritev .long sys_rt_tgsigqueueinfo /* 335 */ .long sys_perf_event_open system_call()函数通过将给定的系统调用号与NR_syscalls做比较来检查其有效性。如果它大于或者等于NR syscalls,该函数就返回一ENOSYS。否则，就执行相应的系统调用。1call *sys_call_table(，%eax, 4) 由于系统调用表中的表项是以32位(4字节)类型存放的，所以内核需要将给定的系统调用号乘以4，然后用所得的结果在该表中查询其位置。 除了系统调用号以外，大部分系统调用都还需要一些外部的参数输入。所以，在发生异常的时候，应该把这些参数从用户空间传给内核。最简单的办法就是像传递系统调用号一样把这些参数也存放在寄存器里。在x86系统上，ebx, ecx, edx, esi和edi按照顺序存放前五个参数。需要六个或六个以上参数的情况不多见，此时，应该用一个单独的寄存器存放指向所有这些参数在用户空间地址的指针。给用户空间的返回值也通过寄存器传递。在x86系统上，它存放在eax寄存器中。下面我们看看用中断的方式如何完成系统调用功能：1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;int main(int argc, const char *argv[])&#123; pid_t pid; asm volatile ( &quot;mov $0, %%ebx\n\t&quot; &quot;mov $20, %%eax\n\t&quot; //把系统调用号20放入eax寄存器中，20对应于SYS_getpid()系统调用 &quot;int $0x80\n\t&quot; //0x80中断 &quot;mov %%eax, %0\n\t&quot; //将执行结果存放在pid变量中 :&quot;=m&quot;(pid) ); printf(&quot;int PID: %d\n&quot;, pid); printf(&quot;api PID: %d\n&quot;, getpid()); return 0;&#125; 此处没有传递参数，因为getpid不需要参数。本实例执行结果为：123$ ./target_binint PID: 4911api PID: 4911 一般情况下，应用程序通过在用户空间实现的应用编程接口（API）而不是系统调用来编程。API是一个函数定义，说明了如何获得一个给定的服务，比如read()、malloc()、free（）、abs()等。它有可能和系统调用形式上一致，比如read()接口就和read系统调用对应，但这种对应并非一一对应，往往会出现几种不同的API内部用到统一个系统调用，比如malloc()、free（）内部利用brk( )系统调用来扩大或缩小进程的堆；或一个API利用了好几个系统调用组合完成服务。更有些API甚至不需要任何系统调用——因为它不必需要内核服务，如计算整数绝对值的abs（）接口。 Linux的用户编程接口遵循了在Unix世界中最流行的应用编程界面标准——POSIX标准，这套标准定义了一系列API。在Linux中（Unix也如此）这些API主要是通过C库（libc）实现的，它除了定义的一些标准的C函数外，一个很重要的任务就是提供了一套封装例程将系统调用在用户空间包装后供用户编程使用。不过封装并非必须的，如果你愿意直接调用，内核也提供了一个syscall()函数来实现调用。如下示例为使用c库调用和直接调用分别来获取当前进程ID：12345678910111213#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;int main(int argc, const char *argv[])&#123; pid_t pid, pidt; pid = getpid(); pidt = syscall(SYS_getpid); printf(&quot;getpid: %d\n&quot;, pid); printf(&quot;SYS_getpid: %d\n&quot;, pidt); return 0;&#125; 系统调用在内核有一个实现函数，以getpid为例，其在内核实现为：12345678910111213/** * sys_getpid - return the thread group id of the current process * * Note, despite the name, this returns the tgid not the pid. The tgid and * the pid are identical unless CLONE_THREAD was specified on clone() in * which case the tgid is the same in all threads of the same group. * * This is SMP safe as current-&gt;tgid does not change. */SYSCALL_DEFINE0(getpid)&#123; return task_tgid_vnr(current);&#125; 其中SYSCALL_DEFINE0为一个宏，它定义一个无参数（尾部数字代表参数个数）的系统调用，展开后代码如下：1234asmlinkage long sys_getpid(void)&#123; return current-&gt;tpid;&#125; 其中asmlinkage 是一个编译指令，通知编译器仅从栈中提取该函数参数，所有系统调用都需要这个限定词。系统调用getpid()在内核中被定义成sys_getpid()，这是linux所有系统调用都应该遵守的命名规则。 下面总结一下系统调用的实现过程：Linux中实现系统调用利用了0x86体系结构中的软件中断，也就是调用int $0x80汇编指令，这条汇编指令将产生向量为128的编程异常，此时处理器切换到内核态并执行0x80号异常处理程序。此时的异常处理程序实际上就是系统调用处理程序，该处理程序的名字为system_call()，对于x86-32系统来说，该处理程序位于arch/x86/kernel/entry_32.S文件中，使用汇编语言编写。那么所有的系统调用都会转到这里。在执行int0x80前，系统调用号被装入eax寄存器（相应参数也会传递到其它寄存器中），这个系统调用号被用来指明到底是要执行哪个系统调用，这样系统调用处理程序一旦运行，就从eax中得到系统调用号，然后根据系统调用号在系统调用表中寻找相应服务例程（例如sys_getpid()函数）。当服务例程结束时，system_call( ) 从eax获得系统调用的返回值，并把这个返回值存放在曾保存用户态 eax寄存器栈单元的那个位置上，最后该函数再负责切换到用户空间，使用户进程继续执行。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23种设计模式总结]]></title>
    <url>%2F2019%2F05%2F14%2F23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式总结: 前言：个人觉得设计模式就是各个对象在不同的时机、不同的调用方被创建，组合结构和封装的侧重点有些不同，从而形成了各个模式的概念。 简单工厂模式通过在工厂类中进行判断，然后创建需要的功能类。简单工厂模式是工厂模式中最简单的一种，他可以用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。 假如，我们不用工厂类，只用AbstractProduct和它的子类，那客户端每次使用不同的子类的时候都需要知道到底是用哪一个子类，当类比较少的时候还没什么问题，但是当类比较多的时候，管理起来就非常的麻烦了，就必须要做大量的替换，一个不小心就会发生错误。 而使用了工厂类之后，就不会有这样的问题，不管里面多少个类，我只需要知道类型号即可。不过，这里还有一个疑问，那就是如果我每次用工厂类创建的类型都不相同，这样修改起来的时候还是会出现问题，还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。 客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。 常用的场景：例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。这样，每次只需要修改配置文件和添加新的产品子类即可。所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。 优点 隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。 客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。 方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。 遵循了依赖倒转原则。 缺点 要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。 每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。 代码演示：抽象产品类代码：12345678910namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象产品类： 汽车 /// &lt;/summary&gt; public interface ICar &#123; void GetCar(); &#125;&#125; 具体产品类代码：123456789101112131415161718192021222324252627282930313233343536373839404142namespace CNBlogs.DesignPattern.Common&#123; public enum CarType &#123; SportCarType = 0, JeepCarType = 1, HatchbackCarType = 2 &#125; /// &lt;summary&gt; /// 具体产品类： 跑车 /// &lt;/summary&gt; public class SportCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把跑车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 越野车 /// &lt;/summary&gt; public class JeepCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把越野车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 两箱车 /// &lt;/summary&gt; public class HatchbackCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把两箱车交给范·迪塞尔&quot;); &#125; &#125;&#125; 简单工厂核心代码：1234567891011121314151617181920namespace CNBlogs.DesignPattern.Common&#123; public class Factory &#123; public ICar GetCar(CarType carType) &#123; switch (carType) &#123; case CarType.SportCarType: return new SportCar(); case CarType.JeepCarType: return new JeepCar(); case CarType.HatchbackCarType: return new HatchbackCar(); default: throw new Exception(&quot;爱上一匹野马,可我的家里没有草原. 你走吧！&quot;); &#125; &#125; &#125;&#125; 客户端调用代码：1234567891011121314151617181920212223242526272829303132//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; ICar car; try &#123; Factory factory = new Factory(); Console.WriteLine(&quot;范·迪塞尔下一场戏开跑车。&quot;); car = factory.GetCar(CarType.SportCarType); car.GetCar(); &#125; catch (Exception ex) &#123; Console.WriteLine(ex.Message); &#125; &#125; &#125;&#125; 策略模式假设一个功能类是一个策略，调用的时候需要创建这个策略的实例，传进一个类似策略控制中心的方法中，然后通过策略基类调用这个传进去的实例子类的方法。 优点：就是相对工厂模式免去了创建那个功能类的判断，简化了工厂模式。缺点：就是把子类实例赋值给了父类，这样就丢掉了子类新增的功能。 工厂方法模式(属于工厂模式)把简单工厂模式中的工厂类，做了进一步的抽象为接口或抽象类，给各个功能创建一个对应的工厂类，然后在这个工厂类里面去创建对应的实例。工厂模式基本与简单工厂模式差不多，上面也说了，每次添加一个产品子类都必须在工厂类中添加一个判断分支，这样违背了开放-封闭原则，因此，工厂模式就是为了解决这个问题而产生的。 既然每次都要判断，那我就把这些判断都生成一个工厂子类，这样，每次添加产品子类的时候，只需再添加一个工厂子类就可以了。这样就完美的遵循了开放-封闭原则。但这其实也有问题，如果产品数量足够多，要维护的量就会增加，好在一般工厂子类只用来生成产品类，只要产品子类的名称不发生变化，那么基本工厂子类就不需要修改，每次只需要修改产品子类就可以了。 同样工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。 常用的场景基本与简单工厂模式一致，只不过是改进了简单工厂模式中的开放-封闭原则的缺陷，使得模式更具有弹性。将实例化的过程推迟到子类中，由子类来决定实例化哪个。 优点：基本与简单工厂模式一致，多的一点优点就是遵循了开放-封闭原则，使得模式的灵活性更强。缺点：当新增一个功能类，就需要创建对于的工厂类，相比简单工厂模式，免去了判断创建那个具体实例，但会创建过多的类，还不如策略模式。 代码演示： 抽象工厂代码：1234567namespace CNBlogs.DesignPattern.Common&#123; public interface IFactory &#123; ICar CreateCar(); &#125;&#125; 抽象产品代码：1234567namespace CNBlogs.DesignPattern.Common&#123; public interface ICar &#123; void GetCar(); &#125;&#125; 具体工厂代码：1234567891011121314151617181920212223242526272829303132333435namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 具体工厂类： 用于创建跑车类 /// &lt;/summary&gt; public class SportFactory : IFactory &#123; public ICar CreateCar() &#123; return new SportCar(); &#125; &#125; /// &lt;summary&gt; /// 具体工厂类： 用于创建越野车类 /// &lt;/summary&gt; public class JeepFactory : IFactory &#123; public ICar CreateCar() &#123; return new JeepCar(); &#125; &#125; /// &lt;summary&gt; /// 具体工厂类： 用于创建两厢车类 /// &lt;/summary&gt; public class HatchbackFactory : IFactory &#123; public ICar CreateCar() &#123; return new HatchbackCar(); &#125; &#125;&#125; 具体产品代码：1234567891011121314151617181920212223242526272829303132333435namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 具体产品类： 跑车 /// &lt;/summary&gt; public class SportCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把跑车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 越野车 /// &lt;/summary&gt; public class JeepCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把越野车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 两箱车 /// &lt;/summary&gt; public class HatchbackCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把两箱车交给范·迪塞尔&quot;); &#125; &#125;&#125; 客户端代码：12345678910111213141516171819202122232425262728293031323334//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System.IO; using System.Configuration; using System.Reflection; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; // 工厂类的类名写在配置文件中可以方便以后修改 string factoryType = ConfigurationManager.AppSettings[&quot;FactoryType&quot;]; // 这里把DLL配置在数据库是因为以后数据可能发生改变 // 比如说现在的数据是从sql server取的，以后需要从oracle取的话只需要添加一个访问oracle数据库的工程就行了 string dllName = ConfigurationManager.AppSettings[&quot;DllName&quot;]; // 利用.NET提供的反射可以根据类名来创建它的实例，非常方便 var currentAssembly = System.Reflection.Assembly.GetExecutingAssembly(); string codeBase = currentAssembly.CodeBase.ToLower().Replace(currentAssembly.ManifestModule.Name.ToLower(), string.Empty); IFactory factory = Assembly.LoadFrom(Path.Combine(codeBase, dllName)).CreateInstance(factoryType) as IFactory; ICar car = factory.CreateCar(); car.GetCar(); &#125; &#125;&#125; 装饰模式一般情况下，当一个基类写好之后，我们也许不愿意去改动，也不能改动，原因是这样的在项目中用得比较久的基类，一旦改动，也许会影响其他功能模块，但是，又要在该类上面添加功能。使用继承，当在A阶段，写出继承类，用过一段时间，发现又要添加新功能，于是又要从原始类或A阶段的类继承，周而复始，慢慢的，子类就越来越多，层级就越来越深。然而，事实上，在C阶段需要A阶段的功能，但不需要B阶段的功能，在这种复杂情形下，继承就显得不灵活，于是想到了装饰模式。装饰模式：需要扩展一个类的功能，或给一个类增加附加责任需要动态地给一个对象增加功能，这些功能可以再动态地撤销。需要增加由一些基本功能的排列组合而产生的非常大量的功能，从而使继承关系变得不现实。 在使用装饰模式前，需要了解虚方法和抽象方法的区别：虚方法，是实例方法，可以在子类中覆盖，也可以由该类对象直接调用。抽象方法需要写在抽象类中，抽象类不能实例化，所以要使用抽象方法必须由子类实现后方可调用。 该模式中，要被扩展的类可以是包含抽象方法的抽象类，也可以是包含虚方法的实例类，也可以是普通实例类。装饰模式就是在原有基类上做扩展，至于基类是什么性质并不重要. 装饰模式在C#代码，和扩展方法，惊人的类似。 Component为统一接口，也是装饰类和被装饰类的基本类型。 ConcreteComponent为具体实现类，也是被装饰类，他本身是个具有一些功能的完整的类。 Decorator是装饰类，实现了Component接口的同时还在内部维护了一个ConcreteComponent的实例，并可以通过构造函数初始化。而Decorator本身，- 通常采用默认实现，他的存在仅仅是一个声明：我要生产出一些用于装饰的子类了。而其子类才是赋有具体装饰效果的装饰产品类。 ConcreteDecorator是具体的装饰产品类，每一种装饰产品都具有特定的装饰效果。可以通过构造器声明装饰哪种类型的ConcreteComponent，从而对其进行装饰。 最简单的代码实现装饰器模式 123456789101112131415161718192021222324252627282930313233343536373839404142//基础接口public interface Component &#123; public void biu();&#125;//具体实现类public class ConcretComponent implements Component &#123; public void biu() &#123; System.out.println(&quot;biubiubiu&quot;); &#125;&#125;//装饰类public class Decorator implements Component &#123; public Component component; public Decorator(Component component) &#123; this.component = component; &#125; public void biu() &#123; this.component.biu(); &#125;&#125;//具体装饰类public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; public void biu() &#123; System.out.println(&quot;ready?go!&quot;); this.component.biu(); &#125;&#125; 这样一个基本的装饰器体系就出来了，当我们想让Component在打印之前都有一个ready？go！的提示时，就可以使用ConcreteDecorator类了。具体方式如下： 1234567 //使用装饰器 Component component = new ConcreteDecorator(new ConcretComponent()); component.biu(); //console： ready?go! biubiubiu 为何使用装饰器模式？一个设计模式的出现一定有他特殊的价值。仅仅看见上面的结构图你可能会想，为何要兜这么一圈来实现？仅仅是想要多一行输出，我直接继承ConcretComponent，或者直接在另一个Component的实现类中实现不是一样吗？ 首先，装饰器的价值在于装饰，他并不影响被装饰类本身的核心功能。在一个继承的体系中，子类通常是互斥的。比如一辆车，品牌只能要么是奥迪、要么是宝马，不可能同时属于奥迪和宝马，而品牌也是一辆车本身的重要属性特征。但当你想要给汽车喷漆，换坐垫，或者更换音响时，这些功能是互相可能兼容的，并且他们的存在不会影响车的核心属性：那就是他是一辆什么车。这时你就可以定义一个装饰器：喷了漆的车。不管他装饰的车是宝马还是奥迪，他的喷漆效果都可以实现。 再回到这个例子中，我们看到的仅仅是一个ConcreteComponent类。在复杂的大型项目中，同一级下的兄弟类通常有很多。当你有五个甚至十个ConcreteComponent时，再想要为每个类都加上“ready？go！”的效果，就要写出五个子类了。毫无疑问这是不合理的。装饰器模式在不影响各个ConcreteComponent核心价值的同时，添加了他特有的装饰效果，具备非常好的通用性，这也是他存在的最大价值。 实战中使用装饰器模式 写这篇博客的初衷也是恰好在工作中使用到了这个模式，觉得非常好用。需求大致是这样：采用sls服务监控项目日志，以Json的格式解析，所以需要将项目中的日志封装成json格式再打印。现有的日志体系采用了log4j + slf4j框架搭建而成。调用起来是这样的:12private static final Logger logger = LoggerFactory.getLogger(Component.class);logger.error(string); 这样打印出来的是毫无规范的一行行字符串。在考虑将其转换成json格式时，我采用了装饰器模式。目前有的是统一接口Logger和其具体实现类，我要加的就是一个装饰类和真正封装成Json格式的装饰产品类。具体实现代码如下：123456789101112131415161718192021222324/** * logger decorator for other extension * this class have no specific implementation * just for a decorator definition * @author jzb * */public class DecoratorLogger implements Logger &#123; public Logger logger; public DecoratorLogger(Logger logger) &#123; this.logger = logger; &#125; @Override public void error(String str) &#123;&#125; @Override public void info(String str) &#123;&#125; //省略其他默认实现&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * json logger for formatted output * @author jzb * */public class JsonLogger extends DecoratorLogger &#123;public JsonLogger(Logger logger) &#123; super(logger); &#125; @Override public void info(String msg) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;MESSAGE&quot;, msg); logger.info(result.toString()); &#125; @Override public void error(String msg) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;MESSAGE&quot;, msg); logger.error(result.toString()); &#125; public void error(Exception e) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;EXCEPTION&quot;, e.getClass().getName()); String exceptionStackTrace = ExceptionUtils.getStackTrace(e); result.put(&quot;STACKTRACE&quot;, exceptionStackTrace); logger.error(result.toString()); &#125; public static class JsonLoggerFactory &#123; @SuppressWarnings(&quot;rawtypes&quot;) public static JsonLogger getLogger(Class clazz) &#123; Logger logger = LoggerFactory.getLogger(clazz); return new JsonLogger(logger); &#125; &#125; private JSONObject composeBasicJsonResult() &#123; //拼装了一些运行时信息 &#125;&#125; 可以看到，在JsonLogger中，对于Logger的各种接口，我都用JsonObject对象进行一层封装。在打印的时候，最终还是调用原生接口logger.error(string)，只是这个string参数已经被我们装饰过了。如果有额外的需求，我们也可以再写一个函数去实现。比如error(Exception e)，只传入一个异常对象，这样在调用时就非常方便了。 另外，为了在新老交替的过程中尽量不改变太多的代码和使用方式。我又在JsonLogger中加入了一个内部的工厂类JsonLoggerFactory（这个类转移到DecoratorLogger中可能更好一些），他包含一个静态方法，用于提供对应的JsonLogger实例。最终在新的日志体系中，使用方式如下：12private static final Logger logger = JsonLoggerFactory.getLogger(Component.class);logger.error(string); 他唯一与原先不同的地方，就是LoggerFactory -&gt; JsonLoggerFactory，这样的实现，也会被更快更方便的被其他开发者接受和习惯。 代理模式代理类成为实际想调用对象的中间件，可以控制对实际调用对象的访问权限；维护实际调用对象的一个引用。 原型模式创建好了一个实例，然后用这个实例，通过克隆方式创建另一个同类型的实例，而不必关心这个新实例是如何创建的。 原型模式使用时需要注意浅拷贝与深拷贝的问题。 建造者模式每个对象都具备自己的功能，但是，它们的创建方式却是一样的。这个时候就需要中间这个建造者类来负责功能对象实例的创建。在调用端只需调用特定的方法即可。 这个和策略模式有点类似。 抽象工厂模式使用该功能类的功能类，利用抽象工厂去创建该功能类的实例。这样的好处在于尽可能的避免去创建功能的实例。更牛逼的做法就是使用反射去创建这个功能类的实例，在调用端就一点都不需要知道要去实例化那个具体的功能类。这当然不是抽象工厂模式独有的。抽象工厂模式就变得比工厂模式更为复杂，就像上面提到的缺点一样，工厂模式和简单工厂模式要求产品子类必须要是同一类型的，拥有共同的方法，这就限制了产品子类的扩展。于是为了更加方便的扩展，抽象工厂模式就将同一类的产品子类归为一类，让他们继承同一个抽象子类，我们可以把他们一起视作一组，然后好几组产品构成一族。 此时，客户端要使用时必须知道是哪一个工厂并且是哪一组的产品抽象类。每一个工厂子类负责产生一族产品，而子类的一种方法产生一种类型的产品。在客户端看来只有AbstractProductA和AbstractProductB两种产品，使用的时候也是直接使用这两种产品。而通过工厂来识别是属于哪一族产品。 产品ProductA_1和ProductB_1构成一族产品，对应于有Factory1来创建，也就是说Factory1总是创建的ProductA_1和ProductB_1的产品，在客户端看来只需要知道是哪一类工厂和产品组就可以了。一般来说， ProductA_1和ProductB_1都是适应同一种环境的，所以他们会被归为一族。 常用的场景例如Linux和windows两种操作系统下，有2个挂件A和B，他们在Linux和Windows下面的实现方式不同，Factory1负责产生能在Linux下运行的挂件A和B，Factory2负责产生能在Windows下运行的挂件A和B，这样如果系统环境发生变化了，我们只需要修改工厂就行了。 优点 封装了产品的创建，使得不需要知道具体是哪种产品，只需要知道是哪个工厂就行了。 可以支持不同类型的产品，使得模式灵活性更强。 可以非常方便的使用一族中间的不同类型的产品。 缺点 结构太过臃肿，如果产品类型比较多，或者产品族类比较多，就会非常难于管理。 每次如果添加一组产品，那么所有的工厂类都必须添加一个方法，这样违背了开放-封闭原则。所以一般适用于产品组合产品族变化不大的情况。 抽象工厂代码：1234567891011121314151617181920namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象工厂类 /// &lt;/summary&gt; public abstract class AbstractEquipment &#123; /// &lt;summary&gt; /// 抽象方法： 创建一辆车 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public abstract AbstractCar CreateCar(); /// &lt;summary&gt; /// 抽象方法： 创建背包 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public abstract AbstractBackpack CreateBackpack(); &#125;&#125; 抽象产品代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象产品: 车抽象类 /// &lt;/summary&gt; public abstract class AbstractCar &#123; /// &lt;summary&gt; /// 车的类型属性 /// &lt;/summary&gt; public abstract string Type &#123; get; &#125; /// &lt;summary&gt; /// 车的颜色属性 /// &lt;/summary&gt; public abstract string Color &#123; get; &#125; &#125; /// &lt;summary&gt; /// 抽象产品: 背包抽象类 /// &lt;/summary&gt; public abstract class AbstractBackpack &#123; /// &lt;summary&gt; /// 包的类型属性 /// &lt;/summary&gt; public abstract string Type &#123; get; &#125; /// &lt;summary&gt; /// 包的颜色属性 /// &lt;/summary&gt; public abstract string Color &#123; get; &#125; &#125;&#125; 具体工厂代码：12345678910111213141516171819202122232425262728293031323334namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 运动装备 /// &lt;/summary&gt; public class SportEquipment : AbstractEquipment &#123; public override AbstractCar CreateCar() &#123; return new SportCar(); &#125; public override AbstractBackpack CreateBackpack() &#123; return new SportBackpack(); &#125; &#125; /// &lt;summary&gt; /// 越野装备 这里就不添加了，同运动装备一个原理，demo里只演示一个，实际项目中可以按需添加 /// &lt;/summary&gt; //public class JeepEquipment : AbstractEquipment //&#123; // public override AbstractCar CreateCar() // &#123; // return new JeeptCar(); // &#125; // public override AbstractBackpack CreateBackpack() // &#123; // return new JeepBackpack(); // &#125; //&#125;&#125; 具体产品代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 跑车 /// &lt;/summary&gt; public class SportCar : AbstractCar &#123; private string type = &quot;Sport&quot;; private string color = &quot;Red&quot;; /// &lt;summary&gt; /// 重写基类的Type属性 /// &lt;/summary&gt; public override string Type &#123; get &#123; return type; &#125; &#125; /// &lt;summary&gt; /// 重写基类的Color属性 /// &lt;/summary&gt; public override string Color &#123; get &#123; return color; &#125; &#125; &#125; /// &lt;summary&gt; /// 运动背包 /// &lt;/summary&gt; public class SportBackpack : AbstractBackpack &#123; private string type = &quot;Sport&quot;; private string color = &quot;Red&quot;; /// &lt;summary&gt; /// 重写基类的Type属性 /// &lt;/summary&gt; public override string Type &#123; get &#123; return type; &#125; &#125; /// &lt;summary&gt; /// 重写基类的Color属性 /// &lt;/summary&gt; public override string Color &#123; get &#123; return color; &#125; &#125; &#125;&#125;//具体产品可以有很多很多， 至于越野类的具体产品这里就不列出来了。 创建装备代码：1234567891011121314151617181920212223namespace CNBlogs.DesignPattern.Common&#123; public class CreateEquipment &#123; private AbstractCar fanCar; private AbstractBackpack fanBackpack; public CreateEquipment(AbstractEquipment equipment) &#123; fanCar = equipment.CreateCar(); fanBackpack = equipment.CreateBackpack(); &#125; public void ReadyEquipment() &#123; Console.WriteLine(string.Format(&quot;老范背着&#123;0&#125;色&#123;1&#125;包开着&#123;2&#125;色&#123;3&#125;车。&quot;, fanBackpack.Color, fanBackpack.Type, fanCar.Color, fanCar.Type )); &#125; &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System; using System.Configuration; using System.Reflection; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; // ***具体app.config配置如下*** // //&lt;add key=&quot;assemblyName&quot; value=&quot;CNBlogs.DesignPattern.Common&quot;/&gt; //&lt;add key=&quot;nameSpaceName&quot; value=&quot;CNBlogs.DesignPattern.Common&quot;/&gt; //&lt;add key=&quot;typename&quot; value=&quot;SportEquipment&quot;/&gt; // 创建一个工厂类的实例 string assemblyName = ConfigurationManager.AppSettings[&quot;assemblyName&quot;]; string fullTypeName = string.Concat(ConfigurationManager.AppSettings[&quot;nameSpaceName&quot;], &quot;.&quot;, ConfigurationManager.AppSettings[&quot;typename&quot;]); AbstractEquipment factory = (AbstractEquipment)Assembly.Load(assemblyName).CreateInstance(fullTypeName); CreateEquipment equipment = new CreateEquipment(factory); equipment.ReadyEquipment(); Console.Read(); &#125; &#125;&#125; 外观模式外观模式：为外界调用提供一个统一的接口，把其他类中需要用到的方法提取出来，由外观类进行调用。然后在调用段实例化外观类，以间接调用需要的方法。这种方式形式上和代理模式有异曲同工之妙。 模板模式模板模式：其实就是抽象出各个具体操作类的公共操作方法，在子类重新实现,然后使用子类去实例化父类。这个模板类其实可以使用接口替换。事实上接口才是专门用来定义操作规范。当然，当有些公共方法，各个子类均有一致需求，此时就不应使用接口，使用抽象类。 状态模式一个方法的判断逻辑太长，就不容易修改。方法过长，其本质就是，就是本类在不同条件下的状态转移。状态模式，就是将这些判断分开到各个能表示当前状态的独立类中。 备忘录模式备忘录模式：事实上我觉得这个东西没什么用，按照这种方式进行备份，会因为值类型与引用类型的不同而导致数据丢失。 适配器模式适配器模式：其实就是代理模式的一个变种，代码的编写方式都差不多。只是，使用这两种模式的出发点不一样，导致这两种模式产生了细微的差别。 组合模式当对象或系统之间出现部分与整体，或类似树状结构的情况时，考虑组合模式。相对装饰模式来说，这两个有异曲同工之妙，都强调对象间的组合，但是，装饰模式同时强调组合的顺序，而组合模式则是随意组合与移除。 单例模式能避免同一对象被反复实例化。比如说，访问数据库的连接对象就比普通对象实例化的时间要长;WCF中，维护服务器端远程对象的创建等，这类情况，很有必要用单例模式进行处理对象的实例化。 单例模式也称为单件模式、单子模式，可能是使用最广泛的设计模式。其意图是保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。有很多地方需要这样的功能模块，如系统的日志输出，GUI应用必须是单鼠标，MODEM的联接需要一条且只需要一条电话线，操作系统只能有一个窗口管理器，一台PC连一个键盘。 单例模式有许多种实现方法，在C++中，甚至可以直接用一个全局变量做到这一点，但这样的代码显的很不优雅。 使用全局对象能够保证方便地访问实例，但是不能保证只声明一个对象——也就是说除了一个全局实例外，仍然能创建相同类的本地实例。《设计模式》一书中给出了一种很不错的实现，定义一个单例类，使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。 单例模式通过类本身来管理其唯一实例，这种特性提供了解决问题的方法。唯一的实例是类的一个普通对象，但设计这个类时，让它只能创建一个实例并提供对此实例的全局访问。唯一实例类Singleton在静态成员函数中隐藏创建实例的操作。习惯上把这个成员函数叫做Instance()，它的返回值是唯一实例的指针。定义如下：123456789101112131415class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125; static CSingleton *m_pInstance;public: static CSingleton * GetInstance() &#123; if(m_pInstance == NULL) //判断是否第一次调用 m_pInstance = new CSingleton(); return m_pInstance; &#125;&#125;; 用户访问唯一实例的方法只有GetInstance()成员函数。如果不通过这个函数，任何创建实例的尝试都将失败，因为类的构造函数是私有的。GetInstance()使用懒惰初始化，也就是说它的返回值是当这个函数首次被访问时被创建的。这是一种防弹设计——所有GetInstance()之后的调用都返回相同实例的指针：123CSingleton* p1 = CSingleton :: GetInstance();CSingleton* p2 = p1-&gt;GetInstance();CSingleton &amp; ref = * CSingleton :: GetInstance(); 对GetInstance稍加修改，这个设计模板便可以适用于可变多实例情况，如一个类允许最多五个实例。 单例类CSingleton有以下特征： 它有一个指向唯一实例的静态指针m_pInstance，并且是私有的； 它有一个公有的函数，可以获取这个唯一的实例，并且在需要的时候创建该实例； 它的构造函数是私有的，这样就不能从别处创建该类的实例。 大多数时候，这样的实现都不会出现问题。有经验的读者可能会问，m_pInstance指向的空间什么时候释放呢？更严重的问题是，该实例的析构函数什么时候执行？如果在类的析构行为中有必须的操作，比如关闭文件，释放外部资源，那么上面的代码无法实现这个要求。我们需要一种方法，正常的删除该实例。可以在程序结束时调用GetInstance()，并对返回的指针掉用delete操作。这样做可以实现功能，但不仅很丑陋，而且容易出错。因为这样的附加代码很容易被忘记，而且也很难保证在delete之后，没有代码再调用GetInstance函数。一个妥善的方法是让这个类自己知道在合适的时候把自己删除，或者说把删除自己的操作挂在操作系统中的某个合适的点上，使其在恰当的时候被自动执行。我们知道，程序在结束的时候，系统会自动析构所有的全局变量。事实上，系统也会析构所有的类的静态成员变量，就像这些静态成员也是全局变量一样。利用这个特征，我们可以在单例类中定义一个这样的静态成员变量，而它的唯一工作就是在析构函数中删除单例类的实例。如下面的代码中的CGarbo类（Garbo意为垃圾工人）：12345678910111213141516171819202122232425class CSingleton&#123;private: CSingleton() &#123; &#125; static CSingleton *m_pInstance; class CGarbo //它的唯一工作就是在析构函数中删除CSingleton的实例 &#123; public: ~CGarbo() &#123; if(CSingleton::m_pInstance) delete CSingleton::m_pInstance; &#125; &#125;; static CGarbo Garbo; //定义一个静态成员变量，程序结束时，系统会自动调用它的析构函数public: static CSingleton * GetInstance() &#123; if(m_pInstance == NULL) //判断是否第一次调用 m_pInstance = new CSingleton(); return m_pInstance; &#125;&#125;; 类CGarbo被定义为CSingleton的私有内嵌类，以防该类被在其他地方滥用。程序运行结束时，系统会调用CSingleton的静态成员Garbo的析构函数，该析构函数会删除单例的唯一实例。使用这种方法释放单例对象有以下特征： 在单例类内部定义专有的嵌套类； 在单例类内定义私有的专门用于释放的静态成员； 利用程序在结束时析构全局变量的特性，选择最终的释放时机； 使用单例的代码不需要任何操作，不必关心对象的释放。 但是添加一个类的静态对象，总是让人不太满意，所以有人用如下方法来重新实现单例和解决它相应的问题，代码如下：12345678910111213class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125;public: static CSingleton &amp; GetInstance() &#123; static CSingleton instance; //局部静态变量 return instance; &#125;&#125;; 使用局部静态变量，非常强大的方法，完全实现了单例的特性，而且代码量更少，也不用担心单例销毁的问题。但使用此种方法也会出现问题，当如下方法使用单例时问题来了，Singleton singleton = Singleton :: GetInstance();这么做就出现了一个类拷贝的问题，这就违背了单例的特性。产生这个问题原因在于：编译器会为类生成一个默认的构造函数，来支持类的拷贝。最后没有办法，我们要禁止类拷贝和类赋值，禁止程序员用这种方式来使用单例，当时领导的意思是GetInstance()函数返回一个指针而不是返回一个引用，函数的代码改为如下：12345678910111213class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125;public: static CSingleton * GetInstance() &#123; static CSingleton instance; //局部静态变量 return &amp;instance; &#125;&#125;; 但我总觉的不好，为什么不让编译器不这么干呢。这时我才想起可以显示的声明类拷贝的构造函数，和重载 = 操作符，新的单例类如下：123456789101112131415class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125; CSingleton(const CSingleton &amp;); CSingleton &amp; operator = (const CSingleton &amp;);public: static CSingleton &amp; GetInstance() &#123; static CSingleton instance; //局部静态变量 return instance; &#125;&#125;; 关于Singleton(const Singleton);和 Singleton &amp; operate = (const Singleton&amp;);函数，需要声明成私有的，并且只声明不实现。这样，如果用上面的方式来使用单例时，不管是在友元类中还是其他的，编译器都是报错。不知道这样的单例类是否还会有问题，但在程序中这样子使用已经基本没有问题了。 考虑到线程安全、异常安全，可以做以下扩展12345678910111213141516171819202122232425262728293031323334353637383940414243class Lock&#123;private: CCriticalSection m_cs;public: Lock(CCriticalSection cs) : m_cs(cs) &#123; m_cs.Lock(); &#125; ~Lock() &#123; m_cs.Unlock(); &#125;&#125;; class Singleton&#123;private: Singleton(); Singleton(const Singleton &amp;); Singleton&amp; operator = (const Singleton &amp;); public: static Singleton *Instantialize(); static Singleton *pInstance; static CCriticalSection cs;&#125;; Singleton* Singleton::pInstance = 0; Singleton* Singleton::Instantialize()&#123; if(pInstance == NULL) &#123; //double check Lock lock(cs); //用lock实现线程安全，用资源管理类，实现异常安全 //使用资源管理类，在抛出异常的时候，资源管理类对象会被析构，析构总是发生的无论是因为异常抛出还是语句块结束。 if(pInstance == NULL) &#123; pInstance = new Singleton(); &#125; &#125; return pInstance;&#125; 之所以在Instantialize函数里面对pInstance 是否为空做了两次判断，因为该方法调用一次就产生了对象，pInstance == NULL 大部分情况下都为false，如果按照原来的方法，每次获取实例都需要加锁，效率太低。而改进的方法只需要在第一次 调用的时候加锁，可大大提高效率。 迭代器模式提供一种方法访问一个容器对象中各个元素，而又不需暴露该对象的内部细节。 Foreach就是这种模式应用的代表。 职责链模式职责链模式：就是一个将请求或命令进行转发的流程，类似工作流。并且，也非常类似状态模式，它们共同的特点就是将一个复杂的判断逻辑，转移到各个子类，然后在由子类进行简单判断。 状态模式与职责链模式的区别：状态模式是让各个状态对象自己知道其下一个处理的对象是谁，即在编译时便设定好了的；而职责链模式中的各个对象并不指定其下一个处理的对象到底是谁，只有在客户端才设定。 命令模式当有客户端发送了一系列的命令或请求，去要求某个对象实现什么操作，可使用命令模式，相当于多个命令发给一个对象。 这一点和观察者模式非常的类似。观察者模式也是某个对象，发出消息，然后由中间对象通知观察者然后去做什么，封装的是要执行操作的对象。而命令模式，则是将各个操作封装成类，然后告知某个对象该做什么。两者的区别是封装的角度不同。 桥接模式依据合成/聚合原则，优先使用类之间的不同组合，来实现各个类要表现的功能,而不是使用继承。比如说：继承会延续父类的功能，然而，并不是所有的子类都需要这样的功能，但是抽象出的东西在父类，导致子类又必须要实现它，这样，父类就越来越庞大，子类又多了很多不必要的东西。因此，桥接模式更强调类之间的组合从而实现解耦。 对比组合模式，它更强调的是部分与整体间的组合，桥接模式强调的是平行级别上不同类的组合。 解释器模式举例：写好了C#代码，VB代码，此时需要个编译器来编译。这时，这个编译器就相当于解释器，解释好了交给CPU执行。 解释器跟适配器模式有点类似，但是，适配器模式不需要预先知道要适配的规则，解释器是根据规则去执行解释。 享元模式享元模式其实是为了避免创建过多的数据对象。比如此列：在象棋中只有红黑双方，红棋子只是红棋中的一颗，很多红棋其实可以使用一个红棋对象表示即可，在外部只需公开该棋的状态即可区分那个红棋，从而达到减少内存消耗的目的。 中介者模式中介者模式：中介者类唯一要干的事情就是给各个成员对象发出通知。因此，中介者事先就应该知道有哪些成员。 中介者模式和代理模式，观察者模式非常的像。但是其它两种模式在调用的时候，并不需要事先设置那个类被代理，或是事先那些对象需要被通知。 访问者模式在不改变原有代码的结构上，又想去影响原来的类，或是访问原来类的成员，此时就可以使用访问者模式。但需要注意的是：事先需要构造好那些要访问的对象的对象结构。这个结构在访问者类中去维护。 观察者模式就是消息订阅–发布模式。本来原始的状况是需要在观察者类内部设置需要通知的对象。结果现在出现了事件。定义委托来通知其他对象，显得更简洁。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode861. Score After Flipping Matrix]]></title>
    <url>%2F2019%2F05%2F13%2FLeetcode861-Score-After-Flipping-Matrix%2F</url>
    <content type="text"><![CDATA[We have a two dimensional matrix A where each value is 0 or 1. A move consists of choosing any row or column, and toggling each value in that row or column: changing all 0s to 1s, and all 1s to 0s. After making any number of moves, every row of this matrix is interpreted as a binary number, and the score of the matrix is the sum of these numbers. Return the highest possible score. Example 1:12345Input: [[0,0,1,1],[1,0,1,0],[1,1,0,0]]Output: 39Explanation:Toggled to [[1,1,1,1],[1,0,0,1],[1,1,1,1]].0b1111 + 0b1001 + 0b1111 = 15 + 9 + 15 = 39 Note: 1 &lt;= A.length &lt;= 201 &lt;= A[0].length &lt;= 20A[i][j] is 0 or 1. 思路：对一个只有0和1的二维矩阵，移动是指选择任一行或任一列，将所有的0变成1，所有的1变成0，在作出任意次数的移动后，将该矩阵中的每一行都按照二进制数来解释，输出和的最大值。要注意的是行和列任意次移动，达到最大值。即以求出最优解为目标（可重复移动）。按二进制数来解释，注意数组[0-n]对应二进制“高位-低位”。 首先对行移动求最优解：二进制数，高位的有效值“1”大于后面所有位数之和，举个例子：10000=16 01010=10 00111=7。所以我们需要判断A[i]0是否为“1”，将为“0”的进行移动操作，本行即达到最优。重复每行即为所有行最优 再对列移动求最优解：本题为矩阵，所以同一列的数字在二进制解释中位于相同的位置（2^n），当一列中”1”的数量最大时,结果值最大。即为列最优解，同理求出所有列最优解。 最后计算矩阵的总和，注意从低位（数组尾部开始计算）。 若行最高位（数组行首元素）不为“1”，移动行。 若列“0”数量多于“1”，移动列。 从低位（行数组尾部）开始计算数组行值。 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int matrixScore(vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++) if(A[i][0]==0) for(int j=0;j&lt;A[i].size();j++) A[i][j]=1-A[i][j]; for(int j=0;j&lt;A[0].size();j++)&#123; int zero=0,one=0; for(int i=0;i&lt;A.size();i++)&#123; if(A[i][j]==0) zero++; else one++; &#125; if(zero&gt;one) for(int i=0;i&lt;A.size();i++) A[i][j]=1-A[i][j]; &#125; int sum=0; for(int i=0;i&lt;A.size();i++)&#123; int temp = 0,in=1; for(int j=A[i].size()-1;j&gt;=0;j--)&#123; temp+=A[i][j]*in; in*=2; &#125; sum+=temp; &#125; return sum; &#125;&#125;; 附上Solution： Notice that a 1 in the i’th column from the right, contributes 2^i to the score. Say we are finished toggling the rows in some configuration. Then for each column, (to maximize the score), we’ll toggle the column if it would increase the number of 1s. We can brute force over every possible way to toggle rows. Say the matrix has R rows and C columns. For each state, the transition trans = state ^ (state-1) represents the rows that must be toggled to get into the state of toggled rows represented by (the bits of) state. We’ll toggle them, and also maintain the correct column sums of the matrix on the side. Afterwards, we’ll calculate the score. If for example the last column has a column sum of 3, then the score is max(3, R-3), where R-3 represents the score we get from toggling the last column. In general, the score is increased by max(col_sum, R - col_sum) * (1 &lt;&lt; (C-1-c)), where the factor (1 &lt;&lt; (C-1-c)) is the power of 2 that each 1 contributes. Note that this approach may not run in the time allotted. 12345678910111213141516171819202122232425262728293031323334class Solution &#123; public int matrixScore(int[][] A) &#123; int R = A.length, C = A[0].length; int[] colsums = new int[C]; for (int r = 0; r &lt; R; ++r) for (int c = 0; c &lt; C; ++c) colsums[c] += A[r][c]; int ans = 0; for (int state = 0; state &lt; (1&lt;&lt;R); ++state) &#123; // Toggle the rows so that after, &apos;state&apos; represents // the toggled rows. if (state &gt; 0) &#123; int trans = state ^ (state-1); for (int r = 0; r &lt; R; ++r) &#123; if (((trans &gt;&gt; r) &amp; 1) &gt; 0) &#123; for (int c = 0; c &lt; C; ++c) &#123; colsums[c] += A[r][c] == 1 ? -1 : 1; A[r][c] ^= 1; &#125; &#125; &#125; &#125; // Calculate the score with the rows toggled by &apos;state&apos; int score = 0; for (int c = 0; c &lt; C; ++c) score += Math.max(colsums[c], R - colsums[c]) * (1 &lt;&lt; (C-1-c)); ans = Math.max(ans, score); &#125; return ans; &#125;&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[try]]></title>
    <url>%2F2019%2F05%2F13%2Ftry%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么size_t重要?]]></title>
    <url>%2F2019%2F05%2F13%2Fcpp%E4%B8%AD%E7%9A%84size_t%2F</url>
    <content type="text"><![CDATA[前言：使用size_t可能会提高代码的可移植性、有效性或者可读性，或许同时提高这三者。 在标准C库中的许多函数使用的参数或者返回值都是表示的用字节表示的对象大小，比如说malloc(n) 函数的参数n指明了需要申请的空间大小，还有memcpy(s1, s2, n)的最后一个参数，表明需要复制的内存大小，strlen(s)函数的返回值表明了以’\0’结尾的字符串的长度（不包括’\0’），其返回值并不是该字符串的实际长度，因为要去掉’\0’。 或许你会认为这些参数或者返回值应该被申明为int类型（或者long或者unsigned），但是事实上并不是。C标准中将他们定义为size_t。标准中记载malloc的申明应该出现在，定义为：1void *malloc(size_t n); memcpy和strlen的申明应该出现在中：12void *memcpy(void *s1, void const *s2, size_t n);size_t strlen(char const *s); size_t还经常出现在C++标准库中，此外，C++库中经常会使用一个相似的类型size_type，用的可能比size_t还要多。据我所知，大部分的C和C++程序员害怕这些库使用size_t，因为他们不知道size_t代表什么或者为什么这些库需要使用它，归根结底，原因在于他们什么时候什么地方需要用到它。 可移植性问题 早期的C语言（由Brian Kernighan 和 Dennis Ritchie 在The C Programming Language书中所写，Prentice-Hall, 1978）并没有提供size_t类型，C标准委员会为了解决移植性问题将size_t引入，举例如下：让我们来写一个可移植的标准memcpy函数，我们将会看到一些不同的申明和它们在不同平台不同大小的地址空间上编译下的情况。回忆memcpy(s1, s2, n)函数，它将s2指向地址开始的n个字节拷贝到s2指向的地址，返回s1，这个函数可以拷贝任何数据类型，所以参数和返回值的类型应该为可以指向任何类型的void，同时，源地址不应该被改变，所以第二个参数s2类型应该为const void，这些都不是问题。真正的问题在于我们如何申明第三个参数，它代表了源对象的大小，我相信大部分程序员都会选择int：1void *memcpy(void *s1, void const *s2, int n); 使用int类型在大部分情况下都是可以的，但是并不是所有情况下都可以。int是有符号的，它可以表示负数，但是，大小不可能是复数。所以我们可以使用unsigned int代替它让第三个参数表示的范围更大。在大部分机器上，unsigned int的最大值要比int的最大值大两倍，比如说再也给16位的机器上，unsigned int的最大值为65535，int的最大值为32767。尽管int类型的大小依赖于C编译器的实现，但是在给定的平台上int对象的大小和unsigned int对象的大小是一样的。因此，使用unsigned int修饰第三个参数的代价与int是相同的：1void *memcpy(void *s1, void const *s2, unsigned int n); 这样似乎没有问题了，unsigned int可以表示最大类型的对象大小了，这种情况只有在整形和指针类型具有相同大小的情况下，比如说在IP16中，整形和指针都占2个字节（16位），而在IP32上面，整形和指针都占4个字节（32位）。（参见下面C数据模型表示法） C数据模型表示法最近，我偶然发现几篇文章，他们使用简明的标记来表述不同目标平台下c语言数据的实现。我还没有找到这个标记的来源，正式的语法，甚至连名字都没有，但他似乎很简单，即使没有正规的定义也可以很容易使用起来。这些标记的一边形式形如：I nI L nL LL nLL P nP。其中每个大写字母（或成对出现）代表一个C的数据类型，每一个对应的n是这个类型包含的位数。I代表int，L代表long，LL代表long long，以及P代表指针（指向数据，而不是函数）。每个字母和数字都是可选的。例如，I16P32架构支持16位int和32位指针类型，没有指明是否支持long或者long long。如果两个连续的类型具有相同的大小，通常省略第一个数字。例如，你可以将I16L32P32写为I16LP32，这是一个支持16位int，32位long，和32位指针的架构。标记通常把字母分类在一起，所以可以按照其对应的数字升序排列。例如，IL32LL64P32表示支持32位int，32位long，64位long long和32位指针的架构；然而，通常写作ILP32LL64。不幸的是，这种memcpy的申明在I16LP32架构上（整形是16-bit 长整形和指针类型时32-bits）显得不够用了，比如说摩托罗拉第一代处理器68000，在这种情况下，处理器可能拷贝的数据大于65535个字节，但是这个函数第三个参数n不能处理这么大的数据。 什么？你说很容易就可以改正？只需要把memcpy的第三个参数的类型修改一下：1void *memcpy(void *s1, void const *s2, unsigned long n); 你可以在I16LP32目标架构上使用这个函数了，它可以处理更大的数据。而且在IP16和IP32平台上效果也还行，说明它确实给出了memcpy的一种移植性较好的申明。但是，在IP16平台上相比于使用unsigned int，你使用unsigned long可能会使你的代码运行效率大打折扣（代码量变大而且运行变慢）。在标准C中规定，长整形（无论无符号或者有符号）至少占用32位，因此在IP16平台上支持标准C的话，那么它一定是IP16L32 平台。这些平台通常使用一对16位的字来实现32位的长整形。在这种情况下，移动一个长整形需要两条机器指令，每条移动一个16位的块。事实上，这个平台上的大部分的32位操作都需要至上两条指令。以可移植性为名将memcpy的第三个参数申明为unsigned long而降低某些平台的性能是我们所不希望看到的。使用size_t可以有效避免这种情况。size_t类型是一个类型定义，通常将一些无符号的整形定义为size_t，比如说unsigned int或者unsigned long，甚至unsigned long long。每一个标准C实现应该选择足够大的无符号整形来代表该平台上最大可能出现的对象大小。 使用size_tsize_t是一种数据相关的无符号类型，它被设计得足够大以便能够内存中任意对象的大小。在C++中，设计 size_t 就是为了适应多个平台的 。size_t的引入增强了程序在不同平台上的可移植性。size_t的定义在&lt;stddef.h&gt;,&lt;stdio.h&gt;,&lt;stdlib.h&gt;,&lt;string.h&gt;, &lt;time.h&gt;和&lt;wchar.h&gt;这些标准C头文件中，也出现在相应的C++头文件, 等等中，你应该在你的头文件中至少包含一个这样的头文件在使用size_t之前。 包含以上任何C头文件（由C或C++编译的程序）表明将size_t作为全局关键字。包含以上任何C++头文件（当你只能在C++中做某种操作时）表明将size_t作为std命名空间的成员。 根据定义，size_t是sizeof关键字（注：sizeof是关键字，并非运算符）运算结果的类型。所以，应当通过适当的方式声明n来完成赋值：1n = sizeof(thing); 考虑到可移植性和程序效率，n应该被申明为size_t类型。类似的，下面的foo函数的参数也应当被申明为sizeof：1foo(sizeof(thing)); 参数中带有size_t的函数通常会含有局部变量用来对数组的大小或者索引进行计算，在这种情况下，size_t是个不错的选择。适当地使用size_t还会使你的代码变得如同自带文档。当你看到一个对象声明为size_t类型，你马上就知道它代表字节大小或数组索引，而不是错误代码或者是一个普通的算术值。 size_t的大小并非像很多网上描述的那样，其大小是由系统的位数决定的。size_t的大小是由你生成的程序类型决定的，只是生成的程序类型与系统的类型有一定关系。32bits的程序既可以在64bits的系统上运行，也可以在32bits的系统上运行。但是64bits的程序只能在64bits的系统上运行。然而我们编译的程序一般是32bits的，因此size_t的大小也就变成了4个字节。 由此引发指针的大小的问题？ 关于指针的大小，网上描述基本上是千篇一律，认为指针是存放地址的，如果是32位机器就是4字节的，如果是64位机器就是8字节的，根据机器字而决定的。 这里的32位机器和64位机器指的是什么呢？我觉的CPU的架构决定了机器的类型，如果CPU是x86架构，那么就是32位的CPU，当然并非所有的x86架构的CPU都是32位的，比如intel的8086和8088就是16位的CPU。 如果CPU是x86-64的架构，那么就是64位的CPU。CPU的位数是由其字长决定，字长表示CPU在同一时间中能够处理二进制数的位数叫字长。字长是由CPU中寄存器的位数决定的，并非由数据总线的宽度决定的，只是数据总线的宽度一般与CPU的位数相一致。 系统的位数是依赖于CPU的位数，即32位的CPU不能装64位的系统，但是现在（2015年）的CPU基本上都是x86-64的CPU，都支持64位的系统。但是正如上面的讨论，如果编译生成的程序不是64位的，那么指针的大小依然是4个字节。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程间通信:管道]]></title>
    <url>%2F2019%2F05%2F13%2FLinux%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E7%AE%A1%E9%81%93%2F</url>
    <content type="text"><![CDATA[管道的定义管道是第一个广泛应用的进程间通信手段。日常在终端执行shell命令时，会大量用到管道。但管道的缺陷在于只能在有亲缘关系（有共同的祖先）的进程之间使用。为了突破这个限制，后来引入了命名管道。 管道的用途管道是最早出现的进程间通信的手段。在shell中执行命令，经常会将上一个命令的输出作为下一个命令的输入，由多个命令配合完成一件事情。而这就是通过管道来实现的。在图9-3中，进程who的标准输出，通过管道传递给下游的wc进程作为标准输入，从而通过相互配合完成了一件任务。 管道的操作管道的作用是在具有亲缘关系的进程之间传递消息，所谓有亲缘关系，是指有同一个祖先。所以管道并不是只可以用于父子进程通信，也可以在兄弟进程之间还可以用在祖孙之间等，反正只要共同的祖先调用了pipe函数，打开的管道文件就会在fork之后，被各个后代所共享。不过由于管道是字节流通信，没有消息边界，多个进程同时发送的字节流混在一起，则无法分辨消息，所有管道一般用于2个进程之间通信，另外管道的内容读完后不会保存，管道是单向的，一边要么读，一边要么写，不可以又读又写，想要一边读一边写，那就创建2个管道，如下图 管道是一种文件，可以调用read、write和close等操作文件的接口来操作管道。另一方面管道又不是一种普通的文件，它属于一种独特的文件系统：pipefs。管道的本质是内核维护了一块缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区内存的操作。下面我们来看一下如何使用管道。#include&lt;unistd.h&gt;int pipe(int fd[2]) 如果成功，则返回值是0，如果失败，则返回值是-1，并且设置errno。成功调用pipe函数之后，会返回两个打开的文件描述符，一个是管道的读取端描述符pipefd[0]，另一个是管道的写入端描述符pipefd[1]。管道没有文件名与之关联，因此程序没有选择，只能通过文件描述符来访问管道，只有那些能看到这两个文件描述符的进程才能够使用管道。那么谁能看到进程打开的文件描述符呢？只有该进程及该进程的子孙进程才能看到。这就限制了管道的使用范围。 成功调用pipe函数之后，可以对写入端描述符pipefd[1]调用write，向管道里面写入数据，代码如下所示：1write(pipefd[1],wbuf,count); 一旦向管道的写入端写入数据后，就可以对读取端描述符pipefd[0]调用read，读出管道里面的内容。如下所示，管道上的read调用返回的字节数等于请求字节数和管道中当前存在的字节数的最小值。如果当前管道为空，那么read调用会阻塞（如果没有设置O_NONBLOCK标志位的话）。 管道非法read与write内核实现解析调用pipe函数返回的两个文件描述符中，读取端pipefd[0]支持的文件操作定义在read_pipefifo_fops，写入端pipefd[1]支持的文件操作定义在write_pipefifo_fops，其定义如下：12345678910111213141516171819202122const struct file_operations read_pipefifo_fops = &#123; //读端相关操作 .llseek = no_llseek, .read = do_sync_read, .aio_read = pipe_read, .write = bad_pipe_w, //一旦写，将调用bad_pipe_w .poll = pipe_poll, .unlocked_ioctl = pipe_ioctl, .open = pipe_read_open, .release = pipe_read_release, .fasync = pipe_read_fasync,&#125;;const struct file_operations write_pipefifo_fops = &#123;//写端相关操作 .llseek = no_llseek, .read = bad_pipe_r, //一旦读，将调用bad_pipe_r .write = do_sync_write, .aio_write = pipe_write, .poll = pipe_poll, .unlocked_ioctl = pipe_ioctl, .open = pipe_write_open, .release = pipe_write_release, .fasync = pipe_write_fasync,&#125;; 我们可以看到，对读取端描述符执行write操作，内核就会执行bad_pipe_w函数；对写入端描述符执行read操作，内核就会执行bad_pipe_r函数。这两个函数比较简单，都是直接返回-EBADF。因此对应的read和write调用都会失败，返回-1，并置errno为EBADF。12345678910static ssize_t bad_pipe_r(struct file filp, char __user buf, size_t count, loff_t ppos) &#123; return -EBADF; //返回错误 &#125; static ssize_t bad_pipe_w(struct file filp, const char __user buf, size_t count,loff_t ppos) &#123; return -EBADF; &#125; 管道通信原理及其亲戚通信解析父子进程通信解析我们只介绍了pipe函数接口，至今尚看不出来该如何使用pipe函数进行进程间通信。调用pipe之后，进程发生了什么呢？请看图9-5。 可以看到，调用pipe函数之后，系统给进程分配了两个文件描述符，即pipe函数返回的两个描述符。该进程既可以往写入端描述符写入信息，也可以从读取端描述符读出信息。可是一个进程管道，起不到任何通信的作用。这不是通信，而是自言自语。如果调用pipe函数的进程随后调用fork函数，创建了子进程，情况就不一样了。fork以后，子进程复制了父进程打开的文件描述符（如图9-6所示），两条通信的通道就建立起来了。此时，可以是父进程往管道里写，子进程从管道里面读；也可以是子进程往管道里写，父进程从管道里面读。这两条通路都是可选的，但是不能都选。原因前面介绍过，管道里面是字节流，父子进程都写、都读，就会导致内容混在一起，对于读管道的一方，解析起来就比较困难。常规的使用方法是父子进程一方只能写入，另一方只能读出，管道变成一个单向的通道，以方便使用。如图9-7所示，父进程放弃读，子进程放弃写，变成父进程写入，子进程读出，成为一个通信的通道… 父进程如何放弃读，子进程又如何放弃写？其实很简单，父进程把读端口pipefd[0]这个文件描述符关闭掉，子进程把写端口pipefd[1]这个文件描述符关闭掉就可以了，示例代码如下：123456789101112131415int pipefd[2]; pipe(pipefd); switch(fork()) &#123; case -1: /fork failed, error handler here/ case 0: /子进程/ close(pipefd[1]) ; /关闭掉写入端对应的文件描述符/ /子进程可以对pipefd[0]调用read/ break； default: /父进程/ close(pipefd[0]); /父进程关闭掉读取端对应的文件描述符/ /父进程可以对pipefd[1]调用write, 写入想告知子进程的内容/ break &#125; 亲缘关系的进程管道通信解析图9-8也讲述了如何在兄弟进程之间通过管道通信。如图9-8所示，父进程再次创建一个子进程B，子进程B就持有管道写入端，这时候两个子进程之间就可以通过管道通信了。父进程为了不干扰两个子进程通信，很自觉地关闭了自己的写入端。从此管道成为了两个子进程之间的单向的通信通道。在shell中执行管道命令就是这种情景，只是略有特殊之处，其特殊的地方是管道描述符占用了标准输入和标准输出两个文件描述符 管道的注意事项及其性质管道有以下三条性质 只有当所有的写入端描述符都已经关闭了，而且管道中的数据都被读出，对读取描述符调用read函数才返回0（及读到EOF标志）。 如果所有的读取端描述符都已经关闭了，此时进程再次往管道里面写入数据，写操作将会失败，并且内核会像进程发送一个SIGPIPE信号(默认杀死进程)。 当所有的读端与写端都已经关闭时，管道才会关闭. 就因为有这些特性，我们要及时关闭没用的管道文件描述符 shell管道的实现shell编程会大量使用管道，我们经常看到前一个命令的标准输出作为后一个命令的标准输入，来协作完成任务，如图9-9所示。管道是如何做到的呢？兄弟进程可以通过管道来传递消息，这并不稀奇，前面已经图示了做法。关键是如何使得一个程序的标准输出被重定向到管道中，而另一个程序的标准输入从管道中读取呢？ 答案就是复制文件描述符。对于第一个子进程，执行dup2之后，标准输出对应的文件描述符1，也成为了管道的写入端。这时候，管道就有了两个写入端，按照前面的建议，需要关闭不相干的写入端，使读取端可以顺利地读到EOF，所以应将刚开始分配的管道写入端的文件描述符pipefd[1]关闭掉。12345if(pipefd[1] != STDOUT_FILENO)&#123;dup2(pipefd[1],STDOUT_FILENO);close(pipefd[1]);&#125; 同样的道理,对于第二个子进程,如法炮制:12345if(pipefd[0] != STDIN_FILENO)&#123;dup2(pipefd[0],STDIN_FILENO);close(pipefd[0]);&#125; 简单来说，就是第一个子进程的标准输出被绑定到了管道的写入端，于是第一个命令的输出，写入了管道，而第二个子进程管道将其标准输入绑定到管道的读取端，只要管道里面有了内容，这些内容就成了标准输入。 两个示例代码，为什么要判断管道的文件描述符是否等于标准输入和标准输出呢？原因是，在调用pipe时，进程很可能已经关闭了标准输入和标准输出，调用pipe函数时，内核会分配最小的文件描述符，所以pipe的文件描述符可能等于0或1。在这种情况下，如果没有if判断加以保护，代码就变成了：12dup2(1,1);close(1); 这样的话，第一行代码什么也没做，第二行代码就把管道的写入端给关闭了，于是便无法传递信息了 与shell命令进行通信道的一个重要作用是和外部命令进行通信。在日常编程中，经常会需要调用一个外部命令，并且要获取命令的输出。而有些时候，需要给外部命令提供一些内容，让外部命令处理这些输入。Linux提供了popen接口来帮助程序员做这些事情。就像system函数，即使没有system函数，我们通过fork、exec及wait家族函数一样也可以实现system的功能。但终归是不方便，system函数为我们提供了一些便利。同样的道理，只用pipe函数及dup2等函数，也能完成popen要完成的工作，但popen接口给我们提供了便利。popen接口定义如下：123#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *type);int pclose(FILE *stream); popen函数会创建一个管道，并且创建一个子进程来执行shell，shell会创建一个子进程来执行command。根据type值的不同，分成以下两种情况。 如果type是r：command执行的标准输出，就会写入管道，从而被调用popen的进程读到。通过对popen返回的FILE类型指针执行read或fgets等操作，就可以读取到command的标准输出，如图9-10所示。 如果type是w：调用popen的进程，可以通过对FILE类型的指针fp执行write、fputs等操作，负责往管道里面写入，写入的内容经过管道传给执行command的进程，作为命令的输入，如图9-11所示 popen函数成功时，会返回stdio库封装的FILE类型的指针，失败时会返回NULL，并且设置errno。常见的失败有fork失败，pipe失败，或者分配内存失败。I/O结束了以后，可以调用pclose函数来关闭管道，并且等待子进程的退出。尽管popen函数返回的是FILE类型的指针，也不应调用fclose函数来关闭popen函数打开的文件流指针，因为fclose不会等待子进程的退出。pclose函数成功时会返回子进程中shell的终止状态。popen函数和system函数类似，如果command对应的命令无法执行，就如同执行了exit（127）一样。如果发生其他错误，pclose函数则返回-1。可以从errno中获取到失败的原因。下面给出一个简单的例子，来示范下popen的用法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;unistd.h&gt;#include&lt;string.h&gt;#include&lt;errno.h&gt;#include&lt;sys/wait.h&gt;#include&lt;signal.h&gt;#define MAX_LINE_SIZE 8192void print_wait_exit(int status)&#123; printf(&quot;status = %d\n&quot;,status); if(WIFEXITED(status)) &#123; printf(&quot;normal termination,exit status = %d\n&quot;,WEXITSTATUS(status)); &#125; else if(WIFSIGNALED(status)) &#123; printf(&quot;abnormal termination,signal number =%d%s\n&quot;, WTERMSIG(status),#ifdef WCOREDUMP WCOREDUMP(status)?&quot;core file generated&quot; : &quot;&quot;);#else &quot;&quot;);#endif &#125;&#125;int main(int argc ,char* argv[])&#123; FILE *fp = NULL ; char command[MAX_LINE_SIZE],buffer[MAX_LINE_SIZE]; if(argc != 2 ) &#123; fprintf(stderr,&quot;Usage: %s filename \n&quot;,argv[0]); exit(1); &#125; snprintf(command,sizeof(command),&quot;cat %s&quot;,argv[1]); fp = popen(command,&quot;r&quot;); if(fp == NULL) &#123; fprintf(stderr,&quot;popen failed (%s)&quot;,strerror(errno)); exit(2); &#125; while(fgets(buffer,MAX_LINE_SIZE,fp) != NULL) &#123; fprintf(stdout,&quot;%s&quot;,buffer); &#125; int ret = pclose(fp); if(ret == 127 ) &#123; fprintf(stderr,&quot;bad command : %s\n&quot;,command); exit(3); &#125; else if(ret == -1) &#123; fprintf(stderr,&quot;failed to get child status (%s)\n&quot;,strerror(errno)); exit(4); &#125; else &#123; print_wait_exit(ret); &#125; exit(0);&#125; 将文件名作为参数传递给程序，执行cat filename的命令。popen创建子进程来负责执行cat filename的命令，子进程的标准输出通过管道传给父进程，父进程可以通过fgets来读取command的标准输出。 system函数与popen函数区别popen函数和system有很多相似的地方，但是也有显著的不同。调用system函数时，shell命令的执行被封装在了函数内部，所以若system函数不返回，调用system的进程就不再继续执行。但是popen函数不同，一旦调用popen函数，调用进程和执行command的进程便处于并行状态。然后pclose函数才会关闭管道，等待执行command的进程退出。换句话说，在popen之后，pclose之前，调用popen的进程和执行command的进程是并行的，这种差异带来了两种显著的不同：在并行期间，调用popen的进程可能会创建其他子进程，所以标准规定popen不能阻塞SIGCHLD信号.这也意味着，popen创建的子进程可能被提前执行的等待操作所捕获。若发生这种情况，调用pclose函数时，已经无法等待command子进程的退出，这种情况下，将返回-1，并且errno为ECHILD。调用进程和command子进程是并行的，所以标准要求popen不能忽略SIGINT和SIGQUIT信号。如果是从键盘产生的上述信号，那么，调用进程和command子进程都会收到信号。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux任务调度机制]]></title>
    <url>%2F2019%2F05%2F13%2FLinux%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[作业调度策略进程调度在近几个版本中都进行了重要的修改。我们先了解一下进程调度的原理： 进程类型在linux调度算法中，将进程分为两种类型，即：I/O消耗型和CPU消耗型。例如文本处理程序与正在执行的Make的程序。文本处理程序大部份时间都在等待I/O设备的输入，而make程序大部份时间都在CPU的处理上。因此为了提高响应速度，I/O消耗程序应该有较高的优先级，才能提高它的交互性。相反的，Make程序相比之下就不那么重要了，只要它能处理完就行了。因此，基于这样的原理，linux有一套交互程序的判断机制。在task_struct结构中新增了一个成员：sleep_avg此值初始值为100。进程在CPU上执行时，此值减少。当进程在等待时，此值增加。最后，在调度的时候。根据sleep_avg的值重新计算优先级。 进程优先级正如我们在上面所说的：交互性强的需要高优先级，交互性弱的需要低优先级。在linux系统中，有两种优先级：普通优先级和实时优先级。我们在这里主要分析的是普通优先级，实时优先级部份可自行了解。 运行时间片进程的时间片是指进程在抢占前可以持续运行的时间。在linux中，时间片长短可根据优先级来调整。进程不一定要一次运行完所有的时间片。可以在运时的中途被切换出去。 进程抢占当一个进程被设为TASK_RUNING状态时，它会判断它的优先级是否高于正在运行的进程，如果是，则设置调度标志位，调用schedule()执行进程的调度。当一个进程的时间片为0时，也会执行进程抢占。 调度程序运行时，要在所有可运行状态的进程中选择最值得运行的进程投入运行。选择进程的依据是什么呢？在每个进程的task_struct结构中有以下四 项：policy、priority、counter、rt_priority。这四项就是调度程序选择进程的依据.其中,policy是进程的调度策略,用来区分两种进程-实时和普通；priority是进程(实时和普通)的优先 级；counter 是进程剩余的时间片,它的大小完全由priority决定;rt_priority是实时优先级,这是实时进程所特有的，用于实时进程间的选择。 首先，Linux 根据policy从整体上区分实时进程和普通进程，因为实时进程和普通进程度调度是不同的，它们两者之间，实时进程应该先于普通进程而运行，然后，对于同一类型的不同进程，采用不同的标准来选择进程： policy的取值会有以下可能： SCHED_OTHER 分时调度策略，（默认的） SCHED_FIFO实时调度策略，先到先服务 SCHED_RR实时调度策略，时间片轮转 实时进程将得到优先调用，实时进程根据实时优先级决定调度权值，分时进程则通过nice和counter值决定权值，nice越小，counter越大，被调度的概率越大，也就是曾经使用了cpu最少的进程将会得到优先调度。 SHCED_RR和SCHED_FIFO的不同：当采用SHCED_RR策略的进程的时间片用完，系统将重新分配时间片，并置于就绪队列尾。放在队列尾保证了所有具有相同优先级的RR任务的调度公平。 SCHED_FIFO一旦占用cpu则一直运行。一直运行直到有 更高优先级任务到达或自己放弃 。 如果有相同优先级的实时进程（根据优先级计算的调度权值是一样的）已经准备好，FIFO时必须等待该进程主动放弃后才可以运行这个优先级相同的任务。而RR可以让每个任务都执行一段时间。 相同点： RR和FIFO都只用于实时任务。 创建时优先级大于0(1-99)。 按照可抢占优先级调度算法进行。 就绪态的实时任务立即抢占非实时任务。 对于普通进程，Linux采用动态优先调度，选择进程的依据就是进程counter的大小。进程创建时，优先级priority被赋一个初值，一般为 0～70之间的数字，这个数字同时也是计数器counter的初值，就是说进程创建时两者是相等的。字面上看，priority是”优先级”、 counter是”计数器”的意思，然而实际上，它们表达的是同一个意思-进程的”时间片”。Priority代表分配给该进程的时间片，counter 表示该进程剩余的时间片。在进程运行过程中，counter不断减少，而priority保持不变，以便在counter变为0的时候（该进程用完了所分 配的时间片）对counter重新赋值。当一个普通进程的时间片用完以后，并不马上用priority对counter进行赋值，只有所有处于可运行状态 的普通进程的时间片(p-&gt;counter==0)都用完了以后，才用priority对counter重新赋值，这个普通进程才有了再次被调度的 机会。这说明，普通进程运行过程中，counter的减小给了其它进程得以运行的机会，直至counter减为0时才完全放弃对CPU的使用，这就相对于 优先级在动态变化，所以称之为动态优先调度。至于时间片这个概念，和其他不同操作系统一样的，Linux的时间单位也是”时钟滴答”，只是不同操作系统对 一个时钟滴答的定义不同而已（Linux为10ms）。进程的时间片就是指多少个时钟滴答，比如，若priority为20，则分配给该进程的时间片就为 20个时钟滴答，也就是20*10ms=200ms。Linux中某个进程的调度策略(policy)、优先级(priority)等可以作为参数由用户 自己决定，具有相当的灵活性。内核创建新进程时分配给进程的时间片缺省为200ms(更准确的，应为210ms)，用户可以通过系统调用改变它。 对于实时进程，Linux采用了两种调度策略，即FIFO(先来先服务调度)和RR（时间片轮转调度）。因为实时进程具有一定程度的紧迫性，所以衡量一个 实时进程是否应该运行，Linux采用了一个比较固定的标准。实时进程的counter只是用来表示该进程的剩余时间片，并不作为衡量它是否值得运行的标 准。实时进程的counter只是用来表示该进程的剩余时间片，并不作为衡量它是否值得运行的标准，这和普通进程是有区别的。上面已经看到，每个进程有两 个优先级（动态优先级和实时优先级），实时优先级就是用来衡量实时进程是否值得运行的。 Linux根据policy的值将进程总体上分为实时进程和普通进程，提供了三种调度算法：一种传统的Unix调度程序和两个由POSIX.1b(原名为 POSIX.4)操作系统标准所规定的”实时”调度程序。但这种实时只是软实时，不满足诸如中断等待时间等硬实时要求，只是保证了当实时进程需要时一定只 把CPU分配给实时进程。 非实时进程有两种优先级，一种是静态优先级，另一种是动态优先级。实时进程又增加了第三种优先级，实时优先级。优先级是一些简单的整数，为了决定应该允许哪一个进程使用CPU的资源，用优先级代表相对权值-优先级越高，它得到CPU时间的机会也就越大。 静态优先级(priority)-不随时间而改变，只能由用户进行修改。它指明了在被迫和其他进程竞争CPU之前，该进程所应该被允许的时间片的最大值（但很可能的，在该时间片耗尽之前，进程就被迫交出了CPU）。 动态优先级(counter)-只要进程拥有CPU，它就随着时间不断减小；当它小于0时，标记进程重新调度。它指明了在这个时间片中所剩余的时间量。 实时优先级(rt_priority)-指明这个进程自动把CPU交给哪一个其他进程；较高权值的进程总是优先于较低权值的进程。如果一个进程不是实时进程，其优先级就是0，所以实时进程总是优先于非实时进程的（但实际上，实时进程也会主动放弃CPU）。 当所有任务都采用FIFO调度策略时（SCHED_FIFO）： 创建进程时指定采用FIFO，并设置实时优先级rt_priority(1-99)。 如果没有等待资源，则将该任务加入到就绪队列中。 调度程序遍历就绪队列，根据实时优先级计算调度权值,选择权值最高的任务使用cpu， 该FIFO任务将一直占有cpu直到有优先级更高的任务就绪(即使优先级相同也不行)或者主动放弃(等待资源)。 调度程序发现有优先级更高的任务到达(高优先级任务可能被中断或定时器任务唤醒，再或被当前运行的任务唤醒，等等)，则调度程序立即在当前任务堆栈中保存当前cpu寄存器的所有数据，重新从高优先级任务的堆栈中加载寄存器数据到cpu，此时高优先级的任务开始运行。重复第3步。 如果当前任务因等待资源而主动放弃cpu使用权，则该任务将从就绪队列中删除，加入等待队列，此时重复第3步。 当所有任务都采用RR调度策略（SCHED_RR）时： 创建任务时指定调度参数为RR， 并设置任务的实时优先级和nice值(nice值将会转换为该任务的时间片的长度)。 如果没有等待资源，则将该任务加入到就绪队列中。 调度程序遍历就绪队列，根据实时优先级计算调度权值,选择权值最高的任务使用cpu。 如果就绪队列中的RR任务时间片为0，则会根据nice值设置该任务的时间片，同时将该任务放入就绪队列的末尾 。重复步骤3。 当前任务由于等待资源而主动退出cpu，则其加入等待队列中。重复步骤3。 系统中既有分时调度，又有时间片轮转调度和先进先出调度： RR调度和FIFO调度的进程属于实时进程，以分时调度的进程是非实时进程。 当实时进程准备就绪后，如果当前cpu正在运行非实时进程，则实时进程立即抢占非实时进程 。 RR进程和FIFO进程都采 作业调度算法： 先来先服务算法 段作业优先调度算法 优先级调度算法 时间片轮转调度算法 最高响应比优先调度算法响应比=周转时间/作业执行时间=(作业执行时间+作业等待时间)/作业执行时间=1+作业等待时间/作业执行时间；作业周转时间=作业完成时间-作业到达时间 多级反馈队列调度算法 进程在进入待调度的队列等待时，首先进入优先级最高的Q1等待。 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。例如：Q1,Q2,Q3三个队列，只有在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。 对于同一个队列中的各个进程，按照时间片轮转法调度。比如Q1队列的时间片为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列，直至完成。 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业（抢占式）。 实时调度算法 最早截止时间优先调度算法 最低松弛度优先调度算法 根据任务紧急的程度，来确定任务的优先级。比如说，一个任务在200ms时必须完成而它本身运行需要100ms，所以此任务就必须在100ms之前调度执行，此任务的松弛度就是100ms。在实现此算法时需要系统中有一个按松弛度排序的实时任务就绪队列，松弛度最低的任务排在最烈的最前面，调度程序总是选择就粗队列中的首任务执行！(可理解为最早额定开始)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斜堆之图文解析和C语言的实现]]></title>
    <url>%2F2019%2F05%2F12%2F%E6%96%9C%E5%A0%86%E4%B9%8B%E5%9B%BE%E6%96%87%E8%A7%A3%E6%9E%90%E5%92%8CC%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概要本章介绍斜堆。和以往一样，本文会先对斜堆的理论知识进行简单介绍，然后给出C语言的实现。后续再分别给出C++和Java版本的实现；实现的语言虽不同，但是原理如出一辙，选择其中之一进行了解即可。若文章有错误或不足的地方，请不吝指出！ 目录 斜堆的介绍 斜堆的基本操作 斜堆的C实现(完整源码) 斜堆的C测试程序 转载请注明出处：http://www.cnblogs.com/skywang12345/p/3638493.html 斜堆的介绍斜堆(Skew heap)也叫自适应堆(self-adjusting heap)，它是左倾堆的一个变种。和左倾堆一样，它通常也用于实现优先队列。它的合并操作的时间复杂度也是O(lg n)。 相比于左倾堆，斜堆的节点没有”零距离”这个属性。除此之外，它们斜堆的合并操作也不同。斜堆的合并操作算法如下：(01) 如果一个空斜堆与一个非空斜堆合并，返回非空斜堆。(02) 如果两个斜堆都非空，那么比较两个根节点，取较小堆的根节点为新的根节点。将”较小堆的根节点的右孩子”和”较大堆”进行合并。(03) 合并后，交换新堆根节点的左孩子和右孩子。 第(03)步是斜堆和左倾堆的合并操作差别的关键所在，如果是左倾堆，则合并后要比较左右孩子的零距离大小，若右孩子的零距离 &gt; 左孩子的零距离，则交换左右孩子；最后，在设置根的零距离。 斜堆的基本操作头文件12345678910111213141516171819202122232425262728293031323334#ifndef _SKEW_HEAP_H_#define _SKEW_HEAP_H_typedef int Type;typedef struct _SkewNode&#123; Type key; // 关键字(键值) struct _SkewNode *left; // 左孩子 struct _SkewNode *right; // 右孩子&#125;SkewNode, *SkewHeap;// 前序遍历&quot;斜堆&quot;void preorder_skewheap(SkewHeap heap);// 中序遍历&quot;斜堆&quot;void inorder_skewheap(SkewHeap heap);// 后序遍历&quot;斜堆&quot;void postorder_skewheap(SkewHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int skewheap_minimum(SkewHeap heap, int *pval);// 合并&quot;斜堆x&quot;和&quot;斜堆y&quot;，并返回合并后的新树SkewNode* merge_skewheap(SkewHeap x, SkewHeap y);// 将结点插入到斜堆中，并返回根节点SkewNode* insert_skewheap(SkewHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点SkewNode* delete_skewheap(SkewHeap heap);// 销毁斜堆void destroy_skewheap(SkewHeap heap);// 打印斜堆void print_skewheap(SkewHeap heap);#endif SkewNode是斜堆对应的节点类。 合并1234567891011121314151617181920212223242526/* * 合并&quot;斜堆x&quot;和&quot;斜堆y&quot; * * 返回值： * 合并得到的树的根节点 */SkewNode* merge_skewheap(SkewHeap x, SkewHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_skewheap_node(x, y); // 将x的右孩子和y合并， // 合并后直接交换x的左右孩子，而不需要像左倾堆一样考虑它们的npl。 SkewNode *tmp = merge_skewheap(x-&gt;right, y); x-&gt;right = x-&gt;left; x-&gt;left = tmp; return x;&#125; merge_skewheap(x, y)的作用是合并x和y这两个斜堆，并返回得到的新堆。merge_skewheap(x, y)是递归实现的。 添加123456789101112131415161718192021/* * 新建结点(key)，并将其插入到斜堆中 * * 参数说明： * heap 斜堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */SkewNode* insert_skewheap(SkewHeap heap, Type key)&#123; SkewNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (SkewNode *)malloc(sizeof(SkewNode))) == NULL) return heap; node-&gt;key = key; node-&gt;left = node-&gt;right = NULL; return merge_skewheap(heap, node);&#125; insert_skewheap(heap, key)的作用是新建键值为key的结点，并将其插入到斜堆中，并返回堆的根节点。 删除12345678910111213141516/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */SkewNode* delete_skewheap(SkewHeap heap)&#123; SkewNode *l = heap-&gt;left; SkewNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_skewheap(l, r); // 返回左右子树合并后的新树&#125; delete_skewheap(heap)的作用是删除斜堆的最小节点，并返回删除节点后的斜堆根节点。 斜堆的C实现(完整源码)斜堆的头文件(skewheap.h)12345678910111213141516171819202122232425262728293031323334#ifndef _SKEW_HEAP_H_#define _SKEW_HEAP_H_typedef int Type;typedef struct _SkewNode&#123; Type key; // 关键字(键值) struct _SkewNode *left; // 左孩子 struct _SkewNode *right; // 右孩子&#125;SkewNode, *SkewHeap;// 前序遍历&quot;斜堆&quot;void preorder_skewheap(SkewHeap heap);// 中序遍历&quot;斜堆&quot;void inorder_skewheap(SkewHeap heap);// 后序遍历&quot;斜堆&quot;void postorder_skewheap(SkewHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int skewheap_minimum(SkewHeap heap, int *pval);// 合并&quot;斜堆x&quot;和&quot;斜堆y&quot;，并返回合并后的新树SkewNode* merge_skewheap(SkewHeap x, SkewHeap y);// 将结点插入到斜堆中，并返回根节点SkewNode* insert_skewheap(SkewHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点SkewNode* delete_skewheap(SkewHeap heap);// 销毁斜堆void destroy_skewheap(SkewHeap heap);// 打印斜堆void print_skewheap(SkewHeap heap);#endif 斜堆的实现文件(skewheap.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186/** * C语言实现的斜堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;skewheap.h&quot;/* * 前序遍历&quot;斜堆&quot; */void preorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; printf(&quot;%d &quot;, heap-&gt;key); preorder_skewheap(heap-&gt;left); preorder_skewheap(heap-&gt;right); &#125;&#125;/* * 中序遍历&quot;斜堆&quot; */void inorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; inorder_skewheap(heap-&gt;left); printf(&quot;%d &quot;, heap-&gt;key); inorder_skewheap(heap-&gt;right); &#125;&#125;/* * 后序遍历&quot;斜堆&quot; */void postorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; postorder_skewheap(heap-&gt;left); postorder_skewheap(heap-&gt;right); printf(&quot;%d &quot;, heap-&gt;key); &#125;&#125;/* * 交换两个节点的内容 */static void swap_skewheap_node(SkewNode *x, SkewNode *y)&#123; SkewNode tmp = *x; *x = *y; *y = tmp;&#125;/* * 获取最小值 * * 返回值： * 成功返回0，失败返回-1 */int skewheap_minimum(SkewHeap heap, int *pval)&#123; if (heap == NULL) return -1; *pval = heap-&gt;key; return 0;&#125; /* * 合并&quot;斜堆x&quot;和&quot;斜堆y&quot; * * 返回值： * 合并得到的树的根节点 */SkewNode* merge_skewheap(SkewHeap x, SkewHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_skewheap_node(x, y); // 将x的右孩子和y合并， // 合并后直接交换x的左右孩子，而不需要像左倾堆一样考虑它们的npl。 SkewNode *tmp = merge_skewheap(x-&gt;right, y); x-&gt;right = x-&gt;left; x-&gt;left = tmp; return x;&#125;/* * 新建结点(key)，并将其插入到斜堆中 * * 参数说明： * heap 斜堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */SkewNode* insert_skewheap(SkewHeap heap, Type key)&#123; SkewNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (SkewNode *)malloc(sizeof(SkewNode))) == NULL) return heap; node-&gt;key = key; node-&gt;left = node-&gt;right = NULL; return merge_skewheap(heap, node);&#125;/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */SkewNode* delete_skewheap(SkewHeap heap)&#123; SkewNode *l = heap-&gt;left; SkewNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_skewheap(l, r); // 返回左右子树合并后的新树&#125;/* * 销毁斜堆 */void destroy_skewheap(SkewHeap heap)&#123; if (heap==NULL) return ; if (heap-&gt;left != NULL) destroy_skewheap(heap-&gt;left); if (heap-&gt;right != NULL) destroy_skewheap(heap-&gt;right); free(heap);&#125;/* * 打印&quot;斜堆&quot; * * heap -- 斜堆的节点 * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */static void skewheap_print(SkewHeap heap, Type key, int direction)&#123; if(heap != NULL) &#123; if(direction==0) // heap是根节点 printf(&quot;%2d is root\n&quot;, heap-&gt;key); else // heap是分支节点 printf(&quot;%2d is %2d&apos;s %6s child\n&quot;, heap-&gt;key, key, direction==1?&quot;right&quot; : &quot;left&quot;); skewheap_print(heap-&gt;left, heap-&gt;key, -1); skewheap_print(heap-&gt;right,heap-&gt;key, 1); &#125;&#125;void print_skewheap(SkewHeap heap)&#123; if (heap != NULL) skewheap_print(heap, heap-&gt;key, 0);&#125; 斜堆的测试程序(skewheap_test.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * C语言实现的斜堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &quot;skewheap.h&quot;#define LENGTH(a) ( (sizeof(a)) / (sizeof(a[0])) )void main()&#123; int i; int a[]= &#123;10,40,24,30,36,20,12,16&#125;; int b[]= &#123;17,13,11,15,19,21,23&#125;; int alen=LENGTH(a); int blen=LENGTH(b); SkewHeap ha,hb; ha=hb=NULL; printf(&quot;== 斜堆(ha)中依次添加: &quot;); for(i=0; i&lt;alen; i++) &#123; printf(&quot;%d &quot;, a[i]); ha = insert_skewheap(ha, a[i]); &#125; printf(&quot;\n== 斜堆(ha)的详细信息: \n&quot;); print_skewheap(ha); printf(&quot;\n== 斜堆(hb)中依次添加: &quot;); for(i=0; i&lt;blen; i++) &#123; printf(&quot;%d &quot;, b[i]); hb = insert_skewheap(hb, b[i]); &#125; printf(&quot;\n== 斜堆(hb)的详细信息: \n&quot;); print_skewheap(hb); // 将&quot;斜堆hb&quot;合并到&quot;斜堆ha&quot;中。 ha = merge_skewheap(ha, hb); printf(&quot;\n== 合并ha和hb后的详细信息: \n&quot;); print_skewheap(ha); // 销毁斜堆 destroy_skewheap(ha);&#125;]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[左倾堆之图文解析和C语言的实现]]></title>
    <url>%2F2019%2F05%2F12%2F%E5%B7%A6%E5%80%BE%E5%A0%86%E4%B9%8B%E5%9B%BE%E6%96%87%E8%A7%A3%E6%9E%90%E5%92%8CC%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概要本章介绍左倾堆，它和二叉堆一样，都是堆结构中的一员。和以往一样，本文会先对左倾堆的理论知识进行简单介绍，然后给出C语言的实现。后续再分别给出C++和Java版本的实现；实现的语言虽不同，但是原理如出一辙，选择其中之一进行了解即可。若文章有错误或不足的地方，请不吝指出！ 目录 左倾堆的介绍 左倾堆的图文解析 左倾堆的C实现(完整源码) 左倾堆的C测试程序 转载请注明出处：http://www.cnblogs.com/skywang12345/p/3638327.html 左倾堆的介绍左倾堆(leftist tree 或 leftist heap)，又被成为左偏树、左偏堆，最左堆等。它和二叉堆一样，都是优先队列实现方式。当优先队列中涉及到”对两个优先队列进行合并”的问题时，二叉堆的效率就无法令人满意了，而本文介绍的左倾堆，则可以很好地解决这类问题。 左倾堆的定义左倾堆是一棵二叉树，它的节点除了和二叉树的节点一样具有左右子树指针外，还有两个属性：键值和零距离。(01) 键值的作用是来比较节点的大小，从而对节点进行排序。(02) 零距离(英文名NPL，即Null Path Length)则是从一个节点到一个”最近的不满节点”的路径长度。不满节点是指该该节点的左右孩子至少有有一个为NULL。叶节点的NPL为0，NULL节点的NPL为-1。 上图是一颗左倾堆，它满足左倾堆的基本性质：[性质1] 节点的键值小于或等于它的左右子节点的键值。[性质2] 节点的左孩子的NPL &gt;= 右孩子的NPL。[性质3] 节点的NPL = 它的右孩子的NPL + 1。 左倾堆，顾名思义，是有点向左倾斜的意思了。它在统计问题、最值问题、模拟问题和贪心问题等问题中有着广泛的应用。此外，斜堆是比左倾堆更为一般的数据结构。当然，今天讨论的是左倾堆，关于斜堆，以后再撰文来表。前面说过，它能和好的解决”两个优先队列合并”的问题。实际上，左倾堆的合并操作的平摊时间复杂度为O(lg n)，而完全二叉堆为O(n)。合并就是左倾树的重点，插入和删除操作都是以合并操作为基础的。插入操作，可以看作两颗左倾树合并；删除操作(移除优先队列中队首元素)，则是移除根节点之后再合并剩余的两个左倾树。闲话说到这里，下面开始介绍左倾树的基本方法。 左倾堆的图文解析合并操作是左倾堆的重点。合并两个左倾堆的基本思想如下：(01) 如果一个空左倾堆与一个非空左倾堆合并，返回非空左倾堆。(02) 如果两个左倾堆都非空，那么比较两个根节点，取较小堆的根节点为新的根节点。将”较小堆的根节点的右孩子”和”较大堆”进行合并。(03) 如果新堆的右孩子的NPL &gt; 左孩子的NPL，则交换左右孩子。(04) 设置新堆的根节点的NPL = 右子堆NPL + 1 下面通过图文演示合并以下两个堆的过程。 提示：这两个堆的合并过程和测试程序相对应！ 第1步：将”较小堆(根为10)的右孩子”和”较大堆(根为11)”进行合并。合并的结果，相当于将”较大堆”设置”较小堆”的右孩子，如下图所示： 第2步：将上一步得到的”根11的右子树”和”根为12的树”进行合并，得到的结果如下： 第3步：将上一步得到的”根12的右子树”和”根为13的树”进行合并，得到的结果如下： 第4步：将上一步得到的”根13的右子树”和”根为16的树”进行合并，得到的结果如下： 第5步：将上一步得到的”根16的右子树”和”根为23的树”进行合并，得到的结果如下： 至此，已经成功的将两棵树合并成为一棵树了。接下来，对新生成的树进行调节。第6步：上一步得到的”树16的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 第7步：上一步得到的”树12的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 第8步：上一步得到的”树10的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 至此，合并完毕。上面就是合并得到的左倾堆！ 下面看看左倾堆的基本操作的代码 头文件1234567891011121314151617181920212223242526272829303132333435#ifndef _LEFTIST_TREE_H_#define _LEFTIST_TREE_H_typedef int Type;typedef struct _LeftistNode&#123; Type key; // 关键字(键值) int npl; // 零路经长度(Null Path Length) struct _LeftistNode *left; // 左孩子 struct _LeftistNode *right; // 右孩子&#125;LeftistNode, *LeftistHeap;// 前序遍历&quot;左倾堆&quot;void preorder_leftist(LeftistHeap heap);// 中序遍历&quot;左倾堆&quot;void inorder_leftist(LeftistHeap heap);// 后序遍历&quot;左倾堆&quot;void postorder_leftist(LeftistHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int leftist_minimum(LeftistHeap heap, int *pval);// 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot;，并返回合并后的新树LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y);// 将结点插入到左倾堆中，并返回根节点LeftistNode* insert_leftist(LeftistHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点LeftistNode* delete_leftist(LeftistHeap heap);// 销毁左倾堆void destroy_leftist(LeftistHeap heap);// 打印左倾堆void print_leftist(LeftistHeap heap);#endif LeftistNode是左倾堆对应的节点类。 合并12345678910111213141516171819202122232425262728293031323334353637/* * 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot; * * 返回值： * 合并得到的树的根节点 */LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_leftist_node(x, y); // 将x的右孩子和y合并，&quot;合并后的树的根&quot;是x的右孩子。 x-&gt;right = merge_leftist(x-&gt;right, y); // 如果&quot;x的左孩子为空&quot; 或者 &quot;x的左孩子的npl&lt;右孩子的npl&quot; // 则，交换x和y if(x-&gt;left == NULL || x-&gt;left-&gt;npl &lt; x-&gt;right-&gt;npl) &#123; LeftistNode *tmp = x-&gt;left; x-&gt;left = x-&gt;right; x-&gt;right = tmp; &#125; // 设置合并后的新树(x)的npl if (x-&gt;right == NULL || x-&gt;left == NULL) x-&gt;npl = 0; else x-&gt;npl = (x-&gt;left-&gt;npl &gt; x-&gt;right-&gt;npl) ? (x-&gt;right-&gt;npl + 1) : (x-&gt;left-&gt;npl + 1); return x;&#125; merge_leftist(x, y)的作用是合并x和y这两个左倾堆，并返回得到的新堆。merge_leftist(x, y)是递归实现的。 添加12345678910111213141516171819202122/* * 新建结点(key)，并将其插入到左倾堆中 * * 参数说明： * heap 左倾堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */LeftistNode* insert_leftist(LeftistHeap heap, Type key)&#123; LeftistNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (LeftistNode *)malloc(sizeof(LeftistNode))) == NULL) return heap; node-&gt;key = key; node-&gt;npl = 0; node-&gt;left = node-&gt;right = NULL; return merge_leftist(heap, node);&#125; insert_leftist(heap, key)的作用是新建键值为key的结点，并将其插入到左倾堆中，并返回堆的根节点。 删除12345678910111213141516171819/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */LeftistNode* delete_leftist(LeftistHeap heap)&#123; if (heap == NULL) return NULL; LeftistNode *l = heap-&gt;left; LeftistNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_leftist(l, r); // 返回左右子树合并后的新树&#125; delete_leftist(heap)的作用是删除左倾堆的最小节点，并返回删除节点后的左倾堆根节点。 左倾堆的C实现(完整源码)左倾堆的头文件(leftist.h)1234567891011121314151617181920212223242526272829303132333435#ifndef _LEFTIST_TREE_H_#define _LEFTIST_TREE_H_typedef int Type;typedef struct _LeftistNode&#123; Type key; // 关键字(键值) int npl; // 零路经长度(Null Path Length) struct _LeftistNode *left; // 左孩子 struct _LeftistNode *right; // 右孩子&#125;LeftistNode, *LeftistHeap;// 前序遍历&quot;左倾堆&quot;void preorder_leftist(LeftistHeap heap);// 中序遍历&quot;左倾堆&quot;void inorder_leftist(LeftistHeap heap);// 后序遍历&quot;左倾堆&quot;void postorder_leftist(LeftistHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int leftist_minimum(LeftistHeap heap, int *pval);// 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot;，并返回合并后的新树LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y);// 将结点插入到左倾堆中，并返回根节点LeftistNode* insert_leftist(LeftistHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点LeftistNode* delete_leftist(LeftistHeap heap);// 销毁左倾堆void destroy_leftist(LeftistHeap heap);// 打印左倾堆void print_leftist(LeftistHeap heap);#endif 左倾堆的实现文件(leftist.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201/** * C语言实现的左倾堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;leftist.h&quot;/* * 前序遍历&quot;左倾堆&quot; */void preorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; printf(&quot;%d &quot;, heap-&gt;key); preorder_leftist(heap-&gt;left); preorder_leftist(heap-&gt;right); &#125;&#125;/* * 中序遍历&quot;左倾堆&quot; */void inorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; inorder_leftist(heap-&gt;left); printf(&quot;%d &quot;, heap-&gt;key); inorder_leftist(heap-&gt;right); &#125;&#125;/* * 后序遍历&quot;左倾堆&quot; */void postorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; postorder_leftist(heap-&gt;left); postorder_leftist(heap-&gt;right); printf(&quot;%d &quot;, heap-&gt;key); &#125;&#125;/* * 交换两个节点的内容 */static void swap_leftist_node(LeftistNode *x, LeftistNode *y)&#123; LeftistNode tmp = *x; *x = *y; *y = tmp;&#125;/* * 获取最小值 * * 返回值： * 成功返回0，失败返回-1 */int leftist_minimum(LeftistHeap heap, int *pval)&#123; if (heap == NULL) return -1; *pval = heap-&gt;key; return 0;&#125; /* * 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot; * * 返回值： * 合并得到的树的根节点 */LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_leftist_node(x, y); // 将x的右孩子和y合并，&quot;合并后的树的根&quot;是x的右孩子。 x-&gt;right = merge_leftist(x-&gt;right, y); // 如果&quot;x的左孩子为空&quot; 或者 &quot;x的左孩子的npl&lt;右孩子的npl&quot; // 则，交换x和y if(x-&gt;left == NULL || x-&gt;left-&gt;npl &lt; x-&gt;right-&gt;npl) &#123; LeftistNode *tmp = x-&gt;left; x-&gt;left = x-&gt;right; x-&gt;right = tmp; &#125; // 设置合并后的新树(x)的npl if (x-&gt;right == NULL || x-&gt;left == NULL) x-&gt;npl = 0; else x-&gt;npl = (x-&gt;left-&gt;npl &gt; x-&gt;right-&gt;npl) ? (x-&gt;right-&gt;npl + 1) : (x-&gt;left-&gt;npl + 1); return x;&#125;/* * 新建结点(key)，并将其插入到左倾堆中 * * 参数说明： * heap 左倾堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */LeftistNode* insert_leftist(LeftistHeap heap, Type key)&#123; LeftistNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (LeftistNode *)malloc(sizeof(LeftistNode))) == NULL) return heap; node-&gt;key = key; node-&gt;npl = 0; node-&gt;left = node-&gt;right = NULL; return merge_leftist(heap, node);&#125;/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */LeftistNode* delete_leftist(LeftistHeap heap)&#123; if (heap == NULL) return NULL; LeftistNode *l = heap-&gt;left; LeftistNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_leftist(l, r); // 返回左右子树合并后的新树&#125;/* * 销毁左倾堆 */void destroy_leftist(LeftistHeap heap)&#123; if (heap==NULL) return ; if (heap-&gt;left != NULL) destroy_leftist(heap-&gt;left); if (heap-&gt;right != NULL) destroy_leftist(heap-&gt;right); free(heap);&#125;/* * 打印&quot;左倾堆&quot; * * heap -- 左倾堆的节点 * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */static void leftist_print(LeftistHeap heap, Type key, int direction)&#123; if(heap != NULL) &#123; if(direction==0) // heap是根节点 printf(&quot;%2d(%d) is root\n&quot;, heap-&gt;key, heap-&gt;npl); else // heap是分支节点 printf(&quot;%2d(%d) is %2d&apos;s %6s child\n&quot;, heap-&gt;key, heap-&gt;npl, key, direction==1?&quot;right&quot; : left&quot;); leftist_print(heap-&gt;left, heap-&gt;key, -1); leftist_print(heap-&gt;right,heap-&gt;key, 1); &#125;&#125;void print_leftist(LeftistHeap heap)&#123; if (heap != NULL) leftist_print(heap, heap-&gt;key, 0);&#125; 左倾堆的测试程序(leftist_test.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * C语言实现的左倾堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &quot;leftist.h&quot;#define LENGTH(a) ( (sizeof(a)) / (sizeof(a[0])) )void main()&#123; int i; int a[]= &#123;10,40,24,30,36,20,12,16&#125;; int b[]= &#123;17,13,11,15,19,21,23&#125;; int alen=LENGTH(a); int blen=LENGTH(b); LeftistHeap ha,hb; ha=hb=NULL; printf(&quot;== 左倾堆(ha)中依次添加: &quot;); for(i=0; i&lt;alen; i++) &#123; printf(&quot;%d &quot;, a[i]); ha = insert_leftist(ha, a[i]); &#125; printf(&quot;\n== 左倾堆(ha)的详细信息: \n&quot;); print_leftist(ha); printf(&quot;\n== 左倾堆(hb)中依次添加: &quot;); for(i=0; i&lt;blen; i++) &#123; printf(&quot;%d &quot;, b[i]); hb = insert_leftist(hb, b[i]); &#125; printf(&quot;\n== 左倾堆(hb)的详细信息: \n&quot;); print_leftist(hb); // 将&quot;左倾堆hb&quot;合并到&quot;左倾堆ha&quot;中。 ha = merge_leftist(ha, hb); printf(&quot;\n== 合并ha和hb后的详细信息: \n&quot;); print_leftist(ha); // 销毁左倾堆 destroy_leftist(ha);&#125; 左倾堆的C测试程序左倾堆的测试程序已经包含在它的实现文件(leftist_test.c)中了，这里仅给出它的运行结果：12345678910111213141516171819202122232425262728293031323334353637== 左倾堆(ha)中依次添加: 10 40 24 30 36 20 12 16 == 左倾堆(ha)的详细信息: 10(2) is root24(1) is 10&apos;s left child30(0) is 24&apos;s left child36(0) is 24&apos;s right child12(1) is 10&apos;s right child20(0) is 12&apos;s left child40(0) is 20&apos;s left child16(0) is 12&apos;s right child== 左倾堆(hb)中依次添加: 17 13 11 15 19 21 23 == 左倾堆(hb)的详细信息: 11(2) is root15(1) is 11&apos;s left child19(0) is 15&apos;s left child21(0) is 15&apos;s right child13(1) is 11&apos;s right child17(0) is 13&apos;s left child23(0) is 13&apos;s right child== 合并ha和hb后的详细信息: 10(2) is root11(2) is 10&apos;s left child15(1) is 11&apos;s left child19(0) is 15&apos;s left child21(0) is 15&apos;s right child12(1) is 11&apos;s right child13(1) is 12&apos;s left child17(0) is 13&apos;s left child16(0) is 13&apos;s right child23(0) is 16&apos;s left child20(0) is 12&apos;s right child40(0) is 20&apos;s left child24(1) is 10&apos;s right child30(0) is 24&apos;s left child36(0) is 24&apos;s right child]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的const关键字]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%ADconst%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[const的用法const是不改变的。在C和C++中，我们使用关键字const来使程序元素保持不变。const关键字可以在C++程序的许多上下文中使用。它可以用于：变量、指针、函数参数和返回类型、类数据成员、类成员函数、对象。 const变量如果你用const关键字做任何变量，你就不能改变它的值。同样，必须在声明的时候初始化常数变量。Example:123456int main&#123; const int i = 10; const int j = i + 10; // works fine i++; // this leads to Compile time error &#125; 上面的代码中，我们使 i 成为常量，因此如果我们试图改变它的值，我们将得到编译时错误。尽管我们可以用它来代替其他变量。 指针与const关键字指针也可以使用const关键字来声明。当我们使用const和指针时，我们可以用两种方式来做：可以把const应用到指针指向的地方，或者我们可以使指针本身成为一个常数。 指向const变量的指针：意味着指针指向一个const变量。1const int* u; 这里，表示u是一个指针，可以指向const int类型变量。指针指向的内容不可改变。简称左定值，因为const位于*号的左边。 我们也可以这样写，1char const* v; 表示v是指向const类型的char的指针。指向const变量的指针非常有用，因为它可以用来使任何字符串或数组不可变 const指针为了使指针保持不变，我们必须把const关键字放到右边。对于const指针p其指向的内存地址不能够被改变，但其内容可以改变。简称，右定向。因为const位于*号的右边。12int x = 1;int* const w = &amp;x; 里，w是一个指针，它是const，指向一个int，现在我们不能改变指针，这意味着它总是指向变量x但是可以改变它指向的值，通过改变x的值。 当你想要一个可以在值中改变但不会在内存中移动的存储器时，常量指针指向一个变量是很有用的。因为指针总是指向相同的内存位置，因为它是用const关键字定义的，但是那个内存位置的值可以被更改。左定值，右定向，const修饰不变量 const函数参数和返回类型123456789void f(const int i)&#123; i++; // error&#125; const int g()&#123; return 1;&#125; 注意几个要点： ①对于内置数据类型，返回const或非const值，不会有任何影响。12345678910const int h()&#123; return 1;&#125;int main()&#123; const int j = h(); int k = h();&#125; j和k都将被赋值为1。不会出现错误。 ②对于用户定义的数据类型，返回const，将阻止它的修改。此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 ③在程序执行时创建的临时对象总是const类型。值传递的 const 修饰传递，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。当 const 参数为指针时，可以防止指针被意外篡改。123456789101112131415161718#include&lt;iostream&gt; using namespace std; void Cpf(int *const a)&#123; cout&lt;&lt;*a&lt;&lt;&quot; &quot;; *a = 9;&#125; int main(void)&#123; int a = 8; Cpf(&amp;a); cout&lt;&lt;a; // a 为 9 system(&quot;pause&quot;); return 0;&#125; 自定义类型的参数传递，需要临时对象复制参数，对于临时对象的构造，需要调用构造函数，比较浪费时间，因此我们采取 const 外加引用传递的方法。并且对于一般的 int、double 等内置类型，我们不采用引用的传递方式。1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt; using namespace std; class Test&#123;public: Test()&#123;&#125; Test(int _m):_cm(_m)&#123;&#125; int get_cm()const &#123; return _cm; &#125; private: int _cm;&#125;; void Cmf(const Test&amp; _tt)&#123; cout&lt;&lt;_tt.get_cm();&#125; int main(void)&#123; Test t(8); Cmf(t); system(&quot;pause&quot;); return 0;&#125; ④如果一个函数有一个非const参数，它在发出调用时不能传递const参数。1234void t(int*) &#123; // function logic&#125; 如果我们把一个const int参数传递给函数t，会出现错误。 ⑤但是，一个具有const类型参数的函数，可以传递一个const类型参数以及一个非const参数。1234void g(const int*) &#123; // function logic&#125; 这个函数可以有一个int，也可以有const int类型参数。 const修饰函数返回值(1)指针传递 如果返回const data,non-const pointer，返回值也必须赋给const data,non-const pointer。因为指针指向的数据是常量不能修改。1234567891011const int * mallocA()&#123; ///const data,non-const pointer int *a=new int(2); return a;&#125;int main()&#123; const int *a = mallocA(); ///int *b = mallocA(); ///编译错误 return 0;&#125; (2)值传递 如果函数返回值采用“值传递方式”，由于函数会把返回值复制到外部临时的存储单元中，加const 修饰没有任何价值。所以，对于值传递来说，加const没有太多意义。 所以： 不要把函数int GetInt(void) 写成const int GetInt(void)。 不要把函数A GetA(void) 写成const A GetA(void)，其中A 为用户自定义的数据类型。 将类数据成员定义为const这些是类中的数据变量，使用const关键字定义。它们在声明期间未初始化。它们的初始化在构造函数中完成。1234567891011121314class Test&#123; const int i; public: Test (int x) : i(x) &#123; &#125;&#125;; int main()&#123; Test t(10); Test s(20);&#125; 在这个程序中，i 是一个常量数据成员，在每个对象中它的独立副本将会出现，因此它使用构造函数对每个对象进行初始化。一旦初始化，它的值就不能改变 把类对象定义为const当一个对象被声明或使用const关键字创建时，它的数据成员在对象的生命周期中永远不会被改变。 语法：1const class_name object; 例如，如果在上面定义的类测试中，我们想要定义一个常数对象，我们可以这样做：1const Test r(30); 将类的成员函数定义为constconst成员函数决不会修改对象中的数据成员。注意：const关键字不能与static关键字同时使用，因为static关键字修饰静态成员函数，静态成员函数不含有this指针，即不能实例化，const成员函数必须具体到某一实例。 如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用mutable关键字修饰这个成员，mutable的意思也是易变的，容易改变的意思，被mutable关键字修饰的成员可以处于不断变化中。 const成员函数不能调用非const成员函数，因为非const成员函数可以会修改成员变量。123456789101112131415161718#include &lt;iostream&gt;using namespace std;class Point&#123; public : Point(int _x):x(_x)&#123;&#125; void testConstFunction(int _x) const&#123; ///错误，在const成员函数中，不能修改任何类成员变量 x=_x; ///错误，const成员函数不能调用非onst成员函数，因为非const成员函数可以会修改成员变量 modify_x(_x); &#125; void modify_x(int _x)&#123; x=_x; &#125; int x;&#125;; 语法：return_type function_name() const;const对象和const成员函数的例子：12345678910111213141516171819202122232425262728293031323334353637class StarWars&#123; public: int i; StarWars(int x) // constructor &#123; i = x; &#125; int falcon() const // constant function &#123; /* can do anything but will not modify any data members */ cout &lt;&lt; &quot;Falcon has left the Base&quot;; &#125; int gamma() &#123; i++; &#125;&#125;; int main()&#123; StarWars objOne(10); // non const object const StarWars objTwo(20); // const object objOne.falcon(); // No error objTwo.falcon(); // No error cout &lt;&lt; objOne.i &lt;&lt; objTwo.i; objOne.gamma(); // No error objTwo.gamma(); // Compile time error&#125; 输出结果：123Falcon has left the BaseFalcon has left the Base10 20 在这里，我们可以看到，const成员函数永远不会改变类的数据成员，并且它可以与const和非const对象一起使用。但是const对象不能与试图改变其数据成员的成员函数一起使用。 关于const的疑问：1.const什么时候为只读变量？2.const什么时候是常量？ const常量的判别标准： 只有字面量初始化的const常量才会进入符号表 使用其他变量初始化的const常量仍然是只读变量 被volatile修饰的const常量不会进入符号表 注意： const引用的类型与初始化变量的类型相同时：初始化变量成为只读变量 const引用的类型与初始化变量的类型不相同时：初生成一个新的只读变量 Example:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt; int main()&#123; const int x = 1; //字面量初始化，此时x为常量，进入符号表 const int&amp; rx = x; //rx代表只读变量 int&amp; nrx = const_cast&lt;int&amp;&gt;(rx); //去掉rx的只读属性 nrx = 5; //改变了nrx内存空间的值 printf(&quot;x = %d\n&quot;, x); // 1 printf(&quot;rx = %d\n&quot;, rx); // 5 printf(&quot;nrx = %d\n&quot;, nrx); // 5 printf(&quot;&amp;x = %p\n&quot;, &amp;x); // &amp;x = 002CFD80 printf(&quot;&amp;rx = %p\n&quot;, &amp;rx); // &amp;x = 002CFD80 printf(&quot;&amp;nrx = %p\n&quot;, &amp;nrx); // &amp;x = 002CFD80 //输出的地址相同，说明了x、rx、nrx代表同样的内存空间 volatile const int y = 2;//volatile代表易变的 int* p = const_cast&lt;int*&gt;(&amp;y); *p = 6; printf(&quot;y = %d\n&quot;, y); //y = 6 printf(&quot;p = %p\n&quot;, p); //p = 001BF928 //判别是否是常量是编译器在编译时能不能确认它的值 const int z = y; p = const_cast&lt;int*&gt;(&amp;z); *p = 7; printf(&quot;z = %d\n&quot;, z); // z = 7 printf(&quot;p = %p\n&quot;, p); //p = 001BF910 char c = &apos;c&apos;; char&amp; rc = c; const int&amp; trc = c; rc = &apos;a&apos;; printf(&quot;c = %c\n&quot;, c); // c = a printf(&quot;rc = %c\n&quot;, rc);// rc = a printf(&quot;trc = %c\n&quot;, trc);//trc = c //变量c是char类型，而trc是int类型，所以生成了一个新的只读变量 return 0;&#125; 输出结果：]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的变长参数]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%AD%E7%9A%84%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[变长参数函数 首先回顾一下较多使用的变长参数函数，最经典的便是printf。1extern int printf(const char *format, ...); 以上是一个变长参数的函数声明。我们自己定义一个测试函数：123456789101112131415161718192021#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;int testparams(int count, ...)&#123; va_list args; va_start(args, count); for (int i = 0; i &lt; count; ++i) &#123; int arg = va_arg(args, int); printf(&quot;arg %d = %d&quot;, i, arg); &#125; va_end(args); return 0;&#125;int main()&#123; testparams(3, 10, 11, 12); return 0;&#125; 变长参数函数的解析，使用到三个宏va_start,va_arg 和va_end，再看va_list的定义typedef char* va_list; 只是一个char指针。 这几个宏如何解析传入的参数呢？ 函数的调用，是一个压栈，保存，跳转的过程。简单的流程描述如下： 把参数从右到左依次压入栈； 调用call指令，把下一条要执行的指令的地址作为返回地址入栈；（被调用函数执行完后会回到该地址继续执行） 当前的ebp（基址指针）入栈保存，然后把当前esp（栈顶指针）赋给ebp作为新函数栈帧的基址； 执行被调用函数，局部变量等入栈； 返回值放入eax，leave，ebp赋给esp，esp所存的地址赋给ebp；（这里可能需要拷贝临时返回对象） 从返回地址开始继续执行；（把返回地址所存的地址给eip） 由于开始的时候从右至左把参数压栈，va_start 传入最左侧的参数，往右的参数依次更早被压入栈，因此地址依次递增（栈顶地址最小）。va_arg传入当前需要获得的参数的类型，便可以利用 sizeof 计算偏移量，依次获取后面的参数值。 12345678910111213#define _INTSIZEOF(n) ((sizeof(n) + sizeof(int) - 1) &amp; ~(sizeof(int) - 1))#define _ADDRESSOF(v) (&amp;const_cast&lt;char&amp;&gt;(reinterpret_cast&lt;const volatile char&amp;&gt;(v)))#define __crt_va_start_a(ap, v) ((void)(ap = (va_list)_ADDRESSOF(v) + _INTSIZEOF(v)))#define __crt_va_arg(ap, t) (*(t*)((ap += _INTSIZEOF(t)) - _INTSIZEOF(t)))#define __crt_va_end(ap) ((void)(ap = (va_list)0))#define __crt_va_start(ap, x) ((void)(__vcrt_va_start_verify_argument_type&lt;decltype(x)&gt;(), __crt_va_start_a(ap, x)))#define va_start __crt_va_start#define va_arg __crt_va_arg#define va_end __crt_va_end 上述宏定义中，_INTSIZEOF(n) 将地址的低2位指令，做内存的4字节对齐。每次取参数时，调用__crt_va_arg(ap,t) ，返回t类型参数地址的值，同时将ap偏移到t之后。最后，调用_crt_va_end(ap)将ap置0. 变长参数的函数的使用及其原理看了宏定义是很好理解的。从上文可知，要使用变长参数函数的参数，我们必须知道传入的每个参数的类型。printf中，有format字符串中的特殊字符组合来解析后面的参数类型。但是当传入类的构造函数的参数时，我们并不知道每个参数都是什么类型，虽然参数能够依次传入函数，但无法解析并获取每个参数的数值。因此传统的变长参数函数并不足以解决传入任意构造函数参数的问题。 变长参数模板我们需要用到C++11的新特性，变长参数模板。 这里举一个使用自定义内存池的例子。定义一个内存池类MemPool.h，以count个类型T为单元分配内存，默认分配一个对象。每当内存内空闲内存不够，则一次申请MEMPOOL_NEW_SIZE个内存对象。内存池本身只负责内存分配，不做初始化工作，因此不需要传入任何参数，只需实例化模板分配相应类型的内存即可。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#ifndef UTIL_MEMPOOL_H#define UTIL_MEMPOOL_H#include &lt;stdlib.h&gt;#define MEMPOOL_NEW_SIZE 8template&lt;typename T, size_t count = 1&gt;class MemPool&#123;private: union MemObj &#123; char _obj[1]; MemObj* _freelink; &#125;;public: static void* Allocate() &#123; if (!_freelist) &#123; refill(); &#125; MemObj* alloc_mem = _freelist; _freelist = _freelist-&gt;_freelink; ++_size; return (void*)alloc_mem; &#125; static void DeAllocate(void* p) &#123; MemObj* q = (MemObj*)p; q-&gt;_freelink = _freelist; _freelist = q; --_size; &#125; static size_t TotalSize() &#123; return _totalsize; &#125; static size_t Size() &#123; return _size; &#125;private: static void refill() &#123; size_t size = sizeof(T) * count; char* new_mem = (char*)malloc(size * MEMPOOL_NEW_SIZE); for (int i = 0; i &lt; MEMPOOL_NEW_SIZE; ++i) &#123; MemObj* free_mem = (MemObj*)(new_mem + i * size); free_mem-&gt;_freelink = _freelist; _freelist = free_mem; &#125; _totalsize += MEMPOOL_NEW_SIZE; &#125; static MemObj* _freelist; static size_t _totalsize; static size_t _size;&#125;;template&lt;typename T, size_t count&gt;typename MemPool&lt;T, count&gt;::MemObj* MemPool&lt;T, count&gt;::_freelist = NULL;template&lt;typename T, size_t count&gt;size_t MemPool&lt;T, count&gt;::_totalsize = 0;template&lt;typename T, size_t count&gt;size_t MemPool&lt;T, count&gt;::_size = 0;#endif 接下来在没有变长参数的情况下，实现通用MemNew和MemDelete函数模板。这里不对函数模板作详细解释，用函数模板我们可以对不同的类型实现同样的内存池分配操作。如下：1234567891011121314151617181920212223242526272829303132template&lt;class T&gt;T *MemNew(size_t count)&#123; T *p = (T*)MemPool&lt;T, count&gt;::Allocate(); if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; new (&amp;p[i]) T(); &#125; &#125; &#125; return p;&#125;template&lt;class T&gt;T *MemDelete(T *p, size_t count)&#123; if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; p[i].~T(); &#125; &#125; MemPool&lt;T, count&gt;::DeAllocate(p); &#125;&#125; 上述实现中，使用placement new对申请的内存进行构造，使用了默认构造函数，当申请内存的类型不具备默认构造函数时，placement new将报错。对于pod类型，可以省去调用构造函数的过程。 引入C++11变长模板参数后MemNew修改为如下:12345678910111213141516template&lt;class T, class... Args&gt;T *MemNew(size_t count, Args&amp;&amp;... args)&#123; T *p = (T*)MemPool&lt;T, count&gt;::Allocate(); if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; new (&amp;p[i]) T(std::forward&lt;Args&gt;(args)...); &#125; &#125; &#125; return p;&#125; 以上函数定义包含了多个特性，后面我将一一解释，其中class… Args 表示变长参数模板，函数参数中Args&amp;&amp; 为右值引用。std::forward 实现参数的完美转发。这样，无论传入的类型具有什么样的构造函数，都能够完美执行placement new。 C++11中引入了变长参数模板的概念，来解决参数个数不确定的模板。12345678910template&lt;class... T&gt; class Test &#123;&#125;;Test&lt;&gt; test0;Test&lt;int&gt; test1;Test&lt;int,int&gt; test2;Test&lt;int,int,long&gt; test3;template&lt;class... T&gt; void test(T... args);test();test&lt;int&gt;(0);test&lt;int,int,long&gt;(0,0,0L); 变长参数函数模板T… args 为形参包，其中args是模式，形参包中可以有0到任意多个参数。调用函数时，可以传任意多个实参。对于函数定义来说，该如何使用参数包呢？在上文的MemNew中，我们使用std::forward依次将参数包传入构造函数，并不关注每个参数具体是什么。如果需要，我们可以用sizeof…(args)操作获取参数个数，也可以把参数包展开，对每个参数做更多的事。展开的方法有两种，递归函数，逗号表达式。 递归函数方式展开，模板推导的时候，一层层递归展开，最后到没有参数时用定义的一般函数终止。1234567891011121314151617void test()&#123;&#125;template&lt;class T, class... Args&gt; void test(T first, Args... args)&#123; std::cout &lt;&lt; typeid(T).name() &lt;&lt; &quot; &quot; &lt;&lt; first &lt;&lt; std::endl; test(args...);&#125;test&lt;int, int, long&gt;(0, 0, 0L);output:int 0int 0long 0 逗号表达式方式展开，利用数组的参数初始化列表和逗号表达式，逐一执行print每个参数。123456789101112131415161718template&lt;class T&gt;void print(T arg)&#123; std::cout &lt;&lt; typeid(T).name() &lt;&lt; &quot; &quot; &lt;&lt; arg &lt;&lt; std::endl;&#125;template&lt;class... Args&gt;void test(Args... args)&#123; int arr[] = &#123; (print(args), 0)... &#125;;&#125;test(0, 0, 0L);output:int 0int 0long 0 变长参数类模板变长参数类模板，一般情况下可以方便我们做一些编译期计算。可以通过偏特化和递归推导的方式依次展开模板参数。 12345678910111213141516171819202122template&lt;class T, class... Types&gt;class Test&#123;public: enum &#123; value = Test&lt;T&gt;::value + Test&lt;Types...&gt;::value, &#125;;&#125;;template&lt;class T&gt;class Test&lt;T&gt;&#123;public: enum &#123; value = sizeof(T), &#125;;&#125;;Test&lt;int, int, long&gt; test;std::cout &lt;&lt; test.value;output: 12 右值引用和完美转发对于变长参数函数模板，需要将形参包展开逐个处理的需求不多，更多的还是像本文的MemNew这样的需求，最终整个传入某个现有的函数。我们把重点放在参数的传递上。 要理解右值引用，需要先说清楚左值和右值。左值是内存中有确定存储地址的对象的表达式的值；右值则是非左值的表达式的值。const左值不可被赋值，临时对象的右值可以被赋值。左值与右值的根本区别在于是否能用&amp;运算符获得内存地址。123456789101112int i =0;//i 左值int *p = &amp;i;// i 左值int&amp; foo();foo() = 42;// foo() 左值int* p1 = &amp;foo();// foo() 左值int foo1();int j = 0;j = foo1();// foo 右值int k = j + 1;// j + 1 右值int *p2 = &amp;foo1(); // 错误，无法取右值的地址j = 1;// 1 右值 理解左值和右值之后，再来看引用，对左值的引用就是左值引用，对右值（纯右值和临终值）的引用就是右值引用。 如下函数foo，传入int类型，返回int类型，这里传入函数的参数0和返回值0都是右值(不能用&amp;取得地址)。于是，未做优化的情况下，传入参数0的时候，我们需要把右值0拷贝给param，函数返回的时候需要将0拷贝给临时对象，临时对象再拷贝给res。当然现在的编译器都做了返回值优化，返回对象是直接创建在返回后的左值上的，这里只用来举个例子1234567int foo(int param)&#123; printf(&quot;%d&quot;, param); return 0;&#125;int res = foo(0); 显然，这里的拷贝都是多余的。可能我们会想要优化，首先将参数int改为int&amp;，传入左值引用，于是0无法传入了，当然我们可以改成const int&amp;，这样终于省去了传参的拷贝。12345int foo(const int&amp; param)&#123; printf(&quot;%d&quot;, param); return 0;&#125; 由于const int&amp; 既可以是左值也可以是右值，传入0或者int变量都能够满足。(但是似乎既然有左值引用的int&amp;类型，就应该有对应的传入右值引用的类型int&amp;&amp;)。另外，这里返回的右值0，似乎不通过拷贝就无法赋值给左值res。 于是有了移动语义，把临时对象的内容直接移动给被赋值的左值对象(std::move)。和右值引用，X&amp;&amp;是到数据类型X的右值引用。123456789int result = 0;int&amp;&amp; foo(int&amp;&amp; param)&#123; printf(&quot;%d&quot;, param); return std::move(result);&#125;int&amp;&amp; res = foo(0);int *pres = &amp;res; 将foo改为右值引用参数和返回值，返回右值引用，免去拷贝。这里res是具名引用，运算符右侧的右值引用作为左值，可以取地址。右值引用既有左值性质，也有右值性质。 上述例子还只存在于拷贝的性能问题。回到MemNew这样的函数模板。 1234567891011121314151617181920212223template&lt;class T&gt;T* Test(T arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(T&amp; arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(const T&amp; arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(T&amp;&amp; arg)&#123; return new T(std::forward&lt;T&gt;(arg));&#125; 上述的前三种方式传参，第一种首先有拷贝消耗，其次有的参数就是需要修改的左值。第二种方式则无法传常数等右值。第三种方式虽然左值右值都能传，却无法对传入的参数进行修改。第四种方式使用右值引用，可以解决参数完美转发的问题。 std::forward能够根据实参的数据类型，返回相应类型的左值和右值引用，将参数完整不动的传递下去。解释这个原理涉及到引用塌缩规则 T&amp; &amp; -&gt;T&amp;T&amp; &amp;&amp;-&gt;T&amp;T&amp;&amp; &amp;-&gt;T&amp;T&amp;&amp; &amp;&amp;-&gt;T&amp;&amp; 1234567891011121314template&lt; class T &gt; struct remove_reference &#123;typedef T type;&#125;;template&lt; class T &gt; struct remove_reference&lt;T&amp;&gt; &#123;typedef T type;&#125;;template&lt; class T &gt; struct remove_reference&lt;T&amp;&amp;&gt; &#123;typedef T type;&#125;;template&lt; class T &gt; T&amp;&amp; forward( typename std::remove_reference&lt;T&gt;::type&amp; t )&#123; return static_cast&lt;T&amp;&amp;&gt;(t);&#125;template&lt;class T&gt;typename std::remove_reference&lt;T&gt;::type&amp;&amp; move(T&amp;&amp; a) noexcept&#123; return static_cast&lt;typename std::remove_reference&lt;T&gt;::type&amp;&amp;&gt;(a);&#125; 对于函数模板12345template&lt;class T&gt;T* Test(T&amp;&amp; arg)&#123; return new T(std::forward&lt;T&gt;(arg));&#125; 当传入实参为X类型左值时，T为X&amp;，最后的类型为X&amp;。当实参为X类型右值时，T为X，最后的类型为X&amp;&amp;。 x为左值时：12X x;Test(x); T为X&amp;，实例化后123456789101112131415161718192021X&amp; &amp;&amp; std::forward(remove_reference&lt;X&amp;&gt;::type&amp; a) noexcept&#123; return static_cast&lt;X&amp; &amp;&amp;&gt;(a);&#125;X* Test(X&amp; &amp;&amp; arg)&#123; return new X(std::forward&lt;X&amp;&gt;(arg)); &#125;// 塌陷后X&amp; std::forward(X&amp; a)&#123; return static_cast&lt;X&amp;&gt;(a);&#125;X* Test(X&amp; arg)&#123; return new X(std::forward&lt;X&amp;&gt;(arg));&#125; x为右值时：12X foo();Test(foo()); T为X，实例化后123456789101112131415161718192021X&amp;&amp; std::forward(remove_reference&lt;X&gt;::type&amp; a) noexcept&#123; return static_cast&lt;X&amp;&amp;&gt;(a);&#125;X* Test(X&amp;&amp; arg)&#123; return new X(std::forward&lt;X&gt;(arg)); &#125;// 塌陷后X&amp;&amp; std::forward(X&amp; a)&#123; return static_cast&lt;X&amp;&amp;&gt;(a);&#125;X* Test(X&amp;&amp; arg)&#123; return new X(std::forward&lt;X&gt;(arg));&#125; 可以看到最终实参总是被推导为和传入时相同的类型引用。 至此，我们讨论了变长参数模板，讨论了右值引用和函数模板的完美转发，完整的解释了MemNew对任意多个参数的构造函数的参数传递过程。利用变长参数函数模板，右值引用和std::forward，可以完成参数的完美转发。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的Volatile关键字]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/god-of-death/p/7852394.html 概述why volatilevolatile 关键词，最早出现于20世纪70年代，被用于处理 MMIO(Memory-mapped I/O) 带来的问题。在引入 MMIO 之后，一块内存地址既有可能是真正的内存，也有可能是映射的一个I/O端口。因此，读/写一个内存地址，既有可能是真正地操作内存，也有可能是读/写一个I/O设备。 那么 MMIO 为什么需要引入 volatile 关键词呢？我们结合下面这段示例代码进行解释：123456789unsigned int *p = FunB();unsigned int a;unsigned int b; a = *p; // 语句1b = *p; // 语句2 *p = a; // 语句3*p = b; // 语句4 在上述代码片段中，指针p既有可能指向一个内存地址，也有可能指向一个I/O设备。如果指针p指向的是I/O设备，那么语句1和语句2中的变量a和变量b，就会接收到I/O设备的连续两个字节。但是，指针p也有可能指向内存地址，这种情况下，编译器就会进行语句优化，编译器的优化策略会判断变量a和变量b同时从同一个内存地址读取数据，因此在执行完语句1之后，直接将变量a赋值给变量b。对于指针p指向I/O设备的这种情况，就需要防止编译器进行此优化，即不能假设指针b指向的内容不变（对应 volatile 的易变性特性）。 同样，语句3和语句4也有类似的问题，编译器发现将变量a和b同时赋值给指针p是无意义的，因此可能会优化语句3中的赋值操作，而仅仅保留语句4。对于指针p指向I/O设备的情况，也需要防止编译器将类似的写操作给优化消失了（对应 volatile 的不可优化特性）。 对于I/O设备，编译器不能随意交互指令的顺序，因为指令顺序一变，写入I/O设备的内容也就发生变化了（对应 volatile 的顺序性）。 为了满足 MMIO 的这三点需求，就有了 volatile 关键字。 IN C/C++在C/C++语言中，使用 volatile 关键字声明的变量（或对象）通常具有与优化、多线程相关的特殊属性。通常，volatile 关键字用来阻止（伪）编译器对其认为的、无法“被代码本身”改变的代码（变量或对象）进行优化。如在C/C++中，volatile 关键字可以用来提醒编译器使用 volatile 声明的变量随时有可能改变，因此编译器在代码编译时就不会对该变量进行某些激进的优化，故而编译生成的程序在每次存储或读取该变量时，都会直接从内存地址中读取数据。相反，如果该变量没有使用 volatile 关键字进行声明，则编译器可能会优化读取和存储操作，可能暂时使用寄存器中该变量的值，而如果这个变量由别的程序（线程）更新了的话，就会出现（内存中与寄存器中的）变量值不一致的现象。 定义为volatile的变量是说这变量可能会被意想不到地改变，即在你程序运行过程中一直会变，你希望这个值被正确的处理，每次从内存中去读这个值，而不是因编译器优化从缓存的地方读取，比如读取缓存在寄存器中的数值，从而保证volatile变量被正确的读取。 在单任务的环境中，一个函数体内部，如果在两次读取变量的值之间的语句没有对变量的值进行修改，那么编译器就会设法对可执行代码进行优化。由于访问寄存器的速度要快过RAM（从RAM中读取变量的值到寄存器），以后只要变量的值没有改变，就一直从寄存器中读取变量的值，而不对RAM进行访问。 而在多任务环境中，虽然在一个函数体内部，在两次读取变量之间没有对变量的值进行修改，但是该变量仍然有可能被其他的程序（如中断程序、另外的线程等）所修改。如果这时还是从寄存器而不是从RAM中读取，就会出现被修改了的变量值不能得到及时反应的问题。 因为访问寄存器要比访问内存单元快的多,所以编译器一般都会作减少存取内存的优化，但有可能会读脏数据。当要求使用volatile声明变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。精确地说就是，遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用valatile，则编译器将对所声明的语句进行优化。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错。加了volatile修饰的变量，编译器将不对其相关代码执行优化，而是生成对应代码直接存取原始内存地址）。 一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。一般说来，volatile用在如下的几个地方： （1）并行设备的硬件寄存器（如：状态寄存器） （2）中断服务程序中修改的供其它程序检测的变量需要加volatile； （3）多任务环境下各任务间共享的标志应该加volatile； （4）存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能有不同意义； 在C/C++语言中，使用 volatile 关键字声明的变量具有三种特性：易变的、不可优化的、顺序执行的。下面分别对这三种特性进行介绍。 易变的volatile 在词典中的主要释义就是“易变的”。 在 C/C++ 语言中，volatile 的易变性体现在：假设有读、写两条语句，依次对同一个 volatile 变量进行操作，那么后一条的读操作不会直接使用前一条的写操作对应的 volatile 变量的寄存器内容，而是重新从内存中读取该 volatile 变量的值。 上述描述的（部分）示例代码如下：1234volatile int nNum = 0; // 将nNum声明为volatileint nSum = 0;nNum = FunA(); // nNum被写入的新内容，其值会缓存在寄存器中nSum = nNum + 1; // 此处会从内存（而非寄存器）中读取nNum的值 不可优化的在 C/C++ 语言中，volatile 的第二个特性是“不可优化性”。volatile 会告诉编译器，不要对 volatile 声明的变量进行各种激进的优化（甚至将变量直接消除），从而保证程序员写在代码中的指令一定会被执行。 上述描述的（部分）示例代码如下：123volatile int nNum; // 将nNum声明为volatilenNum = 1;printf(&quot;nNum is: %d&quot;, nNum); 在上述代码中，如果变量 nNum 没有声明为 volatile 类型，则编译器在编译过程中就会对其进行优化，直接使用常量“1”进行替换（这样优化之后，生成的汇编代码很简介，执行时效率很高）。而当我们使用 volatile 进行声明后，编译器则不会对其进行优化，nNum 变量仍旧存在，编译器会将该变量从内存中取出，放入寄存器之中，然后再调用 printf() 函数进行打印。 顺序执行的在 C/C++ 语言中，volatile 的第三个特性是“顺序执行特性”，即能够保证 volatile 变量间的顺序性，不会被编译器进行乱序优化。 说明：C/C++ 编译器最基本优化原理：保证一段程序的输出，在优化前后无变化。 为了对本特性进行深入了解，下面以两个变量（nNum1 和 nNum2）为例（既然存在“顺序执行”，那描述对象必然大于一个），结合如下示例代码，介绍 volatile 的顺序执行特性。1234int nNum1;int nNum2;nNum2 = nNum1 + 1; // 语句1nNum1 = 10; // 语句2 在上述代码中： 当 nNum1 和 nNum2 都没有使用 volatile 关键字进行修饰时，编译器会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句2”、再执行“语句1”；当 nNum2 使用 volatile 关键字进行修饰时，编译器也可能会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句2”、再执行“语句1”；当 nNum1 和 nNum2 都使用 volatile 关键字进行修饰时，编译器不会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句1”、再执行“语句2”；说明：上述论述可通过观察代码的生成的汇编代码进行验证。 volatile与多线程语义对于多线程编程而言，在临界区内部，可以通过互斥锁（mutex）保证只有一个线程可以访问该临界区的内容，因此临界区内的变量不需要是 volatile 的；而在临界区外部，被多个线程访问的变量应声明为 volatile 的，这也符合了 volatile 的原意：防止编译器缓存（cache）了被多个线程并发用到的变量。 不过，需要注意的是，由于 volatile 关键字的“顺序执行特性”并非会完全保证语句的顺序执行（如 volatile 变量与非volatile 变量之间的操作；又如一些 CPU 也会对语句的执行顺序进行优化），因此导致了对 volatile 变量的操作并不是原子的，也不能用来为线程建立严格的 happens-before 关系。 对于上述描述，示例代码如下：1234567891011121314151617181920int nNum1 = 0;volatile bool flag = false; thread1()&#123; // some code nNum1 = 666; // 语句1 flag = true; // 语句2&#125; thread2()&#123; // some code if (true == flag) &#123; // 语句3：按照程序设计的预想，此处的nNum1的值应为666，并据此进行逻辑设计 &#125;&#125; 在上述代码中，我们的设计思路是先执行 thread1() 中的“语句1”、“语句2”、再执行 thread2() 中的“语句3”，不过实际上程序的执行结果未必如此。根据 volatile 的“顺序性”，非 volatile 变量 nNum1 和 volatile 变量 flag 的执行顺序，可能会被编译器（或 CPU）进行乱序优化，最终导致thread1中的“语句2”先于“语句1”执行，当“语句2”执行完成但“语句1”尚未执行时，此时 thread2 中的判断语句“if (true == flag)”是成立的，但实际上 nNum1 尚未进行赋值为666（语句1尚未执行），所以在判断语句中针对 nNum1 为666的前提下进行的相关操作，就会有问题了。 这是一个在多线程编程中，使用 volatile 不容易发现的问题。 实际上，上述多线程代码想实现的就是一个 happens-before 语义，即保证 thread1 代码块中的所有代码，一定要在 thread2 代码块的第一条代码之前完成。使用互斥锁（mutex）可以保证 happens-before 语义。但是，在 C/C++ 中的 volatile 关键词不能保证这个语义，也就意味着在多线程环境下使用 C/C++ 的 volatile 关键词，如果不够细心，就可能会出现上述问题。 说明：由于 Java 语言的 volatile 关键字支持 Acquire、Release 语义，因此 Java 语言的 volatile 能够用来构建 happens-before 语义。也就是说，前面提到的 C/C++ 中 volatile 在多线程下使用出现的问题，在 Java 语言中是不存在的。 不保证原子性volatile只保证其“可见性”，不保证其“原子性”。 执行count++;这条语句由3条指令组成： 将 count 的值从内存加载到 cpu 的某个 寄存器r； 将 寄存器r 的值 +1，结果存放在 寄存器s； 将 寄存器s 中的值写回内存。 所以，如果有多个线程同时在执行 count++，在某个线程执行完第（3）步之前，其它线程是看不到它的执行结果的。（这里有疑惑：线程同时执行count++，为了保证其原子性，为何不加mutex lock？而是寻求volatile?） 在没有volatile的时候，执行完count++，执行结果其实是写到CPU缓存中，没有马上写回到内存中，后续在某些情况下（比如CPU缓存不够用）再将CPU缓存中的值flush到内存。因为没有存到内存里，其他线程是不能及时看到执行结果的。 在有volatile的时候，执行完count++，执行结果写入缓存中，并同时写入内存中，所以可以保证其它线程马上看到执行的结果。 但是，volatile 并没有保证原子性，在某个线程执行（1）（2）（3）的时候，volatile 并没有锁定 count 的值，也就是并不能阻塞其他线程也执行（1）（2）（3）。可能有两个线程同时执行（1），所以（2）计算出来一样的结果，然后（3）存回的也是同一个值。考虑下面一段代码：12345int some_int = 100;while(some_int == 100)&#123; //your code&#125; 因为编译器认为some_int没被改变过，一直是100。但是在多线程时，如果执行完第一行，但是还没执行到第三行时，另一个线程修改了some_int，while就不能进入循环了。加了volatile后，阻止了编译器优化，每次读到some_int会从内存中读取，而不是本线程的寄存去（当然这会损失效率）。这就是volatile的作用。 一句话总结：volatile保证线程能读到最新的数据，因为是从内存中读取，且存入内存中。而不是线程各自的寄存器中读写。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中断子系统之一：中断系统基本原理]]></title>
    <url>%2F2019%2F05%2F08%2FLinux%E4%B8%AD%E6%96%AD%E5%AD%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E4%B8%80-%E4%B8%AD%E6%96%AD%E7%B3%BB%E7%BB%9F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[声明：本博内容均由http://blog.csdn.net/droidphone原创。 设备、中断控制器和CPU一个完整的设备中，与中断相关的硬件可以划分为3类，它们分别是：设备、中断控制器和CPU本身，下图展示了一个smp系统中的中断硬件的组成结构： 设备：设备是发起中断的源，当设备需要请求某种服务的时候，它会发起一个硬件中断信号，通常，该信号会连接至中断控制器，由中断控制器做进一步的处理。在现代的移动设备中，发起中断的设备可以位于soc（system-on-chip）芯片的外部，也可以位于soc的内部，因为目前大多数soc都集成了大量的硬件IP，例如I2C、SPI、Display Controller等等。 中断控制器：中断控制器负责收集所有中断源发起的中断，现有的中断控制器几乎都是可编程的，通过对中断控制器的编程，我们可以控制每个中断源的优先级、中断的电器类型，还可以打开和关闭某一个中断源，在smp系统中，甚至可以控制某个中断源发往哪一个CPU进行处理。对于ARM架构的soc，使用较多的中断控制器是VIC（Vector Interrupt Controller），进入多核时代以后，GIC（General Interrupt Controller）的应用也开始逐渐变多。 CPU：CPU是最终响应中断的部件，它通过对可编程中断控制器的编程操作，控制和管理者系统中的每个中断，当中断控制器最终判定一个中断可以被处理时，他会根据事先的设定，通知其中一个或者是某几个cpu对该中断进行处理，虽然中断控制器可以同时通知数个cpu对某一个中断进行处理，实际上，最后只会有一个cpu相应这个中断请求，但具体是哪个cpu进行响应是可能是随机的，中断控制器在硬件上对这一特性进行了保证，不过这也依赖于操作系统对中断系统的软件实现。在smp系统中，cpu之间也通过IPI（inter processor interrupt）中断进行通信。 IRQ编号系统中每一个注册的中断源，都会分配一个唯一的编号用于识别该中断，我们称之为IRQ编号。IRQ编号贯穿在整个Linux的通用中断子系统中。在移动设备中，每个中断源的IRQ编号都会在arch相关的一些头文件中，例如arch/xxx/mach-xxx/include/irqs.h。驱动程序在请求中断服务时，它会使用IRQ编号注册该中断，中断发生时，cpu通常会从中断控制器中获取相关信息，然后计算出相应的IRQ编号，然后把该IRQ编号传递到相应的驱动程序中。 在驱动程序中申请中断Linux中断子系统向驱动程序提供了一系列的API，其中的一个用于向系统申请中断：123int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id) 其中， irq是要申请的IRQ编号， handler是中断处理服务函数，该函数工作在中断上下文中，如果不需要，可以传入NULL，但是不可以和thread_fn同时为NULL； thread_fn是中断线程的回调函数，工作在内核进程上下文中，如果不需要，可以传入NULL，但是不可以和handler同时为NULL； irqflags是该中断的一些标志，可以指定该中断的电气类型，是否共享等信息； devname指定该中断的名称； dev_id用于共享中断时的cookie data，通常用于区分共享中断具体由哪个设备发起； 关于该API的详细工作机理我们后面再讨论。 通用中断子系统（Generic irq）的软件抽象在通用中断子系统（generic irq）出现之前，内核使用do_IRQ处理所有的中断，这意味着do_IRQ中要处理各种类型的中断，这会导致软件的复杂性增加，层次不分明，而且代码的可重用性也不好。事实上，到了内核版本2.6.38，__do_IRQ这种方式已经彻底在内核的代码中消失了。通用中断子系统的原型最初出现于ARM体系中，一开始内核的开发者们把3种中断类型区分出来，他们是： 电平触发中断（level type） 边缘触发中断（edge type） 简易的中断（simple type） 后来又针对某些需要回应eoi（end of interrupt）的中断控制器，加入了fast eoi type，针对smp加入了per cpu type。把这些不同的中断类型抽象出来后，成为了中断子系统的流控层。要使所有的体系架构都可以重用这部分的代码，中断控制器也被进一步地封装起来，形成了中断子系统中的硬件封装层。我们可以用下面的图示表示通用中断子系统的层次结构： 硬件封装层 它包含了体系架构相关的所有代码，包括中断控制器的抽象封装，arch相关的中断初始化，以及各个IRQ的相关数据结构的初始化工作，cpu的中断入口也会在arch相关的代码中实现。中断通用逻辑层通过标准的封装接口（实际上就是struct irq_chip定义的接口）访问并控制中断控制器的行为，体系相关的中断入口函数在获取IRQ编号后，通过中断通用逻辑层提供的标准函数，把中断调用传递到中断流控层中。我们看看irq_chip的部分定义：12345678910111213141516171819struct irq_chip &#123; const char *name; unsigned int (*irq_startup)(struct irq_data *data); void (*irq_shutdown)(struct irq_data *data); void (*irq_enable)(struct irq_data *data); void (*irq_disable)(struct irq_data *data); void (*irq_ack)(struct irq_data *data); void (*irq_mask)(struct irq_data *data); void (*irq_mask_ack)(struct irq_data *data); void (*irq_unmask)(struct irq_data *data); void (*irq_eoi)(struct irq_data *data); int (*irq_set_affinity)(struct irq_data *data, const struct cpumask *dest, bool force); int (*irq_retrigger)(struct irq_data *data); int (*irq_set_type)(struct irq_data *data, unsigned int flow_type); int (*irq_set_wake)(struct irq_data *data, unsigned int on); ......&#125;; 看到上面的结构定义，很明显，它实际上就是对中断控制器的接口抽象，我们只要对每个中断控制器实现以上接口（不必全部），并把它和相应的irq关联起来，上层的实现即可通过这些接口访问中断控制器。而且，同一个中断控制器的代码可以方便地被不同的平台所重用。 中断流控层：所谓中断流控是指合理并正确地处理连续发生的中断，比如一个中断在处理中，同一个中断再次到达时如何处理，何时应该屏蔽中断，何时打开中断，何时回应中断控制器等一系列的操作。该层实现了与体系和硬件无关的中断流控处理操作，它针对不同的中断电气类型（level，edge……），实现了对应的标准中断流控处理函数，在这些处理函数中，最终会把中断控制权传递到驱动程序注册中断时传入的处理函数或者是中断线程中。目前内核提供了以下几个主要的中断流控函数的实现（只列出部分）： handle_simple_irq(); handle_level_irq(); 电平中断流控处理程序 handle_edge_irq(); 边沿触发中断流控处理程序 handle_fasteoi_irq(); 需要eoi的中断处理器使用的中断流控处理程序 handle_percpu_irq(); 该irq只有单个cpu响应时使用的流控处理程序 中断通用逻辑层：该层实现了对中断系统几个重要数据的管理，并提供了一系列的辅助管理函数。同时，该层还实现了中断线程的实现和管理，共享中断和嵌套中断的实现和管理，另外它还提供了一些接口函数，它们将作为硬件封装层和中断流控层以及驱动程序API层之间的桥梁，例如以下API： generic_handle_irq(); irq_to_desc(); irq_set_chip(); irq_set_chained_handler(); 驱动程序API：该部分向驱动程序提供了一系列的API，用于向系统申请/释放中断，打开/关闭中断，设置中断类型和中断唤醒系统的特性等操作。驱动程序的开发者通常只会使用到这一层提供的这些API即可完成驱动程序的开发工作，其他的细节都由另外几个软件层较好地“隐藏”起来了，驱动程序开发者无需再关注底层的实现，这看起来确实是一件美妙的事情，不过我认为，要想写出好的中断代码，还是花点时间了解一下其他几层的实现吧。其中的一些API如下： enable_irq(); disable_irq(); disable_irq_nosync(); request_threaded_irq(); irq_set_affinity(); irq描述结构：struct irq_desc整个通用中断子系统几乎都是围绕着irq_desc结构进行，系统中每一个irq都对应着一个irq_desc结构，所有的irq_desc结构的组织方式有两种： 基于数组方式：平台相关板级代码事先根据系统中的IRQ数量，定义常量：NR_IRQS，在kernel/irq/irqdesc.c中使用该常量定义irq_desc结构数组：1234567struct irq_desc irq_desc[NR_IRQS] __cacheline_aligned_in_smp = &#123; [0 ... NR_IRQS-1] = &#123; .handle_irq = handle_bad_irq, .depth = 1, .lock = __RAW_SPIN_LOCK_UNLOCKED(irq_desc-&gt;lock), &#125;&#125;; 基于基数树方式：当内核的配置项CONFIG_SPARSE_IRQ被选中时，内核使用基数树（radix tree）来管理irq_desc结构，这一方式可以动态地分配irq_desc结构，对于那些具备大量IRQ数量或者IRQ编号不连续的系统，使用该方式管理irq_desc对内存的节省有好处，而且对那些自带中断控制器管理设备自身多个中断源的外部设备，它们可以在驱动程序中动态地申请这些中断源所对应的irq_desc结构，而不必在系统的编译阶段保留irq_desc结构所需的内存。下面我们看一看irq_desc的部分定义：1234567891011121314struct irq_data &#123; unsigned int irq; unsigned long hwirq; unsigned int node; unsigned int state_use_accessors; struct irq_chip *chip; struct irq_domain *domain; void *handler_data; void *chip_data; struct msi_desc *msi_desc;#ifdef CONFIG_SMP cpumask_var_t affinity;#endif&#125;; 1234567891011121314151617181920212223242526struct irq_desc &#123; struct irq_data irq_data; unsigned int __percpu *kstat_irqs; irq_flow_handler_t handle_irq;#ifdef CONFIG_IRQ_PREFLOW_FASTEOI irq_preflow_handler_t preflow_handler;#endif struct irqaction *action; /* IRQ action list */ unsigned int status_use_accessors; unsigned int depth; /* nested irq disables */ unsigned int wake_depth; /* nested wake enables */ unsigned int irq_count; /* For detecting broken IRQs */ raw_spinlock_t lock; struct cpumask *percpu_enabled;#ifdef CONFIG_SMP const struct cpumask *affinity_hint; struct irq_affinity_notify *affinity_notify;#ifdef CONFIG_GENERIC_PENDING_IRQ cpumask_var_t pending_mask;#endif#endif wait_queue_head_t wait_for_threads; const char *name;&#125; ____cacheline_internodealigned_in_smp; 对于irq_desc中的主要字段做一个解释： irq_data 这个内嵌结构在2.6.37版本引入，之前的内核版本的做法是直接把这个结构中的字段直接放置在irq_desc结构体中，然后在调用硬件封装层的chip-&gt;xxx()回调中传入IRQ编号作为参数，但是底层的函数经常需要访问-&gt;handler_data，-&gt;chip_data，-&gt;msi_desc等字段，这需要利用irq_to_desc(irq)来获得irq_desc结构的指针，然后才能访问上述字段，者带来了性能的降低，尤其在配置为sparse irq的系统中更是如此，因为这意味着基数树的搜索操作。为了解决这一问题，内核开发者把几个低层函数需要使用的字段单独封装为一个结构，调用时的参数则改为传入该结构的指针。实现同样的目的，那为什么不直接传入irq_desc结构指针？因为这会破坏层次的封装性，我们不希望低层代码可以看到不应该看到的部分，仅此而已。 kstat_irqs 用于irq的一些统计信息，这些统计信息可以从proc文件系统中查询。 action 中断响应链表，当一个irq被触发时，内核会遍历该链表，调用action结构中的回调handler或者激活其中的中断线程，之所以实现为一个链表，是为了实现中断的共享，多个设备共享同一个irq，这在外围设备中是普遍存在的。 status_use_accessors 记录该irq的状态信息，内核提供了一系列irq_settings_xxx的辅助函数访问该字段，详细请查看kernel/irq/settings.h depth 用于管理enable_irq()/disable_irq()这两个API的嵌套深度管理，每次enable_irq时该值减去1，每次disable_irq时该值加1，只有depth==0时才真正向硬件封装层发出关闭irq的调用，只有depth==1时才会向硬件封装层发出打开irq的调用。disable的嵌套次数可以比enable的次数多，此时depth的值大于1，随着enable的不断调用，当depth的值为1时，在向硬件封装层发出打开irq的调用后，depth减去1后，此时depth为0，此时处于一个平衡状态，我们只能调用disable_irq，如果此时enable_irq被调用，内核会报告一个irq失衡的警告，提醒驱动程序的开发人员检查自己的代码。 lock 用于保护irq_desc结构本身的自旋锁。 affinity_hit 用于提示用户空间，作为优化irq和cpu之间的亲缘关系的依据。 pending_mask 用于调整irq在各个cpu之间的平衡。 wait_for_threads 用于synchronize_irq()，等待该irq所有线程完成。 irq_data结构中的各字段： irq 该结构所对应的IRQ编号。 hwirq 硬件irq编号，它不同于上面的irq； node 通常用于hwirq和irq之间的映射操作； state_use_accessors 硬件封装层需要使用的状态信息，不要直接访问该字段，内核定义了一组函数用于访问该字段：irqd_xxxx()，参见include/linux/irq.h。 chip 指向该irq所属的中断控制器的irq_chip结构指针 handler_data 每个irq的私有数据指针，该字段由硬件封转层使用，例如用作底层硬件的多路复用中断。 chip_data 中断控制器的私有数据，该字段由硬件封转层使用。 msi_desc 用于PCIe总线的MSI或MSI-X中断机制。 affinity 记录该irq与cpu之间的亲缘关系，它其实是一个bit-mask，每一个bit代表一个cpu，置位后代表该cpu可能处理该irq。 这是通用中断子系统系列文章的第一篇，这里不会详细介绍各个软件层次的实现原理，但是有必要对整个架构做简要的介绍： 系统启动阶段，取决于内核的配置，内核会通过数组或基数树分配好足够多的irq_desc结构； 根据不同的体系结构，初始化中断相关的硬件，尤其是中断控制器； 为每个必要irq的irq_desc结构填充默认的字段，例如irq编号，irq_chip指针，根据不同的中断类型配置流控handler； 设备驱动程序在初始化阶段，利用request_threaded_irq() api申请中断服务，两个重要的参数是handler和thread_fn； 当设备触发一个中断后，cpu会进入事先设定好的中断入口，它属于底层体系相关的代码，它通过中断控制器获得irq编号，在对irq_data结构中的某些字段进行处理后，会将控制权传递到中断流控层（通过irq_desc-&gt;handle_irq）； 中断流控处理代码在作出必要的流控处理后，通过irq_desc-&gt;action链表，取出驱动程序申请中断时注册的handler和thread_fn，根据它们的赋值情况，或者只是调用handler回调，或者启动一个线程执行thread_fn，又或者两者都执行； 至此，中断最终由驱动程序进行了响应和处理。 中断子系统的proc文件接口在/proc目录下面，有两个与中断子系统相关的文件和子目录，它们是： /proc/interrupts：文件 /proc/irq：子目录 读取interrupts会依次显示irq编号，每个cpu对该irq的处理次数，中断控制器的名字，irq的名字，以及驱动程序注册该irq时使用的名字，以下是一个例子： /proc/irq目录下面会为每个注册的irq创建一个以irq编号为名字的子目录，每个子目录下分别有以下条目： smp_affinity irq和cpu之间的亲缘绑定关系； smp_affinity_hint 只读条目，用于用户空间做irq平衡只用； spurious 可以获得该irq被处理和未被处理的次数的统计信息； handler_name 驱动程序注册该irq时传入的处理程序的名字； 根据irq的不同，以上条目不一定会全部都出现，以下是某个设备的例子：12345678910111213141516171819202122# cd /proc/irq# lsls332248............1211default_smp_affinity# ls 332bcmsdh_sdmmcspuriousnodeaffinity_hintsmp_affinity# cat 332/smp_affinity3 可见，以上设备是一个使用双核cpu的设备，因为smp_affinity的值是3，系统默认每个中断可以由两个cpu进行处理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信的方式——信号、管道、消息队列、共享内存]]></title>
    <url>%2F2019%2F05%2F08%2F%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84%E6%96%B9%E5%BC%8F-%E4%BF%A1%E5%8F%B7-%E7%AE%A1%E9%81%93-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[多进程首先，先来讲一下fork之后，发生了什么事情。 由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程id返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；也可以调用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。 fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。可以这样想象，2个进程一直同时运行，而且步调一致，在fork之后，他们分别作不同的工作，也就是分岔了。这也是fork为什么叫fork的原因 至于哪一个最先运行，可能与操作系统（调度算法）有关，而且这个问题在实际应用中并不重要，如果需要父子进程协同，可以通过原语的办法解决。 常见的通信方式： 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。 信号（sinal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 信号：信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，知道该进程恢复执行并传递给他为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。 Linux提供了几十种信号，分别代表着不同的意义。信号之间依靠他们的值来区分，但是通常在程序中使用信号的名字来表示一个信号。在Linux系统中，这些信号和以他们的名称命名的常量被定义在/usr/includebitssignum.h文件中。通常程序中直接包含&lt;signal.h&gt;就好。 信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式，信号可以在用户空间进程和内核之间直接交互。内核也可以利用信号来通知用户空间的进程来通知用户空间发生了哪些系统事件。信号事件有两个来源： 硬件来源，例如按下了cltr+C，通常产生中断信号sigint 软件来源，例如使用系统调用或者命令发出信号。最常用的发送信号的系统函数是kill,raise,setitimer,sigation,sigqueue函数。软件来源还包括一些非法运算等操作。 一旦有信号产生，用户进程对信号产生的相应有三种方式： 执行默认操作，linux对每种信号都规定了默认操作。 捕捉信号，定义信号处理函数，当信号发生时，执行相应的处理函数。 忽略信号，当不希望接收到的信号对进程的执行产生影响，而让进程继续执行时，可以忽略该信号，即不对信号进程作任何处理。 有两个信号是应用进程无法捕捉和忽略的，即SIGKILL和SEGSTOP，这是为了使系统管理员能在任何时候中断或结束某一特定的进程。 上图表示了Linux中常见的命令 信号发送：信号发送的关键使得系统知道向哪个进程发送信号以及发送什么信号。下面是信号操作中常用的函数： 例子：创建子进程，为了使子进程不在父进程发出信号前结束，子进程中使用raise函数发送sigstop信号，使自己暂停；父进程使用信号操作的kill函数，向子进程发送sigkill信号，子进程收到此信号，结束子进程。 信号处理当某个信号被发送到一个正在运行的进程时，该进程即对次特定的信号注册相应的信号处理函数，以完成所需处理。设置信号处理方式的是signal函数，在程序正常结束前，在应用signal函数恢复系统对信号的默认处理方式。 信号阻塞有时候既不希望进程在接收到信号时立刻中断进程的执行，也不希望此信号完全被忽略掉，而是希望延迟一段时间再去调用信号处理函数，这个时候就需要信号阻塞来完成。 例子：主程序阻塞了cltr+c的sigint信号。用sigpromask将sigint假如阻塞信号集合。 管道：管道允许在进程之间按先进先出的方式传送数据，是进程间通信的一种常见方式。 管道是Linux 支持的最初Unix IPC形式之一，具有以下特点： 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道； 匿名管道只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）； 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 管道分为pipe（无名管道）和fifo（命名管道）两种，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。 pipe用于相关进程之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将自动撤销。 FIFO即命名管道，在磁盘上有对应的节点，但没有数据块——换言之，只是拥有一个名字和相应的访问权限，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。 管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。 无名管道：pipe的例子：父进程创建管道，并在管道中写入数据，而子进程从管道读出数据 命名管道：和无名管道的主要区别在于，命名管道有一个名字，命名管道的名字对应于一个磁盘索引节点，有了这个文件名，任何进程有相应的权限都可以对它进行访问。 而无名管道却不同，进程只能访问自己或祖先创建的管道，而不能访任意访问已经存在的管道——因为没有名字。 Linux中通过系统调用mknod()或makefifo()来创建一个命名管道。最简单的方式是通过直接使用shell1mkfifo myfifo 等价于1mknod myfifo p 以上命令在当前目录下创建了一个名为myfifo的命名管道。用ls -p命令查看文件的类型时，可以看到命名管道对应的文件名后有一条竖线”|”，表示该文件不是普通文件而是命名管道。 使用open()函数通过文件名可以打开已经创建的命名管道，而无名管道不能由open来打开。当一个命名管道不再被任何进程打开时，它没有消失，还可以再次被打开，就像打开一个磁盘文件一样。 可以用删除普通文件的方法将其删除，实际删除的事磁盘上对应的节点信息。 例子：用命名管道实现聊天程序，一个张三端，一个李四端。两个程序都建立两个命名管道，fifo1,fifo2,张三写fifo1，李四读fifo1；李四写fifo2，张三读fifo2。 用select把管道描述符和stdin加入集合，用select进行阻塞，如果有i/o的时候唤醒进程。（粉红色部分为select部分，黄色部分为命名管道部分） 在linux系统中，除了用pipe系统调用建立管道外，还可以使用C函数库中管道函数popen函数来建立管道，使用pclose关闭管道。 例子：设计一个程序用popen创建管道，实现 ls -l |grep main.c的功能 分析：先用popen函数创建一个读管道，调用fread函数将ls -l的结果存入buf变量，用printf函数输出内容，用pclose关闭读管道； 接着用popen函数创建一个写管道，调用fprintf函数将buf的内容写入管道，运行grep命令。 popen的函数原型：1FILE* popen(const char* command,const char* type); 参数说明：command是子进程要执行的命令，type表示管道的类型，r表示读管道，w代表写管道。如果成功返回管道文件的指针，否则返回NULL。 使用popen函数读写管道，实际上也是调用pipe函数调用建立一个管道，再调用fork函数建立子进程，接着会建立一个shell 环境，并在这个shell环境中执行参数所指定的进程。 消息队列：消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。 消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。 可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。 消息队列的常用函数如下表： 进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。 例子：用函数msget创建消息队列，调用msgsnd函数，把输入的字符串添加到消息队列中，然后调用msgrcv函数，读取消息队列中的消息并打印输出，最后再调用msgctl函数，删除系统内核中的消息队列。（黄色部分是消息队列相关的关键代码，粉色部分是读取stdin的关键代码） 共享内存：共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。 采用共享内存进行通信的一个主要好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。 一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件，因此，采用共享内存的通信方式效率非常高。 共享内存有两种实现方式：1、内存映射 2、共享内存机制 内存映射内存映射 memory map机制使进程之间通过映射同一个普通文件实现共享内存，通过mmap()系统调用实现。普通文件被映射到进程地址空间后，进程可以 像访问普通内存一样对文件进行访问，不必再调用read/write等文件操作函数。 例子：创建子进程，父子进程通过匿名映射实现共享内存。 分析：主程序中先调用mmap映射内存，然后再调用fork函数创建进程。那么在调用fork函数之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap函数的返回地址，这样，父子进程就可以通过映射区域进行通信了。 UNIX System V共享内存机制IPC的共享内存指的是把所有的共享数据放在共享内存区域（IPC shared memory region），任何想要访问该数据的进程都必须在本进程的地址空间新增一块内存区域，用来映射存放共享数据的物理内存页面。 和前面的mmap系统调用通过映射一个普通文件实现共享内存不同，UNIX system V共享内存是通过映射特殊文件系统shm中的文件实现进程间的共享内存通信。 例子：设计两个程序，通过unix system v共享内存机制，一个程序写入共享区域，另一个程序读取共享区域。 分析：一个程序调用fotk函数产生标准的key，接着调用shmget函数，获取共享内存区域的id，调用shmat函数，映射内存，循环计算年龄，另一个程序读取共享内存。 （fotk函数在消息队列部分已经用过了，根据pathname指定的文件（或目录）名称，以及proj参数指定的数字，ftok函数为IPC对象生成一个唯一性的键值。）1key_t ftok(char* pathname,char proj)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[__attribute__二三事]]></title>
    <url>%2F2019%2F05%2F07%2Fc%E4%B8%ADattribute%E4%BA%8C%E4%B8%89%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[123static inline skew_heap_entry_t *skew_heap_insert( skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp) __attribute__((always_inline)); 这个函数是在做uCore的时候发现的，有一个特别的地方attribute((always_inline))，之前从来没见过，于是去查了一下，不查不知道，一查下一跳啊，这竟然是GUN C的一个从来没听过的属性。 当我们用__inline__ __attribute__((always_inline))修饰一个函数的时候,编译器会将我们的代码编译.在调用的地方将我们的函数,插入到调用的地方. attribute是GNU C特色之一,在iOS用的比较广泛.系统中有许多地方使用到. attribute可以设置函数属性（Function Attribute ）、变量属性（Variable Attribute ）和类型属性（Type Attribute)等. 函数属性(Function Attribute) noreturn noinline always_inline pure const nothrow sentinel format format_arg no_instrument_function section constructor destructor used unused deprecated weak malloc alias warn_unused_result nonnull 类型属性(Type Attributes) aligned packed transparent_union, unused, deprecated may_alias 变量属性(Variable Attribute) aligned packed Clang特有的 availability overloadable 书写格式书写格式：attribute后面会紧跟一对原括弧，括弧里面是相应的attribute参数1__attribute__(xxx) 常见的系统用法format1#define NS_FORMAT_FUNCTION(F,A) __attribute__((format(__NSString__, F, A))) format属性可以给被声明的函数加上类似printf或者scanf的特征，它可以使编译器检查函数声明和函数实际调用参数之间的格式化字符串是否匹配。该功能十分有用，尤其是处理一些很难发现的bug。对于format参数的使用如下format (archetype, string-index, first-to-check)第一参数需要传递“archetype”指定是哪种风格,这里是 NSString；“string-index”指定传入函数的第几个参数是格式化字符串；“first-to-check”指定第一个可变参数所在的索引. noreturn官方例子: abort() 和 exit() 该属性通知编译器函数从不返回值。当遇到类似函数还未运行到return语句就需要退出来的情况，该属性可以避免出现错误信息。 availability官方例子:12345678910111213- (CGSize)sizeWithFont:(UIFont *)font NS_DEPRECATED_IOS(2_0, 7_0, &quot;Use -sizeWithAttributes:&quot;) __TVOS_PROHIBITED; //来看一下 后边的宏 #define NS_DEPRECATED_IOS(_iosIntro, _iosDep, ...) CF_DEPRECATED_IOS(_iosIntro, _iosDep, __VA_ARGS__) define CF_DEPRECATED_IOS(_iosIntro, _iosDep, ...) __attribute__((availability(ios,introduced=_iosIntro,deprecated=_iosDep,message=&quot;&quot; __VA_ARGS__))) //宏展开以后如下__attribute__((availability(ios,introduced=2_0,deprecated=7_0,message=&quot;&quot;__VA_ARGS__)));//ios即是iOS平台//introduced 从哪个版本开始使用//deprecated 从哪个版本开始弃用//message 警告的消息 availability属性是一个以逗号为分隔的参数列表，以平台的名称开始，包含一些放在附加信息里的一些里程碑式的声明。 introduced：第一次出现的版本。 deprecated：声明要废弃的版本，意味着用户要迁移为其他API obsoleted： 声明移除的版本，意味着完全移除，再也不能使用它 unavailable：在这些平台不可用 message：一些关于废弃和移除的额外信息，clang发出警告的时候会提供这些信息，对用户使用替代的API非常有用。 这个属性支持的平台：ios，macosx。123456789//如果经常用,建议定义成类似系统的宏- (void)oldMethod:(NSString *)string __attribute__((availability(ios,introduced=2_0,deprecated=7_0,message=&quot;用 -newMethod: 这个方法替代 &quot;)))&#123; NSLog(@&quot;我是旧方法,不要调我&quot;);&#125; - (void)newMethod:(NSString *)string&#123; NSLog(@&quot;我是新方法&quot;);&#125; visibility语法:1__attribute__((visibility(&quot;visibility_type&quot;))) 其中，visibility_type 是下列值之一： default:假定的符号可见性可通过其他选项进行更改。缺省可见性将覆盖此类更改。缺省可见性与外部链接对应。 hidden:该符号不存放在动态符号表中，因此，其他可执行文件或共享库都无法直接引用它。使用函数指针可进行间接引用。 internal:除非由特定于处理器的应用二进制接口 (psABI) 指定，否则，内部可见性意味着不允许从另一模块调用该函数。 protected:该符号存放在动态符号表中，但定义模块内的引用将与局部符号绑定。也就是说，另一模块无法覆盖该符号。 除指定 default 可见性外，此属性都可与在这些情况下具有外部链接的声明结合使用。您可在 C 和 C++ 中使用此属性。在 C++ 中，还可将它应用于类型、成员函数和命名空间声明。 系统用法:123456// UIKIT_EXTERN extern #ifdef __cplusplus #define UIKIT_EXTERN extern &quot;C&quot; __attribute__((visibility (&quot;default&quot;))) #else #define UIKIT_EXTERN extern __attribute__((visibility (&quot;default&quot;))) #endif nonnull编译器对函数参数进行NULL的检查,参数类型必须是指针类型(包括对象)1234567- (int)addNum1:(int *)num1 num2:(int *)num2 __attribute__((nonnull (1,2)))&#123;//1,2表示第一个和第二个参数不能为空 return *num1 + *num2;&#125; - (NSString *)getHost:(NSURL *)url __attribute__((nonnull (1)))&#123;//第一个参数不能为空 return url.host;&#125; 常见用法aligned__attribute((aligned (n)))，让所作用的结构成员对齐在n字节自然边界上。如果结构中有成员的长度大于n，则按照最大成员的长度来对齐.例如: 不加修饰的情况123456typedef struct&#123; char member1; int member2; short member3;&#125;Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:45.380 Study[917:436064] Family size is 12 修改字节对齐为1123456typedef struct&#123; char member1; int member2; short member3;&#125;__attribute__ ((aligned (1))) Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:05.315 Study[914:435764] Family size is 12 和上面的结果一致,因为设定的字节对齐为1.而结构体中成员的最大字节数是int 4个字节,1 &lt; 4,按照4字节对齐,和系统默认一致. 修改字节对齐为8123456typedef struct&#123; char member1; int member2; short member3;&#125;__attribute__ ((aligned (8))) Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:05.315 Study[914:435764] Family size is 16 这里 8 &gt; 4,按照8字节对齐,结果为16。 可是想了半天,也不知道这玩意有什么用,设定值小于系统默认的,和没设定一样,设定大了,又浪费空间,效率也没提高,感觉学习学习就好. packed让指定的结构结构体按照一字节对齐,测试:1234567//不加packed修饰typedef struct &#123; char version; int16_t sid; int32_t len; int64_t time;&#125; Header; 计算长度:1NSLog(@&quot;size is %zd&quot;,sizeof(Header)); 输出结果为:12016-07-22 11:53:47.728 Study[14378:5523450] size is 16 可以看出,默认系统是按照4字节对齐1234567//加packed修饰typedef struct &#123; char version; int16_t sid; int32_t len; int64_t time;&#125;__attribute__ ((packed)) Header; 计算长度1NSLog(@&quot;size is %zd&quot;,sizeof(Header)); 输出结果为:12016-07-22 11:57:46.970 Study[14382:5524502] size is 15 用packed修饰后,变为1字节对齐,这个常用于与协议有关的网络传输中. noinline &amp; always_inline内联函数:内联函数从源代码层看，有函数的结构，而在编译后，却不具备函数的性质。内联函数不是在调用时发生控制转移，而是在编译时将函数体嵌入在每一个调用处。编译时，类似宏替换，使用函数体替换调用处的函数名。一般在代码中用inline修饰，但是能否形成内联函数，需要看编译器对该函数定义的具体处理 noinline 不内联always_inline 总是内联这两个都是用在函数上内联的本质是用代码块直接替换掉函数调用处,好处是:快代码的执行，减少系统开销. 适用场景:这个函数更小这个函数不被经常调用 使用例子:12//函数声明void test(int a) __attribute__((always_inline)); warn_unused_result当函数或者方法的返回值很重要时,要求调用者必须检查或者使用返回值,否则编译器会发出警告提示1234 - (BOOL)availiable __attribute__((warn_unused_result))&#123; return 10;&#125; constructor / destructor意思是: 构造器和析构器;constructor修饰的函数会在main函数之前执行,destructor修饰的函数会在程序exit前调用.示例如下:1234567891011121314151617181920212223int main(int argc, char * argv[]) &#123; @autoreleasepool &#123; NSLog(@&quot;main&quot;); return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class])); &#125;&#125; __attribute__((constructor))void before()&#123; NSLog(@&quot;before main&quot;);&#125; __attribute__((destructor))void after()&#123; NSLog(@&quot;after main&quot;);&#125; //在viewController中调用exit- (void)viewDidLoad &#123; [super viewDidLoad]; exit(0);&#125; 输出如下:1232016-07-21 21:49:17.446 Study[14162:5415982] before main2016-07-21 21:49:17.447 Study[14162:5415982] main2016-07-21 21:49:17.534 Study[14162:5415982] after main 注意点: 程序退出的时候才会调用after函数,经测试,手动退出程序会执行 上面两个函数不管写在哪个类里,哪个文件中效果都一样 如果存在多个修饰的函数,那么都会执行,顺序不定 实际上如果存在多个修饰过的函数,可以它们的调整优先级 代码如下:123456789101112131415161718192021222324int main(int argc, char * argv[]) &#123; @autoreleasepool &#123; NSLog(@&quot;main&quot;); return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class])); &#125;&#125; __attribute__((constructor(101)))void before1()&#123; NSLog(@&quot;before main - 1&quot;);&#125;__attribute__((constructor(102)))void before2()&#123; NSLog(@&quot;before main - 2&quot;);&#125; __attribute__((destructor(201)))void after1()&#123; NSLog(@&quot;after main - 1&quot;);&#125;__attribute__((destructor(202)))void after2()&#123; NSLog(@&quot;after main - 2&quot;);&#125; 输出结果如下:123452016-07-21 21:59:35.622 Study[14171:5418393] before main - 12016-07-21 21:59:35.624 Study[14171:5418393] before main - 22016-07-21 21:59:35.624 Study[14171:5418393] main2016-07-21 21:59:35.704 Study[14171:5418393] after main - 22016-07-21 21:59:35.704 Study[14171:5418393] after main - 1 注意点: 括号内的值表示优先级,[0,100]这个返回时系统保留的,自己千万别调用. 根据输出结果可以看出,main函数之前的,数值越小,越先调用;main函数之后的数值越大,越先调用. 当函数声明和函数实现分开写时,格式如下:12345static void before() __attribute__((constructor)); static void before() &#123; printf(&quot;before\n&quot;);&#125; 讨论:+load,constructor,main的执行顺序,代码如下:1234567+ (void)load&#123; NSLog(@&quot;load&quot;);&#125;__attribute__((constructor))void before()&#123; NSLog(@&quot;before main&quot;);&#125; 输出结果如下:1232016-07-21 22:13:58.591 Study[14185:5421811] load2016-07-21 22:13:58.592 Study[14185:5421811] before main2016-07-21 22:13:58.592 Study[14185:5421811] main 可以看出执行顺序为:load-&gt;constructor-&gt;main为什么呢?因为 dyld（动态链接器，程序的最初起点）在加载 image（可以理解成 Mach-O 文件）时会先通知 objc runtime 去加载其中所有的类，每加载一个类时，它的 +load 随之调用，全部加载完成后，dyld 才会调用这个 image 中所有的 constructor 方法,然后才调用main函数. enable_if用来检查参数是否合法,只能用来修饰函数:12345void printAge(int age)__attribute__((enable_if(age &gt; 0 &amp;&amp; age &lt; 120, &quot;你丫太监?&quot;)))&#123; NSLog(@&quot;%d&quot;,age);&#125; 表示只能输入的参数只能是 0 ~ 120左右,否则编译报错.]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode122. Best Time to Buy and Sell Stock II]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode121-Best-Time-to-Buy-and-Sell-Stock-II%2F</url>
    <content type="text"><![CDATA[Say you have an array for which the ith element is the price of a given stock on day i. Design an algorithm to find the maximum profit. You may complete as many transactions as you like (i.e., buy one and sell one share of the stock multiple times). Note: You may not engage in multiple transactions at the same time (i.e., you must sell the stock before you buy again). Example 1:12Input: [7,1,5,3,6,4]Output: 7 Explanation: Buy on day 2 (price = 1) and sell on day 3 (price = 5), profit = 5-1 = 4. Then buy on day 4 (price = 3) and sell on day 5 (price = 6), profit = 6-3 = 3.Example 2:12Input: [1,2,3,4,5]Output: 4 Explanation: Buy on day 1 (price = 1) and sell on day 5 (price = 5), profit = 5-1 = 4. Note that you cannot buy on day 1, buy on day 2 and sell them later, as you are engaging multiple transactions at the same time. You must sell before buying again.Example 3:12Input: [7,6,4,3,1]Output: 0 Explanation: In this case, no transaction is done, i.e. max profit = 0. 123456789101112131415161718192021class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; /* if(prices.size() &lt;= 1) return 0; int buy = -prices[0], sell = 0; for(int i = 1; i &lt; prices.size(); i++) &#123; sell = max(sell, prices[i] + buy); buy = max( buy,sell - prices[i]); &#125; return sell; */ if(prices.size() &lt;= 1) return 0; int total = 0; for (int i=0; i&lt; prices.size()-1; i++) &#123; if (prices[i+1]&gt;prices[i]) total += prices[i+1]-prices[i]; &#125; return total; &#125;&#125;; 上边是两种方法。 转移方程 对比之前的题，这里可以有无限次的买入和卖出，也就是说 买入 状态之前可拥有 卖出 状态，所以买入的转移方程需要变化。 buy = max(buy, sell - price[i])sell = max(sell, buy + prices[i] )边界 第一天 buy = -prices[0], sell = 0，最后返回 sell 即可。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode121. Best Time to Buy and Sell Stock]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode121-Best-Time-to-Buy-and-Sell-Stock%2F</url>
    <content type="text"><![CDATA[Best Time to Buy and Sell Stock Say you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1:12Input: [7,1,5,3,6,4]Output: 5 Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price.Example 2:12Input: [7,6,4,3,1]Output: 0 Explanation: In this case, no transaction is done, i.e. max profit = 0. 我们按照动态规划的思想来思考这道问题。 状态有 买入（buy） 和 卖出（sell） 这两种状态。 转移方程对于买来说，买之后可以卖出（进入卖状态），也可以不再进行股票交易（保持买状态）。 对于卖来说，卖出股票后不在进行股票交易（还在卖状态）。 只有在手上的钱才算钱，手上的钱购买当天的股票后相当于亏损。也就是说当天买的话意味着损失-prices[i]，当天卖的话意味着增加prices[i]，当天卖出总的收益就是 buy+prices[i] 。 所以我们只要考虑当天买和之前买哪个收益更高，当天卖和之前卖哪个收益更高。 buy = max(buy, -price[i]) （注意：根据定义 buy 是负数）sell = max(sell, prices[i] + buy)边界 第一天 buy = -prices[0], sell = 0，最后返回 sell 即可。 12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size()&lt;=1) return 0; int buy = prices[0],sell=0; for(int i=1;i&lt;prices.size();i++)&#123; buy = min(prices[i],buy); sell = max(sell,prices[i]-buy); &#125; return sell; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cannon算法的原理实现以及性能评测]]></title>
    <url>%2F2019%2F05%2F06%2FCannon%E7%AE%97%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[简介 算法流程图 算法设计方法和模式任务划分：根据矩阵乘法公式中的累加计算的可分离性，将参与计算的两个矩阵分解成p个小矩阵块(共有p个计算节点)，每个节点只进行局部的小矩阵乘法，最终计算结束后将局部的小结果矩阵发送回Master节点。 通讯分析：由于算法在下发任务和收集结果的时候采用了主从模式，所以使用了Master-Worker的全局通讯，该部分通讯由于发送方只有一个0号线程，所以无法并行执行，只能串行执行。同时，在迭代进行小矩阵运算时，各计算节点之间也需要交换矩阵，进行了结构化通讯。该部分通讯由于通讯的局部特性，可以并行执行，能够提高效率。 任务组合：每个节点负责一个小矩阵的串行计算，同时负责小矩阵之间的通讯传递。 处理器映射：由于任务的划分个数等于处理器个数，所以在组合任务的同时完成了处理器映射。 Cannon算法采用了主从模式的同时也采用了分而治之的模式。一方面，0号线程作为Master，负责矩阵A和矩阵B以及矩阵C的I/O，也负责小矩阵的分发和结果的聚集。而其他节点作为Worker进行本地的小矩阵串行乘法计算。另一方面，Cannon算法将两个大矩阵的乘法运算分解为若干各小矩阵的乘法运算，最终计算结束后，将计算结果聚集回来，也采用了分而治之的思想。cannon算法不仅实现了矩阵乘法运算的并行化，也减少了分块矩阵乘法的局部存储量，节省了节点的内存开销。 算法复杂度设计算的是一个nn的矩阵乘一个nn的矩阵，共有p个节点，那么Cannon算法的时间复杂度计算如下： 矩阵乘加的时间由于采用了并行化，所以所需时间为： n^3 / p 若不考虑节点延迟时间，设节点之间通讯的启动时间为ti，传输每个数字的时间为tw，则在两个节点间传输一个子矩阵的时间是：ti + n^2*tw / p 所以节点之间传输子矩阵所需的时间为：2*sqrt(p)*(ti + n^2*tw / p) 综上，cannon算法总的所需时间为：2*sqrt(p)*(ti + n^2*tw / p) + n^3 / p 时间复杂度：O(n^3 / p)空间复杂度：O(n^2) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468#include&lt;stdio.h&gt;#include&lt;malloc.h&gt;#include&lt;stdlib.h&gt;#include&lt;mpi.h&gt;#include&lt;pthread.h&gt;#include&lt;math.h&gt;#include&lt;cstring&gt;int myrank, p;// Compute C = A*B. A is a n1*n2 matrix. B is a n2*n3 matrix.void matmul(double* A, double* B, double* C, int n1, int n2, int n3)//做矩阵乘法，结果累加到C矩阵中(需要保证C矩阵初始化过)&#123; int i,j,k; //简单的串行矩阵乘法 for (i = 0; i &lt; n1; i++) &#123; for (j = 0; j &lt; n3; j++) &#123; for (k = 0; k &lt; n2; k++) &#123; C[i*n3+j]+=A[i*n2+k]*B[k*n3+j]; &#125; &#125; &#125; &#125;int setup(int argc,char**argv,double** fstreama,double** fstreamb,int* dim)&#123; FILE* fha; FILE* fhb; int n1,n2,n3; int re=1; if (!(fha = fopen(argv[1], &quot;r&quot;))) //打开存储A矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[1], 1);//打开失败输出信息 return -1; &#125; if(fread(&amp;n1,sizeof(int),1,fha)==0)//读取矩阵的行数 &#123; printf(&quot;fread error1!\n&quot;); return -1; &#125; if(fread(&amp;n2,sizeof(int),1,fha)==0)//读取矩阵的列数 &#123; printf(&quot;fread error2!\n&quot;); return -1; &#125; *fstreama = (double *) malloc (n1*n2*sizeof(double));//为矩阵申请内存 if(fread(*fstreama,sizeof(double),n1*n2,fha)==0)//读取矩阵内容 &#123; printf(&quot;fread error3!\n&quot;); return -1; &#125; fclose(fha);//关闭矩阵文件 if (!(fhb = fopen(argv[2], &quot;r&quot;))) //打开存储A矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[2], 2);//打开失败输出信息 return -1; &#125; if(fread(&amp;n2,sizeof(int),1,fhb)==0)//读取矩阵的行数 &#123; printf(&quot;fread error4!\n&quot;); return -1; &#125; if(fread(&amp;n3,sizeof(int),1,fhb)==0)//读取矩阵的列数 &#123; printf(&quot;fread error5!\n&quot;); return -1; &#125; *fstreamb = (double *) malloc (n2*n3*sizeof(double));//为矩阵申请内存 if(fread(*fstreamb,sizeof(double),n2*n3,fhb)==0)//读取矩阵内容 &#123; printf(&quot;fread error6!\n&quot;); return -1; &#125; fclose(fhb);//关闭矩阵文件 dim[0] = n1;//返回矩阵的大小参数 dim[1] = n2;//返回矩阵的大小参数 dim[2] = n3;//返回矩阵的大小参数 return 0;&#125;void scatter_matrix(double* matrixbuf, int rows, int cols, double* local_matrix, int rootp)//将矩阵划分为小矩阵块并分发到各个节点&#123; int row, column, i, j, count; int maxrows_block = (rows + rootp - 1)/rootp;//小A矩阵块行数的最大值 int maxcols_block = (cols + rootp - 1)/rootp;//小矩阵块列数的最大值 double * matrixbuf2 = NULL;//用来格式化原矩阵的缓冲区 MPI_Status status;//返回通信的状态 if(myrank == 0)//0号线程 &#123; if(!(matrixbuf2 = (double *)malloc(maxcols_block*maxrows_block*rootp*rootp*sizeof(double))))//为缓冲区申请内存 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //将矩阵转化为按块连续存放的形式，方便分发每块小矩阵，同时对于边界没有对齐的小矩阵，补零对齐，方便计算 count = 0; for (i = 0; i &lt; rootp; i++)&#123; for (j = 0; j &lt; rootp; j++)&#123; if(i!=(rootp-1)&amp;&amp;j==(rootp-1))//特殊处理除了最后一行以外的最后一列 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if((j * maxcols_block + column)&gt;=cols)//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row ) * cols +j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else if(i==(rootp-1)&amp;&amp;j!=(rootp-1))//特殊处理除了最后一列以外的最后一行 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if((i * maxrows_block + row)&gt;=rows)//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row)*cols + j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else if(i==(rootp-1)&amp;&amp;j==(rootp-1))//特殊处理最后一列最后一行的那个块 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if(((j * maxcols_block + column)&gt;=cols) || ((i * maxrows_block + row)&gt;=rows))//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row) * cols + j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else&#123;//普通的块 for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row)*cols + j * maxcols_block + column]; count++; &#125; &#125; &#125; &#125; &#125; if(count!=maxcols_block*maxrows_block*rootp*rootp)//检查是否出错 &#123; printf(&quot;scatter_matrix error!\n&quot;); return ; &#125; //将属于本地的那个块留下来 for(i = 0; i &lt; maxrows_block*maxcols_block; i++) &#123; local_matrix[i] = matrixbuf2[i]; &#125; //分发其他块到对应的线程 for(i = 1; i &lt; rootp*rootp; i++) &#123; MPI_Send((matrixbuf2 + (i * maxcols_block * maxrows_block)), maxcols_block * maxrows_block, MPI_DOUBLE, i, 0, MPI_COMM_WORLD); &#125; &#125; else &#123;//非0号线程 MPI_Recv(local_matrix, maxcols_block * maxrows_block , MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status);//非零线程接受0线程发送的小矩阵块 &#125; if(matrixbuf2!=NULL)&#123;//释放缓冲区 free(matrixbuf2); &#125; return;&#125;//A and bufA : n1_block*n2_block; B and bufB : n2_block*n3_block//进行cannon算法，各个节点在本地进行矩阵乘法，并交换矩阵块，进行循环，直到计算完毕void cannon(double* A, double* bufA, double* B, double* bufB, double* C, int n1_block, int n2_block, int n3_block, int rootp)&#123; MPI_Request send_a_req, send_b_req; MPI_Status send_a_status, send_b_status, recv_a_status, recv_b_status; int cycle_count; int rank_next_a,rank_next_b; int rank_last_a,rank_last_b; int curRowP,curColP,i,j; int tag=0;//表示当前正确数据再A中还是bufA中，0表示在A中，1表示在bufA中 //先初始化各个块，即A_ij循环左移i步，B_ij循环上移j步，C_ij初始化为零 //初始化矩阵C，值全部设为0 for(i=0;i&lt;n1_block;i++) &#123; for(j=0;j&lt;n3_block;j++) &#123; C[i*n3_block+j] = 0; &#125; &#125; //循环传播小矩阵 curRowP = myrank/rootp;//当前节点所在行 curColP = myrank%rootp;//当前节点所在列 //获得左移i步后的节点号 if((curColP-curRowP)&lt;0) &#123; rank_next_a = myrank+rootp-curRowP; &#125;else&#123; rank_next_a = myrank-curRowP; &#125; //获得上移j步后的节点号 if((curRowP-curColP)&lt;0) &#123; rank_next_b = myrank -curColP*rootp + rootp*rootp; &#125;else&#123; rank_next_b = myrank -curColP*rootp; &#125; //获得接受左移i步的节点号 if((curColP+curRowP)&gt;=rootp) &#123; rank_last_a = myrank+curRowP-rootp; &#125;else&#123; rank_last_a = myrank+curRowP; &#125; //获得接受上移j步的节点号 if((curRowP+curColP)&gt;=rootp) &#123; rank_last_b = myrank + curColP*rootp - rootp*rootp; &#125;else&#123; rank_last_b = myrank + curColP*rootp; &#125; //非阻塞发送矩阵，如果不需要移动，则直接本地memcpy if(rank_next_a!=myrank) &#123; MPI_Isend(A, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 &#125;else &#123; memcpy(bufA, A, n1_block*n2_block*sizeof(double));//本地直接memcpy &#125; if(rank_next_b!=myrank) &#123; MPI_Isend(B, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 &#125;else &#123; memcpy(bufB, B, n2_block*n3_block*sizeof(double));//本地直接memcpy &#125; //阻塞接受矩阵 if(rank_last_a!=myrank) &#123; MPI_Recv(bufA, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A &#125; if(rank_last_b!=myrank) &#123; MPI_Recv(bufB, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B &#125; //阻塞等待发送矩阵结束 if(rank_next_a!=myrank) &#123; MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 &#125; if(rank_next_b!=myrank) &#123; MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 &#125; MPI_Barrier(MPI_COMM_WORLD);//同步 tag=1; if(myrank%rootp==0)//第一列的节点 &#123; rank_next_a = myrank+rootp-1; &#125;else&#123; rank_next_a = myrank-1; &#125; if(myrank/rootp==0)//第一行的节点 &#123; rank_next_b = myrank+rootp*(rootp-1); &#125;else&#123; rank_next_b = myrank - rootp; &#125; if(myrank%rootp==(rootp-1))//最后一列的节点 &#123; rank_last_a = myrank-rootp+1; &#125;else&#123; rank_last_a = myrank+1; &#125; if(myrank/rootp==(rootp-1))//最后一行的节点 &#123; rank_last_b = myrank-rootp*(rootp-1); &#125;else&#123; rank_last_b = myrank + rootp; &#125; //循环，每次做当前块的乘加运算，并使得A_ij循环左移1步，B_ij循环上移1步 for(cycle_count = 0; cycle_count &lt; rootp; cycle_count++) &#123; if(tag==1)//数据在bufA中 &#123; matmul(bufA, bufB, C, n1_block, n2_block, n3_block);//做当前节点的矩阵乘法 //循环传播小矩阵 MPI_Isend(bufA, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 MPI_Isend(bufB, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 MPI_Recv(A, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A MPI_Recv(B, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 tag = 0; &#125;else&#123;//数据在A中 matmul(A, B, C, n1_block, n2_block, n3_block);//做当前节点的矩阵乘法 //循环传播小矩阵 MPI_Isend(A, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 MPI_Isend(B, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 MPI_Recv(bufA, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A MPI_Recv(bufB, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 tag = 1; &#125; MPI_Barrier(MPI_COMM_WORLD);//同步 &#125; return;&#125;//gather_matrix((double*)(fstreamc + sizeof(int)*2), n1, n3, C, rootp);//将各个节点的小矩阵C收集到0号节点void gather_matrix(double* matrixCbuf, int rows, int cols, double* local_C, int rootp, int rows_block_pad, int cols_block_pad)&#123; int curRow, curCol, i, j, curP; MPI_Status status; double * matrixC_pad = NULL;//有零填充的矩阵C if(myrank == 0) &#123;//0号线程 if(!(matrixC_pad = (double *)malloc(rows_block_pad*cols_block_pad*rootp*rootp*sizeof(double))))//为缓冲区申请内存 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //将本地计算结果直接复制过来 for(i = 0; i &lt; rows_block_pad * cols_block_pad; i++)&#123; matrixC_pad[i] = local_C[i]; &#125; //接受其他非0线程的计算结果 for(i = 1; i &lt; rootp*rootp; i++)&#123; MPI_Recv(matrixC_pad + (i * rows_block_pad * cols_block_pad), rows_block_pad * cols_block_pad, MPI_DOUBLE, i, 0,MPI_COMM_WORLD, &amp;status); &#125; //重新整理矩阵C，除去零填充，并且重新整理顺序 for(i=0;i&lt;rows;i++) &#123; for(j=0;j&lt;cols;j++) &#123; curP = (i/rows_block_pad)*rootp+(j/cols_block_pad);//属于第几个节点，从0开始 curRow = i%rows_block_pad;//属于小矩阵的第几行 curCol = j%cols_block_pad;//属于小矩真的第几列 matrixCbuf[i * cols + j] = matrixC_pad[curP * rows_block_pad * cols_block_pad +curRow*cols_block_pad+curCol]; &#125; &#125; &#125; else &#123;//非0号线程 MPI_Send(local_C,rows_block_pad * cols_block_pad, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);//给0号线程发送计算结果 &#125; if(matrixC_pad!=NULL) &#123; free(matrixC_pad);//释放缓冲区 &#125; return ;&#125;int main(int argc, char** argv)&#123; double elapsed_time; // Suppose A:n1xn2, B:n2xn3. n1~n3 are read from input files int n1, n2, n3,rootp; // Buffers for matrix A, B, C. Because A, B will be shifted, so they each have two buffers double *A, *B, *C, *bufA, *bufB; // On proc 0, buffers to cache matrix files of A, B and C double *fstreama, *fstreamb; char *fstreamc; MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); MPI_Comm_size(MPI_COMM_WORLD, &amp;p); rootp = sqrt(p); if (p != rootp*rootp) &#123; printf(&quot;Processor number must be a square!\n&quot;); &#125; // On proc 0, preprocess the command line, read in files for A, B and // put their sizes in dim[]. int dim[3]; if (myrank == 0) &#123;//0号线程负责从文件中读取矩阵A和B以及他们的大小信息 if (setup(argc, argv, &amp;fstreama, &amp;fstreamb, dim)!=0) &#123; MPI_Finalize(); // Something error during preprocessing exit(-1); &#125; &#125; MPI_Bcast(dim, 3, MPI_INT, 0, MPI_COMM_WORLD);//0号线程将A和B矩阵的size广播给所有线程 n1 = dim[0];//A： n1*n2 n2 = dim[1];//B: n2*n3 n3 = dim[2]; // Allocate memories for A, B, C, bufA and bufB. // Suppose an m*n matrix is 2D block-distributed on a rootp*rootp processor grid. // If rootp doesn&apos;t divide m or n, then submatrixes won&apos;t have the same size. // Because we will shift A, B, so we allocate memories according to the max // rows and cols of A and B. //因为有可能rootp不能整除n1,n2,n3,所以在申请内存的时候考虑最大的块的大小 int maxrows_a = (n1 + rootp - 1)/rootp;//A矩阵块行数的最大值 int maxcols_a = (n2 + rootp - 1)/rootp;//A矩阵块列数的最大值 int maxrows_b = maxcols_a;//B矩阵块行数的最大值 int maxcols_b = (n3 + rootp - 1)/rootp;//B矩阵块列数的最大值 int bufA_size = sizeof(double)*maxrows_a*maxcols_a;//大小为一个A矩阵块的大小 int bufB_size = sizeof(double)*maxrows_b*maxcols_b;//大小为一个B矩阵块的大小 int bufC_size = sizeof(double)*maxrows_a*maxcols_b;//大小为一个C矩阵块的大小 char* buf; int i; if(!(buf = (char *)malloc(bufA_size*2 + bufB_size*2 + bufC_size)))//申请两个A矩阵块，两个B矩阵块，和一个C矩阵块 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //或者以下4个缓存区的指针位置 A = (double*)buf; bufA = (double*) (buf + bufA_size); B = (double*) (buf + bufA_size*2); bufB = (double*) (buf + bufA_size*2 + bufB_size); C = (double*) (buf + bufA_size*2 + bufB_size*2); // Proc 0 scatters A, B to other procs in a 2D block distribution fashion scatter_matrix((double*)fstreama, n1, n2, A, rootp);//0号线程分发A矩阵块到各个线程 MPI_Barrier(MPI_COMM_WORLD);//同步 scatter_matrix((double*)fstreamb, n2, n3, B, rootp);//0号线程分发B矩阵块到各个线程 MPI_Barrier(MPI_COMM_WORLD);//同步 elapsed_time = MPI_Wtime();//记录计算开始的时间戳 // Compute C=A*B by Cannon algorithm cannon(A, bufA, B, bufB, C, maxrows_a,maxcols_a,maxcols_b, rootp); MPI_Barrier(MPI_COMM_WORLD);//同步 elapsed_time = MPI_Wtime() - elapsed_time;//记录计算所用的时间 // Proc 0 gathers C from other procs and write it out FILE* fhc; int fsizec = sizeof(int)*2 + sizeof(double)*n1*n3;//存储C矩阵以及两个大小参数的空间大小 if(myrank == 0) &#123; if (!(fhc = fopen(argv[3], &quot;w&quot;))) //打开输出C矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[3], 3);//打开失败输出信息 MPI_Finalize(); &#125; fstreamc = (char *)malloc(fsizec);//申请存储矩阵C的内存空间 ((int*)fstreamc)[0] = n1;//记录矩阵C的行数 ((int*)fstreamc)[1] = n3;//记录矩阵C的列数 &#125; gather_matrix((double*)(fstreamc + sizeof(int)*2), n1, n3, C, rootp, maxrows_a, maxcols_b);//聚集计算结果，其他线程将自己的C矩阵块发送给线程0 MPI_Barrier(MPI_COMM_WORLD); // Make sure proc 0 read all it needs if(myrank == 0) &#123; printf(&quot;Cannon algrithm: multiply a %dx%d with a %dx%d, use %.2f(s)\n&quot;,n1, n2, n2, n3, elapsed_time); fwrite(fstreamc, sizeof(char), fsizec, fhc);//线程0将矩阵C写入文件 fclose(fhc);//关闭文件 free(fstreama);//释放内存 free(fstreamb);//释放内存 free(fstreamc);//释放内存 &#125; free(buf);//释放存储小矩阵块的内存空间 MPI_Finalize(); return 0;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode933. Number of Recent Calls]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode933-Number-of-Recent-Calls%2F</url>
    <content type="text"><![CDATA[Write a class RecentCounter to count recent requests. It has only one method: ping(int t), where t represents some time in milliseconds. Return the number of pings that have been made from 3000 milliseconds ago until now. Any ping with time in [t - 3000, t] will count, including the current ping. It is guaranteed that every call to ping uses a strictly larger value of t than before. Example 1: Input: inputs = [“RecentCounter”,”ping”,”ping”,”ping”,”ping”], inputs = [[],[1],[100],[3001],[3002]]Output: [null,1,2,3,3] Note: Each test case will have at most 10000 calls to ping.Each test case will call ping with strictly increasing values of t.Each call to ping will have 1 &lt;= t &lt;= 10^9. 行吧，我是没看懂这个题是什么意思。。。只是判断t和3000的关系。1234567891011121314151617181920class RecentCounter &#123;public: queue&lt;int&gt; q; RecentCounter() &#123; &#125; int ping(int t) &#123; q.push(t); while(q.front()&lt;t-3000) q.pop(); return q.size(); &#125;&#125;;/** * Your RecentCounter object will be instantiated and called as such: * RecentCounter* obj = new RecentCounter(); * int param_1 = obj-&gt;ping(t); */]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode69. Sqrt(x)]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode69-Sqrtx%2F</url>
    <content type="text"><![CDATA[Implement int sqrt(int x). Compute and return the square root of x, where x is guaranteed to be a non-negative integer. Since the return type is an integer, the decimal digits are truncated and only the integer part of the result is returned. Example 1: Input: 4Output: 2Example 2: Input: 8Output: 2Explanation: The square root of 8 is 2.82842…, and since the decimal part is truncated, 2 is returned. 二分求一个数的开方，做的恶心，垃圾题，浪费时间。123456789101112131415class Solution &#123;public: int mySqrt(int x) &#123; int low = 0, high = x, mid; if(x&lt;2) return x; // to avoid mid = 0 while(low&lt;high) &#123; mid = (low + high)/2; if(x/mid &gt;= mid) low = mid+1; else high = mid; &#125; return high-1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode852. Peak Index in a Mountain Array]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode852-Peak-Index-in-a-Mountain-Array%2F</url>
    <content type="text"><![CDATA[Let’s call an array A a mountain if the following properties hold: A.length &gt;= 3There exists some 0 &lt; i &lt; A.length - 1 such that A[0] &lt; A[1] &lt; … A[i-1] &lt; A[i] &gt; A[i+1] &gt; … &gt; A[A.length - 1]Given an array that is definitely a mountain, return any i such that A[0] &lt; A[1] &lt; … A[i-1] &lt; A[i] &gt; A[i+1] &gt; … &gt; A[A.length - 1]. Example 1:12Input: [0,1,0]Output: 1 Example 2:12Input: [0,2,1,0]Output: 1 Note: 3 &lt;= A.length &lt;= 100000 &lt;= A[i] &lt;= 10^6A is a mountain, as defined above. 判断一个“山峰”数组的山峰在哪里，本来以为还要判断这个是不是山峰数组的，所以多写了一些，对结果没影响，懒得删了。 123456789101112131415161718192021class Solution &#123;public: int peakIndexInMountainArray(vector&lt;int&gt;&amp; A) &#123; int res; bool isreal=false; if(A.size()&lt;3) return false; for(int i=1;i&lt;A.size();i++)&#123; if(A[i]&gt;A[i-1]) if(!isreal) continue; if(A[i]&lt;A[i-1])&#123; if(!isreal)&#123; res=i-1; isreal=true; &#125; &#125; &#125; return res; &#125;&#125;; 我这个做法不好，可以用二分查找。123456789101112class Solution &#123; public int peakIndexInMountainArray(int[] A) &#123; int lo = 0, hi = A.length - 1; while (lo &lt; hi) &#123; int mi = lo + (hi - lo) / 2; if (A[mi] &lt; A[mi + 1]) lo = mi + 1; else hi = mi; &#125; return lo; &#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode728. Self Dividing Numbers]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode728-Self-Dividing-Numbers%2F</url>
    <content type="text"><![CDATA[A self-dividing number is a number that is divisible by every digit it contains. For example, 128 is a self-dividing number because 128 % 1 == 0, 128 % 2 == 0, and 128 % 8 == 0. Also, a self-dividing number is not allowed to contain the digit zero. Given a lower and upper number bound, output a list of every possible self dividing number, including the bounds if possible. Example 1:Input:left = 1, right = 22Output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 22]Note: The boundaries of each input argument are 1 &lt;= left &lt;= right &lt;= 10000. 如果一个数能被组成这个数的数字整除，那就是要求的结果之一了。注意0的问题！1234567891011121314151617181920212223class Solution &#123;public: bool is(int x)&#123; int n = x; while(x&gt;0)&#123; int temp = x%10; if(temp==0)&#123; return false; &#125; if(n%temp != 0) return false; x/=10; &#125; return true; &#125; vector&lt;int&gt; selfDividingNumbers(int left, int right) &#123; vector&lt;int&gt; res; for(int x=left;x&lt;=right;x++) if(is(x)) res.push_back(x); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode617. Merge Two Binary Trees]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode617-Merge-Two-Binary-Trees%2F</url>
    <content type="text"><![CDATA[Given two binary trees and imagine that when you put one of them to cover the other, some nodes of the two trees are overlapped while the others are not. You need to merge them into a new binary tree. The merge rule is that if two nodes overlap, then sum node values up as the new value of the merged node. Otherwise, the NOT null node will be used as the node of new tree. Example 1:1234567891011121314Input: Tree 1 Tree 2 1 2 / \ / \ 3 2 1 3 / \ \ 5 4 7 Output: Merged tree: 3 / \ 4 5 / \ \ 5 4 7 把两棵树合并，比较简单，递归即可。 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* res(TreeNode* t1, TreeNode* t2)&#123; if(!t1 &amp;&amp; !t2)&#123; return NULL; &#125; if(t1 &amp;&amp; !t2)&#123; return t1; &#125; if(!t1 &amp;&amp; t2)&#123; return t2; &#125; t1-&gt;val+=t2-&gt;val; t1-&gt;left = res(t1-&gt;left,t2-&gt;left); t1-&gt;right = res(t1-&gt;right,t2-&gt;right); return t1; &#125; TreeNode* mergeTrees(TreeNode* t1, TreeNode* t2) &#123; return res(t1,t2); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode921. Minimum Add to Make Parentheses Valid]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode921-Minimum-Add-to-Make-Parentheses-Valid%2F</url>
    <content type="text"><![CDATA[Given a string S of ‘(‘ and ‘)’ parentheses, we add the minimum number of parentheses ( ‘(‘ or ‘)’, and in any positions ) so that the resulting parentheses string is valid. Formally, a parentheses string is valid if and only if: It is the empty string, orIt can be written as AB (A concatenated with B), where A and B are valid strings, orIt can be written as (A), where A is a valid string.Given a parentheses string, return the minimum number of parentheses we must add to make the resulting string valid. Example 1:12Input: &quot;())&quot;Output: 1 Example 2:12Input: &quot;(((&quot;Output: 3 Example 3:12Input: &quot;()&quot;Output: 0 Example 4:12Input: &quot;()))((&quot;Output: 4 Note: S.length &lt;= 1000S only consists of ‘(‘ and ‘)’ characters. 一道变形的括号匹配，这里注意如果res为负数的话，要及时纠正成正的且也要在最终结果加一，如上边的Example4的样子，如果只是按照栈的做法，结果是0，是错的，其实要加4个。 1234567891011121314151617class Solution &#123;public: int minAddToMakeValid(string S) &#123; int res=0,result=0; for(int i=0;i&lt;S.size();i++) if(S[i]==&apos;(&apos;) res++; else&#123; res--; if(res&lt;0)&#123; res=0; result++; &#125; &#125; return result+res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1037. Valid Boomerang]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode1037-Valid-Boomerang%2F</url>
    <content type="text"><![CDATA[A boomerang is a set of 3 points that are all distinct and not in a straight line. Given a list of three points in the plane, return whether these points are a boomerang. Example 1:12Input: [[1,1],[2,3],[3,2]]Output: true Example 2:12Input: [[1,1],[2,2],[3,3]]Output: false Note: points.length == 3points[i].length == 20 &lt;=points[i][j]&lt;= 100 判断三个点是不是互异且不共线的，简单12345678910111213141516class Solution &#123;public: bool isBoomerang(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; for(int i=0;i&lt;points.size();i++) for(int j=i+1;j&lt;points.size();j++) if(points[i][0]==points[j][0] &amp;&amp; points[i][1]==points[j][1]) return false; int dx1 = points[1][0] - points[0][0]; int dx2 = points[1][1] - points[0][1]; int dx3 = points[2][0] - points[1][0]; int dx4 = points[2][1] - points[1][1]; if(dx1*dx4-dx2*dx3==0) return false; return true; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1038. Binary Search Tree to Greater Sum Tree]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode1038-Binary-Search-Tree-to-Greater-Sum-Tree%2F</url>
    <content type="text"><![CDATA[Given the root of a binary search tree with distinct values, modify it so that every node has a new value equal to the sum of the values of the original tree that are greater than or equal to node.val. As a reminder, a binary search tree is a tree that satisfies these constraints: The left subtree of a node contains only nodes with keys less than the node’s key.The right subtree of a node contains only nodes with keys greater than the node’s key.Both the left and right subtrees must also be binary search trees. Example 1: Input: [4,1,6,0,2,5,7,null,null,null,3,null,null,null,8]Output: [30,36,21,36,35,26,15,null,null,null,33,null,null,null,8] 典型的中序遍历，先遍历右子树，再把root赋值，最后看左子树 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int sum=0; void houxu(TreeNode* root)&#123; if(root-&gt;right) houxu(root-&gt;right); sum+=root-&gt;val; root-&gt;val = sum; if(root-&gt;left) houxu(root-&gt;left); &#125; TreeNode* bstToGst(TreeNode* root) &#123; houxu(root); return root; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode763 Partition Labels]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode763-Partition-Labels%2F</url>
    <content type="text"><![CDATA[A string S of lowercase letters is given. We want to partition this string into as many parts as possible so that each letter appears in at most one part, and return a list of integers representing the size of these parts. Example 1:12Input: S = &quot;ababcbacadefegdehijhklij&quot;Output: [9,7,8] Explanation:The partition is “ababcbaca”, “defegde”, “hijhklij”.This is a partition so that each letter appears in at most one part.A partition like “ababcbacadefegde”, “hijhklij” is incorrect, because it splits S into less parts.Note: S will have length in range [1, 500].S will consist of lowercase letters (‘a’ to ‘z’) only. 字符串分割，且每一个字符只能最多出现在一个子串中。1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; partitionLabels(string S) &#123; vector&lt;int&gt; res; int a[26]; for(int i=0;i&lt;S.size();i++)&#123; a[((int)(S[i]-&apos;a&apos;))]=i; &#125; int j=0,temp =0; for(int i=0;i&lt;S.size();i++)&#123; j=max(j,a[((int)(S[i]-&apos;a&apos;))]); if(i==j)&#123; res.push_back(i-temp+1); temp = i+1; &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode561. Array Partition I]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode561-Array-Partition-I%2F</url>
    <content type="text"><![CDATA[Given an array of 2n integers, your task is to group these integers into n pairs of integer, say (a1, b1), (a2, b2), …, (an, bn) which makes sum of min(ai, bi) for all i from 1 to n as large as possible. Example 1:12Input: [1,4,3,2]Output: 4 Explanation: n is 2, and the maximum sum of pairs is 4 = min(1, 2) + min(3, 4).Note:n is a positive integer, which is in the range of [1, 10000].All the integers in the array will be in the range of [-10000, 10000]. 这道题目给了我们一个数组有2n integers， 需要我们把这个数组分成n对，然后从每一对里面拿小的那个数字，把所有的加起来，返回这个sum。并且要使这个sum 尽量最大。如何让sum 最大化呢，我们想一下，如果是两个数字，一个很小，一个很大，这样的话，取一个小的数字，就浪费了那个大的数字。所以我们要使每一对的两个数字尽可能接近。我们先把nums sort 一下，让它从小到大排列，接着每次把index： 0， 2， 4…偶数位的数字加起来就可以了。12345678910class Solution &#123;public: int arrayPairSum(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(),nums.end()); int sum=0; for(int i=0;i&lt;nums.size();i+=2) sum+=nums[i]; return sum; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode942. DI String Match]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode942-DI-String-Match%2F</url>
    <content type="text"><![CDATA[Given a string S that only contains “I” (increase) or “D” (decrease), letN = S.length. Return any permutation A of [0, 1, …, N] such that for alli = 0, ..., N-1: If S[i] == “I”, then A[i] &lt; A[i+1]If S[i] == “D”, then A[i] &gt; A[i+1] Example 1:12Input: &quot;IDID&quot;Output: [0,4,1,3,2] Example 2:12Input: &quot;III&quot;Output: [0,1,2,3] Example 3:12Input: &quot;DDI&quot;Output: [3,2,0,1] Note: 1 &lt;= S.length &lt;= 10000S only contains characters “I” or “D”. 题目的意思是，将字符串与数组一一对应，因为数组多一位，不考虑这一位。剩下的位置，如果字符串写的是‘I’，那么该位置上的数应该比右边所有的数都小。而如果是‘D’，则是比右边的都大。现在需要找到其中任意一组。 其实这个题是一个贪心，并且有点dp的感觉。感觉这个题解不唯一，其实还是比较简单能够证明反例。评论有人提出了解法证明，可以看一下： 只需要证明，对于任何 &gt; 或者 &lt; , 算法的规则都能满足。△N = max-min; 由于每次遇到一个符号，△N-1。当符号为“ &lt; &lt; &lt;”: max–可以保证符号的正确性。当符号为“ &gt; &gt; &gt;”: min++可以保住符号的正确性。当符号为“ ……&lt; &gt; &lt; “: 任意时刻max和min开始比较，是否满足 min &lt; max?答案是：YES! 由于符号的数量为N，最开始△N = N。由于至少出现一对大于号和小于号 , min(△N)= 1，仍然满足min &lt; max;综上，得证。 因为每一位对应的数字只有两种情况：比右边所有数都大，或者都小。那么我们可以设定两个值，初始的话：low = 0，high = N。这样，从左开始遍历字符串，碰见一个字符，如果是‘I’，那么就直接赋值low，同时low++。这样，‘I’右边所有的数，一定是都比这个位置大的。因为此时low&gt;a[i]，同时high &gt; low。 反而言之，碰见‘D’，直接赋值hight，同时high–。这样所有的数就一定比这个小了。大概就是这样，在O(n)的时间复杂度下就能构造出答案数组。 123456789101112131415class Solution &#123;public: vector&lt;int&gt; diStringMatch(string S) &#123; vector&lt;int&gt; res = vector&lt;int&gt;(S.size()+1); int low = 0,high=S.size(); for(int i=0;i&lt;S.size();i++)&#123; if(S[i]==&apos;I&apos;) res[i]=low++; else res[i]=high--; &#125; res[S.size()]=low; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode797. All Paths From Source to Target]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode797-All-Paths-From-Source-to-Target%2F</url>
    <content type="text"><![CDATA[Given a directed, acyclic graph of N nodes. Find all possible paths from node 0 to node N-1, and return them in any order. The graph is given as follows: the nodes are 0, 1, …, graph.length - 1. graph[i] is a list of all nodes j for which the edge (i, j) exists. Example:12345678Input: [[1,2], [3], [3], []] Output: [[0,1,3],[0,2,3]] Explanation: The graph looks like this:0---&gt;1| |v v2---&gt;3There are two paths: 0 -&gt; 1 -&gt; 3 and 0 -&gt; 2 -&gt; 3. Note:The number of nodes in the graph will be in the range [2, 15].You can print different paths in any order, but you should keep the order of nodes inside one path. 这道题给了我们一个无回路有向图，包含N个结点，然后让我们找出所有可能的从结点0到结点N-1的路径。 这个图的数据是通过一个类似邻接链表的二维数组给的，最开始的时候博主没看懂输入数据的意思，其实很简单，我们来看例子中的input，[[1,2], [3], [3], []]，这是一个二维数组，最外层的数组里面有四个小数组，每个小数组其实就是和当前结点相通的邻结点，由于是有向图，所以只能是当前结点到邻结点，反过来不一定行。那么结点0的邻结点就是结点1和2，结点1的邻结点就是结点3，结点2的邻结点也是3，结点3没有邻结点。 那么其实这道题的本质就是遍历邻接链表，由于要列出所有路径情况，那么递归就是不二之选了。我们用cur来表示当前遍历到的结点，初始化为0，然后在递归函数中，先将其加入路径path，如果cur等于N-1了，那么说明到达结点N-1了，将path加入结果res。否则我们再遍历cur的邻接结点，调用递归函数即可，参见代码如下：12345678910111213class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; allPathsSourceTarget(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; vector&lt;vector&lt;int&gt;&gt; res; helper(graph, 0, &#123;&#125;, res); return res; &#125; void helper(vector&lt;vector&lt;int&gt;&gt;&amp; graph, int cur, vector&lt;int&gt; path, vector&lt;vector&lt;int&gt;&gt;&amp; res) &#123; path.push_back(cur); if (cur == graph.size() - 1) res.push_back(path); else for (int neigh : graph[cur]) helper(graph, neigh, path, res); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核内存管理学习之三（slab分配器）]]></title>
    <url>%2F2019%2F05%2F05%2Flinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%89%EF%BC%88slab%E5%88%86%E9%85%8D%E5%99%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[内核内存分配在linux内核中伙伴系统用来管理物理内存，其分配的单位是页，但是向用户程序一样，内核也需要动态分配内存，而伙伴系统分配的粒度又太大。由于内核无法借助标准的C库，因而需要别的手段来实现内核中动态内存的分配管理，linux采用的是slab分配器。slab分配器不仅可以提供动态内存的管理功能，而且可以作为经常分配并释放的内存的缓存。通过slab缓存，内核能够储备一些对象，供后续使用。需要注意的是slab分配器只管理内核的常规地址空间（准确的说是直接被映射到内核地址空间的那部分内存包括ZONE_NORMAL和ZONE_DMA）。采用了slab分配器后，在释放内存时，slab分配器将释放的内存块保存在一个列表中，而不是返回给伙伴系统。在下一次内核申请同样类型的对象时，会使用该列表中的内存开。slab分配器分配的优点： 可以提供小块内存的分配支持 不必每次申请释放都和伙伴系统打交道，提供了分配释放效率 如果在slab缓存的话，其在CPU高速缓存的概率也会较高。 伙伴系统的操作队系统的数据和指令高速缓存有影响，slab分配器降低了这种副作用 伙伴系统分配的页地址都页的倍数，这对CPU的高速缓存的利用有负面影响，页首地址对齐在页面大小上使得如果每次都将数据存放到从伙伴系统分配的页开始的位置会使得高速缓存的有的行被过度使用，而有的行几乎从不被使用。slab分配器通过着色使得slab对象能够均匀的使用高速缓存，提高高速缓存的利用率。 在引入了slab分配器后，内核的内存管理方案如图所示： slab分配器也不是万能的，它也有缺陷： 对于微型嵌入式系统，它显得比较复杂，这是可以使用经过优化的slob分配器，它使用内存块链表，并使用最先适配算法 对于具有大量内存的大型系统，仅仅建立slab分配器的数据结构就需要大量内存，这时候可以使用经过优化的slub分配器 无论是slab分配器家族的这三个中的那个一，它们提供的接口都是相同的：kmalloc,__kmalloc和kmalloc_node用于普通内存的分配kmem_cache_alloc，kmem_cache_alloc_node用于申请特定类型的内存内核中普通内存的申请使用kmalloc(size,flags),size是申请的大小，flags告诉分配器分配什么样的内存，如何分配等等。内核中普通内存的释放使用kfree(*ptr);释放ptr所指向的内存区。可以通过/proc/slabinfo查看活动的缓存列表。 slab分配器的原理slab算法是1994年开发出来的并首先用于sun microsystem solaris 2.4操作系统。这种算法的使用基于以下几个前提： 所存放数据的类型可以影响存储器取区的分配方式。 内核函数倾向于反复请求同一类型的存储器区。 对存储器区的请求可以根据它们发生的频率来分类。 所引入的对象大小不是几何分布的。 硬件高速缓存的高性能。在这种情况下，伙伴函数的每次调用都增加了对内存的平均访问时间。 slab分配器把对象分组放进高速缓存。每个高速缓存都是同种类型对象的一种“储备”。一个cache管理一组大小固定的内存块（也称为对象实体），每个内存块都可用作一种数据结构。cache中的内存块来自一到多个slab。一个slab来自物理内存管理器的一到多个物理页，该slab被分成一组固定大小的块，被称为slab对象（object），一个slab属于一个cache，其中的对象就是该cache所管理的固定大小的内存块。所以一个cache可以有一到多个slab。下图给出了slab分配器的各个部分及其相互关系： 在基于slab的内核内存管理器中，基本的概念是保存管理型数据的缓存（即slab cache，slab缓存）和保存被管理对象的各个slab。每个缓存都负责一种对象类型，比如kmalloc-128会负责管理65-128字节的内存的kmalloc分配。系统中的所有缓存类型都保存在一个链表slab_caches中。 slab缓存slab缓存的详细结构 如图所示： 每个缓存结构都包括了两个重要的成员： struct kmem_list3 **nodelists：kmem_list3结构中包含了三个链表头，分别对应于完全用尽的slab链表，部分用尽的slab链，空闲的slab链表，其中部分空闲的在最开始 struct array_cache *array[NR_CPUS + MAX_NUMNODES]：array是一个数组，系统中的每一个CPU，每一个内存节点都对应该数组中的一个元素。array_cache结构包含了一些特定于该CPU/节点的管理数据以及一个数组，每个数组元素都指向一个该CPU/节点刚释放的内存对象。该数组有助于提高高速缓存的利用率。 当释放内存对象时，首先将内存对象释放到该数组中对应的元素中 申请内存时，内核假定刚释放的内存对象仍然处于CPU高速缓存中，因而会先从该数组的对应数组元素中查找，看是否可以申请。 当特定于CPU/节点的缓存数组是空时，会用slab缓存中的空闲对象填充它 因此，对象分配的次序为： 特定于CPU/节点的缓存列表中的对象 当前已经存在于slab缓存中中的未用对象 从伙伴系统获得内存，然后创建的对象 slab对象对象在slab中不是连续排列的，其排列如图所示: slab对象的长度并不代表其确切的长度，因为需要对长度进行调整以满足对齐要求。对齐要求可能是： 创建slab时指定了SLAB_HWCACHE_ALIGN标志，则会按照cache_line_size的返回值对齐，即对齐的硬件缓存行上。如果对象小于硬件缓存行的一半，则将多个对象放入一个缓存行。 如果没有指定对齐标记，则对齐到BYTES_PER_WORD，即对齐到void指针所需字节数目。 为了使得slab满足对齐要求，会在slab对象中添加填充字节以满足对齐要求,使用对齐的地址可以会加速内存访问。每个slab都对应一个管理结构，它可能位于slab内部也可能位于slab外部专门为它申请的内存中，它保存了所有的管理数据，也包括一个链表域用于将slab连接起来，还包括一个指针指向它所属的cache。大多数情况下，slab内存区的长度是不能被对象长度整除的，因而就有了一些多余的内存，这些内存可以被用来以偏移量的形式给slab“着色”，着色后，缓存的各个slab成员会指定到不同的偏移量，进而可以将数据定位到不同的缓存行。内核通过对象自身即可找到它对应的slab，过程是:对象的物理地址-&gt;物理地址对应的page结构。然后由page找到对应的slab以及cache（包含在page结构中）。 slab分配器的实现使用的数据结构linux使用struct kmem_cache表示slab缓存，使用struct kmem_list3管理缓存所对应的slab链表的链表头，使用struct array_cache管理特定于CPU的slab对象的缓存(注意不是slab缓存是slab对象的缓存)。 内核采用的其它保护机制为了检测错误，内核采用了一些机制来对内存进行保护，主要的方法有：危险区：在每个对象的开始和结束处增加一个额外的内存区，其中会填充一些特殊的字段。如果这个区域被修改了，可能就是某些代码访问了不该访问的内存区域对象毒化：在建立和释放slab时，将对象用预定义的模式填充。如果在对象分配时发现该模式已经改变，就可能是发生了内存越界。 初始化slab分配器的初始化涉及到一个鸡与蛋的问题。为了初始化slab数据结构，内核需要很多远小于一页的内存区，很显然由kmalloc分配这种内存最合适，但是kmalloc只有在slab分配器初始化完才能使用。内核借助一些技巧来解决该问题。kmem_cache_init函数被内核用来初始化slab分配器。它在伙伴系统启用后调用。在SMP系统中，启动CPU正在运行，其它CPU还未初始化，它要在smp_init之前调用。slab采用多步逐步初始化slab分配器，其工作过程：创建第一个名为kmem_cache的slab缓存，此时该缓存的管理数据结构使用的是静态分配的内存。在slab分配器初始化完成后，会将这里使用的静态数据结构替换为动态分配的内存。初始化其它的slab缓存，由于已经初始化了第一个slab缓存，因此这一步是可行。将初始化过程由于“鸡与蛋”的问题而使用的静态数据结构替换为动态分配的。 API创建缓存slab分配器使用kmem_cache_create创建一个新的slab缓存。该函数的基本工作过程为： 参数检查 计算对齐 分配缓存的管理结构所需的内存 计算slab所需的物理内存大小以及每个slab中slab对象的个数 计算slab管理部分应该放在哪里，并存储在缓存的flags域中 计算slab的颜色，颜色数目存在color中，颜色偏移量存在color_off中 建立每CPU的缓存 将新创建的缓存添加到全局slab缓存链表slab_caches中 分配对象kmem_cache_alloc用于从指定的slab缓存分配对象。与kmalloc相比，它多了一个缓存指针的参数，用于指向所要从其中分配内存的缓存。其工作过程如图： 在NUMA系统中，如果在本节点分配失败，还会尝试其它节点。 cache_grow用于缓存的增长，它会从伙伴系统获取内存。其流程如图所示： 释放对象kmem_cache_free用于将对象归还给指定的slab缓存，类似于kmem_cache_free，它比kfree多了一个指向所归还到的slab缓存指针参数。其流程如图： free_block会将缓存中前batchcount个对象移动到slab链表中，并且将缓存中剩余的对象向数组的头部移动。根据slab对象所属的slab的状态(inuse域)，slab对象可能被归给给部分空闲链表（如果该slab中有些slab对象正在被使用）或者空闲链表（该slab中没有其它对象正在被使用），同时如果加入到空闲slab链表中的slab对象数目超过了free_limit的限制（在kmem_list3结构中），则会调用slab_destroy销毁slab。 缓存收缩可以使用kmem_cache_shrink来回收一个slab缓存所管理的内存。它会释放尽可能多的slab。它会尝试回收用于每CPU缓存的内存空间（调用free_block），以及用于空闲链表的slab内存空间，slab的释放最终都由slab_destroy完成。 通用缓存如果不涉及到特定类型的内存，而只是普通类型的内存，可以使用kmalloc和kfree来申请和释放缓存。内核会找到并使用适用于所申请的大小的通用slab缓存来进行分配和释放。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核内存管理学习之二（物理内存管理--伙伴系统）]]></title>
    <url>%2F2019%2F05%2F05%2Flinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BA%8C%EF%BC%88%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86--%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[伙伴系统原理伙伴关系定义：由一个母实体分成的两个各方面属性一致的两个子实体，这两个子实体就处于伙伴关系。在操作系统分配内存的过程中，一个内存块常常被分成两个大小相等的内存块，这两个大小相等的内存块就处于伙伴关系。它满足 3 个条件 ： 两个块具有相同大小记为 2^K 它们的物理地址是连续的 从同一个大块中拆分出来 伙伴算法的实现原理为了便于页面的维护，将多个页面组成内存块，每个内存块都有 2 的方幂个页，方幂的指数被称为阶 order。order相同的内存块被组织到一个空闲链表中。伙伴系统基于2的方幂来申请释放内存页。当申请内存页时，伙伴系统首先检查与申请大小相同的内存块链表中，检看是否有空闲页，如果有就将其分配出去，并将其从链表中删除，否则就检查上一级，即大小为申请大小的2倍的内存块空闲链表，如果该链表有空闲内存，就将其分配出去，同时将剩余的一部分（即未分配出去的一半）加入到下一级空闲链表中；如果这一级仍没有空闲内存；就检查它的上一级，依次类推，直到分配成功或者彻底失败，在成功时还要按照伙伴系统的要求，将未分配的内存块进行划分并加入到相应的空闲内存块链表在释放内存页时，会检查其伙伴是否也是空闲的，如果是就将它和它的伙伴合并为更大的空闲内存块，该检查会递归进行，直到发现伙伴正在被使用或者已经合并成了最大的内存块。 linux中的伙伴系统相关的结构系统中的每个物理内存页（页帧）都对应一个struct page数据结构，每个节点都包含了多个zone，每个zone都有struct zone表示，其中保存了用于伙伴系统的数据结构。zone中的struct free_area free_area[MAX_ORDER];用于管理该zone的伙伴系统信息。伙伴系统将基于这些信息管理该zone的物理内存。该数组中每个数组项用于管理一个空闲内存页块链表，同一个链表中的内存页块的大小相同，并且大小为2的数组下标次方页。MAX_ORDER定义了支持的最大的内存页块大小。12345struct free_area的定义如下struct free_area &#123; structlist_head free_list[MIGRATE_TYPES]; unsignedlong nr_free;&#125;; nr_free:其中nr_free表示内存页块的数目，对于0阶的表示以1页为单位计算，对于1阶的以2页为单位计算，n阶的以2的n次方为单位计算。 free_list:用于将具有该大小的内存页块连接起来。由于内存页块表示的是连续的物理页，因而对于加入到链表中的每个内存页块来说，只需要将内存页块中的第一个页加入该链表即可。因此这些链表连接的是每个内存页块中第一个内存页，使用了struct page中的struct list_head成员lru。free_list数组元素的每一个对应一种属性的类型，可用于不同的目地，但是它们的大小和组织方式相同。因此在伙伴系统看来，一个zone中的内存组织方式如下图所示： 基于伙伴系统的内存管理方式专注于内存节点的某个内存域的管理，但是系统中的所有zone都会通过备用列表连接起来。伙伴系统和内存域/节点的关系如下图所示： 系统中伙伴系统的当前信息可以通过/proc/buddyinfo查看： 这是我的PC上的信息，这些信息描述了每个zone中对应于每个阶的空闲内存页块的数目，从左到右阶数依次升高。 避免碎片碎片概念伙伴系统也存在一些问题，在系统长时间运行后，物理内存会出现很多碎片，如图所示： 这时虽然可用内存页还有很多，但是最大的连续物理内存也只有一页，这对于用户程序不成问题，因为用户程序通过页表映射，应用程序看到的总是连续的虚拟内存。但是对于内核来说就不行了，因为内核有时候需要使用连续的物理内存。 Linux解决方案碎片问题也存在于文件系统，文件系统中的碎片可以通过工具来解决，即分析文件系统，然后重新组织文件的位置，但是这种方不适用于内核，因为有些物理页时不能随意移动。内核采用的方法是反碎片（anti-fragmentation）。为此内核根据页的可移动性将其划分为3种不同的类型： 不可移动的页：在内存中有固定位置，不能移动。分配给核心内核的页大多是此种类型 可回收的页：不能移动，但是可以删除，其内容可以从某些源重新生成。 可移动的页：可以随意移动。属于用户进程的页属于这种类型，因为它们是通过页表映射的，因而在移动后只需要更新用户进程页表即可。 页的可移动性取决于它属于上述三类中的哪一类，内核将页面按照不同的可移动性进行分组，通过这种技术，虽然在不可移动页中仍可能出现碎片，但是由于具有不同可移动性的页不会进入同一个组，因而其它两个类型的内存块就可以获得较好的“对抗碎片”的特性。需要注意的是按照可移动性对内存页进行分组时在运行中进行的，而不是在一开始就设置好的。 数据结构内核定义了MIGRATE_TYPES中迁移类型，其定义如下：123456789enum &#123; MIGRATE_UNMOVABLE, MIGRATE_RECLAIMABLE, MIGRATE_MOVABLE, MIGRATE_PCPTYPES, /* the number of types on the pcp lists */ MIGRATE_RESERVE = MIGRATE_PCPTYPES, MIGRATE_ISOLATE, /* can&apos;t allocate from here */ MIGRATE_TYPES&#125;; 其中前三种分别对应于三种可移动性，其它几种的含义： MIGRATE_PCPTYPES：是per_cpu_pageset，即用来表示每CPU页框高速缓存的数据结构中的链表的迁移类型数目 MIGRATE_RESERVE：是在前三种的列表中都没用可满足分配的内存块时，就可以从MIGRATE_RESERVE分配 MIGRATE_ISOLATE：用于跨越NUMA节点移动物理内存页，在大型系统上，它有益于将物理内存页移动到接近于是用该页最频繁地CPU 每种类型都对应free_list中的一个数组项。类似于从zone中的分配，如果无法从指定的迁移类型分配到页，则会按照fallbacks指定的次序从备用迁移类型中尝试分配，它定义在page_alloc.c中。虽然该特性总是编译进去的，但是该特性只有在系统中有足够的内存可以分配到每种迁移类型对应的链表时才有意义，也就是说每个可以迁移性链表都要有“适量”的内存，内核需要对“适量”的判断是基于两个宏的： pageblock_order：内核认为够大的一个分配的阶。 pageblock_nr_pages：内核认为启用该特性时每个迁移链表需要具有的最少的内存页数。它的定义是基于pageblock_order的。 基于这个“适量”的概念内核会在build_all_zonelists中判断是否要启用该特性。page_group_by_mobility_disabled表示是否启用了该特性。内核定义了两个标志：__GFP_MOVABLE和__GFP_RECLAIMABLE分别用来表示可移动迁移类型和可回收迁移类型，如果没有设置这两个标志，则表示是不可移动的。如果页面迁移特性被禁止了，则所有的页都是不可移动页。 struct zone中包含了一个字段pageblock_flags，它用于跟踪包含pageblock_nr_pages个页的内存区的属性。在初始化期间，内核自动保证对每个迁移类型，在pageblock_flags中都分配了足够存储NR_PAGEBLOCK_BITS个比特的空间。 set_pageblock_migratetype用于设置一个以指定的页为起始地址的内存区的迁移类型。页的迁移类型是预先分配好的，对应的比特位总是可用，在页释放时，必须将其返还给正确的链表。get_pageblock_migratetype可用于从struct page中获取页的迁移类型。通过/proc/pagetypeinfo可以获取系统当前的信息。 在内存初始化期间memmap_init_zone会将所有的内存页都初始化为可移动的。该函数在paging_init中会最终被调到（会经过一些中间函数，其中就有free_area_init_node）。 虚拟可移动内存内核还提供了一种机制来解决碎片问题，即使用虚拟内存域ZONE_MOVABLE。其思想是：可用内存划分为两个部分，一部分用于可移动分配，一部分用于不可移动分配。这样就防止了不可移动页向可移动内存区域引入碎片。该机制需要管理员来配置两部分内存的大小。kernel参数kernelcore用于指定用于不可移动分配的内存数量，如果指定了该参数，其值会保存在required_kernelcore会基于它来计算。kernel参数movablecore用于指定用于可移动分配的内存数量，如果指定了该参数，则其值会被保存在required_movablecore中，同时会基于它来计算required_kernelcore，代码如下（函数find_zone_movable_pfns_for_nodes）：12corepages = totalpages - required_movablecore;required_kernelcore = max(required_kernelcore, corepages); 如果计算出来的required_kernelcore为0，则该机制将无效。该zone是一个虚拟zone，它不和任何物理内存相关联，该域中的内存可能来自高端内存或者普通内存。用于不可移动分配的内存会被均匀的分布到系统的各个内存节点中；同时用于可移动分配的内存只会取自最高内存域的内存，zone_movable_pfn记录了取自各个节点的用于可移动分配的内存的起始地址。 初始化内存域和节点数据结构在内存管理的初始化中，架构相关的代码要完成系统中可用内存的检测，并要将相关信息提交给架构无关的代码。架构无关的代码free_area_init_nodes负责完成管理数据结构的创建。该函数需要一个参数max_zone_pfn，它由架构相关的代码提供，其中保存了每个内存域的最大可用页帧号。内核定义了两个数组：12static unsigned long __meminitdata arch_zone_lowest_possible_pfn[MAX_NR_ZONES];static unsigned long __meminitdata arch_zone_highest_possible_pfn[MAX_NR_ZONES]; 这两个数组在free_area_init_nodes用于保存来自max_zone_pfn的信息，并将它转变成[low，high]的形式。然后内核开始调用find_zone_movable_pfns_for_nodes对ZONE_MOVABLE域进行初始化。然后内核开始为每一个节点调用free_area_init_node，这个函数将完成： 调用calculate_node_totalpages计算节点中页的总数 调用alloc_node_mem_map负责初始化struct pglist_data中的node_mem_map，为它分配的内存将用于存储本节点的所有物理内存的struct page结构。这片内存将对其到伙伴系统的最大分配阶上。而且如果当前节点是第0个节点，则该指针信息还将保存在全局变量mem_map中。 调用free_area_init_core完成初始化进一步的初始化 free_area_init_core将完成内存域数据结构的初始化，在这个函数中 nr_kernel_pages记录直接映射的页面数目，而nr_all_pages则记录了包括高端内存中页数在内的页数 会调用zone_pcp_init初始化该内存域的每CPU缓存 会调用init_currently_empty_zone初始化该zone的wait_table，free_area列表 调用memmap_init初始化zone的页，所有页都被初始化为可移动的 分配器API伙伴系统只能分配2的整数幂个页。因此申请时，需要指定请求分配的阶。有很多分配和释放页的API，都定义在gfp.h中。最简单的是alloc_page(gfp_mask)用来申请一个页， free_page(addr)用来释放一个页。这里更值得关注的获取页面时的参数gfp_mask，所有获取页面的API都需要指定该参数。它用来影响分配器的行为，其中有是分配器提供的标志，标志有两种： zone修饰符：用于告诉分配器从哪个zone分配内存 行为修饰符：告诉分配器应该如何进行分配 其中zone修饰符定义为12345#define __GFP_DMA ((__force gfp_t)___GFP_DMA)#define __GFP_HIGHMEM ((__force gfp_t)___GFP_HIGHMEM)#define __GFP_DMA32 ((__force gfp_t)___GFP_DMA32)#define __GFP_MOVABLE ((__force gfp_t)___GFP_MOVABLE) /* Page is movable */#define GFP_ZONEMASK (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE) 这些定义都一目了然，需要指出的是如果同时指定了__GFP_MOVABLE和__GFP_HIGHMEM，则会从虚拟的ZONE_MOVABLE分配。更详细的可以参考gfp.h，其中包含了所有的标志及其含义。 分配页__alloc_pages会完成最终的内存分配，它是伙伴系统的核心代码（但是在内核代码中，这种命名方式的函数都是需要小心调用的，一般都是给实现该功能的代码自己调用，不作为API提供出去的，因而它的包装器才是对外提供的API，也就是alloc_pages_node）。 选择页选择页中最重要的函数是get_page_from_freelist，它负责通过标志和分配阶来判断分配是否可以进行，如果可以就进行实际的分配。该函数还会调用zone_watermark_ok根据指定的标识判断是否可以从给定的zone中进行分配。该函数需要struct zonelist的指针指向备用zone，当当前zone不能满足分配需求时就依次遍历该列表尝试进行分配。整体的分配流程是： 调用get_page_from_freelist尝试进行分配，如果成功就返回分配到的页，否则 唤醒kswapd，然后再次调用get_page_from_freelist尝试进行分配，如果成功就返回分配的页，否则 如果分配的标志允许不检查阈值进行分配，则以ALLOC_NO_WATERMARKS为标志再次调用get_page_from_freelist尝试分配，如果成功则返回分配的页；如果不允许不检查阈值或者仍然失败，则 如果不允许等待，就分配失败，否则 如果支持压缩，则尝试先对内存进行一次压缩，然后再调用get_page_from_freelist，如果成功就返回，否则 进行内存回收，然后再调用get_page_from_freelist，如果成功就返回，否则 根据回收内存并尝试分配的结果以及分配标志，可能会调用OOM杀死一个进程然后再尝试分配，也可能不执行OOM这一步的操作，如果执行了，则在失败后可能就彻底失败，也可能重新回到第2步，也可能继续下一步 回到第2步中调用get_page_from_freelist的地方或者再尝试一次先压缩后分配，如果走了先压缩再分配这一步，这就是最后一次尝试了，要么成功要么失败，不会再继续尝试了 移出所选择的页在函数get_page_from_freelist中，会首先在zonelist中找到一个具有足够的空闲页的zone，然后会调用buffered_rmqueue进行处理，在分配成功时，该函数会把所分配的内存页从zone的free_list中移出，并且保证剩余的空闲内存页满足伙伴系统的要求，该函数还会把内存页的迁移类型存放在page的private域中。该函数的步骤如图所示： 可以看出buffered_rmqueue的工作过程为： 如果申请的是单页，会做特殊处理，内核会利用每CPU的缓存加速这个过程。并且在必要的时候会首先填充每CPU的缓存。函数rmqueue_bulk用于从伙伴系统获取内存页，并添加到指定的链表，它会调用函数__rmqueue。 如果是分配多个页，则会首先调用__rmqueue从内存域的伙伴系统中选择合适的内存块，这一步可能失败，因为虽然内存域中有足够数目的空闲页，但是页不一定是连续的，如果是这样这一步就会返回NULL。在这一步中如果需要还会将大的内存块分解成小的内存块来进行分配，即按照伙伴系统的要求进行分配。 无论是分配单页还是多个页，如果分配成功，在返回分配的页之前都要调用prep_new_page，如果这一步的处理不成功就会重新进行分配（跳转到函数buffered_rmqueue的开始），否则返回分配的页。 函数__rmqueue的执行过程： 首先调用__rmqueue_smallest尝试根据指定的zone，分配的阶，迁移类型进行分配，该函数根据指定的信息进行查找，在找到一个可用的空闲内存页块后会将该内存页块从空闲内存页块链表中删除，并且会调用expand使得剩余的内存页块满足伙伴系统的要求。如果在这一步成功就返回，否则执行下一步 调用__rmqueue_fallback尝试从备用zone分配。该函数用于根据前一类型的备用列表尝试从其它备用列表分配，但是需要注意的是这里会首先尝试最大的分配阶，依次降低分配的阶，直到指定的分配的阶，采用这个策略是为了避免碎片—如果要用其它迁移类型的内存，就拿一块大的过来，而不是在其它迁移类型的小区域中到处引入碎片。同时如果从其它迁移类型的空闲内存页块分配到的是一个较大的阶，则整块内存页块的迁移类型可能会发生改变，从原来的类型改变为申请分配时所请求的类型（即迁移类型发生了改变）。分配成功时的动作和__rmqueue_smallest类似，移出内存页，调用expand。 函数prep_new_page的操作 对页进行检查，以确保页确实是可用的，否则就返回一个非0值导致分配失败 设置页的标记以及引用计数等等。 如果设置而来__GFP_COMP标志，则调用prep_compound_page将页组织成复合页（hugetlb会用到这个）。 复合页的结构如图所示： 复合页具有如下特性： 复合页中第一个页称为首页，其它所拥有页都称为尾页 组成复合页的所有的private域都指向首页 第一个尾页的lru的next域指向释放复合页的函数指针 第一个尾页的lru的prev域用于指向复合页所对应的分配的阶，即多少个页 释放页__free_pages是释放页的核心函数，伙伴系统提供出去的API都是它的包装器。其流程： 减小页的引用计数，如果计数不为0则直接返回，否则 如果释放的是单页，则调用free_hot_cold_page，否则 调用__free_pages_ok free_hot_cold_page会把页返还给每-CPU缓存而不是直接返回给伙伴系统，因为如果每次都返还给伙伴系统，那么将会出现每次的分配和释放都需要伙伴系统进行分割和合并的情况，这将极大的降低分配的效率。因而这里采用的是一种“惰性合并”，单页会首先返还给每-CPU缓存，当每-CPU缓存的页面数大于一个阈值时（pcp-&gt;high），则一次将pcp-&gt;patch个页返还给伙伴系统。free_pcppages_bulk在free_hot_cold_page中用于将内存页返还给伙伴系统，它会调用函数__free_one_page。函数__free_pages_ok最终页会调到__free_one_page来释放页，__free_one_page会将页面释放返还给伙伴系统，同时在必要时进行递归合并。在__free_one_page进行合并时，需要找到释放的page的伙伴的页帧号，这是通过__find_buddy_index来完成的，其代码非常简单：1234__find_buddy_index(unsigned long page_idx,unsigned int order)&#123; returnpage_idx ^ (1 &lt;&lt; order);&#125; 根据异或的规则，这个结果刚好可以得到邻居的页帧号。因为根据linux的管理策略以及伙伴系统的定义，伙伴系统中每个内存页块的第一个页帧号用来标志该页，因此对于order阶的两个伙伴，它们只有1&lt;&lt;order这个比特位是不同的，这样，只需要将该比特与取反即可，而根据异或的定义，一个比特和0异或还是本身，一个比特和1异或刚好可以取反。因此就得到了这个算式。如果可以合并还需要取得合并后的页帧号，这个更简单，只需要让两个伙伴的页帧号相与即可。__free_one_page调用page_is_buddy来对伙伴进行判断，以决定是否可以合并。 不连续内存页的分配内核总是尝试使用物理上连续的内存区域，但是在分配内存时，可能无法找到大片的物理上连续的内存区域，这时候就需要使用不连续的内存，内核分配了其虚拟地址空间的一部分（vmalloc区）用于管理不连续内存页的分配。每个vmalloc分配的子区域都自包含的，在内核的虚拟地址空间中vmalloc子区域之间都通过一个内存页隔离开来，这个间隔用来防止不正确的访问。 用vmalloc分配内存vmalloc用来分配在虚拟地址空间连续，但是在物理地址空间不一定连续的内存区域。它只需要一个以字节为单位的长度参数。为了节省宝贵的较低端的内存区域，vmalloc会使用高端内存进行分配。内核使用struct vm_struct来管理vmalloc分配的每个子区域，其定义如下：12345678910struct vm_struct &#123; struct vm_struct *next; void *addr; unsigned long size; unsigned long flags; struct page **pages; unsigned int nr_pages; phys_addr_t phys_addr; const void *caller;&#125;; 每个vmalloc子区域都对应一个该结构的实例。 next：指向下一个vmalloc子区域 addr：vmalloc子区域在内核虚拟地址空间的起始地址 size：vmalloc子区域的长度 flags：与该区域相关标志 pages：指针，指向映射到虚拟地址空间的物理内存页的struct page实例 nr_pages：映射的物理页面数目 phys_addr：仅当用ioremap映射了由物理地址描述的内存页时才需要改域，它保存物理地址caller：申请者 创建vmalloc子区域所有的vmalloc子区域都被连接保存在vmlist中，该链表按照addr排序，顺序是从小到大。当创建一个新的子区域时需要，需要找到一个合适的位置。查找合适的位置采用的是首次适用算法，即从vmalloc区域找到第一个可以满足需求的区域，查找这样的区域是通过函数__get_vm_area_node完成的。其分配过程以下几步： 调用__get_vm_area_node找到合适的区域 调用__vmalloc_area_node分配物理内存页 调用map_vm_area将物理内存页映射到内核的读你地址空间 将新的子区域插入vmlist链表 在从伙伴系统分配物理内存页时使用了标志：GFP_KERNEL | __GFP_HIGHMEM还有其它的方式来建立虚拟地址空间的连续映射： vmalloc_32：与vmallo工作方式相同，但是确保所使用的物理地址总可以用32位指针寻址 vmap：将一组物理页面映射到连续的虚拟地址空间 ioremap：特定于处理器的分配函数，用于将取自物理地址空间而、由系统总线用于I/O操作的一个内存块，映射到内核的虚拟地址空间 释放内存vfree用于释放vmalloc和vmalloc_32分配的内存空间，vunmap用于释放由vmap和ioremap分配的空间（iounmap会调到vunmap）。最终都会归结到函数__vunmap。__vunmap的执行过程： 调用remove_vm_area从vmlist中找到一个子区域，然后将其从子区域删除，再解除物理页面的映射 如果设置了deallocate_pages，则将物理页面归还给伙伴系统 释放管理虚拟内存的数据结构struct vm_struct 内核映射高端内存可通过vmalloc机制映射到内核的虚拟地址空间，但是高端内存往内核虚拟地址空间的映射并不依赖于vmalloc，而vmalloc是用于管理不连续内存的，它也并不依赖于高端内存。 持久内核映射如果想要将高端内存长期映射到内核中，则必须使用kmap函数。该函数需要一个page指针用于指向需要映射的页面。如果没有启用高端内存，则该函数直接返回页的地址，因为所有页面都可以直接映射。如果启用了高端内存，则：如果不是高端内存的页面，则直接返回页面地址，否则调用kmap_high进行处理 使用的数据结构vmalloc区域后的持久映射区域用于建立持久映射。pkmap_count是一个有LAST_PKMAP个元素的数组，每个元素对应一个持久映射。每个元素的值是被映射页的一个使用计数器： 0：相关的页么有被使用 1：该位置关联的页已经映射，但是由于CPU的TLB没有刷新而不能使用 大于1的其它值：表示该页的引用计数，n表示有n-1处在使用该页 数据结构12345struct page_address_map &#123; struct page *page; void *virtual; struct list_head list;&#125;; 用于建立物理页和其在虚拟地址空间位置之间的关系。 page：指向全局数据结构mem_map数组中的page实例的指针 virtual：该页在虚拟地址空间中分配的位置所有的持久映射保存在一个散列表page_address_htable中，并用链表处理冲突，page_slot是散列函数。函数page_address用于根据page实例获取器对应的虚拟地址。其处理过程： 如果不是高端内存直接根据page获得虚拟地址（利用__va(paddr)），否则 在散列表中查找该page对应的struct page_address_map实例，获取其虚拟地址 创建映射函数kmap_high完成映射的实际创建，其工作过程： 调用page_address获取对应的虚拟地址 如果没有获取到，则调用map_new_virtual获取虚拟地址 pkmap_count数组中对应于该虚拟地址的元素的引用计数加1 新映射的创建在map_new_virtual中完成，其工作过程： 执行一个无限循环： 更新last_pkmap_nr为last_pkmap_nr+1 同时如果last_pkmap_nr为0，调用flush_all_zero_pkmaps，flush CPU高速缓存 检查pkmap_count数组中索引last_pkmap_nr对应的元素的引用计数是否为0，如果是0就退出循环，否则 将自己加入到一个等待队列 调度其它任务 被唤醒时会首先检查是否有其它任务已经完成了新映射的创建，如果是就直接返回 回到循环头部重新执行 获取与该索引对应的虚拟地址修改内核页表，将该页映射到获取到的虚拟地址更新该索引对应的pkmap_count元素的引用计数为1调用set_page_address将新的映射加入到page_address_htable中 flush_all_zero_pkmaps的工作过程： 调用flush_cache_kmaps执行高速缓存flush动作 遍历pkmap_count中的元素，如果某个元素的值为1就将其减小为0，并删除相关映射同时设置需要刷新标记 如果需要刷新，则调用flush_tlb_kernel_range刷新指定的区域对应的tlb。 解除映射kunmap用于解除kmap创建的映射，如果不是高端内存，什么都不做，否则kunmap_high将完成实际的工作。kunmap_high的工作很简单，将对应的pkmap_count中的元素的引用计数的值减1，如果新值为1，则看是否有任务在pkmap_map_wait上等待，如果有就唤醒它。根据该机制的涉及原理，该函数不能将引用计数减小到小于1，否则就是一个BUG。 临时内核映射kmap不能用于无法休眠的上线文，如果要在不可休眠的上下文调用，则需要调用kmap_atomic。它是原子的，特定于架构的。同样的只有是高端内存时才会做实际的映射。kmap_atomic使用了固定映射机制。在固定映射区域，系统中每个CPU都有一个对应的“窗口”，每个窗口对应于KM_TYPE_NR中不同的类型都有一项。这个映射的核心代码如下（取自powerpc）：12345type = kmap_atomic_idx_push();idx = type + KM_TYPE_NR*smp_processor_id();vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx); __set_pte_at(&amp;init_mm, vaddr, kmap_pte-idx, mk_pte(page, prot), 1);local_flush_tlb_page(NULL, vaddr); 固定映射区域为用于kmap_atomic预留内存区的代码如下：123456789101112enum fixed_addresses &#123; FIX_HOLE, /* reserve the top 128K for early debugging purposes */ FIX_EARLY_DEBUG_TOP = FIX_HOLE, FIX_EARLY_DEBUG_BASE = FIX_EARLY_DEBUG_TOP+((128*1024)/PAGE_SIZE)-1,#ifdef CONFIG_HIGHMEM FIX_KMAP_BEGIN, /* reserved pte&apos;s for temporary kernel mappings */ FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,#endif /* FIX_PCIE_MCFG, */ __end_of_fixed_addresses&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux内核内存管理学习之一（基本概念，分页及初始化）]]></title>
    <url>%2F2019%2F05%2F05%2Flinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%80%EF%BC%88%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%EF%BC%8C%E5%88%86%E9%A1%B5%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/goodluckwhh/article/details/9970845 概述虚拟地址空间内存是通过指针寻址的，因而CPU的字长决定了CPU所能管理的地址空间的大小，该地址空间就被称为虚拟地址空间，因此32位CPU的虚拟地址空间大小为4G，这和实际的物理内存数量无关。Linux内核将虚拟地址空间分成了两部分：一部分是用户进程可用的，这部分地址是地址空间的低地址部分，从0到TASK_SIZE，称为用户空间一部分是由内核保留使用的，这部分地址是地址空间的高地址部分,从KERNELBASE到结束，称为内核空间与之相关的一些宏：KERNELBASE：内核虚拟地址空间的起始地址，一般和PAGE_OFFSET相同，但是也可能不同PAGE_OFFSET：内核虚拟地址空间中低端内存的起始地址PHYSICAL_START：内核物理地址的起始地址MEMORY_START：内核低端内存的物理起始地址 用户进程可用的部分在进程切换时会发生改变，但是由内核保留使用的部分在进程切换时是不变的。在32位系统上，两部分的典型划分比为3:1(该比例可修改),即4G虚拟地址空间中的3G是用户进程可访问的，而另外1G是保留给内核使用的，在这种划分下用户进程可用的虚拟地址空间是0x00000000-0xbfffffff,内核的虚拟地址空间是0xc0000000-0xffffffff。不同的进程使用不同的用户空间可以使得不同进程的用户空间部分相互隔离，从而保护进程的用户空间部分。 内核空间的保护是通过CPU的特权等级实现的，所有现代CPU都提供了多个特权等级，每个特权等级可以获得的权限是不同的，当CPU处在某个权限等级时就只能执行符合这个等级的权限限制的操作。Linux使用了两个权限等级，分别对应于内核权限和用户权限，并且给属于内核的内存空间添加了权限限制，使得只有处于内核权限等级时CPU才能访问这些内存区域，这就将内核空间也保护了起来。 物理地址到虚拟地址的映射可用的物理内存会被映射到内核虚拟地址空间中。在32位系统中，内核会将一部分物理内存直接映射到内核的虚拟地址空间中，如果访问内存时所使用的虚拟地址与内核虚拟地址起始值的偏移量不超过该部分内存的大小，则该虚拟地址会被直接关联到物理页帧；否则就必须借助”高端内存“来访问，因此也可以看出之所以使用“高端内存”是因为CPU可寻址的虚拟地址可能小于实际的物理内存，因而不得不借助其它机制（“高端内存”）来访问所有的内存。在IA-32系统上，这部分空间大小为896M。 64位系统不使用高端内存，这是因为64位的系统理论上可寻址的地址空间远大于实际的物理内存（至少现在是如此），因而就不必借助“高端内存”了。而对于用户进程来说，由于它的所有内存访问都通过页表进行，不会直接进行，因而对用户进程来说也不存在高端内存之说。高端内存由32位架构的内核使用，在32位架构的内核中，要使用高端内存必须首先使用kmap将高端内存映射进内核的虚拟地址空间。 内存类型从硬件角度来说存在两种不同类型的机器，分别用不同的方式来管理内存。UMA(uniform memory access)：一致内存访问机器，它将可用内存以连续的方式组织起来。SMP系统中，每个CPU都可以以同样的速度访问内存。NUMA(non-uniform memory access)：非一致内存访问机器总是多处理器机器。系统的各个CPU都有本地内存，可以支持快速访问。系统中的所有处理器都通过总线连接起来，进而可以访问其它CPU的本地内存，但是不如访问本地内存快。 Linux中如果要支持NUMA系统，则需要打开CONFIG_NUMA选项。 内存组织linux内核对一致和不一致的内存访问系统使用了同样的数据结构，因此对于不同的内存布局，内存的管理算法几乎没有区别。对于UMA系统，将其看作只有一个NUMA节点的NUMA系统，即将其看成NUMA的特例。这样就将简化了内存管理的其它部分，其它部分都可以认为它们是在处理NUMA系统。 基本概念和相关数据结构linux引入了一个概念称为node，一个node对应一个内存bank，对于UMA系统，只有一个node。其对应的数据结构为“struct pglist_data”。对于NUMA系统来讲， 整个系统的内存由一个名为node_data 的struct pglist_data（page_data_t） 指针数组来管理。NUMA系统的内存划分如图所示： 每个node又被分成多个zone，每个zone对应一片内存区域。内核引入了枚举常量 zone_type 来描述zone的类型：123456789101112131415&lt;mmzone.h&gt;enum zone_type &#123;#ifdef CONFIG_ZONE_DMAZONE_DMA,#endif#ifdef CONFIG_ZONE_DMA32ZONE_DMA32,#endifZONE_NORMAL,#ifdef CONFIG_HIGHMEMZONE_HIGHMEM,#endifZONE_MOVABLE,MAX_NR_ZONES&#125; 它们之间的用途是不一样的： ZONE_DMA：可用作DMA的内存区域。该类型的内存区域在物理内存的低端，主要是ISA设备只能用低端的地址做DMA操作。 ZONE_NORMAL：直接被内核直接映射到自己的虚拟地址空间的地址。 ZONE_HIGHMEM：不能被直接映射到内核的虚拟地址空间的地址。 ZONE_MOVABLE：伪zone，在防止物理内存碎片机制中使用 MAX_NR_ZONES：结束标记 很显然根据内核配置项的不同，zone的类型是有变化的。每个zone都和一个数组关联在一起，该数组用于组织管理属于该zone的物理内存页。zone用数据结构struct zone来表示。所有的node都被保存在一个链表中。在使用时，内核总是尝试从与进程所运行的CPU所关联的NUMA节点申请内存。这是就要用到备用列表，每个节点都通过struct zonelist提供了备用列表，该列表包含了其它节点，可用于代替本节点进行内存分配，其顺序代表了分配的优先级，越靠前优先级越高。 阈值计算当系统中可用内存很少的时候，内核线程kswapd被唤醒，开始回收释放page。pages_min, pages_low and pages_high这些参数影响着回收行为。每个zone有三个阈值标准：pages_min, pages_low and pages_high，帮助确定zone中内存分配使用的压力状态。kswapd和这3个参数的互动关系如下图： 在最新的内核中这三个变量变成了watermark数组的成员，分别对应于WMARK_MIN，WMARK_LOW和WMARK_HIGH。内核在计算这几个值之前会首先计算一个关键参数min_free_kbytes，它是为关键性分配保留的内存空间的最小值。该关键参数有一个约束：不能小于128k，不能大于64M。其计算公式：12lowmem_kbytes = nr_free_buffer_pages() * (PAGE_SIZE &gt;&gt; 10); min_free_kbytes = int_sqrt(lowmem_kbytes * 16); 阈值的计算由init_per_zone_pages_min（ 最新内核中是init_per_zone_wmark_min）完成。该函数还会完成每个zone的lowmem_reserve的计算，该数组用于为不能失败的关键分配预留的内存页。这几个阈值的含义： page_min：如果空闲页数目小于该值，则该zone非常缺页，页面回收压力很大。page_low: 如果空闲页数目小于该值，kswapd线程将被唤醒，并开始释放回收页面。page_high: 如果空闲页面的值大于该值，则该zone的状态很完美, kswapd线程将重新休眠。 Zone等待队列表当对一个page做I/O操作的时候，page需要被锁住，以防止不正确的数据被访问。做法是：进程在访问page前，调用wait_on_page*函数，使进程加入一个等待队列（如果没有其它进程正在访问该页，就直接获得访问权限，否则加入等待队列）。当当前访问page的进程完成自己的访问动作后，会调用unlock_page唤醒在该页上wait的进程，因而进程即可获得对页的访问权。每个page都可以有一个等待队列，但是太多的分离的等待队列使得花费太多的内存访问周期。也可以让一个zone中的所有page都使用同一个队列，但是这就意味着，当一个page unlock的时候，访问这个zone里内存page的所有休眠的进程将都被唤醒，这样就会出现惊群效应（thundering herd）。内核的解决方法是将所有的队列放在struct zone数据结构中，并通过哈希表zone-&gt;wait_table来管理zone中的等待队列。哈希表的方法可能会造成一些进程不必要的唤醒，但是这个是小概率事件是可以容忍的。等待队列的哈希表的分配和建立在free_area_init_core()函数中（最终是在zone_wait_table_init()函数中）进行。 冷热页zone中的pageset用于实现冷热分配器。热页指的是已经加载到CPU高速缓存的页，这种页的访问速度比在主存中的快。冷页就是不在高速缓存中的页。SMP系统中每个CPU都有一个或多个高速缓存，各个CPU的管理必须是独立的（即便在NUMA中每个CPU也都可以访问所有的内存页，因而其高速缓存也可能缓存所有的内存页）。每个CPU都有一个struct per_cpu_pages结构，其定义如下：1234567struct per_cpu_pages &#123; int count; /* number of pages in the list */ int high; /* high watermark, emptying needed */ int batch; /* chunk size for buddy add/remove */ /* Lists of pages, one per migrate type stored on the pcp-lists */ struct list_head lists[MIGRATE_PCPTYPES]; &#125;; count：列表中页的数目high：一个阈值，如果列表中页数目超过该值，则表示列表中页太多了；没有下限的阈值，如果列表中没有成员，则重新填充。batch：如果可能，每次操作多个页，batch是每次操作页数目的参考值。lists：页列表。在这些列表中，热页放在列表头部，冷页放在尾部。 页（Page）页概念内核使用struct page作为基本单位来管理物理内存，在内核看来，所有的RAM都被划分成了固定长度的页帧。每一个页帧包含了一个页，也就是说一个页帧的长度和一个页的长度相同。页帧是主存的一部分，是一个存储区域。页和页帧的区别在于，页是抽象的数据结构，可以存放在任意地方，而页帧是真实的存储区域。struct page包含了跟踪一个物理页帧当前被用于什么的有信息。比如页面计数，标志等等。 映射页面到zone内核使用struct page的flags中的字段来保存页所属于的zone以及node。这是通过set_page_zone和set_page_node，这两个函数由函数set_page_links调用。 页表页表机制CPU管理虚拟地址，因而物理地址需要映射到虚拟地址才能给CPU使用。用于将虚拟地址空间映射到物理地址空间的数据结构称为页表。 在使用4k大小页的情况下，4k地址空间需要2的20次方个页表项。即便每个页表项大小为4字节也需要4M内存，而每个进程都需要有自己的页表，这就成了一个极大的内存开销。而且在大多数情况下，虚拟地址空间的大部分区域都是没有被使用的，因而没必要为虚拟地址空间中的每个页都分配管理结构，因而实际中采用的是如下方案： 使用多级页表，每个线性地址被看为形如“页目录表+页目录表+…+页目录表+页表+页内偏移”的形式，每个比特组按照其含义被用于在相应的表中查找数据，最终找到页表。 进程的页表只包含了它所使用的地址空间。进程不使用的地址空间不需要加入进程的页表。 只有在进程实际需要一个页表时才会给该页分配RAM，而不是在一开始就为进程的所有页都分配空间。 页表中包含了关于该页的信息，例如是否存在于主存中，是否是“脏”的，访问所需权限等级，读写标志，cache策略等等。内核的页表保存在全局变量swapper_pg_dir中，应用进程的页表保存在task_struct-&gt;mm-&gt;pgd中，在应用进程切换时，会切换进程的页表（schedule–&gt;__schedule–&gt;context_switch–&gt;switch_mm–&gt;switch_mmu_context–&gt;local_flush_tlb_mm）。linux中采用了4级分页模型。如下： PGD|PUD|PMD|PTE|OFFSET 虽然采用了4级模型，但是： 对于32位且未使能物理地址扩展的系统，使用二级页表。Linux的做法是让页上级目录表和页中间目录表所包含的比特数目为0，让页全局目录表的比特数目包含除了页表和偏移量之外的所有比特,从而取消这两级目录。同时为了让代码可以同时运行在32比特环境和64比特环境，linux保留了这两级目录在指针序列中的位置，做法是将这两级目录所包含的表项数设置为1（这里需要注意的是即便只有一个比特，也可以表示两个项，因此需要此设置）。 对于32且使能了物理地址扩展的系统，使用三级页表。 对于64位系统，取决于硬件对线性地址位的划分。 在Linux中，每个进程都有自己的页全局目录表（PGD），以及自己的页表集。当发生进程切换时，linux会完成页表的切换。使用该方案后，每个虚拟地址都划分为相应的比特分组，其中PGD用于索引每个进程所专有的页全局表，以找到PUD，PUD用于索引进程的页上级目录表，以找到PMD依次类推直到找到PTE。PTE即页表数组，该表的表项包含了指向页帧的指针以及页的访问控制相关的信息，比如权限，是否在主存中，是否包含“脏”数据等等，OFFSET用做表内偏移。使用该机制后，虚拟地址空间中不存在的内存区域对应的PUD,PMD,PTE将不被创建，这就节省了地址空间。但是使用该机制后每次寻址都需要多次查表，才能找到对应的物理地址，因而降低了速递，CPU使用高速缓存和TLB来加速寻址过程。在访问内存时，如果虚拟地址对应的TLB存在，也就是TLB 命中了，则直接访问，否则就要使用相关的页表项更新TLB（此时可能需要创建新的页表项）然后再继续进行访问。下图是一个CPU的虚拟地址到实地址的转换过程： 当被访问的地址不存在对应的TLB表项时，就会产生TLB中断。在TLB中断中，会： 首先查找访问地址对应的页表，如果找不到对应的页表，就会生成相应的页表项（powerpc通过调用读写异常的处理函数完成该过程）。 使用PTE的内容更新TLB。 在TLB的内容更新完后，仍可能产生读写异常（也就是通常说的page fault），因为页表项虽然存在，但是其内容可能是非法的（比如页表并不在内存中），。 x86架构中的页地址空间当使用x86时，必须区分以下三种不同的地址： 逻辑地址:机器语言指令仍用这种地址指定一个操作数的地址或一条指令的地址。这种寻址方式在Intel的分段结构中表现得尤为具体，它使得MS-DOS或Windows程序员把程序分为若干段。每个逻辑地址都由一个段和偏移量组成。 线性地址：线性地址是一个32位的无符号整数，可以表达高达2的32次方（4GB）的地址。通常用16进制表示线性地址，其取值范围为0x00000000～0xffffffff。 物理地址：也就是内存单元的实际地址，用于芯片级内存单元寻址。物理地址也由32位无符号整数表示。 X86中的MMU包含两个部件，一个是分段部件，一个是分页部件，分段部件（段机制）把一个逻辑地址转换为线性地址；接着，分页部件（分页机制）把一个线性地址转换为物理地址。转化过程如图所示： 分段1)分段机制在x86段机制中，逻辑地址由两部分组成，即段部分（选择符）及偏移部分。 段是形成逻辑地址到线性地址转换的基础。如果我们把段看成一个对象的话，那么对它的描述如下： 段的基地址(Base Address)：在线性地址空间中段的起始地址。 段的界限(Limit)：表示在逻辑地址中，段内可以使用的最大偏移量。 段的属性(Attribute)： 表示段的特性。例如，该段是否可被读出或写入，或者该段是否作为一个程序来执行，以及段的特权级等等。 段的界限定义逻辑地址空间中段的大小。段内在偏移量从0到limit范围内的逻辑地址，对应于从Base到Base+Limit范围内的线性地址。在一个段内，偏移量大于段界限的逻辑地址将没有意义，使用这样的逻辑地址，系统将产生异常。另外，如果要对一个段进行访问，系统会根据段的属性检查访问者是否具有访问权限，如果没有，则产生异常。例如，在80386中，如果要在只读段中进行写入，80386将根据该段的属性检测到这是一种违规操作，则产生异常。下图表示一个段如何从逻辑地址空间，重新定位到线性地址空间。图的左侧表示逻辑地址空间，定义了A，B及C三个段，段容量分别为LimitA、LimitB及LimitC。图中虚线把逻辑地址空间中的段A、B及C与线性地址空间区域连接起来表示了这种转换。 段的基地址、界限及保护属性存储在段的描述符表中，在虚拟—线性地址转换过程中要对描述符进行访问。段描述符又存储在存储器的段描述符表中，该描述符表是段描述符的一个数组。简单的说段描述符表里存储了段描述符，而段描述符又包含了硬件进行逻辑地址到线性地址转换所需的所有信息。每个段描述符都定义了线性地址空间中的一段地址，它的属性以及它和逻辑地址空间之间的映射关系，实际上是如何从逻辑地址空间映射到线性地址空间。 2)linux中的段各种段描述符都存放于段描述符表中，要么在GDT中，要么在LDT中。描述符表(即段表)定义了386系统的所有段的情况。所有的描述符表本身都占据一个字节为8的倍数的存储器空间，空间大小在8个字节(至少含一个描述符)到64K字节(至多含8K)个描述符之间。 全局描述符表(GDT)：全局描述符表GDT(Global Descriptor Table)，包含着系统中所有任务都共用的那些段的描述符。 局部描述符表(LDT)：局部描述符表LDT(local Descriptor Table)，包含了与一个给定任务有关的描述符，每个任务各自有一个的LDT。有了LDT，就可以使给定任务的代码、数据与别的任务相隔离。 每一个任务的局部描述符表LDT本身也用一个描述符来表示，称为LDT描述符，它包含了有关局部描述符表的信息，被放在全局描述符表GDT中。但是Linux很少使用分段机制，这是因为，分段和分页都能用于将物理地址划分为小的地址片段的功能，因而它们是相互冗余的。分段可以为不同的进程分配不同的线性地址空间，而分页可以将相同的线性地址空间映射到不同的物理地址空间。linux采用了分页机制，原因是： 如果所有的进程都使用相同的线性地址空间，内存管理更简单 很多其他架构的CPU对分段的支持很有限 在linux中，所有运行在用户模式的进程都使用相同的指令和数据段，因此这两个段也被成为用户数据段和用户指令段。类似的，内核使用自己的内核数据段和内核数据段。这几个段分别用宏_ _USER_CS,_ _USER_DS,_ _KERNEL_CS, and_ _KERNEL_DS定义。这些段都从0开始，并且大小都相同，因而linux中，线性地址和逻辑地址是相同的，而且内核和用户进程都可以使用相同的逻辑地址，逻辑地址也就是虚拟地址，这就和其它架构统一起来了。单处理器系统只有一个GDT，而多处理器系统中每个CPU都有一个GDT，GDT存放在cpu_gdt_table中GDT包含了用户数据段，用户指令段，内核数据段内核指令段以及一些其他段的信息。绝大多数的linux用户程序并不使用LDT，内核定义了一个缺省的LDT给大多数进程共享。它存放于default_ldt中。如果应用程序需要创建自己的局部描述附表，可以通过modify_ldt系统调用来实现。使用该系统调用创建的LDT需要自己的段。应用程序也可以通过modify_ldt来创建自己的段。 内存管理初始化初始化流程内存初始化关键是page_data_t数据结构以及其下级数据结构（zone，page）的初始化。宏NODE_DATA用于获取指定节点对应的page_data_t，在多节点系统中，节点数据结构为struct pglist_data *node_data[];该宏获取对应节点所对应的数据结构，如果是单节点系统，节点的数据结构为struct pglist_data contig_page_data;该宏直接返回它。 初始化代码流程系统启动代码中与内存管理相关的初始化代码如图： 其功能分别为： setup_arch:架构相关的初始化，其中包括了内存管理中与架构相关部分的初始化。boot分配器在这个时候被初始化。 setup_per_cpu_areas:SMP中，该函数初始化源代码中静态定义的每CPU变量，该类变量对系统中每一个CPU都一个副本。此类变量保存在内核二进制影响的一个独立的段中。 build_all_zonelists:建立节点和zone的数据结构 mem_init:初始化内存分配器 setup_per_cpu_pageset:遍历系统中所有的zone，对于每一个zone为所有的CPU分配pageset（冷热页缓存）并进行初始化，在这个函数被调用之前，只有boot pagesets可用。 节点和zone的初始化build_all_zonelists会遍历系统中所有的节点，并为每个节点的内存域生成数据结构。它最终会使用节点数据结构调用build_zonelists，该函数会在该节点和系统中其它节点的内存之间建立一种距离关系，距离表达的是从其它节点分配的代价，因而距离越大，分配代价也越大；之后的内存分配会依据这种距离进行，优先选择本地的，如果本地的不可用，则按照距离从近到远来分配，直到成功或者所有的都失败。在一个节点的内存域中： 高端内存被看做是最廉价的，因为内核不依赖于高端内存，它被耗尽不会对系统有不良影响 DMA看做是最昂贵的，因为它有特殊用途，它用于和外设交互数据 普通内存介于两者之间，因为内核有些部分是依赖于普通内存的，所以它耗尽对系统会有影响 当分配内存时，假设指定的内存区域的昂贵程度为A，则分配过程为： 首先尝试从本节点分配，并且是按照昂贵程度递增的顺序从A开始尝试，直到最昂贵的区域 如果从本节点分配失败，则按照距离关系依次检查其它几点，在检查每个节点时，仍是按照昂贵程度递增的顺序从A开始尝试，直到最昂贵的区域 特定于体系结构的设置内核在内存中的布局在启动装载器将内核复制到内存，并且初始化代码的汇编部分执行完后，内存布局如图所示： 这是一种默认布局，也存在一些例外： PHYSICAL_START可用于配置修改内核在内存中的位置。 内核可以被编译为可重定位二进制程序，此时由启动装载器决定内核的位置。 默认情况下，内核安装在RAM中从物理地址0x00100000开始的地方。也就是第2M开始的那个。没有安装在第1M地址空间开始的地方的原因： 页帧0由BIOS使用，存在上电自检（POST）期间检查到的系统硬件配置。 物理地址从0x000a0000到0x000fffff的范围通常保留给BIOS程序使用 第一个MB内的其它页帧可能由特定计算机模型保留 从_edata到_end之间的初始化数据部分所占用的内存在初始化完成后有些是不再需要的，可以回收利用，可以控制哪些部分可以回收，哪些部分不能回收。内核占用的内存分为几段，其边界保存在变量中，可以通过System.map查看相关的信息，在系统启动后也可以通过/proc/iomem查看相关的信息。 初始化步骤在start_kernel，在其中会调用setup_arch来进行架构相关的初始化。setup_arch会完成启动分配器的初始化以及各个内存域的初始化（paging_init）。paging_init最终会调用free_area_init_node这是个架构无关的函数，它会完成节点以及zone的数据结构的初始化。 分页机制初始化Linux内核将虚拟地址空间分成了两部分：用户空间和内核空间。用户进程可用的部分在进程切换时会发生改变，但是由内核保留使用的部分在进程切换时是不变的。在32位系统上，两部分的典型划分比为3:1(该比例可修改),即4G虚拟地址空间中的3G是用户进程可访问的，而另外1G是保留给内核使用的。32位系统中，内核地址空间又被分为几部分，其图示如下： 直接映射其中第一部分用于将一部分物理内存直接映射到内核的虚拟地址空间中，如果访问内存时所使用的虚拟地址与内核虚拟地址起始值的偏移量不超过该部分内存的大小，则该虚拟地址会被直接关联到物理页帧；否则就必须借助”高端内存“来访问,在IA-32系统上，这部分空间大小为896M。对于直接映射部分的内存，内核提供了两个宏： __pa(vaddr)：用于返回与虚拟地址vaddr相对应的物理地址。 __va(paddr)：用于返回和物理地址paddr相对应的虚拟地址。 剩余部分被内核用作其它用途：虚拟地址中连续，但是物理地址不连续的内存区域可以从VMALLO区域分配。该机制通常用于用户进程，内核自己会尽量尝试使用连续的物理地址。当然，当直接映射部分不能满足需求时，内核也会使用该区域。在ppc32中ioremap就使用了该区域。持久映射区域用于将高端内存中的非持久页映射到内核中。固定映射用于与物理地址空间中的固定页关联的虚拟地址页，但是物理地址页即页帧可以自由选择。内存的各个区域边界由图中所示的常数定义。high_memory定义了直接映射区域的边界。系统中定义了与页相关的一些常量： num_physpages：最高可用页帧的页帧号 totalram_pages：可用页帧的总数目 min_low_pfn：RAM中在内核映像之后的第一个可用的页帧号 max_pfn：最后一个可用的页帧号 max_low_pfn：被内核直接映射的最后一个页帧的页帧号（低端内存中） totalhigh_pages：没有被内核直接映射的页帧的总数（高端内存中） 在直接映射的内存区域和用于vmalloc的内存区域之间有一个大小为VMALLOC_OFFSET的缺口，它用于对内核进行地址保护，防止内核进行越界访问（越过了直接映射区域）。 vmalloc区vmalloc区域的起始位置取决于high_memory和VMALLOC_OFFSET。而其结束位置则取决于是否启用了高端内存支持。如果没有启用高端内存支持，就不需要持久映射区域，因为所有内存都可以直接映射。 持久映射区持久映射页则开始于PKMAP_BASE，其大小由LAST_PKMAP表示有多少个页。 固定映射区固定映射开始于FIXADDR_START结束于FIXADDR_END。这部分区域指向物理内存的随机位置。在该映射中，虚拟地址和物理地址之间的关联是可以自由定义的，但是定义后就不能更改。该区域一直延伸到虚拟地址空间的顶端。 固定映射的优势在于编译时，对该类地址的处理类似于常数，内核一旦启动即为它分配了物理地址。对此类地址的引用比普通指针要快。在上下文切换期间，内核不会将对应于固定地址映射的TLB刷新出去，因此对这类地址的访问总是通过高速缓存。对于每一个固定地址，都必须创建一个常数并添加到称为fixed_addresses的枚举列表里。内核提供了virt_to_fix和fix_to_virt用于虚拟地址和固定地址常数之间的转换。set_fixmap用于建立固定地址常量和物理页之间的对应关系。 冷热页free_area_init_node最终会调到zone_pcp_init，它会为该zone计算一个batch值。而setup_per_cpu_pageset则会完成冷热缓存的初始化。 启动过程中的内存管理bootmem分配器用于内核在启动过程中分配和内存。这是一个很简单的最先适配的分配器。它使用位图来管理页面，比特1表示页忙，0表示空闲。需要分配内存时就扫描位图，直到找到第一个能够满足需求的内存区域。 数据结构:内核为每个节点都分配了一个struct bootmem_data结构的实例用来管理该node的内存。 初始化:在不同的架构下初始化的代码不尽相同，但是都是在paging_int中被调用。 分配器接口:alloc_bootmem用于分配内存free_bootmem用于释放内存 停用bootmem分配器:当slab系统完成初始化，能够承担内存分配工作时，需要停掉该分配器，这是通过free_all_bootmem(UMA系统)或free_all_bootmem_node(NUMA系统)来完成的 释放初始化数据:内核提供了两个属性init用于标记初始化函数，initdata用于标记初始化数据，这意味着这个函数/数据在初始化完成后其内存就不需了，可以进行回收利用。 内核页表的初始化以powerpc为例，内核页表的初始化由MMU_init来完成，它在start_kernel之前被调用：1MMU_init-&gt;mapin_ram-&gt;__mapin_ram_chunk-&gt;map_page, map_page的代码如下：12345678910111213141516171819202122int map_page(unsigned long va, phys_addr_t pa, int flags)&#123; pmd_t *pd; pte_t *pg; int err = -ENOMEM; /* Use upper 10 bits of VA to index the first level map */ pd = pmd_offset(pud_offset(pgd_offset_k(va), va), va); /* Use middle 10 bits of VA to index the second-level map */ pg = pte_alloc_kernel(pd, va); if (pg != 0) &#123; err = 0; /* The PTE should never be already set nor present in the * hash table */ BUG_ON((pte_val(*pg) &amp; (_PAGE_PRESENT | _PAGE_HASHPTE)) &amp;&amp; flags); set_pte_at(&amp;init_mm, va, pg, pfn_pte(pa &gt;&gt; PAGE_SHIFT, __pgprot(flags))); &#125; return err;&#125; 再看下init_mm的相关定义：12345678910struct mm_struct init_mm = &#123; .mm_rb = RB_ROOT, .pgd = swapper_pg_dir, .mm_users = ATOMIC_INIT(2), .mm_count = ATOMIC_INIT(1), .mmap_sem = __RWSEM_INITIALIZER(init_mm.mmap_sem), .page_table_lock = __SPIN_LOCK_UNLOCKED(init_mm.page_table_lock), .mmlist = LIST_HEAD_INIT(init_mm.mmlist), INIT_MM_CONTEXT(init_mm)&#125;; 因此可见，kernel的页表是保存在swapper_pg_dir中的。它是init_task的active_mm：1234567891011121314#define INIT_TASK(tsk) \&#123; \ .state = 0, \ .stack = &amp;init_thread_info, \ .usage = ATOMIC_INIT(2), \ .flags = PF_KTHREAD, \ .prio = MAX_PRIO-20, \ .static_prio = MAX_PRIO-20, \ .normal_prio = MAX_PRIO-20, \ .policy = SCHED_NORMAL, \ .cpus_allowed = CPU_MASK_ALL, \ .nr_cpus_allowed= NR_CPUS, \ .mm = NULL, \ .active_mm = &amp;init_mm, \ 1truct task_struct init_task = INIT_TASK(init_task); init_task是内核代码开始位置被执行的：1234567/* * This is where the main kernel code starts. */start_here: /* ptr to current */ lis r2,init_task@h ori r2,r2,init_task@l start_here在start_kernel之前被执行。在start_kernel里rest_init会启动kernel_init来启动一个init进程，init_task并不是init进程，init_task是内核启动主代码所在的上下文，该进程最后停在了cpu_idle中（start_kernel-&gt;rest_init-&gt;cpu_idle），好吧，它的真面目出来了，它就是创世界的进程，并且最后变成了无所事事的idle了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解C++的动态绑定和静态绑定]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3cpp%E7%9A%84%E5%8A%A8%E6%80%81%E7%BB%91%E5%AE%9A%E5%92%8C%E9%9D%99%E6%80%81%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/chgaowei/article/details/6427731 为了支持c++的多态性，才用了动态绑定和静态绑定。理解他们的区别有助于更好的理解多态性，以及在编程的过程中避免犯错误。需要理解四个名词：1、对象的静态类型：对象在声明时采用的类型。是在编译期确定的。2、对象的动态类型：目前所指对象的类型。是在运行期决定的。对象的动态类型可以更改，但是静态类型无法更改。关于对象的静态类型和动态类型，看一个示例：12345678910111213class B&#123;&#125;class C : public B&#123;&#125;class D : public B&#123;&#125;D* pD = new D();//pD的静态类型是它声明的类型D*，动态类型也是D*B* pB = pD;//pB的静态类型是它声明的类型B*，动态类型是pB所指向的对象pD的类型D*C* pC = new C();pB = pC;//pB的动态类型是可以更改的，现在它的动态类型是C* 3、静态绑定：绑定的是对象的静态类型，某特性（比如函数）依赖于对象的静态类型，发生在编译期。4、动态绑定：绑定的是对象的动态类型，某特性（比如函数）依赖于对象的动态类型，发生在运行期。1234567891011121314151617class B&#123; void DoSomething(); virtual void vfun();&#125;class C : public B&#123; void DoSomething();//首先说明一下，这个子类重新定义了父类的no-virtual函数，这是一个不好的设计，会导致名称遮掩；这里只是为了说明动态绑定和静态绑定才这样使用。 virtual void vfun();&#125;class D : public B&#123; void DoSomething(); virtual void vfun();&#125;D* pD = new D();B* pB = pD; 让我们看一下，pD-&gt;DoSomething()和pB-&gt;DoSomething()调用的是同一个函数吗？不是的，虽然pD和pB都指向同一个对象。因为函数DoSomething是一个no-virtual函数，它是静态绑定的，也就是编译器会在编译期根据对象的静态类型来选择函数。pD的静态类型是D，那么编译器在处理pD-&gt;DoSomething()的时候会将它指向D::DoSomething()。同理，pB的静态类型是B，那pB-&gt;DoSomething()调用的就是B::DoSomething()。 让我们再来看一下，pD-&gt;vfun()和pB-&gt;vfun()调用的是同一个函数吗？是的。因为vfun是一个虚函数，它动态绑定的，也就是说它绑定的是对象的动态类型，pB和pD虽然静态类型不同，但是他们同时指向一个对象，他们的动态类型是相同的，都是D*，所以，他们的调用的是同一个函数：D::vfun()。 上面都是针对对象指针的情况，对于引用（reference）的情况同样适用。 指针和引用的动态类型和静态类型可能会不一致，但是对象的动态类型和静态类型是一致的。D D;D.DoSomething()和D.vfun()永远调用的都是D::DoSomething()和D::vfun()。 我总结了一句话：只有虚函数才使用的是动态绑定，其他的全部是静态绑定。目前我还没有发现不适用这句话的，如果有错误，希望你可以指出来。 特别需要注意的地方 当缺省参数和虚函数一起出现的时候情况有点复杂，极易出错。我们知道，虚函数是动态绑定的，但是为了执行效率，缺省参数是静态绑定的。123456789101112class B&#123; virtual void vfun(int i = 10);&#125;class D : public B&#123; virtual void vfun(int i = 20);&#125;D* pD = new D();B* pB = pD;pD-&gt;vfun();pB-&gt;vfun(); 有上面的分析可知pD-&gt;vfun()和pB-&gt;vfun()调用都是函数D::vfun()，但是他们的缺省参数是多少？分析一下，缺省参数是静态绑定的，pD-&gt;vfun()时，pD的静态类型是D*，所以它的缺省参数应该是20；同理，pB-&gt;vfun()的缺省参数应该是10。编写代码验证了一下，正确。对于这个特性，估计没有人会喜欢。所以，永远记住：“绝不重新定义继承而来的缺省参数（Never redefine function’s inherited default parameters value.）” 关于c++语言目前我基本上都是在c++的子集“面向对象编程”下工作，对于更复杂的知识了解的还不是很多。即便如此，到目前为止编程时需要注意的东西已经很多，而且后面可能还会继续增多，这也许是很多人反对c++的原因。c++是Google的四大官方语言之一。但是Google近几年确推出了go语言，而且定位是和c/c++相似。考虑这种情况，我认为可能是Google的程序员们深感c++的复杂，所以想开发一种c++的替代语言。有时间要了解一下go语言，看它在类似c++的问题上时如何取舍的。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fork()----父子进程共享]]></title>
    <url>%2F2019%2F05%2F05%2Ffork----%E7%88%B6%E5%AD%90%E8%BF%9B%E7%A8%8B%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[fork（）会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。在fork之后exec之前两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间，如果不是因为exec，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而代码段继续共享父进程的物理空间（两者的代码完全相同）。而如果是因为exec，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。 fork之后内核会通过将子进程放在队列的前面，以让子进程先执行，以免父进程执行导致写时复制，而后子进程执行exec系统调用，因无意义的复制而造成效率的下降。fork时子进程获得父进程数据空间、堆和栈的复制，所以变量的地址（当然是虚拟地址）也是一样的。 每个进程都有自己的虚拟地址空间，不同进程的相同的虚拟地址显然可以对应不同的物理地址。因此地址相同（虚拟地址）而值不同没什么奇怪。具体过程是这样的：fork子进程完全复制父进程的栈空间，也复制了页表，但没有复制物理页面，所以这时虚拟地址相同，物理地址也相同，但是会把父子共享的页面标记为“只读”（类似mmap的private的方式），如果父子进程一直对这个页面是同一个页面，知道其中任何一个进程要对共享的页面“写操作”，这时内核会复制一个物理页面给这个进程使用，同时修改页表。而把原来的只读页面标记为“可写”，留给另外一个进程使用。 这就是所谓的“写时复制”。正因为fork采用了这种写时复制的机制，所以fork出来子进程之后，父子进程哪个先调度呢？内核一般会先调度子进程，因为很多情况下子进程是要马上执行exec，会清空栈、堆。。这些和父进程共享的空间，加载新的代码段。。。，这就避免了“写时复制”拷贝共享页面的机会。如果父进程先调度很可能写共享页面，会产生“写时复制”的无用功。所以，一般是子进程先调度滴。 子进程与父进程之间除了代码是共享的之外，堆栈数据和全局数据均是独立的。 pid = fork()返回两次，第一次父进程，第二次子进程：123[root@localhost timetest]# ./testThis is parent process: 4016This is child process: 4017 注意：这里不是绝对的先返回父进程的pid，具体先执行那个进程，要看操作系统的进程调度算法。 操作系统创建一个新的进程（子进程），并且在进程表中相应为它建立一个新的表项。新进程和原有进程的可执行程序是同一个程序；上下文和数据，绝大部分就是原进程（父进程）的拷贝，但它们是两个相互独立的进程！此时程序寄存器pc，在父、子进程的上下文中都声称，这个进程目前执行到fork调用即将返回（此时子进程不占有CPU，子进程的pc不是真正保存在寄存器中，而是作为进程上下文保存在进程表中的对应表项内）。问题是怎么返回，在父子进程中就分道扬镳。 父进程继续执行，操作系统对fork的实现，使这个调用在父进程中返回刚刚创建的子进程的pid（一个正整数），所以下面的if语句中pid&lt;0, pid==0的两个分支都不会执行。所以输出i am the parent process… 子进程在之后的某个时候得到调度，它的上下文被换入，占据 CPU，操作系统对fork的实现，使得子进程中fork调用返回0。所以在这个进程（注意这不是父进程了哦，虽然是同一个程序，但是这是同一个程序的另外一次执行，在操作系统中这次执行是由另外一个进程表示的，从执行的角度说和父进程相互独立）中pid=0。这个进程继续执行的过程中，if语句中 pid&lt;0不满足，但是pid= =0是true。所以输出i am the child process… 为什么看上去程序中互斥的两个分支都被执行了？在一个程序的一次执行中，这当然是不可能的；但是你看到的两行输出是来自两个进程，这两个进程来自同一个程序的两次执行。 fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，但只有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。 可以这样想象，2个进程一直同时运行，而且步调一致，在fork之后，他们分别作不同的工作，也就是分岔了。这也是fork为什么叫fork的原因。 在程序段里用了fork()之后程序出了分岔，派生出了两个进程。具体哪个先运行就看该系统的调度算法了。 如果需要父子进程协同，可以通过原语的办法解决。 父进程为什么要创建子进程呢? 前面我们已经说过了Linux是一个多用户操作系统,在同一时间会有许多的用户在争夺系统的资源.有时进程为了早一点完成任务就创建子进程来争夺资源. 一旦子进程被创建,父子进程一起从fork处继续执行,相互竞争系统的资源.有时候我们希望子进程继续执行,而父进程阻塞,直到子进程完成任务.这个时候我们可以调用wait或者waitpid系统调用. ,对子进程来说，fork返回给它0,但它的pid绝对不会是0；之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid； fork之后父子进程除非采用了同步手段，否则不能确定谁先运行，也不能确定谁先结束。认为子进程结束后父进程才从fork返回的，这是不对的，fork不是这样的，vfork才这样。 为什么返回0呢 首先必须有一点要清楚，函数的返回值是储存在寄存器eax中的。其次，当fork返回时，新进程会返回0是因为在初始化任务结构时，将eax设置为0；在fork中，把子进程加入到可运行的队列中，由进程调度程序在适当的时机调度运行。也就是从此时开始，当前进程分裂为两个并发的进程。无论哪个进程被调度运行，都将继续执行fork函数的剩余代码，执行结束后返回各自的值。 【NOTE5】对于fork来说，父子进程共享同一段代码空间，所以给人的感觉好像是有两次返回，其实对于调用fork的父进程来说，如果fork出来的子进程没有得到调度，那么父进程从fork系统调用返回，同时分析sys_fork知道，fork返回的是子进程的id。再看fork出来的子进程，由 copy_process函数可以看出，子进程的返回地址为ret_from_fork（和父进程在同一个代码点上返回），返回值直接置为0。所以当子进程得到调度的时候，也从fork返回，返回值为0。关键注意两点：1.fork返回后，父进程或子进程的执行位置。（首先会将当前进程eax的值做为返回值）2.两次返回的pid存放的位置。（eax中） 进程调用copy_process得到lastpid的值（放入eax中，fork正常返回后，父进程中返回的就是lastpid）子进程任务状态段tss的eax被设置成0，fork.c 中p-&gt;tss.eax=0;（如果子进程要执行就需要进程切换，当发生切换时，子进程tss中的eax值就调入eax寄存器，子进程执行时首先会将eax的内容做为返回值）当子进程开始执行时，copy_process返回eax的值。fork()后,就是两个任务同时进行,父进程用他的tss,子进程用自己的tss,在切换时,各用各的eax中的值. 所以，“一次调用两次返回”是2个不同的进程！看这一句：pid＝fork()当执行这一句时，当前进程进入fork()运行，此时，fork()内会用一段嵌入式汇编进行系统调用：int 0x80（具体代码可参见内核版本0.11的unistd.h文件的133行_syscall0函数）。这时进入内核根据此前写入eax的系统调用功能号便会运行sys_fork系统调用。接着，sys_fork中首先会调用C函数find_empty_process产生一个新的进程，然后会调用C函数 copy_process将父进程的内容复制给子进程，但是子进程tss中的eax值赋值为0（这也是为什么子进程中返回0的原因），当赋值完成后， copy_process会返回新进程（该子进程）的pid，这个值会被保存到eax中。这时子进程就产生了，此时子进程与父进程拥有相同的代码空间，程序指针寄存器eip指向相同的下一条指令地址，当fork正常返回调用其的父进程后，因为eax中的值是新创建的子进程号，所以，fork()返回子进程号，执行else（pid&gt;0）;当产生进程切换运行子进程时，首先会恢复子进程的运行环境即装入子进程的tss任务状态段，其中的eax 值(copy_process中置为0)也会被装入eax寄存器，所以，当子进程运行时，fork返回的是0执行if(pid==0)。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux线程切换和进程切换的方法]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[进程切换分两步： 切换页目录以使用新的地址空间 切换内核栈和硬件上下文 对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。 切换的性能消耗： 线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。 另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。 系统调用：处于进程上下文 系统调用是在进程上下文中,并没有tasklet之类的延迟运行,系统调用本身可以休眠,这些可以参见内核代码 虽然系统调用实与其他中断实现有点类似,通过IDT表查找入口处理函数,但是系统调用与其他中断最大的不同是,系统调用是代表当前进程执行的,所以current宏/task_struct是有意义的,这个休眠可以被唤醒 系统调用，异常，中断（其中中断是异步时钟，异常时同步时钟），也可以把系统调用成为异常 中断上下文：在中断中执行时依赖的环境，就是中断上下文（不包括系统调用，是硬件中断） 进程上下文：当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文 首先，这两个上下文都处于内核空间。 其次，两者的区别在于，进程上下文与当前执行进程密切相关，而中断上下文在逻辑上与进程没有关系。 进程上下文主要是异常处理程序和内核线程。内核之所以进入进程上下文是因为进程自身的一些工作需要在内核中做。例如，系统调用是为当前进程服务的，异常通常是处理进程导致的错误状态等。所以在进程上下文中引用current是有意义的。 内核进入中断上下文是因为中断信号而导致的中断处理或软中断。而中断信号的发生是随机的，中断处理程序及软中断并不能事先预测发生中断时当前运行的是哪个进程，所以在中断上下文中引用current是可以的，但没有意义。事实上，对于A进程希望等待的中断信号，可能在B进程执行期间发生。例如，A进程启动写磁盘操作，A进程睡眠后现在时B进程在运行，当磁盘写完后磁盘中断信号打断的是B进程，在中断处理时会唤醒A进程。 上下文这个词会让人想到进程的CPU寄存器状态，但好像进入进程上下文（异常处理系统调用）和进入中断上下文（中断处理），内核所做的工作没有太大区别。所以，这两个上下文的主要区别，我认为在于是否与进程相关。 运行于进程上下文的内核代码是可抢占的，但中断上下文则会一直运行至结束，不会被抢占。因此，内核会限制中断上下文的工作，不允许其执行如下操作： (1) 进入睡眠状态或主动放弃CPU; 由于中断上下文不属于任何进程，它与current没有任何关系（尽管此时current指向被中断的进程），所以中断上下文一旦睡眠或者放弃CPU，将无法被唤醒。所以也叫原子上下文（atomic context）。 (2) 占用互斥体; 为了保护中断句柄临界区资源，不能使用mutexes。如果获得不到信号量，代码就会睡眠，会产生和上面相同的情况，如果必须使用锁，则使用spinlock。 (3) 执行耗时的任务; 中断处理应该尽可能快，因为内核要响应大量服务和请求，中断上下文占用CPU时间太长会严重影响系统功能。在中断处理例程中执行耗时任务时，应该交由中断处理例程底半部来处理。 (4) 访问用户空间虚拟内存。 因为中断上下文是和特定进程无关的，它是内核代表硬件运行在内核空间，所以在中断上下文无法访问用户空间的虚拟地址 (5) 中断处理例程不应该设置成reentrant（可被并行或递归调用的例程）。 因为中断发生时，preempt和irq都被disable，直到中断返回。所以中断上下文和进程上下文不一样，中断处理例程的不同实例，是不允许在SMP上并发运行的。 (6)中断处理例程可以被更高级别的IRQ中断。（不能嵌套中断）使用软中断，上部分关中断，也就是禁止嵌套，下半部分使用软中断 如果想禁止这种中断，可以将中断处理例程定义成快速处理例程，相当于告诉CPU，该例程运行时，禁止本地CPU上所有中断请求。这直接导致的结果是，由于其他中断被延迟响应，系统性能下降。 软中断是一种延时机制，代码执行的优先级比进程要高，比硬中断要低。相比于硬件中断，软中段是在开中断的环境中执行的（长时间关中断对系统的开销太大）， 代码是执行在中断/线程上下文的，是不能睡眠的，虽然每个cpu都有一个对应的ksoftirqd/n线程来执行软中断，但是do_softirq这个函数也还会在中断退出时调用到，因此不能睡眠(中断上下文不能睡眠的原因是由于调度系统是以进程为基本单位的，调度时会把当前进程的上下文保存在task_struct这个数据结构中，当进程被调度重新执行时会找到执行的断点，但是中断上下文是没有特定task_struct结构体的，当然现在有所谓的线程话中断，可以满足在中断处理函数执行阻塞操作，但是实时性可能会有问题。还有就是中断代表当前进程执行的概念，个人感觉有点扯淡，毕竟整个内核空间是由所有进程共享的，不存在代表的概念) 上面我们介绍的可延迟函数运行在中断上下文中（软中断的一个检查点就是do_IRQ退出的时候），于是导致了一些问题：软中断不能睡眠、不能阻塞。由于中断上下文出于内核态，没有进程切换，所以如果软中断一旦睡眠或者阻塞，将无法退出这种状态，导致内核会整个僵死。但可阻塞函数不能用在中断上下文中实现，必须要运行在进程上下文中，例如访问磁盘数据块的函数。因此，可阻塞函数不能用软中断来实现。但是它们往往又具有可延迟的特性。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存管理之mmap详解]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8Bmmap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/caogenwangbaoqiang/article/details/80780106 mmap系统调用mmap系统调用mmap将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零。munmap执行相反的操作，删除特定地址区域的对象映射。 当使用mmap映射文件到进程后,就可以直接操作这段虚拟地址进行文件的读写等操作,不必再调用read,write等系统调用.但需注意,直接对该段内存写时不会写入超过当前文件大小的内容. 采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 基于文件的映射，在mmap和munmap执行过程的任何时刻，被映射文件的st_atime可能被更新。如果st_atime字段在前述的情况下没有得到更新，首次对映射区的第一个页索引时会更新该字段的值。用PROT_WRITE 和 MAP_SHARED标志建立起来的文件映射，其st_ctime 和 st_mtime在对映射区写入之后，但在msync()通过MS_SYNC 和 MS_ASYNC两个标志调用之前会被更新。 用法：123void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *start, size_t length); 返回说明： 成功执行时，mmap()返回被映射区的指针，munmap()返回0。失败时，mmap()返回MAP_FAILED[其值为(void *)-1]，munmap返回-1。errno被设为以下的某个值1234567891011EACCES：访问出错EAGAIN：文件已被锁定，或者太多的内存已被锁定EBADF：fd不是有效的文件描述词EINVAL：一个或者多个参数无效ENFILE：已达到系统对打开文件的限制ENODEV：指定文件所在的文件系统不支持内存映射ENOMEM：内存不足，或者进程已超出最大内存映射数量EPERM：权能不足，操作不允许ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志SIGSEGV：试着向只读区写入SIGBUS：试着访问不属于进程的内存区 参数： start：映射区的开始地址。length：映射区的长度。prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起PROT_EXEC //页内容可以被执行PROT_READ //页内容可以被读取PROT_WRITE //页可以被写入PROT_NONE //页不可访问flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体MAP_FIXED //使用指定的映射起始地址，如果由start和len参数指定的内存区重叠于现存的映射空间，重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。并且起始地址必须落在页的边界上。MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。MAP_PRIVATE //建立一个写入时拷贝的私有映射。内存区域的写入不会影响到原文件。这个标志和以上标志是互斥的，只能使用其中一个。MAP_DENYWRITE //这个标志被忽略。MAP_EXECUTABLE //同上MAP_NORESERVE //不要为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号。MAP_LOCKED //锁定映射区的页面，从而防止页面被交换出内存。MAP_GROWSDOWN //用于堆栈，告诉内核VM系统，映射区可以向下扩展。MAP_ANONYMOUS //匿名映射，映射区不与任何文件关联。MAP_ANON //MAP_ANONYMOUS的别称，不再被使用。MAP_FILE //兼容标志，被忽略。MAP_32BIT //将映射区放在进程地址空间的低2GB，MAP_FIXED指定时会被忽略。当前这个标志只在x86-64平台上得到支持。MAP_POPULATE //为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞。MAP_NONBLOCK //仅和MAP_POPULATE一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口。fd：有效的文件描述词。如果MAP_ANONYMOUS被设定，为了兼容问题，其值应为-1。offset：被映射对象内容的起点。 系统调用munmap()int munmap( void * addr, size_t len )该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小。当映射关系解除后，对原来映射地址的访问将导致段错误发生。 系统调用msync()int msync ( void * addr , size_t len, int flags)一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 系统调用mmap()用于共享内存的两种方式：使用普通文件提供的内存映射适用于任何进程之间；此时，需要打开或创建一个文件，然后再调用mmap()；典型调用代码如下：1234fd=open(name, flag, mode); if(fd&lt;0) … ptr=mmap(NULL, len , PROT_READ|PROT_WRITE, MAP_SHARED , fd , 0); 通过mmap()实现共享内存的通信方式有许多特点和要注意的地方 使用特殊文件提供匿名内存映射适用于具有亲缘关系的进程之间；由于父子进程特殊的亲缘关系，在父进程中先调用mmap()，然后调用fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区域进行通信了。注意，这里不是一般的继承关系。一般来说，子进程单独维护从父进程继承下来的一些变量。而mmap()返回的地址，却由父子进程共同维护。对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。此时，不必指定具体的文件，只要设置相应的标志即可. mmap进行内存映射的原理mmap系统调用的最终目的是将,设备或文件映射到用户进程的虚拟地址空间,实现用户进程对文件的直接读写,这个任务可以分为以下三步: 在用户虚拟地址空间中寻找空闲的满足要求的一段连续的虚拟地址空间,为映射做准备(由内核mmap系统调用完成) 每个进程拥有3G字节的用户虚存空间。但是，这并不意味着用户进程在这3G的范围内可以任意使用，因为虚存空间最终得映射到某个物理存储空间（内存或磁盘空间），才真正可以使用。 那么，内核怎样管理每个进程3G的虚存空间呢？概括地说，用户进程经过编译、链接后形成的映象文件有一个代码段和数据段（包括data段和bss段），其中代码段在下，数据段在上。数据段中包括了所有静态分配的数据空间，即全局变量和所有申明为static的局部变量，这些空间是进程所必需的基本要求，这些空间是在建立一个进程的运行映像时就分配好的。除此之外，堆栈使用的空间也属于基本要求，所以也是在建立进程时就分配好的. 在内核中,这样每个区域用一个结构struct vm_area_struct 来表示.它描述的是一段连续的、具有相同访问属性的虚存空间，该虚存空间的大小为物理内存页面的整数倍。可以使用 cat /proc//maps来查看一个进程的内存使用情况,pid是进程号.其中显示的每一行对应进程的一个vm_area_struct结构. 下面是struct vm_area_struct结构体的定义：12345678910111213141516171819202122/* This struct defines a memory VMM memory area. */ struct vm_area_struct &#123; struct mm_struct * vm_mm; /* VM area parameters */ unsigned long vm_start; unsigned long vm_end; /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next; pgprot_t vm_page_prot; unsigned long vm_flags; /* AVL tree of VM areas per task, sorted by address */ short vm_avl_height; struct vm_area_struct * vm_avl_left; struct vm_area_struct * vm_avl_right; /* For areas with an address space and backing store, vm_area_struct *vm_next_share; struct vm_area_struct **vm_pprev_share; struct vm_operations_struct * vm_ops; unsigned long vm_pgoff; /* offset in PAGE_SIZE units, not PAGE_CACHE_SIZE */ struct file * vm_file; unsigned long vm_raend; void * vm_private_data; /* was vm_pte (shared mem) */ &#125;; 通常，进程所使用到的虚存空间不连续，且各部分虚存空间的访问属性也可能不同。所以一个进程的虚存空间需要多个vm_area_struct结构来描述。在vm_area_struct结构的数目较少的时候，各个vm_area_struct按照升序排序，以单链表的形式组织数据（通过vm_next指针指向下一个vm_area_struct结构）。但是当vm_area_struct结构的数据较多的时候，仍然采用链表组织的化，势必会影响到它的搜索速度。针对这个问题，vm_area_struct还添加了vm_avl_hight（树高）、vm_avl_left（左子节点）、vm_avl_right（右子节点）三个成员来实现AVL树，以提高vm_area_struct的搜索速度。 假如该vm_area_struct描述的是一个文件映射的虚存空间，成员vm_file便指向被映射的文件的file结构，vm_pgoff是该虚存空间起始地址在vm_file文件里面的文件偏移，单位为物理页面。 因此,mmap系统调用所完成的工作就是准备这样一段虚存空间,并建立vm_area_struct结构体,将其传给具体的设备驱动程序. 建立虚拟地址空间和文件或设备的物理地址之间的映射(设备驱动完成) 建立文件映射的第二步就是建立虚拟地址和具体的物理地址之间的映射,这是通过修改进程页表来实现的.mmap方法是file_opeartions结构的成员: int (mmap)(struct file ,struct vm_area_struct *); linux有2个方法建立页表: (1) 使用remap_pfn_range一次建立所有页表. int remap_pfn_range(struct vm_area_struct *vma, unsigned long virt_addr, unsigned long pfn, unsigned long size, pgprot_t prot); 返回值: 成功返回 0, 失败返回一个负的错误值参数说明: vma 用户进程创建一个vma区域virt_addr 重新映射应当开始的用户虚拟地址. 这个函数建立页表为这个虚拟地址范围从 virt_addr 到 virt_addr_size.pfn 页帧号, 对应虚拟地址应当被映射的物理地址. 这个页帧号简单地是物理地址右移 PAGE_SHIFT 位. 对大部分使用, VMA 结构的 vm_paoff 成员正好包含你需要的值. 这个函数影响物理地址从 (pfn&lt;&lt;&lt; span=”” style=”word-wrap: break-word;”&gt;size 正在被重新映射的区的大小, 以字节.prot 给新 VMA 要求的”protection”. 驱动可(并且应当)使用在vma-&gt;vm_page_prot 中找到的值. (2) 使用nopage VMA方法每次建立一个页表项.1struct page *(*nopage)(struct vm_area_struct *vma, unsigned long address, int *type); 返回值: 成功则返回一个有效映射页,失败返回NULL. 参数说明: address 代表从用户空间传过来的用户空间虚拟地址. 返回一个有效映射页. (3) 使用方面的限制： remap_pfn_range不能映射常规内存，只存取保留页和在物理内存顶之上的物理地址。因为保留页和在物理内存顶之上的物理地址内存管理系统的各个子模块管理不到。640 KB 和 1MB 是保留页可能映射，设备I/O内存也可以映射。如果想把kmalloc()申请的内存映射到用户空间，则可以通过mem_map_reserve()把相应的内存设置为保留后就可以。 当实际访问新映射的页面时的操作(由缺页中断完成)(1) page cache及swap cache中页面的区分：一个被访问文件的物理页面都驻留在page cache或swap cache中，一个页面的所有信息由struct page来描述。struct page中有一个域为指针mapping ，它指向一个struct address_space类型结构。page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。 (2) 文件与 address_space结构的对应：一个具体的文件在打开后，内核会在内存中为之建立一个struct inode结构，其中的i_mapping域指向一个address_space结构。这样，一个文件就对应一个address_space结构，一个 address_space与一个偏移量能够确定一个page cache 或swap cache中的一个页面。因此，当要寻址某个数据时，很容易根据给定的文件及数据在文件内的偏移量而找到相应的页面。 (3) 进程调用mmap()时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常。 (4) 对于共享内存映射情况，缺页异常处理程序首先在swap cache中寻找目标页（符合address_space以及偏移量的物理页），如果找到，则直接返回地址；如果没有找到，则判断该页是否在交换区 (swap area)，如果在，则执行一个换入操作；如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。 注：对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在page cache中根据address_space以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新. (5) 所有进程在映射同一个共享内存区域时，情况都一样，在建立线性地址与物理地址之间的映射之后，不论进程各自的返回地址如何，实际访问的必然是同一个共享内存区域对应的物理页面。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接存储器存取DMA]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%9B%B4%E6%8E%A5%E5%AD%98%E5%82%A8%E5%99%A8%E5%AD%98%E5%8F%96DMA%2F</url>
    <content type="text"><![CDATA[DMA（Direct Memory Access）DMA（Direct Memory Access）即直接存储器存取，是一种快速传送数据的机制。 工作原理DMA是指外部设备不通过CPU而直接与系统内存交换数据的接口技术。 要把外设的数据读入内存或把内存的数据传送到外设，一般都要通过CPU控制完成，如CPU程序查询或中断方式。利用中断进行数据传送，可以大大提高CPU的利用率。 但是采用中断传送有它的缺点，对于一个高速I/O设备，以及批量交换数据的情况，只能采用DMA方式，才能解决效率和速度问题。DMA在外设与内存间直接进行数据交换，而不通过CPU，这样数据传送的速度就取决于存储器和外设的工作速度。 通常系统的总线是由CPU管理的。在DMA方式时，就希望CPU把这些总线让出来，即CPU连到这些总线上的线处于第三态–高阻状态，而由DMA控制器接管，控制传送的字节数，判断DMA是否结束，以及发出DMA结束信号。DMA控制器必须有以下功能： 能向CPU发出系统保持（HOLD）信号，提出总线接管请求； 当CPU发出允许接管信号后，负责对总线的控制，进入DMA方式； 能对存储器寻址及能修改地址指针，实现对内存的读写操作； 能决定本次DMA传送的字节数，判断DMA传送是否结束 发出DMA结束信号，使CPU恢复正常工作状态。 DMA流程计算机发展到今天，DMA已不再用于内存到内存的数据传送，因为CPU速度非常快，做这件事，比用DMA控制还要快，但要在适配卡和内存之间传送数据，仍然是非DMA莫属。要从适配卡到内存传送数据，DMA同时触发从适配卡读数据总线(即I/O读操作)和向内存写数据的总线。激活I/O读操作就是让适配卡把一个数据单位(通常是一个字节或一个字)放到PC数据总线上，因为此时内存写总线也被激活，数据就被同时从PC总线上拷贝到内存中。 DMA工作方式 随着大规模集成电路技术的发展，DMA传送已不局限于存储器与外设间的信息交换，而可以扩展为在存储器的两个区域之间，或两种高速的外设之间进行DMA传送，如图所示。DMAC是控制存储器和外部设备之间直接高速地传送数据的硬件电路，它应能取代CPU，用硬件完成数据传送的各项功能。各种DMAC一般都有两种基本的DMA传送方式： 单字节方式：每次DMA请求只传送一个字节数据，每传送完一个字节，都撤除DMA请求信号，释放总线。 多字节方式：每次DMA请求连续传送一个数据块，待规定长度的数据块传送完以后，才撤除DMA请求，释放总线。 在DMA传送中，为了使源和目的间的数据传送取得同步，不同的DMAC在操作时都受到外设的请求信号或准备就绪信号–Ready信号的限制。 工作方式DMA与CPU调度DMA控制器可采用哪几种方式与CPU分时使用内存？直接内存访问（DMA）方式是一种完全由硬件执行I/O交换的工作方式。DMA控制器从CPU完全接管对总线的控制。数据交换不经过CPU，而直接在内存和I/O设备之间进行。DMA控制器采用以下三种方式： 停止CPU访问内存：当外设要求传送一批数据时，由DMA控制器发一个信号给CPU。DMA控制器获得总线控制权后，开始进行数据传送。一批数据传送完毕后，DMA控制器通知CPU可以使用内存，并把总线控制权交还给CPU。 周期挪用：当I/O设备没有 DMA请求时，CPU按程序要求访问内存：一旦 I/O设备有DMA请求，则I/O设备挪用一个或几个周期。 DMA与CPU交替访内：一个CPU周期可分为2个周期，一个专供DMA控制器访内，另一个专供CPU访内。不需要总线使用权的申请、建立和归还过程。 DMA概述DMA的英文拼写是“Direct Memory Access”，汉语的意思就是直接内存访问。DMA既可以指内存和外设直接存取数据这种内存访问的计算机技术，又可以指实现该技术的硬件模块（对于通用计算机PC而言，DMA控制逻辑由CPU和DMA控制接口逻辑芯片共同组成，嵌入式系统的DMA控制器内建在处理器芯片内部，一般称为DMA控制器，DMAC）。 DMA内存访问技术使用DMA的好处就是它不需要CPU的干预而直接服务外设，这样CPU就可以去处理别的事务，从而提高系统的效率，对于慢速设备，如UART，其作用只是降低CPU的使用率，但对于高速设备，如硬盘，它不只是降低CPU的使用率，而且能大大提高硬件设备的吞吐量。因为对于这种设备，CPU直接供应数据的速度太低。 因CPU只能一个总线周期最多存取一次总线，而且对于ARM，它不能把内存中A地址的值直接搬到B地址。它只能先把A地址的值搬到一个寄存器，然后再从这个寄存器搬到B地址。也就是说，对于ARM，要花费两个总线周期才能将A地址的值送到B地址。而DMA就不同了，一般系统中的DMA都有突发（Burst）传输的能力，在这种模式下，DMA能一次传输几个甚至几十个字节的数据，所以使用DMA能使设备的吞吐能力大为增强。 使用DMA时我们必须要注意如下事实： DMA使用物理地址，程序是使用虚拟地址的，所以配置DMA时必须将虚拟地址转化成物理地址。 因为程序使用虚拟地址，而且一般使用cache地址，所以Cache中的内容与其物理地址（内存）的内容不一定一致，所以在启动DMA传输前一定要将该地址的cache刷新，即写入内存。 OS并不能保证每次分配到的内存空间在物理上是连续的。尤其是在系统使用过一段时间而又分配了一块比较大的内存时。所以每次都需要判断地址是不是连续的，如果不连续就需要把这段内存分成几段让DMA完成传输 DMAC的基本配置DMA用于无需CPU的介入而直接由专用控制器（DMA控制器）建立源与目的传输的应用，因此，在大量数据传输中解放了CPU。PIC32微控制器中的DMA可用于映射到内存空间中的不同外设，如从存储区到SPI，UART或I2C等设备。DMA特性详见器件参考手册，这里仅对一些基本原理与功能做一个简析。 |—|—地址寄存器|放DMA传输时存储单元地址字节计数器|存放DMA传输的字节数控制寄存器|存放由CPU设定的DMA传输方式，控制命令等状态寄存器|存放DMAC当前的状态，包括有无DMA请求，是否结束等 独立DMA控制芯片在课程《微机原理》中，会讲到X86下一片独立的DMA控制芯片8237A。8237A控制芯片各通道在PC机内的任务： CH0：用作动态存储器的刷新控制CH1：为用户预留CH2：软盘驱动器数据传输用的DMA控制CH3：硬盘驱动器数据传输用的DMA控制 嵌入式设备中的DMA直接存储器存取(DMA)控制器是一种在系统内部转移数据的独特外设，可以将其视为一种能够通过一组专用总线将内部和外部存储器与每个具有DMA能力的外设连接起来的控制器。它之所以属于外设，是因为它是在处理器的编程控制下来执行传输的。值得注意的是，通常只有数据流量较大(kBps或者更高)的外设才需要支持DMA能力，这些应用方面典型的例子包括视频、音频和网络接口。 一般而言，DMA控制器将包括一条地址总线、一条数据总线和控制寄存器。高效率的DMA控制器将具有访问其所需要的任意资源的能力，而无须处理器本身的介入，它必须能产生中断。最后，它必须能在控制器内部计算出地址。 一个处理器可以包含多个DMA控制器。每个控制器有多个DMA通道，以及多条直接与存储器站(memory bank)和外设连接的总线，如图1所示。在很多高性能处理器中集成了两种类型的DMA控制器。第一类通常称为“系统DMA控制器”，可以实现对任何资源(外设和存储器)的访问，对于这种类型的控制器来说，信号周期数是以系统时钟(SCLK)来计数的，以ADI的Blackfin处理器为例，频率最高可达133MHz。第二类称为内部存储器DMA控制器(IMDMA)，专门用于内部存储器所处位置之间的相互存取操作。因为存取都发生在内部(L1－L1、L1－L2，或者L2－L2)，周期数的计数则以内核时钟(CCLK)为基准来进行，该时钟的速度可以超过600MHz。 每个DMA控制器有一组FIFO，起到DMA子系统和外设或存储器之间的缓冲器的作用。对于MemDMA(Memory DMA)来说，传输的源端和目标端都有一组FIFO存在。当资源紧张而不能完成数据传输的话，则FIFO可以提供数据的暂存区，从而提高性能。 因为通常会在代码初始化过程中对DMA控制器进行配置，内核就只需要在数据传输完成后对中断做出响应即可。你可以对DMA控制进行编程，让其与内核并行地移动数据，而同时让内核执行其基本的处理任务―那些应该让它专注完成的工作。 在一个优化的应用中，内核永远不用参与任何数据的移动，而仅仅对L1存储器中的数据进行读写。于是，内核不需要等待数据的到来，因为DMA引擎会在内核准备读取数据之前将数据准备好。图2给出了处理器和DMA控制器间的交互关系。由处理器完成的操作步骤包括：建立传输，启用中断，生成中断时执行代码。返回到处理器的中断输入可以用来指示“数据已经准备好，可进行处理”。 数据除了往来外设之外，还需要从一个存储器空间转移到另一个空间中。例如，视频源可以从一个 视频端口直接流入L3存储器，因为工作缓冲区规模太大，无法放入到存储器中。我们并不希望让处理器在每次需要执行计算时都从外部存储读取像素信息，因此为 了提高存取的效率，可以用一个存储器到存储器的DMA(MemDMA)来将像素转移到L1或者L2存储器中。 到目前为之，我们还仅专注于数据的移动，但是DMA的传送能力并不总是用来移动数据。 在最简单的MemDMA情况中，我们需要告诉DMA控制器源端地址、目标端地址和待传送的字的个数。每次传输的字的大小可以是8、16或者12位。 我们只需要改变数据传输每次的数据大小，就可以简单地增加DMA的灵活性。例如，采用非单一大小的传输方式时，我们以传输数据块的大小的倍数来作为地址增量。也就是说，若规定32位的传输和4个采样的跨度，则每次传输结束后，地址的增量为16字节(4个32位字)。 DMA的设置目前有两类主要的DMA传输结构：寄存器模式和描述符模式。无论属于哪一类DMA，表1所描述的几类信息都会在DMA控制器中出现。当DMA以寄存器模式工作时，DMA控制器只是简单地利用寄存器中所存储的参数值。在描述符模式中，DMA控制器在存储器中查找自己的配置参数。 基于寄存器的DMA在基于寄存器的DMA内部，处理器直接对DMA控制寄存器进行编程，来启动传输。基于寄存器的DMA提供了最佳的DMA控制器性能，因为寄存器并不需要不断地从存储器中的描述符上载入数据，而内核也不需要保持描述符。 基于寄存器的DMA由两种子模式组成：自动缓冲(Autobuffer)模式和停止模式。在自动缓冲DMA中，当一个传输块传输完毕，控制寄存器就自动重新载入其最初的设定值，同一个DMA进程重新启动，开销为零。 正如我们在图3中所看到的那样，如果将一个自动缓冲DMA设定为从外设传输一定数量的字到 L1数据存储器的缓冲器上，则DMA控制器将会在最后一个字传输完成的时刻就迅速重新载入初始的参数。这构成了一个“循环缓冲器”，因为当一个量值被写入 到缓冲器的最后一个位置上时，下一个值将被写入到缓冲器的第一个位置上。 自动缓冲DMA特别适合于对性能敏感的、存在持续数据流的应用。DMA控制器可以在独立于处理器其他活动的情况下读入数据流，然后在每次传输结束时，向内核发出中断。 停止模式的工作方式与自动缓冲DMA类似，区别在于各寄存器在DMA结束后不会重新载入，因 此整个DMA传输只发生一次。停止模式对于基于某种事件的一次性传输来说十分有用。例如，非定期地将数据块从一个位置转移到另一个位置。当你需要对事件进 行同步时，这种模式也非常有用。例如，如果一个任务必须在下一次传输前完成的话，则停止模式可以确保各事件发生的先后顺序。此外，停止模式对于缓冲器的初 始化来说非常有用。 描述符模型基于描述符(descriptor)的DMA要求在存储器中存入一组参数，以 启动DMA的系列操作。该描述符所包含的参数与那些通常通过编程写入DMA控制寄存器组的所有参数相同。不过，描述符还可以容许多个DMA操作序列串在一 起。在基于描述符的DMA操作中，我们可以对一个DMA通道进行编程，在当前的操作序列完成后，自动设置并启动另一次DMA传输。基于描述符的方式为管理 系统中的DMA传输提供了最大的灵活性。 ADI 的Blackfin处理器上有两种主要的描述符方式―描述符阵列和描述符列表，这两种操作方式所要实现的目标是在灵活性和性能之间实现一种折中平衡。 直接内存访问(DMA)什么是DMA直接内存访问是一种硬件机制，它允许外围设备和主内存之间直接传输它们的I/O数据，而不需要系统处理器的参与。使用这种机制可以大大提高与设备通信的吞吐量。 DMA数据传输有两种方式引发数据传输：第一种情况：软件对数据的请求 当进程调用read，驱动程序函数分配一个DMA缓冲区，并让硬件将数据传输到这个缓冲区中。进程处于睡眠状态。 硬件将数据写入到DMA缓冲区中，当写入完毕，产生一个中断 中断处理程序获取输入的数据，应答中断，并唤起进程，该进程现在即可读取数据 第二种情况发生在异步使用DMA时。 硬件产生中断，宣告新数据的到来 中断处理程序分配一个缓冲区，并且告诉硬件向哪里传输数据 外围设备将数据写入数据区，完成后，产生另外一个中断 处理程序分发新数据，唤醒任何相关进程，然后执行清理工作 高效的DMA处理依赖于中断报告。 分配DMA缓冲区使用DMA缓冲区的主要问题是：当大于一页时，它们必须占据连续的物理页，因为设备使用ISA或PCI系统总线传输数据，而这两种方式使用的都是物理地址。 使用get_free_pasges可以分配多大几M字节的内存(MAX_ORDER是11)，但是对于较大数量(即使是远小于128KB)的请求，通常会失败，这是因为系统内存充满了内存碎片。 解决方法之一就是在引导时分配内存，或者为缓冲区保留顶部物理内存。 例子：在系统引导时，向内核传递参数“mem=value”的方法保留顶部的RAM。比如系统有256内存，参数“mem=255M”，使内核不能使用顶部的1M字节。随后，模块可以使用下面代码获得该内存的访问权： dmabuf=ioremap(0XFF00000/*255M/, 0X100000/1M/*); 解决方法之二是使用GPF_NOFAIL分配标志为缓冲区分配内存，但是该方法为内存管理子系统带来了相当大的压力。 解决方法之三十设备支持分散/聚集I/O，这可以将缓冲区分配成多个小块，设备会很好地处理它们。 通用DMA层DMA操作最终会分配缓冲区，并将总线地址传递给设备。内核提高了一个与总线——体系结构无关的DMA层。强烈建议在编写驱动程序时，为DMA操作使用该层。使用这些函数的头文件是&lt;linux/dmamapping.h&gt;。 int dma_set_mask(struct device *dev, u64 mask); 该掩码显示该设备能寻址能力对应的位。比如说，设备受限于24位寻址，则mask应该是0x0FFFFFF。 DMA映射IOMMU在设备可访问的地址范围内规划了物理内存，使得物理上分散的缓冲区对设备来说成连续的。对IOMMU的运用需要使用到通用DMA层，而vir_to_bus函数不能完成这个任务。但是，x86平台没有对IOMMU的支持。 解决之道就是建立回弹缓冲区，然后，必要时会将数据写入或者读出回弹缓冲区。缺点是降低系统性能。 根据DMA缓冲区期望保留的时间长短，PCI代码区分两种类型的DMA映射： 一是一致性DMA映射，存在于驱动程序生命周期中，一致性映射的缓冲区必须可同时被CPU和外围设备访问。一致性映射必须保存在一致性缓存中。建立和使用一致性映射的开销是很大的。 二是流式DMA映射，内核开发者建议尽量使用流式映射，原因：一是在支持映射寄存器的系统中，每个DMA映射使用总线上的一个或多个映射寄存器，而一致性映射生命周期很长，长时间占用这些这些寄存器，甚至在不使用他们的时候也不释放所有权；二是在一些硬件中，流式映射可以被优化，但优化的方法对一致性映射无效。 建立一致性映射驱动程序可调用pci_alloc_consistent函数建立一致性映射： void dma_alloc_coherent(struct device dev, size_t size, dma_addr_t *dma_handle, int falg); 该函数处理了缓冲区的分配和映射，前两个参数是device结构和所需的缓冲区的大小。函数在两处返回DMA映射的结果：函数的返回值是缓冲区的内核虚拟地址，可以被驱动程序使用；而与其相关的总线地址保存在dma_handle中。 当不再需要缓冲区时，调用下函数： void dma_free_conherent(struct device dev, size_t size, void vaddr, dma_addr_t *dma_handle); DMA池DMA池是一个生成小型，一致性DMA映射的机制。调用dma_alloc_coherent函数获得的映射，可能其最小大小为单个页。如果设备需要的DMA区域比这还小，就是用DMA池。在&lt;linux/dmapool.h&gt;中定义了DMA池函数： struct dma_pool dma_pool_create(const char name, struct device *dev, size_t size, size_t align, size_t allocation); void dma_pool_destroy(struct dma_pool *pool); name是DMA池的名字，dev是device结构，size是从该池中分配的缓冲区的大小，align是该池分配操作所必须遵守的硬件对齐原则(用字节表示)，如果allocation不为零，表示内存边界不能超越allocation。比如说传入的allocation是4K，表示从该池分配的缓冲区不能跨越4KB的界限。 在销毁之前必须向DMA池返回所有分配的内存。 void dma_pool_alloc(sturct dma_pool pool, int mem_flags, dma_addr_t *handle); void dma_pool_free(struct dma_pool pool, void addr, dma_addr_t addr); 建立流式DMA映射在某些体系结构中，流式映射也能够拥有多个不连续的页和多个“分散/聚集”缓冲区。建立流式映射时，必须告诉内核数据流动的方向。 DMA_TO_DEVICE DEVICE_TO_DMA 如果数据被发送到设备，使用DMA_TO_DEVICE；而如果数据被发送到CPU，则使用DEVICE_TO_DMA。 DMA_BIDIRECTTONAL 如果数据可双向移动，则使用该值 DMA_NONE 该符号只是出于调试目的。 当只有一个缓冲区要被传输的时候，使用下函数映射它： dma_addr_t dma_map_single(struct device dev, void buffer, size_t size, enum dma_data_direction direction); 返回值是总线地址，可以把它传递给设备；如果执行错误，返回NULL。 当传输完毕后，使用下函数删除映射： void dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size, enum dma-data_direction direction); 使用流式DMA的原则： 一是缓冲区只能用于这样的传送，即其传送方向匹配与映射时给定的方向值； 二是一旦缓冲区被映射，它将属于设备，不是处理器。直到缓冲区被撤销映射前，驱动程序不能以任何方式访问其中的内容。只用当dma_unmap_single函数被调用后，显示刷新处理器缓存中的数据，驱动程序才能安全访问其中的内容。 三是在DMA出于活动期间内，不能撤销对缓冲区的映射，否则会严重破坏系统的稳定性。 如果要映射的缓冲区位于设备不能访问的内存区段(高端内存)，怎么办？一些体系结构只产生一个错误，但是其他一些系统结构件创建一个回弹缓冲区。回弹缓冲区就是内存中的独立区域，它可被设备访问。如果使用DMA_TO_DEVICE标志映射缓冲区，并且需要使用回弹缓冲区，则在最初缓冲区中的内容作为映射操作的一部分被拷贝。很明显，在拷贝后，最初缓冲区内容的改变对设备不可见。同样DEVICE_TO_DMA回弹缓冲区被dma_unmap_single函数拷贝回最初的缓冲区中，也就是说，直到拷贝操作完成，来自设备的数据才可用。 有时候，驱动程序需要不经过撤销映射就访问流式DMA缓冲区的内容，为此内核提供了如下调用： void dma_sync_single_for_cpu(struct device *dev, dma_handle_t bus_addr, size_t size, enum dma_data_directction direction); 应该在处理器访问流式DMA缓冲区前调用该函数。一旦调用了该函数，处理器将“拥有”DMA缓冲区，并可根据需要对它进行访问。然后在设备访问缓冲区前，应该调用下面的函数将所有权交还给设备： void dma_sync_single_for_device(struct device *dev, dma_handle_t bus_addr, size_t size, enum dma_data_direction direction); 再次强调，处理器在调用该函数后，不能再访问DMA缓冲区了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几道和「黑洞照片」那种海量数据有关的算法问题]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%87%A0%E9%81%93%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%9C%89%E5%85%B3%E7%9A%84%E7%AE%97%E6%B3%95%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[原文：https://cxyxiaowu.com/articles/2019/04/11/1554963765366.html 海量数据查找中位数题目描述现在有 10 亿个 int 型的数字（ java 中 int 型占 4B），以及一台可用内存为 1GB 的机器，如何找出这 10 亿个数字的中位数？ 所谓中位数就是有序列表中间的数。如果列表长度是偶数，中位数则是中间两个数的平均值。 题目解析题目中有 10 亿个数字，每个数字在内存中占 4B，那么这 10 亿个数字完全加载到内存中需要：10 10^8 4，大概需要 4GB 的存储空间。根据题目的限制，显然不能把所有的数字都装入内存中。 这里，可以采用基于 二进制位比较 和 快速排序算法中的 分割思想 来寻找中位数，实际上这也是 桶排序 的一种应用。 假设将这 10 亿个数字保存在一个大文件中，依次读一部分文件到内存(不超过内存的限制： 1GB )，将每个数字用二进制表示，比较二进制的最高位(第 32 位)，如果数字的最高位为 0，则将这个数字写入 file_0 文件中；如果最高位为 1，则将该数字写入 file_1 文件中。 注意：最高位为符号位，也就是说 file_1 中的数都是负数，而 file_0 中的数都是正数。 通过这样的操作，这 10 亿个数字分成了两个文件，假设 file_0 文件中有 6 亿个数字，而 file_1 文件中有 4 亿个数字。 这样划分后，思考一下：所求的中位数在哪个文件中？ 10 亿个数字的中位数是10 亿个数排序之后的第 5 亿个数，现在 file_0 有 6 亿个正数，file_1 有 4 亿个负数，file_0 中的数都比 file_1 中的数要大，排序之后的第 5 亿个数一定是正数，那么排序之后的第 5 亿个数一定位于file_0中。 也就是说：中位数就在 file_0 文件中，并且是 file_0 文件中所有数字排序之后的第 1 亿个数字。 现在，我们只需要处理 file_0 文件了（不需要再考虑 file_1 文件）。 而对于 file_0 文件，可以同样的采取上面的措施处理：将 file_0 文件依次读一部分到内存(不超内存限制：1GB )，将每个数字用二进制表示，比较二进制的 次高位（第 31 位），如果数字的次高位为 0，写入 file_0_0 文件中；如果次高位为 1 ，写入 file_0_1 文件中。 现假设 file_0_0 文件中有 3 亿个数字，file_0_1中也有 3 亿个数字，则中位数就是：file_0_0 文件中的数字从小到大排序之后的第 1 亿个数字。 抛弃 file_0_1 文件，继续对 file_0_0 文件 根据次次高位(第 30 位) 划分，假设此次划分的两个文件为：file_0_0_0中有 0.5 亿个数字，file_0_0_1 中有 2.5 亿个数字，那么中位数就是 file_0_0_1 文件中的所有数字排序之后的第 0.5 亿个数。 海量数据中判断数字是否存在题目描述现在有 10 亿个 int 型的数字（ java 中 int 型占 4B），以及一台可用内存为 1GB 的机器，给出一个整数，问如果快速地判断这个整数是否在这 10 亿数字中？ 题目分析这里可以使用 布隆过滤器 进行处理。 布隆过滤器（英语：Bloom Filter）是 1970 年由 Burton Bloom 提出的。 它实际上是一个很长的二进制矢量和一系列随机映射函数。它可以用来判断一个元素是否在一个集合中。它的优势是只需要占用很小的内存空间以及有着高效的查询效率。 对于布隆过滤器而言，它的本质是一个位数组：位数组就是数组的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。 一开始，布隆过滤器的位数组所有位都初始化为 0。比如，数组长度为 m ，那么将长度为 m 个位数组的所有的位都初始化为 0。 0 0 0 0 0 0 0 0 0 00 0 1 。 。 。 。 。 m-2 m-1在数组中的每一位都是二进制位。 布隆过滤器除了一个位数组，还有 K 个哈希函数。当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用 K 个哈希函数对元素值进行 K 次计算，得到 K 个哈希值。根据得到的哈希值，在位数组中把对应下标的值置为 1。 举个例子，假设布隆过滤器有 3 个哈希函数：f1, f2, f3 和一个位数组 arr。现在要把 2333 插入布隆过滤器中： 对值进行三次哈希计算，得到三个值 n1, n2, n3。 把位数组中三个元素 arr[n1], arr[n2], arr[3] 都置为 1。 当要判断一个值是否在布隆过滤器中，对元素进行三次哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode392. Is Subsequence]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode392-Is-Subsequence%2F</url>
    <content type="text"><![CDATA[Given a string s and a string t, check if s is subsequence of t. You may assume that there is only lower case English letters in both s and t. t is potentially a very long (length ~= 500,000) string, and s is a short string (&lt;=100). A subsequence of a string is a new string which is formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (ie, “ace” is a subsequence of “abcde” while “aec” is not). Example 1:12s = &quot;abc&quot;, t = &quot;ahbgdc&quot;Return true. Example 2:12s = &quot;axc&quot;, t = &quot;ahbgdc&quot;Return false. Follow up:If there are lots of incoming S, say S1, S2, … , Sk where k &gt;= 1B, and you want to check one by one to see if T has its subsequence. In this scenario, how would you change your code? 检查一个串是不是另一个串的子串，找两个指针即可。123456789101112131415161718192021class Solution &#123;public: bool isSubsequence(string s, string t) &#123; int ss,tt; ss=0; tt=0; while(ss&lt;s.length() &amp;&amp; tt&lt;t.length())&#123; if(s[ss]==t[tt])&#123; ss++; tt++; &#125; else tt++; &#125; if(ss==s.length())&#123; return true; &#125; else return false; &#125;&#125;; 我们可以用俩个指针i，j分别指向字符串s，t. 算法描述如下: j指针一直往后走，碰到t[j]==s[i]的时候，说明匹配上了一个，将i++，否则i不加1，当t都走完的时候，这个时候，我们判断一下i指针是否走完了s字符串，如果走完了，说明也匹配上了，如果没有走完，那么就是没有匹配上，中间的过程，i提前等于s.length()的时候，也可以退出！此时的时间复杂度就是扫描一遍t，s串的线性复杂度O(t_len+s_len)。 算法正确性： 我们算法的关键点就在于，当s[i]=t[j]的时候，i和j都需要加1，那么这俩个指针加1的过程是否一定是对的呢？我们可以这样理解，当s=”abc”,t=”ahbgdc”,i=1,j=1的时候，我们只需要判断s后面的子串bc是否是t的子串hbgdc的子集（相当于分解为子问题），如果s的子串bc满足是t的子串hbgdc的子集，我们就返回true，如果不满足，我们就返回false。这样一步一步贪心下去就能保证算法正确性。 下面举一个简单例子走一遍算法帮助理解: s=”abc”, t=“ahbgdc” 首先i，j都为0，分别指向s，t俩个串开头. 第一步，当j=0&lt;t_len=6的时候，进入循环，此时t[0]=a,s[0]=a,俩者相等，那么i,j都1，此时i=1，j=1，i!=(s_len=3),不跳出, j还是小于t_len。 此时t[1]=h ,s[1]=b,它们不相等，那么只有j加1，此时i=1,j=2，i!=3，不跳出. j还是小于t_len=6，此时t[2]=b,s[1]=b,它们相等，那么i,j分别加1，此时i=2，j=3,i!=3不跳出. 那么t[3]=g,s[2]=c,它们不相等，那么之后j加1，此时i=2,j=4，i!=3不跳出. 此时t[4]=d,s[2]=2,它们不相等,此时j加1,i=2,j=5,i!=3不跳出. j还是小于6，t[5]=c,s[2]=c,此时它们相等，i++，i=3，此时等于s_len，res=true，跳出while循环，返回结果为true。1234567891011121314151617181920212223242526class Solution &#123;public: bool isSubsequence(string s, string t) &#123; //俩个指针都往前走 if(s.length()==0) return true; //空字符串是任何字符串的子串 int i = 0,j = 0; bool res = false; int s_len = s.length(),t_len = t.length(); while(j &lt; t_len) &#123; if(t[j] == s[i]) &#123; i++; if(i==s_len) &#123; res = true; break; &#125; &#125; j++; //无论t[j]是否等于s[i]，j都要加1 &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统详解]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/alantu2018/p/8461749.html 概述在LINUX系统中有一个重要的概念：一切都是文件。 其实这是UNIX哲学的一个体现，而Linux是重写UNIX而来，所以这个概念也就传承了下来。在UNIX系统中，把一切资源都看作是文件，包括硬件设备。UNIX系统把每个硬件都看成是一个文件，通常称为设备文件，这样用户就可以用读写文件的方式实现对硬件的访问。这样带来优势也是显而易见的： UNIX 权限模型也是围绕文件的概念来建立的，所以对设备也就可以同样处理了。 硬盘驱动常见的硬盘类型有PATA, SATA和AHCI等，在Linux系统中，对不同硬盘所提供的驱动模块一般都存放在内核目录树drivers/ata中，而对于一般通用的硬盘驱动，也许会直接被编译到内核中，而不会以模块的方式出现，可以通过查看/boot/config-xxx.xxx文件来确认： CONFIG_SATA_AHCI=y General Block Device Layer这一层的作用，正是解答了上面提出的第一个问题，不同的硬盘驱动，会提供不同的IO接口，内核认为这种杂乱的接口，不利于管理，需要把这些接口抽象一下，形成一个统一的对外接口，这样，不管你是什么硬盘，什么驱动，对外而言，它们所提供的IO接口没什么区别，都一视同仁的被看作块设备来处理。 所以，如果在一层做的任何修改，将会直接影响到所有文件系统，不管是ext3,ext4还是其它文件系统，只要在这一层次做了某种修改，对它们都会产生影响。 文件系统文件系统这一层相信大家都再熟悉不过了，目前大多Linux发行版本默认使用的文件系统一般是ext4，另外，新一代的btrfs也呼之欲出，不管什么样的文件系统，都是由一系列的mkfs.xxx命令来创建，如：12mkfs.ext4 /dev/sdamkfs.btrfs /dev/sdb 内核所支持的文件系统类型，可以通过内核目录树 fs 目录中的内容来查看。 虚拟文件系统(VFS)Virtual File System这一层，正是用来解决上面提出的第二个问题，试想，当我们通过mkfs.xxx系列命令创建了很多不同的文件系统，但这些文件系统都有各自的API接口，而用户想要的是，不管你是什么API，他们只关心mount/umount，或open/close等操作。 所以，VFS就把这些不同的文件系统做一个抽象，提供统一的API访问接口，这样，用户空间就不用关心不同文件系统中不一样的API了。VFS所提供的这些统一的API，再经过System Call包装一下，用户空间就可以经过SCI的系统调用来操作不同的文件系统。VFS所提供的常用API有：123mount()， umount() …open()，close() …mkdir() … 和文件系统关系最密切的就是存储介质，存储介质大致有RAM，ROM，磁盘磁带，闪存等。 闪存（Flash Memory）是一种长寿命的非易失性（在断电情况下仍能保持所存储的数据信息）的存储器，数据删除不是以单个的字节为单位而是以固定的区块为单位（注意：NOR Flash 为字节存储。），区块大小一般为256KB到20MB。闪存是电子可擦除只读存储器（EEPROM）的变种，EEPROM与闪存不同的是，它能在字节水平上进行删除和重写而不是整个芯片擦写，这样闪存就比EEPROM的更新速度快。由于其断电时仍能保存数据，闪存通常被用来保存设置信息，如在电脑的BIOS（基本输入输出程序）、PDA（个人数字助理）、数码相机中保存资料等。 外存通常是磁性介质或光盘，像硬盘，软盘，磁带，CD等，能长期保存信息，并且不依赖于电来保存信息，但是由机械部件带动，速度与CPU相比就显得慢的多。内存指的就是主板上的存储部件，是CPU直接与之沟通，并用其存储数据的部件，存放当前正在使用的（即执行中）的数据和程序，它的物理实质就是一组或多组具备数据输入输出和数据存储功能的集成电路，内存只用于暂时存放程序和数据，一旦关闭电源或发生断电，其中的程序和数据就会丢失。RAM又分为动态的和静态。。静态被用作cache，动态的常用作内存。。网上说闪存不能代替DRAM是因为闪存不像RAM（随机存取存储器）一样以字节为单位改写数据，因此不能取代RAM。这个以后可以了解下硬件的知识再来辨别. Linux下的文件系统结构如下： Linux启动时，第一个必须挂载的是根文件系统；若系统不能从指定设备上挂载根文件系统，则系统会出错而退出启动。之后可以自动或手动挂载其他的文件系统。因此，一个系统中可以同时存在不同的文件系统。 不同的文件系统类型有不同的特点，因而根据存储设备的硬件特性、系统需求等有不同的应用场合。在嵌入式Linux应用中，主要的存储设备为RAM(DRAM, SDRAM)和ROM(常采用FLASH存储器)，常用的基于存储设备的文件系统类型包括：jffs2, yaffs, cramfs, romfs, ramdisk, ramfs/tmpfs等。 基于FLASH的文件系统Flash(闪存)作为嵌入式系统的主要存储媒介，有其自身的特性。Flash的写入操作只能把对应位置的1修改为0，而不能把0修改为1(擦除Flash就是把对应存储块的内容恢复为1)，因此，一般情况下，向Flash写入内容时，需要先擦除对应的存储区间，这种擦除是以块(block)为单位进行的。 闪存主要有NOR和NAND两种技术。Flash存储器的擦写次数是有限的，NAND闪存还有特殊的硬件接口和读写时序。因此，必须针对Flash的硬件特性设计符合应用要求的文件系统；传统的文件系统如ext2等，用作Flash的文件系统会有诸多弊端。 在嵌入式Linux下，MTD(Memory Technology Device,存储技术设备)为底层硬件(闪存)和上层(文件系统)之间提供一个统一的抽象接口，即Flash的文件系统都是基于MTD驱动层的(参见上面的Linux下的文件系统结构图)。使用MTD驱动程序的主要优点在于，它是专门针对各种非易失性存储器(以闪存为主)而设计的，因而它对Flash有更好的支持、管理和基于扇区的擦除、读/写操作接口。 顺便一提，一块Flash芯片可以被划分为多个分区，各分区可以采用不同的文件系统；两块Flash芯片也可以合并为一个分区使用，采用一个文件系统。即文件系统是针对于存储器分区而言的，而非存储芯片。(1) jffs2JFFS文件系统最早是由瑞典Axis Communications公司基于Linux2.0的内核为嵌入式系统开发的文件系统。JFFS2是RedHat公司基于JFFS开发的闪存文件系统，最初是针对RedHat公司的嵌入式产品eCos开发的嵌入式文件系统，所以JFFS2也可以用在Linux, uCLinux中。Jffs2: 日志闪存文件系统版本2 (Journalling Flash FileSystem v2)主要用于NOR型闪存，基于MTD驱动层，特点是：可读写的、支持数据压缩的、基于哈希表的日志型文件系统，并提供了崩溃/掉电安全保护，提供“写平衡”支持等。缺点主要是当文件系统已满或接近满时，因为垃圾收集的关系而使jffs2的运行速度大大放慢。目前jffs3正在开发中。关于jffs系列文件系统的使用详细文档，可参考MTD补丁包中mtd-jffs-HOWTO.txt。jffsx不适合用于NAND闪存主要是因为NAND闪存的容量一般较大，这样导致jffs为维护日志节点所占用的内存空间迅速增大，另外，jffsx文件系统在挂载时需要扫描整个FLASH的内容，以找出所有的日志节点，建立文件结构，对于大容量的NAND闪存会耗费大量时间。 (2) yaffs：Yet Another Flash File Systemyaffs/yaffs2是专为嵌入式系统使用NAND型闪存而设计的一种日志型文件系统。与jffs2相比，它减少了一些功能(例如不支持数据压缩)，所以速度更快，挂载时间很短，对内存的占用较小。另外，它还是跨平台的文件系统，除了Linux和eCos，还支持WinCE, pSOS和ThreadX等。yaffs/yaffs2自带NAND芯片的驱动，并且为嵌入式系统提供了直接访问文件系统的API，用户可以不使用Linux中的MTD与VFS，直接对文件系统操作。当然，yaffs也可与MTD驱动程序配合使用。yaffs与yaffs2的主要区别在于，前者仅支持小页(512 Bytes) NAND闪存，后者则可支持大页(2KB) NAND闪存。同时，yaffs2在内存空间占用、垃圾回收速度、读/写速度等方面均有大幅提升。 (3) Cramfs：Compressed ROM File SystemCramfs是Linux的创始人 Linus Torvalds参与开发的一种只读的压缩文件系统。它也基于MTD驱动程序。在cramfs文件系统中，每一页(4KB)被单独压缩，可以随机页访问，其压缩比高达2:1,为嵌入式系统节省大量的Flash存储空间，使系统可通过更低容量的FLASH存储相同的文件，从而降低系统成本。Cramfs文件系统以压缩方式存储，在运行时解压缩，所以不支持应用程序以XIP方式运行，所有的应用程序要求被拷到RAM里去运行，但这并不代表比Ramfs需求的RAM空间要大一点，因为Cramfs是采用分页压缩的方式存放档案，在读取档案时，不会一下子就耗用过多的内存空间，只针对目前实际读取的部分分配内存，尚没有读取的部分不分配内存空间，当我们读取的档案不在内存时，Cramfs文件系统自动计算压缩后的资料所存的位置，再即时解压缩到RAM中。另外，它的速度快，效率高，其只读的特点有利于保护文件系统免受破坏，提高了系统的可靠性。由于以上特性，Cramfs在嵌入式系统中应用广泛。但是它的只读属性同时又是它的一大缺陷，使得用户无法对其内容对进扩充。?Cramfs映像通常是放在Flash中，但是也能放在别的文件系统里，使用loopback 设备可以把它安装别的文件系统里。 (4) Romfs传统型的Romfs文件系统是一种简单的、紧凑的、只读的文件系统，不支持动态擦写保存，按顺序存放数据，因而支持应用程序以XIP(eXecute In Place，片内运行)方式运行，在系统运行时，节省RAM空间。uClinux系统通常采用Romfs文件系统。其他文件系统：fat/fat32也可用于实际嵌入式系统的扩展存储器(例如PDA, Smartphone, 数码相机等的SD卡)，这主要是为了更好的与最流行的Windows桌面操作系统相兼容。ext2也可以作为嵌入式Linux的文件系统，不过将它用于FLASH闪存会有诸多弊端。 基于RAM的文件系统(1) RamdiskRamdisk是将一部分固定大小的内存当作分区来使用。它并非一个实际的文件系统，而是一种将实际的文件系统装入内存的机制，并且可以作为根文件系统。将一些经常被访问而又不会更改的文件(如只读的根文件系统)通过Ramdisk放在内存中，可以明显地提高系统的性能。在Linux的启动阶段，initrd提供了一套机制，可以将内核映像和根文件系统一起载入内存。 (2)ramfs/tmpfsRamfs是Linus Torvalds开发的一种基于内存的文件系统，工作于虚拟文件系统(VFS)层，不能格式化，可以创建多个，在创建时可以指定其最大能使用的内存大小。(实际上，VFS本质上可看成一种内存文件系统，它统一了文件在内核中的表示方式，并对磁盘文件系统进行缓冲。)Ramfs/tmpfs文件系统把所有的文件都放在RAM中，所以读/写操作发生在RAM中，可以用ramfs/tmpfs来存储一些临时性或经常要修改的数据，例如/tmp和/var目录，这样既避免了对Flash存储器的读写损耗，也提高了数据读写速度。Ramfs/tmpfs相对于传统的Ramdisk的不同之处主要在于：不能格式化，文件系统大小可随所含文件内容大小变化。Tmpfs的一个缺点是当系统重新引导时会丢失所有数据。 网络文件系统NFS (Network File System)NFS是由Sun开发并发展起来的一项在不同机器、不同操作系统之间通过网络共享文件的技术。在嵌入式Linux系统的开发调试阶段，可以利用该技术在主机上建立基于NFS的根文件系统，挂载到嵌入式设备，可以很方便地修改根文件系统的内容。以上讨论的都是基于存储设备的文件系统(memory-based file system)，它们都可用作Linux的根文件系统。实际上，Linux还支持逻辑的或伪文件系统(logical or pseudo file system)，例如procfs(proc文件系统)，用于获取系统信息，以及devfs(设备文件系统)和sysfs，用于维护设备文件。 附录：NOR闪存与NAND闪存比较NOR FLASH接口时序同SRAM,易使用读取速度较快擦除速度慢，以64-128KB的块为单位写入速度慢(因为一般要先擦除)随机存取速度较快，支持XIP(eXecute In Place，芯片内执行)，适用于代码存储。在嵌入式系统中，常用于存放引导程序、根文件系统等。单片容量较小，1－32MB最大擦写次数10万次 NAND FLASH地址/数据线复用，数据位较窄读取速度较慢擦除速度快，以8－32KB的块为单位写入速度快顺序读取速度较快，随机存取速度慢，适用于数据存储(如大容量的多媒体应用)。在嵌入式系统中，常用于存放用户文件系统等。单片容量较大，8－128MB，提高了单元密度http://bbs.ednchina.com/BLOG_ARTICLE_142972.HTM 文件存储结构介绍文件存储结构前先来看看文件系统如何划分磁盘，创建一个文件、目录、链接的过程。 物理磁盘到文件系统我们知道文件最终是保存在硬盘上的。硬盘最基本的组成部分是由坚硬金属材料制成的涂以磁性介质的盘片，不同容量硬盘的盘片数不等。每个盘片有两面，都可记录信息。盘片被分成许多扇形的区域，每个区域叫一个扇区，每个扇区可存储128×2的N次方（N＝0.1.2.3）字节信息。在DOS中每扇区是128×2的2次方＝512字节，盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道。硬盘中，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用，我们知道，每个磁盘有两个面，每个面都有一个磁头，习惯用磁头号来区分。扇区，磁道（或柱面）和磁头数构成了硬盘结构的基本参数，帮这些参数可以得到硬盘的容量，基计算公式为：存储容量＝磁头数×磁道（柱面）数×每道扇区数×每扇区字节数要点：（1）硬盘有数个盘片，每盘片两个面，每个面一个磁头（2）盘片被划分为多个扇形区域即扇区（3）同一盘片不同半径的同心圆为磁道（4）不同盘片相同半径构成的圆柱面即柱面（5）公式： 存储容量＝磁头数×磁道（柱面）数×每道扇区数×每扇区字节数（6）信息记录可表示为：××磁道（柱面），××磁头，××扇区 那么这些空间又是怎么管理起来的呢？unix/linux使用了一个简单的方法。它将磁盘块分为以下三个部分： 超级块，文件系统中第一个块被称为超级块。这个块存放文件系统本身的结构信息。比如，超级块记录了每个区域的大小，超级块也存放未被使用的磁盘块的信息。 I-切点表。超级块的下一个部分就是i-节点表。每个i-节点就是一个对应一个文件/目录的结构，这个结构它包含了一个文件的长度、创建及修改时间、权限、所属关系、磁盘中的位置等信息。一个文件系统维护了一个索引节点的数组，每个文件或目录都与索引节点数组中的唯一一个元素对应。系统给每个索引节点分配了一个号码，也就是该节点在数组中的索引号，称为索引节点号 数据区。文件系统的第3个部分是数据区。文件的内容保存在这个区域。磁盘上所有块的大小都一样。如果文件包含了超过一个块的内容，则文件内容会存放在多个磁盘块中。一个较大的文件很容易分布上千个独产的磁盘块中。 Linux正统的文件系统(如ext2、ext3)一个文件由目录项、inode和数据块组成。 目录项:包括文件名和inode节点号。 Inode：又称文件索引节点，是文件基本信息的存放地和数据块指针存放地。 数据块：文件的具体内容存放地。 Linux正统的文件系统(如ext2、3等)将硬盘分区时会划分出目录块、inode Table区块和data block数据区域。一个文件由一个目录项、inode和数据区域块组成。Inode包含文件的属性(如读写属性、owner等，以及指向数据块的指针)，数据区域块则是文件内容。当查看某个文件时，会先从inode table中查出文件属性及数据存放点，再从数据块中读取数据。 文件存储结构大概如下： 其中目录项的结构如下(每个文件的目录项存储在改文件所属目录的文件内容里)： 其中文件的inode结构如下（inode里所包含的文件信息可以通过stat filename查看得到）： 以上只反映大体的结构，linux文件系统本身在不断发展。但是以上概念基本是不变的。且如ext2、ext3、ext4文件系统也存在很大差别，如果要了解可以查看专门的文件系统介绍。 创建一个文件的过程我们从前面可以知道文件的内容和属性是分开存放的，那么又是如何管理它们的呢?现在我们以创建一个文件为例来讲解。在命令行输入命令：1$ who &gt; userlist 当完成这个命令时。文件系统中增加了一个存放命令who输出内容的新文件userlist，那么这整个过程到底是怎么回事呢？文件主要有属性、内容以及文件名三项。内核将文件内容存放在数据区，文件属性存放在i-节点，文件名存放在目录中。创建成功一个文件主要有以下四个步骤： 存储属性 也就是文件属性的存储，内核先找到一块空的i-节点。例如，内核找到i-节点号921130。内核把文件的信息记录其中。如文件的大小、文件所有者、和创建时间等。 存储数据 即文件内容的存储，由于该文件需要3个数据块。因此内核从自由块的列表中找到3个自由块。如600、200、992，内核缓冲区的第一块数据复制到块600，第二和第三分别复制到922和600. 记录分配情况，数据保存到了三个数据块中。所以必须要记录起来，以后再找到正确的数据。分配情况记录在文件的i-节点中的磁盘序号列表里。这3个编号分别放在最开始的3个位置。 添加文件名到目录，新文件的名字是userlist 内核将文件的入口(47,userlist)添加到目录文件里。文件名和i-节点号之间的对应关系将文件名和文件和文件的内容属性连接起来，找到文件名就找到文件的i-节点号，通过i-节点号就能找到文件的属性和内容。代码具体实现过程参考：http://blog.csdn.net/kai_ding/article/details/9206057 创建一个目录的过程前面说了创建一个文件的大概过程，也了解文件内容、属性以及入口的保存方式，那么创建一个目录时又是怎么回事呢？我现在test目录使用命令mkdir 新增一个子目录child： 从用户的角度看，目录child是目录test的一个子目录，那么在系统中这层关系是怎么实现的呢？实际上test目录包含一个指向子目录child的i-节点的链接，原理跟普通文件一样，因为目录也是文件。 目录其实也是文件，只是它的内容比较特殊。所以它的创建过程和文件创建过程一样，只是第二步写的内容不同。 系统找到空闲的i-节点号887220,写入目录的属性 找到空闲的数据块1002来存储目录的内容，只是目录的内容比较特殊，包含文件名字列表，列表一般包含两个部分：i-节点号和文件名，这个列表其实也就是文件的入口，新建的目录至少包含三个目录”.”和”..”其中”.”指向自己，”..”指向上级目录，我们可以通过比较对应的i-节点号来验证,887270 对应着上级目录中的child对应的i-节点号 记录分配情况。这个和创建文件完全一样 添加目录的入口到父目录，即在父目录中的child入口。 一般都说文件存放在某个目录中，其实目录中存入的只是文件在i-节点表的入口，而文件的内容则存储在数据区。我们一般会说“文件userlist在目录test中”,其实这意味着目录test中有一个指向i-节点921130的链接，这个链接所附加的文件名为userlist,这也可以这样理解：目录包含的是文件的引用，每个引用被称为链接。文件的内容存储在数据块。文件的属性被记录在一个被称为i-节点的结构中。I-节点的编号和文件名关联起来存在目录中。注意：其中“.”表示是当前目录。而“..”是当前目录的父目录。但也有特殊情况：如我们查看根目录/的情况: 发现“.”和“..”都指向i-节点2。实际上当我们用mkfs创建一个文件系统时，mkfs都会将根目录的父目录指向自己。所以根目录下.和..指向同一个i-节点也不奇怪了。代码具体实现参考：http://blog.csdn.net/kai_ding/article/details/9206057 理解链接我们知道文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。图展示了程序通过文件名获取文件内容的过程。 移动或重命名文件12345678910# stat /home/harris/source/glibc-2.16.0.tar.xz File: `/home/harris/source/glibc-2.16.0.tar.xz&apos; Size: 9990512 Blocks: 19520 IO Block: 4096 regular fileDevice: 807h/2055d Inode: 2485677 Links: 1Access: (0600/-rw-------) Uid: ( 1000/ harris) Gid: ( 1000/ harris)......# mv /home/harris/source/glibc-2.16.0.tar.xz /home/harris/Desktop/glibc.tar.xz# ls -i -F /home/harris/Desktop/glibc.tar.xz2485677 /home/harris/Desktop/glibc.tar.xz 在 Linux 系统中查看 inode 号可使用命令 stat 或 ls -i（若是 AIX 系统，则使用命令 istat）。清单 3.中使用命令 mv 移动并重命名文件 glibc-2.16.0.tar.xz，其结果不影响文件的用户数据及 inode 号，文件移动前后 inode 号均为：2485677。为解决文件的共享使用，Linux 系统引入了两种链接：硬链接 (hard link) 与软链接（又称符号链接，即 soft link 或 symbolic link）。 为 Linux 系统解决了文件的共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。若一个inode号对应多个文件名，则称这些文件为硬链接。换言之，硬链接就是同一个文件使用了多个别名。硬链接可由命令 link 或 ln 创建。如下是对文件 oldfile 创建硬链接。12link oldfile newfileln oldfile newfile 由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性： 文件有相同的 inode 及 data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 不能对目录进行创建，只可对文件创建； 删除一个硬链接文件并不影响其他有相同 inode 号的文件。 创建一个链接的步骤大概如下： 通过原文件的文件名找到文件的i-节点号 添加文件名关联到目录，新文件的名字是mylink 内核将文件的入口(921130,mylink)添加到目录文件里。 和创建文件的过程比较发现，链接少了写文件内容的步骤，完全相同的是把文件名关联到目录这一步现在.i- 节点号921130对应了两个文件名。链接数也会变成2个，文件的内容并不会发生任何变化。前面我们已经讲了：目录包含的是文件的引用，每个引用被称为链接。所以链接文件和原始文件本质上是一样的，因为它们都是指向同一个i-节点。由于此原因也就可以理解链接的下列特性：你改变其中任何一个文件的内容，别的链接文件也一样是变化；另外如果你删除某一个文件，系统只会在所指向的i-节点上把链接数减1，只有当链接数减为零时才会真正释放i-节点。硬链接有两个特点： 不能跨文件系统 不能对目录 123456789101112131415161718192021222324252627282930313233# ls -li total 0 // 只能对已存在的文件创建硬连接 # link old.file hard.link link: cannot create link `hard.link&apos; to `old.file&apos;: No such file or directory # echo &quot;This is an original file&quot; &gt; old.file # cat old.file This is an original file # stat old.file File: `old.file&apos; Size: 25 Blocks: 8 IO Block: 4096 regular file Device: 807h/2055d Inode: 660650 Links: 2 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) ... // 文件有相同的 inode 号以及 data block # link old.file hard.link | ls -li total 8 660650 -rw-r--r-- 2 root root 25 Sep 1 17:44 hard.link 660650 -rw-r--r-- 2 root root 25 Sep 1 17:44 old.file // 不能交叉文件系统 # ln /dev/input/event5 /root/bfile.txt ln: failed to create hard link `/root/bfile.txt&apos; =&gt; `/dev/input/event5&apos;: Invalid cross-device link // 不能对目录进行创建硬连接 # mkdir -p old.dir/test # ln old.dir/ hardlink.dir ln: `old.dir/&apos;: hard link not allowed for directory # ls -iF 660650 hard.link 657948 old.dir/ 660650 old.file 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块（见 图 2.）。因此软链接的创建与使用没有类似硬链接的诸多限制：软链接有自己的文件属性及权限等；可对不存在的文件或目录创建软链接；软链接可交叉文件系统；软链接可对文件或目录创建；创建软链接时，链接计数 i_nlink 不会增加；删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。 软链接实际上只是一段文字，里面包含着它所指向的文件的名字，系统看到软链接后自动跳到对应的文件位置处进行处理；相反，硬链接为文件开设一个新的目录项，硬链接与文件原有的名字是平权的，在Linux看来它们是等价的。由于这个原因，硬链接不能连接两个不同文件系统上的文件。 软连接与windows下的快捷方式类似至于硬连接，举个例子说吧，你把dir1/file1硬连接到dir2/file2, 就是在dir2下建立一个dir1/file1的镜像文件file2，它与file1是占用一样大的空间的，并且改动两者中的一个，另一个也会发生同样的改动.软连接和硬连接可以这样理解：硬连接就像一个文件有多个文件名，软连接就是产生一个新文件(这个文件内容,实际上就是记当要链接原文件路径的信息)，这个文件指向另一个文件的位置，硬连接必须在同一文件系统中，而软连接可以跨文件系统硬连接 ：源文件名和链接文件名都指向相同的物理地址，目录不能够有硬连接，文件在磁盘中只有一个复制，可以节省硬盘空间，由于删除文件要在同一个索引节点属于唯一的连接时才能成功，因此可以防止不必要的误删除软连接（符号连接）用ln -s命令创建文件的符号连接，符号连接是linux特殊文件的一种，作为一个文件，它的资料是它所连接的文件的路径名，类似于硬件方式，**可以删除原始文件 而连接文件仍然存在。** 12345678910111213141516171819202122232425262728# ls -li total 0 // 可对不存在的文件创建软链接 # ln -s old.file soft.link # ls -liF total 0 789467 lrwxrwxrwx 1 root root 8 Sep 1 18:00 soft.link -&gt; old.file // 由于被指向的文件不存在，此时的软链接 soft.link 就是死链接 # cat soft.link cat: soft.link: No such file or directory // 创建被指向的文件 old.file，soft.link 恢复成正常的软链接 # echo &quot;This is an original file_A&quot; &gt;&gt; old.file # cat soft.link This is an original file_A // 对不存在的目录创建软链接 # ln -s old.dir soft.link.dir # mkdir -p old.dir/test # tree . -F --inodes . ├ [ 789497] old.dir/ │ └ [ 789498] test/ ├ [ 789495] old.file ├ [ 789495] soft.link -&gt; old.file └ [ 789497] soft.link.dir -&gt; old.dir/ 文件节点inode可以看到inode节点好比是文件的大脑，下面就详细介绍一下inode。 inode是什么理解inode，要从文件储存说起。 扇区（sector）:硬件（磁盘）上的最小的操作单位,是操作系统和块设备（硬件、磁盘）之间传送数据的单位。 block由一个或多个sector组成，文件系统中最小的操作单位；OS的虚拟文件系统从硬件设备上读取一个block，实际为从硬件设备读取一个或多个sector。对于文件管理来说，每个文件对应的多个block可能是不连续的; block最终要映射到sector上，所以block的大小一般是sector的整数倍。不同的文件系统block可使用不同的大小，操作系统会在内存中开辟内存，存放block到所谓的block buffer中。在Ext2中，物理块的大小是可变化的，这取决于在创建文件系统时的选择，之所以不限制大小，也正体现了Ext2的灵活性和可扩充性。通常，Ext2的物理块占一个或几个连续的扇区，显然，物理块的数目是由磁盘容量等硬件因素决定的。具体文件系统所操作的基本单位是逻辑块，只在需要进行I/O操作时才进行逻辑块到物理块的映射，这显然避免了大量的I/O操作，因而文件系统能够变得高效。逻辑块作为一个抽象的概念，它必然要映射到具体的物理块上去，因此，逻辑块的大小必须是物理块大小的整数倍，一般说来，两者是一样大的。 通常，一个文件占用的多个物理块在磁盘上是不连续存储的，因为如果连续存储，则经过频繁的删除、建立、移动文件等操作，最后磁盘上将形成大量的空洞，很快磁盘上将无空间可供使用。因此，必须提供一种方法将一个文件占用的多个逻辑块映射到对应的非连续存储的物理块上去，Ext2等类文件系统是用索引节点解决这个问题的。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。在Unix/Linux上，一个文件由一个inode 表示。inode在系统管理员看来是每一个文件的唯一标识，在系统里面，inode是一个结构，存储了关于这个文件的大部分信息。 inode内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的UserID*文件的GroupID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode*文件数据block的位置可以用stat命令，查看某个文件的inode信息：statexample.txt总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode中存储了一个文件的以下信息: inode结构123456789101112131415161718192021222324252627282930313233343536373839404142434445struct inode &#123; struct hlist_node i_hash; /* 哈希表 */ struct list_head i_list; /* 索引节点链表 */ struct list_head i_dentry; /* 目录项链表 */ unsigned long i_ino; /* 节点号 */ atomic_t i_count; /* 引用记数 */ umode_t i_mode; /* 访问权限控制 */ unsigned int i_nlink; /* 硬链接数 */ uid_t i_uid; /* 使用者id */ gid_t i_gid; /* 使用者id组 */ kdev_t i_rdev; /* 实设备标识符 */ loff_t i_size; /* 以字节为单位的文件大小 */ struct timespec i_atime; /* 最后访问时间 */ struct timespec i_mtime; /* 最后修改(modify)时间 */ struct timespec i_ctime; /* 最后改变(change)时间 */ unsigned int i_blkbits; /* 以位为单位的块大小 */ unsigned long i_blksize; /* 以字节为单位的块大小 */ unsigned long i_version; /* 版本号 */ unsigned long i_blocks; /* 文件的块数 */ unsigned short i_bytes; /* 使用的字节数 */ spinlock_t i_lock; /* 自旋锁 */ struct rw_semaphore i_alloc_sem; /* 索引节点信号量 */ struct inode_operations *i_op; /* 索引节点操作表 */ struct file_operations *i_fop; /* 默认的索引节点操作 */ struct super_block *i_sb; /* 相关的超级块 */ struct file_lock *i_flock; /* 文件锁链表 */ struct address_space *i_mapping; /* 相关的地址映射 */ struct address_space i_data; /* 设备地址映射 */ struct dquot *i_dquot[MAXQUOTAS]; /* 节点的磁盘限额 */ struct list_head i_devices; /* 块设备链表 */ struct pipe_inode_info *i_pipe; /* 管道信息 */ struct block_device *i_bdev; /* 块设备驱动 */ unsigned long i_dnotify_mask; /* 目录通知掩码 */ struct dnotify_struct *i_dnotify; /* 目录通知 */ unsigned long i_state; /* 状态标志 */ unsigned long dirtied_when; /* 首次修改时间 */ unsigned int i_flags; /* 文件系统标志 */ unsigned char i_sock; /* 可能是个套接字吧 */ atomic_t i_writecount; /* 写者记数 */ void *i_security; /* 安全模块 */ __u32 i_generation; /* 索引节点版本号 */ union &#123; void *generic_ip; /* 文件特殊信息 */ &#125; u;&#125;; inode就是一个文件的一部分描述，不是全部，在内核中，inode对应了这样一个实际存在的结构。复制代码纵观整个inode的C语言描述，没有发现关于文件名的东西，也就是说文件名不由inode保存，实际上系统是不关心文件名的，对于系统中任何的操作，大部分情况下你都是通过文件名来做的，但系统最终都要通过找到文件对应的inode来操作文件，由inode结构中 *i_op指向的接口来操作。文件系统如何存取文件的： 根据文件名，通过Directory里的对应关系，找到文件对应的Inodenumber 再根据Inodenumber读取到文件的Inodetable 再根据Inodetable中的Pointer读取到相应的Blocks 这里有一个重要的内容，就是Directory，他不是我们通常说的目录，而是一个列表，记录了一个文件/目录名称对应的Inodenumber。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hash碰撞冲突方法总结]]></title>
    <url>%2F2019%2F05%2F05%2F%E8%A7%A3%E5%86%B3Hash%E7%A2%B0%E6%92%9E%E5%86%B2%E7%AA%81%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Hash碰撞冲突我们知道，对象Hash的前提是实现equals()和hashCode()两个方法，那么HashCode()的作用就是保证对象返回唯一hash值，但当两个对象计算值一样时，这就发生了碰撞冲突。如下将介绍如何处理冲突，当然其前提是一致性hash。 开放地址法开放地执法有一个公式:Hi=(H(key)+di) MOD m i=1,2,…,k(k&lt;=m-1)其中，m为哈希表的表长。di 是产生冲突的时候的增量序列。如果di值可能为1,2,3,…m-1，称线性探测再散列。如果di取1，则每次冲突之后，向后移动1个位置.如果di取值可能为1,-1,2,-2,4,-4,9,-9,16,-16,…kk,-kk(k&lt;=m/2)，称二次探测再散列。如果di取值可能为伪随机数列。称伪随机探测再散列。 再哈希法当发生冲突时，使用第二个、第三个、哈希函数计算地址，直到无冲突时。缺点：计算时间增加。比如上面第一次按照姓首字母进行哈希，如果产生冲突可以按照姓字母首字母第二位进行哈希，再冲突，第三位，直到不冲突为止 链地址法（拉链法）将所有关键字为同义词的记录存储在同一线性链表中。如下： 因此这种方法，可以近似的认为是筒子里面套筒子 建立一个公共溢出区假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]用以存储发生冲突的记录。 拉链法的优缺点：优点： 拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； 由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元(即开放地址)都是查找失败的条件。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。 缺点： 指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多阶hash表]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%A4%9A%E9%98%B6hash%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[原文:https://blog.csdn.net/wm_1991/article/details/52218718 多阶hash表实际上是一个锯齿数组，看起来是这个样子的：■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 每一行是一阶，上面的元素个数多，下面的元素个数依次减少。每一行的元素个数都是素数的。 数组的每个节点用于存储数据的内容，其中，节点的前四个字节用于存储int类型的key或者是hash_code 创建多阶HASH的时候，用户通过参数来指定有多少阶，每一阶最多多少个元素。那么，下面的每一阶究竟应该选择多少个元素呢？从代码注释上看来，是采用了素数集中原理的算法来查找的。例如，假设每阶最多1000个元素，一共10阶，则算法选择十个比1000小的最大素数，从大到小排列，以此作为各阶的元素个数。通过素数集中的算法得到的10个素数分别是：997 991 983 977 971 967 953 947 941 937。可见，虽然是锯齿数组，各层之间的差别并不是很多。 查找过程： 先将key在第一阶内取模，看是否是这个元素，如果这个位置为空，直接返回不存在；如果是这个KEY，则返回这个位置。 如果这个位置有元素，但是又不是这个key，则说明hash冲突，再到第二阶去找。 循环往复。 好处： hash冲突的处理非常简单； 有多个桶，使得空间利用率很高，你并不需要一个很大的桶来减少冲突。 可以考虑动态增长空间，不断加入新的一阶，且对原来的数据没影响。 使用共享内存的多级哈希表的一种实现在一个服务程序运行的时候，它往往要把数据写入共享内存以便在进城需要重新启动的时候可以直接从共享内存中读取数据，另一方面，在服务进程因某种原因挂掉的时候，共享内存中的数据仍然存在，这样就可以减少带来的损失。关于共享内存的内容请google之，在这里，实现了一种在共享内存中存取数据的hash表，它采用了多级存储求模取余的方法，具体内容请看以下代码：http://lmlf001.blog.sohu.com/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237//hash_shm.h#ifndef _STORMLI_HASH_SHM_H_#define _STORMLI_HASH_SHM_H_#include&lt;iostream&gt;#include&lt;cstdlib&gt;#include&lt;cmath&gt;#include&lt;sys/shm.h&gt;using namespace std;template&lt;typename valueType,unsigned long maxLine,int lines&gt;class hash_shm&#123;public: int find(unsigned long _key); //if _key in the table,return 0,and set lastFound the position,otherwise return -1 int remove(unsigned long _key); //if _key not in the table,return-1,else remove the node,set the node key 0 and return 0 //insert node into the table,if the _key exists,return 1,if insert success,return 0;and if fail return -1 int insert(unsigned long _key,const valueType &amp;_value); void clear(); //remove all the datapublic: //some statistic function double getFullRate()const; //the rate of the space used public: //constructor,with the share memory start position and the space size,if the space is not enough,the program will exit hash_shm(void *startShm,unsigned long shmSize=sizeof(hash_node)*maxLine*lines); //constructor,with the share memory key,it will get share memory,if fail,exit hash_shm(key_t shm_key); ~hash_shm()&#123;&#125; //destroy the classprivate: void *mem; //the start position of the share memory // the mem+memSize space used to storage the runtime data:currentSize unsigned long memSize; //the size of the share memory unsigned long modTable[lines]; //modtable,the largest primes unsigned long maxSize; //the size of the table unsigned long *currentSize; //current size of the table ,the pointer of the shm mem+memSize void *lastFound; //write by the find function,record the last find place struct hash_node&#123; //the node of the hash table unsigned long key; //when key==0,the node is empty valueType value; //name-value pair &#125;;private: bool getShm(key_t shm_key); //get share memory,used by the constructor void getMode(); //get the largest primes blow maxLine,use by the constructor void *getPos(unsigned int _row,unsigned long _col); //get the positon with the (row,col)&#125;;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(void *startShm,unsigned long shmSize)&#123; if(startShm!=NULL)&#123; cerr&lt;&lt;&quot;Argument error\n Please check the shm address\n&quot;; exit(-1); &#125; getMode(); maxSize=0; int i; for(i=0;i&lt;lines;i++) //count the maxSize maxSize+=modTable[i]; if(shmSize&lt;sizeof(hash_node)*(maxSize+1))&#123; //check the share memory size cerr&lt;&lt;&quot;Not enough share memory space\n&quot;; exit(-1); &#125; memSize=shmSize; if(*(currentSize=(unsigned long *)((long)mem+memSize))&lt;0) *currentSize=0;;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(key_t shm_key)&#123; //constructor with get share memory getMode(); maxSize=0; for(int i=0;i&lt;lines;i++) maxSize+=modTable[i]; memSize=sizeof(hash_node)*maxSize; if(!getShm(shm_key))&#123; exit(-1); &#125;// memset(mem,0,memSize); if(*(currentSize=(unsigned long *)((long)mem+memSize))&lt;0) *currentSize=0;&#125; template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::find(unsigned long _key)&#123; unsigned long hash; hash_node *pH=NULL; for(int i=0;i&lt;lines;i++) &#123; hash=(_key+maxLine)%modTable[i]; //calculate the col position pH=(hash_node *)getPos(i,hash);// if(pH==NULL)return -2; //almost not need if(pH-&gt;key==_key)&#123; lastFound=pH; return 0; &#125; &#125; return -1;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::remove(unsigned long _key)&#123; if(find(_key)==-1)return -1; //not found hash_node *pH=(hash_node *)lastFound; pH-&gt;key=0; //only set the key 0 (*currentSize)--; return 0;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::insert(unsigned long _key,const vT &amp;_value)&#123; if(find(_key)==0)return 1; //if the key exists unsigned long hash; hash_node *pH=NULL; for(int i=0;i&lt;lines;i++)&#123; hash=(_key+maxLine)%modTable[i]; pH=(hash_node *)getPos(i,hash); if(pH-&gt;key==0)&#123; //find the insert position,insert the value pH-&gt;key=_key; pH-&gt;value=_value; (*currentSize)++; return 0; &#125; &#125; return -1; //all the appropriate position filled&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::clear()&#123; memset(mem,0,memSize); *currentSize=0;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;bool hash_shm&lt;vT,maxLine,lines&gt;::getShm(key_t shm_key)&#123; int shm_id=shmget(shm_key,memSize,0666); if(shm_id==-1) //check if the shm exists &#123; shm_id=shmget(shm_key,memSize,0666|IPC_CREAT);//create the shm if(shm_id==-1)&#123; cerr&lt;&lt;&quot;Share memory get failed\n&quot;; return false; &#125; &#125; mem=shmat(shm_id,NULL,0); //mount the shm if(int(mem)==-1)&#123; cerr&lt;&lt;&quot;shmat system call failed\n&quot;; return false; &#125; return true;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::getMode()&#123; //采用 6n+1 6n-1 素数集中原理 if(maxLine&lt;5)&#123;exit(-1);&#125; unsigned long t,m,n,p; int i,j,a,b,k; int z=0; for(t=maxLine/6;t&gt;=0,z&lt;lines;t--) &#123; i=1;j=1; k=t%10; m=6*t; /**i,j的值 是是否进行验证的标志也是对应的6t-1和6t+1的素性标志**/ if(((k-4)==0)||((k-9)==0)||((m+1)%3==0))j=0;/*此处是简单验证6*t-1,6*t+1 是不是素数，借以提高素数纯度**/ if(((k-6)==0)||((m-1)%3==0))i=0; /***先通过初步判断去除末尾是5，及被3整除的数***/ for(p=1;p*6&lt;=sqrt(m+1)+2;p++ ) &#123; n=p*6; /**将6*p-1和6*p+1看作伪素数来试除*****/ k=p%10; a=1;b=1; /**同样此处a,b的值也是用来判断除数是否为素数提高除数的素数纯度**/ if(((k-4)==0)||((k-9)==0))a=0; if(((k-6)==0))b=0; if(i)&#123; /*如果i非零就对m-1即所谓6*t-1进行验证，当然还要看除数n+1,n-1,素性纯度*/ if(a)&#123;if((m-1)%(n+1)==0)i=0;&#125; /***一旦被整除就说明不是素数故素性为零即将i 赋值为零***/ if(b)&#123;if((m-1)%(n-1)==0)i=0;&#125; &#125; if(j)&#123; /**如果j非零就对m+1即所谓6*t+1进行验证，当然还要看除数n+1,n-1,素性纯度*/ if(a)&#123;if((m+1)%(n+1)==0)j=0;&#125; /***一旦被整除就说明不是素数故素性为零即将j 赋值为零***/ if(b)&#123;if((m+1)%(n-1)==0)j=0;&#125; &#125; if((i+j)==0)break; /**如果已经知道6*t-1,6*t+1都不是素数了那就结束试除循环***/ &#125; if(j)&#123;modTable[z++]=m+1;if(z&gt;= lines)return;&#125; if(i)&#123;modTable[z++]=m-1;if(z&gt;= lines)return;&#125; &#125;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void *hash_shm&lt;vT,maxLine,lines&gt;::getPos(unsigned int _row,unsigned long _col)&#123; unsigned long pos=0UL; for(int i=0;i&lt;_row;i++) //calculate the positon from the start pos+=modTable[i]; pos+=_col; if(pos&gt;=maxSize)return NULL; return (void *)((long)mem+pos*sizeof(hash_node));&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;double hash_shm&lt;vT,maxLine,lines&gt;::getFullRate()const&#123; return double(*currentSize)/maxSize;&#125;#endif 1234567891011121314151617181920212223//test.cpp#include&quot;hash_shm.h&quot;#include&lt;cstdlib&gt;using namespace std;int main()&#123; hash_shm&lt;int,1000,100&gt; ht(key_t(999)); double rate=0.0;// ht.clear(); for(int i=0;i&lt;100;i++)&#123; srand(time(NULL)+i); while(true)&#123; if(ht.insert(rand(),0)==-1)break; &#125; cout&lt;&lt;ht.getFullRate()&lt;&lt;endl; rate+=ht.getFullRate(); ht.clear(); &#125; cout&lt;&lt;&quot;\n\n\n&quot;; cout&lt;&lt;rate/100&lt;&lt;endl;&#125; 这段代码作测试的时候发现了一些问题，用gprof查看函数时间的时候发现，getPos函数占用了大部分的执行时间，始主要的性能瓶颈，后来又新设立了一个数组，用来记录每行开始时的位置，性能提高了很多，改动部分的代码如下：1234567891011121314151617181920212223242526272829303132333435363738template&lt;typename valueType,unsigned long maxLine,int lines&gt;class hash_shm&#123;private: void *mem; //the start position of the share memory // the mem+memSize space used to storage the runtime data:currentSize unsigned long memSize; //the size of the share memory unsigned long modTable[lines]; //modtable,the largest primes unsigned long modTotal[lines]; //modTotal[i] is the summary of the modTable when x&lt;=i //used by getPos to improve the performance ...&#125;;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(void *startShm,unsigned long shmSize)&#123; ... int i; for(i=0;i&lt;lines;i++)&#123; //count the maxSize maxSize+=modTable[i]; if(i!=0)modTotal[i]=modTotal[i-1]+modTable[i-1]; else modTotal[i]=0; //caculate the modTotal &#125; ...&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(key_t shm_key)&#123; //constructor with get share memory getMode(); maxSize=0; for(int i=0;i&lt;lines;i++)&#123; maxSize+=modTable[i]; if(i!=0)modTotal[i]=modTotal[i-1]+modTable[i-1]; else modTotal[i]=0; &#125; ...&#125; 12345678910template&lt;typename vT,unsigned long maxLine,int lines&gt;void *hash_shm&lt;vT,maxLine,lines&gt;::getPos(unsigned int _row,unsigned long _col)&#123; unsigned long pos=_col+modTotal[_row]; //for(int i=0;i&lt;_row;i++) //calculate the positon from the start // pos+=modTable[i]; if(pos&lt;maxSize) return (void *)((long)mem+pos*sizeof(hash_node)); return NULL; &#125; 新增了一个用于遍历的函数foreach12345678910111213template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::foreach(void (*fn)(unsigned long _key,vT &amp;_value))&#123; typedef unsigned long u_long; u_long beg=(u_long)mem; u_long end=(u_long)mem+sizeof(hash_node)*(modTable[lines-1]+modTotal[lines-1]); hash_node *p=NULL; for(u_long pos=beg;pos&lt;end;pos+=sizeof(hash_node)) &#123; p=(hash_node *)pos; if(p-&gt;key!=0)fn(p-&gt;key,p-&gt;value); &#125;&#125; 为了利于使用新增一个用于查找的函数find,该函数同find(_key)类似，如果找到_key节点，把它赋给_value以返回1int find(unsigned long _key,vT &amp;_value);]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解inode]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%90%86%E8%A7%A3inode%2F</url>
    <content type="text"><![CDATA[原文：http://www.ruanyifeng.com/blog/2011/12/inode.html inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 inode的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 用stat命令，查看某个文件的inode信息： 总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1 df -i 查看每个inode节点的大小，可以用如下命令：1sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码：1 ls -i example.txt 目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。 目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls命令只列出目录文件中的所有文件名：1 ls /etc ls -i命令列出整个目录文件，即文件名和inode号码：1 ls -i /etc 如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。1 ls -l /etc 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接：1 ln 源文件 目标文件 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 软链接除了硬链接以外，还有一种特殊情况。 文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 ln -s命令可以创建软链接。1 ln -s 源文文件或目录 目标文件或目录 inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统调用的实现机制分析]]></title>
    <url>%2F2019%2F05%2F04%2FLinux%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[转载自：http://blog.csdn.net/sailor_8318/archive/2008/09/10/2906968.aspx 系统调用意义linux内核中设置了一组用于实现系统功能的子程序，称为系统调用。系统调用和普通库函数调用非常相似，只是系统调用由操作系统核心提供，运行于核心态，而普通的函数调用由函数库或用户自己提供，运行于用户态。 一般的，进程是不能访问内核的。它不能访问内核所占内存空间也不能调用内核函数。CPU硬件决定了这些（这就是为什么它被称作”保护模式”）。为了和用户空间上运行的进程进行交互，内核提供了一组接口。透过该接口，应用程序可以访问硬件设备和其他操作系统资源。这组接口在应用程序和内核之间扮演了使者的角色，应用程序发送各种请求，而内核负责满足这些请求(或者让应用程序暂时搁置)。实际上提供这组接口主要是为了保证系统稳定可靠，避免应用程序肆意妄行，惹出大麻烦。 系统调用在用户空间进程和硬件设备之间添加了一个中间层。该层主要作用有三个： 它为用户空间提供了一种统一的硬件的抽象接口。比如当需要读些文件的时候，应用程序就可以不去管磁盘类型和介质，甚至不用去管文件所在的文件系统到底是哪种类型。 系统调用保证了系统的稳定和安全。作为硬件设备和应用程序之间的中间人，内核可以基于权限和其他一些规则对需要进行的访问进行裁决。举例来说，这样可以避免应用程序不正确地使用硬件设备，窃取其他进程的资源，或做出其他什么危害系统的事情。 每个进程都运行在虚拟系统中，而在用户空间和系统的其余部分提供这样一层公共接口，也是出于这种考虑。如果应用程序可以随意访问硬件而内核又对此一无所知的话，几乎就没法实现多任务和虚拟内存，当然也不可能实现良好的稳定性和安全性。在Linux中，系统调用是用户空间访问内核的惟一手段；除异常和中断外，它们是内核惟一的合法入口。 API/POSIX/C库的关系一般情况下，应用程序通过应用编程接口(API)而不是直接通过系统调用来编程。这点很重要，因为应用程序使用的这种编程接口实际上并不需要和内核提供的系统调用一一对应。一个API定义了一组应用程序使用的编程接口。它们可以实现成一个系统调用，也可以通过调用多个系统调用来实现，而完全不使用任何系统调用也不存在问题。实际上，API可以在各种不同的操作系统上实现，给应用程序提供完全相同的接口，而它们本身在这些系统上的实现却可能迥异。 在Unix世界中，最流行的应用编程接口是基于POSIX标准的，其目标是提供一套大体上基于Unix的可移植操作系统标准。POSIX是说明API和系统调用之间关系的一个极好例子。在大多数Unix系统上，根据POSIX而定义的API函数和系统调用之间有着直接关系。 Linux的系统调用像大多数Unix系统一样，作为C库的一部分提供如下图所示。C库实现了 Unix系统的主要API，包括标准C库函数和系统调用。所有的C程序都可以使用C库，而由于C语言本身的特点，其他语言也可以很方便地把它们封装起来使用。 从程序员的角度看，系统调用无关紧要，他们只需要跟API打交道就可以了。相反，内核只跟系统调用打交道；库函数及应用程序是怎么使用系统调用不是内核所关心的。 关于Unix的界面设计有一句通用的格言“提供机制而不是策略”。换句话说，Unix的系统调用抽象出了用于完成某种确定目的的函数。至干这些函数怎么用完全不需要内核去关心。区别对待机制(mechanism)和策略(policy)是Unix设计中的一大亮点。大部分的编程问题都可以被切割成两个部分:“需要提供什么功能”(机制)和“怎样实现这些功能”(策略)。 系统调用的实现系统调用处理程序“当我输入 cat /proc/cpuinfo 时，cpuinfo() 函数是如何被调用的？”内核完成引导后，控制流就从相对直观的“接下来调用哪个函数？”改变为取决于系统调用、异常和中断。 用户空间的程序无法直接执行内核代码。它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。如果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。 通知内核的机制是靠软件中断实现的。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。x86系统上的软中断由int产生。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并跳转到一个新的地址，并开始执行那里的异常处理程序。此时的异常处理程序实际上就是系统调用处理程序。它与硬件体系结构紧密相关。 新地址的指令会保存程序的状态，计算出应该调用哪个系统调用，调用内核中实现那个系统调用的函数，恢复用户程序状态，然后将控制权返还给用户程序。系统调用是设备驱动程序中定义的函数最终被调用的一种方式。 系统调用号在Linux中，每个系统调用被赋予一个系统调用号。这样，通过这个独一无二的号就可以关联系统调用。当用户空间的进程执行一个系统调用的时候，这个系统调用号就被用来指明到底是要执行哪个系统调用。进程不会提及系统调用的名称。 系统调用号相当关键，一旦分配就不能再有任何变更，否则编译好的应用程序就会崩溃。Linux有一个“未实现”系统调用sys_ni_syscall()，它除了返回一ENOSYS外不做任何其他工作，这个错误号就是专门针对无效的系统调用而设的。 因为所有的系统调用陷入内核的方式都一样，所以仅仅是陷入内核空间是不够的。因此必须把系统调用号一并传给内核。在x86上，系统调用号是通过eax寄存器传递给内核的。在陷人内核之前，用户空间就把相应系统调用所对应的号放入eax中了。这样系统调用处理程序一旦运行，就可以从eax中得到数据。其他体系结构上的实现也都类似。 内核记录了系统调用表中的所有已注册过的系统调用的列表，存储在sys_call_table中。它与体系结构有关，一般在entry.s中定义。这个表中为每一个有效的系统调用指定了惟一的系统调用号。sys_call_table是一张由指向实现各种系统调用的内核函数的函数指针组成的表：12345678910111213141516ENTRY(sys_call_table).long SYMBOL_NAME(sys_ni_syscall) /* 0 - old &quot;setup()&quot; system call*/.long SYMBOL_NAME(sys_exit).long SYMBOL_NAME(sys_fork).long SYMBOL_NAME(sys_read).long SYMBOL_NAME(sys_write).long SYMBOL_NAME(sys_open) /* 5 */.long SYMBOL_NAME(sys_close).long SYMBOL_NAME(sys_waitpid).long SYMBOL_NAME(sys_capget).long SYMBOL_NAME(sys_capset) /* 185 */.long SYMBOL_NAME(sys_sigaltstack).long SYMBOL_NAME(sys_sendfile).long SYMBOL_NAME(sys_ni_syscall) /* streams1 */.long SYMBOL_NAME(sys_ni_syscall) /* streams2 */.long SYMBOL_NAME(sys_vfork) /* 190 */ system_call()函数通过将给定的系统调用号与NR_syscalls做比较来检查其有效性。如果它大于或者等于NR syscalls,该函数就返回一ENOSYS。否则，就执行相应的系统调用。1call *sys_ call-table(，%eax, 4) 由于系统调用表中的表项是以32位(4字节)类型存放的，所以内核需要将给定的系统调用号乘以4，然后用所得的结果在该表中查询其位置 参数传递除了系统调用号以外，大部分系统调用都还需要一些外部的参数输人。所以，在发生异常的时候，应该把这些参数从用户空间传给内核。最简单的办法就是像传递系统调用号一样把这些参数也存放在寄存器里。在x86系统上，ebx, ecx, edx, esi和edi按照顺序存放前五个参数。需要六个或六个以上参数的情况不多见，此时，应该用一个单独的寄存器存放指向所有这些参数在用户空间地址的指针。 给用户空间的返回值也通过寄存器传递。在x86系统上，它存放在eax寄存器中。接下来许多关于系统调用处理程序的描述都是针对x86版本的。但不用担心，所有体系结构的实现都很类似。 参数验证系统调用必须仔细检查它们所有的参数是否合法有效。举例来说，与文件I/O相关的系统调用必须检查文件描述符是否有效。与进程相关的函数必须检查提供的PID是否有效。必须检查每个参数，保证它们不但合法有效，而且正确。 最重要的一种检查就是检查用户提供的指针是否有效。试想，如果一个进程可以给内核传递指针而又无须被检查，那么它就可以给出一个它根本就没有访问权限的指针，哄骗内核去为它拷贝本不允许它访问的数据，如原本属于其他进程的数据。在接收一个用户空间的指针之前，内核必须保证： 指针指向的内存区域属于用户空间。进程决不能哄骗内核去读内核空间的数据。 指针指向的内存区域在进程的地址空间里。进程决不能哄骗内核去读其他进程的数据。 如果是读，该内存应被标记为可读。如果是写，该内存应被标记为可写。进程决不能绕过内存访问限制。 内核提供了两个方法来完成必须的检查和内核空间与用户空间之间数据的来回拷贝。注意，内核无论何时都不能轻率地接受来自用户空间的指针!这两个方法中必须有一个被调用。为了向用户空间写入数据，内核提供了copy_to_user()，它需要三个参数。第一个参数是进程空间中的目的内存地址。第二个是内核空间内的源地址。最后一个参数是需要拷贝的数据长度(字节数)。 为了从用户空间读取数据，内核提供了copy_from_ user()，它和copy-to-User()相似。该函数把第二个参数指定的位置上的数据拷贝到第一个参数指定的位置上，拷贝的数据长度由第三个参数决定。 如果执行失败，这两个函数返回的都是没能完成拷贝的数据的字节数。如果成功，返回0。当出现上述错误时，系统调用返回标准-EFAULT。 注意copy_to_user()和copy_from_user()都有可能引起阻塞。当包含用户数据的页被换出到硬盘上而不是在物理内存上的时候，这种情况就会发生。此时，进程就会休眠，直到缺页处理程序将该页从硬盘重新换回物理内存。 系统调用的返回值系统调用(在Linux中常称作syscalls)通常通过函数进行调用。它们通常都需要定义一个或几个参数(输入)而且可能产生一些副作用，例如写某个文件或向给定的指针拷贝数据等等。为防止和正常的返回值混淆，系统调用并不直接返回错误码，而是将错误码放入一个名为errno的全局变量中。通常用一个负的返回值来表明错误。返回一个0值通常表明成功。如果一个系统调用失败，你可以读出errno的值来确定问题所在。通过调用perror()库函数，可以把该变量翻译成用户可以理解的错误字符串。 errno不同数值所代表的错误消息定义在errno.h中，你也可以通过命令”man 3 errno”来察看它们。需要注意的是，errno的值只在函数发生错误时设置，如果函数不发生错误，errno的值就无定义，并不会被置为0。另外，在处理errno前最好先把它的值存入另一个变量，因为在错误处理过程中，即使像printf()这样的函数出错时也会改变errno的值。 当然，系统调用最终具有一种明确的操作。举例来说，如getpid()系统调用，根据定义它会返回当前进程的PID。内核中它的实现非常简单:1234asmlinkage long sys_ getpid(void)&#123; return current-&gt; tgid;&#125; 上述的系统调用尽管非常简单，但我们还是可以从中发现两个特别之处。首先，注意函数声明中的asmlinkage限定词，这是一个小戏法，用于通知编译器仅从栈中提取该函数的参数。所有的系统调用都需要这个限定词。其次，注意系统调用get_pid()在内核中被定义成sys_ getpid。这是Linux中所有系统调用都应该遵守的命名规则 添加新系统调用给Linux添加一个新的系统调用是件相对容易的工作。怎样设计和实现一个系统调用是难题所在，而把它加到内核里却无须太多周折。让我们关注一下实现一个新的Linux系统调用所需的步骤。 实现一个新的系统调用的第一步是决定它的用途。它要做些什么？每个系统调用都应该有一个明确的用途。在Linux中不提倡采用多用途的系统调用(一个系统调用通过传递不同的参数值来选择完成不同的工作)。ioctl()就应该被视为一个反例。 新系统调用的参数、返回值和错误码又该是什么呢？系统调用的接口应该力求简洁，参数尽可能少。设计接口的时候要尽量为将来多做考虑。你是不是对函数做了不必要的限制?系统调用设计得越通用越好。不要假设这个系统调用现在怎么用将来也一定就是这么用。系统调用的目的可能不变，但它的用法却可能改变。这个系统调用可移植吗?别对机器的字节长度和字节序做假设。当你写一个系统调用的时候，要时刻注意可移植性和健壮性，不但要考虑当前，还要为将来做打算。 当编写完一个系统调用后，把它注册成一个正式的系统调用是件琐碎的工作： 在系统调用表的最后加入一个表项。每种支持该系统调用的硬件体系都必须做这样的工作。从0开始算起，系统调用在该表中的位置就是它的系统调用号。 对于所支持的各种体系结构，系统调用号都必须定义于&lt;asm/unistd.h&gt;中。 系统调用必须被编译进内核映象(不能被编译成模块)。这只要把它放进kernel/下的一个相关文件中就可以。 让我们通过一个虚构的系统调用f00()来仔细观察一下这些步骤。首先，我们要把sys_foo加入到系统调用表中去。对于大多数体系结构来说，该表位干entry.s文件中，形式如下:123456ENTRY(sys_ call_ table) .long sys_ restart_ syscall/*0*/ .long sys_ exit .long sys_ fork .long sys_ read .long sys_write 我们把新的系统调用加到这个表的末尾:1.long sys_foo 虽然没有明确地指定编号，但我们加入的这个系统调用被按照次序分配给了283这个系统调用号。对于每种需要支持的体系结构，我们都必须将自己的系统调用加人到其系统调用表中去。每种体系结构不需要对应相同的系统调用号。 接下来，我们把系统调用号加入到&lt;asm/unistd.h&gt;中，它的格式如下:1234567/*本文件包含系统调用号*/#define_ NR_ restart_ syscall#define NR exit#define NR fork#define NR read#define NR write#define NR- mq getsetattr 282 然后，我们在该列表中加入下面这行:1#define_ NR_ foo 283 最后，我们来实现f00()系统调用。无论何种配置，该系统调用都必须编译到核心的内核映象中去，所以我们把它放进kernel/sys.c文件中。你也可以将其放到与其功能联系最紧密的代码中去1234asmlinkage long sys-foo(void)&#123; return THREAD SIZE) 就是这样!严格说来，现在就可以在用户空间调用f00()系统调用了。 建立一个新的系统调用非常容易，但却绝不提倡这么做。通常模块可以更好的代替新建一个系统调用。 访问系统调用系统调用上下文内核在执行系统调用的时候处于进程上下文。current指针指向当前任务，即引发系统调用的那个进程。 在进程上下文中，内核可以休眠并且可以被抢占。这两点都很重要。首先，能够休眠说明系统调用可以使用内核提供的绝大部分功能。休眠的能力会给内核编程带来极大便利。在进程上下文中能够被抢占，其实表明，像用户空间内的进程一样，当前的进程同样可以被其他进程抢占。因为新的进程可以使用相同的系统调用，所以必须小心，保证该系统调用是可重人的。当然，这也是在对称多处理中必须同样关心的问题。 当系统调用返回的时候，控制权仍然在system_call()中，它最终会负责切换到用户空间并让用户进程继续执行下去。 系统调用访问示例操作系统使用系统调用表将系统调用编号翻译为特定的系统调用。系统调用表包含有实现每个系统调用的函数的地址。例如，read() 系统调用函数名为 sys_read。read() 系统调用编号是 3，所以 sys_read()位于系统调用表的第四个条目中（因为系统调用起始编号为0）。从地址 sys_call_table + (3 * word_size) 读取数据，得到 sys_read()的地址。 找到正确的系统调用地址后，它将控制权转交给那个系统调用。我们来看定义 sys_read() 的位置，即fs/read_write.c 文件。这个函数会找到关联到 fd 编号（传递给 read() 函数的）的文件结构体。那个结构体包含指向用来读取特定类型文件数据的函数的指针。进行一些检查后，它调用与文件相关的 read() 函数，来真正从文件中读取数据并返回。与文件相关的函数是在其他地方定义的 —— 比如套接字代码、文件系统代码，或者设备驱动程序代码。这是特定内核子系统最终与内核其他部分协作的一个方面。 读取函数结束后，从sys_read()返回，它将控制权切换给ret_from_sys。它会去检查那些在切换回用户空间之前需要完成的任务。如果没有需要做的事情，那么就恢复用户进程的状态，并将控制权交还给用户程序。 从用户空间直接访问系统调用通常，系统调用靠C库支持。用户程序通过包含标准头文件并和C库链接，就可以使用系统调用(或者调用库函数，再由库函数实际调用)。但如果你仅仅写出系统调用，glibc库恐怕并不提供支持。值得庆幸的是，Linux本身提供了一组宏，用于直接对系统调用进行访问。它会设置好寄存器并调用陷人指令。这些宏是_syscalln()，其中n的范围从0到6。代表需要传递给系统调用的参数个数，这是由于该宏必须了解到底有多少参数按照什么次序压入寄存器。举个例子，open()系统调用的定义是:1long open(const char *filename, int flags, int mode) 而不靠库支持，直接调用此系统调用的宏的形式为:12#define NR_ open 5syscall3(long, open, const char*，filename, int, flags, int, mode) 这样，应用程序就可以直接使用open() 对于每个宏来说，都有2+ n个参数。第一个参数对应着系统调用的返回值类型。第二个参数是系统调用的名称。再以后是按照系统调用参数的顺序排列的每个参数的类型和名称。_NR_ open在&lt;asm/unistd.h&gt;中定义，是系统调用号。该宏会被扩展成为内嵌汇编的C函数。由汇编语言执行前一节所讨论的步骤，将系统调用号和参数压入寄存器并触发软中断来陷入内核。调用open()系统调用直接把上面的宏放置在应用程序中就可以了。 让我们写一个宏来使用前面编写的foo()系统调用，然后再写出测试代码炫耀一下我们所做的努力。123456789#define NR foo 283_sysca110(long, foo)int main()&#123; long stack size; stack_ size=foo(); printf(&quot;The kernel stack size is 81d/n&quot;，stack_ size); return;&#125; 系统调用表以下是Linux系统调用的一个列表，包含了大部分常用系统调用和由系统调用派生出的的函数。其中有一些函数的作用完全相同，只是参数不同。可能很多熟悉C++朋友马上就能联想起函数重载，但是别忘了Linux核心是用C语言写的，所以只能取成不同的函数名。 进程控制： 函数名 功能 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制文件读写操作 函数名 功能 fcntl 文件控制 open 打开文件 creat 创建新文件 lose 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 函数名 功能 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制 函数名 功能 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理 函数名 功能 brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理 函数名 功能 getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制 函数名 功能 socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理 函数名 功能 getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信 函数名 功能 ipc 进程间通信总控制调用 信号 函数名 功能 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI C的信号处理函数,作用类似sigaction 消息 函数名 功能 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 函数名 功能 pipe 建管道 信号量 函数名 功能 semctl 信号量控制 semget 获取一组信号量 semop 信号量操作 共享内存 函数名 功能 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信号中断与慢系统调用]]></title>
    <url>%2F2019%2F05%2F04%2F%E4%BF%A1%E5%8F%B7%E4%B8%AD%E6%96%AD%E4%B8%8E%E6%85%A2%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[术语慢系统调用（Slow system call）该术语适用于那些可能永远阻塞的系统调用。永远阻塞的系统调用是指调用永远无法返回，多数网络支持函数都属于这一类。如：若没有客户连接到服务器上，那么服务器的accept调用就会一直阻塞。 慢系统调用可以被永久阻塞，包括以下几个类别： （1）读写‘慢’设备（包括pipe，终端设备，网络连接等）。读时，数据不存在，需要等待；写时，缓冲区满或其他原因，需要等待。读写磁盘文件一般不会阻塞。 （2）当打开某些特殊文件时，需要等待某些条件，才能打开。例如：打开中断设备时，需要等到连接设备的modem响应才能完成。 （3）pause和wait函数。pause函数使调用进程睡眠，直到捕获到一个信号。wait等待子进程终止。 （4）某些ioctl操作。 （5）某些IPC操作。 EINTR介绍EINTR错误产生的原因早期的Unix系统，如果进程在一个慢系统调用(slow system call)中阻塞时，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR（相应的错误描述为“Interrupted system call”）。 怎么看哪些系统条用会产生EINTR错误呢？用man啊！ 如下表所示的系统调用就会产生EINTR错误，当然不同的函数意义也不同。 系统调用函数 errno为EINTR表征的意义 write 由于信号中断，没写成功任何数据。 open 由于信号中断，没读到任何数据。 recv 由于信号中断返回，没有任何数据可用。 sem_wait 函数调用被信号处理函数中断。 如何处理被中断的系统调用既然系统调用会被中断，那么别忘了要处理被中断的系统调用。有三种处理方式： 人为重启被中断的系统调用 安装信号时设置 SA_RESTART属性（该方法对有的系统调用无效） 忽略信号（让系统不产生信号中断） 人为重启被中断的系统调用人为当碰到EINTR错误的时候，有一些可以重启的系统调用要进行重启，而对于有一些系统调用是不能够重启的。例如：accept、read、write、select、和open之类的函数来说，是可以进行重启的。不过对于套接字编程中的connect函数我们是不能重启的，若connect函数返回一个EINTR错误的时候，我们不能再次调用它，否则将立即返回一个错误。针对connect不能重启的处理方法是，必须调用select来等待连接完成。 这里的“重启”怎么理解？ 一些IO系统调用执行时，如 read 等待输入期间，如果收到一个信号，系统将中断read， 转而执行信号处理函数. 当信号处理返回后， 系统遇到了一个问题： 是重新开始这个系统调用， 还是让系统调用失败？早期UNIX系统的做法是， 中断系统调用，并让系统调用失败， 比如read返回 -1， 同时设置 errno 为EINTR中断了的系统调用是没有完成的调用，它的失败是临时性的，如果再次调用则可能成功，这并不是真正的失败，所以要对这种情况进行处理， 典型的方式为：123456again: if ((n = read(fd， buf， BUFFSIZE)) &lt; 0) &#123; if (errno == EINTR) goto again; /* just an interrupted system call */ /* handle other errors */ &#125; 可以去github上看看别人怎么处理EINTR错误的。在github上搜索“==EINTR”关键字就有一大堆了。摘取几个看看：12while ((r = read (fd， buf， len)) &lt; 0 &amp;&amp; errno == EINTR) /*donothing*/ ; 1234567891011121314ssize_t Read(int fd， void *ptr， size_t nbytes)&#123; ssize_t n; again: if((n = read(fd， ptr， nbytes)) == -1)&#123; if(errno == EINTR) goto again; else return -1; &#125; return n;&#125; 安装信号时设置 SA_RESTART属性 我们还可以从信号的角度来解决这个问题， 安装信号的时候， 设置 SA_RESTART属性，那么当信号处理函数返回后， 不会让系统调用返回失败，而是让被该信号中断的系统调用将自动恢复。123456789struct sigaction action; action.sa_handler = handler_func;sigemptyset(&amp;action.sa_mask);action.sa_flags = 0;/* 设置SA_RESTART属性 */action.sa_flags |= SA_RESTART; sigaction(SIGALRM, &amp;action, NULL); 但注意，并不是所有的系统调用都可以自动恢复。如msgsnd喝msgrcv就是典型的例子，msgsnd/msgrcv以block方式发送/接收消息时，会因为进程收到了信号而中断。此时msgsnd/msgrcv将返回-1，errno被设置为EINTR。且即使在插入信号时设置了SA_RESTART，也无效。在man msgrcv中就有提到这点： msgsnd and msgrcv are never automatically restarted after being interrupted by a signal handler, regardless of the setting of the SA_RESTART flag when establishing a signal handler. 忽略信号当然最简单的方法是忽略信号，在安装信号时，明确告诉系统不会产生该信号的中断。123456struct sigaction action; action.sa_handler = SIG_IGN;sigemptyset(&amp;action.sa_mask); sigaction(SIGALRM, &amp;action, NULL); 测试代码为了方便大家测试，这里附上两段测试代码。 测试代码一闹钟信号SIGALRM中断read系统调用。安装SIGALRM信号时如果不设置SA_RESTART属性，信号会中断read系统过调用。如果设置了SA_RESTART属性，read就能够自己恢复系统调用，不会产生EINTR错误。123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;error.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt; void sig_handler(int signum)&#123; printf(&quot;in handler\n&quot;); sleep(1); printf(&quot;handler return\n&quot;);&#125; int main(int argc, char **argv)&#123; char buf[100]; int ret; struct sigaction action, old_action; action.sa_handler = sig_handler; sigemptyset(&amp;action.sa_mask); action.sa_flags = 0; /* 版本1:不设置SA_RESTART属性 * 版本2:设置SA_RESTART属性 */ //action.sa_flags |= SA_RESTART; sigaction(SIGALRM, NULL, &amp;old_action); if (old_action.sa_handler != SIG_IGN) &#123; sigaction(SIGALRM, &amp;action, NULL); &#125; alarm(3); bzero(buf, 100); ret = read(0, buf, 100); if (ret == -1) &#123; perror(&quot;read&quot;); &#125; printf(&quot;read %d bytes:\n&quot;, ret); printf(&quot;%s\n&quot;, buf); return 0;&#125; 测试代码二闹钟信号SIGALRM中断msgrcv系统调用。即使在插入信号时设置了SA_RESTART，也无效。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/msg.h&gt; void ding(int sig)&#123; printf(&quot;Ding!\n&quot;);&#125; struct msgst&#123; long int msg_type; char buf[1];&#125;; int main()&#123; int nMsgID = -1; // 捕捉闹钟信息号 struct sigaction action; action.sa_handler = ding; sigemptyset(&amp;action.sa_mask); action.sa_flags = 0; // 版本1:不设置SA_RESTART属性 // 版本2:设置SA_RESTART属性 action.sa_flags |= SA_RESTART; sigaction(SIGALRM, &amp;action, NULL); alarm(3); printf(&quot;waiting for alarm to go off\n&quot;); // 新建消息队列 nMsgID = msgget(IPC_PRIVATE, 0666 | IPC_CREAT); if( nMsgID &lt; 0 ) &#123; perror(&quot;msgget fail&quot; ); return; &#125; printf(&quot;msgget success.\n&quot;); // 阻塞 等待消息队列 // // msgrcv会因为进程收到了信号而中断。返回-1，errno被设置为EINTR。 // 即使在插入信号时设置了SA_RESTART，也无效。man msgrcv就有说明。 // struct msgst msg_st; if( -1 == msgrcv( nMsgID, (void*)&amp;msg_st, 1, 0, 0 ) ) &#123; perror(&quot;msgrcv fail&quot;); &#125; printf(&quot;done\n&quot;); exit(0);&#125; 总结慢系统调用(slow system call)会被信号中断，系统调用函数返回失败，并且errno被置为EINTR（错误描述为“Interrupted system call”）。 处理方法有以下三种： 人为重启被中断的系统调用； 安装信号时设置 SA_RESTART属性； 忽略信号（让系统不产生信号中断）。 有时我们需要捕获信号，但又考虑到第2种方法的局限性（设置 SA_RESTART属性对有的系统无效，如msgrcv），所以在编写代码时，一定要“人为重启被中断的系统调用”。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析CPU中断技术]]></title>
    <url>%2F2019%2F05%2F04%2F%E6%B5%85%E6%9E%90CPU%E4%B8%AD%E6%96%AD%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/funeral/archive/2013/03/06/2945485.html 什么是CPU中断？使用计算机的过程中，经常会遇到这么一种情景： 你正在看电影 你的朋友发来一条QQ信息 你一边回复朋友的信息，一边继续看电影 这个过程中，一切是那么的顺其自然。但理论上来说，播放电影的时候，CPU正在一丝不苟的执行着一条又一条的指令，它是如何在维持电影播放的情况下，及时接收并响应你的键盘输入信息呢？这就是CPU中断技术在起作用。 CPU中断技术的定义如下： 计算机处于执行期间系统内发生了非寻常或非预期的急需处理事件CPU暂时中断当前正在执行的程序而转去执行相应的事件处理程序处理完毕后返回原来被中断处继续执行。 在这里，“非寻常或非预期的事件”指的就是你回复朋友的QQ时，用键盘键入信息。为了及时响应你键入的信息，CPU将正在执行的任务“播放电影”暂时中断，处理完你键入的信息后，继续执行“播放电影”的任务。由于这个“中断当前任务-&gt;响应键盘输入-&gt;继续当前任务”的执行周期非常短（一般都是微秒级），所以一般人感觉不出来。 CPU中断的作用早期的CPU处理外设的事件(比如接收键盘输入)，往往采用“轮询”的方式。即CPU像个查岗的一样轮番对外设顺序访问，比如它先看看键盘有没被按下，有的话就处理，没的话继续往下看鼠标有没有移动，再看看打印机……这种方式使CPU的执行效率很低，且CPU与外设不能同时工作（因为要等待CPU来“巡查”）。 中断模式时就是说CPU不主动访问这些设备，只管处理自己的任务。如果有设备要与CPU联系，或要CPU处理一些事情，它会给CPU发一个中断请求信号。这时CPU就会放下正在进行的工作而去处理这个外设的请求。处理完中断后，CPU返回去继续执行中断以前的工作。 中断模式的作用和优点在于： 可以使CPU和外设同时工作，使系统可以及时地响应外部事件。 可允许多个外设同时工作，大大提高了CPU的利用率，也提高了数据输入、输出的速度。 可以使CPU及时处理各种软硬件故障（比如计算机在运行过程中，出现了难以预料的情况或一些故障，如电源掉电、存储出错、运算溢出等等。计算机可以利用中断系统自行处理，而不必停机或报告工作人员。） CPU中断的类型在计算机系统中，根据中断源的不同，通常将中断分为两大类： 硬件中断 软件中断 硬件中断硬件中断又称外部中断，主要分为两种：可屏蔽中断、非屏蔽中断。可屏蔽中断： 常由计算机的外设或一些接口功能产生，如键盘、打印机、串行口等 这种类型的中断可以在CPU要处理其它紧急操作时，被软件屏蔽或忽略 非屏蔽中断： 由意外事件导致，如电源断电、内存校验错误等 对于这种类型的中断事件，无法通过软件进行屏蔽，CPU必须无条件响应 在x86架构的处理器中，CPU的中断控制器由两根引脚(INTR和NMI)接收外部中断请求信号。其中： INTR接收可屏蔽中断请求 NMI接收非屏蔽中断请求 典型事例： 典型的可屏蔽中断的例子是打印机中断，CPU对打印机中断请求的响应可以快一些，也可以慢一些，因为让打印机稍等待一会也是完全合理的。 典型的非屏蔽中断的例子是电源断电，一旦出现此中断请求，必须立即无条件地响应，否则进行其他任何工作都是没有意义的。 软件中断软件中断又称内部中断，是指在程序中调用INTR中断指令引起的中断。比如winAPI中，keybd_event和mouse_event两个函数，就是用来模拟键盘和鼠标的输入（这个仅为笔者本人的猜测）。 CPU中断的过程中断请求中断请求是由中断源向CPU发出中断请求信号。外部设备发出中断请求信号要具备以下两个条件： 外部设备的工作已经告一段落。例如输入设备只有在启动后，将要输入的数据送到接口电路的数据寄存器（即准备好要输入的数据）之后，才可以向CPU发出中断请求。 系统允许该外设发出中断请求。如果系统不允许该外设发出中断请求，可以将这个外设的请求屏蔽。当这个外设中断请求被屏蔽，虽然这个外设准备工作已经完成，也不能发出中断请求。 中断响应、处理和返回当满足了中断的条件后，CPU就会响应中断，转入中断程序处理。具体的工作过程如下： 关闭中断信号接收器 保存现场(context) 给出中断入口，转入相应的中断服务程序 处理完成，返回并恢复现场(context) 开启中断信号接收器 中断排队和中断判优 中断申请是随机的，有时会出现多个中断源同时提出中断申请。 CPU每次只能响应一个中断源的请求。 CPU不可能对所有中断请求一视同仁，它会根据各中断源工作性质的轻重缓急，预先安排一个优先级顺序。当多个中断源同时申请中断时，即按此优先级顺序进行排队，等候CPU处理。 了解了CPU中断处理的过程，就不难理解下面一种常见的情景： 正在拷贝文件时，往某个文本框输入信息，这个文本框会出现短暂的假死，键盘输入的数据不能及时显示在文本框中，需要等一会儿才能逐渐显示出来。这是因为该中断操作(往文本框输入信息)在中断队列的优先级比较低，或者CPU认为正在处理的操作(拷贝文件)进行挂起的代价太大，所以只有等到CPU到了一个挂起代价较低的点，才会挂起当前操作，处理本次中断信息。 多核CPU对中断的处理多核CPU的中断处理和单核有很大不同。多核的各处理器核心之间需要通过中断方式进行通信，所以CPU芯片内部既有各处理器核心的本地中断控制器，又有负责仲裁各核之间中断分配的全局中断控制器。 现今的多核处理器在中断处理和中断控制方面主要使用的是APIC（Advanced Programmable Interrupt Controllers），即高级编程中断控制器。它是基于中断控制器两个基础功能单元——本地单元以及I/O单元的分布式体系结构。在多核系统中，多个本地和I/O APIC单元能够作为一个整体通过APIC总线互相操作。 APIC的功能有： 接受来自处理器中断引脚的内部或外部I/O APIC的中断，然后将这些中断发送给处理器核心进行处理 在多核处理器系统中，接收和发送核内中断消息 对于外部设备发出的中断请求，由全局中断控制器接收请求并决定交给CPU的哪一个核心处理。也可针对APIC编程，让所有的中断都被一个固定的CPU处理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-进程、进程组、作业、会话、控制终端详解]]></title>
    <url>%2F2019%2F05%2F04%2FLinux%E4%BC%9A%E8%AF%9D%E6%8E%A7%E5%88%B6%E7%BB%88%E7%AB%AF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/qq_34376868/article/details/80562288 进程传统上，Unix操作系统下运行的应用程序、 服务器以及其他程序都被称为进程，而Linux也继承了来自unix进程的概念。必须要理解下，程序是指的存储在存储设备上（如磁盘）包含了可执行机器指 令（二进制代码）和数据的静态实体；而进程可以认为是已经被OS从磁盘加载到内存上的、动态的、可运行的指令与数据的集合，是在运行的动态实体。这里指的 指令和数据的集合可以理解为Linux上ELF文件格式中的.text .data数据段。 进程组每个进程除了有一个进程ID之外，还属于一个进程组，那什么是进程组呢？ 顾名思义，进程组就是一个或多个进程的集合。这些进程并不是孤立的，他们彼此之间或者存在父子、兄弟关系，或者在功能上有相近的联系。每个进程都有父进程，而所有的进程以init进程为根，形成一个树状结构。 那为啥Linux里要有进程组呢？其实，提供进程组就是为了方便对进程进行管理。假设要完成一个任务，需要同时并发100个进程。当用户处于某种原因要终止这个任务时，要是没有进程组，就需要手动的一个个去杀死这100个进程，并且必须要严格按照进程间父子兄弟关系顺序，否则会扰乱进程树。有了进程组，就可以将这100个进程设置为一个进程组，它们共有1个组号（pgrp），并且有选取一个进程作为组长（通常是“辈分”最高的那个，通常该进程的ID也就作为进程组的ID）。现在就可以通过杀死整个进程组，来关闭这100个进程，并且是严格有序的。组长进程可以创建一个进程组，创建该组中的进程，然后终止。只要在某个进程组中一个进程存在，则该进程组就存在，这与其组长进程是否终止无关。 进程必定属于一个进程组，也只能属于一个进程组。 一个进程组中可以包含多个进程。 进程组的生命周期从被创建开始，到其内所有进程终止或离开该组。 内核中，sys_getpgrp()系统调用用来获取当前进程所在进程组号；sys_setpgid(int pid, int pgid)调用用来设置置顶进程pid的进程组号为pgid。 作业Shell分前后台来控制的不是进程而是作业（Job）或者进程组（Process Group）。一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，Shell可以运行一个前台作业和任意多个后台作业，这称为作业控制。 作业与进程组的区别：如果作业中的某个进程又创建了子进程，则子进程不属于作业。一旦作业运行结束，Shell就把自己提到前台，如果原来的前台进程还存在（如果这个子进程还没终止），它自动变为后台进程组。 会话再看下会话。由于Linux是多用户多任务的分时系统，所以必须要支持多个用户同时使用一个操作系统。当一个用户登录一次系统就形成一次会话 。一个会话可包含多个进程组，但只能有一个前台进程组。每个会话都有一个会话首领（leader），即创建会话的进程。 sys_setsid()调用能创建一个会话。必须注意的是，只有当前进程不是进程组的组长时，才能创建一个新的会话。调用setsid 之后，该进程成为新会话的leader。 一个会话可以有一个控制终端。这通常是登陆到其上的终端设备（在终端登陆情况下）或伪终端设备（在网络登陆情况下）。建立与控制终端连接的会话首进程被称为控制进程。一个会话中的几个进程组可被分为一个前台进程组以及一个或多个后台进程组。所以一个会话中，应该包括控制进程（会话首进程），一个前台进程组和任意后台进程组。 一次登录形成一个会话 一个会话可包含多个进程组，但只能有一个前台进程组 控制终端会话的领头进程打开一个终端之后, 该终端就成为该会话的控制终端 (SVR4/Linux) 与控制终端建立连接的会话领头进程称为控制进程 (session leader) 一个会话只能有一个控制终端 产生在控制终端上的输入和信号将发送给会话的前台进程组中的所有进程 终端上的连接断开时 (比如网络断开或 Modem 断开), 挂起信号将发送到控制进程(session leader) 进程属于一个进程组，进程组属于一个会话，会话可能有也可能没有控制终端。一般而言，当用户在某个终端上登录时，一个新的会话就开始了。进程组由组中的领头进程标识，领头进程的进程标识符就是进程组的组标识符。类似地，每个会话也对应有一个领头进程。 同一会话中的进程通过该会话的领头进程和一个终端相连，该终端作为这个会话的控制终端。一个会话只能有一个控制终端，而一个控制终端只能控制一个会话。用户通过控制终端，可以向该控制终端所控制的会话中的进程发送键盘信号。 同一会话中只能有一个前台进程组，属于前台进程组的进程可从控制终端获得输入，而其他进程均是后台进程，可能分属于不同的后台进程组。 我们打开多个终端窗口时，实际上就创建了多个终端会话。每个会话都会有自己的前台工作和后台工作。 会话的维系维系一个会话，最常见的有两种方式： 一是基于某种凭证，比如web网站的登录会话，在登录验证之后，服务器就会返回一个session id作为凭证。用户之后的请求总是会带上这个id，而服务器通过这个id也就能知道用户是谁。直到用户注销登录、或者登录超时，服务器会清洗掉对应的session id，这个id就失效了，会话也就随之而结束。 第二种方式是基于连接的，当用户和系统之间的连接启用时，系统会对用户进行验证，验证通过之后，来自这个连接的操作都是属于这个用户的。直到连接断开，则会话结束。 linux系统的会话就是以第二种方式来维系的。会话基于连接，那么连接的安全性就决定了会话的安全性。以最常见的两种连接为例： 本地连接，用户是直接通过键盘显示器来跟系统交互的，键盘显示器直接连接在主机上，连接被篡改基本上是不可能的； 远程连接，以ssh为例，其协议会进行加密，从而避免连接被篡改； 下面在讨论会话的时候就围绕两种连接来展开。 连接的启用前面说到，会话是基于连接的。会话的源头，就是用户与系统之间连接的启用。 对于本地连接，连接是在系统初始化时建立的。linux会初始化若干个tty（/dev/tty?），形成若干个虚拟终端。本地连接的键盘和显示器通过对应的驱动程序，跟其中某个tty绑定上。用户可以通过ALT+F[1-12]键，将键盘和显示器切换到不同的tty上（也就是说，一套键盘显示器可以对应多个本地连接）。 在系统启动的时候，init程序会根据相应的配置（如：/etc/init/tty1.conf），启动相应的程序来监听这些tty（如：/sbin/getty -8 38400 tty1。下文说到这个监听程序时，就以getty为例）。当用户通过ALT+F?切换到对应的tty?、并有所输入时，在该tty上监听的getty就能读取到输入信息，然后通过exec启动login程序来进行登录验证。从getty得到输入的这一刻起，tty?上的这个连接就算是启用了。 对于远程连接，本文都以ssh为例。系统安装ssh server之后，在/etc/init.d/下会有它对应的启动脚本，这会使得sshd程序（ssh服务器）在系统启动的时候被启动（当然，root用户也可以在系统启动之后，手动启动sshd）。sshd监听网络上的相应端口（如：tcp:22），等待远程用户的连接。用户的连接始于TCP连接，然后sshd和ssh-client会打通ssh隧道。从这时起，连接启用，sshd会要求用户进行登录验证。 登录验证不管是本地终端登录，还是远程登录，登录验证无非就是要让用户输入用户名和密码。用户输入的信息通过已经启用的连接到达对端程序（如：login、sshd），然后由其进行校验。 系统中的用户信息存放在/etc/passwd文件中，里面保存的系统中所有用户的信息。这些信息主要有：用户名、密码、组、home路径、以及登录后执行的程序、等。这些信息可以分两个层面来看： 用于验证的。包括用户名和密码两项。即用户在与系统建立连接后，需要提供用户名和密码来进行验证（注意，密码一般并不是明文保存在passwd文件中的）； 登录后用于设置用户属性的。除密码外的所有项。下面会详细解释； 用户登录后会得到一个进程，关于这个进程，它有如下一些特征： 对于本地连接，它就是原本执行getty的那个进程；而对于ssh连接，它是由sshd fork出来的进程； 进程的用户名、组、当前路径、等都被按/etc/passwd文件中的描述进行设置； 进程的stdin、stdout、stderr连接到一个对应的终端。对于本地连接，这个终端就是getty监听的那个tty；对于ssh连接，它是由sshd打开的pty（伪终端，后面会详细解释）； 这个进程会执行/etc/passwd中配置的”登录后执行的程序”，这个程序一般就是/bin/sh，即登录后为用户提供一个shell控制台。于是用户可以使用自己的终端跟这个shell程序交互，干各种事情。这个”登录后执行的程序”也常被配置为/bin/nologin，表示对应用户是不允许登录的，因为nologin程序不会与用户进行交互，打印错误信息后就会退出了，所以登录只是白费劲。当然，如果你愿意，并且有root权限，也可以将”登录后执行的程序”配置成其他程序； 于是，用户在登录完成之后，系统中就存在这样一个用户名为该登录用户的进程。通常这个进程运行shell程序，并且其输入输出连接到用户的终端，所以用户可以用键盘来操作这个shell，并且用显示器接收shell的输出。 关于终端前面讲到，登录后的shell其输入输出是连接到用户使用的终端的，不管是本地登录的tty，还是远程登录的pty。但是，为什么要有终端呢？shell的输入直接接到键盘、输出直接接到显示器，这样不行么？尤其是远程的情况，shell的输入输出为什么不能直接接到网络，而非要弄一个pty出来呢？最容易想到的一点，终端能够使得上层不必关心输入输出设备本身的细节，只管对其读写就行了。不过这一点似乎并不是终端所特有的，因为vfs已经能够胜任了。应用程序open设备文件，得到fd，然后同样只用管对其读写就行了，而不用关心这个fd代表的是键盘、还是普通文件，具体的细节已经被隐藏在设备驱动程序之中。 不过，相比于普通的读写，终端还实现了很多可以通过ioctl系统调用进行配置的功能，能够完成一些针对输入输出的处理逻辑。如： 回车换行的转换：定义输入输出如何映射回车换行符。比如：回车键是\r、还是\n、还是\r\n；再如：\n应该如何打印到屏幕上，是回车+换行、还是只换行不回车、等等； 行编辑：允许让输入字符不是立马送到应用程序，而是在换行以后才能被读取到。未换行的输入字符可以通过退格键进行编辑（比如在你密码输错的时候，是可以用CTRL+退格来进行编辑的）； 回显：可以让输入字符自动被回显到终端的输出上。于是，键盘每输入一个字符都能在显示器上看到它，而这些字符其实很可能是还没被应用程序读取到的（因为有行编辑）； 功能键：允许定义功能键。比如最常用的Ctrl+C，杀死前台进程，就是由终端来触发的。终端检测到Ctrl+C输入，会向前台进程组发送SIGTERM信号。而谁是前台进程组呢？这是由shell通过ioctl系统调用对终端使用TIOCSPGRP命令来设置的，每当shell启动一个前台进程，它都需要这么设置一下； 输入输出流向控制，只有前台进程组能够从终端中读数据、而不管前台后台程序都能向终端写数据。这点也是必须的，跟用户进程交互的是前台进程，用户的输入当然不能被其他后台进程抢走。但是一个进程是前台还是后台，是它自己是所不知道的，没法靠进程自己来判断什么时候可以读终端、什么时候不能读。所以需要终端来提供支持，如果后台进程读这个终端，终端的驱动程序将向其发送SIGTTIN信号，从而将其挂起。直到shell将其重新置为前台进程时（通过fg命令），该进程才会继续执行； 终端提供的这些功能未必都会被打开它的程序使用到，但是如果要使用，则可以通过统一的ioctl接口来设置，而不需要关心终端具体接的是什么设备，是键盘显示器？还是网络。大多数应用程序则根本不关心终端，只当它是能够满足读写需求的文件。而像shell这样为人机交互而生的程序，则注定会跟终端打交道。对于shell来说，像“行编辑”、“回显”这样的功能，其实是可以不需要依赖终端的，shell程序自己可以做这样的处理，因为要做处理的数据正是shell从终端里面读到的数据。但是像“功能键”、“输入输出流向控制”这样的功能，则又不得不依赖终端。比如“功能键”，因为这时在对终端进行读操作的是shell启动的前台程序，而不是shell自己，所以不可能由shell来读取功能键，然后触发信号。 可以说，终端是人机交互时，应用程序与用户之间的一个中间层。如果应用程序是在跟人交互，使用终端是其不二的选择；否则则没有必要使用终端。这一点在sshd上面有很好的体现。当用户使用ssh登录到远程机器remotehost，并执行一些操作时（比如执行cat test.txt操作），可以有两种方式： ssh user:pass@remotehost，远程登录后，再在shell中执行cat test.txt命令； ssh user:pass@remotehost ‘cat test.txt’，直接由sshd启动一个shell、自动执行’cat test.txt’命令；第一种方式，是登录之后，再通过人机交互输入命令，这时sshd会为登录后得到的shell程序准备一个pty，以支持人机交互；而第二种方式，在登录之后并不需要交互，所以sshd就并不会使用pty，而是直接通过socket将shell的输入输出跟自己连接起来（再由sshd将其转发给ssh-client）。 下面再说一下pty。pty分master和slave两端，跟pipe的两端很像，写入到master端的数据可以原样从slave端读出，反之亦然。在上面所述的第一种方式下，各个进程的联系如下：ssh-client [socket] sshd [master] [slave] shellpty的master和slave两端分别被sshd和shell打开，就像pipe一样，将它们的输入输出连接起来。而pty跟pipe的不同之处，则正是前面所说的终端的功能（pty的slave端对于shell来说就是一个终端）。跟tty不同，tty是系统初始化时生成的，其数目是固定的（比如12个）。而pty是系统启动后动态创建的。其创建的方法是：fd = open(‘/dev/ptms’)，这样就得到了一个pty。open返回的fd代表master端，通过ptyname(fd)可以得到对应slave端的文件路径（比如’/dev/pts/2’），这个设备文件是master端被open之后动态生成的。 权限控制用户登录验证成功后，getty、sshd这样的程序就会为用户启动他所对应的”登录后执行的程序”，并且在此之前会通过setuid()、setgid()这样的系统调用，设置好进程的uid和gid（用户和组）。之后，这个进程对文件的读、写、执行，以及对系统调用的使用，等都会受到进程uid和gid的限制。 用户对系统的各种操作都是通过进程来完成的。而用户的输入输出都被定向到他登录后所得到的那个进程上，于是用户能够控制这个进程，来干他想干的事情（如果这个进程接受控制的话，比如进程运行着一个shell程序）。用户的操作都受限于进程的uid和gid，比如文件访问、向进程发送信号、使用系统调用、监听网络端口、等都需要对其做检查。 除非是root用户，否则没有权限使用setuid()、setgid()这样的系统调用来修改进程的uid和gid。而login时，login、sshd这样的进程之所以能够设置登录后进程的uid和gid，正是因为它们都是root用户的进程。如果想要改变登录用户，则必须利用属于root用户的进程。一种办法是退出登录，然后走老路，重新跟getty、sshd这样的进程打交道，而使用其他用户名登录。另一种办法是执行一个setuid/setgid程序（参见《记一个linux内核内存提权问题》中的说明），临时获得root权限，再实现用户的切换（例如su就是这样一个能实现用户切换的setuid命令）。 为了实现进程权限控制中的各种功能，进程的uid和gid其实并不止一组，主要有如下三组： ruid/rgid，代表实际的用户和组id； euid/egid，代表当前生效的用户和组id； suid/sgid，代表保留的用户和组id； 什么意思呢？一般情况下，在用户登录得到的进程中，这三组id都是相同的值，与登录用户相对应（假设为aaa）。而用户新创建的进程也会全部继承这三组id。当用户执行一个setuid/setgid程序时，执行程序的进程将得到可执行程序owner（假设为bbb）的用户属性，euid/egid和suid/sgid会更新为bbb（而ruid/rgid不会被更新）。这些id在进程操作别的对象时（比如写文件、发信号、等）或被别的进程操作时（比如其他进程向其发信号、等）会被用做校验。ruid/rgid和euid/egid在进程被操作的时候会使用到，euid/egid在进程发起操作的时候会用到。比如有一个进程，其ruid是aaa、euid是bbb，则euid为aaa或bbb的其他进程都可以向其发送信号。而该进程在进行读写文件、创建文件、等操作时，使用的则是用户bbb的权限：它创建的文件owner是bbb、它在访问owner是aaa的文件时以other权限进行校验。那么第三组id，suid/sgid又是干什么用的呢？之前说普通用户没有权限使用setuid()这样的系统调用来改变进程的uid和gid，其实这个说法并不确切。进程其实是有权限将自己的ruid/rgid、euid/egid、suid/sgid的值修改成与这三者之一相等的值。比如ruid/rgid为aaa、suid/sgid为bbb，则用户可以任意将euid/egid设置为aaa或bbb。因为大多数情况下这三组id是等值的，所以一般说用户进程不能修改自己的uid和gid（只能从aaa修改为aaa，相当于不能修改）。但是执行setuid的程序后，进程的这三组id就有了两种不同的取值，ruid/rgid等于aaa、euid/egid和suid/sgid等于bbb，于是进程的uid就有了一定的选择余地。比如此时进程的euid/egid被更新成了bbb，那就不能再以owner身份去操作aaa的文件了（注意，这个进程原本是以aaa用户登录而得到的）。不过没关系，进程是有权限将euid/egid改回aaa的，因为ruid/rgid的值是aaa。但是改回来之后，ruid/rgid和euid/egid都是aaa了，要再想把euid/egid改为bbb怎么办呢？suid/sgid就是为此而生的，作为一个备份，它的值是bbb，这使得euid/egid还能够修改回bbb。当然，进程也有权限将euid/egid和suid/sgid都改回aaa，这将使得它们不再能修改成bbb了。 会话退出用户登录是一个会话的开始。登录之后，用户会得到一个跟用户使用的终端相连的进程，这个进程被称作是这个会话的leader，会话的id就等于该进程的pid。由该进程fork出来的子进程都是这个会话的成员（进程的sid等于该会话id）。leader进程的退出，将导致它所连接的终端被hangup，这意味着会话结束。反过来，像ssh这样的远程连接也可以通过断开连接的方式来使终端hangup，这将使得leader进程收到SIGHUP信号而退出。如果会话使用的是pty，其本身是随会话的建立而创建出来的，会话结束，则pty被销毁；而如果会话使用的是tty，其本身是在系统初始化时创建的，并不依赖于会话的建立，则会话结束时，tty依然存在。init进程检测到使用该tty的会话已经结束，便会重新启动一个getty来监听该tty。 不过，会话结束，并不意味着在该会话中创建的所有进程都结束了。所谓的daemon进程，正是在某个会话中创建，但是却不依赖该会话，而常驻后台的进程。具体来说，当终端hangup时，内核会有如下两个动作： 向对应会话的leader进程发送SIGHUP信号。而一般来说，会话的leader进程很可能是一个shell，它在收到SIGHUP信号后，并不是马上退出，而是会向它所启动的子进程都各自发送一个SIGHUP信号，将它们都杀死，然后自己才退出。不过，如果是这个作为leader进程shell自己退出，而导致终端hangup的话，向其子进程发送SIGHUP信号的事情就不会发生了，因为shell退出在先，它再也不会收到SIGHUP信号； 修改所有打开该终端的文件句柄，改成一个不可读不可写的实现； 所以，在会话退出之后还常驻后台的进程肯定是没法跟终端交互的。而要想让进程常驻后台，一般有如下几种方法： 避免shell发SIGHUP信号；主要有两种办法：1)主动exit，而不是直接断开终端；2)两次fork。因为shell只认识它自己fork出来的子进程，并不知道”子又生孙”的事情，也就不会给孙子进程发送SIGHUP信号了； 忽略SIGHUP信号；终端hangup时进程可能收到shell发送的SIGHUP信号。信号的默认处理动作是退出进程，但是该信号是可以忽略的。忽略信号，就可以使得后台进程不会随会话退出而退出。nohup命令就是做这件事情的，而且它做得更完整一些，不仅忽略SIGHUP，还会将进程的标准输入重定向为/dev/null、输出重定向到nohup.out文件； 使用setsid()系统调用，为进程开启一个新的会话；从一个会话中fork出来的进程，默认都是属于这个会话的。但是进程可以调用setsid()，使自己脱离原先的会话，而成为一个新会话的leader。于是，原先的会话退出，就不会影响到新建的会话了。setsid命令包装了setsid()系统调用，可以为进程创建新的会话。不过它并不对新进程的输入输出进行重定向，这就意味着新进程的输入输出还是连接到原先的那个tty的，这可能跟原先的会话争抢输入。所以，对新会话的进程进行输入输出的重定向也是一件很重要的事情。 一个进程成为daemon进程，可以不随会话的退出而退出，但是进程的uid/gid并不会因此而改变。对应的用户还可以在其他会话中，通过发信号等方式，操作那些原来由他所启动的daemon进程（因为权限控制是以用户为准的，而并不考虑会话）。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬中断和软中断]]></title>
    <url>%2F2019%2F05%2F01%2F%E7%A1%AC%E4%B8%AD%E6%96%AD%E5%92%8C%E8%BD%AF%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[概述从本质上来讲，中断是一种电信号，当设备有某种事件发生时，它就会产生中断，通过总线把电信号发送给中断控制器。如果中断的线是激活的，中断控制器就把电信号发送给处理器的某个特定引脚。处理器于是立即停止自己正在做的事，跳到中断处理程序的入口点，进行中断处理。 硬中断 由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。 软中断 为了满足实时系统的要求，中断处理应该是越快越好。linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。 中断嵌套 Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。 软中断指令 int是软中断指令。中断向量表是中断号和中断处理函数地址的对应表。int n - 触发软中断n。相应的中断处理函数的地址为：中断向量表地址 + 4 * n。 硬中断和软中断的区别 软中断是执行中断指令产生的，而硬中断是由外设引发的。 硬中断的中断号是由中断控制器提供的，软中断的中断号由指令直接指出，无需使用中断控制器。 硬中断是可屏蔽的，软中断不可屏蔽。 硬中断处理程序要确保它能快速地完成任务，这样程序执行时才不会等待较长时间，称为上半部。 软中断处理硬中断未完成的工作，是一种推后执行的机制，属于下半部。 开关硬中断的开关简单禁止和激活当前处理器上的本地中断：12local_irq_disable();local_irq_enable(); 保存本地中断系统状态下的禁止和激活：123unsigned long flags;local_irq_save(flags);`local_irq_restore(flags); 软中断的开关禁止下半部，如softirq、tasklet和workqueue等：12local_bh_disable();local_bh_enable(); 需要注意的是，禁止下半部时仍然可以被硬中断抢占。 判断中断状态123#define in_interrupt() (irq_count()) // 是否处于中断状态(硬中断或软中断)#define in_irq() (hardirq_count()) // 是否处于硬中断#define in_softirq() (softirq_count()) // 是否处于软中断 硬中断注册中断处理函数注册中断处理函数：1234567891011/** * irq: 要分配的中断号 * handler: 要注册的中断处理函数 * flags: 标志(一般为0) * name: 设备名(dev-&gt;name) * dev: 设备(struct net_device *dev)，作为中断处理函数的参数 * 成功返回0 */ int request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev); 中断处理函数本身：123456789101112131415typedef irqreturn_t (*irq_handler_t) (int, void *);/** * enum irqreturn * @IRQ_NONE: interrupt was not from this device * @IRQ_HANDLED: interrupt was handled by this device * @IRQ_WAKE_THREAD: handler requests to wake the handler thread */enum irqreturn &#123; IRQ_NONE, IRQ_HANDLED, IRQ_WAKE_THREAD,&#125;;typedef enum irqreturn irqreturn_t;#define IRQ_RETVAL(x) ((x) != IRQ_NONE) 注销中断处理函数1234567891011121314/** * free_irq - free an interrupt allocated with request_irq * @irq: Interrupt line to free * @dev_id: Device identity to free * * Remove an interrupt handler. The handler is removed and if the * interrupt line is no longer in use by any driver it is disabled. * On a shared IRQ the caller must ensure the interrupt is disabled * on the card it drives before calling this function. The function does * not return until any executing interrupts for this IRQ have completed. * This function must not be called from interrupt context. */ void free_irq(unsigned int irq, void *dev_id); 软中断定义软中断是一组静态定义的下半部接口，可以在所有处理器上同时执行，即使两个类型相同也可以。但一个软中断不会抢占另一个软中断，唯一可以抢占软中断的是硬中断。 软中断由softirq_action结构体表示：123struct softirq_action &#123; void (*action) (struct softirq_action *); /* 软中断的处理函数 */&#125;; 目前已注册的软中断有10种，定义为一个全局数组：123456789101112131415static struct softirq_action softirq_vec[NR_SOFTIRQS]; enum &#123; HI_SOFTIRQ = 0, /* 优先级高的tasklets */ TIMER_SOFTIRQ, /* 定时器的下半部 */ NET_TX_SOFTIRQ, /* 发送网络数据包 */ NET_RX_SOFTIRQ, /* 接收网络数据包 */ BLOCK_SOFTIRQ, /* BLOCK装置 */ BLOCK_IOPOLL_SOFTIRQ, TASKLET_SOFTIRQ, /* 正常优先级的tasklets */ SCHED_SOFTIRQ, /* 调度程序 */ HRTIMER_SOFTIRQ, /* 高分辨率定时器 */ RCU_SOFTIRQ, /* RCU锁定 */ NR_SOFTIRQS /* 10 */&#125;; 注册软中断处理函数123456789/** * @nr: 软中断的索引号 * @action: 软中断的处理函数 */ void open_softirq(int nr, void (*action) (struct softirq_action *))&#123; softirq_vec[nr].action = action;&#125; 例如：12open_softirq(NET_TX_SOFTIRQ, net_tx_action);open_softirq(NET_RX_SOFTIRQ, net_rx_action); 触发软中断调用raise_softirq()来触发软中断。1234567891011121314151617181920212223void raise_softirq(unsigned int nr)&#123; unsigned long flags; local_irq_save(flags); raise_softirq_irqoff(nr); local_irq_restore(flags);&#125; /* This function must run with irqs disabled */inline void rasie_softirq_irqsoff(unsigned int nr)&#123; __raise_softirq_irqoff(nr); /* If we&apos;re in an interrupt or softirq, we&apos;re done * (this also catches softirq-disabled code). We will * actually run the softirq once we return from the irq * or softirq. * Otherwise we wake up ksoftirqd to make sure we * schedule the softirq soon. */ if (! in_interrupt()) /* 如果不处于硬中断或软中断 */ wakeup_softirqd(void); /* 唤醒ksoftirqd/n进程 */&#125; Percpu变量irq_cpustat_t中的__softirq_pending是等待处理的软中断的位图，通过设置此变量 即可告诉内核该执行哪些软中断。123456789101112131415static inline void __rasie_softirq_irqoff(unsigned int nr)&#123; trace_softirq_raise(nr); or_softirq_pending(1UL &lt;&lt; nr);&#125; typedef struct &#123; unsigned int __softirq_pending; unsigned int __nmi_count; /* arch dependent */&#125; irq_cpustat_t; irq_cpustat_t irq_stat[];#define __IRQ_STAT(cpu, member) (irq_stat[cpu].member)#define or_softirq_pending(x) percpu_or(irq_stat.__softirq_pending, (x))#define local_softirq_pending() percpu_read(irq_stat.__softirq_pending) 唤醒ksoftirqd内核线程处理软中断。12345678static void wakeup_softirqd(void)&#123; /* Interrupts are disabled: no need to stop preemption */ struct task_struct *tsk = __get_cpu_var(ksoftirqd); if (tsk &amp;&amp; tsk-&gt;state != TASK_RUNNING) wake_up_process(tsk);&#125; 在下列地方，待处理的软中断会被检查和执行： 从一个硬件中断代码处返回时 在ksoftirqd内核线程中 在那些显示检查和执行待处理的软中断的代码中，如网络子系统中 而不管是用什么方法唤起，软中断都要在do_softirq()中执行。如果有待处理的软中断，do_softirq()会循环遍历每一个，调用它们的相应的处理程序。在中断处理程序中触发软中断是最常见的形式。中断处理程序执行硬件设备的相关操作，然后触发相应的软中断，最后退出。内核在执行完中断处理程序以后，马上就会调用do_softirq()，于是软中断开始执行中断处理程序完成剩余的任务。 下面来看下do_softirq()的具体实现。123456789101112131415asmlinkage void do_softirq(void)&#123; __u32 pending; unsigned long flags; /* 如果当前已处于硬中断或软中断中，直接返回 */ if (in_interrupt()) return; local_irq_save(flags); pending = local_softirq_pending(); if (pending) /* 如果有激活的软中断 */ __do_softirq(); /* 处理函数 */ local_irq_restore(flags);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* We restart softirq processing MAX_SOFTIRQ_RESTART times, * and we fall back to softirqd after that. * This number has been established via experimentation. * The two things to balance is latency against fairness - we want * to handle softirqs as soon as possible, but they should not be * able to lock up the box. */asmlinkage void __do_softirq(void)&#123; struct softirq_action *h; __u32 pending; /* 本函数能重复触发执行的次数，防止占用过多的cpu时间 */ int max_restart = MAX_SOFTIRQ_RESTART; int cpu; pending = local_softirq_pending(); /* 激活的软中断位图 */ account_system_vtime(current); /* 本地禁止当前的软中断 */ __local_bh_disable((unsigned long)__builtin_return_address(0), SOFTIRQ_OFFSET); lockdep_softirq_enter(); /* current-&gt;softirq_context++ */ cpu = smp_processor_id(); /* 当前cpu编号 */ restart: /* Reset the pending bitmask before enabling irqs */ set_softirq_pending(0); /* 重置位图 */ local_irq_enable(); h = softirq_vec; do &#123; if (pending &amp; 1) &#123; unsigned int vec_nr = h - softirq_vec; /* 软中断索引 */ int prev_count = preempt_count(); kstat_incr_softirqs_this_cpu(vec_nr); trace_softirq_entry(vec_nr); h-&gt;action(h); /* 调用软中断的处理函数 */ trace_softirq_exit(vec_nr); if (unlikely(prev_count != preempt_count())) &#123; printk(KERN_ERR &quot;huh, entered softirq %u %s %p&quot; &quot;with preempt_count %08x,&quot; &quot;exited with %08x?\n&quot;, vec_nr, softirq_to_name[vec_nr], h-&gt;action, prev_count, preempt_count()); &#125; rcu_bh_qs(cpu); &#125; h++; pending &gt;&gt;= 1; &#125; while(pending); local_irq_disable(); pending = local_softirq_pending(); if (pending &amp; --max_restart) /* 重复触发 */ goto restart; /* 如果重复触发了10次了，接下来唤醒ksoftirqd/n内核线程来处理 */ if (pending) wakeup_softirqd(); lockdep_softirq_exit(); account_system_vtime(current); __local_bh_enable(SOFTIRQ_OFFSET);&#125; ksoftirqd内核线程内核不会立即处理重新触发的软中断。当大量软中断出现的时候，内核会唤醒一组内核线程来处理。这些线程的优先级最低(nice值为19)，这能避免它们跟其它重要的任务抢夺资源。但它们最终肯定会被执行，所以这个折中的方案能够保证在软中断很多时用户程序不会因为得不到处理时间而处于饥饿状态，同时也保证过量的软中断最终会得到处理。 每个处理器都有一个这样的线程，名字为ksoftirqd/n，n为处理器的编号。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static int run_ksoftirqd(void *__bind_cpu)&#123; set_current_state(TASK_INTERRUPTIBLE); current-&gt;flags |= PF_KSOFTIRQD; /* I am ksoftirqd */ while(! kthread_should_stop()) &#123; preempt_disable(); if (! local_softirq_pending()) &#123; /* 如果没有要处理的软中断 */ preempt_enable_no_resched(); schedule(); preempt_disable(): &#125; __set_current_state(TASK_RUNNING); while(local_softirq_pending()) &#123; /* Preempt disable stops cpu going offline. * If already offline, we&apos;ll be on wrong CPU: don&apos;t process. */ if (cpu_is_offline(long)__bind_cpu))/* 被要求释放cpu */ goto wait_to_die; do_softirq(); /* 软中断的统一处理函数 */ preempt_enable_no_resched(); cond_resched(); preempt_disable(); rcu_note_context_switch((long)__bind_cpu); &#125; preempt_enable(); set_current_state(TASK_INTERRUPTIBLE); &#125; __set_current_state(TASK_RUNNING); return 0; wait_to_die: preempt_enable(); /* Wait for kthread_stop */ set_current_state(TASK_INTERRUPTIBLE); while(! kthread_should_stop()) &#123; schedule(); set_current_state(TASK_INTERRUPTIBLE); &#125; __set_current_state(TASK_RUNNING); return 0;&#125; 原文：https://blog.csdn.net/zhangskd/article/details/21992933]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准IO与文件IO的区别]]></title>
    <url>%2F2019%2F05%2F01%2F%E6%A0%87%E5%87%86IO%E4%B8%8E%E6%96%87%E4%BB%B6IO%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[先来了解下什么是文件I/O和标准I/O：文件I/O：文件I/O称之为不带缓存的IO（unbuffered I/O)。不带缓存指的是每个read，write都调用内核中的一个系统调用。也就是一般所说的低级I/O——操作系统提供的基本IO服务，与os绑定，特定于linix或unix平台。 标准I/O：标准I/O是ANSI C建立的一个标准I/O模型，是一个标准函数包和stdio.h头文件中的定义，具有一定的可移植性。标准I/O库处理很多细节。例如缓存分配，以优化长度执行I/O等。标准的I/O提供了三种类型的缓存。 全缓存：当填满标准I/O缓存后才进行实际的I/O操作。 行缓存：当输入或输出中遇到新行符时，标准I/O库执行I/O操作。 不带缓存：stderr就是了。 二者的区别文件I/O 又称为低级磁盘I/O，遵循POSIX相关标准。任何兼容POSIX标准的操作系统上都支持文件I/O。标准I/O被称为高级磁盘I/O，遵循ANSI C相关标准。只要开发环境中有标准I/O库，标准I/O就可以使用。（Linux 中使用的是GLIBC，它是标准C库的超集。不仅包含ANSI C中定义的函数，还包括POSIX标准中定义的函数。因此，Linux 下既可以使用标准I/O，也可以使用文件I/O）。 通过文件I/O读写文件时，每次操作都会执行相关系统调用。这样处理的好处是直接读写实际文件，坏处是频繁的系统调用会增加系统开销，标准I/O可以看成是在文件I/O的基础上封装了缓冲机制。先读写缓冲区，必要时再访问实际文件，从而减少了系统调用的次数。 文件I/O中用文件描述符表现一个打开的文件，可以访问不同类型的文件如普通文件、设备文件和管道文件等。而标准I/O中用FILE（流）表示一个打开的文件，通常只用来访问普通文件。 最后来看下他们使用的函数 标准IO 文件IO(低级IO) 打开 fopen,freopen,fdopen open 关闭 fclose close 读 getc,fgetc,getchar,fgets,gets,fread read 写 putc,fputc,putchar,fputs,puts,fwrite write fopen与open标准I/O使用fopen函数打开一个文件：1FILE* fp=fopen(const char* path,const char *mod) 其中path是文件名，mod用于指定文件打开的模式的字符串，比如”r”,”w”,”w+”,”a”等等，可以加上字母b用以指定以二进制模式打开（对于 Unix系统，只有一种文件类型，因此没有区别）,如果成功打开，返回一个FILE文件指针，如果失败返回NULL,这里的文件指针并不是指向实际的文 件，而是一个关于文件信息的数据包，其中包括文件使用的缓冲区信息。 文件IO使用open函数用于打开一个文件：1int fd=open(char *name,int how); 与fopen类似，name表示文件名字符串，而how指定打开的模式：O_RDONLY(只读),O_WRONLY(只写）,O_RDWR （可读可写),还有其他模式请man 2 open。成功返回一个正整数称为文件描述符，这与标准I/O显著不同，失败的话返回-1，与标准I/O返回NULL也是不同的。 open和fopen的区别(2)： 1.缓冲文件系统缓冲文件系统的特点是：在内存开辟一个“缓冲区”，为程序中的每一个文件使用，当执行读文件的操作时，从磁盘文件将数据先读入内存“缓冲区”，装满后再从内存“缓冲区”依此读入接收的变量。执行写文件的操作时，先将数据写入内存“缓冲区”，待内存“缓冲区”装满后再写入文件。由此可以看出，内存“缓冲区”的大小，影响着实际操作外存的次数，内存“缓冲区”越大，则操作外存的次数就少，执行速度就快、效率高。一般来说，文件“缓冲区”的大小随机器而定。fopen, fclose, fread, fwrite, fgetc, fgets, fputc, fputs, freopen, fseek, ftell, rewind等。 2.非缓冲文件系统缓冲文件系统是借助文件结构体指针来对文件进行管理，通过文件指针来对文件进行访问，既可以读写字符、字符串、格式化数据，也可以读写二进制数据。非缓冲文件系统依赖于操作系统，通过操作系统的功能对文件进行读写，是系统级的输入输出，它不设文件结构体指针，只能读写二进制文件，但效率高、速度 快，由于ANSI标准不再包括非缓冲文件系统，因此建议大家最好不要选择它。本书只作简单介绍。open, close, read, write, getc, getchar, putc, putchar 等。 open 是系统调用 返回的是文件句柄，文件的句柄是文件在文件描述副表里的索引，fopen是C的库函数，返回的是一个指向文件结构的指针。 fopen是ANSIC标准中的C语言库函数，在不同的系统中应该调用不同的内核apilinux中的系统函数是open，fopen是其封装函数，个人观点。仅供参考。 文件描述符是linux下的一个概念,linux下的一切设备都是以文件的形式操作.如网络套接字、硬件设备等。当然包括操作文件。fopen是标准c函数。返回文件流而不是linux下文件句柄。 设备文件不可以当成流式文件来用，只能用openfopen是用来操纵正规文件的，并且设有缓冲的，跟open还是有一些区别 一般用fopen打开普通文件，用open打开设备文件 fopen是标准c里的,而open是linux的系统调用.他们的层次不同.fopen可移植,open不能 我认为fopen和open最主要的区别是fopen在用户态下就有了缓存，在进行read和write的时候减少了用户态和内核态的切换，而open则每次都需要进行内核态和用户态的切换；表现为，如果顺序访问文件，fopen系列的函数要比直接调用open系列快；如果随机访问文件open要比fopen快。 来自论坛的经典回答： 前者属于低级IO，后者是高级IO。前者返回一个文件描述符(用户程序区的)，后者返回一个文件指针。前者无缓冲，后者有缓冲。前者与 read, write 等配合使用， 后者与 fread, fwrite等配合使用。后者是在前者的基础上扩充而来的，在大多数情况下，用后者。 fclose与close与打开文件相对的，标准I/O使用fclose关闭文件，将文件指针传入即可，如果成功关闭，返回0，否则返回EOF比如：12if(fclose(fp)!=0) printf(&quot;Error in closing file&quot;); 而文件IO使用close用于关闭open打开的文件，与fclose类似，只不过当错误发生时返回的是-1，而不是EOF，成功关闭同样是返回0。C语言用error code来进行错误处理的传统做法。 读文件，getc,fscanf,fgets和read标准I/O中进行文件读取可以使用getc，一个字符一个字符的读取，也可以使用gets（读取标准io读入的）、fgets以字符串单位进行读取（读到遇 到的第一个换行字符的后面），gets（接受一个参数，文件指针）不判断目标数组是否能够容纳读入的字符，可能导致存储溢出(不建议使用），而fgets使用三个参数：1char * fgets(char *s, int size, FILE *stream); 第一个参数和gets一样，用于存储输入的地址，第二个参数为整数，表示输入字符串的最大长度，最后一个参数就是文件指针，指向要读取的文件。最 后是fscanf，与scanf类似，只不过增加了一个参数用于指定操作的文件，比如fscanf(fp,”%s”,words)文件IO中使用read函数用于读取open函数打开的文件，函数原型如下：1ssize_t numread=read(int fd,void *buf,size_t qty); 其中fd就是open返回的文件描述符，buf用于存储数据的目的缓冲区，而qty指定要读取的字节数。如果成功读取，就返回读取的字节数目（小于等于qty） 判断文件结尾如果尝试读取达到文件结尾，标准IO的getc会返回特殊值EOF，而fgets碰到EOF会返回NULL,而对于*nix的read函数，情况有所 同。read读取qty指定的字节数，最终读取的数据可能没有你所要求的那么多（qty），而当读到结尾再要读的话，read函数将返回0. 写文件：putc,fputs,fprintf和write与读文件相对应的，标准C语言I/O使用putc写入字符，比如：1putc(ch,fp); 第一个参数是字符，第二个是文件指针。而fputs与此类似：1fputs(buf,fp); 仅仅是第一个参数换成了字符串地址。而fprintf与printf类似，增加了一个参数用于指定写入的文件，比如：1fprintf(stdout,&quot;Hello %s.\n&quot;,&quot;dennis&quot;); 切记fscanf和fprintf将FILE指针作为第一个参数，而putc,fputs则是作为第二个参数。 在文件IO中提供write函数用于写入文件，原型与read类似：1ssize_t result=write(int fd,void *buf ,size_t amt); fd是文件描述符，buf是将要写入的内存数据，amt是要写的字节数。如果写入成功返回写入的字节数，通过result与amt的比较可以判断是否写入正常，如果写入失败返回-1 随机存取：fseek()、ftell()和lseek()标准I/O使用fseek和ftell用于文件的随机存取，先看看fseek函数原型 int fseek(FILE *stream, long offset, int whence); 第一个参数是文件指针，第二个参数是一个long类型的偏移量（offset），表示从起始点开始移动的距离。第三个参数就是用于指定起始点的模式，stdio.h指定了下列模式常量：123SEEK_SET 文件开始处 SEEK_CUR 当前位置 SEEK_END 文件结尾处 看几个调用例子：123fseek(fp,0L,SEEK_SET); //找到文件的开始处 fseek(fp,0L,SEEK_END); //定位到文件结尾处 fseek(fp,2L,SEEK_CUR); //文件当前位置向前移动2个字节数 而ftell函数用于返回文件的当前位置，返回类型是一个long类型，比如下面的调用：12fseek(fp,0L,SEEK_END);//定位到结尾 long last=ftell(fp); //返回当前位置 那么此时的last就是文件指针fp指向的文件的字节数。 与标准I/O类似，*nix系统提供了lseek来完成fseek的功能，原型如下：1off_t lseek(int fildes, off_t offset, int whence); fildes是文件描述符，而offset也是偏移量，whence同样是指定起始点模式，唯一的不同是lseek有返回值，如果成功就 返回指针变化前的位置，否则返回-1。whence的取值与fseek相同：SEEK_SET,SEEK_CUR,SEEK_END，但也可以用整数 0,1,2相应代替。 系统调用与库函数上面我们一直在讨论文件I/O与标准I/O的区别，其实可以这样说，文件I/O是系统调用、标准I/O是库函数，看下面这张图： POSIX：Portable Operating System Interface 可移植操作系统接口 ANSI：American National Standrads Institute 美国国家标准学会 系统调用操作系统负责管理和分配所有的计算机资源。为了更好地服务于应用程序，操作系统提供了一组特殊接口——系统调用。通过这组接口用户程序可以使用操作系统内核提供的各种功能。例如分配内存、创建进程、实现进程之间的通信等。 为什么不允许程序直接访问计算机资源？答案是不安全。单片机开发中，由于不需要操作系统，所以开发人员可以编写代码直接访问硬件。而在32位嵌入式系统中通常都要运行操作系统，所以开发人员可以编写代码直接访问硬件。而在32位嵌入式系统中通常都要运行操作系统，程序访问资源的方式都发生了改变。操作系统基本上都支持多任务，即同时可以运行多个程序。如果允许程序直接访问系统资源，肯定会带来很多问题。因此，所有软硬件资源的管理和分配都有操作系统负责。程序要获取资源（如分配内存，读写串口）必须由操作系统来完成，即用户程序向操作系统发出服务请求，操作系统收到请求后执行相关的代码来处理。 用户程序向操作系统提出请求的接口就是系统调用。所有的操作系统都会提供系统调用接口，只不过不同的操作系统提供的系统调用接口各不相同。Linux 系统调用接口非常精简，它继承了Unix 系统调用中最基本的和最有用的部分。这些系统调用按照功能大致可分为进程控制、进程间通信、文件系统控制、存储管理、网络管理、套接字控制、用户管理等几类。 库函数库函数可以说是对系统调用的一种封装，因为系统调用是面对的是操作系统，系统包括Linux、Windows等，如果直接系统调用，会影响程序的移植性，所以这里使用了库函数，比如说C库，这样只要系统中安装了C库，就都可以使用这些函数，比如printf() scanf()等，C库相当于对系统函数进行了翻译，使我们的APP可以调用这些函数； 用户编程接口API前面提到利用系统调用接口程序可以访问各种资源，但在实际开发中程序并不直接使用系统调用接口，而是使用用户编程接口（API）。为什么不直接使用系统调用接口呢？ 原因如下： 系统调用接口功能非常简单，无法满足程序的需求。 不同操作系统的系统调用接口不兼容，程序移植时工作量大。 用户编程接口通俗的解释就是各种库（最重要的就是C库）中的函数。为了提高开发效率，C库中实现了很多函数。这些函数实现了常用的功能，供程序员调用。这样一来，程序员不需要自己编写这些代码，直接调用库函数就可以实现基本功能，提高了代码的复用率。使用用户编程接口还有一个好处：程序具有良好的可移植性。几乎所有的操作系统上都实现了C库，所以程序通常只需要重新编译一下就可以在其他操作系统下运行。 用户编程接口（API）在实现时，通常都要依赖系统调用接口。例如，创建进程的API函数fork()对应于内核空间的sys_fork()系统调用。很多API函数西亚我哦通过多个系统调用来完成其功能。还有一些API函数不要调用任何系统调用。 在Linux 中用户编程接口（API）遵循了在Unix中最流行的应用编程界面标准——POSIX标准。POSIX标准是由IEEE和ISO/IEC共同开发的标准系统。该标准基于当时想用的Unix 实践和经验，描述了操作系统的系统调用编程接口（实际上就是API），用于保证应用程序可以在源代码一级商多种操作系统上运行。这些系统调用编程接口主要是通过C库（libc )实现的。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位图（BitMap）索引]]></title>
    <url>%2F2019%2F05%2F01%2F%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[案例 有张表名为table的表，由三列组成，分别是姓名、性别和婚姻状况，其中性别只有男和女两项，婚姻状况由已婚、未婚、离婚这三项，该表共有100w个记录。现在有这样的查询： select * from table where Gender=‘男’ and Marital=“未婚”。 姓名(Name) 性别(Gender) 婚姻状况(Marital) 张三 男 已婚 李四 女 已婚 王五 男 未婚 赵六 女 离婚 孙七 女 未婚 不使用索引 不使用索引时，数据库只能一行行扫描所有记录，然后判断该记录是否满足查询条件。 B树索引 对于性别，可取值的范围只有’男’,’女’，并且男和女可能各站该表的50%的数据，这时添加B树索引还是需要取出一半的数据， 因此完全没有必要。相反，如果某个字段的取值范围很广，几乎没有重复，比如身份证号，此时使用B树索引较为合适。事实上，当取出的行数据占用表中大部分的数据时，即使添加了B树索引，数据库如oracle、mysql也不会使用B树索引，很有可能还是一行行全部扫描。 位图索引出马如果用户查询的列的基数非常的小， 即只有的几个固定值，如性别、婚姻状况、行政区等等。要为这些基数值比较小的列建索引，就需要建立位图索引。 对于性别这个列，位图索引形成两个向量，男向量为10100…，向量的每一位表示该行是否是男，如果是则位1，否为0，同理，女向量位01011。 RowId 1 2 3 4 5 … 男 1 0 1 0 0 女 0 1 0 1 1 对于婚姻状况这一列，位图索引生成三个向量，已婚为11000…，未婚为00100…，离婚为00010…。 RowId 1 2 3 4 5 … 已婚 1 1 0 0 0 未婚 0 0 1 0 1 离婚 0 0 0 1 0 当我们使用查询语句“select * from table where Gender=‘男’ and Marital=“未婚”;”的时候 首先取出男向量10100…，然后取出未婚向量00100…，将两个向量做and操作，这时生成新向量00100…，可以发现第三位为1，表示该表的第三行数据就是我们需要查询的结果。 RowId 1 2 3 4 5 男 1 0 1 0 0 未婚 0 0 1 0 1 结果 0 0 1 0 0 位图索引的适用条件上面讲了，位图索引适合只有几个固定值的列，如性别、婚姻状况、行政区等等，而身份证号这种类型不适合用位图索引。 此外，位图索引适合静态数据，而不适合索引频繁更新的列。举个例子，有这样一个字段busy，记录各个机器的繁忙与否，当机器忙碌时，busy为1，当机器不忙碌时，busy为0。 这个时候有人会说使用位图索引，因为busy只有两个值。好，我们使用位图索引索引busy字段！假设用户A使用update更新某个机器的busy值，比如update table set table.busy=1 where rowid=100;，但还没有commit，而用户B也使用update更新另一个机器的busy值，update table set table.busy=1 where rowid=12; 这个时候用户B怎么也更新不了，需要等待用户A commit。 原因：用户A更新了某个机器的busy值为1，会导致所有busy为1的机器的位图向量发生改变，因此数据库会将busy＝1的所有行锁定，只有commit之后才解锁。 源地址：http://www.cnblogs.com/LBSer]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的inode的理解]]></title>
    <url>%2F2019%2F05%2F01%2FLinux%E7%9A%84inode%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[inode是什么？理解inode，要从文件储存说起。文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 inode的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 可以用stat命令，查看某个文件的inode信息：stat example.txt 总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1df -i 查看每个inode节点的大小，可以用如下命令：1sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码：1ls -i example.txt 目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。 目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls命令只列出目录文件中的所有文件名：1ls /etc ls -i命令列出整个目录文件，即文件名和inode号码：1ls -i /etc 如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。1ls -l /etc 硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接：1ln 源文件 目标文件 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）,这里的2是父目录对其的“硬链接”和当前目录下的”.硬链接“。 软链接除了硬链接以外，还有一种特殊情况。文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 ln -s命令可以创建软链接。ln -s 源文文件或目录 目标文件或目录 inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 实际问题在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。 查找原因： /data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。 解决方案： 删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。 用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题： ln -s /opt/newcache /data/cache]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux孤儿进程与僵尸进程]]></title>
    <url>%2F2019%2F05%2F01%2FLinux%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[基本概念我们知道在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 问题及危害unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 僵尸进程危害场景： 例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。 孤儿进程和僵尸进程测试孤儿进程测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;int main()&#123; pid_t pid; //创建一个进程 pid = fork(); //创建失败 if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //子进程 if (pid == 0) &#123; printf(&quot;I am the child process.\n&quot;); //输出进程ID和父进程ID printf(&quot;pid: %d\tppid:%d\n&quot;,getpid(),getppid()); printf(&quot;I will sleep five seconds.\n&quot;); //睡眠5s，保证父进程先退出 sleep(5); printf(&quot;pid: %d\tppid:%d\n&quot;,getpid(),getppid()); printf(&quot;child process is exited.\n&quot;); &#125; //父进程 else &#123; printf(&quot;I am father process.\n&quot;); //父进程睡眠1s，保证子进程输出进程id sleep(1); printf(&quot;father process is exited.\n&quot;); &#125; return 0;&#125;pid=3906 ppid=3905pid=3906 ppid=1 僵尸进程测试程序如下所示：123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;int main()&#123; pid_t pid; pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am child process.I am exiting.\n&quot;); exit(0); &#125; printf(&quot;I am father process.I will sleep two seconds\n&quot;); //等待子进程先退出 sleep(2); //输出进程信息 system(&quot;ps -o pid,ppid,state,tty,command&quot;); printf(&quot;father process is exiting.\n&quot;); return 0;&#125; 僵尸进程测试2：父进程循环创建子进程，子进程退出，造成多个僵尸进程，程序如下所示：1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main()&#123; pid_t pid; //循环创建子进程 while(1) &#123; pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am a child process.\nI am exiting.\n&quot;); //子进程退出，成为僵尸进程 exit(0); &#125; else &#123; //父进程休眠20s继续创建子进程 sleep(20); continue; &#125; &#125; return 0;&#125; 僵尸进程解决办法通过信号机制子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;static void sig_child(int signo);int main()&#123; pid_t pid; //创建捕捉子进程退出信号 signal(SIGCHLD,sig_child); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am child process,pid id %d.I am exiting.\n&quot;,getpid()); exit(0); &#125; printf(&quot;I am father process.I will sleep two seconds\n&quot;); //等待子进程先退出 sleep(2); //输出进程信息 system(&quot;ps -o pid,ppid,state,tty,command&quot;); printf(&quot;father process is exiting.\n&quot;); return 0;&#125;static void sig_child(int signo)&#123; pid_t pid; int stat; //处理僵尸进程 while ((pid = waitpid(-1, &amp;stat, WNOHANG)) &gt;0) printf(&quot;child %d terminated.\n&quot;, pid);&#125; fork两次《Unix 环境高级编程》8.6节说的非常详细。原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main()&#123; pid_t pid; //创建第一个子进程 pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程 else if (pid == 0) &#123; //子进程再创建子进程 printf(&quot;I am the first child process.pid:%d\tppid:%d\n&quot;,getpid(),getppid()); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程退出 else if (pid &gt;0) &#123; printf(&quot;first procee is exited.\n&quot;); exit(0); &#125; //第二个子进程 //睡眠3s保证第一个子进程退出，这样第二个子进程的父亲就是init进程里 sleep(3); printf(&quot;I am the second child process.pid: %d\tppid:%d\n&quot;,getpid(),getppid()); exit(0); &#125; //父进程处理第一个子进程退出 if (waitpid(pid, NULL, 0) != pid) &#123; perror(&quot;waitepid error:&quot;); exit(1); &#125; exit(0); return 0;&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode894. All Possible Full Binary Trees]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode894-All-Possible-Full-Binary-Trees%2F</url>
    <content type="text"><![CDATA[A full binary tree is a binary tree where each node has exactly 0 or 2 children. Return a list of all possible full binary trees with N nodes. Each element of the answer is the root node of one possible tree. Each node of each tree in the answer must have node.val = 0. You may return the final list of trees in any order. Example 1:12Input: 7Output: [[0,0,0,null,null,0,0,null,null,0,0],[0,0,0,null,null,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,null,null,null,null,0,0],[0,0,0,0,0,null,null,0,0]] Explanation: 给出了个N，代表一棵二叉树有N个节点，求所能构成的树。 解题方法所有能构成的树，并且返回的不是数目，而是真正的树。所以一定会把所有的节点都求出来。一般就使用了递归。 这个题中，重点是返回一个列表，也就是说每个能够成的树的根节点都要放到这个列表里。而且当左子树、右子树的节点个数固定的时候，也会出现排列组合的情况，所以使用了两重for循环来完成所有的左右子树的组合。 另外的一个技巧就是，左右子树的个数一定是奇数个。 递归方法，虽然比较慢，但是容易理解，就是组成小的子树，一个个拼接，为啥要减1，是因为一定会有个根节点，先把这个减去再说。 代码如下：12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;TreeNode*&gt; allPossibleFBT(int N) &#123; N--; vector&lt;TreeNode*&gt; res; if(N==0)&#123; res.push_back(new TreeNode(0)); return res; &#125; for (int i = 1; i &lt; N; i += 2) &#123; for (auto&amp; left : allPossibleFBT(i)) &#123; for (auto&amp; right : allPossibleFBT(N - i)) &#123; TreeNode* root = new TreeNode(0); root-&gt;left = left; root-&gt;right = right; res.push_back(root); &#125; &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode461. Hamming Distance]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode461-Hamming-Distance%2F</url>
    <content type="text"><![CDATA[Hamming Distance The Hamming distance between two integers is the number of positions at which the corresponding bits are different. Given two integers x and y, calculate the Hamming distance. Note:0 ≤ x, y &lt; 231. Example:12345678Input: x = 1, y = 4Output: 2Explanation:1 (0 0 0 1)4 (0 1 0 0) ↑ ↑ The above arrows point to positions where the corresponding bits are different. 求两个数的海明距离，就是判断其二进制有多少不一样的位12345678910class Solution &#123;public: int hammingDistance(int x, int y) &#123; int temp = x ^ y; int res=0; for(int i=temp;i&gt;0;i=i&gt;&gt;1) if(i&amp;1) res++; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode814. Binary Tree Pruning]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode814-Binary-Tree-Pruning%2F</url>
    <content type="text"><![CDATA[We are given the head node root of a binary tree, where additionally every node’s value is either a 0 or a 1. Return the same tree where every subtree (of the given tree) not containing a 1 has been removed. (Recall that the subtree of a node X is X, plus every node that is a descendant of X.) Example 1:Input: [1,null,0,0,1]Output: [1,null,0,null,1] Explanation:Only the red nodes satisfy the property “every subtree not containing a 1”.The diagram on the right represents the answer. Example 2:Input: [1,0,1,0,0,0,1]Output: [1,null,1,null,1] Example 3:Input: [1,1,0,1,1,0,1,0]Output: [1,1,0,1,1,null,1] Note: The binary tree will have at most 100 nodes.The value of each node will only be 0 or 1. 删掉子树里没有1的，返回这棵树。1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool dele(TreeNode* root)&#123; if(root == NULL) return false; bool a1=dele(root-&gt;left); bool a2=dele(root-&gt;right); if(!a1) root-&gt;left=NULL; if(!a2) root-&gt;right=NULL; return root-&gt;val==1 || a1 || a2; &#125; TreeNode* pruneTree(TreeNode* root) &#123; return dele(root)?root:NULL; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode890. Find and Replace Pattern]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode890-Find-and-Replace-Pattern%2F</url>
    <content type="text"><![CDATA[You have a list of words and a pattern, and you want to know which words in words matches the pattern. A word matches the pattern if there exists a permutation of letters p so that after replacing every letter x in the pattern with p(x), we get the desired word. (Recall that a permutation of letters is a bijection from letters to letters: every letter maps to another letter, and no two letters map to the same letter.) Return a list of the words in words that match the given pattern. You may return the answer in any order. Example 1:12345Input: words = [&quot;abc&quot;,&quot;deq&quot;,&quot;mee&quot;,&quot;aqq&quot;,&quot;dkd&quot;,&quot;ccc&quot;], pattern = &quot;abb&quot;Output: [&quot;mee&quot;,&quot;aqq&quot;]Explanation: &quot;mee&quot; matches the pattern because there is a permutation &#123;a -&gt; m, b -&gt; e, ...&#125;. &quot;ccc&quot; does not match the pattern because &#123;a -&gt; c, b -&gt; c, ...&#125; is not a permutation,since a and b map to the same letter. Note: 1 &lt;= words.length &lt;= 501 &lt;= pattern.length = words[i].length &lt;= 20 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: bool match(string word,string pattern)&#123; int i,j; bool seen[26]; map&lt;char,char&gt; table; map&lt;char, char&gt;::iterator it; for(i=0;i&lt;26;i++) seen[i]=false; for(j=0;j&lt;word.length();j++)&#123; it = table.find(word[j]); if(it==table.end())&#123; table[word[j]]=pattern[j]; &#125; if(table[word[j]]!=pattern[j] ) return false; &#125; for(i=0;i&lt;26;i++) seen[i]=false; for(it=table.begin();it!=table.end();it++)&#123; if(seen[it-&gt;second-&apos;a&apos;]) return false; seen[it-&gt;second-&apos;a&apos;]=true; &#125; return true; &#125; vector&lt;string&gt; findAndReplacePattern(vector&lt;string&gt;&amp; words, string pattern) &#123; vector&lt;string&gt; res; int i,j; for(i=0;i&lt;words.size();i++)&#123; if(match(words[i],pattern)) res.push_back(words[i]); &#125; return res; &#125;&#125;; 这个题判断给定的字符串是不是符合pattern串的模式，很简单的题搞复杂了。用了一个map来匹配字符组合，用seen判断这个pattern字符是否出现过，如果出现过就是非法的了。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode657. Robot Return to Origin]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode657-Robot-Return-to-Origin%2F</url>
    <content type="text"><![CDATA[Robot Return to Origin There is a robot starting at position (0, 0), the origin, on a 2D plane. Given a sequence of its moves, judge if this robot ends up at (0, 0) after it completes its moves. The move sequence is represented by a string, and the character moves[i] represents its ith move. Valid moves are R (right), L (left), U (up), and D (down). If the robot returns to the origin after it finishes all of its moves, return true. Otherwise, return false. Note: The way that the robot is “facing” is irrelevant. “R” will always make the robot move to the right once, “L” will always make it move left, etc. Also, assume that the magnitude of the robot’s movement is the same for each move. Example 1: Input: “UD”Output: trueExplanation: The robot moves up once, and then down once. All moves have the same magnitude, so it ended up at the origin where it started. Therefore, we return true. Example 2: Input: “LL”Output: falseExplanation: The robot moves left twice. It ends up two “moves” to the left of the origin. We return false because it is not at the origin at the end of its moves. 一个序列，判断‘L’和‘R’是不是个数相等，‘U’和‘D’是不是个数相等。12345678910111213141516class Solution &#123;public: bool judgeCircle(string moves) &#123; int ud=0,lr=0; for(int i=0;i&lt;moves.length();i++)&#123; if(moves[i]==&apos;U&apos;) ud++; else if(moves[i]==&apos;D&apos;) ud--; else if(moves[i]==&apos;L&apos;) lr++; else if(moves[i]==&apos;R&apos;) lr--; &#125; if(ud==0 &amp;&amp; lr==0) return true; else return false; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode950. Reveal Cards In Increasing Order]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode950-Reveal-Cards-In-Increasing-Order%2F</url>
    <content type="text"><![CDATA[Reveal Cards In Increasing Order In a deck of cards, every card has a unique integer. You can order the deck in any order you want. Initially, all the cards start face down (unrevealed) in one deck. Now, you do the following steps repeatedly, until all cards are revealed: Take the top card of the deck, reveal it, and take it out of the deck.If there are still cards in the deck, put the next top card of the deck at the bottom of the deck.If there are still unrevealed cards, go back to step 1. Otherwise, stop.Return an ordering of the deck that would reveal the cards in increasing order. The first entry in the answer is considered to be the top of the deck. Example 1:12345678910111213141516171819202122232425262728293031Input: [17,13,11,2,3,5,7]Output: [2,13,3,11,5,17,7]Explanation: We get the deck in the order [17,13,11,2,3,5,7] (this order doesn&apos;t matter), and reorder it.After reordering, the deck starts as [2,13,3,11,5,17,7], where 2 is the top of the deck.We reveal 2, and move 13 to the bottom. The deck is now [3,11,5,17,7,13].We reveal 3, and move 11 to the bottom. The deck is now [5,17,7,13,11].We reveal 5, and move 17 to the bottom. The deck is now [7,13,11,17].We reveal 7, and move 13 to the bottom. The deck is now [11,17,13].We reveal 11, and move 17 to the bottom. The deck is now [13,17].We reveal 13, and move 17 to the bottom. The deck is now [17].We reveal 17.Since all the cards revealed are in increasing order, the answer is correct.``` Note:1 &lt;= A.length &lt;= 10001 &lt;= A[i] &lt;= 10^6A[i] != A[j] for all i != jwoc什么乱七八糟的题，这个确实没懂。从牌组顶部抽一张牌，显示它，然后将其从牌组中移出。如果牌组中仍有牌，则将下一张处于牌组顶部的牌放在牌组的底部。如果仍有未显示的牌，那么返回步骤 1。否则，停止行动。得到的序列要求是递增序列。例如 1 3 2 通过上述变换，可以得到1 2 3，满足题目要求。解法是：1 2 3 通过上述变换，可以得到 1 3 2，即这道题的解。 class Solution {public: vector deckRevealedIncreasing(vector&amp; deck) { queue q; vector res(deck.size()); sort(deck.begin(),deck.end()); for(int i=0;i&lt;deck.size();i++) q.push(i); for(int i=0;i&lt;deck.size();i++) { int temp = q.front(); res[temp]=deck[i]; q.pop(); temp = q.front(); q.push(temp); q.pop(); } return res; } };`]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode980. Unique Paths III]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode980-Unique-Paths-III%2F</url>
    <content type="text"><![CDATA[Unique Paths IIIHard On a 2-dimensional grid, there are 4 types of squares: 1 represents the starting square. There is exactly one starting square.2 represents the ending square. There is exactly one ending square.0 represents empty squares we can walk over.-1 represents obstacles that we cannot walk over.Return the number of 4-directional walks from the starting square to the ending square, that walk over every non-obstacle square exactly once. Example 1:12345Input: [[1,0,0,0],[0,0,0,0],[0,0,2,-1]]Output: 2Explanation: We have the following two paths: 1. (0,0),(0,1),(0,2),(0,3),(1,3),(1,2),(1,1),(1,0),(2,0),(2,1),(2,2)2. (0,0),(1,0),(2,0),(2,1),(1,1),(0,1),(0,2),(0,3),(1,3),(1,2),(2,2) Example 2:1234567Input: [[1,0,0,0],[0,0,0,0],[0,0,0,2]]Output: 4Explanation: We have the following four paths: 1. (0,0),(0,1),(0,2),(0,3),(1,3),(1,2),(1,1),(1,0),(2,0),(2,1),(2,2),(2,3)2. (0,0),(0,1),(1,1),(1,0),(2,0),(2,1),(2,2),(1,2),(0,2),(0,3),(1,3),(2,3)3. (0,0),(1,0),(2,0),(2,1),(2,2),(1,2),(1,1),(0,1),(0,2),(0,3),(1,3),(2,3)4. (0,0),(1,0),(2,0),(2,1),(1,1),(0,1),(0,2),(0,3),(1,3),(1,2),(2,2),(2,3) Example 3:12345Input: [[0,1],[2,0]]Output: 0Explanation: There is no path that walks over every empty square exactly once.Note that the starting and ending square can be anywhere in the grid. Note: 1 &lt;= grid.length * grid[0].length &lt;= 20 给了一个二维矩阵，1代表起点，2代表终点，0代表可以走的格子，-1代表障碍物。求从起点到终点，把所有的可以走的格子都遍历一遍，所有可能的不同路径数。 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; dirs = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; int uniquePathsIII(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int M=grid.size(); int zerosize=0,res=0; int N=grid[0].size(); for(int i=0;i&lt;M;i++) for(int j=0;j&lt;N;j++) if(grid[i][j]==0) zerosize++; for(int i=0;i&lt;M;i++) for(int j=0;j&lt;N;j++) if(grid[i][j]==1) dfs(grid,i,j,0,zerosize,res); return res; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int x, int y, int pathcount, int zerocount, int&amp; res)&#123; if(grid[x][y]==2 &amp;&amp; zerocount == pathcount )&#123; res++; &#125; int M=grid.size(); int N=grid[0].size(); int pre=grid[x][y]; if(pre==0) pathcount++; grid[x][y]=-1; for (auto d : dirs) &#123; int nx = x + d.first; int ny = y + d.second; if (nx &lt; 0 || nx &gt;= M || ny &lt; 0 || ny &gt;= N || grid[nx][ny] == -1) continue; dfs(grid, nx, ny, pathcount, zerocount, res); &#125; grid[x][y]=pre; &#125; &#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode832. Flipping an Image]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode832-Flipping-an-Image%2F</url>
    <content type="text"><![CDATA[Flipping an ImageGiven a binary matrix A, we want to flip the image horizontally, then invert it, and return the resulting image. To flip an image horizontally means that each row of the image is reversed. For example, flipping [1, 1, 0] horizontally results in [0, 1, 1]. To invert an image means that each 0 is replaced by 1, and each 1 is replaced by 0. For example, inverting [0, 1, 1] results in [1, 0, 0]. Example 1:1234Input: [[1,1,0],[1,0,1],[0,0,0]]Output: [[1,0,0],[0,1,0],[1,1,1]]Explanation: First reverse each row: [[0,1,1],[1,0,1],[0,0,0]].Then, invert the image: [[1,0,0],[0,1,0],[1,1,1]] Example 2:1234Input: [[1,1,0,0],[1,0,0,1],[0,1,1,1],[1,0,1,0]]Output: [[1,1,0,0],[0,1,1,0],[0,0,0,1],[1,0,1,0]]Explanation: First reverse each row: [[0,0,1,1],[1,0,0,1],[1,1,1,0],[0,1,0,1]].Then invert the image: [[1,1,0,0],[0,1,1,0],[0,0,0,1],[1,0,1,0]] Notes: 1 &lt;= A.length = A[0].length &lt;= 200 &lt;= A[i][j] &lt;= 1 没啥好说的，普通的矩阵操作。 1234567891011121314151617class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; flipAndInvertImage(vector&lt;vector&lt;int&gt; &gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++)&#123; for(int j=0,k=A[i].size()-1;j&lt;A[i].size()/2;j++,k--)&#123; int temp = A[i][j]; A[i][j]=A[i][k]; A[i][k]=temp; &#125; for(int j=0,k=A[i].size()-1;j&lt;A[i].size();j++,k--)&#123; A[i][j]=1-A[i][j]; &#125; &#125; return A; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核分析笔记----中断和中断处理程序]]></title>
    <url>%2F2019%2F04%2F29%2FLinux%E5%86%85%E6%A0%B8%E5%88%86%E6%9E%90-%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[原文：http://www.cnblogs.com/hanyan225/archive/2011/07/17/2108609.html 中断还是中断，我讲了很多次的中断了，今天还是要讲中断，为啥呢？因为在操作系统中，中断是必须要讲的.. 那么什么叫中断呢， 中断还是打断，这样一说你就不明白了。唉，中断还真是有点像打断。我们知道linux管理所有的硬件设备，要做的第一件事先是通信。然后，我们天天在说一句话：处理器的速度跟外围硬件设备的速度往往不在一个数量级上，甚至几个数量级的差别，这时咋办，你总不能让处理器在那里傻等着你硬件做好了告诉我一声吧。这很容易就和日常生活联系起来了，这样效率太低，不如我处理器做别的事情，你硬件设备准备好了，告诉我一声就得了。这个告诉，咱们说的轻松，做起来还是挺费劲啊！怎么着，简单一点，轮训(polling)可能就是一种解决方法，缺点是操作系统要做太多的无用功，在那里傻傻的做着不重要而要重复的工作，这里有更好的办法—中断，这个中断不要紧，关键在于从硬件设备的角度上看，已经实现了从被动为主动的历史性突破。 中断的例子我就不说了，这个很显然啊。分析中断，本质上是一种特殊的电信号，由硬件设备发向处理器，处理器接收到中断后，会马上向操作系统反应此信号的带来，然后就由OS负责处理这些新到来的数据，中断可以随时发生，才不用操心与处理器的时间同步问题。不同的设备对应的中断不同，他们之间的不同从操作系统级来看，差别就在于一个数字标识—–中断号。专业一点就叫中断请求(IRQ)线,通常IRQ都是一些数值量。有些体系结构上，中断好是固定的，有的是动态分配的，这不是问题所在，问题在于特定的中断总是与特定的设备相关联，并且内核要知道这些信息，这才是最关键的,不是么？哈哈. 用书上一句话说：讨论中断就不得不提及异常，异常和中断不一样，它在产生时必须要考虑与处理器的时钟同步，实际上，异常也常常称为同步中断，在处理器执行到由于编程失误而导致的错误指令的时候，或者是在执行期间出现特殊情况，必须要靠内核来处理的时候，处理器就会产生一个异常。因为许多处理器体系结构处理异常以及处理中断的方式类似，因此，内核对它们的处理也很类似。这里的讨论，大部分都是适合异常，这时可以看成是处理器本身产生的中断。 中断产生告诉中断控制器，继续告诉操作系统内核，内核总是要处理的，是不？这里内核会执行一个叫做中断处理程序或中断处理例程的函数。这里特别要说明，中断处理程序是和特定中断相关联的，而不是和设备相关联，如果一个设备可以产生很多中断，这时该设备的驱动程序也就需要准备多个这样的函数。一个中断处理程序是设备驱动程序的一部分，这个我们在linux设备驱动中已经说过，就不说了，后面我也会提到一些。前边说过一个问题：中断是可能随时发生的，因此必须要保证中断处理程序也能随时执行，中断处理程序也要尽可能的快速执行，只有这样才能保证尽可能快地恢复中断代码的执行。 但是，不想说但是，大学第一节逃课的情形现在仍记忆犹新：又想马儿跑，又想马儿不吃草，怎么可能！但现实问题或者不像想象那样悲观，我们的中断说不定还真有奇迹发生。这个奇迹就是将中断处理切为两个部分或两半。中断处理程序上半部(top half)—接收到一个中断，它就立即开始开始执行，但只做严格时限的工作，这些工作都是在所有中断被禁止的情况下完成的。同时，能够被允许稍后完成的工作推迟到下半部(bottom half)去，此后，下半部会被执行，通常情况下，下半部都会在中断处理程序返回时立即执行。我会在后面谈论linux所提供的是实现下半部的各种机制。 说了那么多，现在开始第一个问题：如何注册一个中断处理程序。我们在linux驱动程序理论里讲过，通过一下函数可注册一个中断处理程序： 1int request_irq(unsigned int irq,irqreturn_t (*handler)(int, void *,struct pt_regs *),unsigned long irqflags,const char * devname,void *dev_id) 有关这个中断的一些参数说明，我就不说了，一旦注册了一个中断处理程序，就肯定会有释放中断处理，这是调用下列函数： 1void free_irq(unsigned int irq, void *dev_id) 这里需要说明的就是要必须要从进程上下文调用free_irq().好了，现在给出一个例子来说明这个过程,首先声明一个中断处理程序： 1static irqreturn_t intr_handler(int irq, void *dev_id, struct pt_regs *regs) 注意：这里的类型和前边说到的request_irq()所要求的参数类型是匹配的，参数不说了。对于返回值，中断处理程序的返回值是一个特殊类型，irqrequest_t,可能返回两个特殊的值：IRQ_NONE和IRQ_HANDLED.当中断处理程序检测到一个中断时，但该中断对应的设备并不是在注册处理函数期间指定的产生源时，返回IRQ_NONE;当中断处理程序被正确调用，且确实是它所对应的设备产生了中断时，返回IRQ_HANDLED.C此外，也可以使用宏IRQ_RETVAL(x)，如果x非0值，那么该宏返回IRQ_HANDLED,否则，返回IRQ_NONE.利用这个特殊的值，内核可以知道设备发出的是否是一种虚假的(未请求)中断。如果给定中断线上所有中断处理程序返回的都是IRQ_NONE，那么，内核就可以检测到出了问题。最后，需要说明的就是那个static了，中断处理程序通常会标记为static，因为它从来不会被别的文件中的代码直接调用。另外，中断处理程序是无需重入的，当一个给定的中断处理程序正在执行时，相应的中断线在所有处理器上都会被屏蔽掉，以防止在同一个中断上接收另外一个新的中断。通常情况下，所有其他的中断都是打开的，所以这些不同中断线上的其他中断都能被处理，但当前中断总是被禁止的。由此可见，同一个中断处理程序绝对不会被同时调用以处理嵌套的中断。 下面要说到的一个问题是和共享的中断处理程序相关的。共享和非共享在注册和运行方式上比较相似的。差异主要有以下几点： request_irq()的参数flags必须设置为SA_SHIRQ标志。 对每个注册的中断处理来说，dev_id参数必须唯一。指向任一设备结构的指针就可以满足这一要求。通常会选择设备结构，因为它是唯一的，而且中断处理程序可能会用到它，不能给共享的处理程序传递NULL值。 中断处理程序必须能够区分它的设备是否真的产生了中断。这既需要硬件的支持，也需要处理程序有相关的处理逻辑。如果硬件不支持这一功能，那中断处理程序肯定会束手无策，它根本没法知道到底是否与它对应的设备发生了中断，还是共享这条中断线的其他设备发出了中断。 在指定SA_SHIRQ标志以调用request_irq()时，只有在以下两种情况下才能成功：中断当前未被注册或者在该线上的所有已注册处理程序都指定了SA_SHIRQ.A。注意，在这一点上2.6与以前的内核是不同的，共享的处理程序可以混用SA_INTERRUPT. 一旦内核接收到一个中断后，它将依次调用在该中断线上注册的每一个处理程序。因此一个处理程序必须知道它是否应该为这个中断负责。如果与它相关的设备并没有产生中断，那么中断处理程序应该立即退出，这需要硬件设备提供状态寄存器(或类似机制)，以便中断处理程序进行检查。毫无疑问，大多数设备都提这种功能。 当执行一个中断处理程序或下半部时，内核处于中断上下文(interrupt context)中。对比进程上下文，进程上下文是一种内核所处的操作模式，此时内核代表进程执行，可以通过current宏关联当前进程。此外，因为进程是进程上下文的形式连接到内核中，因此，在进程上下文可以随时休眠，也可以调度程序。但中断上下文却完全不是这样，它可以休眠，因为我们不能从中断上下文中调用函数。如果一个函数睡眠，就不能在中断处理程序中使用它，这也是对什么样的函数能在中断处理程序中使用的限制。还需要说明一点的是，中断处理程序没有自己的栈，相反，它共享被中断进程的内核栈，如果没有正在运行的进程，它就使用idle进程的栈。因为中断程序共享别人的堆栈，所以它们在栈中获取空间时必须非常节省。内核栈在32位体系结构上是8KB，在64位体系结构上是16KB.执行的进程上下文和产生的所有中断都共享内核栈。 下面给出中断从硬件到内核的路由过程(截图选自liuux内核分析与设计p61)，然后做出总结： 上面的图内部说明已经很明确了，我这里就不在详谈。在内核中，中断的旅程开始于预定义入口点，这类似于系统调用。对于每条中断线，处理器都会跳到对应的一个唯一的位置。这样，内核就可以知道所接收中断的IRQ号了。初始入口点只是在栈中保存这个号，并存放当前寄存器的值(这些值属于被中断的任务)；然后，内核调用函数do_IRQ().从这里开始，大多数中断处理代码是用C写的。do_IRQ()的声明如下：1unsigned int do_IRQ(struct pt_regs regs) 因为C的调用惯例是要把函数参数放在栈的顶部，因此pt_regs结构包含原始寄存器的值，这些值是以前在汇编入口例程中保存在栈上的。中断的值也会得以保存，所以，do_IRQ()可以将它提取出来，X86的代码为： 1int irq = regs.orig_eax &amp; 0xff 计算出中断号后，do_IRQ()对所接收的中断进行应答，禁止这条线上的中断传递。在普通的PC机器上，这些操作是由mask_and_ack_8259A()来完成的，该函数由do_IRQ()调用。接下来，do_IRQ()需要确保在这条中断线上有一个有效的处理程序，而且这个程序已经启动但是当前没有执行。如果这样的话， do_IRQ()就调用handle_IRQ_event()来运行为这条中断线所安装的中断处理程序，有关处理例子，可以参考linux内核设计分析一书，我这里就不细讲了。在handle_IRQ_event()中，首先是打开处理器中断，因为前面已经说过处理器上所有中断这时是禁止中断(因为我们说过指定SA_INTERRUPT)。接下来，每个潜在的处理程序在循环中依次执行。如果这条线不是共享的，第一次执行后就退出循环，否则，所有的处理程序都要被执行。之后，如果在注册期间指定了SA_SAMPLE_RANDOM标志，则还要调用函数add_interrupt_randomness(),这个函数使用中断间隔时间为随机数产生熵。最后，再将中断禁止(do_IRQ()期望中断一直是禁止的)，函数返回。该函数做清理工作并返回到初始入口点，然后再从这个入口点跳到函数ret_from_intr().该函数类似初始入口代码，以汇编编写，它会检查重新调度是否正在挂起，如果重新调度正在挂起，而且内核正在返回用户空间(也就是说，中断了用户进程)，那么schedule()被调用。如果内核正在返回内核空间(也就是中断了内核本身)，只有在preempt_count为0时，schedule()才会被调用(否则，抢占内核是不安全的)。在schedule()返回之前，或者如果没有挂起的工作，那么，原来的寄存器被恢复，内核恢复到曾经中断的点。在x86上，初始化的汇编例程位于arch/i386/kernel/entry.S,C方法位于arch/i386/kernel/irq.c其它支持的结构类似。 下边给出PC机上位于/proc/interrupts文件的输出结果，这个文件存放的是系统中与中断相关的统计信息，这里就解释一下这个表： 上面是这个文件的输入，第一列是中断线(中断号)，第二列是一个接收中断数目的计数器，第三列是处理这个中断的中断控制器，最后一列是与这个中断有关的设备名字，这个名字是通过参数devname提供给函数request_irq()的。最后，如果中断是共享的，则这条中断线上注册的所有设备都会列出来，如4号中断。 Linux内核给我们提供了一组接口能够让我们控制机器上的中断状态，这些接口可以在&lt;asm/system.h&gt;和&lt;asm/irq.h&gt;中找到。一般来说，控制中断系统的原因在于需要提供同步，通过禁止中断，可以确保某个中断处理程序不会抢占当前的代码。此外，禁止中断还可以禁止内核抢占。然而，不管是禁止中断还是禁止内核抢占，都没有提供任何保护机制来防止来自其他处理器的并发访问。Linux支持多处理器，因此，内核代码一般都需要获取某种锁，防止来自其他处理器对共享数据的并发访问，获取这些锁的同时也伴随着禁止本地中断。锁提供保护机制，防止来自其他处理器的并发访问，而禁止中断提供保护机制，则是防止来自其他中断处理程序的并发访问。 在linux设备驱动理论帖里详细介绍过linux的中断操作接口，这里就大致过一下，禁止/使能本地中断(仅仅是当前处理器)用：12local_irq_disable();local_irq_enable(); 如果在调用local_irq_disable()之前已经禁止了中断，那么该函数往往会带来潜在的危险，同样的local_irq_enable()也存在潜在的危险，因为它将无条件的激活中断，尽管中断可能在开始时就是关闭的。所以我们需要一种机制把中断恢复到以前的状态而不是简单地禁止或激活，内核普遍关心这点，是因为内核中一个给定的代码路径可以在中断激活饿情况下达到，也可以在中断禁止的情况下达到，这取决于具体的调用链。面对这种情况，在禁止中断之前保存中断系统的状态会更加安全一些。相反，在准备激活中断时，只需把中断恢复到它们原来的状态： 123unsigned long flags;local_irq_save(flags);local_irq_restore(flags); 参数包含具体体系结构的数据，也就是包含中断系统的状态。至少有一种体系结构把栈信息与值相结合(SPARC),因此flags不能传递给另一个函数(换句话说，它必须驻留在同一个栈帧中)，基于这个原因，对local_irq_save()的调用和local_irq_restore()的调用必须在同一个函数中进行。前面的所有的函数既可以在中断中调用，也可以在进程上下文使用。 前面我提到过禁止整个CPU上所有中断的函数。但有时候，好奇的我就想，我干么没要禁止掉所有的中断，有时，我只需要禁止系统中一条特定的中断就可以了(屏蔽掉一条中断线)，这就有了我下面给出的接口： 1234void disable_irq(unsigned int irq);void disable_irq_nosync(unsigned int irq);void enable_irq(unsigned int irq);void synchronise_irq(unsigned int irq); 对有关函数的说明和注意，我前边已经说的很清楚了，这里飘过。另外，禁止多个中断处理程序共享的中断线是不合适的。禁止中断线也就禁止了这条线上所有设备的中断传递，因此，用于新设备的驱动程序应该倾向于不使用这些接口。另外，我们也可以通过宏定义在&lt;asm/system.h&gt;中的宏irqs_disable()来获取中断的状态，如果中断系统被禁止，则它返回非0，否则，返回0；用定义在&lt;asm/hardirq.h&gt;中的两个宏in_interrupt()和in_irq()来检查内核的当前上下文的接口。由于代码有时要做一些像睡眠这样只能从进程上下文做的事，这时这两个函数的价值就体现出来了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[可重入和不可重入]]></title>
    <url>%2F2019%2F04%2F29%2F%E5%8F%AF%E9%87%8D%E5%85%A5%E5%92%8C%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%85%A5%2F</url>
    <content type="text"><![CDATA[可重入和不可重入 重入一般可以理解为一个函数在同时多次调用，例如操作系统在进程调度过程中，或者单片机、处理器等的中断的时候会发生重入的现象。一般浮点运算都是由专门的硬件来完成，举个例子假设有个硬件寄存器名字叫做FLOAT，用来计算和存放浮点数的中间运算结果假设有这么个函数void fun(){//…这个函数对FLOAT寄存器进行操作}假如第一次执行，有个对浮点数操作运算的结果临时存在FLOAT寄存器中，而就在这时被中断了，而中断函数或者另一个进程也调用fun函数，这时第二次调用的fun函数在执行的过程中就会破坏第一次FLOAT寄存器中的结果，这样当返回到第一次fun函数的时候，结果就不正确了。 可以把fun函数理解为printf()函数。赞同 可重入和不可重入 这种情况出现在多任务系统当中，在任务执行期间捕捉到信号并对其进行处理时，进程正在执行的指令序列就被信号处理程序临时中断。如果从信号处理程序返回，则继续执行进程断点处的正常指令序列，从重新恢复到断点重新执行的过程中，函数所依赖的环境没有发生改变，就说这个函数是可重入的，反之就是不可重入的。众所周知，在进程中断期间，系统会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而函数内部使用的诸如全局或静态变量，buffer等并不在保护之列，所以如果这些值在函数被中断期间发生了改变，那么当函数回到断点继续执行时，其结果就不可预料了。打个比方，比如malloc，将如一个进程此时正在执行malloc分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个malloc，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用刚好覆盖了进程的操作，造成错误。 满足下面条件之一的多数是不可重入函数：(1)使用了静态数据结构;(2)调用了malloc或free;(3)调用了标准I/O函数;标准io库很多实现都以不可重入的方式使用全局数据结构。(4)进行了浮点运算.许多的处理器/编译器中，浮点一般都是不可重入的 (浮点运算大多使用协处理器或者软件模拟来实现。 1) 信号处理程序A内外都调用了同一个不可重入函数B；B在执行期间被信号打断，进入A (A中调用了B),完事之后返回B被中断点继续执行，这时B函数的环境可能改变，其结果就不可预料了。2) 多线程共享进程内部的资源，如果两个线程A，B调用同一个不可重入函数F，A线程进入F后，线程调度，切换到B，B也执行了F，那么当再次切换到线程A时，其调用F的结果也是不可预料的。在信号处理程序中即使调用可重入函数也有问题要注意。作为一个通用的规则，当在信号处理程序中调用可重入函数时，应当在其前保存errno，并在其后恢复errno。(因为每个线程只有一个errno变量，信号处理函数可能会修改其值，要了解经常被捕捉到的信号是SIGCHLD，其信号处理程序通常要调用一种wait函数，而各种wait函数都能改变errno。) 可重入函数列表: _exit（）、 access（）、alarm（）、cfgetispeed（）、cfgetospeed（）、cfsetispeed（）、cfsetospeed （）、chdir（）、chmod（）、chown（）、close（）、creat（）、dup（）、dup2（）、execle（）、 execve（）、fcntl（）、fork（）、fpathconf （）、fstat（）、fsync（）、getegid（）、 geteuid（）、getgid（）、getgroups（）、getpgrp（）、getpid（）、getppid（）、getuid（）、 kill（）、link（）、lseek（）、mkdir（）、mkfifo（）、 open（）、pathconf（）、pause（）、pipe（）、raise（）、read（）、rename（）、rmdir（）、setgid （）、setpgid（）、setsid（）、setuid（）、 sigaction（）、sigaddset（）、sigdelset（）、sigemptyset（）、sigfillset（）、 sigismember（）、signal（）、sigpending（）、sigprocmask（）、sigsuspend（）、sleep（）、 stat（）、sysconf（）、tcdrain（）、tcflow（）、tcflush（）、tcgetattr（）、tcgetpgrp（）、 tcsendbreak（）、tcsetattr（）、tcsetpgrp（）、time（）、times（）、 umask（）、uname（）、unlink（）、utime（）、wait（）、waitpid（）、write（）。 书上关于信号处理程序中调用不可重入函数的例子:12345678910111213141516171819202122232425262728#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;pwd.h&gt;static void func(int signo)&#123; struct passwd *rootptr; if( ( rootptr = getpwnam( &quot;root&quot; ) ) == NULL ) &#123; err_sys( &quot;getpwnam error&quot; ); &#125; signal(SIGALRM,func); alarm(1);&#125;int main(int argc, char** argv)&#123; signal(SIGALRM,func); alarm(1); for(;;) &#123; if( ( ptr = getpwnam(&quot;sar&quot;) ) == NULL ) &#123; err_sys( &quot;getpwnam error&quot; ); &#125; &#125; return 0;&#125; signal了一个SIGALRM,而后设置一个定时器，在for函数运行期间的某个时刻，也许就是在getpwnam函数运行期间，相应信号发生中断，进入信号处理函数func，在运行func期间又收到alarm发出的信号，getpwnam可能再次中断，这样就很容易发生不可预料的问题。 ================================================================================= 不可重入函数不可以在它还没有返回就再次被调用。例如printf，malloc，free等都是不可重入函数。因为中断可能在任何时候发生，例如在printf执行过程中，因此不能在中断处理函数里调用printf，否则printf将会被重入。 函数不可重入大多数是因为在函数中引用了全局变量。例如，printf会引用全局变量stdout，malloc，free会引用全局的内存分配表。 个人理解：如果中断发生的时候,当运行到printf的时候，假设发生了中断嵌套，而此时stdout资源被占用，所以第二个中断printf等待第一个中断的stdout资源释放，第一个中断等待第二个中断返回，造成了死锁，不知这样理解对不对。 不可重入函数指的是该函数在被调用还没有结束以前，再次被调用可能会产生错误。可重入函数不存在这样的问题。不可重入函数在实现时候通常使用了全局的资源，在多线程的环境下，如果没有很好的处理数据保护和互斥访问，就会发生错误。常见的不可重入函数有：printf ——–引用全局变量stdoutmalloc ——–全局内存分配表free ——–全局内存分配表在unix里面通常都有加上_r后缀的同名可重入函数版本。如果实在没有，不妨在可预见的发生错误的地方尝试加上保护锁同步机制等等。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode905. Sort Array By Parity]]></title>
    <url>%2F2019%2F04%2F26%2FLeetcode905-Sort-Array-By-Parity%2F</url>
    <content type="text"><![CDATA[Sort Array By ParityEasy Given an array A of non-negative integers, return an array consisting of all the even elements of A, followed by all the odd elements of A. You may return any answer array that satisfies this condition. Example 1:123Input: [3,1,2,4]Output: [2,4,3,1]The outputs [4,2,3,1], [2,4,1,3], and [4,2,1,3] would also be accepted. Note: 1 &lt;= A.length &lt;= 50000 &lt;= A[i] &lt;= 5000 将奇数和偶数分类。。。简单 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; sortArrayByParity(vector&lt;int&gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++)&#123; if(A[i] % 2)&#123; for(int j=i+1;j&lt;A.size();j++)&#123; if(A[j]%2==0)&#123; int temp = A[j]; A[j] = A[i]; A[i] = temp; &#125; &#125; &#125; &#125; return A; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux awk命令详解]]></title>
    <url>%2F2019%2F04%2F24%2FLinux_awk%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 使用方法1awk &apos;&#123;pattern + action&#125;&apos; &#123;filenames&#125; 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 调用awk有三种方式调用awk123456789101112131.命令行方式awk [-F field-separator] &apos;commands&apos; input-file(s)其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。2.shell脚本方式将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。相当于shell脚本首行的：#!/bin/sh可以换成：#!/bin/awk3.将所有的awk命令插入一个单独文件，然后调用：awk -f awk-script-file input-file(s)其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。 本章重点介绍命令行方式。 入门实例假设last -n 5的输出如下123456[root@www ~]# last -n 5 &lt;==仅取出前五行root pts/1 192.168.1.100 Tue Feb 10 11:21 still logged inroot pts/1 192.168.1.100 Tue Feb 10 00:46 - 02:28 (01:41)root pts/1 192.168.1.100 Mon Feb 9 11:41 - 18:30 (06:48)dmtsai pts/1 192.168.1.100 Mon Feb 9 11:41 - 11:41 (00:00)root tty1 Fri Sep 5 14:09 - 14:10 (00:01) 如果只是显示最近登录的5个帐号123456#last -n 5 | awk &apos;&#123;print $1&#125;&apos;rootrootrootdmtsairoot awk工作流程是这样的：读入有’\n’换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是”空白键” 或 “[tab]键”,所以$1表示登录用户，$3表示登录用户ip,以此类推。 如果只是显示/etc/passwd的账户12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; rootdaemonbinsys 这种是awk+action的示例，每行都会执行action{print $1}。 -F指定域分隔符为’:’。 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以tab键分割12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&quot;\t&quot;$7&#125;&apos;root /bin/bashdaemon /bin/shbin /bin/shsys /bin/sh 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加”blue,/bin/nosh”。12345678cat /etc/passwd |awk -F &apos;:&apos; &apos;BEGIN &#123;print &quot;name,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END &#123;print &quot;blue,/bin/nosh&quot;&#125;&apos;name,shellroot,/bin/bashdaemon,/bin/shbin,/bin/shsys,/bin/sh....blue,/bin/nosh awk工作流程是这样的：先执行BEGING，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录······直到所有的记录都读完，最后执行END操作。 搜索/etc/passwd有root关键字的所有行12#awk -F: &apos;/root/&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash 这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。 搜索支持正则，例如找root开头的: awk -F: ‘/^root/‘ /etc/passwd 搜索/etc/passwd有root关键字的所有行，并显示对应的shell12# awk -F: &apos;/root/&#123;print $7&#125;&apos; /etc/passwd /bin/bash 这里指定了action{print $7} awk内置变量awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。1234567891011ARGC 命令行参数个数ARGV 命令行参数排列ENVIRON 支持队列中系统环境变量的使用FILENAME awk浏览的文件名FNR 浏览文件的记录数FS 设置输入域分隔符，等价于命令行 -F选项NF 浏览记录的域的个数NR 已读的记录数OFS 输出域分隔符ORS 输出记录分隔符RS 控制记录分隔符 此外,$0变量是指整条记录。$1表示当前行的第一个域,$2表示当前行的第二个域,……以此类推。 统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容:12345#awk -F &apos;:&apos; &apos;&#123;print &quot;filename:&quot; FILENAME &quot;,linenumber:&quot; NR &quot;,columns:&quot; NF &quot;,linecontent:&quot;$0&#125;&apos; /etc/passwdfilename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bashfilename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/shfilename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/shfilename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh 使用printf替代print,可以让代码更加简洁，易读1awk -F &apos;:&apos; &apos;&#123;printf(&quot;filename:%10s,linenumber:%s,columns:%s,linecontent:%s\n&quot;,FILENAME,NR,NF,$0)&#125;&apos; /etc/passwd print和printfawk中同时提供了print和printf两种打印输出的函数。 其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已。 printf函数，其用法和c语言中printf基本相似,可以格式化字符串,输出复杂时，printf更加好用，代码更易懂。 awk编程变量和赋值除了awk的内置变量，awk还可以自定义变量。 下面统计/etc/passwd的账户人数1234awk &apos;&#123;count++;print $0;&#125; END&#123;print &quot;user count is &quot;, count&#125;&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash......user count is 40 count是自定义变量。之前的action{}里都是只有一个print,其实print只是一个语句，而action{}可以有多个语句，以;号隔开。 这里没有初始化count，虽然默认是0，但是妥当的做法还是初始化为0:12345awk &apos;BEGIN &#123;count=0;print &quot;[start]user count is &quot;, count&#125; &#123;count=count+1;print $0;&#125; END&#123;print &quot;[end]user count is &quot;, count&#125;&apos; /etc/passwd[start]user count is 0root:x:0:0:root:/root:/bin/bash...[end]user count is 40 统计某个文件夹下的文件占用的字节数12ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size&#125;&apos;[end]size is 8657198 如果以M为单位显示:12ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;&#125;&apos; [end]size is 8.25889 M 注意，统计不包括文件夹的子目录。 条件语句awk中的条件语句是从C语言中借鉴来的，见如下声明方式：12345678910111213141516171819if (expression) &#123; statement; statement; ... ...&#125;if (expression) &#123; statement;&#125; else &#123; statement2;&#125;if (expression) &#123; statement1;&#125; else if (expression1) &#123; statement2;&#125; else &#123; statement3;&#125; 统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹):1234567891011ls -l |awk &apos;BEGIN &#123;size=0;print &quot;[start]size is &quot;, size&#125; &#123;if($5!=4096)&#123;size=size+$5;&#125;&#125; END&#123;print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;&#125;&apos; [end]size is 8.22339 M``` ## 循环语句awk中的循环语句同样借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。## 数组因为awk中数组的下标可以是数字和字母，数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。显示/etc/passwd的账户 awk -F ‘:’ ‘BEGIN {count=0;} {name[count] = $1;count++;}; END{for (i = 0; i &lt; NR; i++) print i, name[i]}’ /etc/passwd0 root1 daemon2 bin3 sys4 sync5 games……`这里使用for循环遍历数组]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELF文件的加载和动态链接过程]]></title>
    <url>%2F2019%2F04%2F24%2FELF%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文：https://jzhihui.iteye.com/blog/1447570 本文的目的：大家对于Hello World程序应该非常熟悉，随便使用哪一种语言，即使还不熟悉的语言，写出一个Hello World程序应该毫不费力，但是如果让大家详细的说明这个程序加载和链接的过程，以及后续的符号动态解析过程，可能还会有点困难。本文就是以一个最基本的C语言版本Hello World程序为基础，了解Linux下ELF文件的格式，分析并验证ELF文件和加载和动态链接的具有实现。 123456789/* hello.c */ #include &lt;stdio.h&gt; int main() &#123; printf(“hello world!\n”); return 0; &#125; $ gcc –o hello hello.c 本文的实验平台： Ubuntu 7.04 Linux kernel 2.6.20 gcc 4.1.2 glibc 2.5 gdb 6.6 objdump/readelf 2.17.50 本文的组织： 第一部分大致描述ELF文件的格式； 第二部分分析ELF文件在内核空间的加载过程； 第三部分分析ELF文件在运行过程中符号的动态解析过程；（以上各部分都是以Hello World程序为例说明） 第四部分简要总结； 第五部分阐明需要深入了解的东西。 ELF文件格式概述Executable and Linking Format(ELF)文件是x86 Linux系统下的一种常用目标文件(object file)格式，有三种主要类型: 适于连接的可重定位文件(relocatable file)，可与其它目标文件一起创建可执行文件和共享目标文件。 适于执行的可执行文件(executable file)，用于提供程序的进程映像，加载的内存执行。 共享目标文件(shared object file)，连接器可将它与其它可重定位文件和共享目标文件连接成其它的目标文件，动态连接器又可将它与可执行文件和其它共享目标文件结合起来创建一个进程映像。 ELF文件格式比较复杂，本文只是简要介绍它的结构，希望能给想了解ELF文件结构的读者以帮助。具体详尽的资料请参阅专门的ELF文档。 文件格式为了方便和高效，ELF文件内容有两个平行的视角:一个是程序连接角度，另一个是程序运行角度，如图所示。 ELF header在文件开始处描述了整个文件的组织，Section提供了目标文件的各项信息（如指令、数据、符号表、重定位信息等），Program header table指出怎样创建进程映像，含有每个program header的入口，section header table包含每一个section的入口，给出名字、大小等信息。 数据表示 ELF数据编码顺序与机器相关，数据类型有六种，见下表： ELF文件头 像bmp、exe等文件一样，ELF的文件头包含整个文件的控制结构。它的定义如下：1234567891011121314151617#define EI_NIDENT 16 typedef struct elf32_hdr&#123; unsigned char e_ident[EI_NIDENT]; Elf32_Half e_type; /* file type */ Elf32_Half e_machine; /* architecture */ Elf32_Word e_version; Elf32_Addr e_entry; /* entry point */ Elf32_Off e_phoff; /* PH table offset */ Elf32_Off e_shoff; /* SH table offset */ Elf32_Word e_flags; Elf32_Half e_ehsize; /* ELF header size in bytes */ Elf32_Half e_phentsize; /* PH size */ Elf32_Half e_phnum; /* PH number */ Elf32_Half e_shentsize; /* SH size */ Elf32_Half e_shnum; /* SH number */ Elf32_Half e_shstrndx; /* SH name string table index */ &#125; Elf32_Ehdr; 其中E_ident的16个字节标明是个ELF文件（7F+’E’+’L’+’F’）。e_type表示文件类型，2表示可执行文件。e_machine说明机器类别，3表示386机器，8表示MIPS机器。e_entry给出进程开始的虚地址，即系统将控制转移的位置。e_phoff指出program header table的文件偏移，e_phentsize表示一个program header表中的入口的长度（字节数表示），e_phnum给出program header表中的入口数目。类似的，e_shoff，e_shentsize，e_shnum 分别表示section header表的文件偏移，表中每个入口的的字节数和入口数目。e_flags给出与处理器相关的标志，e_ehsize给出ELF文件头的长度（字节数表示）。e_shstrndx表示section名表的位置，指出在section header表中的索引。 Section Header目标文件的section header table可以定位所有的section，它是一个Elf32_Shdr结构的数组，Section头表的索引是这个数组的下标。有些索引号是保留的，目标文件不能使用这些特殊的索引。Section包含目标文件除了ELF文件头、程序头表、section头表的所有信息，而且目标文件section满足几个条件： 目标文件中的每个section都只有一个section头项描述，可以存在不指示任何section的section头项。每个section在文件中占据一块连续的空间。Section之间不可重叠。目标文件可以有非活动空间，各种headers和sections没有覆盖目标文件的每一个字节，这些非活动空间是没有定义的。Section header结构定义如下：123456789101112typedef struct &#123; Elf32_Word sh_name; /* name of section, index */ Elf32_Word sh_type; Elf32_Word sh_flags; Elf32_Addr sh_addr; /* memory address, if any */ Elf32_Off sh_offset; Elf32_Word sh_size; /* section size in file */ Elf32_Word sh_link; Elf32_Word sh_info; Elf32_Word sh_addralign; Elf32_Word sh_entsize; /* fixed entry size, if have */ &#125; Elf32_Shdr; 其中sh_name指出section的名字，它的值是后面将会讲到的section header string table中的索引，指出一个以null结尾的字符串。sh_type是类别，sh_flags指示该section在进程执行时的特性。sh_addr指出若此section在进程的内存映像中出现，则给出开始的虚地址。sh_offset给出此section在文件中的偏移。其它字段的意义不太常用，在此不细述。 文件的section含有程序和控制信息，系统使用一些特定的section，并有其固定的类型和属性（由sh_type和sh_info指出）。下面介绍几个常用到的section:“.bss”段含有占据程序内存映像的未初始化数据，当程序开始运行时系统对这段数据初始为零，但这个section并不占文件空间。“.data.”和“.data1”段包含占据内存映像的初始化数据。“.rodata”和“.rodata1”段含程序映像中的只读数据。“.shstrtab”段含有每个section的名字，由section入口结构中的sh_name索引。“.strtab”段含有表示符号表(symbol table)名字的字符串。“.symtab”段含有文件的符号表，在后文专门介绍。“.text”段包含程序的可执行指令。 当然一个实际的ELF文件中，会包含很多的section，如.got，.plt等等，我们这里就不一一细述了，需要时再详细的说明。 Program Header目标文件或者共享文件的program header table描述了系统执行一个程序所需要的段或者其它信息。目标文件的一个段（segment）包含一个或者多个section。Program header只对可执行文件和共享目标文件有意义，对于程序的链接没有任何意义。结构定义如下：12345678910typedef struct elf32_phdr&#123; Elf32_Word p_type; Elf32_Off p_offset; Elf32_Addr p_vaddr; /* virtual address */ Elf32_Addr p_paddr; /* ignore */ Elf32_Word p_filesz; /* segment size in file */ Elf32_Word p_memsz; /* size in memory */ Elf32_Word p_flags; Elf32_Word p_align; &#125; Elf32_Phdr; 其中p_type描述段的类型；p_offset给出该段相对于文件开关的偏移量；p_vaddr给出该段所在的虚拟地址；p_paddr给出该段的物理地址，在Linux x86内核中，这项并没有被使用；p_filesz给出该段的大小，在字节为单元，可能为0；p_memsz给出该段在内存中所占的大小，可能为0；p_filesze与p_memsz的值可能会不相等。 Symbol Table目标文件的符号表包含定位或重定位程序符号定义和引用时所需要的信息。符号表入口结构定义如下：12345678typedef struct elf32_sym&#123; Elf32_Word st_name; Elf32_Addr st_value; Elf32_Word st_size; unsigned char st_info; unsigned char st_other; Elf32_Half st_shndx; &#125; Elf32_Sym; 其中st_name包含指向符号表字符串表(strtab)中的索引，从而可以获得符号名。st_value指出符号的值，可能是一个绝对值、地址等。st_size指出符号相关的内存大小，比如一个数据结构包含的字节数等。st_info规定了符号的类型和绑定属性，指出这个符号是一个数据名、函数名、section名还是源文件名；并且指出该符号的绑定属性是local、global还是weak。 Section和Segment的区别和联系可执行文件中，一个program header描述的内容称为一个段（segment）。Segment包含一个或者多个section，我们以Hello World程序为例，看一下section与segment的映射关系： 如上图红色区域所示，就是我们经常提到的文本段和数据段，由图中绿色部分的映射关系可知，文本段并不仅仅包含.text节，数据段也不仅仅包含.data节，而是都包含了多个section。 ELF文件的加载过程加载和动态链接的简要介绍从编译/链接和运行的角度看，应用程序和库程序的连接有两种方式。一种是固定的、静态的连接，就是把需要用到的库函数的目标代码（二进制）代码从程序库中抽取出来，链接进应用软件的目标映像中；另一种是动态链接，是指库函数的代码并不进入应用软件的目标映像，应用软件在编译/链接阶段并不完成跟库函数的链接，而是把函数库的映像也交给用户，到启动应用软件目标映像运行时才把程序库的映像也装入用户空间（并加以定位），再完成应用软件与库函数的连接。 这样，就有了两种不同的ELF格式映像。一种是静态链接的，在装入/启动其运行时无需装入函数库映像、也无需进行动态连接。另一种是动态连接，需要在装入/启动其运行时同时装入函数库映像并进行动态链接。Linux内核既支持静态链接的ELF映像，也支持动态链接的ELF映像，而且装入/启动ELF映像必需由内核完成，而动态连接的实现则既可以在内核中完成，也可在用户空间完成。因此，GNU把对于动态链接ELF映像的支持作了分工：把ELF映像的装入/启动入在Linux内核中；而把动态链接的实现放在用户空间（glibc），并为此提供一个称为“解释器”（ld-linux.so.2）的工具软件，而解释器的装入/启动也由内核负责，这在后面我们分析ELF文件的加载时就可以看到。 这部分主要说明ELF文件在内核空间的加载过程，下一部分对用户空间符号的动态解析过程进行说明。 Linux可执行文件类型的注册机制在说明ELF文件的加载过程以前，我们先回答一个问题，就是：为什么Linux可以运行ELF文件？ 回答：内核对所支持的每种可执行的程序类型都有个struct linux_binfmt的数据结构，定义如下：12345678910111213/* * This structure defines the functions that are used to load the binary formats that * linux accepts. */ struct linux_binfmt &#123; struct linux_binfmt * next; struct module *module; int (*load_binary)(struct linux_binprm *, struct pt_regs * regs); int (*load_shlib)(struct file *) int (*core_dump)(long signr, struct pt_regs * regs, struct file * file); unsigned long min_coredump; /* minimal dump size */ int hasvdso; &#125;; 其中的load_binary函数指针指向的就是一个可执行程序的处理函数。而我们研究的ELF文件格式的定义如下：12345678static struct linux_binfmt elf_format = &#123; .module = THIS_MODULE, .load_binary = load_elf_binary, .load_shlib = load_elf_library, .core_dump = elf_core_dump, .min_coredump = ELF_EXEC_PAGESIZE, .hasvdso = 1 &#125;; 要支持ELF文件的运行，则必须向内核登记这个数据结构，加入到内核支持的可执行程序的队列中。内核提供两个函数来完成这个功能，一个注册，一个注销，即：12int register_binfmt(struct linux_binfmt * fmt) int unregister_binfmt(struct linux_binfmt * fmt) 当需要运行一个程序时，则扫描这个队列，让各个数据结构所提供的处理程序，ELF中即为load_elf_binary，逐一前来认领，如果某个格式的处理程序发现相符后，便执行该格式映像的装入和启动。 内核空间的加载过程内核中实际执行execv()或execve()系统调用的程序是do_execve()，这个函数先打开目标映像文件，并从目标文件的头部（第一个字节开始）读入若干（当前Linux内核中是128）字节（实际上就是填充ELF文件头，下面的分析可以看到），然后调用另一个函数search_binary_handler()，在此函数里面，它会搜索我们上面提到的Linux支持的可执行文件类型队列，让各种可执行程序的处理程序前来认领和处理。如果类型匹配，则调用load_binary函数指针所指向的处理函数来处理目标映像文件。在ELF文件格式中，处理函数是load_elf_binary函数，下面主要就是分析load_elf_binary函数的执行过程（说明：因为内核中实际的加载需要涉及到很多东西，这里只关注跟ELF文件的处理相关的代码）： 1234567891011121314struct &#123; struct elfhdr elf_ex; struct elfhdr interp_elf_ex; struct exec interp_ex; &#125; *loc; loc = kmalloc(sizeof(*loc), GFP_KERNEL); /* Get the exec-header */ loc-&gt;elf_ex = *((struct elfhdr *)bprm-&gt;buf); …… /* First of all, some simple consistency checks */ if (memcmp(loc-&gt;elf_ex.e_ident, ELFMAG, SELFMAG) != 0) goto out; if (loc-&gt;elf_ex.e_type != ET_EXEC &amp;&amp; loc-&gt;elf_ex.e_type != ET_DYN) goto out; 在load_elf_binary之前，内核已经使用映像文件的前128个字节对bprm-&gt;buf进行了填充，563行就是使用这此信息填充映像的文件头（具体数据结构定义见第一部分，ELF文件头节），然后567行就是比较文件头的前四个字节，查看是否是ELF文件类型定义的“\177ELF”。除这4个字符以外，还要看映像的类型是否ET_EXEC和ET_DYN之一；前者表示可执行映像，后者表示共享库。123456789/* Now read in all of the header information */ if (loc-&gt;elf_ex.e_phnum &lt; 1 || loc-&gt;elf_ex.e_phnum &gt; 65536U / sizeof(struct elf_phdr)) goto out; size = loc-&gt;elf_ex.e_phnum * sizeof(struct elf_phdr); …… elf_phdata = kmalloc(size, GFP_KERNEL); …… retval = kernel_read(bprm-&gt;file, loc-&gt;elf_ex.e_phoff, (char *)elf_phdata, size); 这块就是通过kernel_read读入整个program header table。从代码中可以看到，一个可执行程序必须至少有一个段（segment），而所有段的大小之和不能超过64K。1234567891011121314151617181920212223elf_ppnt = elf_phdata; …… for (i = 0; i &lt; loc-&gt;elf_ex.e_phnum; i++) &#123; if (elf_ppnt-&gt;p_type == PT_INTERP) &#123; …… elf_interpreter = kmalloc(elf_ppnt-&gt;p_filesz, GFP_KERNEL); …… retval = kernel_read(bprm-&gt;file, elf_ppnt-&gt;p_offset, elf_interpreter, elf_ppnt-&gt;p_filesz); …… interpreter = open_exec(elf_interpreter); …… retval = kernel_read(interpreter, 0, bprm-&gt;buf, BINPRM_BUF_SIZE); …… /* Get the exec headers */ …… loc-&gt;interp_elf_ex = *((struct elfhdr *)bprm-&gt;buf); break; &#125; elf_ppnt++; &#125; 这个for循环的目的在于寻找和处理目标映像的“解释器”段。“解释器”段的类型为PT_INTERP，找到后就根据其位置的p_offset和大小p_filesz把整个“解释器”段的内容读入缓冲区（640~640）。事个“解释器”段实际上只是一个字符串，即解释器的文件名，如“/lib/ld-linux.so.2”。有了解释器的文件名以后，就通过open_exec()打开这个文件，再通过kernel_read()读入其开关128个字节（695~696），即解释器映像的头部。我们以Hello World程序为例，看一下这段中具体的内容： 其实从readelf程序的输出中，我们就可以看到需要解释器/lib/ld-linux.so.2，为了进一步的验证，我们用hd命令以16进制格式查看下类型为INTERP的段所在位置的内容，在上面的各个域可以看到，它位于偏移量为0x000114的位置，文件内占19个字节： 从上面红色部分可以看到，这个段中实际保存的就是“/lib/ld-linux.so.2”这个字符串。123456789for(i = 0, elf_ppnt = elf_phdata; i &lt; loc-&gt;elf_ex.e_phnum; i++, elf_ppnt++) &#123; …… if (elf_ppnt-&gt;p_type != PT_LOAD) continue; …… error = elf_map(bprm-&gt;file, load_bias + vaddr, elf_ppnt, elf_prot, elf_flags); …… &#125; 这段代码从目标映像的程序头中搜索类型为PT_LOAD的段（Segment）。在二进制映像中，只有类型为PT_LOAD的段才是需要装入的。当然在装入之前，需要确定装入的地址，只要考虑的就是页面对齐，还有该段的p_vaddr域的值（上面省略这部分内容）。确定了装入地址后，就通过elf_map()建立用户空间虚拟地址空间与目标映像文件中某个连续区间之间的映射，其返回值就是实际映射的起始地址。12345678910if (elf_interpreter) &#123; …… elf_entry = load_elf_interp(&amp;loc-&gt;interp_elf_ex, interpreter, &amp;interp_load_addr); …… &#125; else &#123; elf_entry = loc-&gt;elf_ex.e_entry; …… &#125; 这段程序的逻辑非常简单：如果需要装入解释器，就通过load_elf_interp装入其映像（951~953），并把将来进入用户空间的入口地址设置成load_elf_interp()的返回值，即解释器映像的入口地址。而若不装入解释器，那么这个入口地址就是目标映像本身的入口地址。 12345create_elf_tables(bprm, &amp;loc-&gt;elf_ex, (interpreter_type == INTERPRETER_AOUT), load_addr, interp_load_addr); …… start_thread(regs, elf_entry, bprm-&gt;p); 在完成装入，启动用户空间的映像运行之前，还需要为目标映像和解释器准备好一些有关的信息，这些信息包括常规的argc、envc等等，还有一些“辅助向量（Auxiliary Vector）”。这些信息需要复制到用户空间，使它们在CPU进入解释器或目标映像的程序入口时出现在用户空间堆栈上。这里的create_elf_tables()就起着这个作用。 最后，start_thread()这个宏操作会将eip和esp改成新的地址，就使得CPU在返回用户空间时就进入新的程序入口。如果存在解释器映像，那么这就是解释器映像的程序入口，否则就是目标映像的程序入口。那么什么情况下有解释器映像存在，什么情况下没有呢？如果目标映像与各种库的链接是静态链接，因而无需依靠共享库、即动态链接库，那就不需要解释器映像；否则就一定要有解释器映像存在。 以我们的Hello World为例，gcc在编译时，除非显示的使用static标签，否则所有程序的链接都是动态链接的，也就是说需要解释器。由此可见，我们的Hello World程序在被内核加载到内存，内核跳到用户空间后并不是执行Hello World的，而是先把控制权交到用户空间的解释器，由解释器加载运行用户程序所需要的动态库（Hello World需要libc），然后控制权才会转移到用户程序。 ELF文件中符号的动态解析过程上面一节提到，控制权是先交到解释器，由解释器加载动态库，然后控制权才会到用户程序。因为时间原因，动态库的具体加载过程，并没有进行深入分析。大致的过程就是将每一个依赖的动态库都加载到内存，并形成一个链表，后面的符号解析过程主要就是在这个链表中搜索符号的定义。 我们后面主要就是以Hello World为例，分析程序是如何调用printf的： 查看一下gcc编译生成的Hello World程序的汇编代码（main函数部分）：12345608048374 &lt;main&gt;: 8048374: 8d 4c 24 04 lea 0x4(%esp),%ecx …… 8048385: c7 04 24 6c 84 04 08 movl $0x804846c,(%esp) 804838c: e8 2b ff ff ff call 80482bc &lt;puts@plt&gt; 8048391: b8 00 00 00 00 mov $0x0,%eax 从上面的代码可以看出，经过编译后，printf函数的调用已经换成了puts函数（原因读者可以想一下）。其中的call指令就是调用puts函数。但从上面的代码可以看出，它调用的是puts@plt这个标号，它代表什么意思呢？在进一步说明符号的动态解析过程以前，需要先了解两个概念，一个是global offset table，一个是procedure linkage table。 Global Offset Table（GOT）在位置无关代码中，一般不能包含绝对虚拟地址（如共享库）。当在程序中引用某个共享库中的符号时，编译链接阶段并不知道这个符号的具体位置，只有等到动态链接器将所需要的共享库加载时进内存后，也就是在运行阶段，符号的地址才会最终确定。因此，需要有一个数据结构来保存符号的绝对地址，这就是GOT表的作用，GOT表中每项保存程序中引用其它符号的绝对地址。这样，程序就可以通过引用GOT表来获得某个符号的地址。 在x86结构中，GOT表的前三项保留，用于保存特殊的数据结构地址，其它的各项保存符号的绝对地址。对于符号的动态解析过程，我们只需要了解的就是第二项和第三项，即GOT[1]和GOT[2]：GOT[1]保存的是一个地址，指向已经加载的共享库的链表地址（前面提到加载的共享库会形成一个链表）；GOT[2]保存的是一个函数的地址，定义如下：GOT[2] = &amp;_dl_runtime_resolve，这个函数的主要作用就是找到某个符号的地址，并把它写到与此符号相关的GOT项中，然后将控制转移到目标函数，后面我们会详细分析。 Procedure Linkage Table（PLT）过程链接表（PLT）的作用就是将位置无关的函数调用转移到绝对地址。在编译链接时，链接器并不能控制执行从一个可执行文件或者共享文件中转移到另一个中（如前所说，这时候函数的地址还不能确定），因此，链接器将控制转移到PLT中的某一项。而PLT通过引用GOT表中的函数的绝对地址，来把控制转移到实际的函数。 在实际的可执行程序或者共享目标文件中，GOT表在名称为.got.plt的section中，PLT表在名称为.plt的section中。 大致的了解了GOT和PLT的内容后，我们查看一下puts@plt中到底是什么内容：1234567891011121314151617181920Disassembly of section .plt: 0804828c &lt;__gmon_start__@plt-0x10&gt;: 804828c: ff 35 68 95 04 08 pushl 0x8049568 8048292: ff 25 6c 95 04 08 jmp *0x804956c 8048298: 00 00 ...... 0804829c &lt;__gmon_start__@plt&gt;: 804829c: ff 25 70 95 04 08 jmp *0x8049570 80482a2: 68 00 00 00 00 push $0x0 80482a7: e9 e0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 080482ac &lt;__libc_start_main@plt&gt;: 80482ac: ff 25 74 95 04 08 jmp *0x8049574 80482b2: 68 08 00 00 00 push $0x8 80482b7: e9 d0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 080482bc &lt;puts@plt&gt;: 80482bc: ff 25 78 95 04 08 jmp *0x8049578 80482c2: 68 10 00 00 00 push $0x10 80482c7: e9 c0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 可以看到puts@plt包含三条指令，程序中所有对有puts函数的调用都要先来到这里（Hello World里只有一次）。可以看出，除PLT0以外（就是gmon_start@plt-0x10所标记的内容），其它的所有PLT项的形式都是一样的，而且最后的jmp指令都是0x804828c，即PLT0为目标的。所不同的只是第一条jmp指令的目标和push指令中的数据。PLT0则与之不同，但是包括PLT0在内的每个表项都占16个字节，所以整个PLT就像个数组（实际是代码段）。另外，每个PLT表项中的第一条jmp指令是间接寻址的。比如我们的puts函数是以地址0x8049578处的内容为目标地址进行中跳转的。 顺着这个地址，我们进一步查看此处的内容：12(gdb) x/w 0x8049578 0x8049578 &lt;_GLOBAL_OFFSET_TABLE_+20&gt;: 0x080482c2 从上面可以看出，这个地址就是GOT表中的一项。它里面的内容是0x80482c2，即puts@plt中的第二条指令。前面我们不是提到过，GOT中这里本应该是puts函数的地址才对，那为什么会这样呢？原来链接器在把所需要的共享库加载进内存后，并没有把共享库中的函数的地址写到GOT表项中，而是延迟到函数的第一次调用时，才会对函数的地址进行定位。 puts@plt的第二条指令是pushl $0x10，那这个0x10代表什么呢？12345Relocation section &apos;.rel.plt&apos; at offset 0x25c contains 3 entries: Offset Info Type Sym.Value Sym. Name 08049570 00000107 R_386_JUMP_SLOT 00000000 __gmon_start__ 08049574 00000207 R_386_JUMP_SLOT 00000000 __libc_start_main 08049578 00000307 R_386_JUMP_SLOT 00000000 puts 其中的第三项就是puts函数的重定向信息，0x10即代表相对于.rel.plt这个section的偏移位置（每一项占8个字节）。其中的Offset这个域就代表的是puts函数地址在GOT表项中的位置，从上面puts@plt的第一条指令也可以验证这一点。向堆栈中压入这个偏移量的主要作用就是为了找到puts函数的符号名（即上面的Sym.Name域的“puts”这个字符串）以及puts函数地址在GOT表项中所占的位置，以便在函数定位完成后将函数的实际地址写到这个位置。 puts@plt的第三条指令就跳到了PLT0的位置。这条指令只是将0x8049568这个数值压入堆栈，它实际上是GOT表项的第二个元素，即GOT[1]（共享库链表的地址）。 随即PLT0的第二条指令即跳到了GOT[2]中所保存的地址（间接寻址），即_dl_runtime_resolve这个函数的入口。 _dl_runtime_resolve的定义如下：1234567891011_dl_runtime_resolve: pushl %eax # Preserve registers otherwise clobbered. pushl %ecx pushl %edx movl 16(%esp), %edx # Copy args pushed by PLT in register. Note movl 12(%esp), %eax # that `fixup&apos; takes its parameters in regs. call _dl_fixup # Call resolver. popl %edx # Get register content back. popl %ecx xchgl %eax, (%esp) # Get %eax contents end store function address. ret $8 # Jump to function address. 从调用puts函数到现在，总共有两次压栈操作，一次是压入puts函数的重定向信息的偏移量，一次是GOT[1]（共享库链表的地址）。上面的两次movl操作就是将这两个数据分别取到edx和eax，然后调用_dl_fixup（从寄存器取参数），此函数完成的功能就是找到puts函数的实际加载地址，并将它写到GOT中，然后通过eax将此值返回给_dl_runtime_resolve。xchagl这条指令，不仅将eax的值恢复，而且将puts函数的值压到栈顶，这样当执行ret指令后，控制就转移到puts函数内部。ret指令同时也完成了清栈动作，使栈顶为puts函数的返回地址（main函数中call指令的下一条指令），这样，当puts函数返回时，就返回到正确的位置。 当然，如果是第二次调用puts函数，那么就不需要这么复杂的过程，而只要通过GOT表中已经确定的函数地址直接进行跳转即可。下图是前面过程的一个示意图，红色为第一次函数调用的顺序，蓝色为后续函数调用的顺序（第1步都要执行）。 ELF文件加载和链接的简要总结用户通过shell执行程序，shell通过exceve进入系统调用。（User-Mode） sys_execve经过一系列过程，并最终通过ELF文件的处理函数load_elf_binary将用户程序和ELF解释器加载进内存，并将控制权交给解释器。（Kernel-Mode） ELF解释器进行相关库的加载，并最终把控制权交给用户程序。由解释器处理用户程序运行过程中符号的动态解析。（User-Mode）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 glibc malloc：主流用户态内存分配器实现原理]]></title>
    <url>%2F2019%2F04%2F24%2F%E7%90%86%E8%A7%A3glibc_malloc_%E4%B8%BB%E6%B5%81%E7%94%A8%E6%88%B7%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[来源：https://blog.csdn.net/maokelong95/article/details/51989081 前言堆内存（Heap Memory）是一个很有意思的领域。你可能和我一样，也困惑于下述问题很久了： 如何从内核申请堆内存？ 谁管理它？内核、库函数，还是应用本身？ 内存管理效率怎么这么高？！ 堆内存的管理效率可以进一步提高吗？最近，我终于有时间去深入了解这些问题。下面就让我来谈谈我的调研成果。 开源社区公开了很多现成的内存分配器（Memory Allocators，以下简称为分配器）： dlmalloc – 第一个被广泛使用的通用动态内存分配器； ptmalloc2 – glibc 内置分配器的原型； jemalloc – FreeBSD ＆ Firefox 所用分配器； tcmalloc – Google 贡献的分配器； libumem – Solaris 所用分配器；… 每一种分配器都宣称自己快（fast）、可拓展（scalable）、效率高（memory efficient）！但是并非所有的分配器都适用于我们的应用。内存吞吐量大（memory hungry）的应用程序，其性能很大程度上取决于分配器的性能。 历史：ptmalloc2 基于 dlmalloc 开发，其引入了多线程支持，于 2006 年发布。发布之后，ptmalloc2 整合进了 glibc 源码，此后其所有修改都直接提交到了 glibc malloc 里。因此，ptmalloc2 的源码和 glibc malloc 的源码有很多不一致的地方。（译者注：1996 年出现的 dlmalloc 只有一个主分配区，该分配区为所有线程所争用，1997 年发布的 ptmalloc 在 dlmalloc 的基础上引入了非主分配区的概念。） 申请堆的系统调用我在之前的文章中提到过，malloc 内部通过 brk 或 mmap 系统调用向内核申请堆区。 在内存管理领域，我们一般用「堆」指代用于分配动态内存的虚拟地址空间，而用「栈」指代用于分配静态内存的虚拟地址空间。具体到虚拟内存布局（Memory Layout），堆维护在通过 brk 系统调用申请的「Heap」及通过 mmap 系统调用申请的「Memory Mapping Segment」中；而栈维护在通过汇编栈指令动态调整的「Stack」中。在 Glibc 里，「Heap」用于分配较小的内存及主线程使用的内存。 下图为 Linux 内核 v2.6.7 之后，32 位模式下的虚拟内存布局方式。 多线程支持Linux 的早期版本采用 dlmalloc 作为它的默认分配器，但是因为 ptmalloc2 提供了多线程支持，所以 后来 Linux 就转而采用 ptmalloc2 了。多线程支持可以提升分配器的性能，进而间接提升应用的性能。 在 dlmalloc 中，当两个线程同时 malloc 时，只有一个线程能够访问临界区（critical section）——这是因为所有线程共享用以缓存已释放内存的「空闲列表数据结构」（freelist data structure），所以使用 dlmalloc 的多线程应用会在 malloc 上耗费过多时间，从而导致整个应用性能的下降。 在 ptmalloc2 中，当两个线程同时调用 malloc 时，内存均会得以立即分配——每个线程都维护着单独的堆，各个堆被独立的空闲列表数据结构管理，因此各个线程可以并发地从空闲列表数据结构中申请内存。这种为每个线程维护独立堆与空闲列表数据结构的行为就「per thread arena」。 案例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* Per thread arena example. */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;void* threadFunc(void* arg) &#123; printf(&quot;Before malloc in thread 1\n&quot;); getchar(); char* addr = (char*) malloc(1000); printf(&quot;After malloc and before free in thread 1\n&quot;); getchar(); free(addr); printf(&quot;After free in thread 1\n&quot;); getchar();&#125;int main() &#123; pthread_t t1; void* s; int ret; char* addr; printf(&quot;Welcome to per thread arena example::%d\n&quot;,getpid()); printf(&quot;Before malloc in main thread\n&quot;); getchar(); addr = (char*) malloc(1000); printf(&quot;After malloc and before free in main thread\n&quot;); getchar(); free(addr); printf(&quot;After free in main thread\n&quot;); getchar(); ret = pthread_create(&amp;t1, NULL, threadFunc, NULL); if(ret) &#123; printf(&quot;Thread creation error\n&quot;); return -1; &#125; ret = pthread_join(t1, &amp;s); if(ret) &#123; printf(&quot;Thread join error\n&quot;); return -1; &#125; return 0;&#125; 案例输出在主线程 malloc 之前从如下的输出结果中我们可以看到，这里还没有堆段也没有每个线程的栈，因为 thread1 还没有创建！1234567891011sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main thread...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthreadb7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在主线程 malloc 之后从如下的输出结果中我们可以看到，堆段已经产生，并且其地址区间正好在数据段（0x0804b000 - 0x0806c000）上面，这表明堆内存是移动「Program Break」的位置产生的（也即通过 brk 中断）。此外，请注意，尽管用户只申请了 1000 字节的内存，但是实际产生了 132KB 的堆。这个连续的堆区域被称为「arena」。因为这个 arena 是被主线程建立的，因此其被称为「main arena」。接下来的申请会继续分配这个 arena 的 132KB 中剩余的部分。当分配完毕时，它可以通过继续移动 Program Break 的位置扩容。扩容后，「top chunk」的大小也随之调整，以将这块新增的空间圈进去；相应地，arena 也可以在 top chunk 过大时缩小。 注意：top chunk 是一个 arena 位于最顶层的 chunk。有关 top chunk 的更多信息详见后续章节「top chunk」部分。12345678910111213sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main thread...sploitfun@sploitfun-VirtualBox:~/lsploits/hof/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在主线程 free 之后从如下的输出结果中我们可以看到，当分配的内存区域 free 掉时，其并不会立即归还给操作系统，而仅仅是移交给了作为库函数的分配器。这块 free 掉的内存添加在了「main arenas bin」中（在 glibc malloc 中，空闲列表数据结构被称为「bin」）。随后当用户请求内存时，分配器就不再向内核申请新堆了，而是先试着各个「bin」中查找空闲内存。只有当 bin 中不存在空闲内存时，分配器才会继续向内核申请内存。1234567891011121314sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main thread...sploitfun@sploitfun-VirtualBox:~/lsploits/hof/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 malloc 之前从如下的输出结果中我们可以看到，此时 thread1 的堆尚不存在，但其栈已产生。12345678910111213141516sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 malloc 之后从如下的输出结果中我们可以看到，thread1 的堆段(b7500000 - b7521000，132KB)建立在了内存映射段中，这也表明了堆内存是使用 mmap 系统调用产生的，而非同主线程一样使用 sbrk 系统调用。类似地，尽管用户只请求了 1000B，但是映射到程地址空间的堆内存足有 1MB。这 1MB 中，只有 132KB 被设置了读写权限，并成为该线程的堆内存。这段连续内存（132KB）被称为「thread arena」。 注意：当用户请求超过 128KB(比如 malloc(132*1024)) 大小并且此时 arena 中没有足够的空间来满足用户的请求时，内存将通过 mmap 系统调用（不再是 sbrk）分配，而不论请求是发自 main arena 还是 thread arena。12345678910111213141516171819ploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1After malloc and before free in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7500000-b7521000 rw-p 00000000 00:00 0 b7521000-b7600000 ---p 00000000 00:00 0 b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 free 之后从如下的输出结果中我们可以看到，free 不会把内存归还给操作系统，而是移交给分配器，然后添加在了「thread arenas bin」中。1234567891011121314151617181920sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1After malloc and before free in thread 1After free in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7500000-b7521000 rw-p 00000000 00:00 0 b7521000-b7600000 ---p 00000000 00:00 0 b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ArenaArena 的数量在以上的例子中我们可以看到，主线程包含 main arena 而 thread 1 包含它自己的 thread arena。所以线程和 arena 之间是否存在一一映射关系，而不论线程的数量有多大？当然不是，部分极端的应用甚至运行比处理器核数还多的线程，在这种情况下，每个线程都拥有一个 arena 开销过高且意义不大。所以，arena 数量其实是限于系统核数的。1234For 32 bit systems:Number of arena = 2 * number of cores + 1.For 64 bit systems:Number of arena = 8 * number of cores + 1. Multiple Arena举例而言：让我们来看一个运行在单核计算机上的 32 位操作系统上的多线程应用（4 线程，主线程 + 3 个线程）的例子。这里线程数量（4）&gt; 2 * 核心数（1） + 1，所以分配器中至少有一个 Arena（也即标题所称「multiple arenas」）会被所有线程共享。那么是如何共享的呢？ 当主线程第一次调用 malloc 时，已经建立的 main arena 会被没有任何竞争地使用； 当 thread 1 和 thread 2 第一次调用 malloc 时，一块新的 arena 将被创建，且将被没有任何竞争地使用。此时线程和 arena 之间存在一一映射关系； 当 thread3 第一次调用 malloc 时，arena 的数量限制被计算出来，结果显示已超出，因此尝试复用已经存在的 arena（也即 Main arena 或 Arena 1 或 Arena 2）； 复用：一旦遍历到可用 arena，就开始自旋申请该 arena 的锁；如果上锁成功（比如说 main arena 上锁成功），就将该 arena 返回用户；如果没找到可用 arena，thread 3 的 malloc 将被阻塞，直到有可用的 arena 为止。 当thread 3 调用 malloc 时(第二次了)，分配器会尝试使用上一次使用的 arena（也即，main arena），从而尽量提高缓存命中率。当 main arena 可用时就用，否则 thread 3 就一直阻塞，直至 main arena 空闲。因此现在 main arena 实际上是被 main thread 和 thread 3 所共享。 Multiple Heaps在「glibc malloc」中主要有 3 种数据结构： heap_info ——Heap Header—— 一个 thread arena 可以维护多个堆。每个堆都有自己的堆 Header（注：也即头部元数据）。什么时候 Thread Arena 会维护多个堆呢？ 一般情况下，每个 thread arena 都只维护一个堆，但是当这个堆的空间耗尽时，新的堆（而非连续内存区域）就会被 mmap 到这个 aerna 里； malloc_state ——Arena header—— 一个 thread arena 可以维护多个堆，这些堆另外共享同一个 arena header。Arena header 描述的信息包括：bins、top chunk、last remainder chunk 等； malloc_chunk ——Chunk header—— 根据用户请求，每个堆被分为若干 chunk。每个 chunk 都有自己的 chunk header。 注意： Main arena 无需维护多个堆，因此也无需 heap_info。当空间耗尽时，与 thread arena 不同，main arena 可以通过 sbrk 拓展堆段，直至堆段「碰」到内存映射段； 与 thread arena 不同，main arena 的 arena header 不是保存在通过 sbrk 申请的堆段里，而是作为一个全局变量，可以在 libc.so 的数据段中找到。 main arena 和 thread arena 的图示如下（单堆段）： thread arena 的图示如下（多堆段）： Chunk堆段中存在的 chunk 类型如下： Allocated chunk; Free chunk; Top chunk; Last Remainder chunk. Allocated chunk「Allocated chunck」就是已经分配给用户的 chunk，其图示如下： 图中左方三个箭头依次表示： chunk：该 Allocated chunk 的起始地址； mem：该 Allocated chunk 中用户可用区域的起始地址（= chunk + sizeof(malloc_chunk)）； next_chunk：下一个 chunck（无论类型）的起始地址。 图中结构体内部各字段的含义依次为： prev_size：若上一个 chunk 可用，则此字段赋值为上一个 chunk 的大小；否则，此字段被用来存储上一个 chunk 的用户数据； size：此字段赋值本 chunk 的大小，其最后三位包含标志信息： PREV_INUSE § – 置「1」表示上个 chunk 被分配； IS_MMAPPED (M) – 置「1」表示这个 chunk 是通过 mmap 申请的（较大的内存）； NON_MAIN_ARENA (N) – 置「1」表示这个 chunk 属于一个 thread arena。 注意： malloc_chunk 中的其余结构成员，如 fd、 bk，没有使用的必要而拿来存储用户数据；用户请求的大小被转换为内部实际大小，因为需要额外空间存储 malloc_chunk，此外还需要考虑对齐。 Free chunk「Free chunck」就是用户已释放的 chunk，其图示如下： 图中结构体内部各字段的含义依次为： prev_size: 两个相邻 free chunk 会被合并成一个，因此该字段总是保存前一个 allocated chunk 的用户数据； size: 该字段保存本 free chunk 的大小； fd: Forward pointer —— 本字段指向同一 bin 中的下个 free chunk（free chunk 链表的前驱指针）； bk: Backward pointer —— 本字段指向同一 bin 中的上个 free chunk（free chunk 链表的后继指针）。 Bins「bins」 就是空闲列表数据结构。它们用以保存 free chunks。根据其中 chunk 的大小，bins 被分为如下几种类型： Fast bin; Unsorted bin; Small bin; Large bin. 保存这些 bins 的字段为： fastbinsY: 这个数组用以保存 fast bins； bins: 这个数组用于保存 unsorted bin、small bins 以及 large bins，共计可容纳 126 个，其中： Bin 1: unsorted bin; Bin 2 - 63: small bins; Bin 64 - 126: large bins. Fast Bin大小为 16 ~ 80 字节的 chunk 被称为「fast chunk」。在所有的 bins 中，fast bins 路径享有最快的内存分配及释放速度。 数量：10 每个 fast bin 都维护着一条 free chunk 的单链表，采用单链表是因为链表中所有 chunk 的大小相等，增删 chunk 发生在链表顶端即可；—— LIFO chunk 大小：8 字节递增 fast bins 由一系列所维护 chunk 大小以 8 字节递增的 bins 组成。也即，fast bin[0] 维护大小为 16 字节的 chunk、fast bin[1] 维护大小为 24 字节的 chunk。依此类推…… 指定 fast bin 中所有 chunk 大小相同； 在 malloc 初始化过程中，最大的 fast bin 的大小被设置为 64 而非 80 字节。因为默认情况下只有大小 16 ~ 64 的 chunk 被归为 fast chunk 。 无需合并 —— 两个相邻 chunk 不会被合并。虽然这可能会加剧内存碎片化，但也大大加速了内存释放的速度！ malloc(fast chunk) 初始情况下 fast chunck 最大尺寸以及 fast bin 相应数据结构均未初始化，因此即使用户请求内存大小落在 fast chunk 相应区间，服务用户请求的也将是 small bin 路径而非 fast bin 路径； 初始化后，将在计算 fast bin 索引后检索相应 bin； 相应 bin 中被检索的第一个 chunk 将被摘除并返回给用户。 free(fast chunk) 计算 fast bin 索引以索引相应 bin； free 掉的 chunk 将被添加到上述 bin 的顶端。 Unsorted Bin当 small chunk 和 large chunk 被 free 掉时，它们并非被添加到各自的 bin 中，而是被添加在 「unsorted bin」 中。这使得分配器可以重新使用最近 free 掉的 chunk，从而消除了寻找合适 bin 的时间开销，进而加速了内存分配及释放的效率。 数量：1 unsorted bin 包括一个用于保存 free chunk 的双向循环链表（又名 binlist）； chunk 大小：无限制，任何大小的 chunk 均可添加到这里。 Small Bin大小小于 512 字节的 chunk 被称为 「small chunk」，而保存 small chunks 的 bin 被称为 「small bin」。在内存分配回收的速度上，small bin 比 large bin 更快。 数量：62 每个 small bin 都维护着一条 free chunk 的双向循环链表。free 掉的 chunk 添加在链表的顶端，而 malloc 的 chunk 从链表尾端摘除。—— FIFO chunk 大小：8 字节递增 Small bins 由一系列所维护 chunk 大小以 8 字节递增的 bins 组成。举例而言，small bin[0] （Bin 2）维护着大小为 16 字节的 chunks、small bin[1]（Bin 3）维护着大小为 24 字节的 chunks ，依此类推…… 指定 small bin 中所有 chunk 大小均相同，因此无需排序； 合并 —— 相邻的 free chunk 将被合并，这减缓了内存碎片化，但是减慢了 free 的速度； malloc(small chunk) 初始情况下，small bins 都是 NULL，因此尽管用户请求 small chunk ，提供服务的将是 unsorted bin 路径而不是 small bin 路径； 第一次调用 malloc 时，维护在 malloc_state 中的 small bins 和 large bins 将被初始化，它们都会指向自身以表示其为空； 此后当 small bin 非空，相应的 bin 会摘除其中最后一个 chunk 并返回给用户； free(small chunk) free chunk 的时候，检查其前后的 chunk 是否空闲，若是则合并，也即把它们从所属的链表中摘除并合并成一个新的 chunk，新 chunk 会添加在unsorted bin 的前端。 Large Bin大小大于等于 512 字节的 chunk 被称为「large chunk」，而保存 large chunks 的 bin 被称为 「large bin」。在内存分配回收的速度上，large bin 比 small bin 慢。 数量：63 每个 large bin 都维护着一条 free chunk 的双向循环链表。free 掉的 chunk 添加在链表的顶端，而 malloc 的 chunk 从链表尾端摘除。——FIFO 这 63 个 bins 32 个 bins 所维护的 chunk 大小以 64B 递增，也即 large chunk[0](Bin 65) 维护着大小为 512B ~ 568B 的 chunk 、large chunk[1](Bin 66) 维护着大小为 576B ~ 632B 的 chunk，依此类推…… 16 个 bins 所维护的 chunk 大小以 512 字节递增； 8 个 bins 所维护的 chunk 大小以 4096 字节递增； 4 个 bins 所维护的 chunk 大小以 32768 字节递增； 2 个 bins 所维护的 chunk 大小以 262144 字节递增； 1 个 bin 维护所有剩余 chunk 大小； 不像 small bin ，large bin 中所有 chunk 大小不一定相同，各 chunk 大小递减保存。最大的 chunk 保存顶端，而最小的 chunk 保存在尾端； 合并 —— 两个相邻的空闲 chunk 会被合并； malloc(large chunk) 初始情况下，large bin 都会是 NULL，因此尽管用户请求 large chunk ，提供服务的将是 next largetst bin 路径而不是 large bin 路劲 。 第一次调用 malloc 时，维护在 malloc_state 中的 small bin 和 large bin 将被初始化，它们都会指向自身以表示其为空； 此后当 large bin 非空，如果相应 bin 中的最大 chunk 大小大于用户请求大小，分配器就从该 bin 顶端遍历到尾端，以找到一个大小最接近用户请求的 chunk。一旦找到，相应 chunk 就会被切分成两块： User chunk（用户请求大小）—— 返回给用户； Remainder chunk （剩余大小）—— 添加到 unsorted bin。 如果相应 bin 中的最大 chunk 大小小于用户请求大小，分配器就会扫描 binmaps，从而查找最小非空 bin。如果找到了这样的 - bin，就从中选择合适的 chunk 并切割给用户；反之就使用 top chunk 响应用户请求。 free(large chunk) —— 类似于 small chunk 。 Top Chunk一个 arena 中最顶部的 chunk 被称为「top chunk」。它不属于任何 bin 。当所有 bin 中都没有合适空闲内存时，就会使用 top chunk 来响应用户请求。 当 top chunk 的大小比用户请求的大小大的时候，top chunk 会分割为两个部分： User chunk，返回给用户； Remainder chunk，剩余部分，将成为新的 top chunk。当 top chunk 的大小比用户请求的大小小的时候，top chunk 就通过 sbrk（main arena）或 mmap（ thread arena）系统调用扩容。 Last Remainder Chunk「last remainder chunk」即最后一次 small request 中因分割而得到的剩余部分，它有利于改进引用局部性，也即后续对 small chunk 的 malloc 请求可能最终被分配得彼此靠近。 那么 arena 中的若干 chunks，哪个有资格成为 last remainder chunk 呢？ 当用户请求 small chunk 而无法从 small bin 和 unsorted bin 得到服务时，分配器就会通过扫描 binmaps 找到最小非空 bin。正如前文所提及的，如果这样的 bin 找到了，其中最合适的 chunk 就会分割为两部分：返回给用户的 User chunk 、添加到 unsorted bin 中的 Remainder chunk。这一 Remainder chunk 就将成为 last remainder chunk。 那么引用局部性是如何达成的呢？ 当用户的后续请求 small chunk，并且 last remainder chunk 是 unsorted bin 中唯一的 chunk，该 last remainder chunk 就将分割成两部分：返回给用户的 User chunk、添加到 unsorted bin 中的 Remainder chunk（也是 last remainder chunk）。因此后续的请求的 chunk 最终将被分配得彼此靠近。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC编译参数]]></title>
    <url>%2F2019%2F04%2F23%2FGCC%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[GNU CC(简称gcc)是GNU项目中符合ANSI C标准的编译系统，能够编译用C、C++、Object C、Jave等多种语言编写的程序。gcc又可以作为交叉编译工具，它能够在当前CPU平台上为多种不同体系结构的硬件平台开发软件，非常适合在嵌入式领域的开发编译，如常用的arm-linux-gcc交叉编译工具 通常后跟一些选项和文件名来使用 GCC 编译器。gcc 命令的基本用法如下: gcc [options] [filenames] 选项指定编译器怎样进行编译。 gcc 编译流程预处理-Pre-Processinggcc -E test.c -o test.i //.i文件 编译-Compilinggcc -S test.i -o test.s //.s文件 汇编-Assembling //.o文件gcc -c test.s -o test.o 链接-Linking //bin文件gcc test.o -o test gcc工程惯用编译gcc -c test.c //.o文件，汇编 gcc -o test test.c //bin可执行文件 gcc test.c //a.out可执行文件 如果是c++ 直接将gcc改为g++即可。 常用参数1）-E参数 选项指示编译器仅对输入文件进行预处理。当这个选项被使用时, 预处理器的输出被送到标准输出而不是储存在文件里. 2）-S参数 编译选项告诉 GCC 在为 C 代码产生了汇编语言文件后停止编译。 GCC 产生的汇编语言文件的缺省扩展名是 .s 。 3）-c参数 选项告诉 GCC 仅把源代码编译为目标代码。缺省时 GCC 建立的目标代码文件有一个 .o 的扩展名。 4）-o参数 编译选项来为将产生的可执行文件用指定的文件名。 5）-O参数 选项告诉 GCC 对源代码进行基本优化。这些优化在大多数情况下都会使程序执行的更快。 -O2 选项告诉GCC 产生尽可能小和尽可能快的代码。 如-O2，-O3，-On（n 常为0–3）；-O 主要进行跳转和延迟退栈两种优化；-O2 除了完成-O1的优化之外，还进行一些额外的调整工作，如指令调整等。-O3 则包括循环展开和其他一些与处理特性相关的优化工作。选项将使编译的速度比使用 -O 时慢， 但通常产生的代码执行速度会更快。 如： [root@localhost test]# gcc test.c -O3 [root@localhost test]# gcc -O3 test.c [root@localhost test]# gcc -o tt test.c -O2 [root@localhost test]# gcc -O2 -o tt test.c 6）调试选项-g和-pg GCC 支持数种调试和剖析选项，常用到的是 -g 和 -pg 。 -g 选项告诉 GCC 产生能被 GNU 调试器使用的调试信息以便调试你的程序。GCC 提供了一个很多其他 C 编译器里没有的特性, 在 GCC 里你能使-g 和 -O (产生优化代码)联用。 -pg 选项告诉 GCC 在编译好的程序里加入额外的代码。运行程序时, 产生 gprof 用的剖析信息以显示你的程序的耗时情况。 7） -l参数和-L参数 -l参数就是用来指定程序要链接的库，-l参数紧接着就是库名，那么库名跟真正的库文件名有什么关系呢？就拿数学库来说，他的库名是m，他的库文件名是libm.so，很容易看出，把库文件名的头lib和尾.so去掉就是库名了。 如： gcc xxx.c -lm( 动态数学库) -lpthread 好了现在我们知道怎么得到库名了，比如我们自已要用到一个第三方提供的库名字叫libtest.so，那么我们只要把libtest.so拷贝到 /usr/lib里，编译时加上-ltest参数，我们就能用上libtest.so库了（当然要用libtest.so库里的函数，我们还需要与 libtest.so配套的头文件）。放在/lib和/usr/lib和/usr/local/lib里的库直接用-l参数就能链接了，但如果库文件没放在这三个目录里，而是放在其他目录里， 这时我们只用-l参数的话，链接还是会出错，出错信息大概是：“/usr/bin/ld: cannot find-lxxx”，也就是链接 程序ld在那3个目录里找不到libxxx.so，这时另外一个参数-L就派上用场了，比如常用的X11的库，它放在/usr/X11R6/lib目录 下，我们编译时就要用-L/usr/X11R6/lib -lX11参数，-L参数跟着的是库文件所在的目录名。再比如我们把libtest.so放在/aaa/bbb/ccc目录下，那链接参数就是-L/aaa/bbb/ccc -ltest 另外，大部分libxxxx.so只是一个链接，以RH9为例，比如libm.so它链接到/lib/libm.so.x，/lib/libm.so.6 又链接到/lib/libm-2.3.2.so，如果没有这样的链接，还是会出错，因为ld只会找libxxxx.so，所以如果你要用到xxxx库，而只有libxxxx.so.x或者libxxxx-x.x.x.so，做一个链接就可以了ln -s libxxxx-x.x.x.so libxxxx.so手工来写链接参数总是很麻烦的，还好很多库开发包提供了生成链接参数的程序，名字一般叫xxxx-config，一般放在/usr/bin目录下，比如 gtk1.2的链接参数生成程序是gtk-config，执行gtk-config –libs就能得到以下输出”-L/usr/lib -L/usr/X11R6/lib -lgtk -lgdk -rdynamic -lgmodule -lglib -ldl -lXi -lXext -lX11 -lm”，这就是编译一个gtk1.2程序所需的gtk链接参数，xxx-config除了–libs参数外还有一个参数是–cflags用来生成头文件包含目录的，也就是-I参数，在下面我们将会讲到。你可以试试执行gtk-config –libs –cflags，看看输出结果。 现在的问题就是怎样用这些输出结果了，最笨的方法就是复制粘贴或者照抄，聪明的办法是在编译命令行里加入这个xxxx-config --libs --cflags，比如编译一个gtk程序：gcc gtktest.c gtk-config --libs --cflags这样差不多了。注意`不是单引号，而是1键左边那个键。 除了xxx-config以外，现在新的开发包一般都用pkg-config来生成链接参数，使用方法跟xxx-config类似，但xxx-config是针对特定的开发包，但pkg-config包含很多开发包的链接参数的生成，用pkg-config –list-all命令可以列出所支持的所有开发包，pkg-config的用法就是pkg-config pagName –libs –cflags，其中pagName是包名，是pkg-config–list-all里列出名单中的一个，比如gtk1.2的名字就是gtk+， pkg-config gtk+ –libs –cflags的作用跟gtk-config –libs –cflags是一样的。比如： gcc gtktest.c pkg-config gtk+ --libs --cflags。 8） -include和-I参数 -include用来包含头文件，但一般情况下包含头文件都在源码里用＃i nclude xxxxxx实现，-include参数很少用。-I参数是用来指定头文件目录，/usr/include目录一般是不用指定的，gcc知道去那里找，但 是如果头文件不在/usr/icnclude里我们就要用-I参数指定了，比如头文件放在/myinclude目录里，那编译命令行就要加上-I/myinclude参数了，如果不加你会得到一个”xxxx.h: No such file or directory”的错误。-I参数可以用相对路径，比如头文件在当前目录，可以用-I.来指定。上面我们提到的–cflags参数就是用来生成-I参数的。 9）-Wall、-w 和 -v参数 -Wall 打印出gcc提供的警告信息 -w 关闭所有警告信息 -v 列出所有编译步骤 10) -m64 64位 11) -shared 将-fPIC生成的位置无关的代码作为动态库，一般情况下，-fPIC和-shared都是一起使用的。生成SO文件，共享库 -static 此选项将禁止使用动态库，所以，编译出来的东西，一般都很大，也不需要什么动态连接库，就可以运行 几个相关的环境变量 PKG_CONFIG_PATH：用来指定pkg-config用到的pc文件的路径，默认是/usr/lib/pkgconfig，pc文件是文本文件，扩展名是.pc，里面定义开发包的安装路径，Libs参数和Cflags参数等等。 CC：用来指定c编译器。 CXX：用来指定cxx编译器。 LIBS：跟上面的–libs作用差不多。 CFLAGS:跟上面的–cflags作用差不多。 CC，CXX，LIBS，CFLAGS手动编译时一般用不上，在做configure时有时用到，一般情况下不用管。 环境变量设定方法：export ENV_NAME=xxxxxxxxxxxxxxxxx 关于交叉编译交叉编译通俗地讲就是在一种平台上编译出能运行在体系结构不同的另一种平台上，比如在我们地PC平台(X86 CPU)上编译出能运行在arm CPU平台上的程序，编译得到的程序在X86 CPU平台上是不能运行的，必须放到arm CPU 平台上才能运行。当然两个平台用的都是linux。这种方法在异平台移植和嵌入式开发时用得非常普遍。相对与交叉编译，我们平常做的编译就叫本地编译，也 就是在当前平台编译，编译得到的程序也是在本地执行。用来编译这种程序的编译器就叫交叉编译器，相对来说，用来做本地编译的就叫本地编译器，一般用的都是gcc，但这种gcc跟本地的gcc编译器是不一样的，需要在编译gcc时用特定的configure参数才能得到支持交叉编译的gcc。为了不跟本地编译器混淆，交叉编译器的名字一般都有前缀，比如armc-xxxx-linux-gnu-gcc，arm-xxxx-linux-gnu- g++ 等等 交叉编译器的使用方法 使用方法跟本地的gcc差不多，但有一点特殊的是：必须用-L和-I参数指定编译器用arm系统的库和头文件，不能用本地(X86)的库（头文件有时可以用本地的）。 例子： arm-xxxx-linux-gnu-gcc test.c -L/path/to/sparcLib -I/path/to/armInclude man gcc 部分GCC(1) GNU GCC(1) NAME gcc - GNU project C and C++ compiler SYNOPSIS gcc [-c | -S | -E] [-std=standard] [-g] [-pg] [-Olevel] [-Wwarn...] [-pedantic] [-Idir...] [-Ldir...] [-Dmacro[=defn]...] [-Umacro] [-foption...] [-mmachine-option...] [-o outfile] infile... Only the most useful options are listed here; see below for the remainder. g++ accepts mostly the same options as gcc.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELF文件格式]]></title>
    <url>%2F2019%2F04%2F23%2Felf%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[来源：https://www.cnblogs.com/jiqingwu/p/elf_format_research_01.html ELF文件解析（一）：Segment和SectionELF 是Executable and Linking Format的缩写，即可执行和可链接的格式，是Unix/Linux系统ABI (Application Binary Interface)规范的一部分。 Unix/Linux下的可执行二进制文件、目标代码文件、共享库文件和core dump文件都属于ELF文件。下面的图来自于文档 Executable and Linkable Format (ELF)，描述了ELF文件的大致布局。 左边是ELF的链接视图，可以理解为是目标代码文件的内容布局。右边是ELF的执行视图，可以理解为可执行文件的内容布局。注意目标代码文件的内容是由section组成的，而可执行文件的内容是由segment组成的。 要注意区分段(segment)和节(section)的概念，这两个概念在后面会经常提到。我们写汇编程序时，用.text，.bss，.data这些指示，都指的是section，比如.text，告诉汇编器后面的代码放入.text section中。目标代码文件中的section和section header table中的条目是一一对应的。section的信息用于链接器对代码重定位。 而文件载入内存执行时，是以segment组织的，每个segment对应ELF文件中program header table中的一个条目，用来建立可执行文件的进程映像。比如我们通常说的，代码段、数据段是segment，目标代码中的section会被链接器组织到可执行文件的各个segment中。.text section的内容会组装到代码段中，.data, .bss等节的内容会包含在数据段中。 在目标文件中，program header不是必须的，我们用gcc生成的目标文件也不包含program header。一个好用的解析ELF文件的工具是readelf。对我本机上的一个目标代码文件sleep.o执行readelf -S sleep.o，输出如下：1234567891011121314151617181920212223There are 12 section headers, starting at offset 0x270:Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000015 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 000001e0 0000000000000018 0000000000000018 I 9 1 8 [ 3] .data PROGBITS 0000000000000000 00000055 0000000000000000 0000000000000000 WA 0 0 1 [ 4] .bss NOBITS 0000000000000000 00000055 0000000000000000 0000000000000000 WA 0 0 1 ... ... ... ... [11] .shstrtab STRTAB 0000000000000000 00000210 0000000000000059 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) readelf -S是显示文件中的Section信息，sleep.o中共有12个section, 我们省略了其中一些Section的信息。可以看到，除了我们熟悉的.text, .data, .bss，还有其它Section，这等我们以后展开讲Section的时候还会专门讲到。看每个Section的Flags我们也可以得到一些信息，比如.text section的Flags是AX，表示要分配内存，并且是可执行的，这一节是代码无疑了。.data 和 .bss的Flags的Flags都是WA，表示可写，需分配内存，这都是数据段的特征。 使用readelf -l可以显示文件的program header信息。我们对sleep.o执行readelf -l sleep.o，会输出There are no program headers in this file.。program header和文件中的segment一一对应，因为目标代码文件中没有segment，program header也就没有必要了。 可执行文件的内容组织成segment，因此program header table是必须的。section header不是必须的，但没有strip过的二进制文件中都含有此信息。对本地可执行文件sleep执行readelf -l sleep，输出如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344Elf file type is DYN (Shared object file)Entry point 0x1040There are 11 program headers, starting at offset 64Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align PHDR 0x0000000000000040 0x0000000000000040 0x0000000000000040 0x0000000000000268 0x0000000000000268 R 0x8 INTERP 0x00000000000002a8 0x00000000000002a8 0x00000000000002a8 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000560 0x0000000000000560 R 0x1000 LOAD 0x0000000000001000 0x0000000000001000 0x0000000000001000 0x00000000000001d5 0x00000000000001d5 R E 0x1000 LOAD 0x0000000000002000 0x0000000000002000 0x0000000000002000 0x0000000000000110 0x0000000000000110 R 0x1000 LOAD 0x0000000000002de8 0x0000000000003de8 0x0000000000003de8 0x0000000000000248 0x0000000000000250 RW 0x1000 DYNAMIC 0x0000000000002df8 0x0000000000003df8 0x0000000000003df8 0x00000000000001e0 0x00000000000001e0 RW 0x8 NOTE 0x00000000000002c4 0x00000000000002c4 0x00000000000002c4 0x0000000000000044 0x0000000000000044 R 0x4 GNU_EH_FRAME 0x0000000000002004 0x0000000000002004 0x0000000000002004 0x0000000000000034 0x0000000000000034 R 0x4 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x10 GNU_RELRO 0x0000000000002de8 0x0000000000003de8 0x0000000000003de8 0x0000000000000218 0x0000000000000218 R 0x1 Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 03 .init .plt .text .fini 04 .rodata .eh_frame_hdr .eh_frame 05 .init_array .fini_array .dynamic .got .got.plt .data .bss 06 .dynamic 07 .note.ABI-tag .note.gnu.build-id 08 .eh_frame_hdr 09 10 .init_array .fini_array .dynamic .got 如输出所示，文件中共有11个segment。只有类型为LOAD的段是运行时真正需要的。除了段信息，还输出了每个段包含了哪些section。比如第二个LOAD段标志为R（只读）E（可执行）的，它的编号是03，表示它包含哪些section的那一行内容为：03 .init .plt .text .fini。可以发现.text包含在其中，这一段就是代码段。再比如第三个LOAD段，索引是04，标志为R（只读），但没有可执行的属性，它包含的section有.rodata .eh_frame_hdr .eh_frame，其中rodata表示只读的数据，也就是程序中用到的字符串常量等。最后一个LOAD段，索引05，标志RW（可读写），它包含的节是.init_array .fini_array .dynamic .got .got.plt .data .bss，可以看到.data和.bss都包含其中，这段是数据段无疑。 ELF header详解ELF header的定义可以在/usr/include/elf.h中找到。Elf32_Ehdr是32位 ELF header的结构体。Elf64_Ehdr是64位ELF header的结构体。 1234567891011121314151617181920212223242526272829303132333435typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number和其它信息 */ Elf32_Half e_type; /* Object file type */ Elf32_Half e_machine; /* Architecture */ Elf32_Word e_version; /* Object file version */ Elf32_Addr e_entry; /* Entry point virtual address */ Elf32_Off e_phoff; /* Program header table file offset */ Elf32_Off e_shoff; /* Section header table file offset */ Elf32_Word e_flags; /* Processor-specific flags */ Elf32_Half e_ehsize; /* ELF header size in bytes */ Elf32_Half e_phentsize; /* Program header table entry size */ Elf32_Half e_phnum; /* Program header table entry count */ Elf32_Half e_shentsize; /* Section header table entry size */ Elf32_Half e_shnum; /* Section header table entry count */ Elf32_Half e_shstrndx; /* Section header string table index */&#125; Elf32_Ehdr;typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; 64位和32位只是个别字段长度不同，比如 Elf64_Addr 和 Elf64_Off 都是64位无符号整数。而Elf32_Addr 和 Elf32_Off是32位无符号整数。这导致ELF header的所占的字节数不同。32位的ELF header占52个字节，64位的ELF header占64个字节。 ELF header详解 e_ident占16个字节。前四个字节被称作ELF的Magic Number。后面的字节描述了ELF文件内容如何解码等信息。等一下详细讲。 e_type，2字节，描述了ELF文件的类型。以下取值有意义： 12345678ET_NONE, 0, No file typeET_REL, 1, Relocatable file（可重定位文件，通常是文件名以.o结尾，目标文件）ET_EXEC, 2, Executable file （可执行文件）ET_DYN, 3, Shared object file （动态库文件，你用gcc编译出的二进制往往也属于这种类型，惊讶吗？）ET_CORE, 4, Core file （core文件，是core dump生成的吧？）ET_NUM, 5，表示已经定义了5种文件类型ET_LOPROC, 0xff00, Processor-specificET_HIPROC, 0xffff, Processor-specific 从ET_LOPROC到ET_HIPROC的值，包含特定于处理器的语义。 e_machine，2字节。描述了文件面向的架构，可取值如下（因为文档较老，现在有更多取值，参见/usr/include/elf.h中的EM_开头的宏定义）： 123456789EM_NONE, 0, No machineEM_M32, 1, AT&amp;T WE 32100EM_SPARC, 2, SPARCEM_386, 3, Intel 80386EM_68K, 4, Motorola 68000EM_88K, 5, Motorola 88000EM_860, 7, Intel 80860EM_MIPS, 8, MIPS RS3000... ... e_version，2字节，描述了ELF文件的版本号，合法取值如下： 123EV_NONE, 0, Invalid versionEV_CURRENT, 1, Current version，通常都是这个取值。EV_NUM, 2, 表示已经定义了2种版本号 e_entry，（32位4字节，64位8字节），执行入口点，如果文件没有入口点，这个域保持0。 e_phoff, （32位4字节，64位8字节），program header table的offset，如果文件没有PH，这个值是0。 e_shoff, （32位4字节，64位8字节）， section header table 的offset，如果文件没有SH，这个值是0。 e_flags, 4字节，特定于处理器的标志，32位和64位Intel架构都没有定义标志，因此eflags的值是0。 e_ehsize, 2字节，ELF header的大小，32位ELF是52字节，64位是64字节。 e_phentsize，2字节。program header table中每个入口的大小。 e_phnum, 2字节。如果文件没有program header table, e_phnum的值为0。e_phentsize乘以e_phnum就得到了整个program header table的大小。 e_shentsize, 2字节，section header table中entry的大小，即每个section header占多少字节。 e_shnum, 2字节，section header table中header的数目。如果文件没有section header table, e_shnum的值为0。e_shentsize乘以e_shnum，就得到了整个section header table的大小。 e_shstrndx, 2字节。section header string table index. 包含了section header table中section name string table。如果没有section name string table, e_shstrndx的值是SHN_UNDEF. e_ident回过头来，我们仔细看看文件前16个字节，也是e_ident。 如图，前4个字节是ELF的Magic Number，固定为7f 45 4c 46。第5个字节指明ELF文件是32位还是64位的。第6个字节指明了数据的编码方式，即我们通常说的little endian或是big endian。little endian我喜欢称作小头在前，低位字节在前，或者直接说低位字节在低位地址，比如0x7f454c46，存储顺序就是46 4c 45 7f。big endian就是大头在前，高位字节在前，直接说就是高位字节在低位地址，比如0x7f454c46，在文件中的存储顺序是7f 45 4c 46。第7个字节指明了ELF header的版本号，目前值都是1。第8-16个字节，都填充为0。 readelf读取ELF header我们使用readelf -h 可以读取文件的ELF header信息。比如我本地有执行文件hello，我执行reaelf -h hello，结果如下：1234567891011121314151617181920ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&apos;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: DYN (Shared object file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x1050 Start of program headers: 64 (bytes into file) Start of section headers: 14768 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 11 Size of section headers: 64 (bytes) Number of section headers: 29 Section header string table index: 28 这是我用gcc生成的执行文件，但注意它的Type是DYN (Shared object file)，这大概是因为，这个文件不能直接执行，是依赖于解释器和c库才能运行。真正的可执行文件是解释器，而hello相对于解释器来说也是个共享库文件。这是我的推断，需要后面深入学习后验证。 ELF格式探析之三：sections我们在讲ELF Header的时候，讲到了section header table。它是一个section header的集合，每个section header是一个描述section的结构体。在同一个ELF文件中，每个section header大小是相同的。（其实看了源码就知道，32位ELF文件中的section header都是一样的大小，64位ELF文件中的section header也是一样的大小） 每个section都有一个section header描述它，但是一个section header可能在文件中没有对应的section，因为有的section是不占用文件空间的。每个section在文件中是连续的字节序列。section之间不会有重叠。 一个目标文件中可能有未覆盖到的空间，比如各种header和section都没有覆盖到。这部分字节的内容是未指定的，也是没有意义的。 section header定义section header结构体的定义可以在 /usr/include/elf.h中找到。1234567891011121314151617181920212223242526272829/* Section header. */typedef struct&#123; Elf32_Word sh_name; /* Section name (string tbl index) */ Elf32_Word sh_type; /* Section type */ Elf32_Word sh_flags; /* Section flags */ Elf32_Addr sh_addr; /* Section virtual addr at execution */ Elf32_Off sh_offset; /* Section file offset */ Elf32_Word sh_size; /* Section size in bytes */ Elf32_Word sh_link; /* Link to another section */ Elf32_Word sh_info; /* Additional section information */ Elf32_Word sh_addralign; /* Section alignment */ Elf32_Word sh_entsize; /* Entry size if section holds table */&#125; Elf32_Shdr;typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; 下面我们依次讲解结构体各个字段： sh_name，4字节，是一个索引值，在shstrtable（section header string table，包含section name的字符串表，也是一个section）中的索引。第二讲介绍ELF文件头时，里面专门有一个字段e_shstrndx，其含义就是shstrtable对应的section header在section header table中的索引。 sh_type，4字节，描述了section的类型，常见的取值如下： 1234567891011121314SHT_NULL 0，表明section header无效，没有关联的section。SHT_PROGBITS 1，section包含了程序需要的数据，格式和含义由程序解释。SHT_SYMTAB 2， 包含了一个符号表。当前，一个ELF文件中只有一个符号表。SHT_SYMTAB提供了用于(link editor)链接编辑的符号，当然这些符号也可能用于动态链接。这是一个完全的符号表，它包含许多符号。SHT_STRTAB 3，包含一个字符串表。一个对象文件包含多个字符串表，比如.strtab（包含符号的名字）和.shstrtab（包含section的名称）。SHT_RELA 4，重定位节，包含relocation入口，参见Elf32_Rela。一个文件可能有多个Relocation Section。比如.rela.text，.rela.dyn。SHT_HASH 5，这样的section包含一个符号hash表，参与动态连接的目标代码文件必须有一个hash表。目前一个ELF文件中只包含一个hash表。讲链接的时候再细讲。SHT_DYNAMIC 6，包含动态链接的信息。目前一个ELF文件只有一个DYNAMIC section。SHT_NOTE 7，note section, 以某种方式标记文件的信息，以后细讲。SHT_NOBITS 8，这种section不含字节，也不占用文件空间，section header中的sh_offset字段只是概念上的偏移。SHT_REL 9， 重定位节，包含重定位条目。和SHT_RELA基本相同，两者的区别在后面讲重定位的时候再细讲。SHT_SHLIB 10，保留，语义未指定，包含这种类型的section的elf文件不符合ABI。SHT_DYNSYM 11， 用于动态连接的符号表，推测是symbol table的子集。SHT_LOPROC 0x70000000 到 SHT_HIPROC 0x7fffffff，为特定于处理器的语义保留。SHT_LOUSER 0x80000000 and SHT_HIUSER 0xffffffff，指定了为应用程序保留的索引的下界和上界，这个范围内的索引可以被应用程序使用。 sh_flags, 32位占4字节， 64位占8字节。包含位标志，用 readelf -S 可以看到很多标志。常用的有： 123456SHF_WRITE 0x1，进程执行的时候，section内的数据可写。SHF_ALLOC 0x2，进程执行的时候，section需要占据内存。SHF_EXECINSTR 0x4，节内包含可以执行的机器指令。SHF_STRINGS 0x20，包含0结尾的字符串。SHF_MASKOS 0x0ff00000，这个mask为OS特定的语义保留8位。SHF_MASKPROC 0xf0000000，这个mask包含的所有位保留（也就是最高字节的高4位），为处理器相关的语义使用。 sh_addr, 对32位来说是4字节，64位是8字节。如果section会出现在进程的内存映像中，给出了section第一字节的虚拟地址。 sh_offset，对于32位来说是4字节，64位是8字节。section相对于文件头的字节偏移。对于不占文件空间的section（比如SHT_NOBITS），它的sh_offset只是给出了section逻辑上的位置。 sh_size，section占多少字节，对于SHT_NOBITS类型的section，sh_size没用，其值可能不为0，但它也不占文件空间。 sh_link，含有一个section header的index，该值的解释依赖于section type。 12345如果是SHT_DYNAMIC，sh_link是string table的section header index，也就是说指向字符串表。如果是SHT_HASH，sh_link指向symbol table的section header index，hash table应用于symbol table。如果是重定位节SHT_REL或SHT_RELA，sh_link指向相应符号表的section header index。如果是SHT_SYMTAB或SHT_DYNSYM，sh_link指向相关联的符号表，暂时不解。对于其它的section type，sh_link的值是SHN_UNDEF sh_info，存放额外的信息，值的解释依赖于section type。 123如果是SHT_REL和SHT_RELA类型的重定位节，sh_info是应用relocation的节的节头索引。如果是SHT_SYMTAB和SHT_DYNSYM，sh_info是第一个non-local符号在符号表中的索引。推测local symbol在前面，non-local symbols紧跟在后面，所以文档中也说，sh_info是最后一个本地符号的在符号表中的索引加1。对于其它类型的section，sh_info是0。 sh_addralign，地址对齐，如果一个section有一个doubleword字段，系统在载入section时的内存地址必须是doubleword对齐。也就是说sh_addr必须是sh_addralign的整数倍。只有2的正整数幂是有效的。0和1说明没有对齐约束。 sh_entsize，有些section包含固定大小的记录，比如符号表。这个值给出了每个记录大小。对于不包含固定大小记录的section，这个值是0。 系统预定义的section name 系统预定义了一些节名（以.开头），这些节有其特定的类型和含义。 .bss：包含程序运行时未初始化的数据（全局变量和静态变量）。当程序运行时，这些数据初始化为0。 其类型为SHT_NOBITS，表示不占文件空间。SHF_ALLOC + SHF_WRITE，运行时要占用内存的。 .comment包含版本控制信息（是否包含程序的注释信息？不包含，注释在预处理时已经被删除了）。类型为SHT_PROGBITS。 .data和.data1，包含初始化的全局变量和静态变量。 类型为SHT_PROGBITS，标志为SHF_ALLOC + SHF_WRITE（占用内存，可写）。 .debug，包含了符号调试用的信息，我们要想用gdb等工具调试程序，需要该类型信息，类型为SHT_PROGBITS。 .dynamic，类型SHT_DYNAMIC，包含了动态链接的信息。标志SHF_ALLOC，是否包含SHF_WRITE和处理器有关。 .dynstr，SHT_STRTAB，包含了动态链接用的字符串，通常是和符号表中的符号关联的字符串。标志 SHF_ALLOC .dynsym，类型SHT_DYNSYM，包含动态链接符号表， 标志SHF_ALLOC。 .fini，类型SHT_PROGBITS，程序正常结束时，要执行该section中的指令。标志SHF_ALLOC + SHF_EXECINSTR（占用内存可执行）。现在ELF还包含.fini_array section。 .got，类型SHT_PROGBITS，全局偏移表(global offset table)，以后会重点讲。 .hash，类型SHT_HASH，包含符号hash表，以后细讲。标志SHF_ALLOC。 .init，SHT_PROGBITS，程序运行时，先执行该节中的代码。SHF_ALLOC + SHF_EXECINSTR，和.fini对应。现在ELF还包含.init_array section。 .interp，SHT_PROGBITS，该节内容是一个字符串，指定了程序解释器的路径名。如果文件中有一个可加载的segment包含该节，属性就包含SHF_ALLOC，否则不包含。 .line，SHT_PROGBITS，包含符号调试的行号信息，描述了源程序和机器代码的对应关系。gdb等调试器需要此信息。 .note Note Section, 类型SHT_NOTE，以后单独讲。 .plt 过程链接表（Procedure Linkage Table），类型SHT_PROGBITS,以后重点讲。 .relNAME，类型SHT_REL, 包含重定位信息。如果文件有一个可加载的segment包含该section，section属性将包含SHF_ALLOC，否则不包含。NAME，是应用重定位的节的名字，比如.text的重定位信息存储在.rel.text中。 .relaname类型SHT_RELA，和.rel相同。SHT_RELA和SHT_REL的区别，会在讲重定位的时候说明。 .rodata和.rodata1。类型SHT_PROGBITS, 包含只读数据，组成不可写的段。标志SHF_ALLOC。 .shstrtab，类型SHT_STRTAB，包含section的名字。有读者可能会问：section header中不是已经包含名字了吗，为什么把名字集中存放在这里？ sh_name 包含的是.shstrtab 中的索引，真正的字符串存储在.shstrtab中。那么section names为什么要集中存储？我想是这样：如果有相同的字符串，就可以共用一块存储空间。如果字符串存在包含关系，也可以共用一块存储空间。 .strtab SHT_STRTAB，包含字符串，通常是符号表中符号对应的变量名字。如果文件有一个可加载的segment包含该section，属性将包含SHF_ALLOC。字符串以\0结束， section以\0开始，也以\0结束。一个.strtab可以是空的，它的sh_size将是0。针对空字符串表的非0索引是允许的。 symtab，类型SHT_SYMTAB，Symbol Table，符号表。包含了定位、重定位符号定义和引用时需要的信息。符号表是一个数组，Index 0 第一个入口，它的含义是undefined symbol index， STN_UNDEF。如果文件有一个可加载的segment包含该section，属性将包含SHF_ALLOC。 练习：读取section names从这一讲开始，都会有练习，方便我们把前面的理论知识综合运用。 下面这个练习的目标是：从一个ELF文件中读取存储section name的字符串表。前面讲过，该字符串表也是一个section，section header table中有其对应的section header，并且ELF文件头中给出了节名字符串表对应的section header的索引，e_shstrndx。 我们的思路是这样： 从ELF header中读取section header table的起始位置，每个section header的大小，以及节名字符串表对应section header的索引。 计算section_header_table_offset + section_header_size * e_shstrndx就是节名字符串表对应section header的偏移。 读取section header，可以从中得到节名字符串表在文件中的偏移和大小。 把节名字符串表读取到内存中，打印其内容。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* 64位ELF文件读取section name string table */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;int main(int argc, char *argv[])&#123; /* 打开本地的ELF可执行文件hello */ FILE *fp = fopen(&quot;./hello&quot;, &quot;rb&quot;); if(!fp) &#123; perror(&quot;open ELF file&quot;); exit(1); &#125; /* 1. 通过读取ELF header得到section header table的偏移 */ /* for 64 bit ELF, e_ident(16) + e_type(2) + e_machine(2) + e_version(4) + e_entry(8) + e_phoff(8) = 40 */ fseek(fp, 40, SEEK_SET); uint64_t sh_off; int r = fread(&amp;sh_off, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section header offset&quot;); exit(2); &#125; /* 得到的这个偏移值，可以用`reaelf -h hello`来验证是否正确 */ printf(&quot;section header offset in file: %ld (0x%lx)\n&quot;, sh_off, sh_off); /* 2. 读取每个section header的大小e_shentsize, section header的数量e_shnum, 以及对应section name字符串表的section header的索引e_shstrndx 得到这些值后，都可以用`readelf -h hello`来验证是否正确 */ /* e_flags(4) + e_ehsize(2) + e_phentsize(2) + e_phnum(2) = 10 */ fseek(fp, 10, SEEK_CUR); uint16_t sh_ent_size; /* 每个section header的大小 */ r = fread(&amp;sh_ent_size, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header entry size&quot;); exit(2); &#125; printf(&quot;section header entry size: %d\n&quot;, sh_ent_size); uint16_t sh_num; /* section header的数量 */ r = fread(&amp;sh_num, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header number&quot;); exit(2); &#125; printf(&quot;section header number: %d\n&quot;, sh_num); uint16_t sh_strtab_index; /* 节名字符串表对应的节头的索引 */ r = fread(&amp;sh_strtab_index, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header string table index&quot;); exit(2); &#125; printf(&quot;section header string table index: %d\n&quot;, sh_strtab_index); /* 3. read section name string table offset, size */ /* 先找到节头字符串表对应的section header的偏移位置 */ fseek(fp, sh_off + sh_strtab_index * sh_ent_size, SEEK_SET); /* 再从section header中找到节头字符串表的偏移 */ /* sh_name(4) + sh_type(4) + sh_flags(8) + sh_addr(8) = 24 */ fseek(fp, 24, SEEK_CUR); uint64_t str_table_off; r = fread(&amp;str_table_off, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section name string table offset&quot;); exit(2); &#125; printf(&quot;section name string table offset: %ld\n&quot;, str_table_off); /* 从section header中找到节头字符串表的大小 */ uint64_t str_table_size; r = fread(&amp;str_table_size, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section name string table size&quot;); exit(2); &#125; printf(&quot;section name string table size: %ld\n&quot;, str_table_size); /* 动态分配内存，把节头字符串表读到内存中 */ char *buf = (char *)malloc(str_table_size); if(!buf) &#123; perror(&quot;allocate memory for section name string table&quot;); exit(3); &#125; fseek(fp, str_table_off, SEEK_SET); r = fread(buf, 1, str_table_size, fp); if(r != str_table_size) &#123; perror(&quot;read section name string table&quot;); free(buf); exit(2); &#125; uint16_t i; for(i = 0; i &lt; str_table_size; ++i) &#123; /* 如果节头字符串表中的字节是0，就打印`\0` */ if (buf[i] == 0) printf(&quot;\\0&quot;); else printf(&quot;%c&quot;, buf[i]); &#125; printf(&quot;\n&quot;); free(buf); fclose(fp); return 0;&#125; 把以上代码存为chap3_read_section_names.c，执行gcc -Wall -o secnames chap3_read_section_names.c进行编译，输出的执行文件名叫secnames。执行secnames，输出如下：12345678./secnamessection header offset in file: 14768 (0x39b0)section header entry size: 64section header number: 29section header string table index: 28section name string table offset: 14502section name string table size: 259\0.symtab\0.strtab\0.shstrtab\0.interp\0.note.ABI-tag\0.note.gnu.build-id\0.gnu.hash\0.dynsym\0.dynstr\0.gnu.version\0.gnu.version_r\0.rela.dyn\0.rela.plt\0.init\0.text\0.fini\0.rodata\0.eh_frame_hdr\0.eh_frame\0.init_array\0.fini_array\0.dynamic\0.got\0.got.plt\0.data\0.bss\0.comment\0 可以发现，节头字符串表以\0开始，以\0结束。如果一个section的name字段指向0，则他指向的字节值是0，则它没有名称，或名称是空。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的Queue]]></title>
    <url>%2F2019%2F04%2F21%2Fcpp%E4%B8%AD%E7%9A%84queue%2F</url>
    <content type="text"><![CDATA[原文：http://www.cppblog.com/wanghaiguang/archive/2012/06/05/177644.html C++ Queues(队列) C++队列是一种容器适配器，它给予程序员一种先进先出(FIFO)的数据结构。1.back() 返回一个引用，指向最后一个元素2.empty() 如果队列空则返回真3.front() 返回第一个元素4.pop() 删除第一个元素5.push() 在末尾加入一个元素6.size() 返回队列中元素的个数 队列可以用线性表(list)或双向队列(deque)来实现(注意vector container 不能用来实现queue，因为vector 没有成员函数pop_front!)：queue&lt;list&lt;int&gt;&gt; q1queue&lt;deque&lt;int&gt;&gt; q2其成员函数有“判空(empty)” 、“尺寸(Size)” 、“首元(front)” 、“尾元(backt)” 、“加入队列(push)” 、“弹出队列(pop)”等操作。 例：12345678int main()&#123; queue&lt;int&gt; q; q.push(4); q.push(5); printf(&quot;%d\n&quot;,q.front()); q.pop();&#125; C++ Priority Queues(优先队列) C++优先队列类似队列，但是在这个数据结构中的元素按照一定的断言排列有序。1.empty() 如果优先队列为空，则返回真2.pop() 删除第一个元素3.push() 加入一个元素4.size() 返回优先队列中拥有的元素的个数5.top() 返回优先队列中有最高优先级的元素 优先级队列可以用向量(vector)或双向队列(deque)来实现(注意list container 不能用来实现queue，因为list 的迭代器不是任意存取iterator，而pop 中用到堆排序时是要求randomaccess iterator 的!)：priority_queue&lt;vector&lt;int&gt;, less&lt;int&gt;&gt; pq1; 使用递增less函数对象排序priority_queue&lt;deque&lt;int&gt;, greater&lt;int&gt;&gt; pq2; 使用递减greater函数对象排序其成员函数有“判空(empty)” 、“尺寸(Size)” 、“栈顶元素(top)” 、“压栈(push)” 、“弹栈(pop)”等。 priority_queue模版类有三个模版参数，元素类型，容器类型，比较算子。其中后两个都可以省略，默认容器为vector，默认算子为less，即小的往前排，大的往后排（出队时序列尾的元素出队）。 初学者在使用priority_queue时，最困难的可能就是如何定义比较算子了。如果是基本数据类型，或已定义了比较运算符的类，可以直接用STL的less算子和greater算子——默认为使用less算子，即小的往前排，大的先出队。如果要定义自己的比较算子，方法有多种，这里介绍其中的一种：重载比较运算符。优先队列试图将两个元素x和y代入比较运算符(对less算子，调用x&lt;y，对greater算子，调用x&gt;y)，若结果为真，则x排在y前面，y将先于x出队，反之，则将y排在x前面，x将先出队。 例：123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;queue&gt; using namespace std; class T &#123;public: int x, y, z; T(int a, int b, int c):x(a), y(b), z(c) &#123; &#125;&#125;;bool operator &lt; (const T &amp;t1, const T &amp;t2) &#123; return t1.z &lt; t2.z; // 按照z的顺序来决定t1和t2的顺序&#125; int main()&#123; priority_queue&lt;T&gt; q; q.push(T(4,4,3)); q.push(T(2,2,5)); q.push(T(1,5,4)); q.push(T(3,3,6)); while (!q.empty()) &#123; T t = q.top(); q.pop(); cout &lt;&lt; t.x &lt;&lt; &quot; &quot; &lt;&lt; t.y &lt;&lt; &quot; &quot; &lt;&lt; t.z &lt;&lt; endl; &#125; return 1; &#125; 输出结果为(注意是按照z的顺序从大到小出队的)： 3 3 6 2 2 5 1 5 4 4 4 3 再看一个按照z的顺序从小到大出队的例子：123456789101112131415161718192021222324252627282930#include &lt;iostream&gt; #include &lt;queue&gt; using namespace std; class T &#123; public: int x, y, z; T(int a, int b, int c):x(a), y(b), z(c) &#123; &#125; &#125;; bool operator &gt; (const T &amp;t1, const T &amp;t2) &#123; return t1.z &gt; t2.z; &#125; main() &#123; priority_queue&lt;T, vector&lt;T&gt;, greater&lt;T&gt; &gt; q; q.push(T(4,4,3)); q.push(T(2,2,5)); q.push(T(1,5,4)); q.push(T(3,3,6)); while (!q.empty()) &#123; T t = q.top(); q.pop(); cout &lt;&lt; t.x &lt;&lt; &quot; &quot; &lt;&lt; t.y &lt;&lt; &quot; &quot; &lt;&lt; t.z &lt;&lt; endl; &#125; return 1; &#125; 输出结果为： 4 4 3 1 5 4 2 2 5 3 3 6]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常用技巧]]></title>
    <url>%2F2019%2F04%2F21%2Fgit%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[Git的奇技淫巧:see_no_evil:Git是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 “页面内查找” 的方式进行快速查询：Ctrl/Command+f。 开卷必读如果之前未使用过 Git，可以学习 Git 小白教程入门 一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 目录 展示帮助信息 回到远程仓库的状态 重设第一个commit 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit 修改上一个 commit 的描述 查看 commit 历史 显示本地更新过 HEAD 的 git 命令记录 修改作者名 修改远程仓库的 url 增加远程仓库 列出所有远程仓库 查看两个星期内的改动 把 A 分支的某一个 commit，放到 B 分支上 给 git 命令起别名 存储当前的修改，但不用提交 commit 保存当前状态，包括 untracked 的文件 展示所有 stashes 回到某个 stash 的状态 回到最后一个 stash 的状态，并删除这个 stash 删除所有的 stash 从 stash 中拿出某个文件的修改 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 强制删除 untracked 的目录 展示简化的 commit 历史 查看某段代码是谁写的 把某一个分支到导出成一个文件 从包中导入分支 执行 rebase 之前自动 stash 从远程仓库根据 ID，拉下某一状态，到本地分支 详细展示一行中的修改 清除 .gitignore 文件中记录的文件 展示所有 alias 和 configs 展示忽略的文件 commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit 在 commit log 中显示 GPG 签名 删除全局设置 新建并切换到新分支上，同时这个分支没有任何 commit 展示任意分支某一文件的内容 clone 下来指定的单一分支 忽略某个文件的改动 忽略文件的权限变化 以最后提交的顺序列出所有 Git 分支 在 commit log 中查找相关内容 把暂存区的指定 file 放到工作区中 强制推送 一图详解 优雅的提交Commit信息 联系我 展示帮助信息1git help -g The command output as below: 12345678910111213141516171819The common Git guides are: attributes Defining attributes per path cli Git command-line interface and conventions core-tutorial A Git core tutorial for developers cvs-migration Git for CVS users diffcore Tweaking diff output everyday A useful minimum set of commands for Everyday Git glossary A Git Glossary hooks Hooks used by Git ignore Specifies intentionally untracked files to ignore modules Defining submodule properties namespaces Git namespaces repository-layout Git Repository Layout revisions Specifying revisions and ranges for Git tutorial A tutorial introduction to Git tutorial-2 A tutorial introduction to Git: part two workflows An overview of recommended workflows with Git&apos;git help -a&apos; and &apos;git help -g&apos; list available subcommands and some concept guides. See &apos;git help &lt;command&gt;&apos; or &apos;git help &lt;concept&gt;&apos; to read about a specific subcommand or concept. 回到远程仓库的状态抛弃本地所有的修改，回到远程仓库的状态。1git fetch --all &amp;&amp; git reset --hard origin/master 重设第一个 commit也就是把所有的改动都重新放回工作区，并清空所有的 commit，这样就可以重新提交第一个 commit 了 1git update-ref -d HEAD 展示工作区和暂存区的不同输出工作区和暂存区的 different (不同)。 1git diff 还可以展示本地仓库中任意两个 commit 之间的文件变动：1git diff &lt;commit-id&gt; &lt;commit-id&gt; 展示暂存区和最近版本的不同输出暂存区和本地最近的版本 (commit) 的 different (不同)。1git diff --cached 展示暂存区、工作区和最近版本的不同输出工作区、暂存区 和本地最近的版本 (commit) 的 different (不同)。 1git diff HEAD 快速切换到上一个分支1git checkout - 删除已经合并到 master 的分支1git branch --merged master | grep -v '^\*\| master' | xargs -n 1 git branch -d 展示本地分支关联远程仓库的情况1git branch -vv 关联远程分支关联之后，git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接：git push，不需要指定远程仓库了。1git branch -u origin/mybranch 或者在 push 时加上 -u 参数1git push origin/mybranch -u 列出所有远程分支-r 参数相当于：remote1git branch -r 列出本地和远程分支-a 参数相当于：all1git branch -a 创建并切换到本地分支1git checkout -b &lt;branch-name&gt; 从远程分支中创建并切换到本地分支1git checkout -b &lt;branch-name&gt; origin/&lt;branch-name&gt; 删除本地分支1git branch -d &lt;local-branchname&gt; 删除远程分支1git push origin --delete &lt;remote-branchname&gt; 或者 1git push origin :&lt;remote-branchname&gt; 重命名本地分支1git branch -m &lt;new-branch-name&gt; 查看标签1git tag 展示当前分支的最近的 tag 1git describe --tags --abbrev=0 查看标签详细信息1git tag -ln 本地创建标签1git tag &lt;version-number&gt; 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag：1$ git tag -a &lt;version-number&gt; -m "v1.0 发布(描述)" &lt;commit-id&gt; 推送标签到远程仓库首先要保证本地创建好了标签才可以推送标签到远程仓库： 1git push origin &lt;local-version-number&gt; 一次性推送所有标签，同步到远程仓库： 1git push origin --tags 删除本地标签1git tag -d &lt;tag-name&gt; 删除远程标签删除远程标签需要先删除本地标签，再执行下面的命令： 1git push origin :refs/tags/&lt;tag-name&gt; 切回到某个标签一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回到某一标签下的状态：1git checkout -b branch_name tag_name 放弃工作区的修改1git checkout &lt;file-name&gt; 放弃所有修改：1git checkout . 恢复删除的文件123git rev-list -n 1 HEAD -- &lt;file_path&gt; #得到 deleting_commitgit checkout &lt;deleting_commit&gt;^ -- &lt;file_path&gt; #回到删除文件 deleting_commit 之前的状态 以新增一个 commit 的方式还原某一个 commit 的修改1git revert &lt;commit-id&gt; 回到某个 commit 的状态，并删除后面的 commit和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit 1234567git reset &lt;commit-id&gt; #默认就是-mixed参数。git reset –mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便和HEAD相匹配，但是也到此为止。工作区不会被更改。git reset –soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之前保持一致。如果还要提交，直接commit即可 git reset –hard &lt;commit-id&gt; #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定commit-id版本的内容 修改上一个 commit 的描述如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit 1git commit --amend 查看 commit 历史1git log 查看某段代码是谁写的blame 的意思为‘责怪’，你懂的。 1git blame &lt;file-name&gt; 显示本地更新过 HEAD 的 git 命令记录每次更新了 HEAD 的 git 命令比如 commint、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之后的状态。 1git reflog 修改作者名1git commit --amend --author='Author Name &lt;email@address.com&gt;' 修改远程仓库的 url1git remote set-url origin &lt;URL&gt; 增加远程仓库1git remote add origin &lt;remote-url&gt; 列出所有远程仓库1git remote 查看两个星期内的改动1git whatchanged --since='2 weeks ago' 把 A 分支的某一个 commit，放到 B 分支上这个过程需要 cherry-pick 命令，参考 1git checkout &lt;branch-name&gt; &amp;&amp; git cherry-pick &lt;commit-id&gt; 给 git 命令起别名简化命令 12345git config --global alias.&lt;handle&gt; &lt;command&gt;比如：git status 改成 git st，这样可以简化命令git config --global alias.st status 存储当前的修改，但不用提交 commit详解可以参考廖雪峰老师的 git 教程1git stash 保存当前状态，包括 untracked 的文件untracked 文件：新建的文件1git stash -u 展示所有 stashes1git stash list 回到某个 stash 的状态1git stash apply &lt;stash@&#123;n&#125;&gt; 回到最后一个 stash 的状态，并删除这个 stash1git stash pop 删除所有的 stash1git stash clear 从 stash 中拿出某个文件的修改1git checkout &lt;stash@&#123;n&#125;&gt; -- &lt;file-path&gt; 展示所有 tracked 的文件1git ls-files -t 展示所有 untracked 的文件1git ls-files --others 展示所有忽略的文件1git ls-files --others -i --exclude-standard 强制删除 untracked 的文件可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。clean 命令，注意两点： clean 后，删除的文件无法找回 不会影响 tracked 的文件的改动，只会删除 untracked 的文件 1git clean &lt;file-name&gt; -f 强制删除 untracked 的目录可以用来删除新建的目录，注意:这个命令也可以用来删除 untracked 的文件。详情见上一条 1git clean &lt;directory-name&gt; -df 展示简化的 commit 历史1git log --pretty=oneline --graph --decorate --all 把某一个分支到导出成一个文件1git bundle create &lt;file&gt; &lt;branch-name&gt; 从包中导入分支新建一个分支，分支内容就是上面 git bundle create 命令导出的内容 1git clone repo.bundle &lt;repo-dir&gt; -b &lt;branch-name&gt; 执行 rebase 之前自动 stash1git rebase --autostash 从远程仓库根据 ID，拉下某一状态，到本地分支1git fetch origin pull/&lt;id&gt;/head:&lt;branch-name&gt; 详细展示一行中的修改1git diff --word-diff 清除 gitignore 文件中记录的文件1git clean -X -f 展示所有 alias 和 configs注意： config 分为：当前目录（local）和全局（golbal）的 config，默认为当前目录的 config 12git config --local --list (当前目录)git config --global --list (全局) 展示忽略的文件1git status --ignored commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit1git log Branch1 ^Branch2 在 commit log 中显示 GPG 签名1git log --show-signature 删除全局设置1git config --global --unset &lt;entry-name&gt; 新建并切换到新分支上，同时这个分支没有任何 commit相当于保存修改，但是重写 commit 历史 1git checkout --orphan &lt;branch-name&gt; 展示任意分支某一文件的内容1git show &lt;branch-name&gt;:&lt;file-name&gt; clone 下来指定的单一分支1git clone -b &lt;branch-name&gt; --single-branch https://github.com/user/repo.git 忽略某个文件的改动关闭 track 指定文件的改动，也就是 Git 将不会在记录这个文件的改动 1git update-index --assume-unchanged path/to/file 恢复 track 指定文件的改动 1git update-index --no-assume-unchanged path/to/file 忽略文件的权限变化不再将文件的权限变化视作改动 1git config core.fileMode false 以最后提交的顺序列出所有 Git 分支最新的放在最上面 1git for-each-ref --sort=-committerdate --format='%(refname:short)' refs/heads/ 在 commit log 中查找相关内容通过 grep 查找，given-text：所需要查找的字段 1git log --all --grep='&lt;given-text&gt;' 把暂存区的指定 file 放到工作区中不添加参数，默认是 -mixed 1git reset &lt;file-name&gt; 强制推送1git push -f &lt;remote-name&gt; &lt;branch-name&gt; 一图详解 优雅的提交Commit信息使用Angular团队提交规范 主要有以下组成 标题行: 必填, 描述主要修改类型和内容 主题内容: 描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释: 放 Breaking Changes 或 Closed Issues 常用的修改项 type: commit 的类型 feat: 新特性 fix: 修改问题 refactor: 代码重构 docs: 文档修改 style: 代码格式修改, 注意不是 css 修改 test: 测试用例修改 chore: 其他修改, 比如构建流程, 依赖管理. scope: commit 影响的范围, 比如: route, component, utils, build… subject: commit 的概述 body: commit 具体修改内容, 可以分为多行 footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接.]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode72. Edit Distance]]></title>
    <url>%2F2019%2F04%2F21%2FLeetcode72-Edit-Distance%2F</url>
    <content type="text"><![CDATA[Edit DistanceGiven two words word1 and word2, find the minimum number of operations required to convert word1 to word2. You have the following 3 operations permitted on a word: Insert a characterDelete a characterReplace a characterExample 1:123456Input: word1 = &quot;horse&quot;, word2 = &quot;ros&quot;Output: 3Explanation: horse -&gt; rorse (replace &apos;h&apos; with &apos;r&apos;)rorse -&gt; rose (remove &apos;r&apos;)rose -&gt; ros (remove &apos;e&apos;) Example 2:12345678Input: word1 = &quot;intention&quot;, word2 = &quot;execution&quot;Output: 5Explanation: intention -&gt; inention (remove &apos;t&apos;)inention -&gt; enention (replace &apos;i&apos; with &apos;e&apos;)enention -&gt; exention (replace &apos;n&apos; with &apos;x&apos;)exention -&gt; exection (replace &apos;n&apos; with &apos;c&apos;)exection -&gt; execution (insert &apos;u&apos;) 一道好久不做的dp题，过段时间闲下来复习下dp 给你word1、word2两个字符串，问最少需要几步才能把word1变成word2，下面每种操作都是一步：a)添加一个字符；b)添加一个字符；c)把一个字符用另一个字符代替。 解题思路： 动态规划。用dp[i][j]表示把word1的前i个字符变成word2的前j个字符所需的步数，word1的前i个字符变成word2的前j个字符可以由三种方法得到： word1先删去最后一个字符，然后把word1的前i-1个字符变成word2的前j个字符； word1的前i个字符先变成word2的前j-1个字符；然后word2最后添上一个字符； word1的前i-1个字符先变成word2的前j-1个字符；然后word1的最后一个字符和word2的最后一个字符匹配上。 因此有状态转移方程：当word1[i-1]==word2[j-1]时dp[i][j]=dp[i-1][j-1]，否则dp[i][j]=min(dp[i-1][j]+1,dp[i][j-1]+1,dp[i-1][j-1]+1)。 另外边界需要初始化：dp[0][0]=0，dp[i][0]=i对于i从1到len1，dp[0][i]=i对于i从1到len2,。最终答案为dp[len1][len2]，算法复杂度为O(len1*len2)。 算法正确性： 算法的关键点在于是否可以用动态规划的思想把问题拆分成一个个子问题。可以这么考虑：当你能确定用了若干步把word1的前i个字母变成word2的前j个字母后，接下来就可以处理相邻的状态。对于删除字母，可以把word1的第i+1个字母先删掉，然后再执行那若干步，这样可以得到把word1的前i+1个字母变成word2的前j个字母的步数；对于添加字母，可以先执行那若干步，再加上word2的第j+1个字母，这样可以得到把word1的前i个字母变成word2的前j+1个字母的步数；对于代替字母，可以先执行那若干步，再把word1的第i+1个字母和word2的第j+1个字母匹配上，这样可以得到把word1的前i+1个字母变成word2的前j+1个字母的步数。因此上述算法是正确的。 下面举一个简单例子走一遍算法帮助理解：word1=”ad”，word2=”abc”。初始化：dp[0][0]=0，dp[1][0]=1，dp[2][0]=2，dp[0][1]=1，dp[0][2]=2，dp[0][3]=3；i=1，j=1，word1[0]==word2[0]，dp[1][1]=min(dp[0][1]+1,dp[1][0]+1,dp[0][0])=0；i=1，j=2，word1[0]!=word2[1]，dp[1][2]=min(dp[0][2]+1,dp[1][1]+1,dp[0][1]+1)=2；i=1，j=3，word1[0]!=word2[2]，dp[1][3]=min(dp[0][3]+1,dp[1][2]+1,dp[0][2]+1)=3；i=2，j=1，word1[1]!=word2[0]，dp[2][1]=min(dp[1][1]+1,dp[2][0]+1,dp[1][0]+1)=1；i=2，j=2，word1[1]!=word2[1]，dp[2][2]=min(dp[1][2]+1,dp[2][1]+1,dp[1][1]+1)=1；i=2，j=3，word1[1]!=word2[2]，dp[2][3]=min(dp[1][3]+1,dp[2][2]+1,dp[1][2]+1)=2；最终结果为dp[2][3]=3。 12345678910111213141516171819class Solution &#123;public: int minDistance(string word1, string word2) &#123; int len1=word1.size(),len2=word2.size(); int dp[len1+1][len2+1]; for(int i=0;i&lt;len1+1;i++) dp[i][0]=i; for(int i=0;i&lt;len2+1;i++) dp[0][i]=i; for(int i=1;i&lt;len1+1;i++) for(int j=1;j&lt;len2+1;j++)&#123; if(word1[i-1]==word2[j-1]) dp[i][j]=dp[i-1][j-1];//两个字符相等 else dp[i][j]=min(dp[i-1][j]+1,min(dp[i][j-1]+1,dp[i-1][j-1]+1));//两个字符不相等 &#125; return dp[len1][len2]; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[malloc 函数详解]]></title>
    <url>%2F2019%2F04%2F20%2Fmalloc%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/Commence/p/5785912.html malloc只是C标准库中提供的一个普通函数 而且很多很多人都对malloc的具体实现机制不是很了解。 关于malloc以及相关的几个函数123456#include &lt;stdlib.h&gt;(Linux下)void *malloc(size_t size);void free(void *ptr);void *calloc(size_t nmemb, size_t size);void *realloc(void *ptr, size_t size); 也可以这样认为（window下）原型：extern void *malloc(unsigned int num_bytes);头文件：#include &lt;malloc.h&gt;或者#include &lt;alloc.h&gt;两者的内容是完全一样的。 如果分配成功：则返回指向被分配内存空间的指针，不然，返回空指针NULL。当内存不再使用的时候，应使用free（）函数将内存块释放掉。void ,表示未确定类型的指针。C，C++规定，void 类型可以强转为任何其他类型的的指针。 malloc returns a void pointer to the allocated space, or NULL if there is insufficient memory available. To return a pointer to a type other than void, use a type cast on the return value. The storage space pointed to by the return value is guaranteed to be suitably aligned for storage of any type of object. If size is 0, malloc allocates a zero-length item in the heap and returns a valid pointer to that item. Always check the return from malloc, even if the amount of memory requested is small. 关于void *的其他说法：123void * p1;int *p2;p1 = p2; 就是说其他任意类型都可以直接赋值给它，无需进行强转，但是反过来不可以。 malloc： malloc分配的内存大小至少为size参数所指定的字节数 malloc的返回值是一个指针，指向一段可用内存的起始地址 多次调用malloc所分配的地址不能有重叠部分，除非某次malloc所分配的地址被释放掉 malloc应该尽快完成内存分配并返回（不能使用NP-hard的内存分配算法） 实现malloc时应同时实现内存大小调整和内存释放函数（realloc和free） malloc和free函数是配对的，如果申请后不释放就是内存泄露;如果无故释放那就是什么都没有做，释放只能释放一次，如果释放两次及两次以上会出现错误（但是释放空指针例外，释放空指针其实也等于什么都没有做，所以，释放多少次都是可以的） malloc和new new返回指定类型的指针，并且可以自动计算所需要的大小。123int *p;p = new int; //返回类型为int *类型，分配的大小为sizeof(int)p = new int[100]; //返回类型为int *类型，分配的大小为sizeof(int) * 100 而malloc则必须由我们计算字节数，并且在返回的时候强转成实际指定类型的指针。12int *p;p = (int *)malloc(sizeof(int)); malloc的返回是void ,如果我们写成了: p = malloc(sizeof(int));间接的说明了（将void 转化给了int *,这不合理） malloc的实参是sizeof(int),用于指明一个整形数据需要的大小，如果我们写成：p = （int *）malloc(1),那么可以看出：只是申请了一个字节的空间，如果向里面存放了一个整数的话，将会占用额外的3个字节，可能会改变原有内存空间中的数据； malloc只管分配内存，并不能对其进行初始化，所以得到的一片新内存中，其值将是随机的。一般意义上：我们习惯性的将其初始化为NULL。当然,也可以用memset函数的。 简单的说： malloc 函数其实就是在内存中：找一片指定大小的空间，然后将这个空间的首地址给一个指针变量，这里的指针变量可以是一个单独的指针，也可以是一个数组的首地址， 这要看malloc函数中参数size的具体内容。我们这里malloc分配的内存空间在逻辑上是连续的，而在物理上可以不连续。我们作为程序员，关注的 是逻辑上的连续，其它的，操作系统会帮着我们处理的。 下面我们聊聊malloc的具体实现机制： Linux内存管理虚拟内存地址与物理内存地址为了简单，现代操作系统在处理内存地址时，普遍采用虚拟内存地址技术。即在汇编程序（或机器语言）层面，当涉及内存地址时， 都是使用虚拟内存地址。采用这种技术时，每个进程仿佛自己独享一片2N字节的内存，其中N是机器位数。例如在64位CPU和64位操作系统下，每个进程的 虚拟地址空间为264Byte。 这种虚拟地址空间的作用主要是简化程序的编写及方便操作系统对进程间内存的隔离管理，真实中的进程不太可能（也用不到）如此大的内存空间，实际能用到的内存取决于物理内存大小。 由于在机器语言层面都是采用虚拟地址，当实际的机器码程序涉及到内存操作时，需要根据当前进程运行的实际上下文将虚拟地址转换为物理内存地址，才能实现对真实内存数据的操作。这个转换一般由一个叫MMU（Memory Management Unit）的硬件完成。 页与地址构成在现代操作系统中，不论是虚拟内存还是物理内存，都不是以字节为单位进行管理的，而是以页（Page）为单位。一个内存页是一段固定大小的连续内存地址的总称，具体到Linux中，典型的内存页大小为4096Byte（4K）。 所以内存地址可以分为页号和页内偏移量。下面以64位机器，4G物理内存，4K页大小为例，虚拟内存地址和物理内存地址的组成如下： 上面是虚拟内存地址，下面是物理内存地址。由于页大小都是4K，所以页内便宜都是用低12位表示，而剩下的高地址表示页号。 MMU映射单位并不是字节，而是页，这个映射通过查一个常驻内存的数据结构页表来实现。现在计算机具体的内存地址映射比较复杂，为了加快速度会引入一系列缓存和优化，例如TLB等机制。下面给出一个经过简化的内存地址翻译示意图，虽然经过了简化，但是基本原理与现代计算机真实的情况的一致的。 内存页与磁盘页我们知道一般将内存看做磁盘的的缓存，有时MMU在工作时，会发现页表表明某个内存页不在物理内存中，此时会触发一个缺页异 常（Page Fault），此时系统会到磁盘中相应的地方将磁盘页载入到内存中，然后重新执行由于缺页而失败的机器指令。关于这部分，因为可以看做对malloc实现 是透明的，所以不再详细讲述，有兴趣的可以参考《深入理解计算机系统》相关章节。附上一张在维基百科找到的更加符合真实地址翻译的流程供大家参考，这张图加入了TLB和缺页异常的流程。 Linux进程级内存管理内存排布明白了虚拟内存和物理内存的关系及相关的映射机制，下面看一下具体在一个进程内是如何排布内存的。 以Linux 64位系统为例。理论上，64bit内存地址可用空间为0x0000000000000000 ~ 0xFFFFFFFFFFFFFFFF，这是个相当庞大的空间，Linux实际上只用了其中一小部分（256T）。 根据Linux内核相关文档描述，Linux64位操作系统仅使用低47位，高17位做扩展（只能是全0或全1）。所以，实际用到的地址为空间为0x0000000000000000 ~ 0x00007FFFFFFFFFFF和0xFFFF800000000000 ~ 0xFFFFFFFFFFFFFFFF，其中前面为用户空间（User Space），后者为内核空间（Kernel Space）。图示如下： 对用户来说，主要关注的空间是User Space。将User Space放大后，可以看到里面主要分为如下几段： Code：这是整个用户空间的最低地址部分，存放的是指令（也就是程序所编译成的可执行机器码） Data：这里存放的是初始化过的全局变量 BSS：这里存放的是未初始化的全局变量 Heap：堆，这是我们本文重点关注的地方，堆自低地址向高地址增长，后面要讲到的brk相关的系统调用就是从这里分配内存 Mapping Area：这里是与mmap系统调用相关的区域。大多数实际的malloc实现会考虑通过mmap分配较大块的内存区域，本文不讨论这种情况。这个区域自高地址向低地址增长 Stack：这是栈区域，自高地址向低地址增长 Heap内存模型一般来说，malloc所申请的内存主要从Heap区域分配（本文不考虑通过mmap申请大块内存的情况）。 由上文知道，进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。受物理存储容量限制，整个堆虚拟内存空间不可能全部映射到实际的物理内存。Linux对堆的管理示意如下： Linux维护一个break指针，这个指针指向堆空间的某个地址。从堆起始地址到break之间的地址空间为映射好的，可以供进程访问；而从break往上，是未映射的地址空间，如果访问这段空间则程序会报错。 brk与sbrk由上文知道，要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过brk和sbrk系统调用操作break指针。两个系统调用的原型如下：12int brk(void *addr);void *sbrk(intptr_t increment); brk将break指针直接设置为某个地址，而sbrk将break从当前位置移动increment所指定的增量。brk 在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break移动之前所指向的地址，否则返回(void *)-1。 一个小技巧是，如果将increment设置为0，则可以获得当前break的地址。 另外需要注意的是，由于Linux是按页进行内存映射的，所以如果break被设置为没有按页大小对齐，则系统实际上会在最 后映射一个完整的页，从而实际已映射的内存空间比break指向的地方要大一些。但是使用break之后的地址是很危险的（尽管也许break之后确实有 一小块可用内存地址）。 资源限制与rlimit 系统对每一个进程所分配的资源不是无限的，包括可映射的内存空间，因此每个进程有一个rlimit表示当前进程可用的资源上限。这个限制可以通过getrlimit系统调用得到，下面代码获取当前进程虚拟内存空间的rlimit：12345int main() &#123; struct rlimit *limit = (struct rlimit *)malloc(sizeof(struct rlimit)); getrlimit(RLIMIT_AS, limit); printf(&quot;soft limit: %ld, hard limit: %ld\n&quot;, limit-&gt;rlim_cur, limit-&gt;rlim_max);&#125; 其中rlimit是一个结构体：1234struct rlimit &#123;rlim_t rlim_cur; /* Soft limit */rlim_t rlim_max; /* Hard limit (ceiling for rlim_cur) */&#125;; 每种资源有软限制和硬限制，并且可以通过setrlimit对rlimit进行有条件设置。其中硬限制作为软限制的上限，非特权进程只能设置软限制，且不能超过硬限制。 实现malloc玩具实现在正式开始讨论malloc的实现前，我们可以利用上述知识实现一个简单但几乎没法用于真实的玩具malloc，权当对上面知识的复习：1234567891011/* 一个玩具malloc */#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void *malloc(size_t size)&#123; void *p; p = sbrk(0); if (sbrk(size) == (void *)-1) return NULL; return p;&#125; 这个malloc每次都在当前break的基础上增加size所指定的字节数，并将之前break的地址返回。这个malloc由于对所分配的内存缺乏记录，不便于内存释放，所以无法用于真实场景。 正式实现下面严肃点讨论malloc的实现方案。 数据结构首先我们要确定所采用的数据结构。一个简单可行方案是将堆内存空间以块（Block）的形式组织起来，每个块由meta区和 数据区组成，meta区记录数据块的元信息（数据区大小、空闲标志位、指针等等），数据区是真实分配的内存区域，并且数据区的第一个字节地址即为 malloc返回的地址。 可以用如下结构体定义一个block：12345678typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 由于我们只考虑64位机器，为了方便，我们在结构体最后填充一个int，使得结构体本身的长度为8的倍数，以便内存对齐。示意图如下： 寻找合适的block现在考虑如何在block链中查找合适的block。一般来说有两种查找算法： First fit：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块Best fit：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块 两种方法各有千秋，best fit具有较高的内存使用率（payload较高），而first fit具有更好的运行效率。这里我们采用first fit算法。 123456789/* First fit */t_block find_block(t_block *last, size_t size) &#123;t_block b = first_block;while(b &amp;&amp; !(b-&gt;free &amp;&amp; b-&gt;size &gt;= size)) &#123; *last = b; b = b-&gt;next;&#125;return b;&#125; find_block从frist_block开始，查找第一个符合要求的block并返回block起始地址，如果找不到 这返回NULL。这里在遍历时会更新一个叫last的指针，这个指针始终指向当前遍历的block。这是为了如果找不到合适的block而开辟新 block使用的，具体会在接下来的一节用到。 开辟新的block如果现有block都不能满足size的要求，则需要在链表最后开辟一个新的block。这里关键是如何只使用sbrk创建一个struct：1234567891011121314#define BLOCK_SIZE 24 /* 由于存在虚拟的data字段，sizeof不能正确计算meta长度，这里手工设置 */ t_block extend_heap(t_block last, size_t s) &#123; t_block b; b = sbrk(0); if(sbrk(BLOCK_SIZE + s) == (void *)-1) return NULL; b-&gt;size = s; b-&gt;next = NULL; if(last) last-&gt;next = b; b-&gt;free = 0; return b;&#125; 分裂blockFirst fit有一个比较致命的缺点，就是可能会让很小的size占据很大的一块block，此时，为了提高payload，应该在剩余数据区足够大的情况下，将其分裂为一个新的block，示意如下：123456789void split_block(t_block b, size_t s) &#123; t_block new; new = b-&gt;data + s; new-&gt;size = b-&gt;size - s - BLOCK_SIZE ; new-&gt;next = b-&gt;next; new-&gt;free = 1; b-&gt;size = s; b-&gt;next = new;&#125; malloc的实现有了上面的代码，我们可以利用它们整合成一个简单但初步可用的malloc。注意首先我们要定义个block链表的头first_block，初始化为NULL；另外，我们需要剩余空间至少有BLOCK_SIZE + 8才执行分裂操作。 由于我们希望malloc分配的数据区是按8字节对齐，所以在size不为8的倍数时，我们需要将size调整为大于size的最小的8的倍数：123456789101112131415161718192021222324252627282930313233343536373839size_t align8(size_t s) &#123; if(s &amp; 0x7 == 0) return s; return ((s &gt;&gt; 3) + 1) &lt;&lt; 3;&#125;#define BLOCK_SIZE 24void *first_block=NULL; /* other functions... */ void *malloc(size_t size) &#123; t_block b, last; size_t s; /* 对齐地址 */ s = align8(size); if(first_block) &#123; /* 查找合适的block */ last = first_block; b = find_block(&amp;last, s); if(b) &#123; /* 如果可以，则分裂 */ if ((b-&gt;size - s) &gt;= ( BLOCK_SIZE + 8)) split_block(b, s); b-&gt;free = 0; &#125; else &#123; /* 没有合适的block，开辟一个新的 */ b = extend_heap(last, s); if(!b) return NULL; &#125; &#125; else &#123; b = extend_heap(NULL, s); if(!b) return NULL; first_block = b; &#125; return b-&gt;data;&#125; calloc的实现有了malloc，实现calloc只要两步： malloc一段内存 将数据区内容置为0由于我们的数据区是按8字节对齐的，所以为了提高效率，我们可以每8字节一组置0，而不是一个一个字节设置。我们可以通过新建一个size_t指针，将内存区域强制看做size_t类型来实现。1234567891011void *calloc(size_t number, size_t size) &#123; size_t *new; size_t s8, i; new = malloc(number * size); if(new) &#123; s8 = align8(number * size) &gt;&gt; 3; for(i = 0; i &lt; s8; i++) new[i] = 0; &#125; return new;&#125; free的实现free的实现并不像看上去那么简单，这里我们要解决两个关键问题： 如何验证所传入的地址是有效地址，即确实是通过malloc方式分配的数据区首地址 如何解决碎片问题首先我们要保证传入free的地址是有效的，这个有效包括两方面： 地址应该在之前malloc所分配的区域内，即在first_block和当前break指针范围内 这个地址确实是之前通过我们自己的malloc分配的 第一个问题比较好解决，只要进行地址比较就可以了，关键是第二个问题。这里有两种解决方案：一是在结构体内埋一个magic number字段，free之前通过相对偏移检查特定位置的值是否为我们设置的magic number，另一种方法是在结构体内增加一个magic pointer，这个指针指向数据区的第一个字节（也就是在合法时free时传入的地址），我们在free前检查magic pointer是否指向参数所指地址。这里我们采用第二种方案： 首先我们在结构体中增加magic pointer（同时要修改BLOCK_SIZE）：123456789typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 然后我们定义检查地址合法性的函数：1234567891011121314t_block get_block(void *p) &#123; char *tmp; tmp = p; return (p = tmp -= BLOCK_SIZE);&#125; int valid_addr(void *p) &#123; if(first_block) &#123; if(p &gt; first_block &amp;&amp; p &lt; sbrk(0)) &#123; return p == (get_block(p))-&gt;ptr; &#125; &#125;return 0;&#125; 当多次malloc和free后，整个内存池可能会产生很多碎片block，这些block很小，经常无法使用，甚至出现许多碎片连在一起，虽然总体能满足某此malloc要求，但是由于分割成了多个小block而无法fit，这就是碎片问题。 一个简单的解决方式时当free某个block时，如果发现它相邻的block也是free的，则将block和相邻block合并。为了满足这个实现，需要将s_block改为双向链表。修改后的block结构如下：12345678910typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block prev; /* 指向上个块的指针 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 合并方法如下：123456789t_block fusion(t_block b) &#123; if (b-&gt;next &amp;&amp; b-&gt;next-&gt;free) &#123; b-&gt;size += BLOCK_SIZE + b-&gt;next-&gt;size; b-&gt;next = b-&gt;next-&gt;next; if(b-&gt;next) b-&gt;next-&gt;prev = b; &#125; return b;&#125; 有了上述方法，free的实现思路就比较清晰了：首先检查参数地址的合法性，如果不合法则不做任何事；否则，将此block 的free标为1，并且在可以的情况下与后面的block进行合并。如果当前是最后一个block，则回退break指针释放进程内存，如果当前 block是最后一个block，则回退break指针并设置first_block为NULL。实现如下：123456789101112131415161718void free(void *p) &#123; t_block b; if(valid_addr(p)) &#123; b = get_block(p); b-&gt;free = 1; if(b-&gt;prev &amp;&amp; b-&gt;prev-&gt;free) b = fusion(b-&gt;prev); if(b-&gt;next) fusion(b); else &#123; if(b-&gt;prev) b-&gt;prev-&gt;prev = NULL; else first_block = NULL; brk(b); &#125; &#125;&#125; realloc的实现为了实现realloc，我们首先要实现一个内存复制方法。如同calloc一样，为了效率，我们以8字节为单位进行复制：12345678void copy_block(t_block src, t_block dst) &#123; size_t *sdata, *ddata; size_t i; sdata = src-&gt;ptr; ddata = dst-&gt;ptr; for(i = 0; (i * 8) &lt; src-&gt;size &amp;&amp; (i * 8) &lt; dst-&gt;size; i++) ddata[i] = sdata[i];&#125; 然后我们开始实现realloc。一个简单（但是低效）的方法是malloc一段内存，然后将数据复制过去。但是我们可以做的更高效，具体可以考虑以下几个方面： 如果当前block的数据区大于等于realloc所要求的size，则不做任何操作 如果新的size变小了，考虑split 如果当前block的数据区不能满足size，但是其后继block是free的，并且合并后可以满足，则考虑做合并 下面是realloc的实现：1234567891011121314151617181920212223242526272829303132333435void *realloc(void *p, size_t size) &#123; size_t s; t_block b, new; void *newp; if (!p) /* 根据标准库文档，当p传入NULL时，相当于调用malloc */ return malloc(size); if(valid_addr(p)) &#123; s = align8(size); b = get_block(p); if(b-&gt;size &gt;= s) &#123; if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8)) split_block(b,s); &#125; else &#123; /* 看是否可进行合并 */ if(b-&gt;next &amp;&amp; b-&gt;next-&gt;free &amp;&amp; (b-&gt;size + BLOCK_SIZE + b-&gt;next-&gt;size) &gt;= s) &#123; fusion(b); if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8)) split_block(b, s); &#125; else &#123; /* 新malloc */ newp = malloc (s); if (!newp) return NULL; new = get_block(newp); copy_block(b, new); free(p); return(newp); &#125; &#125; return (p); &#125; return NULL;&#125; 遗留问题和优化以上是一个较为简陋，但是初步可用的malloc实现。还有很多遗留的可能优化点，例如： 同时兼容32位和64位系统在分配较大快内存时，考虑使用mmap而非sbrk，这通常更高效可以考虑维护多个链表而非单个，每个链表中的block大小均为一个范围内，例如8字节链表、16字节链表、24-32字节链表等等。此时可以根据size到对应链表中做分配，可以有效减少碎片，并提高查询block的速度可以考虑链表中只存放free的block，而不存放已分配的block，可以减少查找block的次数，提高效率还有很多可能的优化，这里不一一赘述。下面附上一些参考文献，有兴趣的同学可以更深入研究。 其它参考Computer Systems: A Programmer’s Perspective, 2/E一书有许多值得参考的地方]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode961. N-Repeated Element in Size 2N Array]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode961-N-Repeated-Element-in-Size-2N-Array%2F</url>
    <content type="text"><![CDATA[N-Repeated Element in Size 2N ArrayIn a array A of size 2N, there are N+1 unique elements, and exactly one of these elements is repeated N times. Return the element repeated N times. Example 1:12Input: [1,2,3,3]Output: 3 Example 2:12Input: [2,1,2,5,3,2]Output: 2 Example 3:12Input: [5,1,5,2,5,3,5,4]Output: 5 Note: 4 &lt;= A.length &lt;= 100000 &lt;= A[i] &lt; 10000A.length is even 一个桶排序搞定12345678910111213class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; int counter[10000]; memset(counter,0,sizeof(counter)); for(int i=0;i&lt;A.size();i++)&#123; counter[A[i]]++; if(counter[A[i]]&gt;=A.size()/2) return A[i]; &#125; return -1; &#125;&#125;; 看到了大佬的解法，跪了，如果有两个连续一样的元素，直接返回 The intuition here is that the repeated numbers have to appear either next to each other (A[i] == A[i + 1]), or alternated (A[i] == A[i + 2]). The only exception is sequences like [2, 1, 3, 2]. In this case, the result is the last number, so we just return it in the end. This solution has O(n) runtime.12345int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; for (auto i = 0; i &lt; A.size() - 2; ++i) if (A[i] == A[i + 1] || A[i] == A[i + 2]) return A[i]; return A[A.size() - 1]; &#125; Another interesting approach is to use randomization (courtesy of @lee215 ). If you pick two numbers randomly, there is a 25% chance you bump into the repeated number. So, in average, we will find the answer in 4 attempts, thus O(4) runtime.1234int repeatedNTimes(vector&lt;int&gt;&amp; A, int i = 0, int j = 0) &#123; while (A[i = rand() % A.size()] != A[j = rand() % A.size()] || i == j); return A[i];&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++函数调用分析]]></title>
    <url>%2F2019%2F04%2F20%2Fcpp%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[这里以一个简单的C语言代码为例，来分析函数调用过程 代码：123456789101112131415161718#include &lt;stdio.h&gt;int func(int param1 ,int param2,int param3)&#123; int var1 = param1; int var2 = param2; int var3 = param3; printf(&quot;var1=%d,var2=%d,var3=%d&quot;,var1,var2,var3); return var1;&#125; int main(int argc, char* argv[])&#123; int result = func(1,2,3); return 0; &#125; 首先说明，在堆栈中变量分布是从高地址到低地址分布，EBP是指向栈底的指针，在过程调用中不变，又称为帧指针。ESP指向栈顶，程序执行时移动，ESP减小分配空间，ESP增大释放空间，ESP又称为栈指针。 下面来逐步分析函数的调用过程 函数main执行，main各个参数从右向左逐步压入栈中，最后压入返回地址 执行第15行，3个参数以从左向右的顺序压入堆栈，及从param3到param1，栈内分布如下图： 然后是返回地址入栈：此时的栈内分布如下： 第3行函数调用时，通过跳转指令进入函数后，函数地址入栈后，EBP入栈，然后把当前ESP的值给EBP，对应的汇编指令：12push ebpmov ebp esp 此时栈顶和栈底指向同一位置，栈内分布如下： 第5行开始执行， int var1 = param1; int var2 = param2; int var3 = param3;按申明顺序依次存储。对应的汇编：12mov 0x8(%ebp),%eaxmov %eax,-0x4(%ebp) 其中将[EBP+0x8]地址里的内容赋给EAX，即把param的值赋给EAX，然后把EAX的中的值放到[EBP-4]这个地址里，即把EAX值赋给var1，完成C代码 int var1 = param1，其他变量雷同。 第9行，输出结果，第10行执行 对应的汇编代码：1mov -0x4(%ebp),%eax 最后通过eax寄存器保存函数的返回值； 调用执行函数完毕，局部变量var3，var2，var1一次出栈，EBP恢复原值，返回地址出栈，找到原执行地址，param1，param2，param3依次出栈，函数调用执行完毕。图略]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1026. Maximum Difference Between Node and Ancestor]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1026-Maximum-Difference-Between-Node-and-Ancestor%2F</url>
    <content type="text"><![CDATA[Maximum Difference Between Node and AncestorGiven the root of a binary tree, find the maximum value V for which there exists different nodes A and B where V = |A.val - B.val| and A is an ancestor of B. (A node A is an ancestor of B if either: any child of A is equal to B, or any child of A is an ancestor of B.) Example 1:123456789Input: [8,3,10,1,6,null,14,null,null,4,7,13]Output: 7Explanation: We have various ancestor-node differences, some of which are given below :|8 - 3| = 5|3 - 7| = 4|8 - 1| = 7|10 - 13| = 3Among all possible differences, the maximum value of 7 is obtained by |8 - 1| = 7. Note: The number of nodes in the tree is between 2 and 5000.Each node will have value between 0 and 100000. 给一棵树，找到最大值v，这个v是节点和祖先的值的差的绝对值。dfs里一定要有一个最大一个最小，这样才能算出来绝对值最大的一个，之前考虑只放一个值，没有搞定。一个dfs 123456789101112131415161718192021222324252627/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int val=0; void dfs(TreeNode* root,int maxval,int minval)&#123; val = max(val, abs(root-&gt;val - maxval)); val = max(val, abs(root-&gt;val - minval)); maxval = max(maxval, root-&gt;val); minval = min(minval, root-&gt;val); if(root-&gt;right) dfs(root-&gt;right,maxval,minval); if(root-&gt;left) dfs(root-&gt;left,maxval,minval); &#125; int maxAncestorDiff(TreeNode* root) &#123; dfs(root,root-&gt;val,root-&gt;val); return val; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1025. Divisor Game]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1025-Divisor-Game%2F</url>
    <content type="text"><![CDATA[Divisor GameEasy Alice and Bob take turns playing a game, with Alice starting first. Initially, there is a number N on the chalkboard. On each player’s turn, that player makes a move consisting of: Choosing any x with 0 &lt; x &lt; N and N % x == 0.Replacing the number N on the chalkboard with N - x.Also, if a player cannot make a move, they lose the game. Return True if and only if Alice wins the game, assuming both players play optimally. Example 1:123Input: 2Output: trueExplanation: Alice chooses 1, and Bob has no more moves. Example 2:123Input: 3Output: falseExplanation: Alice chooses 1, Bob chooses 1, and Alice has no more moves. Note: 1 &lt;= N &lt;= 1000 两个人玩游戏，给一个数字N，先轮到A走，A选一个数字x使得0 &lt; x &lt; N且N % x == 0，之后N变为N-x，如果谁选不出来x，那就输了，A遇见偶数赢，奇数输。 如果A看见偶数，就选x=1，则N变成奇数，B只能再选一个奇数，又把N变成偶数，由于1是奇数且1没法再选，故A遇见偶数一定赢，反之则输。 123456class Solution &#123;public: bool divisorGame(int N) &#123; return (N%2)==0; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1024. Video Stitching]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1024-Video-Stitching%2F</url>
    <content type="text"><![CDATA[You are given a series of video clips from a sporting event that lasted T seconds. These video clips can be overlapping with each other and have varied lengths. Each video clip clips[i] is an interval: it starts at time clips[i][0] and ends at time clips[i][1]. We can cut these clips into segments freely: for example, a clip [0, 7] can be cut into segments [0, 1] + [1, 3] + [3, 7]. Return the minimum number of clips needed so that we can cut the clips into segments that cover the entire sporting event ([0, T]). If the task is impossible, return -1. 寻找最少的可以覆盖[0, T]区间的区间数量，一开始没搞定，看答案搞定的。总体思路就是一开始先排序，并且记下来两个end，一个是当前的end，一个是之前一次的end，如果现在这个小区间的end比之前的pre_end还小，直接不考虑了。我做的时候忽略了这一点，如果不记下来之前的per_end的话，可能有区间是重复的（现在这个小区间如果加进去了，就跟上次加进去的那个小区间有重复的部分或者重合） Example 1:1234567Input: clips = [[0,2],[4,6],[8,10],[1,9],[1,5],[5,9]], T = 10Output: 3Explanation: We take the clips [0,2], [8,10], [1,9]; a total of 3 clips.Then, we can reconstruct the sporting event as follows:We cut [1,9] into segments [1,2] + [2,8] + [8,9].Now we have segments [0,2] + [2,8] + [8,10] which cover the sporting event [0, 10]. Example 2:1234Input: clips = [[0,1],[1,2]], T = 5Output: -1Explanation: We can&apos;t cover [0,5] with only [0,1] and [0,2]. Example 3:1234Input: clips = [[0,1],[6,8],[0,2],[5,6],[0,4],[0,3],[6,7],[1,3],[4,7],[1,4],[2,5],[2,6],[3,4],[4,5],[5,7],[6,9]], T = 9Output: 3Explanation: We can take clips [0,4], [4,7], and [6,9]. Example 4:1234Input: clips = [[0,4],[2,8]], T = 5Output: 2Explanation: Notice you can have extra video after the event ends. Note: 1 &lt;= clips.length &lt;= 1000 &lt;= clips[i][0], clips[i][1] &lt;= 1000 &lt;= T &lt;= 100 12345678910111213141516171819202122232425262728class Solution &#123;public: static bool comp(const vector&lt;int&gt; &amp;a, const vector&lt;int&gt; &amp;b) &#123; if(a[0]==b[0]) return a[1] &gt; b[1]; return a[0] &lt; b[0]; &#125; int videoStitching(vector&lt;vector&lt;int&gt;&gt;&amp; clips, int T) &#123; sort(clips.begin(), clips.end(), comp); int count=0, cur_end=0, pre_end=-1; for(int i = 0; i &lt; clips.size(); i ++)&#123; if(clips[i][1] &lt;= cur_end) continue; if(clips[i][0] &gt; cur_end) return -1; if(clips[i][0] &gt; pre_end)&#123; pre_end = cur_end; count++; &#125; cur_end = clips[i][1]; if(cur_end &gt;= T) return count; &#125; return -1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1023. Camelcase Matching]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode1023-Camelcase-Matching%2F</url>
    <content type="text"><![CDATA[Camelcase Matching A query word matches a given pattern if we can insert lowercase letters to the pattern word so that it equals the query. (We may insert each character at any position, and may insert 0 characters.) Given a list of queries, and a pattern, return an answer list of booleans, where answer[i] is true if and only if queries[i] matches the pattern. Example 1:123456Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FB&quot;Output: [true,false,true,true,false]Explanation: &quot;FooBar&quot; can be generated like this &quot;F&quot; + &quot;oo&quot; + &quot;B&quot; + &quot;ar&quot;.&quot;FootBall&quot; can be generated like this &quot;F&quot; + &quot;oot&quot; + &quot;B&quot; + &quot;all&quot;.&quot;FrameBuffer&quot; can be generated like this &quot;F&quot; + &quot;rame&quot; + &quot;B&quot; + &quot;uffer&quot;. Example 2:12345Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FoBa&quot;Output: [true,false,true,false,false]Explanation: &quot;FooBar&quot; can be generated like this &quot;Fo&quot; + &quot;o&quot; + &quot;Ba&quot; + &quot;r&quot;.&quot;FootBall&quot; can be generated like this &quot;Fo&quot; + &quot;ot&quot; + &quot;Ba&quot; + &quot;ll&quot;. Example 3:1234Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FoBaT&quot;Output: [false,true,false,false,false]Explanation: &quot;FooBarTest&quot; can be generated like this &quot;Fo&quot; + &quot;o&quot; + &quot;Ba&quot; + &quot;r&quot; + &quot;T&quot; + &quot;est&quot;. Note: 1 &lt;= queries.length &lt;= 1001 &lt;= queries[i].length &lt;= 1001 &lt;= pattern.length &lt;= 100All strings consists only of lower and upper case English letters. 给一个字符串和一个模式串，看能不能在模式串里加小写字母来转换成字符串，比较简单。123456789101112131415161718192021222324class Solution &#123;public: vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; queries, string pattern) &#123; vector&lt;bool&gt; ans; for(int i=0;i&lt;queries.size();i++)&#123; bool succ=true; int index=0; for(int j=0;j&lt;queries[i].size();j++)&#123; while(islower(queries[i][j])&amp;&amp; pattern[index]!=queries[i][j])&#123; j++; &#125; if(pattern[index]==queries[i][j]) index++; else&#123; succ=false; break; &#125; &#125; ans.push_back(succ); &#125; return ans; &#125;&#125;; 我的代码比较慢，可以看看大佬们怎么写的。 Solution 1, FindFor each query, find all letters in pattern left-to-right. If we found all pattern letters, check that the rest of the letters is in the lower case. 对每个查询，从左到右找pattern里的字幕，如果找到了，检查剩余的是否是小写字母。感觉跟我的类似。 For simplicity, we can replace the found pattern letter in query with a lowercase ‘a’.1234567891011121314vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; qs, string pattern, vector&lt;bool&gt; res = &#123;&#125;) &#123; for (auto i = 0; i &lt; qs.size(); ++i) &#123; for (auto p = -1, j = 0; j &lt; pattern.size(); ++j) &#123; p = qs[i].find(pattern[j], p + 1); if (p == string::npos) &#123; res.push_back(false); break; &#125; qs[i][p] = &apos;a&apos;; &#125; if (res.size() &lt;= i) res.push_back(all_of(begin(qs[i]), end(qs[i]), [](char ch) &#123; return islower(ch); &#125;)); &#125; return res;&#125; Solution 2, Simple ScanInstead of using the find function, we can just check all characters in the query. If a character matches the pattern pointer (pattern[p]), we advance that pointer (++p). Otherwise, we check that the query character is in the lower case. 检查查询的字符串，如果一个字符与pattern[p]匹配了，就继续，如果不匹配，看是不是小些 With this solution, it’s also easer to realize that the complexity is O(n), where n is the total number of query characters.12345678910vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; qs, string pattern, vector&lt;bool&gt; res = &#123;&#125;) &#123; for (auto i = 0, j = 0, p = 0; i &lt; qs.size(); ++i) &#123; for (j = 0, p = 0; j &lt; qs[i].size(); ++j) &#123; if (p &lt; pattern.size() &amp;&amp; qs[i][j] == pattern[p]) ++p; else if (!islower(qs[i][j])) break; &#125; res.push_back(j == qs[i].size() &amp;&amp; p == pattern.size()); &#125; return res;&#125; Complexity AnalysisRuntime: O(n), where n is all letters in all queries. We process each letter only once.Memory: O(m), where m is the number of queries (to store the result).时间复杂度O(n)，空间复杂度O(m)]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode129. Sum Root to Leaf Numbers]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode129-Sum-Root-to-Leaf-Numbers%2F</url>
    <content type="text"><![CDATA[Sum Root to Leaf Numbers Given a binary tree containing digits from 0-9 only, each root-to-leaf path could represent a number. An example is the root-to-leaf path 1-&gt;2-&gt;3 which represents the number 123. Find the total sum of all root-to-leaf numbers. Note: A leaf is a node with no children. Example:123456789Input: [1,2,3] 1 / \ 2 3Output: 25Explanation:The root-to-leaf path 1-&gt;2 represents the number 12.The root-to-leaf path 1-&gt;3 represents the number 13.Therefore, sum = 12 + 13 = 25. Example 2:123456789101112Input: [4,9,0,5,1] 4 / \ 9 0 / \5 1Output: 1026Explanation:The root-to-leaf path 4-&gt;9-&gt;5 represents the number 495.The root-to-leaf path 4-&gt;9-&gt;1 represents the number 491.The root-to-leaf path 4-&gt;0 represents the number 40.Therefore, sum = 495 + 491 + 40 = 1026. 跟1022一样的代码，只是变成了十进制 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int result; void dfs(TreeNode* root ,int now)&#123; if(!root) return; if(!root-&gt;left &amp;&amp; !root-&gt;right)&#123; result += (now*10) + root-&gt;val; &#125; int val = (now*10) + root-&gt;val; if(root-&gt;left) dfs(root-&gt;left, val); if(root-&gt;right) dfs(root-&gt;right, val); &#125; int sumNumbers(TreeNode* root) &#123; result=0; dfs(root,0); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1022. Sum of Root To Leaf Binary Numbers]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode1022-Sum-of-Root-To-Leaf-Binary-Numbers%2F</url>
    <content type="text"><![CDATA[Sum of Root To Leaf Binary Numbers Given a binary tree, each node has value 0 or 1. Each root-to-leaf path represents a binary number starting with the most significant bit. For example, if the path is 0 -&gt; 1 -&gt; 1 -&gt; 0 -&gt; 1, then this could represent 01101 in binary, which is 13. For all leaves in the tree, consider the numbers represented by the path from the root to that leaf. Return the sum of these numbers. 深度优先遍历一波，因为好久没写dsf了，所以特地写一写。1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int result; void dfs(TreeNode* root ,int now)&#123; if(!root-&gt;left &amp;&amp; !root-&gt;right)&#123; result += (now&lt;&lt;1) + root-&gt;val; &#125; int val = (now&lt;&lt;1) + root-&gt;val; if(root-&gt;left) dfs(root-&gt;left, val); if(root-&gt;right) dfs(root-&gt;right, val); &#125; int sumRootToLeaf(TreeNode* root) &#123; result=0; dfs(root,0); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell 逻辑运算符、逻辑表达式详解]]></title>
    <url>%2F2019%2F04%2F19%2FLinux-shell-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6%E3%80%81%E9%80%BB%E8%BE%91%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[转载自：马哥Linux运维 shell的逻辑运算符 涉及有以下几种类型，因此只要适当选择，可以解决我们很多复杂的判断，达到事半功倍效果。 逻辑运算符逻辑卷标表示意思关于档案与目录的侦测逻辑卷标-f 常用！侦测『档案』是否存在 eg: if [ -f filename ] -d 常用！侦测『目录』是否存在 -b 侦测是否为一个『 block 档案』 -c 侦测是否为一个『 character 档案』 -S 侦测是否为一个『 socket 标签档案』 -L 侦测是否为一个『 symbolic link 的档案』 -e 侦测『某个东西』是否存在！ 关于程序的逻辑卷标-G 侦测是否由 GID 所执行的程序所拥有 -O 侦测是否由 UID 所执行的程序所拥有 -p 侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！） 关于档案的属性侦测-r 侦测是否为可读的属性 -w 侦测是否为可以写入的属性 -x 侦测是否为可执行的属性 -s 侦测是否为『非空白档案』 -u 侦测是否具有『 SUID 』的属性 -g 侦测是否具有『 SGID 』的属性 -k 侦测是否具有『 sticky bit 』的属性 两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]-nt 第一个档案比第二个档案新 -ot 第一个档案比第二个档案旧 -ef 第一个档案与第二个档案为同一个档案（ link 之类的档案） 逻辑的『和(and)』『或(or)』&amp;&amp; 逻辑的 AND 的意思 || 逻辑的 OR 的意思 运算符号 代表意义= 等于 应用于：整型或字符串比较 如果在[] 中，只能是字符串 !=不等于 应用于：整型或字符串比较 如果在[] 中，只能是字符串 &lt; 小于 应用于：整型比较 在[] 中，不能使用 表示字符串 > 大于 应用于：整型比较 在[] 中，不能使用 表示字符串 -eq 等于 应用于：整型比较 -ne 不等于 应用于：整型比较 -lt 小于 应用于：整型比较 -gt 大于 应用于：整型比较 -le 小于或等于 应用于：整型比较 -ge 大于或等于 应用于：整型比较 -a 双方都成立（and） 逻辑表达式 –a 逻辑表达式 -o 单方成立（or） 逻辑表达式 –o 逻辑表达式 -z 空字符串 -n 非空字符串 逻辑表达式test 命令使用方法：test EXPRESSION 如：123456789101112131415[root@localhost ~]# test 1 = 1 &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# test -d /etc/ &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# test 1 -eq 1 &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# if test 1 = 1 ; then echo &apos;ok&apos;; fiok 注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。 精简表达式[] 表达式1234567891011121314151617[root@localhost ~]# [ 1 -eq 1 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# [ 2 &lt; 1 ] &amp;&amp; echo &apos;ok&apos;-bash: 2: No such file or directory[root@localhost ~]# [ 2 &lt; 1 ] &amp;&amp; echo &apos;ok&apos;[root@localhost ~]# [ 2 -gt 1 -a 3 -lt 4 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# [ 2 -gt 1 &amp;&amp; 3 -lt 4 ] &amp;&amp; echo &apos;ok&apos;-bash: [: missing `]&apos; 注意：在[] 表达式中，常见的&gt;,&lt;需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持&lt;&gt;运算符，还有逻辑运算符|| &amp;&amp; 它需要用-a[and] –o[or]表示 [[]] 表达式1234567891011[root@localhost ~]# [ 1 -eq 1 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]$ [[ 2 &lt; 3 ]] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]$ [[ 2 &lt; 3 &amp;&amp; 4 &gt; 5 ]] &amp;&amp; echo &apos;ok&apos;ok 注意：[[]] 运算符只是[]运算符的扩充。能够支持&lt;,&gt;符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &amp;&amp; 性能比较bash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容&gt;&lt;之类的运算符。以下是比较它们性能，发现[[]]是最快的。1234567891011121314151617181920212223$ time (for m in &#123;1..100000&#125;; do test -d .;done;)real 0m0.658suser 0m0.558ssys 0m0.100s$ time (for m in &#123;1..100000&#125;; do [ -d . ];done;)real 0m0.609suser 0m0.524ssys 0m0.085s$ time (for m in &#123;1..100000&#125;; do [[ -d . ]];done;)real 0m0.311suser 0m0.275ssys 0m0.036s 不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode136. Single Number]]></title>
    <url>%2F2019%2F04%2F17%2FLeetcode136-Single-Number%2F</url>
    <content type="text"><![CDATA[Single NumberEasy Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?1234Example 1:Input: [2,2,1]Output: 1 1234Example 2:Input: [4,1,2,1,2]Output: 4 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。算法应该具有线性时间复杂度。且可以不使用额外空间来实现。 我的：12345678910class Solution &#123;public: int singleNumber(vector&lt;int&gt;&amp; nums) &#123; int a=0; for(int i=0;i&lt;nums.size();i++)&#123; a ^= nums[i]; &#125; return a; &#125;&#125;; 复杂些的：有一个 n 个元素的数组，除了两个数只出现一次外，其余元素都出现两次，让你找出这两个只出现一次的数分别是几，要求时间复杂度为 O(n) 且再开辟的内存空间固定(与 n 无关)。 示例 :输入: [1,2,2,1,3,4]输出: [3,4] 根据前面找一个不同数的思路算法，在这里把所有元素都异或，那么得到的结果就是那两个只出现一次的元素异或的结果。 然后，因为这两个只出现一次的元素一定是不相同的，所以这两个元素的二进制形式肯定至少有某一位是不同的，即一个为 0 ，另一个为 1 ，现在需要找到这一位。 根据异或的性质 任何一个数字异或它自己都等于 0，得到这个数字二进制形式中任意一个为 1 的位都是我们要找的那一位。 再然后，以这一位是 1 还是 0 为标准，将数组的 n 个元素分成两部分。 将这一位为 0 的所有元素做异或，得出的数就是只出现一次的数中的一个 将这一位为 1 的所有元素做异或，得出的数就是只出现一次的数中的另一个。 这样就解出题目。忽略寻找不同位的过程，总共遍历数组两次，时间复杂度为O(n)。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于可重入、线程安全、异步信号安全几个概念的理解]]></title>
    <url>%2F2019%2F04%2F17%2F%E5%AF%B9%E4%BA%8E%E5%8F%AF%E9%87%8D%E5%85%A5%E3%80%81%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E3%80%81%E5%BC%82%E6%AD%A5%E4%BF%A1%E5%8F%B7%E5%AE%89%E5%85%A8%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/lg1259156776/article/details/52732879 由于前段时间，程序偶尔异常挂起不工作，检查后发现时死锁了，原因就是：在信号处理函数里面调用了fprintf. printf等io函数是需要对输出缓冲区加锁，这类函数对本身是线程安全的，但是对信号处理函数来说是不可重入的（在没有返回之前，不能再次调用），即不是异步信号安全的。 对于printf这类函数，可以这样理解：它们使用了全局数据结构（iobuffer），所以不是线程安全的（多个线程同时访问共享资源），也是不可重入的（有共享资源，可能损坏）； 通过加锁可以变得线程安全，但是仍然不可重入。 对于返回值共享的函数可以通过自己传入地址的方式变得线程可以重入（即线程安全）“_r”类函数。 如果一个函数返回一个静态地址（如上），同时又使用了全局资源（已经加锁保护），那么即使使用上了的_r方法变得线程可以重入，也不代表信号处理函数可以重入（即异步信号安全）。 一个可重入的函数简单来说就是可以被中断的函数，也就是说，可以在这个函数执行的任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现什么错误。《多线程编程指南》中定义，可以被信号控制器安全调用的函数被称为”异步信号安全”函数。因此，我认为可重入与异步信号安全是一个概念。 有人将可重入函数与线程安全函数混为一谈，我认为是不正确的。 这里引用CSAPP中的描述来说明一下： CSAPP13.7.1 线程安全一个函数被称为线程安全的，当且仅当被多个并发线程反复的调用时，它会一直产生正确的结果。13.7.2 可重入性有一类重要的线程安全函数，叫做可重入函数，其特点在于它们具有一种属性：当它们被多个线程调用时，不会引用任何共享的数据。 尽管线程安全和可重入有时会（不正确的）被用做同义词，但是它们之间还是有清晰的技术差别的。可重入函数是线程安全函数的一个真子集。 重入即表示重复进入，首先它意味着这个函数可以被中断，其次意味着它除了使用自己栈上的变量以外不依赖于任何环境（包括static），这样的函数就是purecode（纯代码）可重入，可以允许有该函数的多个副本在运行，由于它们使用的是分离的栈，所以不会互相干扰。可重入函数是线程安全函数，但是反过来，线程安全函数未必是可重入函数。实际上，可重入函数很少，APUE 10.6节中描述了Single UNIX Specification说明的可重入的函数，只有115个；APUE 12.5节中描述了POSIX.1中不能保证线程安全的函数，只有89个。 信号就像硬件中断一样，会打断正在执行的指令序列。信号处理函数无法判断捕获到信号的时候，进程在何处运行。如果信号处理函数中的操作与打断的函数的操作相同，而且这个操作中有静态数据结构等，当信号处理函数返回的时候（当然这里讨论的是信号处理函数可以返回），恢复原先的执行序列，可能会导致信号处理函数中的操作覆盖了之前正常操作中的数据。不可重入函数的原因在于： 已知它们使用静态数据结构 它们调用malloc和free.因为malloc通常会为所分配的存储区维护一个链接表，而插入执行信号处理函数的时候，进程可能正在修改此链接表。 它们是标准IO函数.因为标准IO库的很多实现都使用了全局数据结构 即使对于可重入函数，在信号处理函数中使用也需要注意一个问题就是errno。一个线程中只有一个errno变量，信号处理函数中使用的可重入函数也有可能会修改errno。例如，read函数是可重入的，但是它也有可能会修改errno。因此，正确的做法是在信号处理函数开始，先保存errno；在信号处理函数退出的时候，再恢复errno。 例如，程序正在调用printf输出，但是在调用printf时，出现了信号，对应的信号处理函数也有printf语句，就会导致两个printf的输出混杂在一起。如果是给printf加锁的话，同样是上面的情况就会导致死锁。对于这种情况，采用的方法一般是在特定的区域屏蔽一定的信号。屏蔽信号的方法： signal(SIGPIPE, SIG_IGN); //忽略一些信号 sigprocmask()sigprocmask只为单线程定义的 pthread_sigmask()pthread_sigmasks可以在多线程中使用 现在看来信号异步安全和可重入的限制似乎是一样的，所以这里把它们等同看待;-) 线程安全线程安全：如果一个函数在同一时刻可以被多个线程安全的调用，就称该函数是线程安全的。 不需要共享时，请为每个线程提供一个专用的数据副本。如果共享非常重要，则提供显式同步，以确保程序以确定的方式操作。通过将过程包含在语句中来锁定和解除锁定互斥，可以使不安全过程变成线程安全过程，而且可以进行串行化。 很多函数并不是线程安全的，因为他们返回的数据是存放在静态的内存缓冲区中的。通过修改接口，由调用者自行提供缓冲区就可以使这些函数变为线程安全的。操作系统实现支持线程安全函数的时候，会对POSIX.1中的一些非线程安全的函数提供一些可替换的线程安全版本。例如,gethostbyname()是线程不安全的，在Linux中提供了gethostbyname_r()的线程安全实现。函数名字后面加上”_r”，以表明这个版本是可重入的（对于线程可重入，也就是说是线程安全的，但并不是说对于信号处理函数也是可重入的，或者是异步信号安全的）。 多线程程序中常见的疏忽性问题 将指针作为新线程的参数传递给调用方栈。 在没有同步机制保护的情况下访问全局内存的共享可更改状态。 两个线程尝试轮流获取对同一对全局资源的权限时导致死锁。其中一个线程控制第一种资源，另一个线程控制第二种资源。其中一个线程放弃之前，任何一个线程都无法继续操作。 尝试重新获取已持有的锁（递归死锁）。 在同步保护中创建隐藏的间隔。如果受保护的代码段包含的函数释放了同步机制，而又在返回调用方之前重新获取了该同步机制，则将在保护中出现此间隔。结果具有误导性。对于调用方，表面上看全局数据已受到保护，而实际上未受到保护。 将UNIX 信号与线程混合时，使用sigwait(2) 模型来处理异步信号。 调用setjmp(3C) 和longjmp(3C)，然后长时间跳跃，而不释放互斥锁。 从对_cond_wait() 或_cond_timedwait() 的调用中返回后无法重新评估条件。 总结判断一个函数是不是可重入函数，在于判断其能否可以被打断，打断后恢复运行能够得到正确的结果。（打断执行的指令序列并不改变函数的数据）判断一个函数是不是线程安全的，在于判断其能否在多个线程同时执行其指令序列的时候，保证每个线程都能够得到正确的结果。 如果一个函数对多个线程来说是可重入的，则说这个函数是线程安全的，但这并不能说明对信号处理程序来说该函数也是可重入的。如果函数对异步信号处理程序的重入是安全的，那么就可以说函数是”异步-信号安全”的。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux程序加载过程]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E7%A8%8B%E5%BA%8F%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/hnzziafyz/article/details/52200265 一个进程在内存中主要占用了以下几个部分，分别是代码段、数据段、BSS，栈，堆，等参数。其中，代码、数据、BSS的内容是可执行文件中对应的内容，加载程序并不是把它们的内容从可执行程序中填充到内存中，而是将它们的信息（基地址、长度等）更新到进程控制块（task_struct）中，当CPU第 一次实际寻址执行的时候，就会引起缺页中断，操作系统再将实际的内容从可执行文件中复制内容到物理内存中。 堆的内容是程序执行中动态分配的，所以加载程序 只是将它的起始地址更新到进程控制块中，执行过程中遇到动态分配内存的操作的时候再在物理内存分配实际的页。参数区在新进程加载的时候要存入环境变量和命令行参数列表。栈在程序加载时候存入的内容就是环境参数列表和命令行参数列表的指针和命令行参数的个数。 1）在shell界面输入./可执行文件名。经shell分析，该参数非shell内建命令，则认为是加载可执行文件。于是调用fork函数开始创建新进程，产生0x80中断，映射到函数sys_fork()中，调用find_empty_process()函数，为新进程申请一个可用的进程号。 2）为可执行程序的管理结构找到存储空间。为了实现对进程的保护，系统为每个进程的管理专门设计了一个结构，即task_struct。内核通过调用get_free_page函数获得用于保存task_struct和内核栈的页面只能在内核的线性地址空间。 3）shell进程为新进程复制task_struct结构。行程序复制了task_struct后，新进程便继承了shell的全部管理信息。但由于每个进程呢的task_struct结构中的信息是不一样的，所以还要对该结构进行个性化设置（为防止在设置的过程中被切换到该进程，应先设置为不可中断状态）。个性化设置主要包括进程号、父进程、时间片、TSS段（为进程间切换而设计的，进程的切换时建立在对进程的保护的基础上的，在进程切换时TSS用来保存或恢复该进程的现场所用到的寄存器的值）。这些都是通过函数copy_process来完成的。 4）复制新进程页表并设置其对应的页目录项。现在调用函数copy_mem为进程分段（LDT），更新代码段和数据段的基地址，即确定线性地址空间（关键在于确定段基址和限长）。接着就是分页，分页是建立在分段的基础上的。 5）建立新进程与全局描述符（GDT）的关联，将新进程的TSS和LDT挂接在GDT的指定位置处。（注：TSS和LDT对进程的保护至关重要） 6）将新进程设置为就绪状态 7）加载可执行文件。进入do_execve函数之后，将可执行文件的头表加载到内存中并检测相关信息。加载执行程序（讲程序按需加载到内存）。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存描述符mm_struct实例详解]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E5%86%85%E5%AD%98%E6%8F%8F%E8%BF%B0%E7%AC%A6mm-struct%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux对于内存的管理涉及到非常多的方面，这篇文章首先从对进程虚拟地址空间的管理说起，具体实例代码大家通过本文学习下吧Linux对于内存的管理涉及到非常多的方面，这篇文章首先从对进程虚拟地址空间的管理说起。(所依据的代码是2.6.32.60） 无论是内核线程还是用户进程，对于内核来说，无非都是task_struct这个数据结构的一个实例而已，task_struct被称为进程描述符（process descriptor),因为它记录了这个进程所有的context。其中有一个被称为’内存描述符‘（memory descriptor)的数据结构mm_struct，抽象并描述了Linux视角下管理进程地址空间的所有信息。 mm_struct定义在include/linux/mm_types.h中，其中的域抽象了进程的地址空间，如下图所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091struct mm_struct &#123; struct vm_area_struct * mmap; //指向虚拟区间(VMA)的链表 struct rb_root mm_rb; //指向线性区对象红黑树的根 struct vm_area_struct * mmap_cache; //指向最近找到的虚拟区间 unsigned long(*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags);//在进程地址空间中搜索有效线性地址区 unsigned long(*get_unmapped_exec_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); void(*unmap_area) (struct mm_struct *mm, unsigned long addr);//释放线性地址区间时调用的方法 unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ unsigned long cached_hole_size; unsigned long free_area_cache; //内核从这个地址开始搜索进程地址空间中线性地址的空闲区域 pgd_t * pgd; //指向页全局目录 atomic_t mm_users; //次使用计数器，使用这块空间的个数 atomic_t mm_count; //主使用计数器 int map_count; //线性的个数 struct rw_semaphore mmap_sem; //线性区的读/写信号量 spinlock_t page_table_lock; //线性区的自旋锁和页表的自旋锁 struct list_head mmlist; //指向内存描述符链表中的相邻元素 /* Special counters, in some configurations protected by the * page_table_lock, in other configurations by being atomic. */ mm_counter_t _file_rss; //mm_counter_t代表的类型实际是typedef atomic_long_t mm_counter_t _anon_rss; mm_counter_t _swap_usage; unsigned long hiwater_rss; //进程所拥有的最大页框数 unsigned long hiwater_vm; //进程线性区中最大页数 unsigned long total_vm, locked_vm, shared_vm, exec_vm; //total_vm 进程地址空间的大小(页数） //locked_vm 锁住而不能换出的页的个数 //shared_vm 共享文件内存映射中的页数 unsigned long stack_vm, reserved_vm, def_flags, nr_ptes; //stack_vm 用户堆栈中的页数 //reserved_vm 在保留区中的页数或者在特殊线性区中的页数 //def_flags 线性区默认的访问标志 //nr_ptes 进程的页表数 unsigned long start_code, end_code, start_data, end_data; //start_code 可执行代码的起始地址 //end_code 可执行代码的最后地址 //start_data已初始化数据的起始地址 // end_data已初始化数据的最后地址 unsigned long start_brk, brk, start_stack; //start_stack堆的起始位置 //brk堆的当前的最后地址 //用户堆栈的起始地址 unsigned long arg_start, arg_end, env_start, env_end; //arg_start 命令行参数的起始地址 //arg_end命令行参数的起始地址 //env_start环境变量的起始地址 //env_end环境变量的最后地址 unsigned long saved_auxv[AT_VECTOR_SIZE]; /* for /proc/PID/auxv */ struct linux_binfmt *binfmt; cpumask_t cpu_vm_mask; //用于惰性TLB交换的位掩码 /* Architecture-specific MM context */ mm_context_t context; //指向有关特定结构体系信息的表 unsigned int faultstamp; unsigned int token_priority; unsigned int last_interval; unsigned long flags; /* Must use atomic bitops to access the bits */ struct core_state *core_state; /* coredumping support */#ifdef CONFIG_AIO spinlock_t ioctx_lock; //用于保护异步I/O上下文链表的锁 struct hlist_head ioctx_list;//异步I/O上下文#endif#ifdef CONFIG_MM_OWNER struct task_struct *owner;#endif#ifdef CONFIG_PROC_FS unsigned long num_exe_file_vmas;#endif#ifdef CONFIG_MMU_NOTIFIER struct mmu_notifier_mm *mmu_notifier_mm;#endif#ifdef CONFIG_TRANSPARENT_HUGEPAGE pgtable_t pmd_huge_pte; /* protected by page_table_lock */#endif#ifdef __GENKSYMS__ unsigned long rh_reserved[2];#else //有多少任务分享这个mm OOM_DISABLE union &#123; unsigned long rh_reserved_aux; atomic_t oom_disable_count; &#125;; /* base of lib map area (ASCII armour) */ unsigned long shlib_base;#endif&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux信号（signal) 机制分析]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E4%BF%A1%E5%8F%B7%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[【摘要】本文分析了Linux内核对于信号的实现机制和应用层的相关处理。首先介绍了软中断信号的本质及信号的两种不同分类方法尤其是不可靠信号的原理。接着分析了内核对于信号的处理流程包括信号的触发/注册/执行及注销等。最后介绍了应用层的相关处理，主要包括信号处理函数的安装、信号的发送、屏蔽阻塞等，最后给了几个简单的应用实例。 中断和异常中断（也称硬件中断）定义：中断是由其他硬件设备依照CPU时钟周期信号随机产生的。分类： 可屏蔽中断、非可屏蔽中断来源：间隔定时器和I/O 异常（也称软件中断）定义：当指令执行时由CPU控制单元产生的，异常也称为“异步中断”是因为只有在 一条指令终止执行后CPU才会发出中断。分类： 处理器探测到的异常、故障、陷阱、异常终止、编程异常(也称软中断)、int指令来源：程序的错误产生的内核必须处理的异常(例如：缺页和内核服务的请求-int) 异常处理当发生异常时，CPU控制单元产生一个硬件出错码。CPU根据该中断吗找到中断向量表内的对应向量，根据该向量转到中断处理程序。中断处理程序处理完之后向当前进程发送一个SIG***信号。若进程定义了相应的信号处理程序则转移到相应的程序执行，若没有，则执行内核定义的操作。 中断处理设备产生中断，PIC（可编程中断控制器）会产生一个对应的中断向量和中断向量表中的每一个中断向量进行比较，转到对应的中断处理程序，中断处理程序进行保存现场，做相关处理，恢复现场，内核调度，返回用户进程。 硬件中断的上半部和下半部及实现方式硬件中断的分类 紧急的 —— 这类中断必须立即执行 非紧急的 —— 也必须立即执行 非紧急可延迟的 —— 上半部立即执行，下半部延迟执行 硬件中断任务（处理程序）是一个快速、异步、简单地对硬件做出迅速响应并在最短时间内完成必要操作的中断处理程序。硬中断处理程序可以抢占内核任务并且执 行时还会屏蔽同级中断或其它中断，因此中断处理必须要快、不能阻塞。这样一来对于一些要求处理过程比较复杂的任务就不合适在中断任务中一次处理。比如，网卡接收数据的过程中,首先网卡发送中断信号告诉CPU来取数据，然后系统从网卡中读取数据存入系统缓冲区中，再下来解析数据然后送入应用层。这些如果都让中断处理程序来处理显然过程太长，造成新来的中断丢失。因此Linux开发人员将这种任务分割为两个部分，一个叫上底，即中断处理程序，短平快地处理与硬 件相关的操作（如从网卡读数据到系统缓存）；而把对时间要求相对宽松的任务（如解析数据的工作）放在另一个部分执行，这个部分就是我们这里要讲的下半底。 下半底是一种推后执行任务，它将某些不那么紧迫的任务推迟到系统更方便的时刻运行。因为并不是非常紧急，通常还是比较耗时的，因此由系统自行安排运行时机，不在中断服务上下文中执行。内核中实现 下半底的手段经过不断演化，目前已经从最原始的BH(bottom thalf)演生出BH、任务队列（Task queues）、软中断（Softirq）、Tasklet、工作队列（Work queues）（2.6内核中新出现的）。 关于软中断和硬中断的其它解析：软中断一般是指由指令int引起的“伪”中断动作——给CPU制造一个中断的假象；而硬中断则是实实在在由8259的连线触发的中断。因此，严格的 讲，int与IRQ毫无关系，但二者均与中断向量有关系。int引起的中断，CPU是从指令中取得中断向量号；而IRQ引起的中断，CPU必须从数据线上取回中断号，接下来CPU的工作就一样了：保护现场、根据中断号得到中断处理程序地址、执行中断处理、恢复现场继续执行被中断的指令。 在软中断和硬中断之间的区别是什么？ 硬中断是由外部事件引起的因此具有随机性和突发性；软中断是执行中断指令产生的，无面外部施加中断请求信 号，因此中断的发生不是随机的而是由程序安排好的。 硬中断的中断响应周期，CPU需要发中断回合信号（NMI不需要），软中断的中断响应周 期，CPU不需发中断回合信号。 硬中断的中断号是由中断控制器提供的（NMI硬中断中断号系统指定为02H）；软中断的中断号由指令直接给出， 无需使用中断控制器。 硬中断是可屏蔽的（NMI硬中断不可屏蔽），软中断不可屏蔽。 硬中断： 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。 处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主CPU的支持下，可以同时处理多个中断。）。 硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。 对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。 软中断： 软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。 通常，软中断是一些对I/O的请求。这些请求会调用内核中可以调度I/O发生的程序。对于某些设备，I/O请求需要被立即处理，而磁盘I/O请求通常可以排队并且可以稍后处理。根据I/O模型的不同，进程或许会被挂起直到I/O完成，此时内核调度器就会选择另一个进程去运行。I/O可以在进程之间产生并且调度过程通常和磁盘I/O的方式是相同。 软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。 软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。 信号本质软中断信号（signal，又简称为信号）用来通知进程发生了异步事件。在软件层次上是对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是进程间通信机制中唯一的异步通信机制，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。 产生信号的条件主要有： 用户在终端 按下某些键时，终端驱动程序会发送信号给前台进程，例如Ctrl-C产生SIGINT信 号，Ctrl-/产生SIGQUIT信号，Ctrl-Z产生SIGTSTP信号。 硬件异常产生信号，这些条件由硬件检测到并通知内核，然后内核向当前进程发送适当的信号。例如当前进程执行了 除以0的指令，CPU的运算单元会产生异常，内核将这个异常解释为SIGFPE信号发送给进 程。再比如当前进程访问了非法内存地址，，MMU会产生异常，内核将这个异常解释为SIGSEGV信 号发送给进程。 一个进程调用kill(2)函数可以发送信 号给另一个进程。 可以用kill(1)命令发送信号给某个 进程，kill(1)命令也是调用kill(2)函 数实现的，如果不明确指定信号则发送SIGTERM信号，该信号的默认处理动作是终止进程。 当内核检测到某种软件条件发生时也可以通过信号通知进程，例如闹钟超时产生SIGALRM信 号，向读端已关闭的管道写数据时产生SIGPIPE信号。 收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类： 第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。 第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。 第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。 信号的种类可以从两个不同的分类角度对信号进行分类： 可靠性方面：可靠信号与不可靠信号； 与时间的关系上：实时信号与非实时信号。 可靠信号与不可靠信号Linux信号机制基本上是从Unix系统中继承过来的。早期Unix系统中的信号机制比较简单和原始，信号值小于SIGRTMIN的信号都是不可靠信号。这就是”不可靠信号”的来源。它的主要问题是信号可能丢失。 随着时间的发展，实践证明了有必要对信号的原始机制加以改进和扩充。由于原来定义的信号已有许多应用，不好再做改动，最终只好又新增加了一些信号，并在一开始就把它们定义为可靠信号，这些信号支持排队，不会丢失。 信号值位于SIGRTMIN和SIGRTMAX之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。Linux在支持新版本的信号安装函数sigation()以及信号发送函数sigqueue()的同时，仍然支持早期的signal()信号安装函数，支持信号发送函数kill()。 信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前linux中的signal()是通过sigation()函数实现的，因此，即使通过signal()安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal()安装的实时信号支持排队，同样不会丢失。 对于目前linux的两个信号安装函数：signal()及sigaction()来说，它们都不能把SIGRTMIN以前的信号变成可靠信号（都不支持排队，仍有可能丢失，仍然是不可靠信号），而且对SIGRTMIN以后的信号都支持排队。这两个函数的最大区别在于，经过sigaction安装的信号都能传递信息给信号处理函数，而经过signal安装的信号不能向信号处理函数传递信息。对于信号发送函数来说也是一样的。 实时信号与非实时信号早期Unix系统只定义了32种信号，前32种信号已经有了预定义值，每个信号有了确定的用途及含义，并且每种信号都有各自的缺省动作。如按键盘的CTRL ^C时，会产生SIGINT信号，对该信号的默认反应就是进程终止。后32个信号表示实时信号，等同于前面阐述的可靠信号。这保证了发送的多个实时信号都被接收。 非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。 信号处理流程对于一个完整的信号生命周期(从信号发送到相应的处理函数执行完毕)来说，可以分为三个阶段： 信号诞生 信号在进程中注册 信号的执行和注销 信号诞生信号事件的发生有两个来源：硬件来源(比如我们按下了键盘或者其它硬件故障)；软件来源，最常用发送信号的系统函数是kill, raise, alarm和setitimer以及sigqueue函数，软件来源还包括一些非法运算等操作。 这里按发出信号的原因简单分类，以了解各种信号： 与进程终止相关的信号。当进程退出，或者子进程终止时，发出这类信号。 与进程例外事件相关的信号。如进程越界，或企图写一个只读的内存区域（如程序正文区），或执行一个特权指令及其他各种硬件错误。 与在系统调用期间遇到不可恢复条件相关的信号。如执行系统调用exec时，原有资源已经释放，而目前系统资源又已经耗尽。 与执行系统调用时遇到非预测错误条件相关的信号。如执行一个并不存在的系统调用。 在用户态下的进程发出的信号。如进程调用系统调用kill向其他进程发送信号。 与终端交互相关的信号。如用户关闭一个终端，或按下break键等情况。 跟踪进程执行的信号。 Linux支持的信号列表如下。很多信号是与机器的体系结构相关的 (1) SIGHUP：当用户退出Shell时，由该Shell启的发所有进程都退接收到这个信号，默认动作为终止进程。 (2) SIGINT：用户按下组合键时，用户端时向正在运行中的由该终端启动的程序发出此信号。默认动作为终止进程。 (3) SIGQUIT：当用户按下组合键时产生该信号，用户终端向正在运行中的由该终端启动的程序发出此信号。默认动作为终止进程并产生core文件。 (4) SIGILL ：CPU检测到某进程执行了非法指令。默认动作为终止进程并产生core文件。 (5) SIGTRAP：该信号由断点指令或其他trap指令产生。默认动作为终止进程并产生core文件。 (6) SIGABRT：调用abort函数时产生该信号。默认动作为终止进程并产生core文件。 (7) SIGBUS：非法访问内存地址，包括内存地址对齐（alignment）出错，默认动作为终止进程并产生core文件。 (8) SIGFPE：在发生致命的算术错误时产生。不仅包括浮点运行错误，还包括溢出及除数为0等所有的算术错误。默认动作为终止进程并产生core文件。 (9) SIGKILL：无条件终止进程。本信号不能被忽略、处理和阻塞。默认动作为终止进程。它向系统管理员提供了一种可以杀死任何进程的方法。 (10) SIGUSR1：用户定义的信号，即程序可以在程序中定义并使用该信号。默认动作为终止进程。 (11) SIGSEGV：指示进程进行了无效的内存访问。默认动作为终止进程并使用该信号。默认动作为终止进程。 (12) SIGUSR2：这是另外一个用户定义信号，程序员可以在程序中定义并使用该信号。默认动作为终止进程。 (13) SIGPIPE：Broken pipe：向一个没有读端的管道写数据。默认动作为终止进程。 (14) SIGALRM：定时器超时，超时的时间由系统调用alarm设置。默认动作为终止进程。 (15) SIGTERM：程序结束(terminate)信号，与SIGKILL不同的是，该信号可以被阻塞和处理。通常用来要求程序正常退出。执行Shell命令kill时，缺少产生这个信号。默认动作为终止进程。 (17) SIGCHLD：子程序结束时，父进程会收到这个信号。默认动作为忽略该信号。 (18) SIGCONT：让一个暂停的进程继续执行。 (19) SIGSTOP：停止(stopped)进程的执行。注意它和SIGTERM以及SIGINT的区别：该进程还未结束，只是暂停执行。本信号不能被忽略、处理和阻塞。默认作为暂停进程。 (20) SIGTSTP：停止进程的动作，但该信号可以被处理和忽略。按下组合键时发出该信号。默认动作为暂停进程。 (21) SIGTTIN：当后台进程要从用户终端读数据时，该终端中的所有进程会收到SIGTTIN信号。默认动作为暂停进程。 (22) SIGTTOU：该信号类似于SIGTIN，在后台进程要向终端输出数据时产生。默认动作为暂停进程。 (23) SIGURG：套接字（socket）上有紧急数据时，向当前正在运行的进程发出此信号，报告有紧急数据到达。默认动作为忽略该信号。 (24) SIGXCPU：进程执行时间超过了分配给该进程的CPU时间，系统产生该信号并发送给该进程。默认动作为终止进程。 (25) SIGXFSZ：超过文件最大长度的限制。默认动作为yl终止进程并产生core文件。 (26) SIGVTALRM：虚拟时钟超时时产生该信号。类似于SIGALRM，但是它只计算该进程占有用的CPU时间。默认动作为终止进程。 (27) SIGPROF：类似于SIGVTALRM，它不仅包括该进程占用的CPU时间还抱括执行系统调用的时间。默认动作为终止进程。 (28) SIGWINCH：窗口大小改变时发出。默认动作为忽略该信号。 (29) SIGIO：此信号向进程指示发出一个异步IO事件。默认动作为忽略。 (30) SIGPWR：关机。默认动作为终止进程。 (31) SIGRTMIN~SIGRTMAX：Linux的实时信号，它没有固定的含义(或者说可以由用户自由使用)。注意，Linux线程机制使用了前3个实时信号。所有的实时信号的默认动作都是终止进程。 信号在目标进程中注册在进程表的表项中有一个软中断信号域，该域中每一位对应一个信号。内核给一个进程发送软中断信号的方法，是在进程所在的进程表项的信号域设置对应于该信号的位。如果信号发送给一个正在睡眠的进程，如果进程睡眠在可被中断的优先级上，则唤醒进程；否则仅设置进程表中信号域相应的位，而不唤醒进程。如果发送给一个处于可运行状态的进程，则只置相应的域即可。 进程的task_struct结构中有关于本进程中未决信号的数据成员：struct sigpending pending1234struct sigpending&#123; struct sigqueue *head, *tail; sigset_t signal;&#125;; 第三个成员是进程中所有未决信号集，第一、第二个成员分别指向一个sigqueue类型的结构链（称之为”未决信号信息链”）的首尾，信息链中的每个sigqueue结构刻画一个特定信号所携带的信息，并指向下一个sigqueue结构:1234struct sigqueue&#123; struct sigqueue *next; siginfo_t info;&#125; 信号在进程中注册指的就是信号值加入到进程的未决信号集sigset_t signal（每个信号占用一位）中，并且信号所携带的信息被保留到未决信号信息链的某个sigqueue结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。 当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做”可靠信号”。这意味着同一个实时信号可以在同一个进程的未决信号信息链中占有多个sigqueue结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）。 当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册（通过sigset_t signal指示），则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做”不可靠信号”。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个sigqueue结构。 总之信号注册与否，与发送信号的函数（如kill()或sigqueue()等）以及信号安装函数（signal()及sigaction()）无关，只与信号值有关（信号值小于SIGRTMIN的信号最多只注册一次，信号值在SIGRTMIN及SIGRTMAX之间的信号，只要被进程接收到就被注册） 信号的执行和注销内核处理一个进程收到的软中断信号是在该进程的上下文中，因此，进程必须处于运行状态。当其由于被信号唤醒或者正常调度重新获得CPU时，在其从内核空间返回到用户空间时会检测是否有信号等待处理。如果存在未决信号等待处理且该信号没有被进程阻塞，则在运行相应的信号处理函数前，进程会把信号在未决信号链中占有的结构卸掉。 对于非实时信号来说，由于在未决信号信息链中最多只占用一个sigqueue结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）；而对于实时信号来说，可能在未决信号信息链中占用多个sigqueue结构，因此应该针对占用sigqueue结构的数目区别对待：如果只占用一个sigqueue结构（进程只收到该信号一次），则执行完相应的处理函数后应该把信号在进程的未决信号集中删除（信号注销完毕）。否则待该信号的所有sigqueue处理完毕后再在进程的未决信号集中删除该信号。 当所有未被屏蔽的信号都处理完毕后，即可返回用户空间。对于被屏蔽的信号，当取消屏蔽后，在返回到用户空间时会再次执行上述检查处理的一套流程。 内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理。进程只有处理完信号才会返回用户态，进程在用户态下不会有未处理完的信号。 处理信号有三种类型： 进程接收到信号后退出； 进程忽略该信号； 进程收到信号后执行用户设定用系统调用signal的函数。 当进程接收到一个它忽略的信号时，进程丢弃该信号，就象没有收到该信号似的继续运行。如果进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数。而且执行用户定义的函数的方法很巧妙，内核是在用户栈上创建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时，才返回原先进入内核的地方。这样做的原因是用户定义的处理函数不能且不允许在内核态下执行（如果用户定义的函数在内核态下运行的话，用户就可以获得任何权限）。 信号的安装如果进程要处理某一信号，那么就要在进程中安装该信号。安装信号主要用来确定信号值及进程针对该信号值的动作之间的映射关系，即进程将要处理哪个信号；该信号被传递给进程时，将执行何种操作。 linux主要有两个函数实现信号的安装：signal()、sigaction()。其中signal()只有两个参数，不支持信号传递信息，主要是用于前32种非实时信号的安装；而sigaction()是较新的函数（由两个系统调用实现：sys_signal以及sys_rt_sigaction），有三个参数，支持信号传递信息，主要用来与 sigqueue() 系统调用配合使用，当然，sigaction()同样支持非实时信号的安装。sigaction()优于signal()主要体现在支持信号带有参数。 signal()12#include &lt;signal.h&gt;void (*signal(int signum, void (*handler))(int)))(int); 如果该函数原型不容易理解的话，可以参考下面的分解方式来理解：12typedef void (*sighandler_t)(int)；sighandler_t signal(int signum, sighandler_t handler)); 第一个参数指定信号的值，第二个参数指定针对前面信号值的处理，可以忽略该信号（参数设为SIG_IGN）；可以采用系统默认方式处理信号(参数设为SIG_DFL)；也可以自己实现处理方式(参数指定一个函数地址)。 如果signal()调用成功，返回最后一次为安装信号signum而调用signal()时的handler值；失败则返回SIG_ERR。 传递给信号处理例程的整数参数是信号值，这样可以使得一个信号处理例程处理多个信号。1234567891011121314151617181920212223242526#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;void sigroutine(int dunno)&#123; /* 信号处理例程，其中dunno将会得到信号的值 */ switch (dunno) &#123; case 1: printf(&quot;Get a signal -- SIGHUP &quot;); break; case 2: printf(&quot;Get a signal -- SIGINT &quot;); break; case 3: printf(&quot;Get a signal -- SIGQUIT &quot;); break; &#125; return;&#125;int main() &#123; printf(&quot;process id is %d &quot;,getpid()); signal(SIGHUP, sigroutine); //* 下面设置三个信号的处理方法 signal(SIGINT, sigroutine); signal(SIGQUIT, sigroutine); for (;;) ;&#125; 其中信号SIGINT由按下Ctrl-C发出，信号SIGQUIT由按下Ctrl-发出。该程序执行的结果如下：123456789101112localhost:~$ ./sig_testprocess id is 463Get a signal -SIGINT //按下Ctrl-C得到的结果Get a signal -SIGQUIT //按下Ctrl-得到的结果//按下Ctrl-z将进程置于后台 [1]+ Stopped ./sig_testlocalhost:~$ bg [1]+ ./sig_test &amp;localhost:~$ kill -HUP 463 //向进程发送SIGHUP信号localhost:~$ Get a signal – SIGHUPkill -9 463 //向进程发送SIGKILL信号，终止进程localhost:~$ sigaction()12#include &lt;signal.h&gt;int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact)); sigaction函数用于改变进程接收到特定信号后的行为。该函数的第一个参数为信号的值，可以为除SIGKILL及SIGSTOP外的任何一个特定有效的信号（为这两个信号定义自己的处理函数，将导致信号安装错误）。第二个参数是指向结构sigaction的一个实例的指针，在结构sigaction的实例中，指定了对特定信号的处理，可以为空，进程会以缺省方式对信号处理；第三个参数oldact指向的对象用来保存返回的原来对相应信号的处理，可指定oldact为NULL。如果把第二、第三个参数都设为NULL，那么该函数可用于检查信号的有效性。 第二个参数最为重要，其中包含了对指定信号的处理、信号所传递的信息、信号处理函数执行过程中应屏蔽掉哪些信号等等。 sigaction结构定义如下：12345678struct sigaction &#123; union&#123; __sighandler_t _sa_handler; void (*_sa_sigaction)(int,struct siginfo *, void *)； &#125;_u sigset_t sa_mask； unsigned long sa_flags；&#125; 联合数据结构中的两个元素_sa_handler以及*_sa_sigaction指定信号关联函数，即用户指定的信号处理函数。除了可以是用户自定义的处理函数外，还可以为SIG_DFL(采用缺省的处理方式)，也可以为SIG_IGN（忽略信号）。 由_sa_sigaction是指定的信号处理函数带有三个参数，是为实时信号而设的（当然同样支持非实时信号），它指定一个3参数信号处理函数。第一个参数为信号值，第三个参数没有使用，第二个参数是指向siginfo_t结构的指针，结构中包含信号携带的数据值，参数所指向的结构如下： 1234567891011121314151617181920siginfo_t &#123; int si_signo; /* 信号值，对所有信号有意义*/ int si_errno; /* errno值，对所有信号有意义*/ int si_code; /* 信号产生的原因，对所有信号有意义*/ union&#123; /* 联合数据结构，不同成员适应不同信号 */ //确保分配足够大的存储空间 int _pad[SI_PAD_SIZE]; //对SIGKILL有意义的结构 struct&#123; ... &#125;... ... ... ... ... //对SIGILL, SIGFPE, SIGSEGV, SIGBUS有意义的结构 struct&#123; ... &#125;... ... ... &#125;&#125; 前面在讨论系统调用sigqueue发送信号时，sigqueue的第三个参数就是sigval联合数据结构，当调用sigqueue时，该数据结构中的数据就将拷贝到信号处理函数的第二个参数中。这样，在发送信号同时，就可以让信号传递一些附加信息。信号可以传递信息对程序开发是非常有意义的。 sa_mask指定在信号处理程序执行过程中，哪些信号应当被阻塞。缺省情况下当前信号本身被阻塞，防止信号的嵌套发送，除非指定SA_NODEFER或者SA_NOMASK标志位。 注：请注意sa_mask指定的信号阻塞的前提条件，是在由sigaction（）安装信号的处理函数执行过程中由sa_mask指定的信号才被阻塞。 sa_flags中包含了许多标志位，包括刚刚提到的SA_NODEFER及SA_NOMASK标志位。另一个比较重要的标志位是SA_SIGINFO，当设定了该标志位时，表示信号附带的参数可以被传递到信号处理函数中，因此，应该为sigaction结构中的sa_sigaction指定处理函数，而不应该为sa_handler指定信号处理函数，否则，设置该标志变得毫无意义。即使为sa_sigaction指定了信号处理函数，如果不设置SA_SIGINFO，信号处理函数同样不能得到信号传递过来的数据，在信号处理函数中对这些信息的访问都将导致段错误（Segmentation fault）。 信号的发送发送信号的主要函数有：kill()、raise()、 sigqueue()、alarm()、setitimer()以及abort()。 kill()123#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int kill(pid_t pid,int signo) 该系统调用可以用来向任何进程或进程组发送任何信号。参数pid的值为信号的接收进程 pid&gt;0 进程ID为pid的进程 pid=0 同一个进程组的进程 pid&lt;0 pid!=-1 进程组ID为 -pid的所有进程 pid=-1 除发送进程自身外，所有进程ID大于1的进程 Sinno是信号值，当为0时（即空信号），实际不发送任何信号，但照常进行错误检查，因此，可用于检查目标进程是否存在，以及当前进程是否具有向目标发送信号的权限（root权限的进程可以向任何进程发送信号，非root权限的进程只能向属于同一个session或者同一个用户的进程发送信号）。 Kill()最常用于pid&gt;0时的信号发送。该调用执行成功时，返回值为0；错误时，返回-1，并设置相应的错误代码errno。下面是一些可能返回的错误代码： EINVAL：指定的信号sig无效。 ESRCH：参数pid指定的进程或进程组不存在。注意，在进程表项中存在的进程，可能是一个还没有被wait收回，但已经终止执行的僵死进程。 EPERM： 进程没有权力将这个信号发送到指定接收信号的进程。因为，一个进程被允许将信号发送到进程pid时，必须拥有root权力，或者是发出调用的进程的UID 或EUID与指定接收的进程的UID或保存用户ID（savedset-user-ID）相同。如果参数pid小于-1，即该信号发送给一个组，则该错误表示组中有成员进程不能接收该信号。 sigqueue()123#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int sigqueue(pid_t pid, int sig, const union sigval val) 调用成功返回 0；否则，返回 -1。 sigqueue()是比较新的发送信号系统调用，主要是针对实时信号提出的（当然也支持前32种），支持信号带有参数，与函数sigaction()配合使用。 sigqueue的第一个参数是指定接收信号的进程ID，第二个参数确定即将发送的信号，第三个参数是一个联合数据结构union sigval，指定了信号传递的参数，即通常所说的4字节值。1234typedef union sigval &#123; int sival_int; void *sival_ptr;&#125;sigval_t; sigqueue()比kill()传递了更多的附加信息，但sigqueue()只能向一个进程发送信号，而不能发送信号给一个进程组。如果signo=0，将会执行错误检查，但实际上不发送任何信号，0值信号可用于检查pid的有效性以及当前进程是否有权限向目标进程发送信号。 在调用sigqueue时，sigval_t指定的信息会拷贝到对应sig 注册的3参数信号处理函数的siginfo_t结构中，这样信号处理函数就可以处理这些信息了。由于sigqueue系统调用支持发送带参数信号，所以比kill()系统调用的功能要灵活和强大得多。 alarm（）12#include &lt;unistd.h&gt;unsigned int alarm(unsigned int seconds) 系统调用alarm安排内核为调用进程在指定的seconds秒后发出一个SIGALRM的信号。如果指定的参数seconds为0，则不再发送 SIGALRM信号。后一次设定将取消前一次的设定。该调用返回值为上次定时调用到发送之间剩余的时间，或者因为没有前一次定时调用而返回0。 注意，在使用时，alarm只设定为发送一次信号，如果要多次发送，就要多次使用alarm调用。 setitimer（）现在的系统中很多程序不再使用alarm调用，而是使用setitimer调用来设置定时器，用getitimer来得到定时器的状态，这两个调用的声明格式如下：12int getitimer(int which, struct itimerval *value);int setitimer(int which, const struct itimerval *value, struct itimerval *ovalue); 在使用这两个调用的进程中加入以下头文件：1#include &lt;sys/time.h&gt; 该系统调用给进程提供了三个定时器，它们各自有其独有的计时域，当其中任何一个到达，就发送一个相应的信号给进程，并使得计时器重新开始。三个计时器由参数which指定，如下所示： TIMER_REAL：按实际时间计时，计时到达将给进程发送SIGALRM信号。 ITIMER_VIRTUAL：仅当进程执行时才进行计时。计时到达将发送SIGVTALRM信号给进程。 ITIMER_PROF：当进程执行时和系统为该进程执行动作时都计时。与ITIMER_VIR-TUAL是一对，该定时器经常用来统计进程在用户态和内核态花费的时间。计时到达将发送SIGPROF信号给进程。 定时器中的参数value用来指明定时器的时间，其结构如下：1234struct itimerval &#123; struct timeval it_interval; /* 下一次的取值 */ struct timeval it_value; /* 本次的设定值 */&#125;; 该结构中timeval结构定义如下：1234struct timeval &#123; long tv_sec; /* 秒 */ long tv_usec; /* 微秒，1秒 = 1000000 微秒*/&#125;; 在setitimer 调用中，参数ovalue如果不为空，则其中保留的是上次调用设定的值。定时器将it_value递减到0时，产生一个信号，并将it_value的值设定为it_interval的值，然后重新开始计时，如此往复。当it_value设定为0时，计时器停止，或者当它计时到期，而it_interval 为0时停止。调用成功时，返回0；错误时，返回-1，并设置相应的错误代码errno： EFAULT：参数value或ovalue是无效的指针。 EINVAL：参数which不是ITIMER_REAL、ITIMER_VIRT或ITIMER_PROF中的一个。 下面是关于setitimer调用的一个简单示范，在该例子中，每隔一秒发出一个SIGALRM，每隔0.5秒发出一个SIGVTALRM信号：1234567891011121314151617181920212223242526272829303132333435#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;int sec;void sigroutine(int signo) &#123; switch (signo) &#123; case SIGALRM: printf(&quot;Catch a signal -- SIGALRM &quot;); break; case SIGVTALRM: printf(&quot;Catch a signal -- SIGVTALRM &quot;); break; &#125; return;&#125;int main()&#123; struct itimerval value,ovalue,value2; sec = 5; printf(&quot;process id is %d &quot;,getpid()); signal(SIGALRM, sigroutine); signal(SIGVTALRM, sigroutine); value.it_value.tv_sec = 1; value.it_value.tv_usec = 0; value.it_interval.tv_sec = 1; value.it_interval.tv_usec = 0; setitimer(ITIMER_REAL, &amp;value, &amp;ovalue); value2.it_value.tv_sec = 0; value2.it_value.tv_usec = 500000; value2.it_interval.tv_sec = 0; value2.it_interval.tv_usec = 500000; setitimer(ITIMER_VIRTUAL, &amp;value2, &amp;ovalue); for (;;) ;&#125; 该例子的屏幕拷贝如下：12345678localhost:~$ ./timer_testprocess id is 579Catch a signal – SIGVTALRMCatch a signal – SIGALRMCatch a signal – SIGVTALRMCatch a signal – SIGVTALRMCatch a signal – SIGALRMCatch a signal –GVTALRM abort()12#include &lt;stdlib.h&gt;void abort(void); 向进程发送SIGABORT信号，默认情况下进程会异常退出，当然可定义自己的信号处理函数。即使SIGABORT被进程设置为阻塞信号，调用abort()后，SIGABORT仍然能被进程接收。该函数无返回值。 raise()12#include &lt;signal.h&gt;int raise(int signo) 向进程本身发送信号，参数为即将发送的信号值。调用成功返回 0；否则，返回 -1。 信号集及信号集操作函数：信号集被定义为一种数据类型：123typedef struct &#123; unsigned long sig[_NSIG_WORDS]；&#125; sigset_t 信号集用来描述信号的集合，每个信号占用一位。Linux所支持的所有信号可以全部或部分的出现在信号集中，主要与信号阻塞相关函数配合使用。下面是为信号集操作定义的相关函数：1234567891011#include &lt;signal.h&gt;int sigemptyset(sigset_t *set)；int sigfillset(sigset_t *set)；int sigaddset(sigset_t *set, int signum)int sigdelset(sigset_t *set, int signum)；int sigismember(const sigset_t *set, int signum)；sigemptyset(sigset_t *set)初始化由set指定的信号集，信号集里面的所有信号被清空；sigfillset(sigset_t *set)调用该函数后，set指向的信号集中将包含linux支持的64种信号；sigaddset(sigset_t *set, int signum)在set指向的信号集中加入signum信号；sigdelset(sigset_t *set, int signum)在set指向的信号集中删除signum信号；sigismember(const sigset_t *set, int signum)判定信号signum是否在set指向的信号集中。 信号阻塞与信号未决:每个进程都有一个用来描述哪些信号递送到进程时将被阻塞的信号集，该信号集中的所有信号在递送到进程后都将被阻塞。下面是与信号阻塞相关的几个函数：1234#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *set, sigset_t *oldset))；int sigpending(sigset_t *set));int sigsuspend(const sigset_t *mask))； sigprocmask()函数能够根据参数how来实现对信号集的操作，操作主要有三种： SIG_BLOCK 在进程当前阻塞信号集中添加set指向信号集中的信号 SIG_UNBLOCK 如果进程阻塞信号集中包含set指向信号集中的信号，则解除对该信号的阻塞 SIG_SETMASK 更新进程阻塞信号集为set指向的信号集 sigpending(sigset_t *set))获得当前已递送到进程，却被阻塞的所有信号，在set指向的信号集中返回结果。 sigsuspend(const sigset_t *mask))用于在接收到某个信号之前, 临时用mask替换进程的信号掩码, 并暂停进程执行，直到收到信号为止。sigsuspend 返回后将恢复调用之前的信号掩码。信号处理函数完成后，进程将继续执行。该系统调用始终返回-1，并将errno设置为EINTR。 信号应用实例linux下的信号应用并没有想象的那么恐怖，程序员所要做的最多只有三件事情： 安装信号（推荐使用sigaction()）； 实现三参数信号处理函数，handler(int signal,struct siginfo info, void )； 发送信号，推荐使用sigqueue()。 实际上，对有些信号来说，只要安装信号就足够了（信号处理方式采用缺省或忽略）。其他可能要做的无非是与信号集相关的几种操作。 实例一：信号发送及处理实现一个信号接收程序sigreceive（其中信号安装由sigaction（））。12345678910111213141516171819202122232425262728293031#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; int sig; sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=new_op; if(sigaction(sig,&amp;act,NULL) &lt; 0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); &#125;&#125; void new_op(int signum,siginfo_t *info,void *myact)&#123; printf(&quot;receive signal %d&quot;, signum); sleep(5);&#125; 说明，命令行参数为信号值，后台运行sigreceive signo &amp;，可获得该进程的ID，假设为pid，然后再另一终端上运行kill -s signo pid验证信号的发送接收及处理。同时，可验证信号的排队问题。 实例二：信号传递附加信息主要包括两个实例： 向进程本身发送信号，并传递指针参数123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; union sigval mysigval; int i; int sig; pid_t pid; char data[10]; memset(data,0,sizeof(data)); for(i=0;i &lt; 5;i++) data[i]=&apos;2&apos;; mysigval.sival_ptr=data; sig=atoi(argv[1]); pid=getpid(); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op;//三参数信号处理函数 act.sa_flags=SA_SIGINFO;//信息传递开关，允许传说参数信息给new_op if(sigaction(sig,&amp;act,NULL) &lt; 0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); sigqueue(pid,sig,mysigval);//向本进程发送信号，并传递附加信息 &#125;&#125;void new_op(int signum,siginfo_t *info,void *myact)//三参数信号处理函数的实现&#123; int i; for(i=0;i&lt;10;i++) &#123; printf(&quot;%c\n &quot;,(*( (char*)((*info).si_ptr)+i))); &#125; printf(&quot;handle signal %d over;&quot;,signum);&#125; 这个例子中，信号实现了附加信息的传递，信号究竟如何对这些信息进行处理则取决于具体的应用。 不同进程间传递整型参数： 把1中的信号发送和接收放在两个程序中，并且在发送过程中传递整型参数。 信号接收程序：12345678910111213141516171819202122232425262728293031#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; int sig; pid_t pid; pid=getpid(); sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op; act.sa_flags=SA_SIGINFO; if(sigaction(sig,&amp;act,NULL)&lt;0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); &#125;&#125;void new_op(int signum,siginfo_t *info,void *myact)&#123; printf(&quot;the int value is %d \n&quot;,info-&gt;si_int);&#125; 信号发送程序：命令行第二个参数为信号值，第三个参数为接收进程ID。 12345678910111213141516#include &lt;signal.h&gt;#include &lt;sys/time.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;main(int argc,char**argv)&#123; pid_t pid; int signum; union sigval mysigval; signum=atoi(argv[1]); pid=(pid_t)atoi(argv[2]); mysigval.sival_int=8;//不代表具体含义，只用于说明问题 if(sigqueue(pid,signum,mysigval)==-1) printf(&quot;send error\n&quot;); sleep(2);&#125; 注：实例2的两个例子侧重点在于用信号来传递信息，目前关于在linux下通过信号传递信息的实例非常少，倒是Unix下有一些，但传递的基本上都是关于传递一个整数 实例三：信号阻塞及信号集操作12345678910111213141516171819202122232425262728293031323334#include &quot;signal.h&quot;#include &quot;unistd.h&quot;static void my_op(int);main()&#123; sigset_t new_mask,old_mask,pending_mask; struct sigaction act; sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=(void*)my_op; if(sigaction(SIGRTMIN+10,&amp;act,NULL)) printf(&quot;install signal SIGRTMIN+10 error\n&quot;); sigemptyset(&amp;new_mask); sigaddset(&amp;new_mask,SIGRTMIN+10); if(sigprocmask(SIG_BLOCK, &amp;new_mask,&amp;old_mask)) printf(&quot;block signal SIGRTMIN+10 error\n&quot;); sleep(10); printf(&quot;now begin to get pending mask and unblock SIGRTMIN+10\n&quot;); if(sigpending(&amp;pending_mask)&lt;0) printf(&quot;get pending mask error\n&quot;); if(sigismember(&amp;pending_mask,SIGRTMIN+10)) printf(&quot;signal SIGRTMIN+10 is pending\n&quot;); if(sigprocmask(SIG_SETMASK,&amp;old_mask,NULL)&lt;0) printf(&quot;unblock signal error\n&quot;); printf(&quot;signal unblocked\n&quot;); sleep(10);&#125;static void my_op(int signum)&#123; printf(&quot;receive signal %d \n&quot;,signum);&#125; 编译该程序，并以后台方式运行。在另一终端向该进程发送信号(运行kill -s 42 pid，SIGRTMIN+10为42)，查看结果可以看出几个关键函数的运行机制，信号集相关操作比较简单。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核poll/epoll/select实现剖析]]></title>
    <url>%2F2019%2F04%2F12%2FLinux%E5%86%85%E6%A0%B8poll_select_epoll%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[poll/select/epoll的实现都是基于文件提供的poll方法(f_op-&gt;poll)，该方法利用poll_table提供的_qproc方法向文件内部事件掩码_key对应的的一个或多个等待队列(wait_queue_head_t)上添加包含唤醒函数(wait_queue_t.func)的节点(wait_queue_t)，并检查文件当前就绪的状态返回给poll的调用者(依赖于文件的实现)。当文件的状态发生改变时(例如网络数据包到达)，文件就会遍历事件对应的等待队列并调用回调函数(wait_queue_t.func)唤醒等待线程。 通常的file.f_ops.poll实现及相关结构体如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105struct file &#123; const struct file_operations *f_op; spinlock_t f_lock; // 文件内部实现细节 void *private_data; #ifdef CONFIG_EPOLL /* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head f_ep_links; struct list_head f_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */ // 其他细节.... &#125;; // 文件操作 struct file_operations &#123; // 文件提供给poll/select/epoll // 获取文件当前状态, 以及就绪通知接口函数 unsigned int (*poll) (struct file *, struct poll_table_struct *); // 其他方法read/write 等... ... &#125;; // 通常的file.f_ops.poll 方法的实现 unsigned int file_f_op_poll (struct file *filp, struct poll_table_struct *wait) &#123; unsigned int mask = 0; wait_queue_head_t * wait_queue; //1. 根据事件掩码wait-&gt;key_和文件实现filep-&gt;private_data 取得事件掩码对应的一个或多个wait queue head some_code(); // 2. 调用poll_wait 向获得的wait queue head 添加节点 poll_wait(filp, wait_queue, wait); // 3. 取得当前就绪状态保存到mask some_code(); return mask; &#125; // select/poll/epoll 向文件注册就绪后回调节点的接口结构 typedef struct poll_table_struct &#123; // 向wait_queue_head 添加回调节点(wait_queue_t)的接口函数 poll_queue_proc _qproc; // 关注的事件掩码, 文件的实现利用此掩码将等待队列传递给_qproc unsigned long _key; &#125; poll_table; typedef void (*poll_queue_proc)(struct file *, wait_queue_head_t *, struct poll_table_struct *); // 通用的poll_wait 函数, 文件的f_ops-&gt;poll 通常会调用此函数 static inline void poll_wait(struct file * filp, wait_queue_head_t * wait_address, poll_table *p) &#123; if (p &amp;&amp; p-&gt;_qproc &amp;&amp; wait_address) &#123; // 调用_qproc 在wait_address 上添加节点和回调函数 // 调用 poll_table_struct 上的函数指针向wait_address添加节点, 并设置节点的func // (如果是select或poll 则是 __pollwait, 如果是 epoll 则是 ep_ptable_queue_proc), p-&gt;_qproc(filp, wait_address, p); &#125; &#125; // wait_queue 头节点 typedef struct __wait_queue_head wait_queue_head_t; struct __wait_queue_head &#123; spinlock_t lock; struct list_head task_list; &#125;; // wait_queue 节点 typedef struct __wait_queue wait_queue_t; struct __wait_queue &#123; unsigned int flags; #define WQ_FLAG_EXCLUSIVE 0x01 void *private; wait_queue_func_t func; struct list_head task_list; &#125;; typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key); // 当文件的状态发生改变时, 文件会调用此函数，此函数通过调用wait_queue_t.func通知poll的调用者 // 其中key是文件当前的事件掩码 void __wake_up(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, void *key) &#123; unsigned long flags; spin_lock_irqsave(&amp;q-&gt;lock, flags); __wake_up_common(q, mode, nr_exclusive, 0, key); spin_unlock_irqrestore(&amp;q-&gt;lock, flags); &#125; static void __wake_up_common(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, int wake_flags, void *key) &#123; wait_queue_t *curr, *next; // 遍历并调用func 唤醒, 通常func会唤醒调用poll的线程 list_for_each_entry_safe(curr, next, &amp;q-&gt;task_list, task_list) &#123; unsigned flags = curr-&gt;flags; if (curr-&gt;func(curr, mode, wake_flags, key) &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive) &#123; break; &#125; &#125; &#125; poll 和 selectpoll和select的实现基本上是一致的，只是传递参数有所不同，他们的基本流程如下： 复制用户数据到内核空间 估计超时时间 遍历每个文件并调用f_op-&gt;poll 取得文件当前就绪状态， 如果前面遍历的文件都没有就绪，向文件插入wait_queue节点 遍历完成后检查状态：a). 如果已经有就绪的文件转到5； b). 如果有信号产生，重启poll或select（转到 1或3）； c). 否则挂起进程等待超时或唤醒，超时或被唤醒后再次遍历所有文件取得每个文件的就绪状态 将所有文件的就绪状态复制到用户空间 清理申请的资源 关键结构体下面是poll/select共用的结构体及其相关功能: poll_wqueues 是 select/poll 对poll_table接口的具体化实现,其中的table, inline_index和inline_entries都是为了管理内存。poll_table_entry 与一个文件相关联，用于管理插入到文件的wait_queue节点。1234567891011121314151617181920212223// select/poll 对poll_table的具体化实现 struct poll_wqueues &#123; poll_table pt; struct poll_table_page *table; // 如果inline_entries 空间不足, 从poll_table_page 中分配 struct task_struct *polling_task; // 调用poll 或select 的进程 int triggered; // 已触发标记 int error; int inline_index; // 下一个要分配的inline_entrie 索引 struct poll_table_entry inline_entries[N_INLINE_POLL_ENTRIES];// &#125;; // 帮助管理select/poll 申请的内存 struct poll_table_page &#123; struct poll_table_page * next; // 下一个 page struct poll_table_entry * entry; // 指向第一个entries struct poll_table_entry entries[0]; &#125;; // 与一个正在poll /select 的文件相关联, struct poll_table_entry &#123; struct file *filp; // 在poll/select中的文件 unsigned long key; wait_queue_t wait; // 插入到wait_queue_head_t 的节点 wait_queue_head_t *wait_address; // 文件上的wait_queue_head_t 地址 &#125;; 公共函数 下面是poll/select公用的一些函数，这些函数实现了poll和select的核心功能。 poll_initwait 用于初始化poll_wqueues， __pollwait 实现了向文件中添加回调节点的逻辑， pollwake 当文件状态发生改变时，由文件调用，用来唤醒线程， poll_get_entry，free_poll_entry，poll_freewait用来申请释放poll_table_entry 占用的内存，并负责释放文件上的wait_queue节点。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// poll_wqueues 的初始化: // 初始化 poll_wqueues , __pollwait会在文件就绪时被调用 void poll_initwait(struct poll_wqueues *pwq) &#123; // 初始化poll_table, 相当于调用基类的构造函数 init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait); /* * static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc) * &#123; * pt-&gt;_qproc = qproc; * pt-&gt;_key = ~0UL; * &#125; */ pwq-&gt;polling_task = current; pwq-&gt;triggered = 0; pwq-&gt;error = 0; pwq-&gt;table = NULL; pwq-&gt;inline_index = 0; &#125; // wait_queue设置函数 // poll/select 向文件wait_queue中添加节点的方法 static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p) &#123; struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt); struct poll_table_entry *entry = poll_get_entry(pwq); if (!entry) &#123; return; &#125; get_file(filp); //put_file() in free_poll_entry() entry-&gt;filp = filp; entry-&gt;wait_address = wait_address; // 等待队列头 entry-&gt;key = p-&gt;key; // 设置回调为 pollwake init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake); entry-&gt;wait.private = pwq; // 添加到等待队列 add_wait_queue(wait_address, &amp;entry-&gt;wait); &#125; // 在等待队列(wait_queue_t)上回调函数(func) // 文件就绪后被调用，唤醒调用进程，其中key是文件提供的当前状态掩码 static int pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key) &#123; struct poll_table_entry *entry; // 取得文件对应的poll_table_entry entry = container_of(wait, struct poll_table_entry, wait); // 过滤不关注的事件 if (key &amp;&amp; !((unsigned long)key &amp; entry-&gt;key)) &#123; return 0; &#125; // 唤醒 return __pollwake(wait, mode, sync, key); &#125; static int __pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key) &#123; struct poll_wqueues *pwq = wait-&gt;private; // 将调用进程 pwq-&gt;polling_task 关联到 dummy_wait DECLARE_WAITQUEUE(dummy_wait, pwq-&gt;polling_task); smp_wmb(); pwq-&gt;triggered = 1;// 标记为已触发 // 唤醒调用进程 return default_wake_function(&amp;dummy_wait, mode, sync, key); &#125; // 默认的唤醒函数,poll/select 设置的回调函数会调用此函数唤醒 // 直接唤醒等待队列上的线程,即将线程移到运行队列(rq) int default_wake_function(wait_queue_t *curr, unsigned mode, int wake_flags, void *key) &#123; // 这个函数比较复杂, 这里就不具体分析了 return try_to_wake_up(curr-&gt;private, mode, wake_flags); &#125; poll，select对poll_table_entry的申请和释放采用的是类似内存池的管理方式，先使用预分配的空间，预分配的空间不足时，分配一个内存页，使用内存页上的空间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 分配或使用已先前申请的 poll_table_entry, static struct poll_table_entry *poll_get_entry(struct poll_wqueues *p) &#123; struct poll_table_page *table = p-&gt;table; if (p-&gt;inline_index &lt; N_INLINE_POLL_ENTRIES) &#123; return p-&gt;inline_entries + p-&gt;inline_index++; &#125; if (!table || POLL_TABLE_FULL(table)) &#123; struct poll_table_page *new_table; new_table = (struct poll_table_page *) __get_free_page(GFP_KERNEL); if (!new_table) &#123; p-&gt;error = -ENOMEM; return NULL; &#125; new_table-&gt;entry = new_table-&gt;entries; new_table-&gt;next = table; p-&gt;table = new_table; table = new_table; &#125; return table-&gt;entry++; &#125; // 清理poll_wqueues 占用的资源 void poll_freewait(struct poll_wqueues *pwq) &#123; struct poll_table_page * p = pwq-&gt;table; // 遍历所有已分配的inline poll_table_entry int i; for (i = 0; i &lt; pwq-&gt;inline_index; i++) &#123; free_poll_entry(pwq-&gt;inline_entries + i); &#125; // 遍历在poll_table_page上分配的inline poll_table_entry // 并释放poll_table_page while (p) &#123; struct poll_table_entry * entry; struct poll_table_page *old; entry = p-&gt;entry; do &#123; entry--; free_poll_entry(entry); &#125; while (entry &gt; p-&gt;entries); old = p; p = p-&gt;next; free_page((unsigned long) old); &#125; &#125; static void free_poll_entry(struct poll_table_entry *entry) &#123; // 从等待队列中删除, 释放文件引用计数 remove_wait_queue(entry-&gt;wait_address, &amp;entry-&gt;wait); fput(entry-&gt;filp); &#125; poll/select核心结构关系下图是 poll/select 实现公共部分的关系图，包含了与文件直接的关系，以及函数之间的依赖。 poll的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227// poll 使用的结构体 struct pollfd &#123; int fd; // 描述符 short events; // 关注的事件掩码 short revents; // 返回的事件掩码 &#125;; // long sys_poll(struct pollfd *ufds, unsigned int nfds, long timeout_msecs) SYSCALL_DEFINE3(poll, struct pollfd __user *, ufds, unsigned int, nfds, long, timeout_msecs) &#123; struct timespec end_time, *to = NULL; int ret; if (timeout_msecs &gt;= 0) &#123; to = &amp;end_time; // 将相对超时时间msec 转化为绝对时间 poll_select_set_timeout(to, timeout_msecs / MSEC_PER_SEC, NSEC_PER_MSEC * (timeout_msecs % MSEC_PER_SEC)); &#125; // do sys poll ret = do_sys_poll(ufds, nfds, to); // do_sys_poll 被信号中断, 重新调用, 对使用者来说 poll 是不会被信号中断的. if (ret == -EINTR) &#123; struct restart_block *restart_block; restart_block = &amp;current_thread_info()-&gt;restart_block; restart_block-&gt;fn = do_restart_poll; // 设置重启的函数 restart_block-&gt;poll.ufds = ufds; restart_block-&gt;poll.nfds = nfds; if (timeout_msecs &gt;= 0) &#123; restart_block-&gt;poll.tv_sec = end_time.tv_sec; restart_block-&gt;poll.tv_nsec = end_time.tv_nsec; restart_block-&gt;poll.has_timeout = 1; &#125; else &#123; restart_block-&gt;poll.has_timeout = 0; &#125; // ERESTART_RESTARTBLOCK 不会返回给用户进程, // 而是会被系统捕获, 然后调用 do_restart_poll, ret = -ERESTART_RESTARTBLOCK; &#125; return ret; &#125; int do_sys_poll(struct pollfd __user *ufds, unsigned int nfds, struct timespec *end_time) &#123; struct poll_wqueues table; int err = -EFAULT, fdcount, len, size; /* 首先使用栈上的空间，节约内存，加速访问 */ long stack_pps[POLL_STACK_ALLOC/sizeof(long)]; struct poll_list *const head = (struct poll_list *)stack_pps; struct poll_list *walk = head; unsigned long todo = nfds; if (nfds &gt; rlimit(RLIMIT_NOFILE)) &#123; // 文件描述符数量超过当前进程限制 return -EINVAL; &#125; // 复制用户空间数据到内核 len = min_t(unsigned int, nfds, N_STACK_PPS); for (;;) &#123; walk-&gt;next = NULL; walk-&gt;len = len; if (!len) &#123; break; &#125; // 复制到当前的 entries if (copy_from_user(walk-&gt;entries, ufds + nfds-todo, sizeof(struct pollfd) * walk-&gt;len)) &#123; goto out_fds; &#125; todo -= walk-&gt;len; if (!todo) &#123; break; &#125; // 栈上空间不足，在堆上申请剩余部分 len = min(todo, POLLFD_PER_PAGE); size = sizeof(struct poll_list) + sizeof(struct pollfd) * len; walk = walk-&gt;next = kmalloc(size, GFP_KERNEL); if (!walk) &#123; err = -ENOMEM; goto out_fds; &#125; &#125; // 初始化 poll_wqueues 结构, 设置函数指针_qproc 为__pollwait poll_initwait(&amp;table); // poll fdcount = do_poll(nfds, head, &amp;table, end_time); // 从文件wait queue 中移除对应的节点, 释放entry. poll_freewait(&amp;table); // 复制结果到用户空间 for (walk = head; walk; walk = walk-&gt;next) &#123; struct pollfd *fds = walk-&gt;entries; int j; for (j = 0; j &lt; len; j++, ufds++) if (__put_user(fds[j].revents, &amp;ufds-&gt;revents)) &#123; goto out_fds; &#125; &#125; err = fdcount; out_fds: // 释放申请的内存 walk = head-&gt;next; while (walk) &#123; struct poll_list *pos = walk; walk = walk-&gt;next; kfree(pos); &#125; return err; &#125; // 真正的处理函数 static int do_poll(unsigned int nfds, struct poll_list *list, struct poll_wqueues *wait, struct timespec *end_time) &#123; poll_table* pt = &amp;wait-&gt;pt; ktime_t expire, *to = NULL; int timed_out = 0, count = 0; unsigned long slack = 0; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; // 已经超时,直接遍历所有文件描述符, 然后返回 pt = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) &#123; // 估计进程等待时间，纳秒 slack = select_estimate_accuracy(end_time); &#125; // 遍历文件，为每个文件的等待队列添加唤醒函数(pollwake) for (;;) &#123; struct poll_list *walk; for (walk = list; walk != NULL; walk = walk-&gt;next) &#123; struct pollfd * pfd, * pfd_end; pfd = walk-&gt;entries; pfd_end = pfd + walk-&gt;len; for (; pfd != pfd_end; pfd++) &#123; // do_pollfd 会向文件对应的wait queue 中添加节点 // 和回调函数(如果 pt 不为空) // 并检查当前文件状态并设置返回的掩码 if (do_pollfd(pfd, pt)) &#123; // 该文件已经准备好了. // 不需要向后面文件的wait queue 中添加唤醒函数了. count++; pt = NULL; &#125; &#125; &#125; // 下次循环的时候不需要向文件的wait queue 中添加节点, // 因为前面的循环已经把该添加的都添加了 pt = NULL; // 第一次遍历没有发现ready的文件 if (!count) &#123; count = wait-&gt;error; // 有信号产生 if (signal_pending(current)) &#123; count = -EINTR; &#125; &#125; // 有ready的文件或已经超时 if (count || timed_out) &#123; break; &#125; // 转换为内核时间 if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; // 等待事件就绪, 如果有事件发生或超时，就再循 // 环一遍，取得事件状态掩码并计数, // 注意此次循环中, 文件 wait queue 中的节点依然存在 if (!poll_schedule_timeout(wait, TASK_INTERRUPTIBLE, to, slack)) &#123; timed_out = 1; &#125; &#125; return count; &#125; static inline unsigned int do_pollfd(struct pollfd *pollfd, poll_table *pwait) &#123; unsigned int mask; int fd; mask = 0; fd = pollfd-&gt;fd; if (fd &gt;= 0) &#123; int fput_needed; struct file * file; // 取得fd对应的文件结构体 file = fget_light(fd, &amp;fput_needed); mask = POLLNVAL; if (file != NULL) &#123; // 如果没有 f_op 或 f_op-&gt;poll 则认为文件始终处于就绪状态. mask = DEFAULT_POLLMASK; if (file-&gt;f_op &amp;&amp; file-&gt;f_op-&gt;poll) &#123; if (pwait) &#123; // 设置关注的事件掩码 pwait-&gt;key = pollfd-&gt;events | POLLERR | POLLHUP; &#125; // 注册回调函数，并返回当前就绪状态，就绪后会调用pollwake mask = file-&gt;f_op-&gt;poll(file, pwait); &#125; mask &amp;= pollfd-&gt;events | POLLERR | POLLHUP; // 移除不需要的状态掩码 fput_light(file, fput_needed);// 释放文件 &#125; &#125; pollfd-&gt;revents = mask; // 更新事件状态 return mask; &#125; static long do_restart_poll(struct restart_block *restart_block) &#123; struct pollfd __user *ufds = restart_block-&gt;poll.ufds; int nfds = restart_block-&gt;poll.nfds; struct timespec *to = NULL, end_time; int ret; if (restart_block-&gt;poll.has_timeout) &#123; // 获取先前的超时时间 end_time.tv_sec = restart_block-&gt;poll.tv_sec; end_time.tv_nsec = restart_block-&gt;poll.tv_nsec; to = &amp;end_time; &#125; ret = do_sys_poll(ufds, nfds, to); // 重新调用 do_sys_poll if (ret == -EINTR) &#123; // 又被信号中断了, 再次重启 restart_block-&gt;fn = do_restart_poll; ret = -ERESTART_RESTARTBLOCK; &#125; return ret; &#125; select 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258typedef struct &#123; unsigned long *in, *out, *ex; unsigned long *res_in, *res_out, *res_ex; &#125; fd_set_bits; // long sys_select(int n, fd_set *inp, fd_set *outp, fd_set *exp, struct timeval *tvp) SYSCALL_DEFINE5(select, int, n, fd_set __user *, inp, fd_set __user *, outp, fd_set __user *, exp, struct timeval __user *, tvp) &#123; struct timespec end_time, *to = NULL; struct timeval tv; int ret; if (tvp) &#123; if (copy_from_user(&amp;tv, tvp, sizeof(tv))) &#123; return -EFAULT; &#125; // 计算超时时间 to = &amp;end_time; if (poll_select_set_timeout(to, tv.tv_sec + (tv.tv_usec / USEC_PER_SEC), (tv.tv_usec % USEC_PER_SEC) * NSEC_PER_USEC)) &#123; return -EINVAL; &#125; &#125; ret = core_sys_select(n, inp, outp, exp, to); // 复制剩余时间到用户空间 ret = poll_select_copy_remaining(&amp;end_time, tvp, 1, ret); return ret; &#125; int core_sys_select(int n, fd_set __user *inp, fd_set __user *outp, fd_set __user *exp, struct timespec *end_time) &#123; fd_set_bits fds; void *bits; int ret, max_fds; unsigned int size; struct fdtable *fdt; //小对象使用栈上的空间,节约内存, 加快访问速度 long stack_fds[SELECT_STACK_ALLOC/sizeof(long)]; ret = -EINVAL; if (n &lt; 0) &#123; goto out_nofds; &#125; rcu_read_lock(); // 取得进程对应的 fdtable fdt = files_fdtable(current-&gt;files); max_fds = fdt-&gt;max_fds; rcu_read_unlock(); if (n &gt; max_fds) &#123; n = max_fds; &#125; size = FDS_BYTES(n); bits = stack_fds; if (size &gt; sizeof(stack_fds) / 6) &#123; // 栈上的空间不够, 申请内存, 全部使用堆上的空间 ret = -ENOMEM; bits = kmalloc(6 * size, GFP_KERNEL); if (!bits) &#123; goto out_nofds; &#125; &#125; fds.in = bits; fds.out = bits + size; fds.ex = bits + 2*size; fds.res_in = bits + 3*size; fds.res_out = bits + 4*size; fds.res_ex = bits + 5*size; // 复制用户空间到内核 if ((ret = get_fd_set(n, inp, fds.in)) || (ret = get_fd_set(n, outp, fds.out)) || (ret = get_fd_set(n, exp, fds.ex))) &#123; goto out; &#125; // 初始化fd set zero_fd_set(n, fds.res_in); zero_fd_set(n, fds.res_out); zero_fd_set(n, fds.res_ex); ret = do_select(n, &amp;fds, end_time); if (ret &lt; 0) &#123; goto out; &#125; if (!ret) &#123; // 该返回值会被系统捕获, 并以同样的参数重新调用sys_select() ret = -ERESTARTNOHAND; if (signal_pending(current)) &#123; goto out; &#125; ret = 0; &#125; // 复制到用户空间 if (set_fd_set(n, inp, fds.res_in) || set_fd_set(n, outp, fds.res_out) || set_fd_set(n, exp, fds.res_ex)) &#123; ret = -EFAULT; &#125; out: if (bits != stack_fds) &#123; kfree(bits); &#125; out_nofds: return ret; &#125; int do_select(int n, fd_set_bits *fds, struct timespec *end_time) &#123; ktime_t expire, *to = NULL; struct poll_wqueues table; poll_table *wait; int retval, i, timed_out = 0; unsigned long slack = 0; rcu_read_lock(); // 检查fds中fd的有效性, 并获取当前最大的fd retval = max_select_fd(n, fds); rcu_read_unlock(); if (retval &lt; 0) &#123; return retval; &#125; n = retval; // 初始化 poll_wqueues 结构, 设置函数指针_qproc 为__pollwait poll_initwait(&amp;table); wait = &amp;table.pt; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; wait = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) &#123; // 估计需要等待的时间. slack = select_estimate_accuracy(end_time); &#125; retval = 0; for (;;) &#123; unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp; inp = fds-&gt;in; outp = fds-&gt;out; exp = fds-&gt;ex; rinp = fds-&gt;res_in; routp = fds-&gt;res_out; rexp = fds-&gt;res_ex; // 遍历所有的描述符, i 文件描述符 for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) &#123; unsigned long in, out, ex, all_bits, bit = 1, mask, j; unsigned long res_in = 0, res_out = 0, res_ex = 0; const struct file_operations *f_op = NULL; struct file *file = NULL; // 检查当前的 slot 中的描述符 in = *inp++; out = *outp++; ex = *exp++; all_bits = in | out | ex; if (all_bits == 0) &#123; // 没有需要监听的描述符, 下一个slot i += __NFDBITS; continue; &#125; for (j = 0; j &lt; __NFDBITS; ++j, ++i, bit &lt;&lt;= 1) &#123; int fput_needed; if (i &gt;= n) &#123; break; &#125; // 不需要监听描述符 i if (!(bit &amp; all_bits)) &#123; continue; &#125; // 取得文件结构 file = fget_light(i, &amp;fput_needed); if (file) &#123; f_op = file-&gt;f_op; // 没有 f_op 的话就认为一直处于就绪状态 mask = DEFAULT_POLLMASK; if (f_op &amp;&amp; f_op-&gt;poll) &#123; // 设置等待事件的掩码 wait_key_set(wait, in, out, bit); /* static inline void wait_key_set(poll_table *wait, unsigned long in, unsigned long out, unsigned long bit) &#123; wait-&gt;_key = POLLEX_SET;// (POLLPRI) if (in &amp; bit) wait-&gt;_key |= POLLIN_SET;//(POLLRDNORM | POLLRDBAND | POLLIN | POLLHUP | POLLERR) if (out &amp; bit) wait-&gt;_key |= POLLOUT_SET;//POLLOUT_SET (POLLWRBAND | POLLWRNORM | POLLOUT | POLLERR) &#125; */ // 获取当前的就绪状态, 并添加到文件的对应等待队列中 mask = (*f_op-&gt;poll)(file, wait); // 和poll完全一样 &#125; fput_light(file, fput_needed); // 释放文件 // 检查文件 i 是否已有事件就绪， if ((mask &amp; POLLIN_SET) &amp;&amp; (in &amp; bit)) &#123; res_in |= bit; retval++; // 如果已有就绪事件就不再向其他文件的 // 等待队列中添加回调函数 wait = NULL; &#125; if ((mask &amp; POLLOUT_SET) &amp;&amp; (out &amp; bit)) &#123; res_out |= bit; retval++; wait = NULL; &#125; if ((mask &amp; POLLEX_SET) &amp;&amp; (ex &amp; bit)) &#123; res_ex |= bit; retval++; wait = NULL; &#125; &#125; &#125; if (res_in) &#123; *rinp = res_in; &#125; if (res_out) &#123; *routp = res_out; &#125; if (res_ex) &#123; *rexp = res_ex; &#125; cond_resched(); &#125; wait = NULL; // 该添加回调函数的都已经添加了 if (retval || timed_out || signal_pending(current)) &#123; break; // 信号发生，监听事件就绪或超时 &#125; if (table.error) &#123; retval = table.error; // 产生错误了 break; &#125; // 转换到内核时间 if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; // 等待直到超时, 或由回调函数唤醒, 超时后会再次遍历文件描述符 if (!poll_schedule_timeout(&amp;table, TASK_INTERRUPTIBLE, to, slack)) &#123; timed_out = 1; &#125; &#125; poll_freewait(&amp;table); return retval; &#125; epoll实现epoll 的实现比poll/select 复杂一些，这是因为： epoll_wait, epoll_ctl 的调用完全独立开来,内核需要锁机制对这些操作进行保护，并且需要持久的维护添加到epoll的文件 epoll本身也是文件，也可以被poll/select/epoll监视，这可能导致epoll之间循环唤醒的问题 单个文件的状态改变可能唤醒过多监听在其上的epoll，产生唤醒风暴 epoll各个功能的实现要非常小心面对这些问题，使得复杂度大大增加。 epoll的核心数据结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// epoll的核心实现对应于一个epoll描述符 struct eventpoll &#123; spinlock_t lock; struct mutex mtx; wait_queue_head_t wq; // sys_epoll_wait() 等待在这里 // f_op-&gt;poll() 使用的, 被其他事件通知机制利用的wait_address wait_queue_head_t poll_wait; /* 已就绪的需要检查的epitem 列表 */ struct list_head rdllist; /* 保存所有加入到当前epoll的文件对应的epitem*/ struct rb_root rbr; // 当正在向用户空间复制数据时, 产生的可用文件 struct epitem *ovflist; /* The user that created the eventpoll descriptor */ struct user_struct *user; struct file *file; /*优化循环检查，避免循环检查中重复的遍历 */ int visited; struct list_head visited_list_link; &#125; // 对应于一个加入到epoll的文件 struct epitem &#123; // 挂载到eventpoll 的红黑树节点 struct rb_node rbn; // 挂载到eventpoll.rdllist 的节点 struct list_head rdllink; // 连接到ovflist 的指针 struct epitem *next; /* 文件描述符信息fd + file, 红黑树的key */ struct epoll_filefd ffd; /* Number of active wait queue attached to poll operations */ int nwait; // 当前文件的等待队列(eppoll_entry)列表 // 同一个文件上可能会监视多种事件, // 这些事件可能属于不同的wait_queue中 // (取决于对应文件类型的实现), // 所以需要使用链表 struct list_head pwqlist; // 当前epitem 的所有者 struct eventpoll *ep; /* List header used to link this item to the &amp;quot;struct file&amp;quot; items list */ struct list_head fllink; /* epoll_ctl 传入的用户数据 */ struct epoll_event event; &#125;; struct epoll_filefd &#123; struct file *file; int fd; &#125;; // 与一个文件上的一个wait_queue_head 相关联，因为同一文件可能有多个等待的事件，这些事件可能使用不同的等待队列 struct eppoll_entry &#123; // List struct epitem.pwqlist struct list_head llink; // 所有者 struct epitem *base; // 添加到wait_queue 中的节点 wait_queue_t wait; // 文件wait_queue 头 wait_queue_head_t *whead; &#125;; // 用户使用的epoll_event struct epoll_event &#123; __u32 events; __u64 data; &#125; EPOLL_PACKED; 文件系统初始化和epoll_create12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// epoll 文件系统的相关实现 // epoll 文件系统初始化, 在系统启动时会调用 static int __init eventpoll_init(void) &#123; struct sysinfo si; si_meminfo(&amp;si); // 限制可添加到epoll的最多的描述符数量 max_user_watches = (((si.totalram - si.totalhigh) / 25) &lt;&lt; PAGE_SHIFT) / EP_ITEM_COST; BUG_ON(max_user_watches &lt; 0); // 初始化递归检查队列 ep_nested_calls_init(&amp;poll_loop_ncalls); ep_nested_calls_init(&amp;poll_safewake_ncalls); ep_nested_calls_init(&amp;poll_readywalk_ncalls); // epoll 使用的slab分配器分别用来分配epitem和eppoll_entry epi_cache = kmem_cache_create(&quot;eventpoll_epi&quot;, sizeof(struct epitem), 0, SLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL); pwq_cache = kmem_cache_create(&quot;eventpoll_pwq&quot;, sizeof(struct eppoll_entry), 0, SLAB_PANIC, NULL); return 0; &#125; SYSCALL_DEFINE1(epoll_create, int, size) &#123; if (size &lt;= 0) &#123; return -EINVAL; &#125; return sys_epoll_create1(0); &#125; SYSCALL_DEFINE1(epoll_create1, int, flags) &#123; int error, fd; struct eventpoll *ep = NULL; struct file *file; /* Check the EPOLL_* constant for consistency. */ BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC); if (flags &amp; ~EPOLL_CLOEXEC) &#123; return -EINVAL; &#125; /* * Create the internal data structure (&quot;struct eventpoll&quot;). */ error = ep_alloc(&amp;ep); if (error &lt; 0) &#123; return error; &#125; /* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */ fd = get_unused_fd_flags(O_RDWR | (flags &amp; O_CLOEXEC)); if (fd &lt; 0) &#123; error = fd; goto out_free_ep; &#125; // 设置epfd的相关操作，由于epoll也是文件也提供了poll操作 file = anon_inode_getfile(&quot;[eventpoll]&quot;, &amp;eventpoll_fops, ep, O_RDWR | (flags &amp; O_CLOEXEC)); if (IS_ERR(file)) &#123; error = PTR_ERR(file); goto out_free_fd; &#125; fd_install(fd, file); ep-&gt;file = file; return fd; out_free_fd: put_unused_fd(fd); out_free_ep: ep_free(ep); return error; &#125; epoll中的递归死循环和深度检查递归深度检测(ep_call_nested)epoll本身也是文件，也可以被poll/select/epoll监视，如果epoll之间互相监视就有可能导致死循环。epoll的实现中，所有可能产生递归调用的函数都由函函数ep_call_nested进行包裹，递归调用过程中出现死循环或递归过深就会打破死循环和递归调用直接返回。该函数的实现依赖于一个外部的全局链表nested_call_node(不同的函数调用使用不同的节点)，每次调用可能发生递归的函数(nproc)就向链表中添加一个包含当前函数调用上下文ctx(进程，CPU，或epoll文件)和处理的对象标识cookie的节点，通过检测是否有相同的节点就可以知道是否发生了死循环，检查链表中同一上下文包含的节点个数就可以知道递归的深度。以下就是这一过程的源码。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162struct nested_call_node &#123; struct list_head llink; void *cookie; // 函数运行标识, 任务标志 void *ctx; // 运行环境标识 &#125;; struct nested_calls &#123; struct list_head tasks_call_list; spinlock_t lock; &#125;; // 全局的不同调用使用的链表 // 死循环检查和唤醒风暴检查链表 static nested_call_node poll_loop_ncalls; // 唤醒时使用的检查链表 static nested_call_node poll_safewake_ncalls; // 扫描readylist 时使用的链表 static nested_call_node poll_readywalk_ncalls; // 限制epoll 中直接或间接递归调用的深度并防止死循环 // ctx: 任务运行上下文(进程, CPU 等) // cookie: 每个任务的标识 // priv: 任务运行需要的私有数据 // 如果用面向对象语言实现应该就会是一个wapper类 static int ep_call_nested(struct nested_calls *ncalls, int max_nests, int (*nproc)(void *, void *, int), void *priv, void *cookie, void *ctx) &#123; int error, call_nests = 0; unsigned long flags; struct list_head *lsthead = &amp;ncalls-&gt;tasks_call_list; struct nested_call_node *tncur; struct nested_call_node tnode; spin_lock_irqsave(&amp;ncalls-&gt;lock, flags); // 检查原有的嵌套调用链表ncalls, 查看是否有深度超过限制的情况 list_for_each_entry(tncur, lsthead, llink) &#123; // 同一上下文中(ctx)有相同的任务(cookie)说明产生了死循环 // 同一上下文的递归深度call_nests 超过限制 if (tncur-&gt;ctx == ctx &amp;&amp; (tncur-&gt;cookie == cookie || ++call_nests &gt; max_nests)) &#123; error = -1; &#125; goto out_unlock; &#125; /* 将当前的任务请求添加到调用列表*/ tnode.ctx = ctx; tnode.cookie = cookie; list_add(&amp;tnode.llink, lsthead); spin_unlock_irqrestore(&amp;ncalls-&gt;lock, flags); /* nproc 可能会导致递归调用(直接或间接)ep_call_nested * 如果发生递归调用, 那么在此函数返回之前, * ncalls 又会被加入额外的节点, * 这样通过前面的检测就可以知道递归调用的深度 */ error = (*nproc)(priv, cookie, call_nests); /* 从链表中删除当前任务*/ spin_lock_irqsave(&amp;ncalls-&gt;lock, flags); list_del(&amp;tnode.llink); out_unlock: spin_unlock_irqrestore(&amp;ncalls-&gt;lock, flags); return error; &#125; 循环检测(ep_loop_check)循环检查(ep_loop_check)，该函数递归调用ep_loop_check_proc利用ep_call_nested来实现epoll之间相互监视的死循环。因为ep_call_nested中已经对死循环和过深的递归做了检查，实际的ep_loop_check_proc的实现只是递归调用自己。其中的visited_list和visited标记完全是为了优化处理速度，如果没有visited_list和visited标记函数也是能够工作的。该函数中得上下文就是当前的进程，cookie就是正在遍历的epoll结构。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static LIST_HEAD(visited_list); // 检查 file (epoll)和ep 之间是否有循环 static int ep_loop_check(struct eventpoll *ep, struct file *file) &#123; int ret; struct eventpoll *ep_cur, *ep_next; ret = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, ep_loop_check_proc, file, ep, current); /* 清除链表和标志 */ list_for_each_entry_safe(ep_cur, ep_next, &amp;visited_list, visited_list_link) &#123; ep_cur-&gt;visited = 0; list_del(&amp;ep_cur-&gt;visited_list_link); &#125; return ret; &#125; static int ep_loop_check_proc(void *priv, void *cookie, int call_nests) &#123; int error = 0; struct file *file = priv; struct eventpoll *ep = file-&gt;private_data; struct eventpoll *ep_tovisit; struct rb_node *rbp; struct epitem *epi; mutex_lock_nested(&amp;ep-&gt;mtx, call_nests + 1); // 标记当前为已遍历 ep-&gt;visited = 1; list_add(&amp;ep-&gt;visited_list_link, &amp;visited_list); // 遍历所有ep 监视的文件 for (rbp = rb_first(&amp;ep-&gt;rbr); rbp; rbp = rb_next(rbp)) &#123; epi = rb_entry(rbp, struct epitem, rbn); if (unlikely(is_file_epoll(epi-&gt;ffd.file))) &#123; ep_tovisit = epi-&gt;ffd.file-&gt;private_data; // 跳过先前已遍历的, 避免循环检查 if (ep_tovisit-&gt;visited) &#123; continue; &#125; // 所有ep监视的未遍历的epoll error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, ep_loop_check_proc, epi-&gt;ffd.file, ep_tovisit, current); if (error != 0) &#123; break; &#125; &#125; else &#123; // 文件不在tfile_check_list 中, 添加 // 最外层的epoll 需要检查子epoll监视的文件 if (list_empty(&amp;epi-&gt;ffd.file-&gt;f_tfile_llink)) list_add(&amp;epi-&gt;ffd.file-&gt;f_tfile_llink, &amp;tfile_check_list); &#125; &#125; mutex_unlock(&amp;ep-&gt;mtx); return error; &#125; 唤醒风暴检测（reverse_path_check） 当文件状态发生改变时，会唤醒监听在其上的epoll文件，而这个epoll文件还可能唤醒其他的epoll文件，这种连续的唤醒就形成了一个唤醒路径，所有的唤醒路径就形成了一个有向图。如果文件对应的epoll唤醒有向图的节点过多，那么文件状态的改变就会唤醒所有的这些epoll(可能会唤醒很多进程，这样的开销是很大的)，而实际上一个文件经过少数epoll处理以后就可能从就绪转到未就绪，剩余的epoll虽然认为文件已就绪而实际上经过某些处理后已不可用。epoll的实现中考虑到了此问题，在每次添加新文件到epoll中时，就会首先检查是否会出现这样的唤醒风暴。 该函数的实现逻辑是这样的，递归调用reverse_path_check_proc遍历监听在当前文件上的epoll文件，在reverse_pach_check_proc中统计并检查不同路径深度上epoll的个数，从而避免产生唤醒风暴。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#define PATH_ARR_SIZE 5 // 在EPOLL_CTL_ADD 时, 检查是否有可能产生唤醒风暴 // epoll 允许的单个文件的唤醒深度小于5, 例如 // 一个文件最多允许唤醒1000个深度为1的epoll描述符, //允许所有被单个文件直接唤醒的epoll描述符再次唤醒的epoll描述符总数是500 // // 深度限制 static const int path_limits[PATH_ARR_SIZE] = &#123; 1000, 500, 100, 50, 10 &#125;; // 计算出来的深度 static int path_count[PATH_ARR_SIZE]; static int path_count_inc(int nests) &#123; /* Allow an arbitrary number of depth 1 paths */ if (nests == 0) &#123; return 0; &#125; if (++path_count[nests] &gt; path_limits[nests]) &#123; return -1; &#125; return 0; &#125; static void path_count_init(void) &#123; int i; for (i = 0; i &lt; PATH_ARR_SIZE; i++) &#123; path_count[i] = 0; &#125; &#125; // 唤醒风暴检查函数 static int reverse_path_check(void) &#123; int error = 0; struct file *current_file; /* let&apos;s call this for all tfiles */ // 遍历全局tfile_check_list 中的文件, 第一级 list_for_each_entry(current_file, &amp;tfile_check_list, f_tfile_llink) &#123; // 初始化 path_count_init(); // 限制递归的深度, 并检查每个深度上唤醒的epoll 数量 error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, reverse_path_check_proc, current_file, current_file, current); if (error) &#123; break; &#125; &#125; return error; &#125; static int reverse_path_check_proc(void *priv, void *cookie, int call_nests) &#123; int error = 0; struct file *file = priv; struct file *child_file; struct epitem *epi; list_for_each_entry(epi, &amp;file-&gt;f_ep_links, fllink) &#123; // 遍历监视file 的epoll child_file = epi-&gt;ep-&gt;file; if (is_file_epoll(child_file)) &#123; if (list_empty(&amp;child_file-&gt;f_ep_links)) &#123; // 没有其他的epoll监视当前的这个epoll, // 已经是叶子了 if (path_count_inc(call_nests)) &#123; error = -1; break; &#125; &#125; else &#123; // 遍历监视这个epoll 文件的epoll, // 递归调用 error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, reverse_path_check_proc, child_file, child_file, current); &#125; if (error != 0) &#123; break; &#125; &#125; else &#123; // 不是epoll , 不可能吧? printk(KERN_ERR &quot;reverse_path_check_proc: &quot; &quot;file is not an ep!\n&quot;); &#125; &#125; return error; &#125; epoll 的唤醒过程12345678910111213141516171819202122232425static void ep_poll_safewake(wait_queue_head_t *wq) &#123; int this_cpu = get_cpu(); ep_call_nested(&amp;poll_safewake_ncalls, EP_MAX_NESTS, ep_poll_wakeup_proc, NULL, wq, (void *) (long) this_cpu); put_cpu(); &#125; static int ep_poll_wakeup_proc(void *priv, void *cookie, int call_nests) &#123; ep_wake_up_nested((wait_queue_head_t *) cookie, POLLIN, 1 + call_nests); return 0; &#125; static inline void ep_wake_up_nested(wait_queue_head_t *wqueue, unsigned long events, int subclass) &#123; // 这回唤醒所有正在等待此epfd 的select/epoll/poll 等 // 如果唤醒的是epoll 就可能唤醒其他的epoll, 产生连锁反应 // 这个很可能在中断上下文中被调用 wake_up_poll(wqueue, events); &#125; epoll_ctl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114// long epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) &#123; int error; int did_lock_epmutex = 0; struct file *file, *tfile; struct eventpoll *ep; struct epitem *epi; struct epoll_event epds; error = -EFAULT; if (ep_op_has_event(op) &amp;&amp; // 复制用户空间数据到内核 copy_from_user(&amp;epds, event, sizeof(struct epoll_event))) &#123; goto error_return; &#125; // 取得 epfd 对应的文件 error = -EBADF; file = fget(epfd); if (!file) &#123; goto error_return; &#125; // 取得目标文件 tfile = fget(fd); if (!tfile) &#123; goto error_fput; &#125; // 目标文件必须提供 poll 操作 error = -EPERM; if (!tfile-&gt;f_op || !tfile-&gt;f_op-&gt;poll) &#123; goto error_tgt_fput; &#125; // 添加自身或epfd 不是epoll 句柄 error = -EINVAL; if (file == tfile || !is_file_epoll(file)) &#123; goto error_tgt_fput; &#125; // 取得内部结构eventpoll ep = file-&gt;private_data; // EPOLL_CTL_MOD 不需要加全局锁 epmutex if (op == EPOLL_CTL_ADD || op == EPOLL_CTL_DEL) &#123; mutex_lock(&amp;epmutex); did_lock_epmutex = 1; &#125; if (op == EPOLL_CTL_ADD) &#123; if (is_file_epoll(tfile)) &#123; error = -ELOOP; // 目标文件也是epoll 检测是否有循环包含的问题 if (ep_loop_check(ep, tfile) != 0) &#123; goto error_tgt_fput; &#125; &#125; else &#123; // 将目标文件添加到 epoll 全局的tfile_check_list 中 list_add(&amp;tfile-&gt;f_tfile_llink, &amp;tfile_check_list); &#125; &#125; mutex_lock_nested(&amp;ep-&gt;mtx, 0); // 以tfile 和fd 为key 在rbtree 中查找文件对应的epitem epi = ep_find(ep, tfile, fd); error = -EINVAL; switch (op) &#123; case EPOLL_CTL_ADD: if (!epi) &#123; // 没找到, 添加额外添加ERR HUP 事件 epds.events |= POLLERR | POLLHUP; error = ep_insert(ep, &amp;epds, tfile, fd); &#125; else &#123; error = -EEXIST; &#125; // 清空文件检查列表 clear_tfile_check_list(); break; case EPOLL_CTL_DEL: if (epi) &#123; error = ep_remove(ep, epi); &#125; else &#123; error = -ENOENT; &#125; break; case EPOLL_CTL_MOD: if (epi) &#123; epds.events |= POLLERR | POLLHUP; error = ep_modify(ep, epi, &amp;epds); &#125; else &#123; error = -ENOENT; &#125; break; &#125; mutex_unlock(&amp;ep-&gt;mtx); error_tgt_fput: if (did_lock_epmutex) &#123; mutex_unlock(&amp;epmutex); &#125; fput(tfile); error_fput: fput(file); error_return: return error; &#125; EPOLL_CTL_ADD 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129// EPOLL_CTL_ADD static int ep_insert(struct eventpoll *ep, struct epoll_event *event, struct file *tfile, int fd) &#123; int error, revents, pwake = 0; unsigned long flags; long user_watches; struct epitem *epi; struct ep_pqueue epq; /* struct ep_pqueue &#123; poll_table pt; struct epitem *epi; &#125;; */ // 增加监视文件数 user_watches = atomic_long_read(&amp;ep-&gt;user-&gt;epoll_watches); if (unlikely(user_watches &gt;= max_user_watches)) &#123; return -ENOSPC; &#125; // 分配初始化 epi if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL))) &#123; return -ENOMEM; &#125; INIT_LIST_HEAD(&amp;epi-&gt;rdllink); INIT_LIST_HEAD(&amp;epi-&gt;fllink); INIT_LIST_HEAD(&amp;epi-&gt;pwqlist); epi-&gt;ep = ep; // 初始化红黑树中的key ep_set_ffd(&amp;epi-&gt;ffd, tfile, fd); // 直接复制用户结构 epi-&gt;event = *event; epi-&gt;nwait = 0; epi-&gt;next = EP_UNACTIVE_PTR; // 初始化临时的 epq epq.epi = epi; init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc); // 设置事件掩码 epq.pt._key = event-&gt;events; // 内部会调用ep_ptable_queue_proc, 在文件对应的wait queue head 上 // 注册回调函数, 并返回当前文件的状态 revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt); // 检查错误 error = -ENOMEM; if (epi-&gt;nwait &lt; 0) &#123; // f_op-&gt;poll 过程出错 goto error_unregister; &#125; // 添加当前的epitem 到文件的f_ep_links 链表 spin_lock(&amp;tfile-&gt;f_lock); list_add_tail(&amp;epi-&gt;fllink, &amp;tfile-&gt;f_ep_links); spin_unlock(&amp;tfile-&gt;f_lock); // 插入epi 到rbtree ep_rbtree_insert(ep, epi); /* now check if we&apos;ve created too many backpaths */ error = -EINVAL; if (reverse_path_check()) &#123; goto error_remove_epi; &#125; spin_lock_irqsave(&amp;ep-&gt;lock, flags); /* 文件已经就绪插入到就绪链表rdllist */ if ((revents &amp; event-&gt;events) &amp;&amp; !ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); if (waitqueue_active(&amp;ep-&gt;wq)) // 通知sys_epoll_wait , 调用回调函数唤醒sys_epoll_wait 进程 &#123; wake_up_locked(&amp;ep-&gt;wq); &#125; // 先不通知调用eventpoll_poll 的进程 if (waitqueue_active(&amp;ep-&gt;poll_wait)) &#123; pwake++; &#125; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); atomic_long_inc(&amp;ep-&gt;user-&gt;epoll_watches); if (pwake) // 安全通知调用eventpoll_poll 的进程 &#123; ep_poll_safewake(&amp;ep-&gt;poll_wait); &#125; return 0; error_remove_epi: spin_lock(&amp;tfile-&gt;f_lock); // 删除文件上的 epi if (ep_is_linked(&amp;epi-&gt;fllink)) &#123; list_del_init(&amp;epi-&gt;fllink); &#125; spin_unlock(&amp;tfile-&gt;f_lock); // 从红黑树中删除 rb_erase(&amp;epi-&gt;rbn, &amp;ep-&gt;rbr); error_unregister: // 从文件的wait_queue 中删除, 释放epitem 关联的所有eppoll_entry ep_unregister_pollwait(ep, epi); /* * We need to do this because an event could have been arrived on some * allocated wait queue. Note that we don&apos;t care about the ep-&gt;ovflist * list, since that is used/cleaned only inside a section bound by &quot;mtx&quot;. * And ep_insert() is called with &quot;mtx&quot; held. */ // TODO: spin_lock_irqsave(&amp;ep-&gt;lock, flags); if (ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_del_init(&amp;epi-&gt;rdllink); &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 释放epi kmem_cache_free(epi_cache, epi); return error; &#125; EPOLL_CTL_DELEPOLL_CTL_DEL 的实现调用的是 ep_remove 函数，函数只是清除ADD时， 添加的各种结构，EPOLL_CTL_MOD 的实现调用的是ep_modify，在ep_modify中用新的事件掩码调用f_ops-&gt;poll，检测事件是否已可用，如果可用就直接唤醒epoll，这两个的实现与EPOLL_CTL_ADD 类似，代码上比较清晰，这里就不具体分析了。1234567891011121314151617181920212223242526272829303132333435static int ep_remove(struct eventpoll *ep, struct epitem *epi) &#123; unsigned long flags; struct file *file = epi-&gt;ffd.file; /* * Removes poll wait queue hooks. We _have_ to do this without holding * the &quot;ep-&gt;lock&quot; otherwise a deadlock might occur. This because of the * sequence of the lock acquisition. Here we do &quot;ep-&gt;lock&quot; then the wait * queue head lock when unregistering the wait queue. The wakeup callback * will run by holding the wait queue head lock and will call our callback * that will try to get &quot;ep-&gt;lock&quot;. */ ep_unregister_pollwait(ep, epi); /* Remove the current item from the list of epoll hooks */ spin_lock(&amp;file-&gt;f_lock); if (ep_is_linked(&amp;epi-&gt;fllink)) list_del_init(&amp;epi-&gt;fllink); spin_unlock(&amp;file-&gt;f_lock); rb_erase(&amp;epi-&gt;rbn, &amp;ep-&gt;rbr); spin_lock_irqsave(&amp;ep-&gt;lock, flags); if (ep_is_linked(&amp;epi-&gt;rdllink)) list_del_init(&amp;epi-&gt;rdllink); spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* At this point it is safe to free the eventpoll item */ kmem_cache_free(epi_cache, epi); atomic_long_dec(&amp;ep-&gt;user-&gt;epoll_watches); return 0; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * Modify the interest event mask by dropping an event if the new mask * has a match in the current file status. Must be called with &quot;mtx&quot; held. */ static int ep_modify(struct eventpoll *ep, struct epitem *epi, struct epoll_event *event) &#123; int pwake = 0; unsigned int revents; poll_table pt; init_poll_funcptr(&amp;pt, NULL); /* * Set the new event interest mask before calling f_op-&gt;poll(); * otherwise we might miss an event that happens between the * f_op-&gt;poll() call and the new event set registering. */ epi-&gt;event.events = event-&gt;events; pt._key = event-&gt;events; epi-&gt;event.data = event-&gt;data; /* protected by mtx */ /* * Get current event bits. We can safely use the file* here because * its usage count has been increased by the caller of this function. */ revents = epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, &amp;pt); /* * If the item is &quot;hot&quot; and it is not registered inside the ready * list, push it inside. */ if (revents &amp; event-&gt;events) &#123; spin_lock_irq(&amp;ep-&gt;lock); if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); /* Notify waiting tasks that events are available */ if (waitqueue_active(&amp;ep-&gt;wq)) wake_up_locked(&amp;ep-&gt;wq); if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; spin_unlock_irq(&amp;ep-&gt;lock); &#125; /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(&amp;ep-&gt;poll_wait); return 0; &#125; epoll_wait123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197/* epoll_wait实现 */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) &#123; int error; struct file *file; struct eventpoll *ep; // 检查输入数据有效性 if (maxevents &lt;= 0 || maxevents &gt; EP_MAX_EVENTS) &#123; return -EINVAL; &#125; if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) &#123; error = -EFAULT; goto error_return; &#125; /* Get the &quot;struct file *&quot; for the eventpoll file */ error = -EBADF; file = fget(epfd); if (!file) &#123; goto error_return; &#125; error = -EINVAL; if (!is_file_epoll(file)) &#123; goto error_fput; &#125; // 取得ep 结构 ep = file-&gt;private_data; // 等待事件 error = ep_poll(ep, events, maxevents, timeout); error_fput: fput(file); error_return: return error; &#125; static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) &#123; int res = 0, eavail, timed_out = 0; unsigned long flags; long slack = 0; wait_queue_t wait; ktime_t expires, *to = NULL; if (timeout &gt; 0) &#123; // 转换为内核时间 struct timespec end_time = ep_set_mstimeout(timeout); slack = select_estimate_accuracy(&amp;end_time); to = &amp;expires; *to = timespec_to_ktime(end_time); &#125; else if (timeout == 0) &#123; // 已经超时直接检查readylist timed_out = 1; spin_lock_irqsave(&amp;ep-&gt;lock, flags); goto check_events; &#125; fetch_events: spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 没有可用的事件，ready list 和ovflist 都为空 if (!ep_events_available(ep)) &#123; // 添加当前进程的唤醒函数 init_waitqueue_entry(&amp;wait, current); __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); for (;;) &#123; /* * We don&apos;t want to sleep if the ep_poll_callback() sends us * a wakeup in between. That&apos;s why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ set_current_state(TASK_INTERRUPTIBLE); if (ep_events_available(ep) || timed_out) &#123; break; &#125; if (signal_pending(current)) &#123; res = -EINTR; break; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 挂起当前进程，等待唤醒或超时 if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) &#123; timed_out = 1; &#125; spin_lock_irqsave(&amp;ep-&gt;lock, flags); &#125; __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); set_current_state(TASK_RUNNING); &#125; check_events: // 再次检查是否有可用事件 eavail = ep_events_available(ep); spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* * Try to transfer events to user space. In case we get 0 events and * there&apos;s still timeout left over, we go trying again in search of * more luck. */ if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) // 复制事件到用户空间 &amp;&amp; !timed_out) // 复制事件失败并且没有超时，重新等待。 &#123; goto fetch_events; &#125; return res; &#125; static inline int ep_events_available(struct eventpoll *ep) &#123; return !list_empty(&amp;ep-&gt;rdllist) || ep-&gt;ovflist != EP_UNACTIVE_PTR; &#125; struct ep_send_events_data &#123; int maxevents; struct epoll_event __user *events; &#125;; static int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) &#123; struct ep_send_events_data esed; esed.maxevents = maxevents; esed.events = events; return ep_scan_ready_list(ep, ep_send_events_proc, &amp;esed, 0); &#125; static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) &#123; struct ep_send_events_data *esed = priv; int eventcnt; unsigned int revents; struct epitem *epi; struct epoll_event __user *uevent; // 遍历已就绪链表 for (eventcnt = 0, uevent = esed-&gt;events; !list_empty(head) &amp;&amp; eventcnt &lt; esed-&gt;maxevents;) &#123; epi = list_first_entry(head, struct epitem, rdllink); list_del_init(&amp;epi-&gt;rdllink); // 获取ready 事件掩码 revents = epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, NULL) &amp; epi-&gt;event.events; /* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding &quot;mtx&quot;, so no operations coming from userspace * can change the item. */ if (revents) &#123; // 事件就绪, 复制到用户空间 if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123; list_add(&amp;epi-&gt;rdllink, head); return eventcnt ? eventcnt : -EFAULT; &#125; eventcnt++; uevent++; if (epi-&gt;event.events &amp; EPOLLONESHOT) &#123; epi-&gt;event.events &amp;= EP_PRIVATE_BITS; &#125; else if (!(epi-&gt;event.events &amp; EPOLLET)) &#123; // 不是边缘模式, 再次添加到ready list, // 下次epoll_wait 时直接进入此函数检查ready list是否仍然继续 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); &#125; // 如果是边缘模式, 只有当文件状态发生改变时, // 才文件会再次触发wait_address 上wait_queue的回调函数, &#125; &#125; return eventcnt; &#125; eventpoll_poll 由于epoll自身也是文件系统，其描述符也可以被poll/select/epoll监视，因此需要实现poll方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119static const struct file_operations eventpoll_fops = &#123; .release = ep_eventpoll_release, .poll = ep_eventpoll_poll, .llseek = noop_llseek, &#125;; static unsigned int ep_eventpoll_poll(struct file *file, poll_table *wait) &#123; int pollflags; struct eventpoll *ep = file-&gt;private_data; // 插入到wait_queue poll_wait(file, &amp;ep-&gt;poll_wait, wait); // 扫描就绪的文件列表, 调用每个文件上的poll 检测是否真的就绪, // 然后复制到用户空间 // 文件列表中有可能有epoll文件, 调用poll的时候有可能会产生递归, // 调用所以用ep_call_nested 包装一下, 防止死循环和过深的调用 pollflags = ep_call_nested(&amp;poll_readywalk_ncalls, EP_MAX_NESTS, ep_poll_readyevents_proc, ep, ep, current); // static struct nested_calls poll_readywalk_ncalls; return pollflags != -1 ? pollflags : 0; &#125; static int ep_poll_readyevents_proc(void *priv, void *cookie, int call_nests) &#123; return ep_scan_ready_list(priv, ep_read_events_proc, NULL, call_nests + 1); &#125; static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv, int depth) &#123; int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); /* * We need to lock this because we could be hit by * eventpoll_release_file() and epoll_ctl(). */ mutex_lock_nested(&amp;ep-&gt;mtx, depth); spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 移动rdllist 到新的链表txlist list_splice_init(&amp;ep-&gt;rdllist, &amp;txlist); // 改变ovflist 的状态, 如果ep-&gt;ovflist != EP_UNACTIVE_PTR, // 当文件激活wait_queue时，就会将对应的epitem加入到ep-&gt;ovflist // 否则将文件直接加入到ep-&gt;rdllist， // 这样做的目的是避免丢失事件 // 这里不需要检查ep-&gt;ovflist 的状态，因为ep-&gt;mtx的存在保证此处的ep-&gt;ovflist // 一定是EP_UNACTIVE_PTR ep-&gt;ovflist = NULL; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 调用扫描函数处理txlist error = (*sproc)(ep, &amp;txlist, priv); spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 调用 sproc 时可能有新的事件，遍历这些新的事件将其插入到ready list for (nepi = ep-&gt;ovflist; (epi = nepi) != NULL; nepi = epi-&gt;next, epi-&gt;next = EP_UNACTIVE_PTR) &#123; // #define EP_UNACTIVE_PTR (void *) -1 // epi 不在rdllist, 插入 if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); &#125; &#125; // 还原ep-&gt;ovflist的状态 ep-&gt;ovflist = EP_UNACTIVE_PTR; // 将处理后的 txlist 链接到 rdllist list_splice(&amp;txlist, &amp;ep-&gt;rdllist); if (!list_empty(&amp;ep-&gt;rdllist)) &#123; // 唤醒epoll_wait if (waitqueue_active(&amp;ep-&gt;wq)) &#123; wake_up_locked(&amp;ep-&gt;wq); &#125; // 当前的ep有其他的事件通知机制监控 if (waitqueue_active(&amp;ep-&gt;poll_wait)) &#123; pwake++; &#125; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); mutex_unlock(&amp;ep-&gt;mtx); if (pwake) &#123; // 安全唤醒外部的事件通知机制 ep_poll_safewake(&amp;ep-&gt;poll_wait); &#125; return error; &#125; static int ep_read_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) &#123; struct epitem *epi, *tmp; poll_table pt; init_poll_funcptr(&amp;pt, NULL); list_for_each_entry_safe(epi, tmp, head, rdllink) &#123; pt._key = epi-&gt;event.events; if (epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, &amp;pt) &amp; epi-&gt;event.events) &#123; return POLLIN | POLLRDNORM; &#125; else &#123; // 这个事件虽然在就绪列表中, // 但是实际上并没有就绪, 将他移除 // 这有可能是水平触发模式中没有将文件从就绪列表中移除 // 也可能是事件插入到就绪列表后有其他的线程对文件进行了操作 list_del_init(&amp;epi-&gt;rdllink); &#125; &#125; return 0; &#125; epoll全景以下是epoll使用的全部数据结构之间的关系图，采用的是一种类UML图，希望对理解epoll的内部实现有所帮助。 poll/select/epoll 对比通过以上的分析可以看出，poll和select的实现基本是一致，只是用户到内核传递的数据格式有所不同， select和poll即使只有一个描述符就绪，也要遍历整个集合。如果集合中活跃的描述符很少，遍历过程的开销就会变得很大，而如果集合中大部分的描述符都是活跃的，遍历过程的开销又可以忽略。 epoll的实现中每次只遍历活跃的描述符(如果是水平触发，也会遍历先前活跃的描述符)，在活跃描述符较少的情况下就会很有优势，在代码的分析过程中可以看到epoll的实现过于复杂并且其实现过程中需要同步处理(锁)，如果大部分描述符都是活跃的，epoll的效率可能不如select或poll。(参见epoll 和poll的性能测试 http://jacquesmattheij.com/Poll+vs+Epoll+once+again) select能够处理的最大fd无法超出FDSETSIZE。 select会复写传入的fd_set 指针，而poll对每个fd返回一个掩码，不更改原来的掩码，从而可以对同一个集合多次调用poll，而无需调整。 select对每个文件描述符最多使用3个bit，而poll采用的pollfd需要使用64个bit，epoll采用的 epoll_event则需要96个bit 如果事件需要循环处理select, poll 每一次的处理都要将全部的数据复制到内核，而epoll的实现中，内核将持久维护加入的描述符，减少了内核和用户复制数据的开销。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[select、poll、epoll之间的区别总结[整理]]]></title>
    <url>%2F2019%2F04%2F12%2Fselect_poll_epoll%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E6%80%BB%E7%BB%93%5B%E6%95%B4%E7%90%86%5D%2F</url>
    <content type="text"><![CDATA[原文：http://www.cnblogs.com/Anker/p/3265058.html select、poll、epoll之间的区别总结[整理] select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 select实现select的调用过程如下所示： （1）使用copy_from_user从用户空间拷贝fd_set到内核空间 （2）注册回调函数__pollwait （3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） （4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 （5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 （6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 （7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 （8）把fd_set从内核空间拷贝到用户空间。 总结： select的几大缺点： （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 （3）select支持的文件描述符数量太小了，默认是1024 poll实现 poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。 epollepoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 总结： （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode977. Squares of a Sorted Array]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode977-Squares-of-a-Sorted-Array%2F</url>
    <content type="text"><![CDATA[Squares of a Sorted Array Given an array of integers A sorted in non-decreasing order, return an array of the squares of each number, also in sorted non-decreasing order. Example 1:12Input: [-4,-1,0,3,10]Output: [0,1,9,16,100] Example 2:12Input: [-7,-3,2,3,11]Output: [4,9,9,49,121] Note: 1 &lt;= A.length &lt;= 10000-10000 &lt;= A[i] &lt;= 10000A is sorted in non-decreasing order. 给一个vector，有正有负，输出排序之后的平方数组。123456789101112class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; res(A.size()); int l = 0,r = A.size()-1, p = A.size() - 1; while(l&lt;=r)&#123; res[p--]=pow(A[abs(A[l])&gt;abs(A[r])?l++:r--],2); &#125; return res; &#125;&#125;; 另一种方法：1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; res(A.size()); int i=0,j=0,k=0; while(i&lt;A.size() &amp;&amp; A[i]&lt;0) i++; j=i-1; while(j&gt;=0 &amp;&amp; i&lt;A.size())&#123; res[k++] = pow(A[abs(A[i])&lt;abs(A[j])?i++:j--],2); &#125; while(j&gt;=0) res[k++]=pow(A[j--],2); while(i&lt;A.size()) res[k++]=pow(A[i++],2); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qsub教程]]></title>
    <url>%2F2019%2F04%2F12%2Fqsub%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[PBS作业管理，即以qsub、qstat、qdel命令为核心的集群作业管理系统，且它是开源的。 在此环境下运行，用户不需要指定程序在哪些节点上运行，程序所需的硬件资源由PBS管理和分配。 qsub、qstat、qdel的功能分别为“提交作业”、“查看作业状态”、“删除作业”。 非PBS下mpi计算通常来说，使用mpirun即可，例如mpirun -np 16 ./pom.kii2b.exe &lt; /dev/null &gt; pom.log，意为在一个节点上使用16核执行pom.kii2b.exe，stdin重定向至空，stdout重定向至pom.log。 之后可能会再执行几个mv命令之类的，例如把pom.log文件移动至别处，防止多次调用时覆盖log。 PBS作业提交直接执行qsub会提示输入PBS作业脚本，这样很不方便，因此通常来说都是把qsub脚本写到文件里，重定向输入来进行作业提交，例如qsub &lt; cess.sbpom.qsub（其实不加&lt;也可以），提交一个写在cess.sbpom.qsub文件里的PBS脚本。 PBS脚本形如下面那段代码从#!/bin/sh到mv pom.log ../$TIME.pom.log的部分。 由于存在需要多次提交相似作业的可能，例如我有20个文件夹的数据，每个文件夹里数据的处理方式相同，调用同一个程序，总不能写20个PBS脚本。因此更为通常的做法是，使用shell脚本进行qsub脚本输出再提交，举例如下：123456789101112131415161718192021 PNAME=fz_letkf NODE=1 NP=16 QSUBTIME=&quot;24:00:00&quot; NOWDIR=`pwd` QSUB=cess.letkf.qsub LETKF=letkf020.m01cat &lt;&lt;EOF &gt;$QSUB#!/bin/sh#PBS -q hpca #PBS -V #PBS -N $PNAME#PBS -l nodes=$NODE:ppn=$NP#PBS -l walltime=&quot;$QSUBTIME&quot;#PBS -o /home/xfh_stu/WORK3/qsublog#PBS -j oe cd $NOWDIRmpirun ./$LETKF &lt; /dev/nullmv pom.log ../$TIME.pom.logEOF qsub $QSUB &gt;cessrunid 调用此脚本就会自动将PBS脚本输出至$QSUB文件中，并提交此作业。通常在这段代码外面会套上循环，每次修改相应变量，从而实现一次提交多个相似作业。 在这里cat命令使用了一种叫做heredoc的写法，用于输出大段文字，同时还要替换其中的变量。界定符EOF是可以自定义的，不过通常来说都使用EOF。另外，用于结束的界定符必须顶格写（想不顶格也是可以的，但是有其他限制，且不方便）。 下面解释一下参数的意思。 -q：指定使用的队列。可使用qstat -q查看队列信息，包括队列名、资源限制、正在运行的任务数等。 -V：将执行qsub命令时拥有的环境变量都export该作业。 -N：指定作业名。 -l：指定作业使用的节点数与核数、时间限制等。 -o：重定向此作业的stdout至指定的文件夹中，名为作业名.o作业ID。 -j oe：合并此作业的stdout与stderr。 qsub成功提交作业后，会在stdout输出Job ID，形如作业ID.主机名，例如15252.manager。在上面的例子中，我将qsub的结果重定向至cessrunid文件中，用于存储作业ID，以便后续处理。 查看作业状态执行qstat即可查看当前正在执行的作业以及刚刚完成的作业。在S那一列，C表示已完成，R表示正在执行，Q表示正在等待，还有一些其他不常见的状态，可以man qstat并以job state为关键词查询即可。 现在还有个问题，即如何在脚本中判断作业完成与否呢？一个很实际的例子是，我在脚本中一次提交完多个作业后，后续的脚本必须在完成这些作业后才能继续执行，那么就需要知道这些作业有没有完成。 通常有两种思路： 一是查看程序本应输出的文件有没有正常输出，即判断输出文件是否存在。或者在程序中写一些日志输出语句，脚本就可以通过查找日志文件某关键的一句话有没有输出从而知道程序运行有没有正常完成。 二是查看上文中通过-o参数指定的作业stdout输出文件，文件名为作业名.o作业ID。这也就是为什么我要把qsub提交信息保存到cessrunid这个文件里。通常来说，只要作业正常完成了，就会生成此文件。 对于第一种思路，就要根据程序具体情况来编写了。 对于第二种思路，一个典型的判断脚本如下：12345678910111213while :do temp=`cat cessrunid` runid=$&#123;PNAME&#125;.o$&#123;temp%.manager&#125; runfilename=&apos;/home/xfh_stu/WORK3/qsublog/&apos;$runid if [ -f &quot;$runfilename&quot; ]; then break fi sleep 60done 大意为： 提取出cessrunid这个文件里的qsub提交信息，并去掉后面的.manager主机名（CESS集群主机名为manager），之后改写成作业名.o作业ID的形式，并加上路径，判断该文件是否存在。 如果文件存在，则说明作业已完成，即可break掉这个无限循环，继续后面的操作了。 这里需要注意的一个地方就是，在无限循环里的每次判断中间要加上一个sleep语句，比如我设置的是每分钟跑一次循环，这样机器就不会由于每时每刻都在执行判断而耗尽资源。 删除作业执行qdel -W 15 15303即可在15秒后停止并删除Job ID为15303的作业。 脚本的正确使用方法通常来说，我们都是在shell脚本中进行qsub脚本输出再提交该qsub脚本。 这里存在一个问题，即shell脚本自身需要后台执行。如果执行前台执行脚本，就会导致断开SSH连接后，脚本就会停止执行。 因此，需要使用nohup ./your.script.name.sh &amp;命令，它可以脚本在后台执行且将stdout重定向至nohup.out文件中。要注意命令最后的&amp;是不可缺少的，如果不写，脚本虽然也会在后台执行，但是在关闭SSH后就会停止。 另外，在执行完这个命令之后要按一下回车，使其回到shell上来。 当我们解决脚本后台执行的问题后，又出现了新问题，即如何停止该脚本？ 通过脚本提交的PBS作业可以通过qdel命令结束掉，而脚本本身停止就需要kill掉该脚本的进程了。 首先，我们使用ps -ef | grep your.script.name.sh查询到脚本的进程PID，之后执行kill xxxxx即可停止PID为xxxxx的进程了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO模式及 select、poll、epoll详解]]></title>
    <url>%2F2019%2F04%2F12%2FLinux_IO%E6%A8%A1%E5%8F%8Aselect_poll_epoll%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://segmentfault.com/a/1190000003063859?utm_source=tag-newest 本文讨论的背景是Linux环境下的network IO。 概念说明在进行解释之前，首先要说明几个概念： 用户空间和内核空间 进程切换 进程的阻塞 文件描述符 缓存 I/O 用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 注：总而言之就是很耗资源，具体的可以参考这篇文章：进程切换 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）Linux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： 通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 I/O 多路复用之select、poll、epoll详解select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下） select1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll操作过程epoll操作过程需要三个接口，分别如下：123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： 1234struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;; //events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 总结假如有这样一个例子： 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)…… LT模式：如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。 ET模式：如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。 当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：1234567891011121314151617181920212223while(rs)&#123; buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen &lt; 0)&#123; // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读 // 在这里就当作是该次事件已处理处. if(errno == EAGAIN)&#123; break; &#125; else&#123; return; &#125; &#125; else if(buflen == 0)&#123; // 这里表示对端的socket已正常关闭. &#125; if(buflen == sizeof(buf)&#123; rs = 1; // 需要再次读取 &#125; else&#123; rs = 0; &#125;&#125; Linux中的EAGAIN含义 Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。 例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。 代码演示下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#define IPADDRESS &quot;127.0.0.1&quot;#define PORT 8787#define MAXSIZE 1024#define LISTENQ 5#define FDSIZE 1000#define EPOLLEVENTS 100listenfd = socket_bind(IPADDRESS,PORT);struct epoll_event events[EPOLLEVENTS];//创建一个描述符epollfd = epoll_create(FDSIZE);//添加监听描述符事件add_event(epollfd,listenfd,EPOLLIN);//循环等待for ( ; ; )&#123; //该函数返回已经准备好的描述符事件数目 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接 handle_events(epollfd,events,ret,listenfd,buf);&#125;//事件处理函数static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf)&#123; int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。 for (i = 0;i &lt; num;i++) &#123; fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events &amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events &amp; EPOLLOUT) do_write(epollfd,fd,buf); &#125;&#125;//添加事件static void add_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev);&#125;//处理接收到的连接static void handle_accpet(int epollfd,int listenfd)&#123; int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)&amp;cliaddr,&amp;cliaddrlen); if (clifd == -1) perror(&quot;accpet error:&quot;); else &#123; printf(&quot;accept a new client: %s:%d\n&quot;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); &#125; &#125;//读处理static void do_read(int epollfd,int fd,char *buf)&#123; int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) &#123; perror(&quot;read error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else if (nread == 0) &#123; fprintf(stderr,&quot;client close.\n&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else &#123; printf(&quot;read message is : %s&quot;,buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); &#125; &#125;//写处理static void do_write(int epollfd,int fd,char *buf) &#123; int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1)&#123; perror(&quot;write error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLOUT); //删除监听 &#125;else&#123; modify_event(epollfd,fd,EPOLLIN); &#125; memset(buf,0,MAXSIZE); &#125;//删除事件static void delete_event(int epollfd,int fd,int state) &#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev);&#125;//修改事件static void modify_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev);&#125; epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面： 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的nohup命令的用法]]></title>
    <url>%2F2019%2F04%2F12%2FLinux%E7%9A%84nohup%E5%91%BD%E4%BB%A4%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是有很多程序并不想mysqld一样，这样我们就需要nohup命令，怎样使用nohup命令呢？这里讲解nohup命令的一些用法。 nohup /root/start.sh &amp; 在shell中回车后提示： [~]$ appending output to nohup.out 原程序的的标准输出被自动改向到当前目录下的nohup.out文件，起到了log的作用。 但是有时候在这一步会有问题，当把终端关闭后，进程会自动被关闭，察看nohup.out可以看到在关闭终端瞬间服务自动关闭。 咨询红旗Linux工程师后，他也不得其解，在我的终端上执行后，他启动的进程竟然在关闭终端后依然运行。 在第二遍给我演示时，我才发现我和他操作终端时的一个细节不同：他是在当shell中提示了nohup成功后还需要按终端上键盘任意键退回到shell输入命令窗口，然后通过在shell中输入exit来退出终端；而我是每次在nohup执行成功后直接点关闭程序按钮关闭终端.。所以这时候会断掉该命令所对应的session，导致nohup对应的进程被通知需要一起shutdown。 这个细节有人和我一样没注意到，所以在这儿记录一下了。 附：nohup命令参考 nohup 命令 用途：不挂断地运行命令。 语法：nohup Command [ Arg … ] [ &amp; ] 描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示”and”的符号）到命令的尾部。 无论是否将 nohup 命令的输出重定向到终端，输出都将附加到当前目录的 nohup.out 文件中。如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。 退出状态：该命令返回下列出口值： 126 可以查找但不能调用 Command 参数指定的命令。 127 nohup 命令发生错误或不能查找由 Command 参数指定的命令。 否则，nohup 命令的退出状态是 Command 参数指定命令的退出状态。 nohup命令及其输出文件 nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( n ohang up)。 该命令的一般形式为：nohup command &amp; 使用nohup命令提交作业 如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件： nohup command &gt; myout.file 2&gt;&amp;1 &amp; 在上面的例子中，输出被重定向到myout.file文件中。 使用 jobs 查看任务。 使用 fg %n 关闭。 另外有两个常用的ftp工具ncftpget和ncftpput，可以实现后台的ftp上传和下载，这样就可以利用这些命令在后台上传和下载文件了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c-cpp中mem函数的类型及用法]]></title>
    <url>%2F2019%2F04%2F12%2Fc-cpp%E4%B8%ADmem%E5%87%BD%E6%95%B0%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[函数名称: memccpy函数原型: void memccpy(void dest, const void *src, int c, size_t n)函数功能: 字符串拷贝，到指定长度或遇到指定字符时停止拷贝函数返回:参数说明: src-源字符串指针，c-中止拷贝检查字符，n-长度,dest-拷贝底目的字符串指针所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314151617#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char *src= &quot;This is the source string &quot;; char dest[50]; char *ptr; ptr=memccpy(dest,src, &apos;c &apos;,strlen(src)); if (ptr) &#123; *ptr= &apos;\0 &apos;; printf( &quot;The character was found:%s &quot;,dest); &#125; else printf( &quot;The character wasn &apos;t found &quot;); return 0; &#125; @函数名称: memchr函数原型: void memchr(const void s, int c, size_t n)函数功能: 在字符串中第开始n个字符中寻找某个字符c的位置函数返回: 返回c的位置指针，返回NULL时表示未找到参数说明: s-要搜索的字符串，c-要寻找的字符，n-指定长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char str[17]; char *ptr; strcpy(str, &quot;This is a string &quot;); ptr=memchr(str, &apos;r &apos;,strlen(str)); if(ptr) printf( &quot;The character &apos;r &apos; is at position:%d &quot;,ptr-str); else printf( &quot;The character was not found &quot;); return 0; &#125; @函数名称: memcmp函数原型: int memcmp(const void s1, const void s2, size_t n)函数功能: 按字典顺序对字符串s1,s2比较，并只比较前n个字符函数返回: 返回数值表示比较结果参数说明: s1,s2-要比较的字符串，n-比较的长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; auto char buffer[80]; strcpy(buffer, &quot;world &quot;); if( memcmp(buffer, &quot;would &quot;,6)&lt;0)&#123; printf( &quot;Less than\n &quot;); &#125; return 0; &#125; @函数名称: memicmp函数原型: int memicmp(const void s1, const void s2, size_t n)函数功能: 按字典顺序、不考虑字母大小写对字符串s1,s2比较，并只比较前n个字符函数返回: 返回数值表示比较结果参数说明: s1,s2-要比较的字符串，n-比较的长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; char *buf1 = &quot;ABCDE123 &quot;; char *buf2 = &quot;abcde456 &quot;; int stat; stat = memicmp(buf1, buf2, 5); printf( &quot;The strings to position 5 are &quot;); if(stat) printf( &quot;not &quot;); printf( &quot;the same &quot;); return 0; &#125; @函数名称: memcpy函数原型: void memcpy(void dest, const void *src, size_t n)函数功能: 字符串拷贝函数返回: 指向dest的指针参数说明: src-源字符串，n-拷贝的最大长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;123456789101112131415#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; char src[] = &quot;****************************** &quot;; char dest[] = &quot;abcdefghijlkmnopqrstuvwxyz0123456709 &quot;; char *ptr; printf( &quot;destination before memcpy: %s &quot;,dest); ptr=memcpy(dest,src,strlen(src)); if(ptr) printf( &quot;destination after memcpy:%s &quot;,dest); else printf( &quot;memcpy failed &quot;); return 0; &#125; @函数名称: memmove函数原型: void memmove(void dest, const void *src, size_t n)函数功能: 字符串拷贝函数返回: 指向dest的指针参数说明: src-源字符串，n-拷贝的最大长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;12345678910#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char dest[40]= &quot;abcdefghijklmnopqrstuvwxyz0123456789 &quot;; printf( &quot;destination prior to memmove:%s\n &quot;,dest); memmove(dest+1,dest,35); printf( &quot;destination after memmove:%s &quot;,dest); return 0; &#125; @函数名称: memset函数原型: void memset(void s, int c, size_t n)函数功能: 字符串中的n个字节内容设置为c函数返回:参数说明: s-要设置的字符串，c-设置的内容，n-长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; #include &lt;mem.h&gt;; int main() &#123; char buffer[] = &quot;Hello world &quot;; printf( &quot;Buffer before memset:%s &quot;,buffer); memset(buffer, &apos;* &apos;,strlen(buffer)-1); printf( &quot;Buffer after memset:%s &quot;,buffer); return 0; &#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode929. Unique Email Addresses]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode929-Unique-Email-Addresses%2F</url>
    <content type="text"><![CDATA[Unique Email AddressesEasy Every email consists of a local name and a domain name, separated by the @ sign. For example, in alice@leetcode.com, alice is the local name, and leetcode.com is the domain name. Besides lowercase letters, these emails may contain ‘.’s or ‘+’s. If you add periods (‘.’) between some characters in the local name part of an email address, mail sent there will be forwarded to the same address without dots in the local name. For example, “alice.z@leetcode.com“ and “alicez@leetcode.com“ forward to the same email address. (Note that this rule does not apply for domain names.) If you add a plus (‘+’) in the local name, everything after the first plus sign will be ignored. This allows certain emails to be filtered, for example m.y+name@email.com will be forwarded to my@email.com. (Again, this rule does not apply for domain names.) It is possible to use both of these rules at the same time. Given a list of emails, we send one email to each address in the list. How many different addresses actually receive mails? Example 1:123Input: [&quot;test.email+alex@leetcode.com&quot;,&quot;test.e.mail+bob.cathy@leetcode.com&quot;,&quot;testemail+david@lee.tcode.com&quot;]Output: 2Explanation: &quot;testemail@leetcode.com&quot; and &quot;testemail@lee.tcode.com&quot; actually receive mails Note: 1 &lt;= emails[i].length &lt;= 1001 &lt;= emails.length &lt;= 100Each emails[i] contains exactly one ‘@’ character.All local and domain names are non-empty.Local names do not start with a ‘+’ character. 字符串处理，如果一个email地址里有点(‘.’)的话，就忽略这个点，如果有加号(‘+’)，忽略这个加号到(‘@’)之间的字符。判断一共有几个一样的email地址。不难，但是涉及字符串处理的话总归有些麻烦的。 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int numUniqueEmails(vector&lt;string&gt;&amp; emails) &#123; char result[100][100]; memset(result,&apos;\0&apos;,sizeof(result)); int result_len=0; for(unsigned int i=0; i&lt;emails.size(); i++) &#123; char temp[100]; memset(temp,&apos;\0&apos;,100); int temp_len = 0, k=0; unsigned int j; for(j=0; j&lt;emails[i].length(); j++) &#123; if(emails[i][j]==&apos;.&apos;) continue; else if(emails[i][j]==&apos;+&apos; || emails[i][j]==&apos;@&apos; ) break; else temp[temp_len++]=emails[i][j]; &#125; for(j=emails[i].find(&apos;@&apos;); j&lt;emails[i].length(); j++) temp[temp_len++]=emails[i][j]; for(k=0; k&lt;result_len; k++) if(strcmp(result[k],temp)==0) break; if(k==result_len) memcpy(result[result_len++], temp, sizeof(temp)); memset(temp,&apos;\0&apos;,100); &#125; return result_len; &#125;&#125;; 解析：For each email address, convert it to the canonical address that actually receives the mail. This involves a few steps: Separate the email address into a local part and the rest of the address. If the local part has a ‘+’ character, remove it and everything beyond it from the local part. Remove all the zeros from the local part. The canonical address is local + rest. After, we can count the number of unique canonical addresses with a Set structure.1234567891011121314151617class Solution &#123; public int numUniqueEmails(String[] emails) &#123; Set&lt;String&gt; seen = new HashSet(); for (String email: emails) &#123; int i = email.indexOf(&apos;@&apos;); String local = email.substring(0, i); String rest = email.substring(i); if (local.contains(&quot;+&quot;)) &#123; local = local.substring(0, local.indexOf(&apos;+&apos;)); &#125; local = local.replaceAll(&quot;.&quot;, &quot;&quot;); seen.add(local + rest); &#125; return seen.size(); &#125;&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL vector的内部实现原理及基本用法]]></title>
    <url>%2F2019%2F04%2F12%2FSTL-vector%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文地址：https://blog.csdn.net/u012658346/article/details/50725933 本文基于STL vector源代码，但是不考虑分配器allocator，迭代器iterator，异常处理try/catch等内容，同时对_Ucopy（）、 _Umove（）、 _Ufill（）函数也不会过度分析。 vector的定义123456789101112template&lt;class _Ty, class _Ax&gt; class vector : public _Vector_val&lt;_Ty, _Ax&gt; &#123; // varying size array of valuespublic: /********/protected: pointer _Myfirst; // pointer to beginning of array pointer _Mylast; // pointer to current end of sequence pointer _Myend; // pointer to end of array &#125;; 简单理解，就是vector是利用上述三个指针来表示的，基本示意图如下： 两个关键大小：大小：size=_Mylast - _Myfirst;容量：capacity=_Myend - _Myfirst;分别对应于resize()、reserve()两个函数。size表示vector中已有元素的个数，容量表示vector最多可存储的元素的个数；为了降低二次分配时的成本，vector实际配置的大小可能比客户需求的更大一些，以备将来扩充，这就是容量的概念。即capacity&gt;=size，当等于时，容器此时已满，若再要加入新的元素时，就要重新进行内存分配，整个vector的数据都要移动到新内存。二次分配成本较高，在实际操作时，应尽量预留一定空间，避免二次分配。 构造与析构构造vector的构造函数主要有以下几种：1234567891011121314151617vector() : _Mybase() &#123; // construct empty vector _Buy(0); &#125; explicit vector(size_type _Count) : _Mybase() &#123; // construct from _Count * _Ty() _Construct_n(_Count, _Ty()); &#125;vector(size_type _Count, const _Ty&amp; _Val) : _Mybase() &#123; // construct from _Count * _Val _Construct_n(_Count, _Val); &#125;vector(const _Myt&amp; _Right) : _Mybase(_Right._Alval) &#123; // construct by copying _Right if (_Buy(_Right.size())) _Mylast = _Ucopy(_Right.begin(), _Right.end(), _Myfirst); &#125; vector优异性能的秘诀之一，就是配置比其所容纳的元素所需更多的内存，一般在使用vector之前，就先预留足够空间，以避免二次分配，这样可以使vector的性能达到最佳。因此元素个数_Count是个远比元素值 _Val重要的参数，因此当构造一个vector时，首要参数一定是元素个数。由上各构造函数可知，基本上所有构造函数都是基于_Construct _n() 的12345678910111213141516171819bool _Buy(size_type _Capacity) &#123; // allocate array with _Capacity elements _Myfirst = 0, _Mylast = 0, _Myend = 0; if (_Capacity == 0) //_Count为0时，直接返回 return (false); else &#123; // nonempty array, allocate storage _Myfirst = this-&gt;_Alval.allocate(_Capacity); //分配内存，并更新成员变量 _Mylast = _Myfirst; _Myend = _Myfirst + _Capacity; &#125; return (true); &#125;void _Construct_n(size_type _Count, const _Ty&amp; _Val) &#123; // 构造含有_Count个值为_Val的元素的容器 if (_Buy(_Count)) _Mylast = _Ufill(_Myfirst, _Count, _Val); &#125; 这样就完成了vector容器的构造了。 析构vector的析构函数很简单，就是先销毁所有已存在的元素，然后释放所有内存123456789void _Tidy() &#123; // free all storage if (_Myfirst != 0) &#123; // something to free, destroy and deallocate it _Destroy(_Myfirst, _Mylast); this-&gt;_Alval.deallocate(_Myfirst, _Myend - _Myfirst); &#125; _Myfirst = 0, _Mylast = 0, _Myend = 0; &#125; 插入和删除元素vector的插入和删除元素是通过push_ back () 、 pop_back()两个接口来实现的，他们的内部实现也非常简单12345678910111213141516void push_back(const _Ty&amp; _Val) &#123; // insert element at end if (size() &lt; capacity()) _Mylast = _Ufill(_Mylast, 1, _Val); else insert(end(), _Val); //空间不足时，就会触发内存的二次分配 &#125;void pop_back() &#123; // erase element at end if (!empty()) &#123; // erase last element _Destroy(_Mylast - 1, _Mylast); --_Mylast; &#125; &#125; 其他接口1、reserve()操作 之前提到过reserve（Count） 函数主要是预留Count大小的空间，对应的是容器的容量，目的是保证（_Myend - _Myfirst）&gt;=Count。只有当空间不足时，才会操作，即重新分配一块内存，将原有元素拷贝到新内存，并销毁原有内存1234567891011121314151617void reserve(size_type _Count) &#123; // determine new minimum length of allocated storage if (capacity() &lt; _Count) &#123; // not enough room, reallocate pointer _Ptr = this-&gt;_Alval.allocate(_Count); _Umove(begin(), end(), _Ptr); size_type _Size = size(); if (_Myfirst != 0) &#123; // destroy and deallocate old array _Destroy(_Myfirst, _Mylast); this-&gt;_Alval.deallocate(_Myfirst, _Myend - _Myfirst); &#125; _Myend = _Ptr + _Count; _Mylast = _Ptr + _Size; _Myfirst = _Ptr; &#125; &#125; 2、resize()操作resize（Count） 函数主要是用于改变size的，也就是改变vector的大小，最终改变的是（_Mylast - _Myfirst）的值，当size &lt; Count时,就插入元素，当size &gt;Count时，就擦除元素。1234567void resize(size_type _Newsize, _Ty _Val) &#123; // determine new length, padding with _Val elements as needed if (size() &lt; _Newsize) _Insert_n(end(), _Newsize - size(), _Val); else if (_Newsize &lt; size()) erase(begin() + _Newsize, end()); &#125; 3、_Insert_n()操作 resize()操作和insert()操作都会利用到_Insert_n()这个函数，这个函数非常重要，也比其他函数稍微复杂一点虽然_Insert_n(_where, _Count, _Val ) 函数比较长，但是操作都非常简单，主要可以分为以下几种情况： _Count == 0，不需要插入，直接返回 max_size() - size() &lt; _Count，超过系统设置的最大容量，会溢出，造成Xlen（）异常 _Capacity &lt; size() + _Count，vector的容量不足以插入Count个元素，需要进行二次分配，扩大vector的容量。 在VS下，vector容量会扩大50%，即 _Capacity = _Capacity + _Capacity / 2;若仍不足，则 _Capacity = size() + _Count; 12345678910111213else if (_Capacity &lt; size() + _Count) &#123; // not enough room, reallocate _Capacity = max_size() - _Capacity / 2 &lt; _Capacity ? 0 : _Capacity + _Capacity / 2; // try to grow by 50% if (_Capacity &lt; size() + _Count) _Capacity = size() + _Count; pointer _Newvec = this-&gt;_Alval.allocate(_Capacity); pointer _Ptr = _Newvec; _Ptr = _Umove(_Myfirst, _VEC_ITER_BASE(_Where),_Newvec); // copy prefix _Ptr = _Ufill(_Ptr, _Count, _Val); // add new stuff _Umove(_VEC_ITER_BASE(_Where), _Mylast, _Ptr); // copy suffix //内存释放与变量更新 &#125; 这种情况下，数据从原始容器移动到新分配内存时是从前到后移动的 空间足够，且被插入元素的位置比较靠近_Mylast,即已有元素的尾部 这种情况下不需要再次进行内存分配，且数据是从后往前操作的。首先是将where~last向后移动，为待插入数据预留Count大小的空间，然后从_Mylast处开始填充，然后将从where处开始填充剩余元素12345678910else if ((size_type)(_Mylast - _VEC_ITER_BASE(_Where)) &lt; _Count) &#123; // new stuff spills off end _Umove(_VEC_ITER_BASE(_Where), _Mylast, _VEC_ITER_BASE(_Where) + _Count); // copy suffix _Ufill(_Mylast, _Count - (_Mylast - _VEC_ITER_BASE(_Where)), _Val); // insert new stuff off end _Mylast += _Count; std::fill(_VEC_ITER_BASE(_Where), _Mylast - _Count, _Val); // insert up to old end &#125; 空间足够，但插入的位置比较靠前1234567891011&#123; // new stuff can all be assigned_Ty _Tmp = _Val; // in case _Val is in sequencepointer _Oldend = _Mylast;_Mylast = _Umove(_Oldend - _Count, _Oldend, _Mylast); // copy suffix_STDEXT _Unchecked_move_backward(_VEC_ITER_BASE(_Where), _Oldend - _Count, _Oldend); // copy holestd::fill(_VEC_ITER_BASE(_Where), _VEC_ITER_BASE(_Where) + _Count, _Tmp); // insert into hole&#125; 4、erase()操作12345678910111213141516iterator erase(const_iterator _First_arg, const_iterator _Last_arg) &#123; // erase [_First, _Last) iterator _First = _Make_iter(_First_arg); iterator _Last = _Make_iter(_Last_arg); if (_First != _Last) &#123; // worth doing, copy down over hole pointer _Ptr = _STDEXT unchecked_copy(_VEC_ITER_BASE(_Last), _Mylast, _VEC_ITER_BASE(_First)); _Destroy(_Ptr, _Mylast); _Mylast = _Ptr; &#125; return (_First); &#125; 主要操作就是将后半部分的有效元素向前拷贝，并将后面空间的无效元素析构，并更新_Mylast变量 5、assign()操作 assign()操作最终都会调用到下面的函数，主要操作是首先擦除容器中已有的全部元素，在从头开始插入Count个Val元素123456void _Assign_n(size_type _Count, const _Ty&amp; _Val) &#123; // assign _Count * _Val _Ty _Tmp = _Val; // in case _Val is in sequence erase(begin(), end()); insert(begin(), _Count, _Tmp); &#125; 基本使用在经过上述对vector内部实现的分析后，再来理解相应接口就变得简单得多。vector对外接口主要可以分为： 构造、析构：12345678vector&lt;Elem&gt; cvector &lt;Elem&gt; c1(c2)vector &lt;Elem&gt; c(n)vector &lt;Elem&gt; c(n, elem)vector &lt;Elem&gt; c(beg,end)c.~ vector &lt;Elem&gt;()``插入、删除、赋值 c.push_back(elem)c.pop_back()c.insert(pos,elem)c.insert(pos,n,elem)c.insert(pos,beg,end)c.erase(pos)c.erase(beg,end)c.clear()c.assign(beg,end)c.assign(n,elem)1大小相关 c.capacity()c.max_size()c.resize(num)c.reserve()c.size()1获取迭代器 c.begin()c.end()c.rbegin()c.rend()1获取数据 operator[]c.at(idx)c.front()c.back()`]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c语言str相关的函数]]></title>
    <url>%2F2019%2F04%2F12%2Fc%E8%AF%AD%E8%A8%80str%E7%9B%B8%E5%85%B3%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C语言str系列库函数在不同的库中有不同的实现方法，但原理都是一样的。因为库函数都是没有进行入口参数检查的，并且str系列库函数在面试中经常容易被面试官喊在纸上写某一个函数的实现，因此本文参考了OpenBSD和vc++ 8.0库中的代码，结合自己的编程习惯，部分整理如下： 1、strcpy12345678910111213char * strcpy(char *dst, const char *src) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d++ = *src++) // while ((*d++ = *src++) != &apos;\0&apos;) ; return dst; &#125; 2、strncpy123456789101112131415161718//copy at most n characters of src to dst //Pad with &apos;\0&apos; if src fewer than n characters char *strncpy(char *dst, const char*src, size_t n) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (n != 0 &amp;&amp; (*d++ = *src++)) /* copy string */ n--; if (n != 0) while (--n != 0) *d++ == &apos;\0&apos;; /* pad out with zeroes */ return dst; &#125; 注意n是unsigned int，在进行n–操作时特别要小心。如果不小心写成下面这样就会出错：1234while (n-- != 0 &amp;&amp; (*d++ = *src++)) ; while (n-- != 0) *d++ = &apos;\0&apos;; 第一个while循环中，当n变为0时，仍然会执行n–一，此时n等于经由-1变成的大正数，导致后面对n的使用出错。3、strcat1234567891011121314151617char *strcat(char *dst, const char *src) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d) d++; //while (*d++ != 0); //d--; while (*d++ = *src++) ; return dst; &#125; 4、strncat写法1：123456789101112131415161718192021//concatenate at most n characters of src to the end of dst //terminates dst with &apos;\0&apos; char *strncat(char *dst, const char *src, size_t n) &#123; if (NULL == dst || NULL == src) return dst; if (n != 0) &#123; char *d = dst; do &#123; if ((*d = *src++) == &apos;\0&apos; ) return dst; //break d++; &#125; while (--n != 0); *d = &apos;\0&apos;; &#125; return dst; &#125; 写法2：123456789101112131415161718192021222324252627char *strncat(char *dst, const char *src, size_t n) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d) d++; //(1) while (n != 0) &#123; if ((*d++ = *src++) == &apos;\0&apos;) return dst; n--; &#125; //(2) //while (n--) //这种方式写最后n的值不为0，不过这个n后面不会再被使用 // if ((*d++ == *src++) == &apos;\0&apos;) // return dst; *d = &apos;\0&apos;; return dst; &#125; 5、strcmp123456789101112131415int strcmp(const char *s1, const char *s2) &#123; if (s1 == NULL || s2 == NULL) return 0; //(1) //while (*s1 == *s2++) // if (*s1++ == &apos;\0&apos;) // return 0; //(2) for (; *s1 == *s2; s1++, s2++) if (*s1 == &apos;\0&apos;) return 0; return *(unsigned char*)s1 - *(unsigned char*)s2; &#125; 6、strncmp123456789101112131415161718192021222324252627int strncmp(const char *s1, const char *s2, size_t n) &#123; if (s1 == NULL || s2 == NULL) return 0; if (n == 0) return 0; do &#123; if (*s1 != *s2++) return *(unsigned char*)s1 - *(unsigned char*)--s2; if (*s1++ == &apos;\0&apos;) break; &#125; while (--n != 0); //do //&#123; // if (*s1 != *s2) // return *(unsigned char*)s1 - *(unsigned char*)s2; // if (*s1 == &apos;\0&apos;) // break; // s1++; // s2++; //&#125; while (--n != 0); return 0; &#125; 7、strstr写法1：12345678910111213141516171819202122232425//return pointer to first occurrence of find in s //or NULL if not present char *strstr(const char *s, const char *find) &#123; char *cp = (char*)s; char *s1, *s2; if (s == NULL || find == NULL) return NULL; while (*cp != &apos;\0&apos;) &#123; s1 = cp; s2 = (char*)find; while (*s1 &amp;&amp; *s2 &amp;&amp; *s1 == *s2) s1++, s2++; if(*s2 == &apos;\0&apos;) return cp; cp++; &#125; return NULL; &#125; 写法2：参照简单模式匹配算法12345678910111213141516char *strstr(const char *s, const char *find) &#123; int i = 0, j = 0; while (*(s + i) != &apos;\0&apos; &amp;&amp; *(find + j) != &apos;\0&apos;) &#123; if (*(s + i + j) == *(find + j)) j++; //继续比较后一字符 else &#123; i++; //开始新一轮比较 j = 0; &#125; &#125; return *(find + j) == &apos;\0&apos; ? (char*)(s + i) : NULL; &#125; 8、strchr1234567891011//return pointer to first occurrence of ch in str //NULL if not present char *strchr(const char*str, int ch) &#123; while (*str != &apos;\0&apos; &amp;&amp; *str != (char)ch) str++; if(*str == (char)ch) return (char*)str; return NULL; &#125; 9、strrchr12345678910111213141516171819//return pointer to last occurrence of ch in str //NULL if not present char *strrchr(const char *str, int ch) &#123; if (str == NULL) return NULL; char *s = (char*)str; while (*s++) ; /* find end of string */ while (--s != str &amp;&amp; *s != (char)ch) ; /* search towards front */ if(*s == (char)ch) return (char*)s; return NULL; &#125; 10、strlen12345678910size_t strlen(const char *str) &#123; if (str == NULL) return 0; const char *eos = str; while (*eos++) ; return (eos - 1 - str); &#125;]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode804. Unique Morse Code Words]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode804-Unique-Morse-Code-Words%2F</url>
    <content type="text"><![CDATA[Unique Morse Code WordsEasy International Morse Code defines a standard encoding where each letter is mapped to a series of dots and dashes, as follows: “a” maps to “.-“, “b” maps to “-…”, “c” maps to “-.-.”, and so on. For convenience, the full table for the 26 letters of the English alphabet is given below: [“.-“,”-…”,”-.-.”,”-..”,”.”,”..-.”,”–.”,”….”,”..”,”.—“,”-.-“,”.-..”,”–”,”-.”,”—“,”.–.”,”–.-“,”.-.”,”…”,”-“,”..-“,”…-“,”.–”,”-..-“,”-.–”,”–..”]Now, given a list of words, each word can be written as a concatenation of the Morse code of each letter. For example, “cba” can be written as “-.-..–…”, (which is the concatenation “-.-.” + “-…” + “.-“). We’ll call such a concatenation, the transformation of a word. Return the number of different transformations among all words we have. Example:123456789Input: words = [&quot;gin&quot;, &quot;zen&quot;, &quot;gig&quot;, &quot;msg&quot;]Output: 2Explanation: The transformation of each word is:&quot;gin&quot; -&gt; &quot;--...-.&quot;&quot;zen&quot; -&gt; &quot;--...-.&quot;&quot;gig&quot; -&gt; &quot;--...--.&quot;&quot;msg&quot; -&gt; &quot;--...--.&quot;There are 2 different transformations, &quot;--...-.&quot; and &quot;--...--.&quot;. Note: The length of words will be at most 100.Each words[i] will have length in range [1, 12].words[i] will only consist of lowercase letters. 也比较简单，主要是字符串的表示太麻烦，不太了解char*和string的表示，还有vector的使用也要新开一个Markdown记一下。 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;string&gt; codes=&#123;&quot;.-&quot;,&quot;-...&quot;,&quot;-.-.&quot;,&quot;-..&quot;,&quot;.&quot;,&quot;..-.&quot;,&quot;--.&quot;,&quot;....&quot;,&quot;..&quot;,&quot;.---&quot;,&quot;-.-&quot;,&quot;.-..&quot;,&quot;--&quot;,&quot;-.&quot;,&quot;---&quot;,&quot;.--.&quot;,&quot;--.-&quot;,&quot;.-.&quot;,&quot;...&quot;,&quot;-&quot;,&quot;..-&quot;,&quot;...-&quot;,&quot;.--&quot;,&quot;-..-&quot;,&quot;-.--&quot;,&quot;--..&quot;&#125;; int uniqueMorseRepresentations(vector&lt;string&gt;&amp; words) &#123;// map&lt;char,int&gt; table;// for(int i=0;i&lt;26;i++)&#123;// table.insert(map&lt;char, int&gt;::value_type(&apos;a&apos;+i,i));// &#125;// vector&lt;string&gt; result; for(unsigned int i=0;i&lt;words.size();i++)&#123; string temp = &quot;&quot;; for(unsigned int j=0;j&lt;words[i].length();j++)&#123; temp.append(codes[words[i][j]]-&apos;a&apos;);// temp.append(codes[table[words[i][j]]]); &#125; unsigned int k=0; for(k=0;k&lt;result.size();k++)&#123; if(result[k]==temp) break; &#125; if(k==result.size()) result.push_back(temp); temp=&quot;&quot;; &#125; return result.size(); &#125;&#125;; Runtime: 8 ms, faster than 74.00% of C++ online submissions for Unique Morse Code Words.Memory Usage: 9 MB, less than 100.00% of C++ online submissions for Unique Morse Code Words.被注释的原先的代码，比较慢，但是内存占的少。如果把代码换成上边的，取消map，就会把时间减少到4ms。 贴一个大佬的代码：1234567891011121314151617 vector&lt;string&gt; output; for(int i=0; i&lt;words.size(); i++) &#123; string s = words[i]; string morseCode = &quot;&quot;; for(int j=0; j&lt;s.length(); j++) &#123; char c = s[j]; int k = c - &apos;a&apos;; morseCode+=morseCodes[k]; &#125; if(find(output.begin(),output.end(),morseCode) == output.end()) output.push_back(morseCode); &#125; return output.size();&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode701. Insert into a Binary Search Tree]]></title>
    <url>%2F2019%2F04%2F11%2FLeetcode701-Insert-into-a-Binary-Search-Tree%2F</url>
    <content type="text"><![CDATA[Insert into a Binary Search TreeMedium Given the root node of a binary search tree (BST) and a value to be inserted into the tree, insert the value into the BST. Return the root node of the BST after the insertion. It is guaranteed that the new value does not exist in the original BST. Note that there may exist multiple valid ways for the insertion, as long as the tree remains a BST after insertion. You can return any of them. For example,1234567891011121314151617181920212223Given the tree: 4 / \ 2 7 / \ 1 3And the value to insert: 5You can return this binary search tree: 4 / \ 2 7 / \ / 1 3 5This tree is also valid: 5 / \ 2 7 / \ 1 3 \ 4 非常简单，不用详细说了，递归插入一个节点即可。 1234567891011121314151617181920212223/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* insertIntoBST(TreeNode* root, int val) &#123; if(root == NULL)&#123; root = new TreeNode(val); return root; &#125; if(val &lt; root-&gt;val) root-&gt;left = insertIntoBST(root-&gt;left,val); else root-&gt;right = insertIntoBST(root-&gt;right,val); return root; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode654. Maximum Binary Tree]]></title>
    <url>%2F2019%2F04%2F11%2FLeetcode654-Maximum-Binary-Tree%2F</url>
    <content type="text"><![CDATA[Maximum Binary TreeMedium Given an integer array with no duplicates. A maximum tree building on this array is defined as follow: The root is the maximum number in the array.The left subtree is the maximum tree constructed from left part subarray divided by the maximum number.The right subtree is the maximum tree constructed from right part subarray divided by the maximum number.Construct the maximum tree by the given array and output the root node of this tree. Example 1:12345678910Input: [3,2,1,6,0,5]Output: return the tree root node representing the following tree: 6 / \ 3 5 \ / 2 0 \ 1 Note:The size of the given array will be in the range [1,1000]. 这个题比较奇怪，其实每太懂题意，主要是给一个数组，把数组建立成一个树，找到最大的数作为root，然后递归建立，大概是这个意思。 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int max(vector&lt;int&gt;&amp; nums, int l,int r)&#123; int biggest = l; for(int i=l;i&lt;r;i++)&#123; if(nums[biggest]&lt;nums[i]) biggest = i; &#125; return biggest; &#125; TreeNode* construct(vector&lt;int&gt;&amp; nums, int l, int r)&#123; if(l == r) return NULL; int biggest = max(nums,l,r); TreeNode* root = new TreeNode(nums[biggest]); root-&gt;left=construct(nums,l,biggest); root-&gt;right=construct(nums,biggest+1,r); return root; &#125; TreeNode* constructMaximumBinaryTree(vector&lt;int&gt;&amp; nums) &#123; return construct(nums, 0, nums.size()); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c_cpp内存对齐原则及作用]]></title>
    <url>%2F2019%2F04%2F11%2Fc-cpp%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E5%8E%9F%E5%88%99%E5%8F%8A%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[struct/class/union内存对齐原则有四个： 数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始(比如int在３２位机为４字节, 则要从４的整数倍地址开始存储),基本类型不包括struct/class/uinon。 结构体作为成员:如果一个结构里有某些结构体成员,则结构体成员要从其内部”最宽基本类型成员”的整数倍地址开始存储.(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储.)。 收尾工作:结构体的总大小,也就是sizeof的结果,.必须是其内部最大成员的”最宽基本类型成员”的整数倍.不足的要补齐.(基本类型不包括struct/class/uinon)。 sizeof(union)，以结构里面size最大元素为union的size,因为在某一时刻，union只有一个成员真正存储于该地址。 实例解释：下面以class为代表1234567No. 1class Data&#123; char c; int a;&#125;;cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 12345678No. 2class Data&#123; char c; double a;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 显然程序No.1 输出的结果为 8， No.2 输出的结果为 16。No.1最大的数据成员是4bytes，1+4=5，补齐为4的倍数，也就是8。而No.2为8bytes，1+8=9，补齐为8的倍数，也就是16。 123456789No.3class Data&#123; char c; int a; char d;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 123456789No.4class Data&#123; char c; char d; int a;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; No.3运行结果为 12 No.4运行结果为 8 class中的数据成员放入内存的时候，内存拿出一个内存块来，数据成员们排队一个一个往里放，遇到太大的，不是把自己劈成两半，能放多少放多少，而是等下一个内存块过来。这样的话，就可以理解为什么No.3,No.4两端的代码输出结果不一样了，因为左边是1+（3）+4+1+（3）=12，而右边是1+1+（2）+4=8。括号中为补齐的bytes。 1234567891011121314No.5class BigData&#123; char array[33];&#125;; class Data&#123; BigData bd; int integer; double d;&#125;; cout &lt;&lt; sizeof(BigData) &lt;&lt; &quot; &quot; &lt;&lt; sizeof(Data) &lt;&lt; endl; 12345678910111213No.6class BigData&#123; char array[33];&#125;; class Data&#123; BigData bd; double d;&#125;; cout &lt;&lt; sizeof(BigData) &lt;&lt; &quot; &quot; &lt;&lt; sizeof(Data) &lt;&lt; endl; No.5和No.6运行结果均为： 48 在默认条件下，内存对齐是以class中最大的那个基本类型为基准的，如果class中有自定义类型，则递归的取其中最大的基本类型来参与比较。在No.5和No.6中内存块一个接一个的过来接走数据成员，一直到第5块的时候，BigData里只剩1个char了，将它放入内存块中，内存块还剩7个bytes，接下来是个int（4bytes），能够放下，所以也进入第5个内存块，这时候内存块还剩3bytes，而接下来是个double（8bytes），放不下，所以要等下一个内存快到来。因此，No.5的Data的size=33+4+（3）+8=48，同理No.6应该是33+（7）+8=48。 顺便提一下Union： 共用体表示几个变量共用一个内存位置，在不同的时间保存不同的数据类型和不同长度的变量。在union中，所有的共用体成员共用一个空间，并且同一时间只能储存其中一个成员变量的值。 内存对齐的主要作用是： 1、 平台原因(移植原因)：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。 2、 性能原因：经过内存对齐后，CPU的内存访问速度大大提升。具体原因稍后解释。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存管理器ptmalloc]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%99%A8ptmalloc%2F</url>
    <content type="text"><![CDATA[内存管理器ptmalloc 内存布局了解ptmalloc内存管理器，就必须得先了解操作系统的内存布局方式。通过下面这个图，我很很清晰的可以看到堆、栈等的内存分布。 X86平台LINUX进程内存布局： 上图就是linux操作系统的内存布局。内存从低到高分别展示了操作系统各个模块的内存分布。 Test Segment：存放程序代码，只读，编译的时候确定 Data Segment：存放程序运行的时候就能确定的数据，可读可写 BBS Segment：定义而没有初始化的全局变量和静态变量 Heap：堆。堆的内存地址由低到高。 Mmap：映射区域。 Stack：栈。编译器自动分配和释放。内存地址由高到低 ptmalloc内存管理器ptmalloc是glibc默认的内存管理器。我们常用的malloc和free就是由ptmalloc内存管理器提供的基础内存分配函数。ptmalloc有点像我们自己写的内存池，当我们通过malloc或者free函数来申请和释放内存的时候，ptmalloc会将这些内存管理起来，并且通过一些策略来判断是否需要回收给操作系统。这样做的最大好处就是：让用户申请内存和释放内存的时候更加高效。 为了内存分配函数malloc的高效性，ptmalloc会预先向操作系统申请一块内存供用户使用，并且ptmalloc会将已经使用的和空闲的内存管理起来；当用户需要销毁内存free的时候，ptmalloc又会将回收的内存管理起来，根据实际情况是否回收给操作系统。 设计假设ptmalloc在设计时折中了高效率，高空间利用率，高可用性等设计目标。所以有了下面一些设计上的假设条件： 具有长生命周期的大内存分配使用mmap。 特别大的内存分配总是使用mmap。 具有短生命周期的内存分配使用brk。 尽量只缓存临时使用的空闲小内存块，对大内存块或是长生命周期的大内存块在释放时都直接归还给操作系统。 对空闲的小内存块只会在malloc和free的时候进行合并，free时空闲内存块可能放入pool中，不一定归还给操作系统。 收缩堆的条件是当前free的块大小加上前后能合并chunk的大小大于64KB、，并且堆顶的大小达到阈值，才有可能收缩堆，把堆最顶端的空闲内存返回给操作系统。 需要保持长期存储的程序不适合用ptmalloc来管理内存。 不停的内存分配ptmalloc会对内存进行切割和合并，会导致一定的内存碎片 主分配区和非主分配区ptmalloc的内存分配器中，为了解决多线程锁争夺问题，分为主分配区main_area和非主分配区no_main_area。 每个进程有一个主分配区，也可以允许有多个非主分配区。 主分配区可以使用brk和mmap来分配，而非主分配区只能使用mmap来映射内存块 非主分配区的数量一旦增加，则不会减少。 主分配区和非主分配区形成一个环形链表进行管理。 chunk 内存块的基本组织单元ptmalloc通过chunk的数据结构来组织每个内存单元。当我们使用malloc分配得到一块内存的时候，这块内存就会通过chunk的形式被记录到glibc上并且管理起来。你可以把它想象成自己写内存池的时候的一个内存数据结构。chunk的结构可以分为使用中的chunk和空闲的chunk。使用中的chunk和空闲的chunk数据结构基本项同，但是会有一些设计上的小技巧，巧妙的节省了内存。 使用中的chunk： chunk指针指向chunk开始的地址；mem指针指向用户内存块开始的地址。 p=0时，表示前一个chunk为空闲，prev_size才有效 p=1时，表示前一个chunk正在使用，prev_size无效 p主要用于内存块的合并操作 ptmalloc 分配的第一个块总是将p设为1, 以防止程序引用到不存在的区域 M=1 为mmap映射区域分配；M=0为heap区域分配 A=1 为非主分区分配；A=0 为主分区分配 空闲的chunk： 空闲的chunk会被放置到空闲的链表bins上。当用户申请内存malloc的时候，会先去查找空闲链表bins上是否有合适的内存。 fp和bp分别指向前一个和后一个空闲链表上的chunk fp_nextsize和bp_nextsize分别指向前一个空闲chunk和后一个空闲chunk的大小，主要用于在空闲链表上快速查找合适大小的chunk。 fp、bp、fp_nextsize、bp_nextsize的值都会存在原本的用户区域，这样就不需要专门为每个chunk准备单独的内存存储指针了。 空闲链表bins当用户使用free函数释放掉的内存，ptmalloc并不会马上交还给操作系统（这边很多时候我们明明执行了free函数，但是进程内存并没有回收就是这个原因），而是被ptmalloc本身的空闲链表bins管理起来了，这样当下次进程需要malloc一块内存的时候，ptmalloc就会从空闲的bins上寻找一块合适大小的内存块分配给用户使用。这样的好处可以避免频繁的系统调用，降低内存分配的开销。 ptmalloc一共维护了128bin。每个bins都维护了大小相近的双向链表的chunk。 通过上图这个bins的列表就能看出，当用户调用malloc的时候，能很快找到用户需要分配的内存大小是否在维护的bin上，如果在某一个bin上，就可以通过双向链表去查找合适的chunk内存块给用户使用。 fast bins。fast bins是bins的高速缓冲区，大约有10个定长队列。当用户释放一块不大于max_fast（默认值64）的chunk（一般小内存）的时候，会默认会被放到fast bins上。当用户下次需要申请内存的时候首先会到fast bins上寻找是否有合适的chunk，然后才会到bins上空闲的chunk。ptmalloc会遍历fast bin，看是否有合适的chunk需要合并到bins上。 unsorted bin。是bins的一个缓冲区。当用户释放的内存大于max_fast或者fast bins合并后的chunk都会进入unsorted bin上。当用户malloc的时候，先会到unsorted bin上查找是否有合适的bin，如果没有合适的bin，ptmalloc会将unsorted bin上的chunk放入bins上，然后到bins上查找合适的空闲chunk。 small bins和large bins。small bins和large bins是真正用来放置chunk双向链表的。每个bin之间相差8个字节，并且通过上面的这个列表，可以快速定位到合适大小的空闲chunk。前64个为small bins，定长；后64个为large bins，非定长。 Top chunk。并不是所有的chunk都会被放到bins上。top chunk相当于分配区的顶部空闲内存，当bins上都不能满足内存分配要求的时候，就会来top chunk上分配。 mmaped chunk。当分配的内存非常大（大于分配阀值，默认128K）的时候，需要被mmap映射，则会放到mmaped chunk上，当释放mmaped chunk上的内存的时候会直接交还给操作系统。 内存分配malloc流程 获取分配区的锁，防止多线程冲突。 计算出需要分配的内存的chunk实际大小。 判断chunk的大小，如果小于max_fast（64b），则取fast bins上去查询是否有适合的chunk，如果有则分配结束。 chunk大小是否小于512B，如果是，则从small bins上去查找chunk，如果有合适的，则分配结束。 继续从 unsorted bins上查找。如果unsorted bins上只有一个chunk并且大于待分配的chunk，则进行切割，并且剩余的chunk继续扔回unsorted bins；如果unsorted bins上有大小和待分配chunk相等的，则返回，并从unsorted bins删除；如果unsorted bins中的某一chunk大小 属于small bins的范围，则放入small bins的头部；如果unsorted bins中的某一chunk大小 属于large bins的范围，则找到合适的位置放入。 从large bins中查找，找到链表头后，反向遍历此链表，直到找到第一个大小 大于待分配的chunk，然后进行切割，如果有余下的，则放入unsorted bin中去，分配则结束。 如果搜索fast bins和bins都没有找到合适的chunk，那么就需要操作top chunk来进行分配了（top chunk相当于分配区的剩余内存空间）。判断top chunk大小是否满足所需chunk的大小，如果是，则从top chunk中分出一块来。 如果top chunk也不能满足需求，则需要扩大top chunk。主分区上，如果分配的内存小于分配阀值（默认128k），则直接使用brk()分配一块内存；如果分配的内存大于分配阀值，则需要mmap来分配；非主分区上，则直接使用mmap来分配一块内存。通过mmap分配的内存，就会放入mmap chunk上，mmap chunk上的内存会直接回收给操作系统。 内存释放free流程 获取分配区的锁，保证线程安全。 如果free的是空指针，则返回，什么都不做。 判断当前chunk是否是mmap映射区域映射的内存，如果是，则直接munmap()释放这块内存。前面的已使用chunk的数据结构中，我们可以看到有M来标识是否是mmap映射的内存。 判断chunk是否与top chunk相邻，如果相邻，则直接和top chunk合并（和top chunk相邻相当于和分配区中的空闲内存块相邻）。转到步骤8 如果chunk的大小大于max_fast（64b），则放入unsorted bin，并且检查是否有合并，有合并情况并且和top chunk相邻，则转到步骤8；没有合并情况则free。 如果chunk的大小小于 max_fast（64b），则直接放入fast bin，fast bin并没有改变chunk的状态。没有合并情况，则free；有合并情况，转到步骤7 在fast bin，如果当前chunk的下一个chunk也是空闲的，则将这两个chunk合并，放入unsorted bin上面。合并后的大小如果大于64KB，会触发进行fast bins的合并操作，fast bins中的chunk将被遍历，并与相邻的空闲chunk进行合并，合并后的chunk会被放到unsorted bin中，fast bin会变为空。合并后的chunk和topchunk相邻，则会合并到topchunk中。转到步骤8 判断top chunk的大小是否大于mmap收缩阈值（默认为128KB），如果是的话，对于主分配区，则会试图归还top chunk中的一部分给操作系统。free结束。 mallopt 参数调优 M_MXFAST：用于设置fast bins中保存的chunk的最大大小，默认值为64B。最大80B M_TRIM_THRESHOLD：用于设置mmap收缩阈值，默认值为128KB。 M_MMAP_THRESHOLD：M_MMAP_THRESHOLD用于设置mmap分配阈值，默认值为128KB。当用户需要分配的内存大于mmap分配阈值，ptmalloc的malloc()函数其实相当于mmap()的简单封装，free函数相当于munmap()的简单封装。 M_MMAP_MAX：M_MMAP_MAX用于设置进程中用mmap分配的内存块的地址段数量，默认值为65536 M_TOP_PAD：该参数决定了，当libc内存管理器调用brk释放内存时，堆顶还需要保留的空闲内存数量。该值缺省为 0. 使用注意事项为了避免Glibc内存暴增，需要注意： 后分配的内存先释放，因为ptmalloc收缩内存是从top chunk开始，如果与top chunk相邻的chunk不能释放，top chunk以下的chunk都无法释放。 Ptmalloc不适合用于管理长生命周期的内存，特别是持续不定期分配和释放长生命周期的内存，这将导致ptmalloc内存暴增。 多线程分阶段执行的程序不适合用ptmalloc，这种程序的内存更适合用内存池管理 尽量减少程序的线程数量和避免频繁分配/释放内存。频繁分配，会导致锁的竞争，最终导致非主分配区增加，内存碎片增高，并且性能降低。 防止内存泄露，ptmalloc对内存泄露是相当敏感的，根据它的内存收缩机制，如果与top chunk相邻的那个chunk没有回收，将导致top chunk一下很多的空闲内存都无法返回给操作系统。 防止程序分配过多内存，或是由于Glibc内存暴增，导致系统内存耗尽，程序因OOM被系统杀掉。预估程序可以使用的最大物理内存大小，配置系统的/proc/sys/vm/overcommit_memory，/proc/sys/vm/overcommit_ratio，以及使用ulimt –v限制程序能使用虚拟内存空间大小，防止程序因OOM被杀掉。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典字符串hash函数介绍及性能比较]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%BB%8F%E5%85%B8%E5%AD%97%E7%AC%A6%E4%B8%B2hash%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/djinglan/article/details/8812934 今天根据自己的理解重新整理了一下几个字符串hash函数，使用了模板，使其支持宽字符串，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183/// @brief BKDR Hash Function /// @detail 本 算法由于在Brian Kernighan与Dennis Ritchie的《The C Programming Language》一书被展示而得 名，是一种简单快捷的hash算法，也是Java目前采用的字符串的Hash算法（累乘因子为31）。 template&lt;class T&gt; size_t BKDRHash(const T *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = hash * 131 + ch; // 也可以乘以31、131、1313、13131、131313.. // 有人说将乘法分解为位运算及加减法可以提高效率，如将上式表达为：hash = hash &lt;&lt; 7 + hash &lt;&lt; 1 + hash + ch; // 但其实在Intel平台上，CPU内部对二者的处理效率都是差不多的， // 我分别进行了100亿次的上述两种运算，发现二者时间差距基本为0（如果是Debug版，分解成位运算后的耗时还要高1/3）； // 在ARM这类RISC系统上没有测试过，由于ARM内部使用Booth&apos;s Algorithm来模拟32位整数乘法运算，它的效率与乘数有关： // 当乘数8-31位都为1或0时，需要1个时钟周期 // 当乘数16-31位都为1或0时，需要2个时钟周期 // 当乘数24-31位都为1或0时，需要3个时钟周期 // 否则，需要4个时钟周期 // 因此，虽然我没有实际测试，但是我依然认为二者效率上差别不大 &#125; return hash; &#125; /// @brief SDBM Hash Function /// @detail 本算法是由于在开源项目SDBM（一种简单的数据库引擎）中被应用而得名，它与BKDRHash思想一致，只是种子不同而已。 template&lt;class T&gt; size_t SDBMHash(const T *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = 65599 * hash + ch; //hash = (size_t)ch + (hash &lt;&lt; 6) + (hash &lt;&lt; 16) - hash; &#125; return hash; &#125; /// @brief RS Hash Function /// @detail 因Robert Sedgwicks在其《Algorithms in C》一书中展示而得名。 template&lt;class T&gt; size_t RSHash(const T *str) &#123; register size_t hash = 0; size_t magic = 63689; while (size_t ch = (size_t)*str++) &#123; hash = hash * magic + ch; magic *= 378551; &#125; return hash; &#125; /// @brief AP Hash Function /// @detail 由Arash Partow发明的一种hash算法。 template&lt;class T&gt; size_t APHash(const T *str) &#123; register size_t hash = 0; size_t ch; for (long i = 0; ch = (size_t)*str++; i++) &#123; if ((i &amp; 1) == 0) &#123; hash ^= ((hash &lt;&lt; 7) ^ ch ^ (hash &gt;&gt; 3)); &#125; else &#123; hash ^= (~((hash &lt;&lt; 11) ^ ch ^ (hash &gt;&gt; 5))); &#125; &#125; return hash; &#125; /// @brief JS Hash Function /// 由Justin Sobel发明的一种hash算法。 template&lt;class T&gt; size_t JSHash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 1315423911; while (size_t ch = (size_t)*str++) &#123; hash ^= ((hash &lt;&lt; 5) + ch + (hash &gt;&gt; 2)); &#125; return hash; &#125; /// @brief DEK Function /// @detail 本算法是由于Donald E. Knuth在《Art Of Computer Programming Volume 3》中展示而得名。 template&lt;class T&gt; size_t DEKHash(const T* str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 1315423911; while (size_t ch = (size_t)*str++) &#123; hash = ((hash &lt;&lt; 5) ^ (hash &gt;&gt; 27)) ^ ch; &#125; return hash; &#125; /// @brief FNV Hash Function /// @detail Unix system系统中使用的一种著名hash算法，后来微软也在其hash_map中实现。 template&lt;class T&gt; size_t FNVHash(const T* str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 2166136261; while (size_t ch = (size_t)*str++) &#123; hash *= 16777619; hash ^= ch; &#125; return hash; &#125; /// @brief DJB Hash Function /// @detail 由Daniel J. Bernstein教授发明的一种hash算法。 template&lt;class T&gt; size_t DJBHash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 5381; while (size_t ch = (size_t)*str++) &#123; hash += (hash &lt;&lt; 5) + ch; &#125; return hash; &#125; /// @brief DJB Hash Function 2 /// @detail 由Daniel J. Bernstein 发明的另一种hash算法。 template&lt;class T&gt; size_t DJB2Hash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 5381; while (size_t ch = (size_t)*str++) &#123; hash = hash * 33 ^ ch; &#125; return hash; &#125; /// @brief PJW Hash Function /// @detail 本算法是基于AT&amp;T贝尔实验室的Peter J. Weinberger的论文而发明的一种hash算法。 template&lt;class T&gt; size_t PJWHash(const T *str) &#123; static const size_t TotalBits = sizeof(size_t) * 8; static const size_t ThreeQuarters = (TotalBits * 3) / 4; static const size_t OneEighth = TotalBits / 8; static const size_t HighBits = ((size_t)-1) &lt;&lt; (TotalBits - OneEighth); register size_t hash = 0; size_t magic = 0; while (size_t ch = (size_t)*str++) &#123; hash = (hash &lt;&lt; OneEighth) + ch; if ((magic = hash &amp; HighBits) != 0) &#123; hash = ((hash ^ (magic &gt;&gt; ThreeQuarters)) &amp; (~HighBits)); &#125; &#125; return hash; &#125; /// @brief ELF Hash Function /// @detail 由于在Unix的Extended Library Function被附带而得名的一种hash算法，它其实就是PJW Hash的变形。 template&lt;class T&gt; size_t ELFHash(const T *str) &#123; static const size_t TotalBits = sizeof(size_t) * 8; static const size_t ThreeQuarters = (TotalBits * 3) / 4; static const size_t OneEighth = TotalBits / 8; static const size_t HighBits = ((size_t)-1) &lt;&lt; (TotalBits - OneEighth); register size_t hash = 0; size_t magic = 0; while (size_t ch = (size_t)*str++) &#123; hash = (hash &lt;&lt; OneEighth) + ch; if ((magic = hash &amp; HighBits) != 0) &#123; hash ^= (magic &gt;&gt; ThreeQuarters); hash &amp;= ~magic; &#125; &#125; return hash; &#125; 我对这些hash的散列质量及效率作了一个简单测试，测试结果如下： 测试1：对100000个由大小写字母与数字随机的ANSI字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 测试2：对100000个由任意UNICODE组成随机字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 测试3：对1000000个随机ANSI字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 结论：也许是我的样本存在一些特殊性，在对ASCII码字符串进行散列时，PJW与ELF Hash（它们其实是同一种算法）无论是质量还是效率，都相当糟糕；例如：”b5”与“aE”，这两个字符串按照PJW散列出来的hash值就是一样的。 另外，其它几种依靠异或来散列的哈希函数，如：JS/DEK/DJB Hash，在对字母与数字组成的字符串的散列效果也不怎么好。相对而言，还是BKDR与SDBM这类简单的Hash效率与效果更好。 常用的字符串Hash函数还有ELFHash，APHash等等，都是十分简单有效的方法。这些函数使用位运算使得每一个字符都对最后的函数值产生 影响。另外还有以MD5和SHA1为代表的杂凑函数，这些函数几乎不可能找到碰撞。 常用字符串哈希函数有 BKDRHash，APHash，DJBHash，JSHash，RSHash，SDBMHash，PJWHash，ELFHash等等。对于以上几种哈 希函数，我对其进行了一个小小的评测。 其中数据1为100000个字母和数字组成的随机串哈希冲突个数。数据2为100000个有意义的英文句子哈希冲突个数。数据3为数据1的哈希值与 1000003(大素数)求模后存储到线性表中冲突的个数。数据4为数据1的哈希值与10000019(更大素数)求模后存储到线性表中冲突的个数。 经过比较，得出以上平均得分。平均数为平方平均数。可以发现，BKDRHash无论是在实际效果还是编码实现中，效果都是最突出的。APHash也 是较为优秀的算法。DJBHash,JSHash,RSHash与SDBMHash各有千秋。PJWHash与ELFHash效果最差，但得分相似，其算 法本质是相似的。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的正则表达式]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[常用的正则表达式 校验数字的表达式12345678910111213141516171819数字：^[0-9]*$n位的数字：^\d&#123;n&#125;$至少n位的数字：^\d&#123;n,&#125;$m-n位的数字：^\d&#123;m,n&#125;$零和非零开头的数字：^(0|[1-9][0-9]*)$非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]&#123;1,2&#125;)?$带1-2位小数的正数或负数：^(\-)?\d+(\.\d&#123;1,2&#125;)?$正数、负数、和小数：^(\-|\+)?\d+(\.\d+)?$有两位小数的正实数：^[0-9]+(.[0-9]&#123;2&#125;)?$有1~3位小数的正实数：^[0-9]+(.[0-9]&#123;1,3&#125;)?$非零的正整数：^[1-9]\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\+?[1-9][0-9]*$非零的负整数：^\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\d*$非负整数：^\d+$ 或 ^[1-9]\d*|0$非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$非负浮点数：^\d+(\.\d+)?$ 或 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$非正浮点数：^((-\d+(\.\d+)?)|(0+(\.0+)?))$ 或 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$正浮点数：^[1-9]\d*\.\d*|0\.\d*[1-9]\d*$ 或 ^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 或 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$浮点数：^(-?\d+)(\.\d+)?$ 或 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 校验字符的表达式123456789101112汉字：^[\u4e00-\u9fa5]&#123;0,&#125;$英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$长度为3-20的所有字符：^.&#123;3,20&#125;$由26个英文字母组成的字符串：^[A-Za-z]+$由26个大写英文字母组成的字符串：^[A-Z]+$由26个小写英文字母组成的字符串：^[a-z]+$由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w&#123;3,20&#125;$中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]&#123;2,20&#125;$可以输入含有^%&amp;&apos;,;=?$\&quot;等字符：[^%&amp;&apos;,;=?$\x22]+禁止输入含有~的字符：[^~\x22]+ 特殊需求表达式123456789101112131415161718192021222324252627282930313233Email地址：^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(/.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+/.?InternetURL：[a-zA-z]+://[^\s]* 或 ^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$手机号码：^(13[0-9]|14[0-9]|15[0-9]|16[0-9]|17[0-9]|18[0-9]|19[0-9])\d&#123;8&#125;$ (由于工信部放号段不定时，所以建议使用泛解析 ^([1][3,4,5,6,7,8,9])\d&#123;9&#125;$)电话号码(&quot;XXX-XXXXXXX&quot;、&quot;XXXX-XXXXXXXX&quot;、&quot;XXX-XXXXXXX&quot;、&quot;XXX-XXXXXXXX&quot;、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\(\d&#123;3,4&#125;-)|\d&#123;3.4&#125;-)?\d&#123;7,8&#125;$ 国内电话号码(0511-4405222、021-87888822)：\d&#123;3&#125;-\d&#123;8&#125;|\d&#123;4&#125;-\d&#123;7&#125; 18位身份证号码(数字、字母x结尾)：^((\d&#123;18&#125;)|([0-9x]&#123;18&#125;)|([0-9X]&#123;18&#125;))$帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w&#123;5,17&#125;$强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$ 日期格式：^\d&#123;4&#125;-\d&#123;1,2&#125;-\d&#123;1,2&#125;一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 1.有四种钱的表示形式我们可以接受:&quot;10000.00&quot; 和 &quot;10,000.00&quot;, 和没有 &quot;分&quot; 的 &quot;10000&quot; 和 &quot;10,000&quot;：^[1-9][0-9]*$ 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 5.必须说明的是,小数点后面至少应该有1位数,所以&quot;10.&quot;是不通过的,但是 &quot;10&quot; 和 &quot;10.2&quot; 是通过的：^[0-9]+(.[0-9]&#123;2&#125;)?$ 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]&#123;1,2&#125;)?$ 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*(.[0-9]&#123;1,2&#125;)?$ 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*)(.[0-9]&#123;1,2&#125;)?$ 备注：这就是最终结果了,别忘了&quot;+&quot;可以用&quot;*&quot;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$中文字符的正则表达式：[\u4e00-\u9fa5]双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))空白行的正则表达式：\n\s*\r (可以用来删除空白行)HTML标记的正则表达式：&lt;(\S*?)[^&gt;]*&gt;.*?&lt;/\1&gt;|&lt;.*? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)首尾空白字符的正则表达式：^\s*|\s*$或(^\s*)|(\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)中国邮政编码：[1-9]\d&#123;5&#125;(?!\d) (中国邮政编码为6位数字)IP地址：\d+\.\d+\.\d+\.\d+ (提取IP地址时有用)IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d))]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于按字寻址和按字节寻址的理解]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E6%8C%89%E5%AD%97%E5%AF%BB%E5%9D%80%E5%92%8C%E6%8C%89%E5%AD%97%E8%8A%82%E5%AF%BB%E5%9D%80%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/lishuhuakai/article/details/8934540 关于按字寻址和按字节寻址的理解 我们先从一道简单的问题说起！ 设有一个1MB容量的存储器，字长32位，问：按字节编址，字编址的寻址范围以及各自的寻址范围大小? 如果按字节编址，则 1MB = 2^20B 1字节=1B=8bit 2^20B/1B = 2^20 地址范围为0~(2^20)-1,也就是说需要二十根地址线才能完成对1MB空间的编码，所以地址寄存器为20位,寻址范围大小为2^20=1M 如果按字编址，则 1MB=2^20B 1字=32bit=4B 2^20B/4B = 2^18 地范围为0~2^18-1，也就是说我们至少要用18根地址线才能完成对1MB空间的编码。因此按字编址的寻址范围是2^18 以上题目注意几点： 区分寻址空间与寻址范围两个不同的概念，寻址范围仅仅是一个数字范围，不带有单位。而寻址范围的大小很明显是一个数，指寻址区间的大小；而寻址空间指能够寻址最大容量，单位一般用MB、B来表示；本题中寻址范围为0~(2^20)-1,寻址空间为1MB。 按字节寻址，指的是存储空间的最小编址单位是字节，按字编址，是指存储空间的最小编址单位是字，以上题为例，总的存储器容量是一定的，按字编址和按字节编址所需要的编码数量是不同的，按字编址由于编址单位比较大（1字=32bit=4B），从而编码较少，而按字节编址由于编码单位较小（1字节=1B=8bit），从而编码较多。 区别M和MB。 M为数量单位。1024=1K，1024K=1M MB指容量大小。1024B=1KB，1024KB=1MB. 想要搞清按字寻址和按字节寻址就要先搞清位、字节、字长、字的定义 ： 位：数据存储的最小单位。计算机中最小的数据单位，一个位的取值只能是0或1； 字节：由八位二进制数组成，是计算机中最基本的计量单位，也是最重要的计量单位（个人理解）。 字长：计算机中对CPU在单位时间内能处理的最大二进制数的位数叫做字长。 字：字是不同计算机系统中占据一个单独的地址(内存单元的编号)并作为一个单元(由一个或多个字节组合而成)处理的一组二进制数。 下面是我对于按字寻址和按字节寻址的理解： 按字节寻址：最通俗的理解就是一组地址线的每个不同状态对应一个字节的地址。比如说有24根地址线，按字节寻址，而且每根线有两个状态，那么24根地址线组成的地址信号就有2^24个不同状态，每个状态对应一个字节的地址空间的话，24根地址线的可寻址空间2^24B，即16MB。 按字寻址：最通俗的理解就是一组地址线的每个不同状态对应一个字的地址。因为字节是计算机中最基本的计量单位且一个字由若干字节构成，所以计算机在寻址过程中会区分字里面的字节，即会给字里面的字节编址，这样就会占用部分地址线。比如说有24根地址线，按字寻址，字长16位，16位即两个字节，这样就会占用一根地址线用来字内寻址，这样就剩下23根地址线，所以寻址范围是2^23W，即8MW，这里W是字长的意思。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于数据库缓存的若干问题]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%AD%98%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[关于【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案 本文是某大佬的面试记录，扒过来学习 前言昨天晚上接到阿里的电面电话，过程中就问到了关于缓存相关的问题。 虽然以前接触过，多多少少了解了一些。但是之前自己并没有好好记录这些内容，在真正面试的时候，并没有回答得出来。今天记录一下，长长记性。 在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。 特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。 今天我们不牵涉多级缓存的知识，就把系统使用到的缓存方案，不管是一级还是多级的都统称为缓存，主要是为了讲述使用缓存的时候可能会遇到的一些问题以及一些解决办法。 我们使用缓存时，我们的业务系统大概的调用流程如下图： 当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能会出现一些现象。 缓存穿透什么是缓存穿透正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为缓存穿透。 穿透带来的问题试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。 解决办法缓存空值之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。 BloomFilterBloomFilter 类似于一个hbase set 用来判断某个元素（key）是否存在于某个集合中。这种方式在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url 是否已经被爬取过。这种方案可以加在第一种方案中，在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -&gt; 查 DB。 流程图如下： 如何选择针对于一些恶意攻击，攻击带过来的大量key 是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据。此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些key。针对这种key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。 缓存击穿什么是击穿缓存击穿是我们可能遇到的第二个使用缓存方案可能遇到的问题。在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题会造成某一时刻数据库请求量过大，压力剧增。 如何解决上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 缓存雪崩什么是缓存雪崩缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 称不住，挂掉。 解决办法事前：使用集群缓存，保证缓存服务的高可用。这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。 事中：ehcache本地缓存 + Hystrix限流&amp;降级,避免MySQL被打死。使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。使用 Hystrix进行限流 &amp; 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。 事后：开启Redis持久化机制，尽快恢复缓存集群。一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。防止雪崩方案如下图所示： 解决热点数据集中失效问题我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。 解决办法设置不同的失效时间为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。比如在一个基础的时间上加上或者减去一个范围内的随机值。 互斥锁结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出全面解析RDMA]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%85%A8%E9%9D%A2%E8%A7%A3%E6%9E%90RDMA%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/qq_21125183/article/details/80563463 RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。 背景介绍 传统TCP/IP通信模式传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。 通信网络定义计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。 当今网络现状当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。 传统TCP/IP存在的问题传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。 相关工作高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。 TCP Offloading Engine在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。 这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。 User-Net Networking(U-Net)U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。 U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。 RDMA详解RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。 RDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth RDMA 简介Remote：数据通过网络与远程机器间进行数据传输 Direct：没有内核的参与，有关发送传输的所有内容都卸载到网卡上 Memory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制 Access：send、receive、read、write、atomic操作 RDMA基本概念RDMA有两种基本操作。 Memory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。 Messaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。 RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失，以及使用链路层重传的基于位错误的损失。因此，不可靠的传输很少会丢弃数据包。 目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。 RDMA三种不同的硬件实现目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。 目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。 Infiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。 RoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。 iWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。 RDMA技术 传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。 RDMA整体系统架构图 上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。 RDMA技术详解RDMA 的工作过程如下: 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。 NIC 读取缓冲的内容，并通过网络传送到远程NIC。 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。 RDMA操作细节RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。 消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。 RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。 RDAM单边操作 (RDMA READ)READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。 对于单边操作，以存储网络环境下的存储为例，数据的流程如下： 首先A、B建立连接，QP已经创建并且初始化。 数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。 B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。 A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到A的VA虚拟地址。 A在存储完成后，会向B返回整个数据传输的状态信息。 单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。 RDMA 单边操作 (RDMA WRITE)对于单边操作，以存储网络环境下的存储为例，数据的流程如下： 首先A、B建立连接，QP已经创建并且初始化。 数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。 B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。 A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。 A在发送数据完成后，会向B返回整个数据传输的状态信息。 单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。 RDMA 双边操作 (RDMA SEND/RECEIVE)RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下： 首先，A和B都要创建并初始化好各自的QP，CQ A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。 A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。 AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。 双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中的string]]></title>
    <url>%2F2019%2F04%2F10%2Fcpp%E4%B8%AD%E7%9A%84string%2F</url>
    <content type="text"><![CDATA[标准C++中的string类的用法总结 相信使用过MFC编程的朋友对CString这个类的印象应该非常深刻吧？的确，MFC中的CString类使用起来真的非常的方便好用。但是如果离开了MFC框架，还有没有这样使用起来非常方便的类呢？答案是肯定的。也许有人会说，即使不用MFC框架，也可以想办法使用MFC中的API，具体的操作方法在本文最后给出操作方法。其实，可能很多人很可能会忽略掉标准C++中string类的使用。标准C++中提供的string类得功能也是非常强大的，一般都能满足我们开发项目时使用。现将具体用法的一部分罗列如下，只起一个抛砖引玉的作用吧，好了，废话少说，直接进入正题吧！ 要想使用标准C++中string类，必须要包含12345#include &lt;string&gt;// 注意是&lt;string&gt;，不是&lt;string.h&gt;，带.h的是C语言中的头文件using std::string;using std::wstring; 或1using namespace std; 下面你就可以使用string/wstring了，它们两分别对应着char和wchar_t。 string和wstring的用法是一样的，以下只用string作介绍： string类的构造函数：string(const char *s); //用c字符串s初始化string(int n,char c); //用n个字符c初始化此外，string类还支持默认构造函数和复制构造函数，如string s1；string s2=”hello”；都是正确的写法。当构造的string太长而无法表达时会抛出length_error异常 ； string类的字符操作：const char &amp;operatorconst;const char &amp;at(int n)const;char &amp;operator;char &amp;at(int n);operator[]和at()均返回当前字符串中第n个字符的位置，但at函数提供范围检查，当越界时会抛出out_of_range异常，下标运算符[]不提供检查访问。const char data()const;//返回一个非null终止的c字符数组const char c_str()const;//返回一个以null终止的c字符串int copy(char *s, int n, int pos = 0) const;//把当前串中以pos开始的n个字符拷贝到以s为起始位置的字符数组中，返回实际拷贝的数目 string的特性描述:int capacity()const; //返回当前容量（即string中不必增加内存即可存放的元素个数）int max_size()const; //返回string对象中可存放的最大字符串的长度int size()const; //返回当前字符串的大小int length()const; //返回当前字符串的长度bool empty()const; //当前字符串是否为空void resize(int len,char c);//把字符串当前大小置为len，并用字符c填充不足的部分 string类的输入输出操作:string类重载运算符operator&gt;&gt;用于输入，同样重载运算符operator&lt;&lt;用于输出操作。函数getline(istream &amp;in,string &amp;s);用于从输入流in中读取字符串到s中，以换行符’\n’分开。 string的赋值：string &amp;operator=(const string &amp;s);//把字符串s赋给当前字符串string &amp;assign(const char s);//用c类型字符串s赋值string &amp;assign(const char s,int n);//用c字符串s开始的n个字符赋值string &amp;assign(const string &amp;s);//把字符串s赋给当前字符串string &amp;assign(int n,char c);//用n个字符c赋值给当前字符串string &amp;assign(const string &amp;s,int start,int n);//把字符串s中从start开始的n个字符赋给当前字符串string &amp;assign(const_iterator first,const_itertor last);//把first和last迭代器之间的部分赋给字符串 string的连接：string &amp;operator+=(const string &amp;s);//把字符串s连接到当前字符串的结尾string &amp;append(const char s); //把c类型字符串s连接到当前字符串结尾string &amp;append(const char s,int n);//把c类型字符串s的前n个字符连接到当前字符串结尾string &amp;append(const string &amp;s); //同operator+=()string &amp;append(const string &amp;s,int pos,int n);//把字符串s中从pos开始的n个字符连接到当前字符串的结尾string &amp;append(int n,char c); //在当前字符串结尾添加n个字符cstring &amp;append(const_iterator first,const_iterator last);//把迭代器first和last之间的部分连接到当前字符串的结尾 string的比较：bool operator==(const string &amp;s1,const string &amp;s2)const;//比较两个字符串是否相等运算符”&gt;”,”&lt;”,”&gt;=”,”&lt;=”,”!=”均被重载用于字符串的比较；int compare(const string &amp;s) const;//比较当前字符串和s的大小int compare(int pos, int n,const string &amp;s)const;//比较当前字符串从pos开始的n个字符组成的字符串与s的大小int compare(int pos, int n,const string &amp;s,int pos2,int n2)const;//比较当前字符串从pos开始的n个字符组成的字符串与s中 //pos2开始的n2个字符组成的字符串的大小int compare(const char s) const;int compare(int pos, int n,const char s) const;int compare(int pos, int n,const char *s, int pos2) const;compare函数在&gt;时返回1，&lt;时返回-1，==时返回0 string的子串：string substr(int pos = 0,int n = npos) const;//返回pos开始的n个字符组成的字符串 string的交换：void swap(string &amp;s2); //交换当前字符串与s2的值 string类的查找函数：int find(char c, int pos = 0) const;//从pos开始查找字符c在当前字符串的位置int find(const char s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置int find(const char s, int pos, int n) const;//从pos开始查找字符串s中前n个字符在当前串中的位置int find(const string &amp;s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置//查找成功时返回所在位置，失败返回string::npos的值int rfind(char c, int pos = npos) const;//从pos开始从后向前查找字符c在当前串中的位置int rfind(const char s, int pos = npos) const;int rfind(const char s, int pos, int n = npos) const;int rfind(const string &amp;s,int pos = npos) const;//从pos开始从后向前查找字符串s中前n个字符组成的字符串在当前串中的位置，成功返回所在位置，失败时返回string::npos的值int find_first_of(char c, int pos = 0) const;//从pos开始查找字符c第一次出现的位置int find_first_of(const char s, int pos = 0) const;int find_first_of(const char s, int pos, int n) const;int find_first_of(const string &amp;s,int pos = 0) const;//从pos开始查找当前串中第一个在s的前n个字符组成的数组里的字符的位置。查找失败返回string::nposint find_first_not_of(char c, int pos = 0) const;int find_first_not_of(const char s, int pos = 0) const;int find_first_not_of(const char s, int pos,int n) const;int find_first_not_of(const string &amp;s,int pos = 0) const;//从当前串中查找第一个不在串s中的字符出现的位置，失败返回string::nposint find_last_of(char c, int pos = npos) const;int find_last_of(const char s, int pos = npos) const;int find_last_of(const char s, int pos, int n = npos) const;int find_last_of(const string &amp;s,int pos = npos) const;int find_last_not_of(char c, int pos = npos) const;int find_last_not_of(const char s, int pos = npos) const;int find_last_not_of(const char s, int pos, int n) const;int find_last_not_of(const string &amp;s,int pos = npos) const;//find_last_of和find_last_not_of与find_first_of和find_first_not_of相似，只不过是从后向前查找 string类的替换函数：string &amp;replace(int p0, int n0,const char s);//删除从p0开始的n0个字符，然后在p0处插入串sstring &amp;replace(int p0, int n0,const char s, int n);//删除p0开始的n0个字符，然后在p0处插入字符串s的前n个字符string &amp;replace(int p0, int n0,const string &amp;s);//删除从p0开始的n0个字符，然后在p0处插入串sstring &amp;replace(int p0, int n0,const string &amp;s, int pos, int n);//删除p0开始的n0个字符，然后在p0处插入串s中从pos开始的n个字符string &amp;replace(int p0, int n0,int n, char c);//删除p0开始的n0个字符，然后在p0处插入n个字符cstring &amp;replace(iterator first0, iterator last0,const char s);//把[first0，last0）之间的部分替换为字符串sstring &amp;replace(iterator first0, iterator last0,const char s, int n);//把[first0，last0）之间的部分替换为s的前n个字符string &amp;replace(iterator first0, iterator last0,const string &amp;s);//把[first0，last0）之间的部分替换为串sstring &amp;replace(iterator first0, iterator last0,int n, char c);//把[first0，last0）之间的部分替换为n个字符cstring &amp;replace(iterator first0, iterator last0,const_iterator first, const_iterator last);//把[first0，last0）之间的部分替换成[first，last）之间的字符串 string类的插入函数：string &amp;insert(int p0, const char s);string &amp;insert(int p0, const char s, int n);string &amp;insert(int p0,const string &amp;s);string &amp;insert(int p0,const string &amp;s, int pos, int n);//前4个函数在p0位置插入字符串s中pos开始的前n个字符string &amp;insert(int p0, int n, char c);//此函数在p0处插入n个字符citerator insert(iterator it, char c);//在it处插入字符c，返回插入后迭代器的位置void insert(iterator it, const_iterator first, const_iterator last);//在it处插入[first，last）之间的字符void insert(iterator it, int n, char c);//在it处插入n个字符c string类的删除函数iterator erase(iterator first, iterator last);//删除[first，last）之间的所有字符，返回删除后迭代器的位置iterator erase(iterator it);//删除it指向的字符，返回删除后迭代器的位置string &amp;erase(int pos = 0, int n = npos);//删除pos开始的n个字符，返回修改后的字符串 string类的迭代器处理：string类提供了向前和向后遍历的迭代器iterator，迭代器提供了访问各个字符的语法，类似于指针操作，迭代器不检查范围。用string::iterator或string::const_iterator声明迭代器变量，const_iterator不允许改变迭代的内容。常用迭代器函数有：const_iterator begin()const;iterator begin(); //返回string的起始位置const_iterator end()const;iterator end(); //返回string的最后一个字符后面的位置const_iterator rbegin()const;iterator rbegin(); //返回string的最后一个字符的位置const_iterator rend()const;iterator rend(); //返回string第一个字符位置的前面rbegin和rend用于从后向前的迭代访问，通过设置迭代器string::reverse_iterator,string::const_reverse_iterator实现 字符串流处理：通过定义ostringstream和istringstream变量实现，#include 头文件中例如： string input(“hello,this is a test”); istringstream is(input); string s1,s2,s3,s4; is&gt;&gt;s1&gt;&gt;s2&gt;&gt;s3&gt;&gt;s4;//s1=”hello,this”,s2=”is”,s3=”a”,s4=”test” ostringstream os; os&lt;&lt;s1&lt;&lt;s2&lt;&lt;s3&lt;&lt;s4; cout&lt;&lt;os.str(); 以上就是对C++ string类的一个简要介绍。 string特性描述可用下列函数来获得string的一些特性： int capacity()const; //返回当前容量（即string中不必增加内存即可存放的元素个数）int max_size()const; //返回string对象中可存放的最大字符串的长度int size()const; //返回当前字符串的大小int length()const; //返回当前字符串的长度bool empty()const; //当前字符串是否为空void resize(int len,char c); //把字符串当前大小置为len，多去少补，多出的字符c填充不足的部分测试代码：12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str; if (str.empty()) cout&lt;&lt;&quot;str is NULL.&quot;&lt;&lt;endl; else cout&lt;&lt;&quot;str is not NULL.&quot;&lt;&lt;endl; str = str + &quot;abcdefg&quot;; cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s size is &quot;&lt;&lt;str.size()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s capacity is &quot;&lt;&lt;str.capacity()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s max size is &quot;&lt;&lt;str.max_size()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s length is &quot;&lt;&lt;str.length()&lt;&lt;endl; str.resize(20,&apos;c&apos;); cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; str.resize(5); cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; return 0;&#125; string的查找由于查找是使用最为频繁的功能之一，string提供了非常丰富的查找函数：（注：string::npos） size_type find( const basic_string &amp;str, size_type index ); //返回str在字符串中第一次出现的位置（从index开始查找），如果没找到则返回string::npos size_type find( const char *str, size_type index ); // 同上 size_type find( const char *str, size_type index, size_type length ); //返回str在字符串中第一次出现的位置（从index开始查找，长度为length），如果没找到就返回string::npos size_type find( char ch, size_type index ); // 返回字符ch在字符串中第一次出现的位置（从index开始查找），如果没找到就返回string::npos 注意：查找字符串a是否包含子串b,不是用 strA.find(strB) &gt; 0 而是 strA.find(strB) != string:npos 这是为什么呢？（初学者比较容易犯的一个错误）本部分参考自web100与luhao1993 先看下面的代码12int idx = str.find(&quot;abc&quot;);if (idx == string::npos); 上述代码中，idx的类型被定义为int，这是错误的，即使定义为unsigned int 也是错的，它必须定义为 string::size_type。npos 是这样定义的： static const size_type npos = -1; 因为 string::size_type (由字符串配置器 allocator 定义) 描述的是 size，故需为无符号整数型别。因为缺省配置器以型别 size_t 作为 size_type，于是 -1 被转换为无符号整数型别，npos 也就成了该型别的最大无符号值。不过实际数值还是取决于型别 size_type 的实际定义。不幸的是这些最大值都不相同。事实上，(unsigned long)-1 和 (unsigned short)-1 不同(前提是两者型别大小不同)。因此，比较式 idx == string::npos 中，如果 idx 的值为-1，由于 idx 和字符串string::npos 型别不同，比较结果可能得到 false。因此要想判断 find()等查找函数的结果是否为npos，最好的办法是直接比较。 测试代码：1234567891011121314151617181920#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;int main()&#123; int loc; string s=&quot;study hard and make progress everyday! every day!!&quot;; loc=s.rfind(&quot;make&quot;,10); cout&lt;&lt;&quot;the word make is at index&quot;&lt;&lt;loc&lt;&lt;endl;//-1表示没找到 loc=s.rfind(&quot;make&quot;);//缺省状态下，从最后一个往前找 cout&lt;&lt;&quot;the word make is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_first_of(&quot;day&quot;); cout&lt;&lt;&quot;the word day(first) is at index &quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_first_not_of(&quot;study&quot;); cout&lt;&lt;&quot;the first word not of study is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_last_of(&quot;day&quot;); cout&lt;&lt;&quot;the last word of day is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find(&quot;day&quot;);//缺陷状态下从第一个往后找 cout&lt;&lt;loc; return 0;&#125; 运行结果： 其他常用函数string &amp;insert(int p,const string &amp;s); //在p位置插入字符串sstring &amp;replace(int p, int n,const char *s); //删除从p开始的n个字符，然后在p处插入串sstring &amp;erase(int p, int n); //删除p开始的n个字符，返回修改后的字符串string substr(int pos = 0,int n = npos) const; //返回pos开始的n个字符组成的字符串void swap(string &amp;s2); //交换当前字符串与s2的值string &amp;append(const char *s); //把字符串s连接到当前字符串结尾void push_back(char c) //当前字符串尾部加一个字符cconst char *data()const; //返回一个非null终止的c字符数组，data():与c_str()类似，用于string转const char*其中它返回的数组是不以空字符终止,const char *c_str()const; //返回一个以null终止的c字符串，即c_str()函数返回一个指向正规C字符串的指针, 内容与本string串相同,用于string转const char*测试代码：123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str1 = &quot;abc123defg&quot;; string str2 = &quot;swap!&quot;; cout&lt;&lt;str1&lt;&lt;endl; cout&lt;&lt;str1.erase(3,3)&lt;&lt;endl; //从索引3开始的3个字符,即删除掉了&quot;123&quot; cout&lt;&lt;str1.insert(0,&quot;123&quot;)&lt;&lt;endl; //在头部插入 cout&lt;&lt;str1.append(&quot;123&quot;)&lt;&lt;endl; //append()方法可以添加字符串 str1.push_back(&apos;A&apos;); //push_back()方法只能添加一个字符 cout&lt;&lt;str1&lt;&lt;endl; cout&lt;&lt;str1.replace(0,3,&quot;hello&quot;)&lt;&lt;endl; //即将索引0开始的3个字符替换成&quot;hello&quot; cout&lt;&lt;str1.substr(5,7)&lt;&lt;endl; //从索引5开始7个字节 str1.swap(str2); cout&lt;&lt;str1&lt;&lt;endl; const char* p = str.c_str(); printf(&quot;%s\n&quot;,p); return 0;&#125; 程序执行结果为：1234567891011121314151617abc123defgabcdefg123abcdefg123abcdefg123123abcdefg123Ahelloabcdefg123Aabcdefgswap!swap!]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中的map]]></title>
    <url>%2F2019%2F04%2F10%2Fcpp%E4%B8%AD%E7%9A%84map%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/google19890102/article/details/51720305 标准库map类型是一种以键-值(key-value)存储的数据类型。 第一个可以称为关键字(key)，每个关键字只能在map中出现一次； 第二个可能称为该关键字的值(value)； map以模板(泛型)方式实现，可以存储任意类型的数据，包括使用者自定义的数据类型。Map主要用于资料一对一映射(one-to-one)的情況，map內部的实现自建一颗红黑树，这颗树具有对数据自动排序的功能。在map内部所有的数据都是有序的。 以下分别从以下的几个方面总结： map对象的定义和初始化 map对象的基本操作，主要包括添加元素，遍历等 pair类型pair类型的定义和初始化pair类型是在有文件utility中定义的，pair类型包含了两个数据值，通常有以下的一些定义和初始化的一些方法：123pair&lt;T1, T2&gt; p;pair&lt;T1, T2&gt; p(v1, v2);make_pair(v1, v2) 上述第一种方法是定义了一个空的pair对象p，第二种方法是定义了包含初始值为v1和v2的pair对象p。第三种方法是以v1和v2值创建的一个新的pair对象。 pair对象的一些操作除此之外，pair对象还有一些方法，如取出pair对象中的每一个成员的值：12p.firstp.second 一个例子：12345678910111213#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;string&gt;#include &lt;utility&gt;using namespace std;int main()&#123; pair&lt;int, string&gt; p1(0, &quot;Hello&quot;); printf(&quot;%d, %s\n&quot;, p1.first, p1.second.c_str()); pair&lt;int, string&gt; p2 = make_pair(1, &quot;World&quot;); printf(&quot;%d, %s\n&quot;, p2.first, p2.second.c_str()); return 0;&#125; map对象的定义和初始化map是键-值对的组合，有以下的一些定义的方法：123map&lt;k, v&gt; m;map&lt;k, v&gt; m(m2);map&lt;k, v&gt; m(b, e); 上述第一种方法定义了一个名为m的空的map对象；第二种方法创建了m2的副本m；第三种方法创建了map对象m，并且存储迭代器b和e范围内的所有元素的副本。 map的value_type是存储元素的键以及值的pair类型，键为const。 使用map得包含map类所在的头文件1#include &lt;map&gt; //注意，STL头文件没有扩展名.h map对象是模板类，需要关键字和存储对象两个模板参数：1std:map&lt;int, string&gt; personnel; 这样就定义了一个用int作为索引,并拥有相关联的指向string的指针. 为了使用方便，可以对模板类进行一下类型定义，1typedef aap&lt;int,CString&gt; UDT_MAP_INT_CSTRING; map共提供了6个构造函数，这块涉及到内存分配器这些东西，略过不表，在下面我们将接触到一些map的构造方法，这里要说下的就是，我们通常用如下方法构造一个map：1map&lt;int, string&gt; mapStudent; map对象的一些基本操作map中元素的插入在map中元素有两种插入方法： 使用下标 使用insert函数 在map中使用下标访问不存在的元素将导致在map容器中添加一个新的元素。 insert函数的插入方法主要有如下： m.insert(e) m.insert(beg, end) m.insert(iter, e) 上述的e一个value_type类型的值。beg和end标记的是迭代器的开始和结束。 两种插入方法如下面的例子所示：123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 10; i ++)&#123; mp[i] = i; &#125; for (int i = 10; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d--&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; 另外的方法：12345678910111213// 定义一个map对象map&lt;int, string&gt; mapStudent; // 第一种 用insert函數插入pairmapStudent.insert(pair&lt;int, string&gt;(000, &quot;student_zero&quot;)); // 第二种 用insert函数插入value_type数据mapStudent.insert(map&lt;int, string&gt;::value_type(001, &quot;student_one&quot;)); // 第三种 用&quot;array&quot;方式插入mapStudent[123] = &quot;student_first&quot;;mapStudent[456] = &quot;student_second&quot;; 以上三种用法，虽然都可以实现数据的插入，但是它们是有区别的，当然了第一种和第二种在效果上是完成一样的，用insert函数插入数据，在数据的 插入上涉及到集合的唯一性这个概念，即当map中有这个关键字时，insert操作是不能在插入数据的，但是用数组方式就不同了，它可以覆盖以前该关键字对 应的值，用程序说明如下：12mapStudent.insert(map&lt;int, string&gt;::value_type (001, &quot;student_one&quot;));mapStudent.insert(map&lt;int, string&gt;::value_type (001, &quot;student_two&quot;)); map中元素的查找和读取注意：上述采用下标的方法读取map中元素时，若map中不存在该元素，则会在map中插入。 因此，若只是查找该元素是否存在，可以使用函数count(k)，该函数返回的是k出现的次数；若是想取得key对应的值，可以使用函数find(k)，该函数返回的是指向该元素的迭代器。 上述的两个函数的使用如下所示：123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; if (mp.count(0))&#123; printf(&quot;yes!\n&quot;); &#125;else&#123; printf(&quot;no!\n&quot;); &#125; map&lt;int, int&gt;::iterator it_find; it_find = mp.find(0); if (it_find != mp.end())&#123; it_find-&gt;second = 20; &#125;else&#123; printf(&quot;no!\n&quot;); &#125; map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d-&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; 从map中删除元素从map中删除元素的函数是erase()，该函数有如下的三种形式： m.erase(k)m.erase(p)m.erase(b, e)第一种方法删除的是m中键为k的元素，返回的是删除的元素的个数；第二种方法删除的是迭代器p指向的元素，返回的是void；第三种方法删除的是迭代器b和迭代器e范围内的元素，返回void。 如下所示：12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; mp.erase(0); mp.erase(mp.begin()); map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d-&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; map的基本操作函数：C++ maps是一种关联式容器，包含“关键字/值”对 begin() 返回指向map头部的迭代器clear() 删除所有元素count() 返回指定元素出现的次数empty() 如果map为空则返回trueend() 返回指向map末尾的迭代器equal_range() 返回特殊条目的迭代器对erase() 删除一个元素find() 查找一个元素get_allocator() 返回map的配置器insert() 插入元素key_comp() 返回比较元素key的函数lower_bound() 返回键值&gt;=给定元素的第一个位置max_size() 返回可以容纳的最大元素个数rbegin() 返回一个指向map尾部的逆向迭代器rend() 返回一个指向map头部的逆向迭代器size() 返回map中元素的个数swap() 交换两个mapupper_bound() 返回键值&gt;给定元素的第一个位置value_comp() 返回比较元素value的函数]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode535. Encode and Decode TinyURL]]></title>
    <url>%2F2019%2F04%2F10%2FLeetcode535-Encode-and-Decode-TinyURL%2F</url>
    <content type="text"><![CDATA[这道题其实不难，给一个url，要求转成一个短字符串，并且能还原出来。为什么专门做这种题呢，其实是想复习C++一些STL的用法，这道题涉及了string和map的用法，先讲题，再专门开两个md谈用法。 Encode and Decode TinyURLMedium Note: This is a companion problem to the System Design problem: Design TinyURL TinyURL is a URL shortening service where you enter a URL such as https://leetcode.com/problems/design-tinyurl and it returns a short URL such as http://tinyurl.com/4e9iAk. Design the encode and decode methods for the TinyURL service. There is no restriction on how your encode/decode algorithm should work. You just need to ensure that a URL can be encoded to a tiny URL and the tiny URL can be decoded to the original URL. 我的代码：1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: map&lt;string, int&gt; map1; map&lt;int, string&gt; map2; string s=&quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;; // Encodes a URL to a shortened URL. string encode(string longUrl) &#123; map&lt;string,int&gt;::iterator key = map1.find(longUrl); if(key==map1.end()) &#123; map1.insert(map&lt;string, int&gt;::value_type (longUrl,map1.size()+1)); map2.insert(map&lt;int, string&gt;::value_type (map2.size()+1,longUrl)); &#125; int n=map2.size(); string result; // n is the number of longUrl while(n&gt;0)&#123; printf(&quot;(%d) &quot;,n); int r = n%62; n /= 62; result.append(1,s[r]); &#125; //printf(&quot;%s\n&quot;,result); return result; &#125; // Decodes a shortened URL to its original URL. string decode(string shortUrl) &#123; int length = shortUrl.size(); int val=0; for(int i=0;i&lt;length;i++)&#123; val = val*62+s.find(shortUrl[i]); &#125; return map2.find(val)-&gt;second; &#125;&#125;;// Your Solution object will be instantiated and called as such:// Solution solution;// solution.decode(solution.encode(url)); 别人的代码：123456789101112131415161718192021222324252627class Solution &#123;public: string alphabet = &quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;; unordered_map&lt;string, string&gt; map; string key = getRandom(); string getRandom() &#123; string s; for (int i = 0; i &lt; 6 ; i++) &#123; s += alphabet[rand() % 61]; &#125; return s; &#125; // Encodes a URL to a shortened URL. string encode(string longUrl) &#123; while(map.count(key)) &#123; key = getRandom(); &#125; map.insert(make_pair(key, longUrl)); return &quot;http://tinyurl.com/&quot; + key; &#125; // Decodes a shortened URL to its original URL. string decode(string shortUrl) &#123; return map.at(shortUrl.replace(0,shortUrl.size()-6,&quot;&quot;)); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode938. Range Sum of BST]]></title>
    <url>%2F2019%2F04%2F10%2FLeetcode938-Range-Sum-of-BST%2F</url>
    <content type="text"><![CDATA[Range Sum of BSTMedium Given the root node of a binary search tree, return the sum of values of all nodes with value between L and R (inclusive). The binary search tree is guaranteed to have unique values.一棵树，给定了根节点，再给一个范围（L，R），求这棵二叉树中在这个范围内的数的和，太简单了。。。直接递归查找，没难度，还奇怪呢这么简单的题还标着个medium。。。 1234Example 1:Input: root = [10,5,15,3,7,null,18], L = 7, R = 15Output: 32 1234Example 2:Input: root = [10,5,15,3,7,13,18,1,null,6], L = 6, R = 10Output: 23 123456789101112131415161718192021/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int rangeSumBST(TreeNode* root, int L, int R) &#123; if(root)&#123; if(root-&gt;val &gt;= L &amp;&amp; root-&gt;val &lt;= R) return root-&gt;val + rangeSumBST(root-&gt;left,L,R)+rangeSumBST(root-&gt;right,L,R); else return rangeSumBST(root-&gt;left,L,R)+rangeSumBST(root-&gt;right,L,R); &#125; return 0; &#125;&#125;; Note: The number of nodes in the tree is at most 10000.The final answer is guaranteed to be less than 2^31.]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量设置]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介环境变量是在操作系统中一个具有特定名字的对象，它包含了一个或多个应用程序将使用到的信息。Linux是一个多用户的操作系统，每个用户登录系统时都会有一个专用的运行环境，通常情况下每个用户的默认的环境都是相同的。这个默认环境就是一组环境变量的定义。每个用户都可以通过修改环境变量的方式对自己的运行环境进行配置。 分类根据环境变量的生命周期我们可以将其分为永久性变量和临时性变量，根据用户等级的不同又可以将其分为系统级变量和用户级变量。怎么分都无所谓，主要是对它的理解。 对所有用户生效的永久性变量（系统级）这类变量对系统内的所有用户都生效，所有用户都可以使用这类变量。作用范围是整个系统。设置方式： 用vim在/etc/profile文件中添加我们想要的环境变量。当然，这个文件只有在root（超级用户）下才能修改。我们可以在etc目录下使用ls -l查看这个文件的用户及权限。 利用vim打开/etc/ profile文件，用export指令添加环境变量。 【注意】：添加完成后新的环境变量不会立即生效，除非你调用source /etc/profile 该文件才会生效。否则只能在下次重进此用户时才能生效。 对单一用户生效的永久性变量（用户级）该类环境变量只对当前的用户永久生效。也就是说假如用户A设置了此类环境变量，这个环境变量只有A可以使用。而对于其他的B,C,D,E….用户等等，这个变量是不存在的。 设置方法：在用户主目录”~”下的隐藏文件 “.bash_profile”中添加自己想要的环境变量。查看隐藏文件： ls -a或ls -al 利用vim打开文件，利用export添加环境变量。与上相同。同样注意，添加完成后新的环境变量不会立即生效，除非你调用source ./.bash_profile 该文件才会生效。否则只能在下次重进此用户时才能生效。 可以看到我在上图中用红框框住了两个文件，.bashrc和.bash_profile。原则上来说设置此类环境变量时在这两个文件任意一个里面添加都是可以的。 ~/.bash_profile是交互式login方式进入bash shell运行。~/ .bashrc是交互式non-login方式进入bash shell运行。 二者设置大致相同。通俗点说，就是.bash_profile文件只会在用户登录的时候读取一次，而.bashrc在每次打开终端进行一次新的会话时都会读取。 临时有效的环境变量（只对当前shell有效）此类环境变量只对当前的shell有效。当我们退出登录或者关闭终端再重新打开时，这个环境变量就会消失。是临时的。 设置方法：直接使用export指令添加。 设置环境变量常用的几个指令echo查看显示环境变量，使用时要加上符号“”例：echo”例：echoPATH export设置新的环境变量export 新环境变量名=内容例:export MYNAME=”LLZZ” 修改环境变量修改环境变量没有指令，可以直接使用环境变量名进行修改。例：MYNAME=”ZZLL” env查看所有环境变量 set查看本地定义的所有shell变量 unset删除一个环境变量例 unset MYNAME readonly设置只读环境变量。例：readonly MYNAME 常用的几个环境变量（一般都为大写）PATH指定命令的搜索路径。通过设置环境变量PATH可以让我们运行程序或指令更加方便。echo $PATH 查看环境变量PATH。 每一个冒号都是一个路径，这些搜索路径都是一些可以找到可执行程序的目录列表。当我们输入一个指令时，shell会先检查命令是否是内部命令，不是的话会再检查这个命令是否是一个应用程序。然后shell会试着从这些搜索路径，即PATH（上图中路径）中寻找这些应用程序。如果shell在这些路径目录里没有找到可执行文件。则会报错。若找到，shell内部命令或应用程序将被分解为系统调用并传给Linux内核。 举个例子：现在有一个c程序test.c通过gcc编译生成的可执行文件a.out（功能：输出helloworld）。我们平常执行这个a.out的时候是使用①相对路径调用方式： ./a.out （”.”代表当前目录，”/”分隔符）。②还可以使用绝对路径调用方式：将其全部路径写出：/home/lzk/test/a.out（此路径是我的工作目录路径，只是个例子，仅供参考） ③通过设置PATH环境变量，直接用文件名调用：在没设置PATH前，我们直接使用a.out调用程序会报错，因为shell并没有从PATH已拥有的搜索路径目录中找到a.out这个可执行程序。 使用export指令，将a.out的路径添加到搜索路径当中，export PATH=$PATH:路径我们就可以使用a.out直接执行程序。 HOME指定用户的主工作目录，即为用户登录到Linux系统中时的默认目录，即“~”。 HISTSIZE指保存历史命令记录的条数。我们输入的指令都会被系统保存下来，这个环境变量记录的就是保持指令的条数。一般为1000。 这些历史指令都被保存在用户工作主目录“~”下的隐藏文件.bash_profile中。 我们可以通过指令history来查看。 LOGNAME指当前用户的登录名 HOSTNAME指主机的名称。 SHELL指当前用户用的是哪种shell LANG/LANGUGE和语言相关的环境变量，使用多种语言的用户可以修改此环境变量。 MAIL指当前用户的邮件存放目录 PS1命令提示符，root用户是#，普通用户是$ PS2附属提示符，默认是“&gt;” SECONDS从当前shell开始运行所流逝的秒数 总结环境变量是和shell紧密相关的，用户登录系统后就启动了一个shell，对于Linux来说一般是bash（Bourne Again shell，Bourne shell（sh）的扩展），也可以切换到其他版本的shell。bash有两个基本的系统级配置文件：/etc/bashrc和/etc/profile。这些配置文件包含了两组不同的变量：shell变量和环境变量。shell变量是局部的，而环境变量是全局的。环境变量是通过shell命令来设置。设置好的环境变量又可以被所以当前用户的程序使用。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 中的各种栈]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%A0%88%2F</url>
    <content type="text"><![CDATA[栈是什么？栈有什么作用？首先，栈 (stack) 是一种串列形式的 数据结构。这种数据结构的特点是 后入先出 (LIFO, Last In First Out)，数据只能在串列的一端 (称为：栈顶 top) 进行 推入 (push) 和 弹出 (pop) 操作。根据栈的特点，很容易的想到可以利用数组，来实现这种数据结构。但是本文要讨论的并不是软件层面的栈，而是硬件层面的栈。 大多数的处理器架构，都有实现硬件栈。有专门的栈指针寄存器，以及特定的硬件指令来完成 入栈/出栈 的操作。例如在 ARM 架构上，R13 (SP) 指针是堆栈指针寄存器，而 PUSH 是用于压栈的汇编指令，POP 则是出栈的汇编指令。 【扩展阅读】：ARM 寄存器简介 ARM 处理器拥有 37 个寄存器。 这些寄存器按部分重叠组方式加以排列。 每个处理器模式都有一个不同的寄存器组。 编组的寄存器为处理处理器异常和特权操作提供了快速的上下文切换。 提供了下列寄存器： 三十个 32 位通用寄存器： 存在十五个通用寄存器，它们分别是 r0-r12、sp、lr sp (r13) 是堆栈指针。C/C++ 编译器始终将 sp 用作堆栈指针 lr (r14) 用于存储调用子例程时的返回地址。如果返回地址存储在堆栈上，则可将 lr 用作通用寄存器 程序计数器 (pc)：指令寄存器 应用程序状态寄存器 (APSR)：存放算术逻辑单元 (ALU) 状态标记的副本 当前程序状态寄存器 (CPSR)：存放 APSR 标记，当前处理器模式，中断禁用标记等 保存的程序状态寄存器 (SPSR)：当发生异常时，使用 SPSR 来存储 CPSR 上面是栈的原理和实现，下面我们来看看栈有什么作用。栈作用可以从两个方面体现：函数调用和多任务支持。 一、函数调用我们知道一个函数调用有以下三个基本过程： 调用参数的传入 局部变量的空间管理 函数返回 函数的调用必须是高效的，而数据存放在 CPU通用寄存器 或者 RAM 内存 中无疑是最好的选择。以传递调用参数为例，我们可以选择使用 CPU通用寄存器 来存放参数。但是通用寄存器的数目都是有限的，当出现函数嵌套调用时，子函数再次使用原有的通用寄存器必然会导致冲突。因此如果想用它来传递参数，那在调用子函数前，就必须先 保存原有寄存器的值，然后当子函数退出的时候再 恢复原有寄存器的值 。 函数的调用参数数目一般都相对少，因此通用寄存器是可以满足一定需求的。但是局部变量的数目和占用空间都是比较大的，再依赖有限的通用寄存器未免强人所难，因此我们可以采用某些 RAM 内存区域来存储局部变量。但是存储在哪里合适？既不能让函数嵌套调用的时候有冲突，又要注重效率。 这种情况下，栈无疑提供很好的解决办法。一、对于通用寄存器传参的冲突，我们可以再调用子函数前，将通用寄存器临时压入栈中；在子函数调用完毕后，在将已保存的寄存器再弹出恢复回来。二、而局部变量的空间申请，也只需要向下移动下栈顶指针；将栈顶指针向回移动，即可就可完成局部变量的空间释放；三、对于函数的返回，也只需要在调用子函数前，将返回地址压入栈中，待子函数调用结束后，将函数返回地址弹出给 PC 指针，即完成了函数调用的返回； 于是上述函数调用的三个基本过程，就演变记录一个栈指针的过程。每次函数调用的时候，都配套一个栈指针。即使循环嵌套调用函数，只要对应函数栈指针是不同的，也不会出现冲突。 【扩展阅读】：函数栈帧 (Stack Frame) 函数调用经常是嵌套的，在同一时刻，栈中会有多个函数的信息。每个未完成运行的函数占用一个独立的连续区域，称作栈帧(Stack Frame)。栈帧存放着函数参数，局部变量及恢复前一栈帧所需要的数据等，函数调用时入栈的顺序为： 实参N~1 → 主调函数返回地址 → 主调函数帧基指针EBP → 被调函数局部变量1~N 栈帧的边界由 栈帧基地址指针 EBP 和 栈指针 ESP 界定，EBP 指向当前栈帧底部(高地址)，在当前栈帧内位置固定；ESP指向当前栈帧顶部(低地址)，当程序执行时ESP会随着数据的入栈和出栈而移动。因此函数中对大部分数据的访问都基于EBP进行。函数调用栈的典型内存布局如下图所示： 二、多任务支持然而栈的意义还不只是函数调用，有了它的存在，才能构建出操作系统的多任务模式。我们以 main 函数调用为例，main 函数包含一个无限循环体，循环体中先调用 A 函数，再调用 B 函数。123456789func B(): return;func A(): B();func main(): while (1) A(); 试想在单处理器情况下，程序将永远停留在此 main 函数中。即使有另外一个任务在等待状态，程序是没法从此 main 函数里面跳转到另一个任务。因为如果是函数调用关系，本质上还是属于 main 函数的任务中，不能算多任务切换。此刻的 main 函数任务本身其实和它的栈绑定在了一起，无论如何嵌套调用函数，栈指针都在本栈范围内移动。 由此可以看出一个任务可以利用以下信息来表征： main 函数体代码 main 函数栈指针 当前 CPU 寄存器信息 假如我们可以保存以上信息，则完全可以强制让出 CPU 去处理其他任务。只要将来想继续执行此 main 任务的时候，把上面的信息恢复回去即可。有了这样的先决条件，多任务就有了存在的基础，也可以看出栈存在的另一个意义。在多任务模式下，当调度程序认为有必要进行任务切换的话，只需保存任务的信息（即上面说的三个内容）。恢复另一个任务的状态，然后跳转到上次运行的位置，就可以恢复运行了。 可见每个任务都有自己的栈空间，正是有了独立的栈空间，为了代码重用，不同的任务甚至可以混用任务的函数体本身，例如可以一个main函数有两个任务实例。至此之后的操作系统的框架也形成了，譬如任务在调用 sleep() 等待的时候，可以主动让出 CPU 给别的任务使用，或者分时操作系统任务在时间片用完是也会被迫的让出 CPU。不论是哪种方法，只要想办法切换任务的上下文空间，切换栈即可。 【扩展阅读】：任务、线程、进程 三者关系 任务是一个抽象的概念，即指软件完成的一个活动；而线程则是完成任务所需的动作；进程则指的是完成此动作所需资源的统称；关于三者的关系，有一个形象的比喻： 任务 = 送货 线程 = 开送货车 系统调度 = 决定合适开哪部送货车 进程 = 道路 + 加油站 + 送货车 + 修车厂 Linux 中有几种栈？各种栈的内存位置？介绍完栈的工作原理和用途作用后，我们回归到 Linux 内核上来。内核将栈分成四种： 进程栈线程栈内核栈中断栈 一、进程栈进程栈是属于用户态栈，和进程 虚拟地址空间 (Virtual Address Space) 密切相关。那我们先了解下什么是虚拟地址空间：在 32 位机器下，虚拟地址空间大小为 4G。这些虚拟地址通过页表 (Page Table) 映射到物理内存，页表由操作系统维护，并被处理器的内存管理单元 (MMU) 硬件引用。每个进程都拥有一套属于它自己的页表，因此对于每个进程而言都好像独享了整个虚拟地址空间。 Linux 内核将这 4G 字节的空间分为两部分，将最高的 1G 字节（0xC0000000-0xFFFFFFFF）供内核使用，称为 内核空间。而将较低的3G字节（0x00000000-0xBFFFFFFF）供各个进程使用，称为 用户空间。每个进程可以通过系统调用陷入内核态，因此内核空间是由所有进程共享的。虽然说内核和用户态进程占用了这么大地址空间，但是并不意味它们使用了这么多物理内存，仅表示它可以支配这么大的地址空间。它们是根据需要，将物理内存映射到虚拟地址空间中使用。 Linux 对进程地址空间有个标准布局，地址空间中由各个不同的内存段组成 (Memory Segment)，主要的内存段如下： 程序段 (Text Segment)：可执行文件代码的内存映射 数据段 (Data Segment)：可执行文件的已初始化全局变量的内存映射 BSS段 (BSS Segment)：未初始化的全局变量或者静态变量（用零页初始化） 堆区 (Heap) : 存储动态内存分配，匿名的内存映射 栈区 (Stack) : 进程用户空间栈，由编译器自动分配释放，存放函数的参数值、局部变量的值等 映射段(Memory Mapping Segment)：任何内存映射文件 而上面进程虚拟地址空间中的栈区，正指的是我们所说的进程栈。进程栈的初始化大小是由编译器和链接器计算出来的，但是栈的实时大小并不是固定的，Linux 内核会根据入栈情况对栈区进行动态增长（其实也就是添加新的页表）。但是并不是说栈区可以无限增长，它也有最大限制 RLIMIT_STACK (一般为 8M)，我们可以通过 ulimit 来查看或更改 RLIMIT_STACK 的值。 【扩展阅读】：如何确认进程栈的大小 我们要知道栈的大小，那必须得知道栈的起始地址和结束地址。栈起始地址 获取很简单，只需要嵌入汇编指令获取栈指针 esp 地址即可。栈结束地址 的获取有点麻烦，我们需要先利用递归函数把栈搞溢出了，然后再 GDB 中把栈溢出的时候把栈指针 esp 打印出来即可。代码如下：1234567891011121314/* file name: stacksize.c */void *orig_stack_pointer;void blow_stack() &#123; blow_stack();&#125;int main() &#123; __asm__(&quot;movl %esp, orig_stack_pointer&quot;); blow_stack(); return 0;&#125; 1234567891011121314$ g++ -g stacksize.c -o ./stacksize$ gdb ./stacksize(gdb) rStarting program: /home/home/misc-code/setrlimitProgram received signal SIGSEGV, Segmentation fault.blow_stack () at setrlimit.c:44 blow_stack();(gdb) print (void *)$esp$1 = (void *) 0xffffffffff7ff000(gdb) print (void *)orig_stack_pointer$2 = (void *) 0xffffc800(gdb) print 0xffffc800-0xff7ff000$3 = 8378368 // Current Process Stack Size is 8M 上面对进程的地址空间有个比较全局的介绍，那我们看下 Linux 内核中是怎么体现上面内存布局的。内核使用内存描述符来表示进程的地址空间，该描述符表示着进程所有地址空间的信息。内存描述符由 mm_struct 结构体表示，下面给出内存描述符结构中各个域的描述，请大家结合前面的 进程内存段布局 图一起看： 12345678910111213141516171819202122232425struct mm_struct &#123; struct vm_area_struct *mmap; /* 内存区域链表 */ struct rb_root mm_rb; /* VMA 形成的红黑树 */ ... struct list_head mmlist; /* 所有 mm_struct 形成的链表 */ ... unsigned long total_vm; /* 全部页面数目 */ unsigned long locked_vm; /* 上锁的页面数据 */ unsigned long pinned_vm; /* Refcount permanently increased */ unsigned long shared_vm; /* 共享页面数目 Shared pages (files) */ unsigned long exec_vm; /* 可执行页面数目 VM_EXEC &amp; ~VM_WRITE */ unsigned long stack_vm; /* 栈区页面数目 VM_GROWSUP/DOWN */ unsigned long def_flags; unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */ unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */ unsigned long arg_start, arg_end, env_start, env_end; /* 命令行参数 和 环境变量的 起始地址和结束地址 */ ... /* Architecture-specific MM context */ mm_context_t context; /* 体系结构特殊数据 */ /* Must use atomic bitops to access the bits */ unsigned long flags; /* 状态标志位 */ ... /* Coredumping and NUMA and HugePage 相关结构体 */&#125;; 【扩展阅读】：进程栈的动态增长实现 进程在运行的过程中，通过不断向栈区压入数据，当超出栈区容量时，就会耗尽栈所对应的内存区域，这将触发一个 缺页异常 (page fault)。通过异常陷入内核态后，异常会被内核的 expand_stack() 函数处理，进而调用 acct_stack_growth() 来检查是否还有合适的地方用于栈的增长。 如果栈的大小低于 RLIMIT_STACK（通常为8MB），那么一般情况下栈会被加长，程序继续执行，感觉不到发生了什么事情，这是一种将栈扩展到所需大小的常规机制。然而，如果达到了最大栈空间的大小，就会发生 栈溢出（stack overflow），进程将会收到内核发出的 段错误（segmentation fault） 信号。 动态栈增长是唯一一种访问未映射内存区域而被允许的情形，其他任何对未映射内存区域的访问都会触发页错误，从而导致段错误。一些被映射的区域是只读的，因此企图写这些区域也会导致段错误。 二、线程栈从 Linux 内核的角度来说，其实它并没有线程的概念。Linux 把所有线程都当做进程来实现，它将线程和进程不加区分的统一到了 task_struct 中。线程仅仅被视为一个与其他进程共享某些资源的进程，而是否共享地址空间几乎是进程和 Linux 中所谓线程的唯一区别。线程创建的时候，加上了 CLONE_VM 标记，这样 线程的内存描述符 将直接指向 父进程的内存描述符。1234567if (clone_flags &amp; CLONE_VM) &#123; /* * current 是父进程而 tsk 在 fork() 执行期间是共享子进程 */ atomic_inc(&amp;current-&gt;mm-&gt;mm_users); tsk-&gt;mm = current-&gt;mm;&#125; 虽然线程的地址空间和进程一样，但是对待其地址空间的 stack 还是有些区别的。对于 Linux 进程或者说主线程，其 stack 是在 fork 的时候生成的，实际上就是复制了父亲的 stack 空间地址，然后写时拷贝 (cow) 以及动态增长。然而对于主线程生成的子线程而言，其 stack 将不再是这样的了，而是事先固定下来的，使用 mmap 系统调用，它不带有 VM_STACK_FLAGS 标记。这个可以从 glibc 的nptl/allocatestack.c 中的 allocate_stack() 函数中看到：12mem = mmap (NULL, size, prot, MAP_PRIVATE | MAP_ANONYMOUS | MAP_STACK, -1, 0); 由于线程的 mm-&gt;start_stack 栈地址和所属进程相同，所以线程栈的起始地址并没有存放在 task_struct 中，应该是使用 pthread_attr_t 中的 stackaddr 来初始化 task_struct-&gt;thread-&gt;sp（sp 指向 struct pt_regs 对象，该结构体用于保存用户进程或者线程的寄存器现场）。这些都不重要，重要的是，线程栈不能动态增长，一旦用尽就没了，这是和生成进程的 fork 不同的地方。由于线程栈是从进程的地址空间中 map 出来的一块内存区域，原则上是线程私有的。但是同一个进程的所有线程生成的时候浅拷贝生成者的 task_struct 的很多字段，其中包括所有的 vma，如果愿意，其它线程也还是可以访问到的，于是一定要注意。 三、进程内核栈在每一个进程的生命周期中，必然会通过到系统调用陷入内核。在执行系统调用陷入内核之后，这些内核代码所使用的栈并不是原先进程用户空间中的栈，而是一个单独内核空间的栈，这个称作进程内核栈。进程内核栈在进程创建的时候，通过 slab 分配器从 thread_info_cache 缓存池中分配出来，其大小为 THREAD_SIZE，一般来说是一个页大小 4K；12345union thread_union &#123; struct thread_info thread_info; unsigned long stack[THREAD_SIZE/sizeof(long)];&#125;; ` thread_union 进程内核栈 和 task_struct 进程描述符有着紧密的联系。由于内核经常要访问 task_struct，高效获取当前进程的描述符是一件非常重要的事情。因此内核将进程内核栈的头部一段空间，用于存放 thread_info 结构体，而此结构体中则记录了对应进程的描述符，两者关系如下图（对应内核函数为 dup_task_struct()）： 有了上述关联结构后，内核可以先获取到栈顶指针 esp，然后通过 esp 来获取 thread_info。这里有一个小技巧，直接将 esp 的地址与上 ~(THREAD_SIZE - 1) 后即可直接获得 thread_info 的地址。由于 thread_union 结构体是从 thread_info_cache 的 Slab 缓存池中申请出来的，而 thread_info_cache 在 kmem_cache_create 创建的时候，保证了地址是 THREAD_SIZE 对齐的。因此只需要对栈指针进行 THREAD_SIZE 对齐，即可获得 thread_union 的地址，也就获得了 thread_union 的地址。成功获取到 thread_info 后，直接取出它的 task 成员就成功得到了 task_struct。其实上面这段描述，也就是 current 宏的实现方法：1234567891011register unsigned long current_stack_pointer asm (&quot;sp&quot;);static inline struct thread_info *current_thread_info(void) &#123; return (struct thread_info *) (current_stack_pointer &amp; ~(THREAD_SIZE - 1));&#125; #define get_current() (current_thread_info()-&gt;task)#define current get_current() 四、中断栈进程陷入内核态的时候，需要内核栈来支持内核函数调用。中断也是如此，当系统收到中断事件后，进行中断处理的时候，也需要中断栈来支持函数调用。由于系统中断的时候，系统当然是处于内核态的，所以中断栈是可以和内核栈共享的。但是具体是否共享，这和具体处理架构密切相关。 X86 上中断栈就是独立于内核栈的；独立的中断栈所在内存空间的分配发生在 arch/x86/kernel/irq_32.c 的 irq_ctx_init() 函数中(如果是多处理器系统，那么每个处理器都会有一个独立的中断栈)，函数使用 __alloc_pages 在低端内存区分配 2个物理页面，也就是8KB大小的空间。有趣的是，这个函数还会为 softirq 分配一个同样大小的独立堆栈。如此说来，softirq 将不会在 hardirq 的中断栈上执行，而是在自己的上下文中执行。 而 ARM 上中断栈和内核栈则是共享的；中断栈和内核栈共享有一个负面因素，如果中断发生嵌套，可能会造成栈溢出，从而可能会破坏到内核栈的一些重要数据，所以栈空间有时候难免会捉襟见肘。 Linux 为什么需要区分这些栈？为什么需要区分这些栈，其实都是设计上的问题。这里就我看到过的一些观点进行汇总，供大家讨论： 为什么需要单独的进程内核栈？ 所有进程运行的时候，都可能通过系统调用陷入内核态继续执行。假设第一个进程 A 陷入内核态执行的时候，需要等待读取网卡的数据，主动调用 schedule() 让出 CPU；此时调度器唤醒了另一个进程 B，碰巧进程 B 也需要系统调用进入内核态。那问题就来了，如果内核栈只有一个，那进程 B 进入内核态的时候产生的压栈操作，必然会破坏掉进程 A 已有的内核栈数据；一但进程 A 的内核栈数据被破坏，很可能导致进程 A 的内核态无法正确返回到对应的用户态了；为什么需要单独的线程栈？ Linux 调度程序中并没有区分线程和进程，当调度程序需要唤醒”进程”的时候，必然需要恢复进程的上下文环境，也就是进程栈；但是线程和父进程完全共享一份地址空间，如果栈也用同一个那就会遇到以下问题。假如进程的栈指针初始值为 0x7ffc80000000；父进程 A 先执行，调用了一些函数后栈指针 esp 为 0x7ffc8000FF00，此时父进程主动休眠了；接着调度器唤醒子线程 A1：此时 A1 的栈指针 esp 如果为初始值 0x7ffc80000000，则线程 A1 一但出现函数调用，必然会破坏父进程 A 已入栈的数据。如果此时线程 A1 的栈指针和父进程最后更新的值一致，esp 为 0x7ffc8000FF00，那线程 A1 进行一些函数调用后，栈指针 esp 增加到 0x7ffc8000FFFF，然后线程 A1 休眠；调度器再次换成父进程 A 执行，那这个时候父进程的栈指针是应该为 0x7ffc8000FF00 还是 0x7ffc8000FFFF 呢？无论栈指针被设置到哪个值，都会有问题不是吗？进程和线程是否共享一个内核栈？ No，线程和进程创建的时候都调用 dup_task_struct 来创建 task 相关结构体，而内核栈也是在此函数中 alloc_thread_info_node 出来的。因此虽然线程和进程共享一个地址空间 mm_struct，但是并不共享一个内核栈。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态链接库中函数的地址确定]]></title>
    <url>%2F2019%2F04%2F09%2F%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%BA%93%E4%B8%AD%E5%87%BD%E6%95%B0%E7%9A%84%E5%9C%B0%E5%9D%80%E7%A1%AE%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[有一个问题是我们调用了动态链接库里面的函数，我们怎么知道动态链接库里面的函数的地址呢？事实上，直到我们第一次调用这个函数，我们并不知道这个函数的地址，这个功能要做延迟绑定 lazy bind。 因为程序的分支很多，并不是所有的分支都能跑到，想想我们的异常处理，异常处理分支的动态链接库里面的函数也许永远跑不到，所以，一上来就解析所有出现过的动态库里面的函数是个浪费的办法，降低性能并且没有必要。 下面我们看下延迟绑定的效果。我写了个程序，先睡15s，然后pthread_create 一个线程。我们用LD_DEBUG观察符号的解析。123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;void* myfunc()&#123; while(1) &#123; sleep(10); &#125; return NULL;&#125;int main()&#123; sleep(15); pthread_t tid = 0; int ret = pthread_create(&amp;tid,NULL,myfunc,NULL); if(ret) &#123; fprintf(stderr,&quot;pthread create failed %m \n&quot;); return -1; &#125; ret = pthread_join(tid,NULL); if(ret) &#123; fprintf(stderr,&quot;pthread join failed %m\n&quot;); return -2; &#125; return 0;&#125; 1234567891011121314151617root@libin:~/program/C/plt_got# LD_DEBUG=symbols ./test2849: symbol=_res; lookup in file=./test [0]2849: symbol=_res; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=_res; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=_IO_file_close; lookup in file=./test [0]2849: symbol=_IO_file_close; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=_IO_file_close; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=rpc_createerr; lookup in file=./test [0]2849: symbol=rpc_createerr; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=rpc_createerr; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: transferring control: ./test2849:2849: symbol=sleep; lookup in file=./test [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]=================================================================================== 然后停了15s，才解析出pthread_create的地址，由此可见，得确是运行时重定位，知道用到这个函数pthread_create才真正去找这个函数的地址。 123456789101112132849: 2849: symbol=sleep; lookup in file=./test [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]===================================================================================2849: symbol=pthread_create; lookup in file=./test [0]2849: symbol=pthread_create; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=__getpagesize; lookup in file=./test [0]2849: symbol=__getpagesize; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=__getpagesize; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=mmap; lookup in file=./test [0]2849: symbol=mmap; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=mmap; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0] 真正动态库中函数地址的解析是第一次调用的时候做的，然后如果再次用到动态库的解析过的函数，就直接用第一次解析的结果。很自然的想法就是，一定有地方存储函数的地址，否则第一次解析出来的结果，第二次调用也没法利用。 这个存储动态库函数的地方就要GOT，Global Offset Table。 OK，我们可以想象，如果我的程序里面用到了6个动态库里面的函数，那个这个GOT里面就应该存有6个条目，每个条目里面存储着对应函数的地址。事实的确是这样： 123456789101112131415root@libin:~/program/C/plt_got# readelf -r testRelocation section &apos;.rel.dyn&apos; at offset 0x394 contains 2 entries:Offset Info Type Sym.Value Sym. Name08049ff0 00000206 R_386_GLOB_DAT 00000000 __gmon_start__0804a020 00000905 R_386_COPY 0804a020 stderrRelocation section &apos;.rel.plt&apos; at offset 0x3a4 contains 6 entries:Offset Info Type Sym.Value Sym. Name0804a000 00000107 R_386_JUMP_SLOT 00000000 pthread_join0804a004 00000207 R_386_JUMP_SLOT 00000000 __gmon_start__0804a008 00000407 R_386_JUMP_SLOT 00000000 __libc_start_main0804a00c 00000507 R_386_JUMP_SLOT 00000000 fprintf0804a010 00000607 R_386_JUMP_SLOT 00000000 pthread_create0804a014 00000707 R_386_JUMP_SLOT 00000000 sleep 我们看到了有全局变量stderr和gmon_start需要重定位，这些本文并不关心。下面是需要重定位的函数，可以看出，我们调用动态库里面的函数都在这了，fprintf是Glibc库的，pthread_create是pthread库的等等。 .got.plt这个段的起始地址是0x8049ff4。 .got.plt这个section大小为0x24 = 36,可是我们只有6个需要解析地址的function，4*6=24个字节，只需要24个字节就能存放这6个函数指针。多出来的12个字节是dynamic段地址，ModuleID 和 _dl_runtime_resolve的地址，如下图所示 OK 。我们看一下：123456789101112131415(gdb) b mainBreakpoint 1 at 0x8048551: file test.c, line 19.(gdb) rStarting program: /home/libin/program/C/plt_got/test[Thread debugging using libthread_db enabled]Breakpoint 1, main () at test.c:1919 sleep(15);(gdb) x/24x 0x8049ff40x8049ff4 &lt;_GLOBAL_OFFSET_TABLE_&gt;: 0x08049f18 0x0012c8f8 0x00123270 0x0804841a0x804a004 &lt;_GLOBAL_OFFSET_TABLE_+16&gt;: 0x0804842a 0x0015daf0 0x0804844a 0x0804845a0x804a014 &lt;_GLOBAL_OFFSET_TABLE_+32&gt;: 0x0804846a 0x00000000 0x00000000 0x0029c5800x804a024 : 0x00000000 0x00000000 0x00000000 0x000000000x804a034: 0x00000000 0x00000000 0x00000000 0x000000000x804a044: 0x00000000 0x00000000 0x00000000 0x00000000 蓝色的0x0849f18是dynamic段的地址1[21] .dynamic DYNAMIC 08049f18 000f18 0000d8 08 WA 7 0 4 接下来，我们要分析PLT 和GOT的关系了。1234567(gdb) disas main0x0804857e &lt;+54&gt;: lea 0x1c(%esp),%eax0x08048582 &lt;+58&gt;: mov %eax,(%esp)0x08048585 &lt;+61&gt;: call 0x8048454 &lt;pthread_create@plt&gt;0x0804858a &lt;+66&gt;: mov %eax,0x18(%esp)0x0804858e &lt;+70&gt;: cmpl $0x0,0x18(%esp) 要执行pthread_create 函数，跳到PLT部分。12345678910111213141516171819202122232425262728293031323334353637383940libin@libin:~/program/C/plt_got$ objdump -dj .plt testtest: file format elf32-i386Disassembly of section .plt:08048404 :8048404: ff 35 f8 9f 04 08 pushl 0x8049ff8804840a: ff 25 fc 9f 04 08 jmp *0x8049ffc8048410: 00 00 add %al,(%eax)08048414 :8048414: ff 25 00 a0 04 08 jmp *0x804a000804841a: 68 00 00 00 00 push $0x0804841f: e9 e0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048424 &lt;__gmon_start__@plt&gt;:8048424: ff 25 04 a0 04 08 jmp *0x804a004804842a: 68 08 00 00 00 push $0x8804842f: e9 d0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048434 &lt;__libc_start_main@plt&gt;:8048434: ff 25 08 a0 04 08 jmp *0x804a008804843a: 68 10 00 00 00 push $0x10804843f: e9 c0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048444 :8048444: ff 25 0c a0 04 08 jmp *0x804a00c804844a: 68 18 00 00 00 push $0x18804844f: e9 b0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048454 :8048454: ff 25 10 a0 04 08 jmp *0x804a010804845a: 68 20 00 00 00 push $0x20804845f: e9 a0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048464 :8048464: ff 25 14 a0 04 08 jmp *0x804a014804846a: 68 28 00 00 00 push $0x28804846f: e9 90 ff ff ff jmp 8048404 &lt;_init+0x30&gt; PLT部分认为pthread_create函数存放在GOT，0x804a010是GOT里面的一个条目，这个条目存储着pthread_create函数的地址。当第二次以至于第N次调用pthead_create的时候，的的确确存放着pthread_create的地址，但是第一次不行，第一次这个条目里面还没记录这个地址。那么这个条目记录的是什么呢？ 123456789101112131415(gdb) x/10i 0x80484540x8048454 : jmp *0x804a0100x804845a : push $0x200x804845f : jmp 0x80484040x8048464 : jmp *0x804a0140x804846a : push $0x280x804846f : jmp 0x80484040x8048474: add %al,(%eax)0x8048476: add %al,(%eax)0x8048478: add %al,(%eax)0x804847a: add %al,(%eax)(gdb) x/10x 0x804a0100x804a010 &lt;_GLOBAL_OFFSET_TABLE_+28&gt;: 0x0804845a 0x0804846a 0x00000000 0x000000000x804a020 : 0x0029c580 0x00000000 0x00000000 0x000000000x804a030: 0x00000000 0x00000000 0x804a010这个地址最终应该记录的是pthread_create的地址，但是目前还不是，记录的是0x084845a 123408048454 :8048454: ff 25 10 a0 04 08 jmp *0x804a010804845a: 68 20 00 00 00 push $0x20804845f: e9 a0 ff ff ff jmp 8048404 &lt;_init+0x30&gt; 从PLT跳到GOT 找地址，但是第一次找的时候，并不是pthread_create的地址，而是又跳回来PLT，我们看到push了0x20之后，跳到了0x8048404。 每一个PLT的代码段，都是push了一个值之后，跳到了0x8048404。大家可以去上面的图验证。 接下来，我们看0x8048404存放的是啥指令：1234567891011(gdb) x/10i 0x8048404 0x8048404: pushl 0x8049ff8 0x804840a: jmp *0x8049ffc 0x8048410: add %al,(%eax) 0x8048412: add %al,(%eax) 0x8048414 &lt;&lt;/span&gt;pthread_join@plt&gt;: jmp *0x804a000 0x804841a &lt;&lt;/span&gt;pthread_join@plt+6&gt;: push $0x0 0x804841f &lt;&lt;/span&gt;pthread_join@plt+11&gt;: jmp 0x8048404 0x8048424 &lt;&lt;/span&gt;__gmon_start__@plt&gt;: jmp *0x804a004 0x804842a &lt;&lt;/span&gt;__gmon_start__@plt+6&gt;: push $0x8 0x804842f &lt;&lt;/span&gt;__gmon_start__@plt+11&gt;: jmp 0x8048404 123456789101112131415161718192021222324252627282930313233343536373839404142434445(gdb) x/10x 0x8049ffc0x8049ffc &lt;&lt;/span&gt;_GLOBAL_OFFSET_TABLE_+8&gt;: 0x00123270 0x0804841a 0x0804842a 0x0015daf00x804a00c &lt;&lt;/span&gt;_GLOBAL_OFFSET_TABLE_+24&gt;: 0x0804844a 0x0804845a 0x0804846a 0x000000000x804a01c &lt;&lt;/span&gt;__dso_handle&gt;: 0x00000000 0x0029c580(gdb) x/10i 0x00123270 0x123270 &lt;&lt;/span&gt;_dl_runtime_resolve&gt;: push %eax 0x123271 &lt;&lt;/span&gt;_dl_runtime_resolve+1&gt;: push %ecx 0x123272 &lt;&lt;/span&gt;_dl_runtime_resolve+2&gt;: push %edx 0x123273 &lt;&lt;/span&gt;_dl_runtime_resolve+3&gt;: mov 0x10(%esp),%edx 0x123277 &lt;&lt;/span&gt;_dl_runtime_resolve+7&gt;: mov 0xc(%esp),%eax 0x12327b &lt;&lt;/span&gt;_dl_runtime_resolve+11&gt;: call 0x11d5a0 &lt;&lt;/span&gt;_dl_fixup&gt; 0x123280 &lt;&lt;/span&gt;_dl_runtime_resolve+16&gt;: pop %edx 0x123281 &lt;&lt;/span&gt;_dl_runtime_resolve+17&gt;: mov (%esp),%ecx 0x123284 &lt;&lt;/span&gt;_dl_runtime_resolve+20&gt;: mov %eax,(%esp) 0x123287 &lt;&lt;/span&gt;_dl_runtime_resolve+23&gt;: mov 0x4(%esp),%eax````` 我们看到0x8049ffc就是GOT的第三项，前文提到的dl_runtime_resolve的地址。这个函数将帮助我们将pthread_create函数地址定位，并且填入GOT表的相应位置 0x804a010。 我们watch下GOT pthread_create对应条目，看下这个条目啥时候变化：````` (gdb) b mainBreakpoint 1 at 0x8048551: file test.c, line 19.(gdb) rStarting program: /home/libin/program/C/plt_got/test [Thread debugging using libthread_db enabled]Breakpoint 1, main () at test.c:1919 sleep(15);(gdb) watch *0x804a010Hardware watchpoint 2: *0x804a010(gdb) cContinuing.Hardware watchpoint 2: *0x804a010Old value = 134513754New value = 1260912_dl_fixup (l=&lt;&lt;/span&gt;value optimized out&gt;, reloc_arg=&lt;&lt;/span&gt;value optimized out&gt;) at dl-runtime.c:155155 dl-runtime.c: 没有那个文件或目录. in dl-runtime.c(gdb) bt#0 _dl_fixup (l=&lt;&lt;/span&gt;value optimized out&gt;, reloc_arg=&lt;&lt;/span&gt;value optimized out&gt;) at dl-runtime.c:155#1 0x00123280 in _dl_runtime_resolve () at ../sysdeps/i386/dl-trampoline.S:37#2 0x0804858a in main () at test.c:21(gdb)`` 看到了，是_dl_runtime_resolve调用了_dl_fixup修改了GOT的对应条目。 (gdb) x/10i 1260912 0x133d70 &lt;&lt;/span&gt;__pthread_create_2_1&gt;: push %ebp 0x133d71 &lt;&lt;/span&gt;__pthread_create_2_1+1&gt;: mov %esp,%ebp 0x133d73 &lt;&lt;/span&gt;__pthread_create_2_1+3&gt;: push %edi 0x133d74 &lt;&lt;/span&gt;__pthread_create_2_1+4&gt;: push %esi 0x133d75 &lt;&lt;/span&gt;__pthread_create_2_1+5&gt;: push %ebx 0x133d76 &lt;&lt;/span&gt;__pthread_create_2_1+6&gt;: call 0x132340 &lt;&lt;/span&gt;__i686.get_pc_thunk.bx&gt; 0x133d7b &lt;&lt;/span&gt;__pthread_create_2_1+11&gt;: add $0x10279,%ebx 0x133d81 &lt;&lt;/span&gt;__pthread_create_2_1+17&gt;: sub $0x4c,%esp 0x133d84 &lt;&lt;/span&gt;__pthread_create_2_1+20&gt;: mov 0xc(%ebp),%edx 0x133d87 &lt;&lt;/span&gt;__pthread_create_2_1+23&gt;: test %edx,%edx 这是第一次。第二次就比较简单了，因为GOT里面有一个条目已经有了pthread_create函数的地址。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存管理]]></title>
    <url>%2F2019%2F04%2F09%2Fcpp%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[导语内存管理是C++最令人切齿痛恨的问题，也是C++最有争议的问题，C++高手从中获得了更好的性能，更大的自由，C++菜鸟的收获则是一遍一遍的检查代码和对C++的痛恨，但内存管理在C++中无处不在，内存泄漏几乎在每个C++程序中都会发生，因此要想成为C++高手，内存管理一关是必须要过的，除非放弃C++，转到Java或者.NET，他们的内存管理基本是自动的，当然你也放弃了自由和对内存的支配权，还放弃了C++超绝的性能。本期专题将从内存管理、内存泄漏、内存回收这三个方面来探讨C++内存管理问题。 内存管理伟大的Bill Gates 曾经失言： 640K ought to be enough for everybody —— Bill Gates 1981 程序员们经常编写内存管理程序，往往提心吊胆。如果不想触雷，唯一的解决办法就是发现所有潜伏的地雷并且排除它们，躲是躲不了的。本文的内容比一般教科书的要深入得多，读者需细心阅读，做到真正地通晓内存管理。 C++内存管理详解内存分配方式分配方式简介在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。 栈，在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。 自由存储区，就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。 明确区分堆与栈在bbs上，堆与栈的区分问题，似乎是一个永恒的话题，由此可见，初学者对此往往是混淆不清的，所以我决定拿他第一个开刀。 首先，我们举一个例子：1void f() &#123; int* p=new int[5]; &#125; 这条短短的一句话就包含了堆与栈，看到new，我们首先就应该想到，我们分配了一块堆内存，那么指针p呢？他分配的是一块栈内存，所以这句话的意思就是：在栈内存中存放了一个指向一块堆内存的指针p。在程序会先确定在堆中分配内存的大小，然后调用operator new分配内存，然后返回这块内存的首地址，放入栈中，他在VC6下的汇编代码如下：12345600401028 push 14h0040102A call operator new (00401060)0040102F add esp,400401032 mov dword ptr [ebp-8],eax00401035 mov eax,dword ptr [ebp-8]00401038 mov dword ptr [ebp-4],eax 这里，我们为了简单并没有释放内存，那么该怎么去释放呢？是delete p么？澳，错了，应该是delete []p，这是为了告诉编译器：我删除的是一个数组，VC6就会根据相应的Cookie信息去进行释放内存的工作。 堆和栈究竟有什么区别？好了，我们回到我们的主题：堆和栈究竟有什么区别？ 主要的区别由以下几点：1.管理方式不同；2.空间大小不同；3.能否产生碎片不同；4.生长方向不同；5.分配方式不同；6.分配效率不同；管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。 空间大小：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）。当然，我们可以修改： 打开工程，依次操作菜单如下：Project-&gt;Setting-&gt;Link，在Category 中选中Output，然后在Reserve中设定堆栈的最大值和commit。 注意：reserve最小值为4Byte；commit是保留在虚拟内存的页文件里面，它设置的较大会使栈开辟较大的值，可能增加内存的开销和启动时间。 碎片问题：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出，详细的可以参考数据结构，这里我们就不再一一讨论了。 生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。 分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。 分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。 从这里我们可以看到，堆和栈相比，由于大量new/delete的使用，容易造成大量的内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和核心态的切换，内存的申请，代价变得更加昂贵。所以栈在程序中是应用最广泛的，就算是函数的调用也利用栈去完成，函数调用过程中的参数，返回地址，EBP和局部变量都采用栈的方式存放。所以，我们推荐大家尽量用栈，而不是用堆。 虽然栈有如此众多的好处，但是由于和堆相比不是那么灵活，有时候分配大量的内存空间，还是用堆好一些。 无论是堆还是栈，都要防止越界现象的发生（除非你是故意使其越界），因为越界的结果要么是程序崩溃，要么是摧毁程序的堆、栈结构，产生以想不到的结果,就算是在你的程序运行过程中，没有发生上面的问题，你还是要小心，说不定什么时候就崩掉，那时候debug可是相当困难的：） 控制C++的内存分配在嵌入式系统中使用C++的一个常见问题是内存分配，即对new和delete操作符的失控。 具有讽刺意味的是，问题的根源却是C++对内存的管理非常的容易而且安全。具体地说，当一个对象被消除时，它的析构函数能够安全的释放所分配的内存。 这当然是个好事情，但是这种使用的简单性使得程序员们过度使用new和delete，而不注意在嵌入式C++环境中的因果关系。并且，在嵌入式系统中，由于内存的限制，频繁的动态分配不定大小的内存会引起很大的问题以及堆破碎的风险。 作为忠告，保守的使用内存分配是嵌入式环境中的第一原则。 但当你必须要使用new 和delete时，你不得不控制C++中的内存分配。你需要用一个全局的new和delete来代替系统的内存分配符，并且一个类一个类的重载new和delete。 一个防止堆破碎的通用方法是从不同固定大小的内存持中分配不同类型的对象。对每个类重载new 和delete就提供了这样的控制。 重载全局的new和delete操作符可以很容易地重载new 和 delete 操作符，如下所示:12345678910void * operator new(size_t size)&#123; void *p = malloc(size); return (p);&#125;void operator delete(void *p);&#123; free(p);&#125; 这段代码可以代替默认的操作符来满足内存分配的请求。出于解释C++的目的，我们也可以直接调用malloc() 和free()。 也可以对单个类的new 和 delete 操作符重载。这是你能灵活的控制对象的内存分配。123456789101112131415class TestClass &#123;public: void * operator new(size_t size); void operator delete(void *p); // .. other members here ...&#125;;void *TestClass::operator new(size_t size)&#123; void *p = malloc(size); // Replace this with alternative allocator return (p);&#125;void TestClass::operator delete(void *p)&#123; free(p); // Replace this with alternative de-allocator&#125; 所有TestClass 对象的内存分配都采用这段代码。更进一步，任何从TestClass 继承的类也都采用这一方式，除非它自己也重载了new 和 delete 操作符。通过重载new 和 delete 操作符的方法，你可以自由地采用不同的分配策略，从不同的内存池中分配不同的类对象。 为单个的类重载 new[ ]和delete[ ]必须小心对象数组的分配。你可能希望调用到被你重载过的new 和 delete 操作符，但并不如此。内存的请求被定向到全局的new[ ]和delete[ ] 操作符，而这些内存来自于系统堆。 C++将对象数组的内存分配作为一个单独的操作，而不同于单个对象的内存分配。为了改变这种方式，你同样需要重载new[ ] 和 delete[ ]操作符。123456789101112131415161718192021class TestClass &#123;public: void * operator new[ ](size_t size); void operator delete[ ](void *p); // .. other members here ..&#125;;void *TestClass::operator new[ ](size_t size)&#123; void *p = malloc(size); return (p);&#125;void TestClass::operator delete[ ](void *p)&#123; free(p);&#125;int main(void)&#123; TestClass *p = new TestClass[10]; // ... etc ... delete[ ] p;&#125; 但是注意：对于多数C++的实现，new[]操作符中的个数参数是数组的大小加上额外的存储对象数目的一些字节。在你的内存分配机制重要考虑的这一点。你应该尽量避免分配对象数组，从而使你的内存分配策略简单。 常见的内存错误及其对策发生内存错误是件非常麻烦的事情。编译器不能自动发现这些错误，通常是在程序运行时才能捕捉到。而这些错误大多没有明显的症状，时隐时现，增加了改错的难度。有时用户怒气冲冲地把你找来，程序却没有发生任何问题，你一走，错误又发作了。 常见的内存错误及其对策如下： 内存分配未成功，却使用了它。 编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行 检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。 内存分配虽然成功，但是尚未初始化就引用它。 犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。 内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。 内存分配成功并且已经初始化，但操作越过了内存的边界。 例如在使用数组时经常发生下标”多1”或者”少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。 忘记了释放内存，造成内存泄露。 含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然死掉，系统出现提示：内存耗尽。 动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。 释放了内存却继续使用它。 有三种情况： （1）程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。 （2）函数的return语句写错了，注意不要返回指向”栈内存”的”指针”或者”引用”，因为该内存在函数体结束时被自动销毁。 （3）使用free或delete释放了内存后，没有将指针设置为NULL。导致产生”野指针”。 【规则1】用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。 【规则2】不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。 【规则3】避免数组或指针的下标越界，特别要当心发生”多1”或者”少1”操作。 【规则4】动态内存的申请与释放必须配对，防止内存泄漏。 【规则5】用free或delete释放了内存之后，立即将指针设置为NULL，防止产生”野指针”。 指针与数组的对比C++/C程序中，指针和数组在不少地方可以相互替换着用，让人产生一种错觉，以为两者是等价的。 数组要么在静态存储区被创建（如全局数组），要么在栈上被创建。数组名对应着（而不是指向）一块内存，其地址与容量在生命期内保持不变，只有数组的内容可以改变。 指针可以随时指向任意类型的内存块，它的特征是”可变”，所以我们常用指针来操作动态内存。指针远比数组灵活，但也更危险。 下面以字符串为例比较指针与数组的特性。 修改内容下面示例中，字符数组a的容量是6个字符，其内容为hello。a的内容可以改变，如a[0]= ‘X’。指针p指向常量字符串”world”（位于静态存储区，内容为world），常量字符串的内容是不可以被修改的。从语法上看，编译器并不觉得语句p[0]=’X’有什么不妥，但是该语句企图修改常量字符串的内容而导致运行错误。123456char a[] =&quot;hello&quot;;a[0] = &apos;X&apos;;cout&lt;&lt;a&lt;&lt;endl;char *p = &quot;world&quot;; // 注意p指向常量字符串p[0] = &apos;X&apos;; // 编译器不能发现该错误cout&lt;&lt;p&lt;&lt;endl; 内容复制与比较不能对数组名进行直接复制与比较。若想把数组a的内容复制给数组b，不能用语句 b = a ，否则将产生编译错误。应该用标准库函数strcpy进行复制。同理，比较b和a的内容是否相同，不能用if(b==a) 来判断，应该用标准库函数strcmp进行比较。 语句p = a 并不能把a的内容复制指针p，而是把a的地址赋给了p。要想复制a的内容，可以先用库函数malloc为p申请一块容量为strlen(a)+1个字符的内存，再用strcpy进行字符串复制。同理，语句if(p==a) 比较的不是内容而是地址，应该用库函数strcmp来比较。1234567891011// 数组…char a[] = &quot;hello&quot;;char b[10];strcpy(b, a); // 不能用 b = a;if(strcmp(b, a) == 0) // 不能用 if (b == a)…// 指针…int len = strlen(a);char *p = (char *)malloc(sizeof(char)*(len+1));strcpy(p,a); // 不要用 p = a;if(strcmp(p, a) == 0) // 不要用 if (p == a) 计算内存容量用运算符sizeof可以计算出数组的容量（字节数）。如下示例中，sizeof(a)的值是12（注意别忘了’’）。指针p指向a，但是sizeof(p)的值却是4。这是因为sizeof(p)得到的是一个指针变量的字节数，相当于sizeof(char*)，而不是p所指的内存容量。C++/C语言没有办法知道指针所指的内存容量，除非在申请内存时记住它。1234char a[] = &quot;hello world&quot;;char *p = a;cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 12字节cout&lt;&lt; sizeof(p) &lt;&lt; endl; // 4字节 注意当数组作为函数的参数进行传递时，该数组自动退化为同类型的指针。如下示例中，不论数组a的容量是多少，sizeof(a)始终等于sizeof(char *)。1234void Func(char a[100])&#123; cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 4字节而不是100字节&#125; 指针参数是如何传递内存的？如果函数的参数是一个指针，不要指望用该指针去申请动态内存。如下示例中，Test函数的语句GetMemory(str, 200)并没有使str获得期望的内存，str依旧是NULL，为什么？12345678910void GetMemory(char *p, int num)&#123; p = (char *)malloc(sizeof(char) * num);&#125;void Test(void)&#123; char *str = NULL; GetMemory(str, 100); // str 仍然为 NULL strcpy(str, &quot;hello&quot;); // 运行错误&#125; 毛病出在函数GetMemory中。编译器总是要为函数的每个参数制作临时副本，指针参数p的副本是 _p，编译器使 _p = p。如果函数体内的程序修改了_p的内容，就导致参数p的内容作相应的修改。这就是指针可以用作输出参数的原因。在本例中，_p申请了新的内存，只是把_p所指的内存地址改变了，但是p丝毫未变。所以函数GetMemory并不能输出任何东西。事实上，每执行一次GetMemory就会泄露一块内存，因为没有用free释放内存。 如果非得要用指针参数去申请内存，那么应该改用“指向指针的指针”，见示例：123456789101112void GetMemory2(char **p, int num)&#123; *p = (char *)malloc(sizeof(char) * num);&#125;void Test2(void)&#123; char *str = NULL; GetMemory2(&amp;str, 100); // 注意参数是 &amp;str，而不是str strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 由于“指向指针的指针”这个概念不容易理解，我们可以用函数返回值来传递动态内存。这种方法更加简单，见示例：12345678910111213char *GetMemory3(int num)&#123; char *p = (char *)malloc(sizeof(char) * num); return p;&#125;void Test3(void)&#123; char *str = NULL; str = GetMemory3(100); strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 用函数返回值来传递动态内存这种方法虽然好用，但是常常有人把return语句用错了。这里强调不要用return语句返回指向”栈内存”的指针，因为该内存在函数结束时自动消亡，见示例：1234567891011char *GetString(void)&#123; char p[] = &quot;hello world&quot;; return p; // 编译器将提出警告&#125;void Test4(void)&#123; char *str = NULL; str = GetString(); // str 的内容是垃圾 cout&lt;&lt; str &lt;&lt; endl;&#125; 用调试器逐步跟踪Test4，发现执行str = GetString语句后str不再是NULL指针，但是str的内容不是“hello world”而是垃圾。 如果把上述示例改写成如下示例，会怎么样？1234567891011char *GetString2(void)&#123; char *p = &quot;hello world&quot;; return p;&#125;void Test5(void)&#123; char *str = NULL; str = GetString2(); cout&lt;&lt; str &lt;&lt; endl;&#125; 函数Test5运行虽然不会出错，但是函数GetString2的设计概念却是错误的。因为GetString2内的“hello world”是常量字符串，位于静态存储区，它在程序生命期内恒定不变。无论什么时候调用GetString2，它返回的始终是同一个“只读”的内存块。 杜绝“野指针”“野指针”不是NULL指针，是指向“垃圾”内存的指针。人们一般不会错用NULL指针，因为用if语句很容易判断。但是“野指针”是很危险的，if语句对它不起作用。 “野指针”的成因主要有两种： 指针变量没有被初始化。任何指针变量刚被创建时不会自动成为NULL指针，它的缺省值是随机的，它会乱指一气。所以，指针变量在创建的同时应当被初始化，要么将指针设置为NULL，要么让它指向合法的内存。例如12char *p = NULL;char *str = (char *) malloc(100); 指针p被free或者delete之后，没有置为NULL，让人误以为p是个合法的指针。 指针操作超越了变量的作用域范围。这种情况让人防不胜防，示例程序如下：1234567891011121314class A&#123; public: void Func(void)&#123; cout &lt;&lt; “Func of class A” &lt;&lt; endl; &#125;&#125;;void Test(void)&#123; A *p; &#123; A a; p = &amp;a; // 注意 a 的生命期 &#125; p-&gt;Func(); // p是&quot;野指针&quot;&#125; 函数Test在执行语句p-&gt;Func()时，对象a已经消失，而p是指向a的，所以p就成了”野指针”。但奇怪的是我运行这个程序时居然没有出错，这可能与编译器有关。 有了malloc/free为什么还要new/delete？malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。 对于非内部数据类型的对象而言，光用malloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。 因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。我们先看一看malloc/free和new/delete如何实现对象的动态内存管理，见示例：12345678910111213141516171819202122class Obj&#123; public : Obj(void)&#123; cout &lt;&lt; “Initialization” &lt;&lt; endl; &#125; ~Obj(void)&#123; cout &lt;&lt; “Destroy” &lt;&lt; endl; &#125; void Initialize(void)&#123; cout &lt;&lt; “Initialization” &lt;&lt; endl; &#125; void Destroy(void)&#123; cout &lt;&lt; “Destroy” &lt;&lt; endl; &#125;&#125;;void UseMallocFree(void)&#123; Obj *a = (obj *)malloc(sizeof(obj)); // 申请动态内存 a-&gt;Initialize(); // 初始化 //… a-&gt;Destroy(); // 清除工作 free(a); // 释放内存&#125;void UseNewDelete(void)&#123; Obj *a = new Obj; // 申请动态内存并且初始化 //… delete a; // 清除并且释放内存&#125; 类Obj的函数Initialize模拟了构造函数的功能，函数Destroy模拟了析构函数的功能。函数UseMallocFree中，由于malloc/free不能执行构造函数与析构函数，必须调用成员函数Initialize和Destroy来完成初始化与清除工作。函数UseNewDelete则简单得多。 所以我们不要企图用malloc/free来完成动态对象的内存管理，应该用new/delete。由于内部数据类型的”对象”没有构造与析构的过程，对它们而言malloc/free和new/delete是等价的。 既然new/delete的功能完全覆盖了malloc/free，为什么C++不把malloc/free淘汰出局呢？这是因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。 如果用free释放”new创建的动态对象”，那么该对象因无法执行析构函数而可能导致程序出错。如果用delete释放”malloc申请的动态内存”，结果也会导致程序出错，但是该程序的可读性很差。所以new/delete必须配对使用，malloc/free也一样。 内存耗尽怎么办？如果在申请动态内存时找不到足够大的内存块，malloc和new将返回NULL指针，宣告内存申请失败。通常有三种方式处理”内存耗尽”问题。 判断指针是否为NULL，如果是则马上用return语句终止本函数。例如： 12345678void Func(void)&#123; A *a = new A; if(a == NULL) &#123; return; &#125;&#125; 判断指针是否为NULL，如果是则马上用exit(1)终止整个程序的运行。例如： 123456789void Func(void)&#123; A *a = new A; if(a == NULL) &#123; cout &lt;&lt; “Memory Exhausted” &lt;&lt; endl; exit(1); &#125;&#125; 为new和malloc设置异常处理函数。例如Visual C++可以用_set_new_hander函数为new设置用户自己定义的异常处理函数，也可以让malloc享用与new相同的异常处理函数。详细内容请参考C++使用手册。 上述（1）（2）方式使用最普遍。如果一个函数内有多处需要申请动态内存，那么方式（1）就显得力不从心（释放内存很麻烦），应该用方式（2）来处理。 很多人不忍心用exit(1)，问：”不编写出错处理程序，让操作系统自己解决行不行？” 不行。如果发生”内存耗尽”这样的事情，一般说来应用程序已经无药可救。如果不用exit(1)把坏程序杀死，它可能会害死操作系统。道理如同：如果不把歹徒击毙，歹徒在老死之前会犯下更多的罪。 有一个很重要的现象要告诉大家。对于32位以上的应用程序而言，无论怎样使用malloc与new，几乎不可能导致”内存耗尽”。我在Windows 98下用Visual C++编写了测试程序，见示例7。这个程序会无休止地运行下去，根本不会终止。因为32位操作系统支持”虚存”，内存用完了，自动用硬盘空间顶替。我只听到硬盘嘎吱嘎吱地响，Window 98已经累得对键盘、鼠标毫无反应。 我可以得出这么一个结论：对于32位以上的应用程序，”内存耗尽”错误处理程序毫无用处。这下可把Unix和Windows程序员们乐坏了：反正错误处理程序不起作用，我就不写了，省了很多麻烦。 我不想误导读者，必须强调：不加错误处理将导致程序的质量很差，千万不可因小失大。1234567891011void main(void)&#123; float *p = NULL; while(TRUE) &#123; p = new float[1000000]; cout &lt;&lt; “eat memory” &lt;&lt; endl; if(p==NULL) exit(1); &#125;&#125; malloc/free的使用要点函数malloc的原型如下：1void * malloc(size_t size); 用malloc申请一块长度为length的整数类型的内存，程序如下：1int *p = (int *) malloc(sizeof(int) * length); 我们应当把注意力集中在两个要素上：”类型转换”和”sizeof”。 malloc返回值的类型是void ，所以在调用malloc时要显式地进行类型转换，将void 转换成所需要的指针类型。 malloc函数本身并不识别要申请的内存是什么类型，它只关心内存的总字节数。我们通常记不住int, float等数据类型的变量的确切字节数。例如int变量在16位系统下是2个字节，在32位下是4个字节；而float变量在16位系统下是4个字节，在32位下也是4个字节。最好用以下程序作一次测试： 12345678cout &lt;&lt; sizeof(char) &lt;&lt; endl;cout &lt;&lt; sizeof(int) &lt;&lt; endl;cout &lt;&lt; sizeof(unsigned int) &lt;&lt; endl;cout &lt;&lt; sizeof(long) &lt;&lt; endl;cout &lt;&lt; sizeof(unsigned long) &lt;&lt; endl;cout &lt;&lt; sizeof(float) &lt;&lt; endl;cout &lt;&lt; sizeof(double) &lt;&lt; endl;cout &lt;&lt; sizeof(void *) &lt;&lt; endl; 在malloc的”()”中使用sizeof运算符是良好的风格，但要当心有时我们会昏了头，写出 p = malloc(sizeof(p))这样的程序来。 函数free的原型如下：1void free( void * memblock ); 为什么free函数不象malloc函数那样复杂呢？这是因为指针p的类型以及它所指的内存的容量事先都是知道的，语句free(p)能正确地释放内存。如果p是NULL指针，那么free对p无论操作多少次都不会出问题。如果p不是NULL指针，那么free对p连续操作两次就会导致程序运行错误。 new/delete的使用要点运算符new使用起来要比函数malloc简单得多，例如：123int *p1 = (int *)malloc(sizeof(int) * length);int *p2 = new int[length]; 这是因为new内置了sizeof、类型转换和类型安全检查功能。对于非内部数据类型的对象而言，new在创建动态对象的同时完成了初始化工作。如果对象有多个构造函数，那么new的语句也可以有多种形式。例如1234567891011121314class Obj&#123; public : Obj(void); // 无参数的构造函数 Obj(int x); // 带一个参数的构造函数&#125;void Test(void)&#123; Obj *a = new Obj; Obj *b = new Obj(1); // 初值为1 delete a; delete b;&#125; 如果用new创建对象数组，那么只能使用对象的无参数构造函数。例如：1Obj *objects = new Obj[100]; // 创建100个动态对象 不能写成：1Obj *objects = new Obj[100](1);// 创建100个动态对象的同时赋初值1 在用delete释放对象数组时，留意不要丢了符号’[]’。例如：12delete []objects; // 正确的用法delete objects; // 错误的用法 后者有可能引起程序崩溃和内存泄漏。 C++中的健壮指针和资源管理我最喜欢的对资源的定义是：”任何在你的程序中获得并在此后释放的东西?quot;内存是一个相当明显的资源的例子。它需要用new来获得，用delete来释放。同时也有许多其它类型的资源文件句柄、重要的片断、Windows中的GDI资源，等等。将资源的概念推广到程序中创建、释放的所有对象也是十分方便的，无论对象是在堆中分配的还是在栈中或者是在全局作用于内生命的。 对于给定的资源的拥有着，是负责释放资源的一个对象或者是一段代码。所有权分立为两种级别——自动的和显式的（automatic and explicit），如果一个对象的释放是由语言本身的机制来保证的，这个对象的就是被自动地所有。例如，一个嵌入在其他对象中的对象，他的清除需要其他对象来在清除的时候保证。外面的对象被看作嵌入类的所有者。 类似地，每个在栈上创建的对象（作为自动变量）的释放（破坏）是在控制流离开了对象被定义的作用域的时候保证的。这种情况下，作用于被看作是对象的所有者。注意所有的自动所有权都是和语言的其他机制相容的，包括异常。无论是如何退出作用域的————正常流程控制退出、一个break语句、一个return、一个goto、或者是一个throw————自动资源都可以被清除。 到目前为止，一切都很好！问题是在引入指针、句柄和抽象的时候产生的。如果通过一个指针访问一个对象的话，比如对象在堆中分配，C++不自动地关注它的释放。程序员必须明确的用适当的程序方法来释放这些资源。比如说，如果一个对象是通过调用new来创建的，它需要用delete来回收。一个文件是用CreateFile(Win32 API)打开的，它需要用CloseHandle来关闭。用EnterCritialSection进入的临界区（Critical Section）需要LeaveCriticalSection退出，等等。一个”裸”指针，文件句柄，或者临界区状态没有所有者来确保它们的最终释放。基本的资源管理的前提就是确保每个资源都有他们的所有者。 第一条规则（RAII）一个指针，一个句柄，一个临界区状态只有在我们将它们封装入对象的时候才会拥有所有者。这就是我们的第一规则：在构造函数中分配资源，在析构函数中释放资源。 当你按照规则将所有资源封装的时候，你可以保证你的程序中没有任何的资源泄露。这点在当封装对象（Encapsulating Object）在栈中建立或者嵌入在其他的对象中的时候非常明显。但是对那些动态申请的对象呢？不要急！任何动态申请的东西都被看作一种资源，并且要按照上面提到的方法进行封装。这一对象封装对象的链不得不在某个地方终止。它最终终止在最高级的所有者，自动的或者是静态的。这些分别是对离开作用域或者程序时释放资源的保证。 下面是资源封装的一个经典例子。在一个多线程的应用程序中，线程之间共享对象的问题是通过用这样一个对象联系临界区来解决的。每一个需要访问共享资源的客户需要获得临界区。例如，这可能是Win32下临界区的实现方法。123456789101112131415161718class CritSect&#123; friend class Lock; public: CritSect () &#123; InitializeCriticalSection (&amp;_critSection); &#125; ~CritSect () &#123; DeleteCriticalSection (&amp;_critSection); &#125; private: void Acquire () &#123; EnterCriticalSection (&amp;_critSection); &#125; void Release () &#123; LeaveCriticalSection (&amp;_critSection); &#125; private: CRITICAL_SECTION _critSection;&#125;; 这里聪明的部分是我们确保每一个进入临界区的客户最后都可以离开。”进入”临界区的状态是一种资源，并应当被封装。封装器通常被称作一个锁（lock）。1234567891011121314class Lock&#123; public: Lock (CritSect&amp; critSect) : _critSect (critSect) &#123; _critSect.Acquire (); &#125; ~Lock () &#123; _critSect.Release (); &#125; private CritSect &amp; _critSect;&#125;; 锁一般的用法如下：123456void Shared::Act () throw (char *)&#123; Lock lock (_critSect); // perform action —— may throw // automatic destructor of lock&#125; 注意无论发生什么，临界区都会借助于语言的机制保证释放。 还有一件需要记住的事情————每一种资源都需要被分别封装。这是因为资源分配是一个非常容易出错的操作，是要资源是有限提供的。我们会假设一个失败的资源分配会导致一个异常————事实上，这会经常的发生。所以如果你想试图用一个石头打两只鸟的话，或者在一个构造函数中申请两种形式的资源，你可能就会陷入麻烦。只要想想在一种资源分配成功但另一种失败抛出异常时会发生什么。因为构造函数还没有全部完成，析构函数不可能被调用，第一种资源就会发生泄露。 这种情况可以非常简单的避免。无论何时你有一个需要两种以上资源的类时，写两个小的封装器将它们嵌入你的类中。每一个嵌入的构造都可以保证删除，即使包装类没有构造完成。 Smart Pointers我们至今还没有讨论最常见类型的资源————用操作符new分配，此后用指针访问的一个对象。我们需要为每个对象分别定义一个封装类吗？（事实上，C++标准模板库已经有了一个模板类，叫做auto_ptr，其作用就是提供这种封装。我们一会儿在回到auto_ptr。）让我们从一个极其简单、呆板但安全的东西开始。看下面的Smart Pointer模板类，它十分坚固，甚至无法实现。123456789101112template &lt;class T&gt;class SmartPointer&#123; public: ~SmartPointer () &#123; delete _p; &#125; T * operator-&gt;() &#123; return _p; &#125; T const * operator-&gt;() const &#123; return _p; &#125; protected: SmartPointer (): _p (0) &#123;&#125; explicit SmartPointer (T* p): _p (p) &#123;&#125; T * _p;&#125;; 为什么要把SmartPointer的构造函数设计为protected呢？如果我需要遵守第一条规则，那么我就必须这样做。资源————在这里是class T的一个对象————必须在封装器的构造函数中分配。但是我不能只简单的调用new T，因为我不知道T的构造函数的参数。因为，在原则上，每一个T都有一个不同的构造函数；我需要为他定义个另外一个封装器。模板的用处会很大，为每一个新的类，我可以通过继承SmartPointer定义一个新的封装器，并且提供一个特定的构造函数。123456class SmartItem: public SmartPointer&lt;Item&gt;&#123; public: explicit SmartItem (int i) : SmartPointer&lt;Item&gt; (new Item (i)) &#123;&#125;&#125;; 为每一个类提供一个Smart Pointer真的值得吗？说实话————不！他很有教学的价值，但是一旦你学会如何遵循第一规则的话，你就可以放松规则并使用一些高级的技术。这一技术是让SmartPointer的构造函数成为public，但是只是是用它来做资源转换（Resource Transfer）我的意思是用new操作符的结果直接作为SmartPointer的构造函数的参数，像这样：1SmartPointer&lt;Item&gt; item (new Item (i)); 这个方法明显更需要自控性，不只是你，而且包括你的程序小组的每个成员。他们都必须发誓出了作资源转换外不把构造函数用在人以其他用途。幸运的是，这条规矩很容易得以加强。只需要在源文件中查找所有的new即可。 Resource Transfer到目前为止，我们所讨论的一直是生命周期在一个单独的作用域内的资源。现在我们要解决一个困难的问题————如何在不同的作用域间安全的传递资源。这一问题在当你处理容器的时候会变得十分明显。你可以动态的创建一串对象，将它们存放至一个容器中，然后将它们取出，并且在最终安排它们。为了能够让这安全的工作————没有泄露————对象需要改变其所有者。 这个问题的一个非常显而易见的解决方法是使用Smart Pointer，无论是在加入容器前还是还找到它们以后。这是他如何运作的，你加入Release方法到Smart Pointer中：1234567template &lt;class T&gt;T * SmartPointer&lt;T&gt;::Release ()&#123; T * pTmp = _p; _p = 0; return pTmp;&#125; 注意在Release调用以后，Smart Pointer就不再是对象的所有者了————它内部的指针指向空。现在，调用了Release都必须是一个负责的人并且迅速隐藏返回的指针到新的所有者对象中。在我们的例子中，容器调用了Release，比如这个Stack的例子：123456void Stack::Push (SmartPointer &lt;Item&gt; &amp; item) throw (char *)&#123; if (_top == maxStack) throw &quot;Stack overflow&quot;; _arr [_top++] = item.Release ();&#125;; 同样的，你也可以再你的代码中用加强Release的可靠性。 相应的Pop方法要做些什么呢？他应该释放了资源并祈祷调用它的是一个负责的人而且立即作一个资源传递它到一个Smart Pointer？这听起来并不好。 Strong Pointers资源管理在内容索引（Windows NT Server上的一部分，现在是Windows 2000）上工作，并且，我对这十分满意。然后我开始想……这一方法是在这样一个完整的系统中形成的，如果可以把它内建入语言的本身岂不是一件非常好？我提出了强指针（Strong Pointer）和弱指针(Weak Pointer)。一个Strong Pointer会在许多地方和我们这个SmartPointer相似–它在超出它的作用域后会清除他所指向的对象。资源传递会以强指针赋值的形式进行。也可以有Weak Pointer存在，它们用来访问对象而不需要所有对象–比如可赋值的引用。 任何指针都必须声明为Strong或者Weak，并且语言应该来关注类型转换的规定。例如，你不可以将Weak Pointer传递到一个需要Strong Pointer的地方，但是相反却可以。Push方法可以接受一个Strong Pointer并且将它转移到Stack中的Strong Pointer的序列中。Pop方法将会返回一个Strong Pointer。把Strong Pointer的引入语言将会使垃圾回收成为历史。 这里还有一个小问题–修改C++标准几乎和竞选美国总统一样容易。当我将我的注意告诉给Bjarne Stroutrup的时候，他看我的眼神好像是我刚刚要向他借一千美元一样。 然后我突然想到一个念头。我可以自己实现Strong Pointers。毕竟，它们都很想Smart Pointers。给它们一个拷贝构造函数并重载赋值操作符并不是一个大问题。事实上，这正是标准库中的auto_ptr有的。重要的是对这些操作给出一个资源转移的语法，但是这也不是很难。1234567891011121314template &lt;class T&gt;SmartPointer&lt;T&gt;::SmartPointer (SmartPointer&lt;T&gt; &amp; ptr)&#123; _p = ptr.Release ();&#125;template &lt;class T&gt;void SmartPointer&lt;T&gt;::operator = (SmartPointer&lt;T&gt; &amp; ptr)&#123; if (_p != ptr._p) &#123; delete _p; _p = ptr.Release (); &#125;&#125; 使这整个想法迅速成功的原因之一是我可以以值方式传递这种封装指针！我有了我的蛋糕，并且也可以吃了。看这个Stack的新的实现：1234567891011121314151617181920212223class Stack&#123; enum &#123; maxStack = 3 &#125;; public: Stack () : _top (0) &#123;&#125; void Push (SmartPointer&lt;Item&gt; &amp; item) throw (char *) &#123; if (_top &gt;= maxStack) throw &quot;Stack overflow&quot;; _arr [_top++] = item; &#125; SmartPointer&lt;Item&gt; Pop () &#123; if (_top == 0) return SmartPointer&lt;Item&gt; (); return _arr [--_top]; &#125; private int _top; SmartPointer&lt;Item&gt; _arr [maxStack];&#125;; Pop方法强制客户将其返回值赋给一个Strong Pointer,SmartPointer。任何试图将他对一个普通指针的赋值都会产生一个编译期错误，因为类型不匹配。此外，因为Pop以值方式返回一个Strong Pointer(在Pop的声明时SmartPointer后面没有&amp;符号)，编译器在return时自动进行了一个资源转换。他调用了operator =来从数组中提取一个Item,拷贝构造函数将他传递给调用者。调用者最后拥有了指向Pop赋值的Strong Pointer指向的一个Item。 我马上意识到我已经在某些东西之上了。我开始用了新的方法重写原来的代码。 Parser我过去有一个老的算术操作分析器，是用老的资源管理的技术写的。分析器的作用是在分析树中生成节点，节点是动态分配的。例如分析器的Expression方法生成一个表达式节点。我没有时间用Strong Pointer去重写这个分析器。我令Expression、Term和Factor方法以传值的方式将Strong Pointer返回到Node中。看下面的Expression方法的实现：123456789101112131415161718192021SmartPointer&lt;Node&gt; Parser::Expression()&#123; // Parse a term SmartPointer&lt;Node&gt; pNode = Term (); EToken token = _scanner.Token(); if ( token == tPlus || token == tMinus ) &#123; // Expr := Term &#123; (&apos;+&apos; | &apos;-&apos;) Term &#125; SmartPointer&lt;MultiNode&gt; pMultiNode = new SumNode (pNode); do &#123; _scanner.Accept(); SmartPointer&lt;Node&gt; pRight = Term (); pMultiNode-&gt;AddChild (pRight, (token == tPlus)); token = _scanner.Token(); &#125; while (token == tPlus || token == tMinus); pNode = up_cast&lt;Node, MultiNode&gt; (pMultiNode); &#125; // otherwise Expr := Term return pNode; // by value!&#125; 最开始，Term方法被调用。他传值返回一个指向Node的Strong Pointer并且立刻把它保存到我们自己的Strong Pointer,pNode中。如果下一个符号不是加号或者减号，我们就简单的把这个SmartPointer以值返回，这样就释放了Node的所有权。另外一方面，如果下一个符号是加号或者减号，我们创建一个新的SumMode并且立刻（直接传递）将它储存到MultiNode的一个Strong Pointer中。这里，SumNode是从MultiMode中继承而来的，而MulitNode是从Node继承而来的。原来的Node的所有权转给了SumNode。 只要是他们在被加号和减号分开的时候，我们就不断的创建terms，我们将这些term转移到我们的MultiNode中，同时MultiNode得到了所有权。最后，我们将指向MultiNode的Strong Pointer向上映射为指向Mode的Strong Pointer，并且将他返回调用着。 我们需要对Strong Pointers进行显式的向上映射，即使指针是被隐式的封装。例如，一个MultiNode是一个Node，但是相同的is-a关系在SmartPointer和SmartPointer之间并不存在，因为它们是分离的类（模板实例）并不存在继承关系。up-cast模板是像下面这样定义的：12345template&lt;class To, class From&gt;inline SmartPointer&lt;To&gt; up_cast (SmartPointer&lt;From&gt; &amp; from)&#123; return SmartPointer&lt;To&gt; (from.Release ());&#125; 如果你的编译器支持新加入标准的成员模板（member template）的话，你可以为SmartPointer定义一个新的构造函数用来从接受一个class U。1234template &lt;class T&gt;template &lt;class U&gt; SmartPointer&lt;T&gt;::SmartPointer (SPrt&lt;U&gt; &amp; uptr): _p (uptr.Release ())&#123;&#125; 这里的这个花招是模板在U不是T的子类的时候就不会编译成功（换句话说，只在U is-a T的时候才会编译）。这是因为uptr的缘故。Release()方法返回一个指向U的指针，并被赋值为_p，一个指向T的指针。所以如果U不是一个T的话，赋值会导致一个编译时刻错误。1std::auto_ptr 后来我意识到在STL中的auto_ptr模板，就是我的Strong Pointer。在那时候还有许多的实现差异（auto_ptr的Release方法并不将内部的指针清零–你的编译器的库很可能用的就是这种陈旧的实现），但是最后在标准被广泛接受之前都被解决了。 Transfer Semantics目前为止，我们一直在讨论在C++程序中资源管理的方法。宗旨是将资源封装到一些轻量级的类中，并由类负责它们的释放。特别的是，所有用new操作符分配的资源都会被储存并传递进Strong Pointer（标准库中的auto_ptr）的内部。 这里的关键词是传递（passing）。一个容器可以通过传值返回一个StrongPointer来安全的释放资源。容器的客户只能够通过提供一个相应的Strong Pointer来保存这个资源。任何一个将结果赋给一个”裸”指针的做法都立即会被编译器发现。12auto_ptr&lt;Item&gt; item = stack.Pop (); // okItem * p = stack.Pop (); // Error! Type mismatch. 以传值方式被传递的对象有value semantics 或者称为 copy semantics。Strong Pointers是以值方式传递的–但是我们能说它们有copy semantics吗？不是这样的！它们所指向的对象肯定没有被拷贝过。事实上，传递过后，源auto_ptr不在访问原有的对象，并且目标auto_ptr成为了对象的唯一拥有者（但是往往auto_ptr的旧的实现即使在释放后仍然保持着对对象的所有权）。自然而然的我们可以将这种新的行为称作Transfer Semantics。 拷贝构造函数（copy construcor）和赋值操作符定义了auto_ptr的Transfer Semantics，它们用了非const的auto_ptr引用作为它们的参数。12auto_ptr (auto_ptr&lt;T&gt; &amp; ptr);auto_ptr &amp; operator = (auto_ptr&lt;T&gt; &amp; ptr); 这是因为它们确实改变了他们的源–剥夺了对资源的所有权。 通过定义相应的拷贝构造函数和重载赋值操作符，你可以将Transfer Semantics加入到许多对象中。例如，许多Windows中的资源，比如动态建立的菜单或者位图，可以用有Transfer Semantics的类来封装。 Strong Vectors标准库只在auto_ptr中支持资源管理。甚至连最简单的容器也不支持ownership semantics。你可能想将auto_ptr和标准容器组合到一起可能会管用，但是并不是这样的。例如，你可能会这样做，但是会发现你不能够用标准的方法来进行索引。1vector&lt; auto_ptr&lt;Item&gt; &gt; autoVector; 这种建造不会编译成功；1Item * item = autoVector [0]; 另一方面，这会导致一个从autoVect到auto_ptr的所有权转换：1auto_ptr&lt;Item&gt; item = autoVector [0]; 我们没有选择，只能够构造我们自己的Strong Vector。最小的接口应该如下：123456789101112template &lt;class T&gt;class auto_vector&#123; public: explicit auto_vector (size_t capacity = 0); T const * operator [] (size_t i) const; T * operator [] (size_t i); void assign (size_t i, auto_ptr&lt;T&gt; &amp; p); void assign_direct (size_t i, T * p); void push_back (auto_ptr&lt;T&gt; &amp; p); auto_ptr&lt;T&gt; pop_back ();&#125;; 你也许会发现一个非常防御性的设计态度。我决定不提供一个对vector的左值索引的访问，取而代之，如果你想设定(set)一个值的话，你必须用assign或者assign_direct方法。我的观点是，资源管理不应该被忽视，同时，也不应该在所有的地方滥用。在我的经验里，一个strong vector经常被许多push_back方法充斥着。 Strong vector最好用一个动态的Strong Pointers的数组来实现：123456789template &lt;class T&gt;class auto_vector&#123;private void grow (size_t reqCapacity); auto_ptr&lt;T&gt; *_arr; size_t _capacity; size_t _end;&#125;; grow方法申请了一个很大的auto_ptr的数组，将所有的东西从老的书组类转移出来，在其中交换，并且删除原来的数组。 auto_vector的其他实现都是十分直接的，因为所有资源管理的复杂度都在auto_ptr中。例如，assign方法简单的利用了重载的赋值操作符来删除原有的对象并转移资源到新的对象：1234void assign (size_t i, auto_ptr&lt;T&gt; &amp; p)&#123; _arr [i] = p;&#125; 我已经讨论了push_back和pop_back方法。push_back方法传值返回一个auto_ptr，因为它将所有权从auto_vector转换到auto_ptr中。 对auto_vector的索引访问是借助auto_ptr的get方法来实现的，get简单的返回一个内部指针。1234T * operator [] (size_t i)&#123; return _arr [i].get ();&#125; 没有容器可以没有iterator。我们需要一个iterator让auto_vector看起来更像一个普通的指针向量。特别是，当我们废弃iterator的时候，我们需要的是一个指针而不是auto_ptr。我们不希望一个auto_vector的iterator在无意中进行资源转换。123456789101112131415template&lt;class T&gt;class auto_iterator: publiciterator&lt;random_access_iterator_tag, T *&gt;&#123; public: auto_iterator () : _pp (0) &#123;&#125; auto_iterator (auto_ptr&lt;T&gt; * pp) : _pp (pp) &#123;&#125; bool operator != (auto_iterator&lt;T&gt; const &amp; it) const &#123; return it._pp != _pp; &#125; auto_iterator const &amp; operator++ (int) &#123; return _pp++; &#125; auto_iterator operator++ () &#123; return ++_pp; &#125; T * operator * () &#123; return _pp-&gt;get (); &#125; private auto_ptr&lt;T&gt; * _pp;&#125;; 我们给auto_vect提供了标准的begin和end方法来找回iterator：1234567class auto_vector&#123;public: typedef auto_iterator&lt;T&gt; iterator; iterator begin () &#123; return _arr; &#125; iterator end () &#123; return _arr + _end; &#125;&#125;; 你也许会问我们是否要利用资源管理重新实现每一个标准的容器？幸运的是，不；事实是strongvector解决了大部分所有权的需求。当你把你的对象都安全的放置到一个strong vector中，你可以用所有其它的容器来重新安排（weak）pointer。 设想，例如，你需要对一些动态分配的对象排序的时候。你将它们的指针保存到一个strongvector中。然后你用一个标准的vector来保存从strong vector中获得的weak指针。你可以用标准的算法对这个vector进行排序。这种中介vector叫做permutation vector。相似的，你也可以用标准的maps, priority queues, heaps, hash tables等等。 Code Inspection如果你严格遵照资源管理的条款，你就不会再资源泄露或者两次删除的地方遇到麻烦。你也降低了访问野指针的几率。同样的，遵循原有的规则，用delete删除用new申请的德指针，不要两次删除一个指针。你也不会遇到麻烦。但是，那个是更好的注意呢？ 这两个方法有一个很大的不同点。就是和寻找传统方法的bug相比，找到违反资源管理的规定要容易的多。后者仅需要一个代码检测或者一个运行测试，而前者则在代码中隐藏得很深，并需要很深的检查。 设想你要做一段传统的代码的内存泄露检查。第一件事，你要做的就是grep所有在代码中出现的new，你需要找出被分配空间地指针都作了什么。你需要确定导致删除这个指针的所有的执行路径。你需要检查break语句，过程返回，异常。原有的指针可能赋给另一个指针，你对这个指针也要做相同的事。 相比之下，对于一段用资源管理技术实现的代码。你也用grep检查所有的new，但是这次你只需要检查邻近的调用： ● 这是一个直接的Strong Pointer转换，还是我们在一个构造函数的函数体中？ ● 调用的返回知是否立即保存到对象中，构造函数中是否有可以产生异常的代码。？ ● 如果这样的话析构函数中时候有delete? 下一步，你需要用grep查找所有的release方法，并实施相同的检查。 不同点是需要检查、理解单个执行路径和只需要做一些本地的检验。这难道不是提醒你非结构化的和结构化的程序设计的不同吗？原理上，你可以认为你可以应付goto，并且跟踪所有的可能分支。另一方面，你可以将你的怀疑本地化为一段代码。本地化在两种情况下都是关键所在。 在资源管理中的错误模式也比较容易调试。最常见的bug是试图访问一个释放过的strong pointer。这将导致一个错误，并且很容易跟踪。 共享的所有权为每一个程序中的资源都找出或者指定一个所有者是一件很容易的事情吗？答案是出乎意料的，是！如果你发现了一些问题，这可能说明你的设计上存在问题。还有另一种情况就是共享所有权是最好的甚至是唯一的选择。 共享的责任分配给被共享的对象和它的客户（client）。一个共享资源必须为它的所有者保持一个引用计数。另一方面，所有者再释放资源的时候必须通报共享对象。最后一个释放资源的需要在最后负责free的工作。 最简单的共享的实现是共享对象继承引用计数的类RefCounted：12345678910class RefCounted&#123;public: RefCounted () : _count (1) &#123;&#125; int GetRefCount () const &#123; return _count; &#125; void IncRefCount () &#123; _count++; &#125; int DecRefCount () &#123; return --_count; &#125;private int _count;&#125;; 按照资源管理，一个引用计数是一种资源。如果你遵守它，你需要释放它。当你意识到这一事实的时候，剩下的就变得简单了。简单的遵循规则–再构造函数中获得引用计数，在析构函数中释放。甚至有一个RefCounted的smart pointer等价物：123456789101112131415161718template &lt;class T&gt;class RefPtr&#123; public: RefPtr (T * p) : _p (p) &#123;&#125; RefPtr (RefPtr&lt;T&gt; &amp; p) &#123; _p = p._p; _p-&gt;IncRefCount (); &#125; ~RefPtr () &#123; if (_p-&gt;DecRefCount () == 0) delete _p; &#125; private T * _p;&#125;; 注意模板中的T不比成为RefCounted的后代，但是它必须有IncRefCount和DecRefCount的方法。当然，一个便于使用的RefPtr需要有一个重载的指针访问操作符。在RefPtr中加入转换语义学（transfer semantics）是读者的工作。 所有权网络链表是资源管理分析中的一个很有意思的例子。如果你选择表成为链(link)的所有者的话，你会陷入实现递归的所有权。每一个link都是它的继承者的所有者，并且，相应的，余下的链表的所有者。下面是用smart pointer实现的一个表单元：123456class Link&#123;// ...private auto_ptr&lt;Link&gt; _next;&#125;; 最好的方法是，将连接控制封装到一个弄构进行资源转换的类中。 对于双链表呢？安全的做法是指明一个方向，如forward:1234567class DoubleLink&#123;// ...private DoubleLink *_prev; auto_ptr&lt;DoubleLink&gt; _next;&#125;; 注意不要创建环形链表。 这给我们带来了另外一个有趣的问题–资源管理可以处理环形的所有权吗？它可以，用一个mark-and-sweep的算法。这里是实现这种方法的一个例子：12345678910111213141516171819202122template&lt;class T&gt;class CyclPtr&#123; public: CyclPtr (T * p) :_p (p), _isBeingDeleted (false) &#123;&#125; ~CyclPtr () &#123; _isBeingDeleted = true; if (!_p-&gt;IsBeingDeleted ()) delete _p; &#125; void Set (T * p) &#123; _p = p; &#125; bool IsBeingDeleted () const &#123; return _isBeingDeleted; &#125; private T * _p; bool _isBeingDeleted;&#125;; 注意我们需要用class T来实现方法IsBeingDeleted，就像从CyclPtr继承。对特殊的所有权网络普通化是十分直接的。 将原有代码转换为资源管理代码 如果你是一个经验丰富的程序员，你一定会知道找资源的bug是一件浪费时间的痛苦的经历。我不必说服你和你的团队花费一点时间来熟悉资源管理是十分值得的。你可以立即开始用这个方法，无论你是在开始一个新项目或者是在一个项目的中期。转换不必立即全部完成。下面是步骤。 首先，在你的工程中建立基本的Strong Pointer。然后通过查找代码中的new来开始封装裸指针。 最先封装的是在过程中定义的临时指针。简单的将它们替换为auto_ptr并且删除相应的delete。如果一个指针在过程中没有被删除而是被返回，用auto_ptr替换并在返回前调用release方法。在你做第二次传递的时候，你需要处理对release的调用。注意，即使是在这点，你的代码也可能更加”精力充沛”–你会移出代码中潜在的资源泄漏问题。 下面是指向资源的裸指针。确保它们被独立的封装到auto_ptr中，或者在构造函数中分配在析构函数中释放。如果你有传递所有权的行为的话，需要调用release方法。如果你有容器所有对象，用Strong Pointers重新实现它们。 接下来，找到所有对release的方法调用并且尽力清除所有，如果一个release调用返回一个指针，将它修改传值返回一个auto_ptr。 重复着一过程，直到最后所有new和release的调用都在构造函数或者资源转换的时候发生。这样，你在你的代码中处理了资源泄漏的问题。对其他资源进行相似的操作。 你会发现资源管理清除了许多错误和异常处理带来的复杂性。不仅仅你的代码会变得精力充沛，它也会变得简单并容易维护。 内存泄漏C++中动态内存分配引发问题的解决方案假设我们要开发一个String类，它可以方便地处理字符串数据。我们可以在类中声明一个数组，考虑到有时候字符串极长，我们可以把数组大小设为200，但一般的情况下又不需要这么多的空间，这样是浪费了内存。对了，我们可以使用new操作符，这样是十分灵活的，但在类中就会出现许多意想不到的问题，本文就是针对这一现象而写的。现在，我们先来开发一个String类，但它是一个不完善的类。的确，我们要刻意地使它出现各种各样的问题，这样才好对症下药。好了，我们开始吧！1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* String.h */#ifndef STRING_H_#define STRING_H_class String&#123;private: char * str; //存储数据 int len; //字符串长度public: String(const char * s); //构造函数 String(); // 默认构造函数 ~String(); // 析构函数 friend ostream &amp; operator&lt;&lt;(ostream &amp; os,const String&amp; st);&#125;;#endif/*String.cpp*/#include &lt;iostream＞#include &lt;cstring＞#include &quot;String.h&quot;using namespace std;String::String(const char * s)&#123; len = strlen(s); str = new char[len + 1]; strcpy(str, s);&#125;//拷贝数据String::String()&#123; len =0; str = new char[len+1]; str[0]=&apos;&quot;0&apos;;&#125;String::~String()&#123; cout&lt;&lt;&quot;这个字符串将被删除：&quot;&lt;&lt;str&lt;&lt;&apos;&quot;n&apos;;//为了方便观察结果，特留此行代码。 delete [] str;&#125;ostream &amp; operator&lt;&lt;(ostream &amp; os, const String &amp; st)&#123; os &lt;&lt; st.str; return os;&#125;/*test_right.cpp*/#include &lt;iostream＞#include &lt;stdlib.h＞#include &quot;String.h&quot;using namespace std;int main()&#123; String temp(&quot;天极网&quot;); cout&lt;&lt;temp&lt;&lt;&apos;&quot;n&apos;; system(&quot;PAUSE&quot;); return 0;&#125; 运行结果：123天极网按任意键继续. . . 大家可以看到，以上程序十分正确，而且也是十分有用的。可是，我们不能被表面现象所迷惑！下面，请大家用test_String.cpp文件替换test_right.cpp文件进行编译，看看结果。有的编译器可能就是根本不能进行编译！ test_String.cpp:12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream＞#include &lt;stdlib.h＞#include &quot;String.h&quot;using namespace std;void show_right(const String&amp;);void show_String(const String);//注意，参数非引用，而是按值传递。int main()&#123; String test1(&quot;第一个范例。&quot;); String test2(&quot;第二个范例。&quot;); String test3(&quot;第三个范例。&quot;); String test4(&quot;第四个范例。&quot;); cout&lt;&lt;&quot;下面分别输入三个范例&quot;; cout&lt;&lt;test1&lt;&lt;endl; cout&lt;&lt;test2&lt;&lt;endl; cout&lt;&lt;test3&lt;&lt;endl; String* String1=new String(test1); cout&lt;&lt;*String1&lt;&lt;endl; delete String1; cout&lt;&lt;test1&lt;&lt;endl; //在Dev-cpp上没有任何反应。 cout&lt;&lt;&quot;使用正确的函数：&quot;&lt;&lt;endl; show_right(test2); cout&lt;&lt;test2&lt;&lt;endl; cout&lt;&lt;&quot;使用错误的函数：&quot;&lt;&lt;endl; show_String(test2); cout&lt;&lt;test2&lt;&lt;endl; //这一段代码出现严重的错误！ String String2(test3); cout&lt;&lt;&quot;String2: &quot;&lt;&lt;String2&lt;&lt;endl; String String3; String3=test4; cout&lt;&lt;&quot;String3: &quot;&lt;&lt;String3&lt;&lt;endl; cout&lt;&lt;&quot;下面，程序结束，析构函数将被调用。&quot;&lt;&lt;endl; return 0;&#125;void show_right(const String&amp; a)&#123; cout&lt;&lt;a&lt;&lt;endl;&#125;void show_String(const String a)&#123; cout&lt;&lt;a&lt;&lt;endl;&#125; 运行结果：1234567891011121314151617181920212223下面分别输入三个范例：第一个范例。第二个范例。第三个范例。第一个范例。这个字符串将被删除：第一个范例。使用正确的函数：第二个范例。第二个范例。使用错误的函数：第二个范例。这个字符串将被删除：第二个范例。这个字符串将被删除：?=?=String2: 第三个范例。String3: 第四个范例。下面，程序结束，析构函数将被调用。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：?=这个字符串将被删除：x =这个字符串将被删除：?=这个字符串将被删除： 现在，请大家自己试试运行结果，或许会更加惨不忍睹呢！下面，我为大家一一分析原因。 首先，大家要知道，C＋＋类有以下这些极为重要的函数： 一：复制构造函数。 二：赋值函数。 我们先来讲复制构造函数。什么是复制构造函数呢？比如，我们可以写下这样的代码：String test1(test2);这是进行初始化。我们知道，初始化对象要用构造函数。可这儿呢？按理说，应该有声明为这样的构造函数：String(const String &amp;);可是，我们并没有定义这个构造函数呀？答案是，C＋＋提供了默认的复制构造函数，问题也就出在这儿。 （1）：什么时候会调用复制构造函数呢？（以String类为例。） 在我们提供这样的代码：String test1(test2)时，它会被调用；当函数的参数列表为按值传递，也就是没有用引用和指针作为类型时，如：void show_String(const String)，它会被调用。其实，还有一些情况，但在这儿就不列举了。 （2）：它是什么样的函数。 它的作用就是把两个类进行复制。拿String类为例，C＋＋提供的默认复制构造函数是这样的：12345String(const String&amp; a)&#123; str=a.str; len=a.len;&#125; 在平时，这样并不会有任何的问题出现，但我们用了new操作符，涉及到了动态内存分配，我们就不得不谈谈浅复制和深复制了。以上的函数就是实行的浅复制，它只是复制了指针，而并没有复制指针指向的数据，可谓一点儿用也没有。打个比方吧！就像一个朋友让你把一个程序通过网络发给他，而你大大咧咧地把快捷方式发给了他，有什么用处呢？我们来具体谈谈： 假如，A对象中存储了这样的字符串：”C＋＋”。它的地址为2000。现在，我们把A对象赋给B对象：String B=A。现在，A和B对象的str指针均指向2000地址。看似可以使用，但如果B对象的析构函数被调用时，则地址2000处的字符串”C＋＋”已经被从内存中抹去，而A对象仍然指向地址2000。这时，如果我们写下这样的代码：cout&lt;&lt;A&lt;&lt;endl;或是等待程序结束，A对象的析构函数被调用时，A对象的数据能否显示出来呢？只会是乱码。而且，程序还会这样做：连续对地址2000处使用两次delete操作符，这样的后果是十分严重的！ 本例中，有这样的代码：12345String* String1=new String(test1);cout&lt;&lt;*String1&lt;&lt;endl;delete String1; 假设test1中str指向的地址为2000,而String中str指针同样指向地址2000，我们删除了2000处的数据，而test1对象呢？已经被破坏了。大家从运行结果上可以看到，我们使用cout&lt;&lt;test1时，一点反应也没有。而在test1的析构函数被调用时，显示是这样：”这个字符串将被删除：”。 再看看这段代码：123cout&lt;&lt;&quot;使用错误的函数：&quot;&lt;&lt;endl;show_String(test2);cout&lt;&lt;test2&lt;&lt;endl;//这一段代码出现严重的错误！ show_String函数的参数列表void show_String(const String a)是按值传递的，所以，我们相当于执行了这样的代码：String a=test2;函数执行完毕，由于生存周期的缘故，对象a被析构函数删除，我们马上就可以看到错误的显示结果了：这个字符串将被删除：?=。当然，test2也被破坏了。解决的办法很简单，当然是手工定义一个复制构造函数喽！人力可以胜天！123456String::String(const String&amp; a)&#123; len=a.len; str=new char(len+1); strcpy(str,a.str);&#125; 我们执行的是深复制。这个函数的功能是这样的：假设对象A中的str指针指向地址2000，内容为”I am a C++ Boy!”。我们执行代码String B=A时，我们先开辟出一块内存，假设为3000。我们用strcpy函数将地址2000的内容拷贝到地址3000中，再将对象B的str指针指向地址3000。这样，就互不干扰了。 大家把这个函数加入程序中，问题就解决了大半，但还没有完全解决，问题在赋值函数上。我们的程序中有这样的段代码：12String String3;String3=test4; 经过我前面的讲解，大家应该也会对这段代码进行寻根摸底：凭什么可以这样做：String3=test4？？？原因是，C＋＋为了用户的方便，提供的这样的一个操作符重载函数：operator=。所以，我们可以这样做。大家应该猜得到，它同样是执行了浅复制，出了同样的毛病。比如，执行了这段代码后，析构函数开始大展神威。由于这些变量是后进先出的，所以最后的String3变量先被删除：这个字符串将被删除：第四个范例。很正常。最后，删除到test4的时候，问题来了：这个字符串将被删除：?=。原因我不用赘述了，只是这个赋值函数怎么写，还有一点儿学问呢！大家请看： 平时，我们可以写这样的代码：x=y=z。（均为整型变量。）而在类对象中，我们同样要这样，因为这很方便。而对象A=B=C就是A.operator=(B.operator=(c))。而这个operator=函数的参数列表应该是：const String&amp; a，所以，大家不难推出，要实现这样的功能，返回值也要是String&amp;，这样才能实现A＝B＝C。我们先来写写看：12345678String&amp; String::operator=(const String&amp; a)&#123; delete [] str;//先删除自身的数据 len=a.len; str=new char[len+1]; strcpy(str,a.str);//此三行为进行拷贝 return *this;//返回自身的引用&#125; 是不是这样就行了呢？我们假如写出了这种代码：A=A，那么大家看看，岂不是把A对象的数据给删除了吗？这样可谓引发一系列的错误。所以，我们还要检查是否为自身赋值。只比较两对象的数据是不行了，因为两个对象的数据很有可能相同。我们应该比较地址。以下是完好的赋值函数：12345678910String&amp; String::operator=(const String&amp; a)&#123; if(this==&amp;a) return *this; delete [] str; len=a.len; str=new char[len+1]; strcpy(str,a.str); return *this;&#125; 把这些代码加入程序，问题就完全解决，下面是运行结果：1234567891011121314151617181920212223下面分别输入三个范例：第一个范例第二个范例第三个范例第一个范例这个字符串将被删除：第一个范例。第一个范例使用正确的函数：第二个范例。第二个范例。使用错误的函数：第二个范例。这个字符串将被删除：第二个范例。第二个范例。String2: 第三个范例。String3: 第四个范例。下面，程序结束，析构函数将被调用。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：第二个范例。这个字符串将被删除：第一个范例。 如何对付内存泄漏？写出那些不会导致任何内存泄漏的代码。很明显，当你的代码中到处充满了new 操作、delete操作和指针运算的话，你将会在某个地方搞晕了头，导致内存泄漏，指针引用错误，以及诸如此类的问题。这和你如何小心地对待内存分配工作其实完全没有关系：代码的复杂性最终总是会超过你能够付出的时间和努力。于是随后产生了一些成功的技巧，它们依赖于将内存分配（allocations）与重新分配（deallocation）工作隐藏在易于管理的类型之后。标准容器（standard containers）是一个优秀的例子。它们不是通过你而是自己为元素管理内存，从而避免了产生糟糕的结果。想象一下，没有string和vector的帮助，写出这个：12345678910111213141516171819#include&lt;vector&gt;#include&lt;string&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int main() // small program messing around with strings&#123; cout &lt;&lt; &quot;enter some whitespace-separated words:&quot;n&quot;; vector&lt;string&gt; v; string s; while (cin&gt;&gt;s) v.push_back(s); sort(v.begin(),v.end()); string cat; typedef vector&lt;string&gt;::const_iterator Iter; for (Iter p = v.begin(); p!=v.end(); ++p) cat += *p+&quot;+&quot;; cout &lt;&lt; cat &lt;&lt; &apos;&quot;n&apos;;&#125; 你有多少机会在第一次就得到正确的结果？你又怎么知道你没有导致内存泄漏呢？ 注意，没有出现显式的内存管理，宏，造型，溢出检查，显式的长度限制，以及指针。通过使用函数对象和标准算法（standard algorithm），我可以避免使用指针————例如使用迭代子（iterator），不过对于一个这么小的程序来说有点小题大作了。 这些技巧并不完美，要系统化地使用它们也并不总是那么容易。但是，应用它们产生了惊人的差异，而且通过减少显式的内存分配与重新分配的次数，你甚至可以使余下的例子更加容易被跟踪。早在1981年，我就指出，通过将我必须显式地跟踪的对象的数量从几万个减少到几打，为了使程序正确运行而付出的努力从可怕的苦工，变成了应付一些可管理的对象，甚至更加简单了。 如果你的程序还没有包含将显式内存管理减少到最小限度的库，那么要让你程序完成和正确运行的话，最快的途径也许就是先建立一个这样的库。 模板和标准库实现了容器、资源句柄以及诸如此类的东西，更早的使用甚至在多年以前。异常的使用使之更加完善。 如果你实在不能将内存分配/重新分配的操作隐藏到你需要的对象中时，你可以使用资源句柄（resource handle），以将内存泄漏的可能性降至最低。这里有个例子：我需要通过一个函数，在空闲内存中建立一个对象并返回它。这时候可能忘记释放这个对象。毕竟，我们不能说，仅仅关注当这个指针要被释放的时候，谁将负责去做。使用资源句柄，这里用了标准库中的auto_ptr，使需要为之负责的地方变得明确了。12345678910111213141516171819202122232425262728#include&lt;memory&gt;#include&lt;iostream&gt;using namespace std;struct S &#123; S() &#123; cout &lt;&lt; &quot;make an S&quot;n&quot;; &#125; ~S() &#123; cout &lt;&lt; &quot;destroy an S&quot;n&quot;; &#125; S(const S&amp;) &#123; cout &lt;&lt; &quot;copy initialize an S&quot;n&quot;; &#125; S&amp; operator=(const S&amp;) &#123; cout &lt;&lt; &quot;copy assign an S&quot;n&quot;; &#125;&#125;;S* f()&#123; return new S; // 谁该负责释放这个S？&#125;;auto_ptr&lt;S&gt; g()&#123; return auto_ptr&lt;S&gt;(new S); // 显式传递负责释放这个S&#125;int main()&#123; cout &lt;&lt; &quot;start main&quot;n&quot;; S* p = f(); cout &lt;&lt; &quot;after f() before g()&quot;n&quot;; // S* q = g(); // 将被编译器捕捉 auto_ptr&lt;S&gt; q = g(); cout &lt;&lt; &quot;exit main&quot;n&quot;; // *p产生了内存泄漏 // *q被自动释放&#125; 在更一般的意义上考虑资源，而不仅仅是内存。 如果在你的环境中不能系统地应用这些技巧（例如，你必须使用别的地方的代码，或者你的程序的另一部分简直是原始人类（译注：原文是Neanderthals，尼安德特人，旧石器时代广泛分布在欧洲的猿人）写的，如此等等），那么注意使用一个内存泄漏检测器作为开发过程的一部分，或者插入一个垃圾收集器（garbage collector）。 浅谈C/C++内存泄漏及其检测工具对于一个c/c++程序员来说，内存泄漏是一个常见的也是令人头疼的问题。已经有许多技术被研究出来以应对这个问题，比如Smart Pointer，Garbage Collection等。Smart Pointer技术比较成熟，STL中已经包含支持Smart Pointer的class，但是它的使用似乎并不广泛，而且它也不能解决所有的问题；Garbage Collection技术在Java中已经比较成熟，但是在c/c++领域的发展并不顺畅，虽然很早就有人思考在C++中也加入GC的支持。现实世界就是这样的，作为一个c/c++程序员，内存泄漏是你心中永远的痛。不过好在现在有许多工具能够帮助我们验证内存泄漏的存在，找出发生问题的代码。 内存泄漏的定义一般我们常说的内存泄漏是指堆内存的泄漏。堆内存是指程序从堆中分配的，大小任意的（内存块的大小可以在程序运行期决定），使用完后必须显示释放的内存。应用程序一般使用malloc，realloc，new等函数从堆中分配到一块内存，使用完后，程序必须负责相应的调用free或delete释放该内存块，否则，这块内存就不能被再次使用，我们就说这块内存泄漏了。以下这段小程序演示了堆内存发生泄漏的情形：12345678910void MyFunction(int nSize)&#123; char* p= new char[nSize]; if( !GetStringFrom( p, nSize ) )&#123; MessageBox(“Error”); return; &#125; …//using the string pointed by p; delete p;&#125; 当函数GetStringFrom()返回零的时候，指针p指向的内存就不会被释放。这是一种常见的发生内存泄漏的情形。程序在入口处分配内存，在出口处释放内存，但是c函数可以在任何地方退出，所以一旦有某个出口处没有释放应该释放的内存，就会发生内存泄漏。 广义的说，内存泄漏不仅仅包含堆内存的泄漏，还包含系统资源的泄漏(resource leak)，比如核心态HANDLE，GDI Object，SOCKET， Interface等，从根本上说这些由操作系统分配的对象也消耗内存，如果这些对象发生泄漏最终也会导致内存的泄漏。而且，某些对象消耗的是核心态内存，这些对象严重泄漏时会导致整个操作系统不稳定。所以相比之下，系统资源的泄漏比堆内存的泄漏更为严重。 GDI Object的泄漏是一种常见的资源泄漏：12345678910111213void CMyView::OnPaint( CDC* pDC )&#123; CBitmap bmp; CBitmap* pOldBmp; bmp.LoadBitmap(IDB_MYBMP); pOldBmp = pDC-&gt;SelectObject( &amp;bmp ); ... if( Something() )&#123; return; &#125; pDC-&gt;SelectObject( pOldBmp ); return;&#125; 当函数Something()返回非零的时候，程序在退出前没有把pOldBmp选回pDC中，这会导致pOldBmp指向的HBITMAP对象发生泄漏。这个程序如果长时间的运行，可能会导致整个系统花屏。这种问题在Win9x下比较容易暴露出来，因为Win9x的GDI堆比Win2k或NT的要小很多。 内存泄漏的发生方式以发生的方式来分类，内存泄漏可以分为4类： 常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。比如例二，如果Something()函数一直返回True，那么pOldBmp指向的HBITMAP对象总是发生泄漏。 偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。比如例二，如果Something()函数只有在特定环境下才返回True，那么pOldBmp指向的HBITMAP对象并不总是发生泄漏。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。 一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，但是因为这个类是一个Singleton，所以内存泄漏只会发生一次。另一个例子： 12345678char* g_lpszFileName = NULL;void SetFileName( const char* lpcszFileName )&#123; if( g_lpszFileName )&#123; free( g_lpszFileName ); &#125; g_lpszFileName = strdup( lpcszFileName );&#125; 如果程序在结束的时候没有释放g_lpszFileName指向的字符串，那么，即使多次调用SetFileName()，总会有一块内存，而且仅有一块内存发生泄漏。 隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。举一个例子：123456789101112131415161718192021222324252627282930class Connection&#123; public: Connection( SOCKET s); ~Connection(); private: SOCKET _socket;&#125;;class ConnectionManager&#123; public: ConnectionManager()&#123;&#125; ~ConnectionManager()&#123; list::iterator it; for( it = _connlist.begin(); it != _connlist.end(); ++it )&#123; delete （*it）; &#125; _connlist.clear(); &#125; void OnClientConnected( SOCKET s )&#123; Connection* p = new Connection(s); _connlist.push_back(p); &#125; void OnClientDisconnected( Connection* pconn )&#123; _connlist.remove( pconn ); delete pconn; &#125; private: list _connlist;&#125;; 假设在Client从Server端断开后，Server并没有呼叫OnClientDisconnected()函数，那么代表那次连接的Connection对象就不会被及时的删除（在Server程序退出的时候，所有Connection对象会在ConnectionManager的析构函数里被删除）。当不断的有连接建立、断开时隐式内存泄漏就发生了。 从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到。 检测内存泄漏检测内存泄漏的关键是要能截获住对分配内存和释放内存的函数的调用。截获住这两个函数，我们就能跟踪每一块内存的生命周期，比如，每当成功的分配一块内存后，就把它的指针加入一个全局的list中；每当释放一块内存，再把它的指针从list中删除。这样，当程序结束的时候，list中剩余的指针就是指向那些没有被释放的内存。这里只是简单的描述了检测内存泄漏的基本原理，详细的算法可以参见Steve Maguire的&lt;&gt;。 如果要检测堆内存的泄漏，那么需要截获住malloc/realloc/free和new/delete就可以了（其实new/delete最终也是用malloc/free的，所以只要截获前面一组即可）。对于其他的泄漏，可以采用类似的方法，截获住相应的分配和释放函数。比如，要检测BSTR的泄漏，就需要截获SysAllocString/SysFreeString；要检测HMENU的泄漏，就需要截获CreateMenu/ DestroyMenu。（有的资源的分配函数有多个，释放函数只有一个，比如，SysAllocStringLen也可以用来分配BSTR，这时就需要截获多个分配函数） 在Windows平台下，检测内存泄漏的工具常用的一般有三种，MS C-Runtime Library内建的检测功能；外挂式的检测工具，诸如，Purify，BoundsChecker等；利用Windows NT自带的Performance Monitor。这三种工具各有优缺点，MS C-Runtime Library虽然功能上较之外挂式的工具要弱，但是它是免费的；Performance Monitor虽然无法标示出发生问题的代码，但是它能检测出隐式的内存泄漏的存在，这是其他两类工具无能为力的地方。 以下我们详细讨论这三种检测工具： VC下内存泄漏的检测方法用MFC开发的应用程序，在DEBUG版模式下编译后，都会自动加入内存泄漏的检测代码。在程序结束后，如果发生了内存泄漏，在Debug窗口中会显示出所有发生泄漏的内存块的信息，以下两行显示了一块被泄漏的内存块的信息：12E:&quot;TestMemLeak&quot;TestDlg.cpp(70) : &#123;59&#125; normal block at 0x00881710, 200 bytes long.Data: &lt;abcdefghijklmnop&gt; 61 62 63 64 65 66 67 68 69 6A 6B 6C 6D 6E 6F 70 第一行显示该内存块由TestDlg.cpp文件，第70行代码分配，地址在0x00881710，大小为200字节，{59}是指调用内存分配函数的Request Order，关于它的详细信息可以参见MSDN中_CrtSetBreakAlloc()的帮助。第二行显示该内存块前16个字节的内容，尖括号内是以ASCII方式显示，接着的是以16进制方式显示。 一般大家都误以为这些内存泄漏的检测功能是由MFC提供的，其实不然。MFC只是封装和利用了MS C-Runtime Library的Debug Function。非MFC程序也可以利用MS C-Runtime Library的Debug Function加入内存泄漏的检测功能。MS C-Runtime Library在实现malloc/free，strdup等函数时已经内建了内存泄漏的检测功能。 注意观察一下由MFC Application Wizard生成的项目，在每一个cpp文件的头部都有这样一段宏定义：123456789#ifdef _DEBUG#define new DEBUG_NEW#undef THIS_FILEstatic char THIS_FILE[] = __FILE__;#endif 有了这样的定义，在编译DEBUG版时，出现在这个cpp文件中的所有new都被替换成DEBUG_NEW了。那么DEBUG_NEW是什么呢？DEBUG_NEW也是一个宏，以下摘自afx.h，1632行1#define DEBUG_NEW new(THIS_FILE, __LINE__) 所以如果有这样一行代码：1char* p = new char[200]; 经过宏替换就变成了：1char* p = new( THIS_FILE, __LINE__)char[200]; 根据C++的标准，对于以上的new的使用方法，编译器会去找这样定义的operator new：1void* operator new(size_t, LPCSTR, int) 我们在afxmem.cpp 63行找到了一个这样的operator new 的实现1234567891011void* AFX_CDECL operator new(size_t nSize, LPCSTR lpszFileName, int nLine)&#123; return ::operator new(nSize, _NORMAL_BLOCK, lpszFileName, nLine);&#125;void* __cdecl operator new(size_t nSize, int nType, LPCSTR lpszFileName, int nLine)&#123; pResult = _malloc_dbg(nSize, nType, lpszFileName, nLine); if (pResult != NULL) return pResult; ...&#125; 第二个operator new函数比较长，为了简单期间，我只摘录了部分。很显然最后的内存分配还是通过_malloc_dbg函数实现的，这个函数属于MS C-Runtime Library 的Debug Function。这个函数不但要求传入内存的大小，另外还有文件名和行号两个参数。文件名和行号就是用来记录此次分配是由哪一段代码造成的。如果这块内存在程序结束之前没有被释放，那么这些信息就会输出到Debug窗口里。 这里顺便提一下THIS_FILE，FILE和LINE__。FILE和LINE都是编译器定义的宏。当碰到FILE时，编译器会把FILE替换成一个字符串，这个字符串就是当前在编译的文件的路径名。当碰到LINE时，编译器会把LINE替换成一个数字，这个数字就是当前这行代码的行号。在DEBUG_NEW的定义中没有直接使用FILE，而是用了THIS_FILE，其目的是为了减小目标文件的大小。假设在某个cpp文件中有100处使用了new，如果直接使用FILE，那编译器会产生100个常量字符串，这100个字符串都是cpp文件的路径名，显然十分冗余。如果使用THIS_FILE，编译器只会产生一个常量字符串，那100处new的调用使用的都是指向常量字符串的指针。 再次观察一下由MFC Application Wizard生成的项目，我们会发现在cpp文件中只对new做了映射，如果你在程序中直接使用malloc函数分配内存，调用malloc的文件名和行号是不会被记录下来的。如果这块内存发生了泄漏，MS C-Runtime Library仍然能检测到，但是当输出这块内存块的信息，不会包含分配它的的文件名和行号。 要在非MFC程序中打开内存泄漏的检测功能非常容易，你只要在程序的入口处加入以下几行代码：123int tmpFlag = _CrtSetDbgFlag( _CRTDBG_REPORT_FLAG );tmpFlag |= _CRTDBG_LEAK_CHECK_DF;_CrtSetDbgFlag( tmpFlag ); 这样，在程序结束的时候，也就是winmain，main或dllmain函数返回之后，如果还有内存块没有释放，它们的信息会被打印到Debug窗口里。 如果你试着创建了一个非MFC应用程序，而且在程序的入口处加入了以上代码，并且故意在程序中不释放某些内存块，你会在Debug窗口里看到以下的信息：123&#123;47&#125; normal block at 0x00C91C90, 200 bytes long.Data: &lt; &gt; 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F 内存泄漏的确检测到了，但是和上面MFC程序的例子相比，缺少了文件名和行号。对于一个比较大的程序，没有这些信息，解决问题将变得十分困难。 为了能够知道泄漏的内存块是在哪里分配的，你需要实现类似MFC的映射功能，把new，maolloc等函数映射到_malloc_dbg函数上。这里我不再赘述，你可以参考MFC的源代码。 由于Debug Function实现在MS C-RuntimeLibrary中，所以它只能检测到堆内存的泄漏，而且只限于malloc，realloc或strdup等分配的内存，而那些系统资源，比如HANDLE，GDI Object，或是不通过C-Runtime Library分配的内存，比如VARIANT，BSTR的泄漏，它是无法检测到的，这是这种检测法的一个重大的局限性。另外，为了能记录内存块是在哪里分配的，源代码必须相应的配合，这在调试一些老的程序非常麻烦，毕竟修改源代码不是一件省心的事，这是这种检测法的另一个局限性。 对于开发一个大型的程序，MS C-Runtime Library提供的检测功能是远远不够的。接下来我们就看看外挂式的检测工具。我用的比较多的是BoundsChecker，一则因为它的功能比较全面，更重要的是它的稳定性。这类工具如果不稳定，反而会忙里添乱。到底是出自鼎鼎大名的NuMega，我用下来基本上没有什么大问题。 使用BoundsChecker检测内存泄漏BoundsChecker采用一种被称为 Code Injection的技术，来截获对分配内存和释放内存的函数的调用。简单地说，当你的程序开始运行时，BoundsChecker的DLL被自动载入进程的地址空间（这可以通过system-level的Hook实现），然后它会修改进程中对内存分配和释放的函数调用，让这些调用首先转入它的代码，然后再执行原来的代码。BoundsChecker在做这些动作的时，无须修改被调试程序的源代码或工程配置文件，这使得使用它非常的简便、直接。 这里我们以malloc函数为例，截获其他的函数方法与此类似。 需要被截获的函数可能在DLL中，也可能在程序的代码里。比如，如果静态连结C-Runtime Library，那么malloc函数的代码会被连结到程序里。为了截获住对这类函数的调用，BoundsChecker会动态修改这些函数的指令。 以下两段汇编代码，一段没有BoundsChecker介入，另一段则有BoundsChecker的介入：1234567891011121314151617126: _CRTIMP void * __cdecl malloc (127: size_t nSize128: )129: &#123;00403C10 push ebp00403C11 mov ebp,esp130: return _nh_malloc_dbg(nSize, _newmode, _NORMAL_BLOCK, NULL, 0);00403C13 push 000403C15 push 000403C17 push 100403C19 mov eax,[__newmode (0042376c)]00403C1E push eax00403C1F mov ecx,dword ptr [nSize]00403C22 push ecx00403C23 call _nh_malloc_dbg (00403c80)00403C28 add esp,14h131: &#125; 以下这一段代码有BoundsChecker介入：1234567891011121314126: _CRTIMP void * __cdecl malloc (127: size_t nSize128: )129: &#123;00403C10 jmp 01F41EC800403C15 push 000403C17 push 100403C19 mov eax,[__newmode (0042376c)]00403C1E push eax00403C1F mov ecx,dword ptr [nSize]00403C22 push ecx00403C23 call _nh_malloc_dbg (00403c80)00403C28 add esp,14h131: &#125; 当BoundsChecker介入后，函数malloc的前三条汇编指令被替换成一条jmp指令，原来的三条指令被搬到地址01F41EC8处了。当程序进入malloc后先jmp到01F41EC8，执行原来的三条指令，然后就是BoundsChecker的天下了。大致上它会先记录函数的返回地址（函数的返回地址在stack上，所以很容易修改），然后把返回地址指向属于BoundsChecker的代码，接着跳到malloc函数原来的指令，也就是在00403c15的地方。当malloc函数结束的时候，由于返回地址被修改，它会返回到BoundsChecker的代码中，此时BoundsChecker会记录由malloc分配的内存的指针，然后再跳转到到原来的返回地址去。 如果内存分配/释放函数在DLL中，BoundsChecker则采用另一种方法来截获对这些函数的调用。BoundsChecker通过修改程序的DLL Import Table让table中的函数地址指向自己的地址，以达到截获的目的。 截获住这些分配和释放函数，BoundsChecker就能记录被分配的内存或资源的生命周期。接下来的问题是如何与源代码相关，也就是说当BoundsChecker检测到内存泄漏，它如何报告这块内存块是哪段代码分配的。答案是调试信息（Debug Information）。当我们编译一个Debug版的程序时，编译器会把源代码和二进制代码之间的对应关系记录下来，放到一个单独的文件里(.pdb)或者直接连结进目标程序，通过直接读取调试信息就能得到分配某块内存的源代码在哪个文件，哪一行上。使用Code Injection和Debug Information，使BoundsChecker不但能记录呼叫分配函数的源代码的位置，而且还能记录分配时的Call Stack，以及Call Stack上的函数的源代码位置。这在使用像MFC这样的类库时非常有用，以下我用一个例子来说明：12345678910111213141516171819202122232425void ShowXItemMenu()&#123; ... CMenu menu; menu.CreatePopupMenu(); //add menu items. menu.TrackPropupMenu(); ...&#125;void ShowYItemMenu( )&#123; ... CMenu menu; menu.CreatePopupMenu(); //add menu items. menu.TrackPropupMenu(); menu.Detach();//this will cause HMENU leak ...&#125;BOOL CMenu::CreatePopupMenu()&#123; ... hMenu = CreatePopupMenu(); ...&#125; 当调用ShowYItemMenu()时，我们故意造成HMENU的泄漏。但是，对于BoundsChecker来说被泄漏的HMENU是在class CMenu::CreatePopupMenu()中分配的。假设的你的程序有许多地方使用了CMenu的CreatePopupMenu()函数，如CMenu::CreatePopupMenu()造成的，你依然无法确认问题的根结到底在哪里，在ShowXItemMenu()中还是在ShowYItemMenu()中，或者还有其它的地方也使用了CreatePopupMenu()？有了Call Stack的信息，问题就容易了。BoundsChecker会如下报告泄漏的HMENU的信息：123456789FunctionFileLineCMenu::CreatePopupMenuE:&quot;8168&quot;vc98&quot;mfc&quot;mfc&quot;include&quot;afxwin1.inl1009ShowYItemMenuE:&quot;testmemleak&quot;mytest.cpp100 这里省略了其他的函数调用 如此，我们很容易找到发生问题的函数是ShowYItemMenu()。当使用MFC之类的类库编程时，大部分的API调用都被封装在类库的class里，有了Call Stack信息，我们就可以非常容易的追踪到真正发生泄漏的代码。 记录Call Stack信息会使程序的运行变得非常慢，因此默认情况下BoundsChecker不会记录Call Stack信息。可以按照以下的步骤打开记录Call Stack信息的选项开关： 打开菜单：BoundsChecker|Setting… 在Error Detection页中，在Error Detection Scheme的List中选择Custom 在Category的Combox中选择 Pointer and leak error check 钩上Report Call Stack复选框 点击Ok 基于Code Injection，BoundsChecker还提供了API Parameter的校验功能，memory over run等功能。这些功能对于程序的开发都非常有益。由于这些内容不属于本文的主题，所以不在此详述了。 尽管BoundsChecker的功能如此强大，但是面对隐式内存泄漏仍然显得苍白无力。所以接下来我们看看如何用Performance Monitor检测内存泄漏。 使用Performance Monitor检测内存泄漏NT的内核在设计过程中已经加入了系统监视功能，比如CPU的使用率，内存的使用情况，I/O操作的频繁度等都作为一个个Counter，应用程序可以通过读取这些Counter了解整个系统的或者某个进程的运行状况。Performance Monitor就是这样一个应用程序。 为了检测内存泄漏，我们一般可以监视Process对象的Handle Count，Virutal Bytes 和Working Set三个Counter。Handle Count记录了进程当前打开的HANDLE的个数，监视这个Counter有助于我们发现程序是否有Handle泄漏；Virtual Bytes记录了该进程当前在虚地址空间上使用的虚拟内存的大小，NT的内存分配采用了两步走的方法，首先，在虚地址空间上保留一段空间，这时操作系统并没有分配物理内存，只是保留了一段地址。然后，再提交这段空间，这时操作系统才会分配物理内存。所以，Virtual Bytes一般总大于程序的Working Set。监视Virutal Bytes可以帮助我们发现一些系统底层的问题; Working Set记录了操作系统为进程已提交的内存的总量，这个值和程序申请的内存总量存在密切的关系，如果程序存在内存的泄漏这个值会持续增加，但是Virtual Bytes却是跳跃式增加的。 监视这些Counter可以让我们了解进程使用内存的情况，如果发生了泄漏，即使是隐式内存泄漏，这些Counter的值也会持续增加。但是，我们知道有问题却不知道哪里有问题，所以一般使用Performance Monitor来验证是否有内存泄漏，而使用BoundsChecker来找到和解决。 当Performance Monitor显示有内存泄漏，而BoundsChecker却无法检测到，这时有两种可能：第一种，发生了偶发性内存泄漏。这时你要确保使用Performance Monitor和使用BoundsChecker时，程序的运行环境和操作方法是一致的。第二种，发生了隐式的内存泄漏。这时你要重新审查程序的设计，然后仔细研究Performance Monitor记录的Counter的值的变化图，分析其中的变化和程序运行逻辑的关系，找到一些可能的原因。这是一个痛苦的过程，充满了假设、猜想、验证、失败，但这也是一个积累经验的绝好机会。 探讨C++内存回收C++内存对象大会战如果一个人自称为程序高手，却对内存一无所知，那么我可以告诉你，他一定在吹牛。用C或C++写程序，需要更多地关注内存，这不仅仅是因为内存的分配是否合理直接影响着程序的效率和性能，更为主要的是，当我们操作内存的时候一不小心就会出现问题，而且很多时候，这些问题都是不易发觉的，比如内存泄漏，比如悬挂指针。笔者今天在这里并不是要讨论如何避免这些问题，而是想从另外一个角度来认识C++内存对象。 我们知道，C++将内存划分为三个逻辑区域：堆、栈和静态存储区。既然如此，我称位于它们之中的对象分别为堆对象，栈对象以及静态对象。那么这些不同的内存对象有什么区别了？堆对象和栈对象各有什么优劣了？如何禁止创建堆对象或栈对象了？这些便是今天的主题。 基本概念先来看看栈。栈，一般用于存放局部变量或对象，如我们在函数定义中用类似下面语句声明的对象：1Type stack_object ; stack_object便是一个栈对象，它的生命期是从定义点开始，当所在函数返回时，生命结束。 另外，几乎所有的临时对象都是栈对象。比如，下面的函数定义：1Type fun(Type object); 这个函数至少产生两个临时对象，首先，参数是按值传递的，所以会调用拷贝构造函数生成一个临时对象object_copy1 ，在函数内部使用的不是使用的不是object，而是object_copy1，自然，object_copy1是一个栈对象，它在函数返回时被释放；还有这个函数是值返回的，在函数返回时，如果我们不考虑返回值优化（NRV），那么也会产生一个临时对象object_copy2，这个临时对象会在函数返回后一段时间内被释放。比如某个函数中有如下代码：123Type tt ,result ; //生成两个栈对象tt = fun(tt); //函数返回时，生成的是一个临时对象object_copy2 上面的第二个语句的执行情况是这样的，首先函数fun返回时生成一个临时对象object_copy2 ，然后再调用赋值运算符执行1tt = object_copy2 ; //调用赋值运算符 看到了吗？编译器在我们毫无知觉的情况下，为我们生成了这么多临时对象，而生成这些临时对象的时间和空间的开销可能是很大的，所以，你也许明白了，为什么对于”大”对象最好用const引用传递代替按值进行函数参数传递了。 接下来，看看堆。堆，又叫自由存储区，它是在程序执行的过程中动态分配的，所以它最大的特性就是动态性。在C++中，所有堆对象的创建和销毁都要由程序员负责，所以，如果处理不好，就会发生内存问题。如果分配了堆对象，却忘记了释放，就会产生内存泄漏；而如果已释放了对象，却没有将相应的指针置为NULL，该指针就是所谓的”悬挂指针”，再度使用此指针时，就会出现非法访问，严重时就导致程序崩溃。 那么，C++中是怎样分配堆对象的？唯一的方法就是用new（当然，用类malloc指令也可获得C式堆内存），只要使用new，就会在堆中分配一块内存，并且返回指向该堆对象的指针。 再来看看静态存储区。所有的静态对象、全局对象都于静态存储区分配。关于全局对象，是在main()函数执行前就分配好了的。其实，在main()函数中的显示代码执行之前，会调用一个由编译器生成的_main()函数，而_main()函数会进行所有全局对象的的构造及初始化工作。而在main()函数结束之前，会调用由编译器生成的exit函数，来释放所有的全局对象。比如下面的代码：1234void main（void）&#123; ... ...// 显式代码&#125; 实际上，被转化成这样：1234567void main（void）&#123; _main（）; //隐式代码，由编译器产生，用以构造所有全局对象 ... ... // 显式代码 ... ... exit（） ; // 隐式代码，由编译器产生，用以释放所有全局对象&#125; 所以，知道了这个之后，便可以由此引出一些技巧，如，假设我们要在main()函数执行之前做某些准备工作，那么我们可以将这些准备工作写到一个自定义的全局对象的构造函数中，这样，在main()函数的显式代码执行之前，这个全局对象的构造函数会被调用，执行预期的动作，这样就达到了我们的目的。 刚才讲的是静态存储区中的全局对象，那么，局部静态对象了？局部静态对象通常也是在函数中定义的，就像栈对象一样，只不过，其前面多了个static关键字。局部静态对象的生命期是从其所在函数第一次被调用，更确切地说，是当第一次执行到该静态对象的声明代码时，产生该静态局部对象，直到整个程序结束时，才销毁该对象。 还有一种静态对象，那就是它作为class的静态成员。考虑这种情况时，就牵涉了一些较复杂的问题。 第一个问题是class的静态成员对象的生命期，class的静态成员对象随着第一个class object的产生而产生，在整个程序结束时消亡。也就是有这样的情况存在，在程序中我们定义了一个class，该类中有一个静态对象作为成员，但是在程序执行过程中，如果我们没有创建任何一个该class object，那么也就不会产生该class所包含的那个静态对象。还有，如果创建了多个class object，那么所有这些object都共享那个静态对象成员。 第二个问题是，当出现下列情况时：12345678910111213141516171819class Base&#123; public: static Type s_object ;&#125;class Derived1 : public Base / / 公共继承&#123; ... ...// other data&#125;class Derived2 : public Base / / 公共继承&#123; ... ...// other data&#125;Base example ;Derivde1 example1 ;Derivde2 example2 ;**example.s_object = ...... ;****example1.s_object = ...... ;****example2.s_object = ...... ; ** 请注意上面标为黑体的三条语句，它们所访问的s_object是同一个对象吗？答案是肯定的，它们的确是指向同一个对象，这听起来不像是真的，是吗？但这是事实，你可以自己写段简单的代码验证一下。我要做的是来解释为什么会这样？ 我们知道，当一个类比如Derived1，从另一个类比如Base继承时，那么，可以看作一个Derived1对象中含有一个Base型的对象，这就是一个subobject。一个Derived1对象的大致内存布局如下： 让我们想想，当我们将一个Derived1型的对象传给一个接受非引用Base型参数的函数时会发生切割，那么是怎么切割的呢？相信现在你已经知道了，那就是仅仅取出了Derived1型的对象中的subobject，而忽略了所有Derived1自定义的其它数据成员，然后将这个subobject传递给函数（实际上，函数中使用的是这个subobject的拷贝）。 所有继承Base类的派生类的对象都含有一个Base型的subobject（这是能用Base型指针指向一个Derived1对象的关键所在，自然也是多态的关键了），而所有的subobject和所有Base型的对象都共用同一个s_object对象，自然，从Base类派生的整个继承体系中的类的实例都会共用同一个s_object对象了。上面提到的example、example1、example2的对象布局如下图所示： 三种内存对象的比较栈对象的优势是在适当的时候自动生成，又在适当的时候自动销毁，不需要程序员操心；而且栈对象的创建速度一般较堆对象快，因为分配堆对象时，会调用operator new操作，operator new会采用某种内存空间搜索算法，而该搜索过程可能是很费时间的，产生栈对象则没有这么麻烦，它仅仅需要移动栈顶指针就可以了。但是要注意的是，通常栈空间容量比较小，一般是1MB～2MB，所以体积比较大的对象不适合在栈中分配。特别要注意递归函数中最好不要使用栈对象，因为随着递归调用深度的增加，所需的栈空间也会线性增加，当所需栈空间不够时，便会导致栈溢出，这样就会产生运行时错误。 堆对象，其产生时刻和销毁时刻都要程序员精确定义，也就是说，程序员对堆对象的生命具有完全的控制权。我们常常需要这样的对象，比如，我们需要创建一个对象，能够被多个函数所访问，但是又不想使其成为全局的，那么这个时候创建一个堆对象无疑是良好的选择，然后在各个函数之间传递这个堆对象的指针，便可以实现对该对象的共享。另外，相比于栈空间，堆的容量要大得多。实际上，当物理内存不够时，如果这时还需要生成新的堆对象，通常不会产生运行时错误，而是系统会使用虚拟内存来扩展实际的物理内存。 接下来看看static对象。 首先是全局对象。全局对象为类间通信和函数间通信提供了一种最简单的方式，虽然这种方式并不优雅。一般而言，在完全的面向对象语言中，是不存在全局对象的，比如C#，因为全局对象意味着不安全和高耦合，在程序中过多地使用全局对象将大大降低程序的健壮性、稳定性、可维护性和可复用性。C++也完全可以剔除全局对象，但是最终没有，我想原因之一是为了兼容C。 其次是类的静态成员，上面已经提到，基类及其派生类的所有对象都共享这个静态成员对象，所以当需要在这些class之间或这些class objects之间进行数据共享或通信时，这样的静态成员无疑是很好的选择。 接着是静态局部对象，主要可用于保存该对象所在函数被屡次调用期间的中间状态，其中一个最显著的例子就是递归函数，我们都知道递归函数是自己调用自己的函数，如果在递归函数中定义一个nonstatic局部对象，那么当递归次数相当大时，所产生的开销也是巨大的。这是因为nonstatic局部对象是栈对象，每递归调用一次，就会产生一个这样的对象，每返回一次，就会释放这个对象，而且，这样的对象只局限于当前调用层，对于更深入的嵌套层和更浅露的外层，都是不可见的。每个层都有自己的局部对象和参数。 在递归函数设计中，可以使用static对象替代nonstatic局部对象（即栈对象），这不仅可以减少每次递归调用和返回时产生和释放nonstatic对象的开销，而且static对象还可以保存递归调用的中间状态，并且可为各个调用层所访问。 使用栈对象的意外收获前面已经介绍到，栈对象是在适当的时候创建，然后在适当的时候自动释放的，也就是栈对象有自动管理功能。那么栈对象会在什么会自动释放了？第一，在其生命期结束的时候；第二，在其所在的函数发生异常的时候。你也许说，这些都很正常啊，没什么大不了的。是的，没什么大不了的。但是只要我们再深入一点点，也许就有意外的收获了。 栈对象，自动释放时，会调用它自己的析构函数。如果我们在栈对象中封装资源，而且在栈对象的析构函数中执行释放资源的动作，那么就会使资源泄漏的概率大大降低，因为栈对象可以自动的释放资源，即使在所在函数发生异常的时候。实际的过程是这样的：函数抛出异常时，会发生所谓的stack_unwinding（堆栈回滚），即堆栈会展开，由于是栈对象，自然存在于栈中，所以在堆栈回滚的过程中，栈对象的析构函数会被执行，从而释放其所封装的资源。除非，除非在析构函数执行的过程中再次抛出异常――而这种可能性是很小的，所以用栈对象封装资源是比较安全的。基于此认识，我们就可以创建一个自己的句柄或代理来封装资源了。智能指针（auto_ptr）中就使用了这种技术。在有这种需要的时候，我们就希望我们的资源封装类只能在栈中创建，也就是要限制在堆中创建该资源封装类的实例。 禁止产生堆对象上面已经提到，你决定禁止产生某种类型的堆对象，这时你可以自己创建一个资源封装类，该类对象只能在栈中产生，这样就能在异常的情况下自动释放封装的资源。 那么怎样禁止产生堆对象了？我们已经知道，产生堆对象的唯一方法是使用new操作，如果我们禁止使用new不就行了么。再进一步，new操作执行时会调用operator new，而operator new是可以重载的。方法有了，就是使new operator 为private，为了对称，最好将operator delete也重载为private。现在，你也许又有疑问了,难道创建栈对象不需要调用new吗？是的，不需要，因为创建栈对象不需要搜索内存，而是直接调整堆栈指针，将对象压栈，而operator new的主要任务是搜索合适的堆内存，为堆对象分配空间，这在上面已经提到过了。好，让我们看看下面的示例代码：1234567891011121314151617181920212223242526#include &lt;stdlib.h&gt; //需要用到C式内存分配函数class Resource ; //代表需要被封装的资源类class NoHashObject&#123; private: Resource* ptr ;//指向被封装的资源 ... ... //其它数据成员 void* operator new(size_t size) //非严格实现，仅作示意之用 &#123; return malloc(size) ; &#125; void operator delete(void* pp) //非严格实现，仅作示意之用 &#123; free(pp) ; &#125; public: NoHashObject() &#123; //此处可以获得需要封装的资源，并让ptr指针指向该资源 ptr = new Resource() ; &#125; ~NoHashObject() &#123; delete ptr ; //释放封装的资源 &#125;&#125;; NoHashObject现在就是一个禁止堆对象的类了，如果你写下如下代码：12NoHashObject* fp = new NoHashObject() ; //编译期错误！delete fp ; 上面代码会产生编译期错误。好了，现在你已经知道了如何设计一个禁止堆对象的类了，你也许和我一样有这样的疑问，难道在类NoHashObject的定义不能改变的情况下，就一定不能产生该类型的堆对象了吗？不，还是有办法的，我称之为”暴力破解法”。C++是如此地强大，强大到你可以用它做你想做的任何事情。这里主要用到的是技巧是指针类型的强制转换。1234567891011121314151617void main(void)&#123; char* temp = new char[sizeof(NoHashObject)] ; //强制类型转换，现在ptr是一个指向NoHashObject对象的指针 NoHashObject* obj_ptr = (NoHashObject*)temp ; temp = NULL ; //防止通过temp指针修改NoHashObject对象 //再一次强制类型转换，让rp指针指向堆中NoHashObject对象的ptr成员 Resource* rp = (Resource*)obj_ptr ; //初始化obj_ptr指向的NoHashObject对象的ptr成员 rp = new Resource() ; //现在可以通过使用obj_ptr指针使用堆中的NoHashObject对象成员了 .. ... delete rp ;//释放资源 temp = (char*)obj_ptr ; obj_ptr = NULL ;//防止悬挂指针产生 delete [] temp ;//释放NoHashObject对象所占的堆空间。&#125; 上面的实现是麻烦的，而且这种实现方式几乎不会在实践中使用，但是我还是写出来路，因为理解它，对于我们理解C++内存对象是有好处的。对于上面的这么多强制类型转换，其最根本的是什么了？我们可以这样理解： 某块内存中的数据是不变的，而类型就是我们戴上的眼镜，当我们戴上一种眼镜后，我们就会用对应的类型来解释内存中的数据，这样不同的解释就得到了不同的信息。 所谓强制类型转换实际上就是换上另一副眼镜后再来看同样的那块内存数据。 另外要提醒的是，不同的编译器对对象的成员数据的布局安排可能是不一样的，比如，大多数编译器将NoHashObject的ptr指针成员安排在对象空间的头4个字节，这样才会保证下面这条语句的转换动作像我们预期的那样执行：1Resource* rp = (Resource*)obj_ptr ; 但是，并不一定所有的编译器都是如此。 既然我们可以禁止产生某种类型的堆对象，那么可以设计一个类，使之不能产生栈对象吗？当然可以。 禁止产生栈对象前面已经提到了，创建栈对象时会移动栈顶指针以”挪出”适当大小的空间，然后在这个空间上直接调用对应的构造函数以形成一个栈对象，而当函数返回时，会调用其析构函数释放这个对象，然后再调整栈顶指针收回那块栈内存。在这个过程中是不需要operator new/delete操作的，所以将operator new/delete设置为private不能达到目的。当然从上面的叙述中，你也许已经想到了：将构造函数或析构函数设为私有的，这样系统就不能调用构造/析构函数了，当然就不能在栈中生成对象了。 这样的确可以，而且我也打算采用这种方案。但是在此之前，有一点需要考虑清楚,那就是，如果我们将构造函数设置为私有，那么我们也就不能用new来直接产生堆对象了，因为new在为对象分配空间后也会调用它的构造函数啊。所以，我打算只将析构函数设置为private。再进一步，将析构函数设为private除了会限制栈对象生成外，还有其它影响吗？是的，这还会限制继承。 如果一个类不打算作为基类，通常采用的方案就是将其析构函数声明为private。 为了限制栈对象，却不限制继承，我们可以将析构函数声明为protected，这样就两全其美了。如下代码所示：12345678910class NoStackObject&#123; protected: ~NoStackObject() &#123; &#125; public: void destroy() &#123; delete this ;//调用保护析构函数 &#125;&#125;; 接着，可以像这样使用NoStackObject类：123NoStackObject* hash_ptr = new NoStackObject() ;... ... //对hash_ptr指向的对象进行操作hash_ptr-&gt;destroy() ; 呵呵，是不是觉得有点怪怪的，我们用new创建一个对象，却不是用delete去删除它，而是要用destroy方法。很显然，用户是不习惯这种怪异的使用方式的。所以，我决定将构造函数也设为private或protected。这又回到了上面曾试图避免的问题，即不用new，那么该用什么方式来生成一个对象了？我们可以用间接的办法完成，即让这个类提供一个static成员函数专门用于产生该类型的堆对象。（设计模式中的singleton模式就可以用这种方式实现。）让我们来看看：123456789101112131415class NoStackObject&#123; protected: NoStackObject() &#123; &#125; ~NoStackObject() &#123; &#125; public: static NoStackObject* creatInstance() &#123; return new NoStackObject() ;//调用保护的构造函数 &#125;void destroy()&#123; delete this ;//调用保护的析构函数&#125;&#125;; 现在可以这样使用NoStackObject类了：1234NoStackObject* hash_ptr = NoStackObject::creatInstance() ;... ... //对hash_ptr指向的对象进行操作hash_ptr-&gt;destroy() ;hash_ptr = NULL ; //防止使用悬挂指针 现在感觉是不是好多了，生成对象和释放对象的操作一致了。 浅议C++ 中的垃圾回收方法许多 C 或者 C++ 程序员对垃圾回收嗤之以鼻，认为垃圾回收肯定比自己来管理动态内存要低效，而且在回收的时候一定会让程序停顿在那里，而如果自己控制内存管理的话，分配和释放时间都是稳定的，不会导致程序停顿。最后，很多 C/C++ 程序员坚信在C/C++ 中无法实现垃圾回收机制。这些错误的观点都是由于不了解垃圾回收的算法而臆想出来的。 其实垃圾回收机制并不慢，甚至比动态内存分配更高效。因为我们可以只分配不释放，那么分配内存的时候只需要从堆上一直的获得新的内存，移动堆顶的指针就够了；而释放的过程被省略了，自然也加快了速度。现代的垃圾回收算法已经发展了很多，增量收集算法已经可以让垃圾回收过程分段进行，避免打断程序的运行了。而传统的动态内存管理的算法同样有在适当的时间收集内存碎片的工作要做，并不比垃圾回收更有优势。 而垃圾回收的算法的基础通常基于扫描并标记当前可能被使用的所有内存块，从已经被分配的所有内存中把未标记的内存回收来做的。C/C++ 中无法实现垃圾回收的观点通常基于无法正确扫描出所有可能还会被使用的内存块，但是，看似不可能的事情实际上实现起来却并不复杂。首先，通过扫描内存的数据，指向堆上动态分配出来内存的指针是很容易被识别出来的，如果有识别错误，也只能是把一些不是指针的数据当成指针，而不会把指针当成非指针数据。这样，回收垃圾的过程只会漏回收掉而不会错误的把不应该回收的内存清理。其次，如果回溯所有内存块被引用的根，只可能存在于全局变量和当前的栈内，而全局变量(包括函数内的静态变量)都是集中存在于 bss 段或 data段中。 垃圾回收的时候，只需要扫描 bss 段, data 段以及当前被使用着的栈空间，找到可能是动态内存指针的量，把引用到的内存递归扫描就可以得到当前正在使用的所有动态内存了。 如果肯为你的工程实现一个不错的垃圾回收器，提高内存管理的速度，甚至减少总的内存消耗都是可能的。如果有兴趣的话，可以搜索一下网上已有的关于垃圾回收的论文和实现了的库，开拓视野对一个程序员尤为重要。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解软件包的配置、编译与安装]]></title>
    <url>%2F2019%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E9%85%8D%E7%BD%AE%E3%80%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[从源代码安装过软件的朋友一定对 ./configure &amp;&amp; make &amp;&amp; make install 安装三步曲非常熟悉了。然而究竟这个过程中的每一步幕后都发生了些什么呢？本文将带领你一探究竟。深入理解这个过程将有助于你在LFS的基础上玩出自己的花样来。不过需要说明的是本文对 Makefile 和 make 的讲解是相当近视和粗浅的，但是对于理解安装过程来说足够了。 概述用一句话来解释这个过程就是： 根据源码包中 Makefile.in 文件的指示，configure 脚本检查当前的系统环境和配置选项，在当前目录中生成 Makefile 文件(还有其它本文无需关心的文件)，然后 make 程序就按照当前目录中的 Makefile 文件的指示将源代码编译为二进制文件，最后将这些二进制文件移动(即安装)到指定的地方(仍然按照 Makefile 文件的指示)。 由此可见 Makefile 文件是幕后的核心。要深入理解安装过程，必须首先对 Makefile 文件有充分的了解。本文将首先讲述 Makefile 与 make ，然后再讲述 configure 脚本。并且在讲述这两部分内容时，提供了尽可能详细的、可以运用于实践的参考资料。 Makefile 与 make用一句话来概括Makefile 与 make 的关系就是：Makefile 包含了所有的规则和目标，而 make 则是为了完成目标而去解释 Makefile 规则的工具。 make 语法首先看看 make 的命令行语法： make [options] [targets] [VAR=VALUE]...[options]是命令行选项，可以用 make –help 命令查看全部，[VAR=VALUE]是在命令行上指定环境变量，这两个大家都很熟悉，将在稍后详细讲解。而[targets]是什么呢？字面的意思是”目标”，也就是希望本次 make 命令所完成的任务。凭经验猜测，这个[targets]大概可以用”check”,”install”之类(也就是常见的测试和安装命令)。但是它到底是个啥玩意儿？不带任何”目标”的 make 命令是什么意思？为什么在安装 LFS 工具链中的 Perl-5.8.8 软件包时会出现”make perl utilities”这样怪异的命令？要回答这些问题必须首先理解 Makefile 文件中的”规则”。 Makefile 规则Makefile 规则包含了文件之间的依赖关系和更新此规则目标所需要的命令。 一个简单的 Makefile 规则是这样写的：12TARGET : PREREQUISITES COMMAND TARGET规则的目标。也就是可以被 make 使用的”目标”。有些目标可以没有依赖而只有动作(命令行)，比如”clean”，通常仅仅定义一系列删除中间文件的命令。同样，有些目标可以没有动作而只有依赖，比如”all”，通常仅仅用作”终极目标”。PREREQUISITES规则的依赖。通常一个目标依赖于一个或者多个文件。COMMAND规则的命令行。一个规则可以有零个或多个命令行。OK! 现在你明白[targets]是什么了，原来它们来自于 Makefile 文件中一条条规则的目标(TARGET)。另外，Makefile文件中第一条规则的目标被称为”终极目标”，也就是你省略[targets]参数时的目标(通常为”all”)。 当你查看一个实际的 Makefile 文件时，你会发现有些规则非常复杂，但是它都符合规则的基本格式。此外，Makefile 文件中通常还包含了除规则以外的其它很多东西，不过本文只关心其中的变量。 Makefile 变量Makefile 中的”变量”更像是 C 语言中的宏，代表一个文本字符串(变量的值)，可以用于规则的任何部分。变量的定义很简单：VAR=VALUE；变量的引用也很简单：$(VAR) 或者 ${VAR}。变量引用的展开过程是严格的文本替换过程，就是说变量值的字符串被精确的展开在变量被引用的地方。比如，若定义：VAR=c，那么，”$(VAR) $(VAR)-$(VAR) VAR.$(VAR)”将被展开为”c c-c VAR.c”。 虽然在 Makefile 中可以直接使用系统的环境变量，但是也可以通过在 Makefile 中定义同名变量来”遮盖”系统的环境变量。另一方面，我们可以在调用 make 时使用 -e 参数强制使系统中的环境变量覆盖 Makefile 中的同名变量，除此之外，在调用 make 的命令行上使用 VAR=VALUE 格式指定的环境变量也可以覆盖 Makefile 中的同名变量。 Makefile 实例下面看一个简单的、实际的Makefile文件：123456789101112131415161718192021222324252627282930313233CC=gccCPPFLAGS=CFLAGS=-O2 -pipeLDFLAGS=-sPREFIX=/usrall : prog1 prog2prog1 : prog1.o $(CC) $(LDFLAGS) -o prog1 prog1.oprog1.o : prog1.c $(CC) -c $(CFLAGS) prog1.cprog2 : prog2.o $(CC) $(CFLAGS) $(LDFLAGS) -o prog2 prog2.oprog2.o : prog2.c $(CC) -c $(CPPFLAGS) $(CFLAGS) prog2.cclean : rm -f *.&#123;o,a&#125; prog&#123;1,2&#125;install : prog1 prog2 if ( test ! -d $(PREFIX)/bin ) ; then mkdir -p $(PREFIX)/bin ; fi cp -f prog1 $(PREFIX)/bin/prog1 cp -f prog2 $(PREFIX)/bin/prog2check test : prog1 prog2 prog1 &lt; sample1.ref &gt; sample1.rz prog1 &lt; sample2.ref &gt; sample3.rz cmp sample1.ok sample1.rz cmp sample2.ok sample2.rz 从中可以看出，make 与 make all 以及 make prog1 prog2 三条命令其实是等价的。而常用的 make check 和 make install 也找到了归属。同时我们也看到了 Makefile 中的各种变量是如何影响编译的。针对这个特定的 Makefile ，你甚至可以省略安装三步曲中的 make 命令而直接使用 make install 进行安装。 同样，为了使用自定义的编译参数编译 prog2 ，我们可以使用 make prog2 CFLAGS=”-O3 -march=athlon64” 或 CFLAGS=”-O3 -march=athlon64” &amp;&amp; make -e prog2 命令达到此目的。 Makefile 惯例下面是Makefile中一些约定俗成的目标名称及其含义： all编译整个软件包，但不重建任何文档。一般此目标作为默认的终极目标。此目标一般对所有源程序的编译和连接使用”-g”选项，以使最终的可执行程序中包含调试信息。可使用 strip 程序去掉这些调试符号。clean清除当前目录下在 make 过程中产生的文件。它不能删除软件包的配置文件，也不能删除 build 时创建的那些文件。distclean类似于”clean”，但增加删除当前目录下的的配置文件、build 过程产生的文件。info产生必要的 Info 文档。check 或 test完成所有的自检功能。在执行检查之前，应确保所有程序已经被创建(但可以尚未安装)。为了进行测试，需要实现在程序没有安装的情况下被执行的测试命令。install完成程序的编译并将最终的可执行程序、库文件等拷贝到指定的目录。此种安装一般不对可执行程序进行 strip 操作。install-strip和”install”类似，但是会对复制到安装目录下的可执行文件进行 strip 操作。uninstall删除所有由”install”安装的文件。installcheck执行安装检查。在执行安装检查之前，需要确保所有程序已经被创建并且被安装。installdirs创建安装目录及其子目录。它不能更改软件的编译目录，而仅仅是创建程序的安装目录。下面是 Makefile 中一些约定俗成的变量名称及其含义： 这些约定俗成的变量分为三类。第一类代表可执行程序的名字，例如 CC 代表编译器这个可执行程序；第二类代表程序使用的参数(多个参数使用空格分开)，例如 CFLAGS 代表编译器执行时使用的参数(一种怪异的做法是直接在 CC 中包含参数)；第三类代表安装目录，例如 prefix 等等，含义简单，下面只列出它们的默认值。12345678910111213141516171819202122232425262728293031323334AR 函数库打包程序，可创建静态库.a文档。默认是&quot;ar&quot;。AS 汇编程序。默认是&quot;as&quot;。CC C编译程序。默认是&quot;cc&quot;。CXX C++编译程序。默认是&quot;g++&quot;。CPP C/C++预处理器。默认是&quot;$(CC) -E&quot;。FC Fortran编译器。默认是&quot;f77&quot;。PC Pascal语言编译器。默认是&quot;pc&quot;。YACC Yacc文法分析器。默认是&quot;yacc&quot;。ARFLAGS 函数库打包程序的命令行参数。默认值是&quot;rv&quot;。ASFLAGS 汇编程序的命令行参数。CFLAGS C编译程序的命令行参数。CXXFLAGS C++编译程序的命令行参数。CPPFLAGS C/C++预处理器的命令行参数。FFLAGS Fortran编译器的命令行参数。PFLAGS Pascal编译器的命令行参数。YFLAGS Yacc文法分析器的命令行参数。LDFLAGS 链接器的命令行参数。prefix /usr/localexec_prefix $(prefix)bindir $(exec_prefix)/binsbindir $(exec_prefix)/sbinlibexecdir $(exec_prefix)/libexecdatadir $(prefix)/sharesysconfdir $(prefix)/etcsharedstatedir $(prefix)/comlocalstatedir $(prefix)/varlibdir $(exec_prefix)/libinfodir $(prefix)/infoincludedir $(prefix)/includeoldincludedir $(prefix)/includemandir $(prefix)/mansrcdir 需要编译的源文件所在的目录，无默认值 make 选项最后说说 make 的命令行选项(以Make-3.81版本为准)： -B, –always-make无条件的重建所有规则的目标，而不是根据规则的依赖关系决定是否重建某些目标文件。-C DIR, –directory=DIR在做任何动作之前先切换工作目录到 DIR ，然后再执行 make 程序。-d在 make 执行过程中打印出所有的调试信息。包括：make 认为那些文件需要重建；那些文件需要比较它们的最后修改时间、比较的结果；重建目标所要执行的命令；使用的隐含规则等。使用该选项我们可以看到 make 构造依赖关系链、重建目标过程的所有信息，它等效于”-debug=a”。–debug=FLAGS在 make 执行过程中打印出调试信息。FLAGS 用于控制调试信息级别：a输出所有类型的调试信息b输出基本调试信息。包括：那些目标过期、是否重建成功过期目标文件。v除 b 级别以外还包括：解析的 makefile 文件名，不需要重建文件等。i除 b 级别以外还包括：所有使用到的隐含规则描述。j输出所有执行命令的子进程，包括命令执行的 PID 等。m输出 make 读取、更新、执行 makefile 的信息。-e, –environment-overrides使用系统环境变量的定义覆盖 Makefile 中的同名变量定义。-f FILE, –file=FILE, –makefile=FILE将 FILE 指定为 Makefile 文件。-h, –help打印帮助信息。-i, –ignore-errors忽略规则命令执行过程中的错误。-I DIR, –include-dir=DIR指定包含 Makefile 文件的搜索目录。使用多个”-I”指定目录时，搜索目录按照指定顺序进行。-j [N], –jobs[=N]指定并行执行的命令数目。在没有指定”-j”参数的情况下，执行的命令数目将是系统允许的最大可能数目。-k, –keep-going遇见命令执行错误时不终止 make 的执行，也就是尽可能执行所有的命令，直到出现致命错误才终止。-l [N], –load-average[=N], –max-load[=N]如果系统负荷超过 LOAD(浮点数)，不再启动新任务。-L, –check-symlink-times同时考察符号连接的时间戳和它所指向的目标文件的时间戳，以两者中较晚的时间戳为准。-n, –just-print, –dry-run, –recon只打印出所要执行的命令，但并不实际执行命令。-o FILE, –old-file=FILE, –assume-old=FILE即使相对于它的依赖已经过期也不重建 FILE 文件；同时也不重建依赖于此文件任何文件。-p, –print-data-base命令执行之前，打印出 make 读取的 Makefile 的所有数据（包括规则和变量的值），同时打印出 make 的版本信息。如果只需要打印这些数据信息，可以使用 make -qp 命令。查看 make 执行前的预设规则和变量，可使用命令 make -p -f /dev/null 。-q, –question“询问模式”。不运行任何命令，并且无输出，只是返回一个查询状态。返回状态为 0 表示没有目标需要重建，1 表示存在需要重建的目标，2 表示有错误发生。-r, –no-builtin-rules取消所有内嵌的隐含规则，不过你可以在 Makefile 中使用模式规则来定义规则。同时还会取消所有支持后追规则的隐含后缀列表，同样我们也可以在 Makefile 中使用”.SUFFIXES”定义我们自己的后缀规则。此选项不会取消 make 内嵌的隐含变量。-R, –no-builtin-variables取消 make 内嵌的隐含变量，不过我们可以在 Makefile 中明确定义某些变量。注意，此选项同时打开了”-r”选项。因为隐含规则是以内嵌的隐含变量为基础的。-s, –silent, –quiet不显示所执行的命令。-S, –no-keep-going, –stop取消”-k”选项。在递归的 make 过程中子 make 通过 MAKEFLAGS 变量继承了上层的命令行选项。我们可以在子 make 中使用”-S”选项取消上层传递的”-k”选项，或者取消系统环境变量 MAKEFLAGS 中的”-k”选项。-t, –touch更新所有目标文件的时间戳到当前系统时间。防止 make 对所有过时目标文件的重建。-v, –version打印版本信息。-w, –print-directory在 make 进入一个目录之前打印工作目录。使用”-C”选项时默认打开这个选项。–no-print-directory取消”-w”选项。可以是用在递归的 make 调用过程中，取消”-C”参数将默认打开”-w”。-W FILE, –what-if=FILE, –new-file=FILE, –assume-new=FILE设定 FILE 文件的时间戳为当前时间，但不改变文件实际的最后修改时间。此选项主要是为实现了对所有依赖于 FILE 文件的目标的强制重建。–warn-undefined-variables在发现 Makefile 中存在对未定义的变量进行引用时给出告警信息。此功能可以帮助我们调试一个存在多级套嵌变量引用的复杂 Makefile 。但是：我们建议在书写 Makefile 时尽量避免超过三级以上的变量套嵌引用。 configure此阶段的主要目的是生成 Makefile 文件，是最关键的运筹帷幄阶段，基本上所有可以对安装过程进行的个性化调整都集中在这一步。 configure 脚本能够对 Makefile 中的哪些内容产生影响呢？基本上可以这么说：所有内容，包括本文最关心的 Makefile 规则与 Makefile 变量。那么又是哪些因素影响着最终生成的 Makefile 文件呢？答曰：系统环境和配置选项。 配置选项的影响是显而易见的。但是”系统环境”的概念却很宽泛，包含很多方面内容，不过我们这里只关心环境变量，具体说来就是将来会在 Makefile 中使用到的环境变量以及与 Makefile 中的变量同名的环境变量。 通用 configure 语法在进一步讲述之前，先看看 configure 脚本的语法，一般有两种：12configure [OPTIONS] [VAR=VALUE]...configure [OPTIONS] [HOST] 不管是哪种语法，我们都可以用 configure –help 查看所有可用的[OPTIONS]，并且通常在结尾部分还能看到这个脚本所关心的环境变量有哪些。在本文中将对这两种语法进行合并，使用下面这种简化的语法：1configure [OPTIONS] 这种语法能够被所有的 configure 脚本所识别，同时也能通过设置环境变量和使用特定的[OPTIONS]完成上述两种语法的一切功能。 通用 configure 选项虽然每个软件包的 configure 脚本千差万别，但是它们却都有一些共同的选项，也基本上都遵守相同的选项语法。 脚本自身选项–help显示帮助信息。–version显示版本信息。–cache-file=FILE在FILE文件中缓存测试结果(默认禁用)。–no-createconfigure脚本运行结束后不输出结果文件，常用于正式编译前的测试。–quiet, –silent不显示脚本工作期间输出的”checking …”消息。目录选项–srcdir=DIR源代码文件所在目录，默认为configure脚本所在目录或其父目录。–prefix=PREFIX体系无关文件的顶级安装目录PREFIX ，默认值一般是 /usr/local 或 /usr/local/pkgName–exec-prefix=EPREFIX体系相关文件的顶级安装目录EPREFIX ，默认值一般是 PREFIX–bindir=DIR用户可执行文件的存放目录DIR ，默认值一般是 EPREFIX/bin–sbindir=DIR系统管理员可执行目录DIR ，默认值一般是 EPREFIX/sbin–libexecdir=DIR程序可执行目录DIR ，默认值一般是 EPREFIX/libexec–datadir=DIR通用数据文件的安装目录DIR ，默认值一般是 PREFIX/share–sysconfdir=DIR只读的单一机器数据目录DIR ，默认值一般是 PREFIX/etc–sharedstatedir=DIR可写的体系无关数据目录DIR ，默认值一般是 PREFIX/com–localstatedir=DIR可写的单一机器数据目录DIR ，默认值一般是 PREFIX/var–libdir=DIR库文件的安装目录DIR ，默认值一般是 EPREFIX/lib–includedir=DIRC头文件目录DIR ，默认值一般是 PREFIX/include–oldincludedir=DIR非gcc的C头文件目录DIR ，默认值一般是 /usr/include–infodir=DIRInfo文档的安装目录DIR ，默认值一般是 PREFIX/info–mandir=DIRMan文档的安装目录DIR ，默认值一般是 PREFIX/man体系结构选项玩交叉编译的朋友对这些选项已经很熟悉了，对于不使用交叉编译的朋友也不必担心，不要理它们就可以了。 –build=BUILD工具链当前的运行环境，默认是 config.guess 脚本的输出结果。–host=HOST编译出的二进制代码将要运行在HOST上，默认值是BUILD。–target=TARGET编译出的工具链所将来生成的二进制代码要在TARGET上运行，这个选项仅对工具链(也就是GCC和Binutils两者)有意义。特性选项–enable-FEATURE启用FEATURE特性–disable-FEATURE禁用FEATURE特性–with-PACKAGE[=DIR]启用附加软件包PACKAGE，亦可同时指定PACKAGE所在目录DIR–without-PACKAGE禁用附加软件包PACKAGE通用环境变量除了上述通用的选项外，下列环境变量影响着最终生成的 Makefile 文件： CPPC预处理器命令CXXCPPC++预处理器命令CPPFLAGSC/C++预处理器命令行参数CCC编译器命令CFLAGSC编译器命令行参数CXXC++编译器命令CXXFLAGSC++编译器命令行参数LDFLAGS连接器命令行参数至于设置这些环境变量的方法，你可以将它们 export 为全局变量在全局范围内使用，也可以在命令行上使用 [VAR=VALUE]… configure [OPTIONS] 的语法局部使用。此处就不详细描述了。 看完上述内容以后，不用多说你应当自然而然的明白该进行如何对自己的软件包进行定制安装了。祝你好运！]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC 编译优化指南]]></title>
    <url>%2F2019%2F04%2F09%2FGCC%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[基本原理我们首先从三个方面来看与优化相关的内容： 从运行时的依赖关系来看，对性能有较大影响的组件有 kernel 和 glibc ，虽然这严格说来这不属于本文的话题，但是经过精心选择、精心配置、精心编译的内核与C库将对提高系统的运行速度起着基础性的作用。从被编译的软件包来看，每个软件包的 configure 脚本都提供了许多配置选项，其中有许多选项是与性能息息相关的。比如，对于 Apache-2.2.6 而言，你可以使用 –enable-MODULE=static 将模块静态编译进核心，使用 –disable-MODULE 禁用不需要的模块，使用 –with-mpm=MPM 选择一个高效的多路处理模块，在不需要IPv6的情况下使用 –disable-ipv6 禁用IPv6支持，在不使用线程化的MPM时使用 –disable-threads 禁用线程支持，等等……这部分内容显然不可能在本文中进行完整的讲述，本文只能讲述与优化相关的通用选项。针对特定的软件包，请在编译前使用 configure –help 查看所有选项，并精心选择。从编译过程自身来看，将源代码编译为二进制文件是在 Makefile 文件的指导下，由 make 程序调用一条条编译命令完成的。而将源代码编译为二进制文件又需要经过以下四个步骤：预处理(cpp) → 编译(gcc或g++) → 汇编(as) → 连接(ld) ；括号中表示每个阶段所使用的程序，它们分别属于 GCC 和 Binutils 软件包。显然的，优化应当从编译工具自身的选择以及控制编译工具的行为入手。大体上编译优化就这”三板斧”(其实是”三脚猫”)了，本文接下来的内容将讨论这只猫的后两只脚。 编译工具的选择对于编译工具自身的选择，在假定使用 Binutils 和 GCC 以及 Make 的前提下，没什么好说的，基本上新版本都能带来性能提升，同时比老版本对新硬件的支持更好，所以应当尽量选用新版本。不过追新也可能带来系统的不稳定，这就要针对实际情况进行权衡了。本文以 Binutils-2.18 和 GCC-4.2.2/GCC-4.3.0 以及 Make-3.81 为例进行说明。 configure 选项这里我们只讲解通用的”体系结构选项”，由于”特性选项”在每个软件包之间千差万别，所以不可能在此处进行讲解。 这部分内容很简单，并且其含义也是不言而喻的，下面只列出常用的值： i586-pc-linux-gnui686-pc-linux-gnux86_64-pc-linux-gnupowerpc-unknown-linux-gnupowerpc64-unknown-linux-gnu如果你实在不知道应当使用哪一个，那么就干脆不使用这几个选项，让 config.guess 脚本自己去猜吧，反正也挺准的。 编译选项让我们先看看 Makefile 规则中的编译命令通常是怎么写的。 大多数软件包遵守如下约定俗成的规范： 首先从源代码生成目标文件(预处理,编译,汇编)，”-c”选项表示不执行链接步骤。$(CC) $(CPPFLAGS) $(CFLAGS) example.c -c -o example.o 然后将目标文件连接为最终的结果(连接)，”-o”选项用于指定输出文件的名字。$(CC) $(LDFLAGS) example.o -o example 有一些软件包一次完成四个步骤：$(CC) $(CPPFLAGS) $(CFLAGS) $(LDFLAGS) example.c -o example当然也有少数软件包不遵守这些约定俗成的规范，比如： 有些在命令行中漏掉应有的Makefile变量(注意：有些遗漏是故意的)$(CC) $(CFLAGS) example.c -c -o example.o$(CC) $(CPPFLAGS) example.c -c -o example.o$(CC) example.o -o example$(CC) example.c -o example 有些在命令行中增加了不必要的Makefile变量$(CC) $(CFLAGS) $(LDFLAGS) example.o -o example$(CC) $(CPPFLAGS) $(CFLAGS) $(LDFLAGS) example.c -c -o example.o当然还有极个别软件包完全是”胡来”：乱用变量(增加不必要的又漏掉了应有的)者有之，不用$(CC)者有之，不一而足….. 尽管将源代码编译为二进制文件的四个步骤由不同的程序(cpp,gcc/g++,as,ld)完成，但是事实上 cpp, as, ld 都是由 gcc/g++ 进行间接调用的。换句话说，控制了 gcc/g++ 就等于控制了所有四个步骤。从 Makefile 规则中的编译命令可以看出，编译工具的行为全靠 CC/CXX CPPFLAGS CFLAGS/CXXFLAGS LDFLAGS 这几个变量在控制。当然理论上控制编译工具行为的还应当有 AS ASFLAGS ARFLAGS 等变量，但是实践中基本上没有软件包使用它们。 那么我们如何控制这些变量呢？一种简易的做法是首先设置与这些 Makefile 变量同名的环境变量并将它们 export 为全局，然后运行 configure 脚本，大多数 configure 脚本会使用这同名的环境变量代替 Makefile 中的值。但是少数 configure 脚本并不这样做(比如GCC-3.4.6和Binutils-2.16.1的脚本就不传递LDFLAGS)，你必须手动编辑生成的 Makefile 文件，在其中寻找这些变量并修改它们的值，许多源码包在每个子文件夹中都有 Makefile 文件，真是一件很累人的事！ CC 与 CXX这是 C 与 C++ 编译器命令。默认值一般是 “gcc” 与 “g++”。这个变量本来与优化没有关系，但是有些人因为担心软件包不遵守那些约定俗成的规范，害怕自己苦心设置的 CFLAGS/CXXFLAGS/LDFLAGS 之类的变量被忽略了，而索性将原本应当放置在其它变量中的选项一股老儿塞到 CC 或 CXX 中，比如：CC=”gcc -march=k8 -O2 -s”。这是一种怪异的用法，本文不提倡这种做法，而是提倡按照变量本来的含义使用变量。 CPPFLAGS这是用于预处理阶段的选项。不过能够用于此变量的选项，看不出有哪个与优化相关。如果你实在想设一个，那就使用下面这两个吧： -DNDEBUG“NDEBUG”是一个标准的 ANSI 宏，表示不进行调试编译。-D_FILE_OFFSET_BITS=64大多数包使用这个来提供大文件(&gt;2G)支持。CFLAGS 与 CXXFLAGSCFLAGS 表示用于 C 编译器的选项，CXXFLAGS 表示用于 C++ 编译器的选项。这两个变量实际上涵盖了编译和汇编两个步骤。大多数程序和库在编译时默认的优化级别是”2”(使用”-O2”选项)并且带有调试符号来编译，也就是 CFLAGS=”-O2 -g”, CXXFLAGS=$CFLAGS 。事实上，”-O2”已经启用绝大多数安全的优化选项了。另一方面，由于大部分选项可以同时用于这两个变量，所以仅在最后讲述只能用于其中一个变量的选项。[提醒]下面所列选项皆为非默认选项，你只要按需添加即可。 先说说”-O3”在”-O2”基础上增加的几项： -finline-functions允许编译器选择某些简单的函数在其被调用处展开，比较安全的选项，特别是在CPU二级缓存较大时建议使用。-funswitch-loops将循环体中不改变值的变量移动到循环体之外。-fgcse-after-reload为了清除多余的溢出，在重载之后执行一个额外的载入消除步骤。另外： -fomit-frame-pointer对于不需要栈指针的函数就不在寄存器中保存指针，因此可以忽略存储和检索地址的代码，同时对许多函数提供一个额外的寄存器。所有”-O”级别都打开它，但仅在调试器可以不依靠栈指针运行时才有效。在AMD64平台上此选项默认打开，但是在x86平台上则默认关闭。建议显式的设置它。-falign-functions=N-falign-jumps=N-falign-loops=N-falign-labels=N这四个对齐选项在”-O2”中打开，其中的根据不同的平台N使用不同的默认值。如果你想指定不同于默认值的N，也可以单独指定。比如，对于L2-cache&gt;=1M的cpu而言，指定 -falign-functions=64 可能会获得更好的性能。建议在指定了 -march 的时候不明确指定这里的值。调试选项： -fprofile-arcs在使用这一选项编译程序并运行它以创建包含每个代码块的执行次数的文件后，程序可以再次使用 -fbranch-probabilities 编译，文件中的信息可以用来优化那些经常选取的分支。如果没有这些信息，gcc将猜测哪个分支将被经常运行以进行优化。这类优化信息将会存放在一个以源文件为名字的并以”.da”为后缀的文件中。全局选项： -pipe在编译过程的不同阶段之间使用管道而非临时文件进行通信，可以加快编译速度。建议使用。目录选项： –sysroot=dir将dir作为逻辑根目录。比如编译器通常会在 /usr/include 和 /usr/lib 中搜索头文件和库，使用这个选项后将在 dir/usr/include 和 dir/usr/lib 目录中搜索。如果使用这个选项的同时又使用了 -isysroot 选项，则此选项仅作用于库文件的搜索路径，而 -isysroot 选项将作用于头文件的搜索路径。这个选项与优化无关，但是在 CLFS 中有着神奇的作用。代码生成选项： -fno-bounds-check关闭所有对数组访问的边界检查。该选项将提高数组索引的性能，但当超出数组边界时，可能会造成不可接受的行为。-freg-struct-return如果struct和union足够小就通过寄存器返回，这将提高较小结构的效率。如果不够小，无法容纳在一个寄存器中，将使用内存返回。建议仅在完全使用GCC编译的系统上才使用。-fpic生成可用于共享库的位置独立代码。所有的内部寻址均通过全局偏移表完成。要确定一个地址，需要将代码自身的内存位置作为表中一项插入。该选项产生可以在共享库中存放并从中加载的目标模块。-fstack-check为防止程序栈溢出而进行必要的检测，仅在多线程环境中运行时才可能需要它。-fvisibility=hidden设置默认的ELF镜像中符号的可见性为隐藏。使用这个特性可以非常充分的提高连接和加载共享库的性能，生成更加优化的代码，提供近乎完美的API输出和防止符号碰撞。我们强烈建议你在编译任何共享库的时候使用该选项。参见 -fvisibility-inlines-hidden 选项。硬件体系结构相关选项[仅仅针对x86与x86_64]： -march=cpu-type为特定的cpu-type编译二进制代码(不能在更低级别的cpu上运行)。Intel可以用：pentium2, pentium3(=pentium3m), pentium4(=pentium4m), pentium-m, prescott, nocona, core2(GCC-4.3新增) 。AMD可以用：k6-2(=k6-3), athlon(=athlon-tbird), athlon-xp(=athlon-mp), k8(=opteron=athlon64=athlon-fx)-mfpmath=sseP3和athlon-xp级别及以上的cpu支持”sse”标量浮点指令。仅建议在P4和K8以上级别的处理器上使用该选项。-malign-double将double, long double, long long对齐于双字节边界上；有助于生成更高速的代码，但是程序的尺寸会变大，并且不能与未使用该选项编译的程序一起工作。-m128bit-long-double指定long double为128位，pentium以上的cpu更喜欢这种标准，并且符合x86-64的ABI标准，但是却不附合i386的ABI标准。-mregparm=N指定用于传递整数参数的寄存器数目(默认不使用寄存器)。0&lt;=N&lt;=3 ；注意：当N&gt;0时你必须使用同一参数重新构建所有的模块，包括所有的库。-msseregparm使用SSE寄存器传递float和double参数和返回值。注意：当你使用了这个选项以后，你必须使用同一参数重新构建所有的模块，包括所有的库。-mmmx-msse-msse2-msse3-m3dnow-mssse3(没写错!GCC-4.3新增)-msse4.1(GCC-4.3新增)-msse4.2(GCC-4.3新增)-msse4(含4.1和4.2,GCC-4.3新增)是否使用相应的扩展指令集以及内置函数，按照自己的cpu选择吧！-maccumulate-outgoing-args指定在函数引导段中计算输出参数所需最大空间，这在大部分现代cpu中是较快的方法；缺点是会明显增加二进制文件尺寸。-mthreads支持Mingw32的线程安全异常处理。对于依赖于线程安全异常处理的程序，必须启用这个选项。使用这个选项时会定义”-D_MT”，它将包含使用选项”-lmingwthrd”连接的一个特殊的线程辅助库，用于为每个线程清理异常处理数据。-minline-all-stringops默认时GCC只将确定目的地会被对齐在至少4字节边界的字符串操作内联进程序代码。该选项启用更多的内联并且增加二进制文件的体积，但是可以提升依赖于高速 memcpy, strlen, memset 操作的程序的性能。-minline-stringops-dynamicallyGCC-4.3新增。对未知尺寸字符串的小块操作使用内联代码，而对大块操作仍然调用库函数，这是比”-minline-all-stringops”更聪明的策略。决定策略的算法可以通过”-mstringop-strategy”控制。-momit-leaf-frame-pointer不为叶子函数在寄存器中保存栈指针，这样可以节省寄存器，但是将会使调试变的困难。注意：不要与 -fomit-frame-pointer 同时使用，因为会造成代码效率低下。-m64生成专门运行于64位环境的代码，不能运行于32位环境，仅用于x86_64[含EMT64]环境。-mcmodel=small[默认值]程序和它的符号必须位于2GB以下的地址空间。指针仍然是64位。程序可以静态连接也可以动态连接。仅用于x86_64[含EMT64]环境。-mcmodel=kernel内核运行于2GB地址空间之外。在编译linux内核时必须使用该选项！仅用于x86_64[含EMT64]环境。-mcmodel=medium程序必须位于2GB以下的地址空间，但是它的符号可以位于任何地址空间。程序可以静态连接也可以动态连接。注意：共享库不能使用这个选项编译！仅用于x86_64[含EMT64]环境。其它优化选项： -fforce-addr必须将地址复制到寄存器中才能对他们进行运算。由于所需地址通常在前面已经加载到寄存器中了，所以这个选项可以改进代码。-finline-limit=n对伪指令数超过n的函数，编译程序将不进行内联展开，默认为600。增大此值将增加编译时间和编译内存用量并且生成的二进制文件体积也会变大，此值不宜太大。-fmerge-all-constants试图将跨编译单元的所有常量值和数组合并在一个副本中。但是标准C/C++要求每个变量都必须有不同的存储位置，所以该选项可能会导致某些不兼容的行为。-fgcse-sm在全局公共子表达式消除之后运行存储移动，以试图将存储移出循环。gcc-3.4中曾属于”-O2”级别的选项。-fgcse-las在全局公共子表达式消除之后消除多余的在存储到同一存储区域之后的加载操作。gcc-3.4中曾属于”-O2”级别的选项。-floop-optimize已废除(GCC-4.1曾包含在”-O1”中)。-floop-optimize2使用改进版本的循环优化器代替原来”-floop-optimize”。该优化器将使用不同的选项(-funroll-loops, -fpeel-loops, -funswitch-loops, -ftree-loop-im)分别控制循环优化的不同方面。目前这个新版本的优化器尚在开发中，并且生成的代码质量并不比以前的版本高。已废除，仅存在于GCC-4.1之前的版本中。-funsafe-loop-optimizations假定循环不会溢出，并且循环的退出条件不是无穷。这将可以在一个比较广的范围内进行循环优化，即使优化器自己也不能断定这样做是否正确。-fsched-spec-load允许一些装载指令执行一些投机性的动作。-ftree-loop-linear在trees上进行线型循环转换。它能够改进缓冲性能并且允许进行更进一步的循环优化。-fivopts在trees上执行归纳变量优化。-ftree-vectorize在trees上执行循环向量化。-ftracer执行尾部复制以扩大超级块的尺寸，它简化了函数控制流，从而允许其它的优化措施做的更好。据说挺有效。-funroll-loops仅对循环次数能够在编译时或运行时确定的循环进行展开，生成的代码尺寸将变大，执行速度可能变快也可能变慢。-fprefetch-loop-arrays生成数组预读取指令，对于使用巨大数组的程序可以加快代码执行速度，适合数据库相关的大型软件等。具体效果如何取决于代码。-fweb建立经常使用的缓存器网络，提供更佳的缓存器使用率。gcc-3.4中曾属于”-O3”级别的选项。-ffast-math违反IEEE/ANSI标准以提高浮点数计算速度，是个危险的选项，仅在编译不需要严格遵守IEEE规范且浮点计算密集的程序考虑采用。-fsingle-precision-constant将浮点常量作为单精度常量对待，而不是隐式地将其转换为双精度。-fbranch-probabilities在使用 -fprofile-arcs 选项编译程序并执行它来创建包含每个代码块执行次数的文件之后，程序可以利用这一选项再次编译，文件中所产生的信息将被用来优化那些经常发生的分支代码。如果没有这些信息，gcc将猜测那一分支可能经常发生并进行优化。这类优化信息将会存放在一个以源文件为名字的并以”.da”为后缀的文件中。-frename-registers试图驱除代码中的假依赖关系，这个选项对具有大量寄存器的机器很有效。gcc-3.4中曾属于”-O3”级别的选项。-fbranch-target-load-optimize-fbranch-target-load-optimize2在执行序启动以及结尾之前执行分支目标缓存器加载最佳化。-fstack-protector在关键函数的堆栈中设置保护值。在返回地址和返回值之前，都将验证这个保护值。如果出现了缓冲区溢出，保护值不再匹配，程序就会退出。程序每次运行，保护值都是随机的，因此不会被远程猜出。-fstack-protector-all同上，但是在所有函数的堆栈中设置保护值。–param max-gcse-memory=xxM执行GCSE优化使用的最大内存量(xxM)，太小将使该优化无法进行，默认为50M。–param max-gcse-passes=n执行GCSE优化的最大迭代次数，默认为 1。传递给汇编器的选项： -Wa,optionsoptions是一个或多个由逗号分隔的可以传递给汇编器的选项列表。其中的每一个均可作为命令行选项传递给汇编器。-Wa,–strip-local-absolute从输出符号表中移除局部绝对符号。-Wa,-R合并数据段和正文段，因为不必在数据段和代码段之间转移，所以它可能会产生更短的地址移动。-Wa,–64设置字长为64bit，仅用于x86_64，并且仅对ELF格式的目标文件有效。此外，还需要使用”–enable-64-bit-bfd”选项编译的BFD支持。-Wa,-march=CPU按照特定的CPU进行优化：pentiumiii, pentium4, prescott, nocona, core, core2; athlon, sledgehammer, opteron, k8 。仅可用于 CFLAGS 的选项： -fhosted按宿主环境编译，其中需要有完整的标准库，入口必须是main()函数且具有int型的返回值。内核以外几乎所有的程序都是如此。该选项隐含设置了 -fbuiltin，且与 -fno-freestanding 等价。-ffreestanding按独立环境编译，该环境可以没有标准库，且对main()函数没有要求。最典型的例子就是操作系统内核。该选项隐含设置了 -fno-builtin，且与 -fno-hosted 等价。仅可用于 CXXFLAGS 的选项： -fno-enforce-eh-specsC++标准要求强制检查异常违例，但是该选项可以关闭违例检查，从而减小生成代码的体积。该选项类似于定义了”NDEBUG”宏。-fno-rtti如果没有使用’dynamic_cast’和’typeid’，可以使用这个选项禁止为包含虚方法的类生成运行时表示代码，从而节约空间。此选项对于异常处理无效(仍然按需生成rtti代码)。-ftemplate-depth-n将最大模版实例化深度设为’n’，符合标准的程序不能超过17，默认值为500。-fno-optional-diags禁止输出诊断消息，C++标准并不需要这些消息。-fno-threadsafe-staticsGCC自动在访问C++局部静态变量的代码上加锁，以保证线程安全。如果你不需要线程安全，可以使用这个选项。-fvisibility-inlines-hidden默认隐藏所有内联函数，从而减小导出符号表的大小，既能缩减文件的大小，还能提高运行性能，我们强烈建议你在编译任何共享库的时候使用该选项。参见 -fvisibility=hidden 选项。LDFLAGSLDFLAGS 是传递给连接器的选项。这是一个常被忽视的变量，事实上它对优化的影响也是很明显的。 -s删除可执行程序中的所有符号表和所有重定位信息。其结果与运行命令 strip 所达到的效果相同，这个选项是比较安全的。-Wl,optionsoptions是由一个或多个逗号分隔的传递给链接器的选项列表。其中的每一个选项均会作为命令行选项提供给链接器。-Wl,-On当n&gt;0时将会优化输出，但是会明显增加连接操作的时间，这个选项是比较安全的。-Wl,–exclude-libs=ALL不自动导出库中的符号，也就是默认将库中的符号隐藏。-Wl,-m仿真连接器，当前ld所有可用的仿真可以通过”ld -V”命令获取。默认值取决于ld的编译时配置。-Wl,–sort-common把全局公共符号按照大小排序后放到适当的输出节，以防止符号间因为排布限制而出现间隙。-Wl,-x删除所有的本地符号。-Wl,-X删除所有的临时本地符号。对于大多数目标平台，就是所有的名字以’L’开头的本地符号。-Wl,-zcomberloc组合多个重定位节并重新排布它们，以便让动态符号可以被缓存。-Wl,–enable-new-dtags在ELF中创建新式的”dynamic tags”，但在老式的ELF系统上无法识别。-Wl,–as-needed移除不必要的符号引用，仅在实际需要的时候才连接，可以生成更高效的代码。-Wl,–no-define-common限制对普通符号的地址分配。该选项允许那些从共享库中引用的普通符号只在主程序中被分配地址。这会消除在共享库中的无用的副本的空间，同时也防止了在有多个指定了搜索路径的动态模块在进行运行时符号解析时引起的混乱。-Wl,–hash-style=gnu使用gnu风格的符号散列表格式。它的动态链接性能比传统的sysv风格(默认)有较大提升，但是它生成的可执行程序和库与旧的Glibc以及动态链接器不兼容。最后说两个与优化无关的系统环境变量，因为会影响GCC编译程序的方式，下面两个是咱中国人比较关心的： LANG指定编译程序使用的字符集，可用于创建宽字符文件、串文字、注释；默认为英文。[目前只支持日文”C-JIS,C-SJIS,C-EUCJP”，不支持中文]LC_ALL指定多字节字符的字符分类，主要用于确定字符串的字符边界以及编译程序使用何种语言发出诊断消息；默认设置与LANG相同。中文相关的几项：”zh_CN.GB2312 , zh_CN.GB18030 , zh_CN.GBK , zh_CN.UTF-8 , zh_TW.BIG5”。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Glibc Binutils GCC 安装]]></title>
    <url>%2F2019%2F04%2F09%2FGlibc%2BBinutils%2BGCC%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[从别的地方抓过来一篇文章，非常详尽。做个备份。 Glibc 安装指南(2.6.1 → 2.9)安装信息的来源源码包内的下列文件：configure FAQ INSTALL NOTES Makeconfig README localedata/READMEhttp://www.gnu.org/software/libc/manual/html_node/System-Configuration.htmlhttp://www.gnu.org/software/libc/manual/html_node/Installation.htmlhttp://www.gnu.org/software/libc/manual/html_node/Name-Service-Switch.html 要点提示编译Glibc的时候应该尽可能使用最新的内核头文件，至少要使用 2.6.16 以上版本的内核，先前的版本有一些缺陷会导致”make check”时一些与pthreads测试相关的项目失败。使用高版本内核头文件编译的Glibc二进制文件完全可以运行在较低版本的内核上，并且当你升级内核后新内核的特性仍然可以得到充分发挥而无需重新编译Glibc。但是如果编译时使用的头文件的版本较低，那么运行在更高版本的内核上时，新内核的特性就不能得到充分发挥。更多细节可以查看[八卦故事]内核头文件传奇的跟帖部分。 推荐使用GCC-4.1以上的版本编译，老版本的GCC可能会生成有缺陷的代码。 不要在运行中的系统上安装 Glibc，否则将会导致系统崩溃，至少应当将新 Glibc 安装到其他的单独目录，以保证不覆盖当前正在使用的 Glibc 。 Glibc 不能在源码目录中编译，它必须在一个额外分开的目录中编译。这样在编译发生错误的时候，就可以删除整个编译目录重新开始。 源码树下的Makeconfig文件中有许多用于特定目的的变量，你可以在编译目录下创建一个configparms文件来改写这些变量。执行make命令的时候configparms文件中的内容将会按照Makefile规则进行解析。比如可以通过在其中设置 CFLAGS LDFLAGS 环境变量来优化编译，设置 CC BUILD_CC AR RANLIB 来指定交叉编译环境。 需要注意的是有些测试项目假定是以非 root 身份执行的，因此我们强烈建议你使用非 root 身份编译和测试 Glibc 。 配置选项下列选项皆为非默认值[特别说明的除外] –help–version–quiet–config-cache–no-create–srcdir=DIR–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–datarootdir=DIR–datadir=DIR–infodir=DIR–localedir=DIR–mandir=DIR–docdir=DIR–htmldir=DIR–dvidir=DIR–pdfdir=DIR–psdir=DIR–build=BUILD–host=HOST这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。需要注意的是：没有–target=TARGET选项。 –prefix=PREFIX安装目录，默认为 /usr/localLinux文件系统标准要求基本库必须位于 /lib 目录并且必须与根目录在同一个分区上，但是 /usr 可以在其他分区甚至是其他磁盘上。因此，如果在Linux平台上指定 –prefix=/usr ，那么基本库部分将自动安装到 /lib 目录下，而非基本库部分则会自动安装到 /usr/lib 目录中，同时将使用 /etc 作为配置目录，也就是等价于”slibdir=/lib sysconfdir=/etc”。但是如果保持默认值或指定其他目录，那么所有组件都间被安装到PREFIX目录下。 –disable-sanity-checks真正禁用线程(仅在特殊环境下使用该选项)。 –enable-check-abi在”make check”时执行”make check-abi”。[提示]在我的机器上始终导致check-abi-libm测试失败。 –disable-shared不编译共享库(即使平台支持)。在支持 ELF 并且使用 GNU 连接器的系统上默认为enable 。[提示] –disable-static 选项实际上是不存在的，静态库总是被无条件的编译和安装。 –enable-profile启用 profiling 信息相关的库文件编译。主要用于调试目的。 –enable-omitfp编译时忽略帧指示器(使用 -fomit-frame-pointer 编译)，并采取一些其他优化措施。忽略帧指示器可以提高运行效率，但是调试将变得不可用，并且可能生成含有 bug 的代码。使用这个选项还将导致额外编译带有调试信息的非优化版本的静态库(库名称以”_g”结尾)。 –enable-bounded启用运行时边界检查(比如数组越界)，这样会降低运行效率，但能防止某些溢出漏洞。 –disable-versioning不在共享库对象中包含符号的版本信息。这样可以减小库的体积，但是将不兼容依赖于老版本 C 库的二进制程序。[提示]在我的机器上使用此选项总是导致编译失败。 –enable-oldest-abi=ABI启用老版本的应用程序二进制接口支持。ABI是Glibc的版本号，只有明确指定版本号时此选项才有效。 –enable-stackguard-randomization在程序启动时使用一个随机数初始化 __stack_chk_guard ，主要用来抵抗恶意攻击。 –enable-add-ons[=DIRS…]为了减小软件包的复杂性，一些可选的libc特性被以单独的软件包发布，比如’linuxthreads’(现在已经被废弃了)，他们被称为’add-ons’。要使用这些额外的包，可以将他们解压到Glibc的源码树根目录下，然后使用此选项将DIR1,DIR2,…中的附加软件包包含进来。其中的”DIR”是附加软件包的目录名。默认值”yes”表示编译所有源码树根目录下找到的附加软件包。 –disable-hidden-plt默认情况下隐藏仅供内部调用的函数，以避免这些函数被加入到过程链接表(PLT,Procedure Linkage Table)中，这样可以减小 PLT 的体积并将仅供内部使用的函数隐藏起来。而使用该选项将把这些函数暴露给外部用户。 –enable-bind-now禁用”lazy binding”，也就是动态连接器在载入 DSO 时就解析所有符号(不管应用程序是否用得到)，默认行为是”lazy binding”，也就是仅在应用程序首次使用到的时候才对符号进行解析。因为在大多数情况下，应用程序并不需要使用动态库中的所有符号，所以默认的 “lazy binding”可以提高应用程序的加载性能并节约内存用量。然而，在两种情况下，”lazy binding”是不利的：①因为第一次调用DSO中的函数时，动态连接器要先拦截该调用来解析符号，所以初次引用DSO中的函数所花的时间比再次调用要花的时间长，但是某些应用程序不能容忍这种不可预知性。②如果一个错误发生并且动态连接器不能解析该符号，动态连接器将终止整个程序。在”lazy binding”方式下，这种情况可能发生在程序运行过程中的某个时候。某些应用程序也是不能容忍这种不可预知性的。通过关掉”lazy binding”方式，在应用程序接受控制权之前，让动态连接器在处理进程初始化期间就发现这些错误，而不要到运行时才出乱子。 –enable-static-nss编译静态版本的NSS(Name Service Switch)库。仅在/etc/nsswitch.conf中只使用dns和files的情况下，NSS才能编译成静态库，并且你还需要在静态编译应用程序的时候明确的连接所有与NSS库相关的库才行[比如：gcc -static test.c -o test -Wl,-lc,-lnss_files,-lnss_dns,-lresolv]。不推荐使用此选项，因为连接到静态NSS库的程序不能动态配置以使用不同的名字数据库。 –disable-force-install不强制安装当前新编译的版本(即使已存在的文件版本更新)。 –enable-kernel=VERSIONVERSION 的格式是 X.Y.Z，表示编译出来的 Glibc 支持的最低内核版本。VERSION 的值越高(不能超过内核头文件的版本)，加入的兼容性代码就越少，库的运行速度就越快。 –enable-all-warnings在编译时显示所有编译器警告，也就是使用 -Wall 选项编译。 –with-gd–with-gd-include –with-gd-lib指定libgd的安装目录(DIR/include和DIR/lib)。后两个选项分别指定包含文件和库目录。 –without-fp仅在硬件没有浮点运算单元并且操作系统没有模拟的情况下使用。x86 与 x86_64 的 CPU 都有专门的浮点运算单元。而且 Linux 有 FPU 模拟。简单的说，不要 without 这个选项！因为它会导致许多问题！ –with-binutils=DIR明确指定编译时使用的Binutils(as,ld)所在目录。 –with-elf指定使用 ELF 对象格式，默认不使用。建议在支持 ELF 的 Linux 平台上明确指定此选项。 –with-selinux–without-selinux启用/禁用 SELinux 支持，默认值自动检测。 –with-xcoff使用XCOFF对象格式(主要用于windows)。 –without-cvs不访问CVS服务器。推荐使用该选项，特别对于从CVS下载的的版本。 –with-headers=DIR指定内核头文件的所在目录，在Linux平台上默认是’/usr/include’。 –without-tls禁止编译支持线程本地存储(TLS)的库。使用这个选项将导致兼容性问题。 –without-__thread即使平台支持也不使用TSL特性。建议不要使用该选项。 –with-cpu=CPU在 gcc 命令行中加入”-mcpu=CPU”。鉴于”-mcpu”已经被反对使用，所以建议不要设置该选项，或者设为 –without-cpu 。 编译与测试使用 make 命令编译，使用 make check 测试。如果 make check 没有完全成功，就千万不要使用这个编译结果。需要注意的是有些测试项目假定是以非 root 身份执行的，因此我们强烈建议你使用非 root 身份编译和测试。 测试中需要使用一些已经存在的文件(包括随后的安装过程)，比如 /etc/passwd, /etc/nsswitch.conf 之类。请确保这些文件中包含正确的内容。 安装与配置使用 make install 命令安装。比如：make install LC_ALL=C 如果你打算将此 Glibc 安装为主 C 库，那么我们强烈建议你关闭系统，重新引导到单用户模式下安装。这样可以将可能的损害减小到最低。 安装后需要配置 GCC 以使其使用新安装的 C 库。最简单的办法是使用恰当 GCC 的编译选项(比如 -Wl,–dynamic-linker=/lib/ld-linux.so.2 )重新编译 GCC 。然后还需要修改 specs 文件(通常位于 /usr/lib/gcc-lib/TARGET/VERSION/specs )，这个工作有点像巫术，调整实例请参考 LFS 中的两次工具链调整。 可以在 make install 命令行使用’install_root’变量指定安装实际的安装目录(不同于 –prefix 指定的值)。这个在 chroot 环境下或者制作二进制包的时候通常很有用。’install_root’必须使用绝对路径。 被’grantpt’函数调用的辅助程序’/usr/libexec/pt_chown’以 setuid ‘root’ 安装。这个可能成为安全隐患。如果你的 Linux 内核支持’devptsfs’或’devfs’文件系统提供的 pty slave ，那么就不需要使用 pt_chown 程序。 安装完毕之后你还需要配置时区和 locale 。使用 localedef 来配置locale 。比如使用’localedef -i de_DE -f ISO-8859-1 de_DE’将 locale 设置为’de_DE.ISO-8859-1’。可以在编译目录中使用’make localedata/install-locales’命令配置所有可用的 locale ，但是一般不需要这么做。 时区使用’TZ’环境变量设置。tzselect 脚本可以帮助你选择正确的值。设置系统全局范围内的时区可以将 /etc/localtime 文件连接到 /usr/share/zoneinfo 目录下的正确文件上。比如对于中国人可以’ln -s /usr/share/zoneinfo/PRC /etc/localtime’。 Binutils 安装指南(2.18 → 2.19.1)安装信息的来源源码包内的下列文件：各级目录下的configure脚本 README {bfd,binutils,gas,gold,libiberty}/README要点提示如果想与GCC联合编译，那么可以将binutils包的内容解压到GCC的源码目录中(tar -xvf binutils-2.19.1.tar.bz2 –strip-components=1 -C gcc-4.3.3)，然后按照正常编译GCC的方法编译即可。这样做的好处之一是可以完整的将 GCC 与 Binutils 进行一次bootstrap。 推荐用一个新建的目录来编译，而不是在源码目录中。编译完毕后可以使用”make check”运行测试套件。这个测试套件依赖于DejaGnu软件包，而DejaGnu又依赖于expect，expect依赖于tcl。 如果只想编译 ld 可以使用”make all-ld”，如果只想编译 as 可以使用”make all-gas”。类似的还有 clean-ld clean-as distclean-ld distclean-as check-ld check-as 等。 配置选项下列选项皆为非默认值[特别说明的除外] –help–version–quiet–config-cache–no-create–srcdir=DIR–prefix=PREFIX–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–datadir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–infodir=DIR–mandir=DIR–program-prefix=PREFIX–program-suffix=SUFFIX–program-transform-name=PROGRAM–build=BUILD–host=HOST–target=TARGET这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。 –disable-nls禁用本地语言支持(它允许按照非英语的本地语言显示警告和错误消息)。编译时出现”undefined reference to ‘libintl_gettext’”错误则必须禁用。 –disable-rpath不在二进制文件中硬编码库文件的路径。 –disable-multilib禁止编译适用于多重目标体系的库。例如，在x86_64平台上，默认既可以生成64位代码，也可以生成32位代码，若使用此选项，那么将只能生成64位代码。 –enable-cgen-maint=CGENDIR编译cgen相关的文件[主要用于GDB调试]。 –enable-shared[=PKG[,…]]–disable-shared–enable-static[=PKG[,…]]–disable-static允许/禁止编译共享或静态版本的库和可执行程序，全部可识别的PKG如下：binutils,gas,gprof,ld,bfd,opcodes,libiberty(仅支持作为静态库)。static在所有目录下的默认值都是”yes”；而shared在不同子目录下默认值不同，有些为”yes”(binutils,gas,gprof,ld)有些为”no”(bfd,opcodes,libiberty)。 –enable-install-libbfd–disable-install-libbfd允许或禁止安装 libbfd 以及相关的头文件( libbfd 是二进制文件描述库,用于读写目标文件”.o”,被GDB/ld/as等程序使用)。本地编译或指定–enable-shared的情况下默认值为”yes”，否则默认值为”no”。 –enable-64-bit-bfd让BFD支持64位目标，如果希望在32位平台上编译64程序就需要使用这个选项。如果指定的目标(TARGET)是64位则此选项默认打开，否则默认关闭(即使 –enable-targets=all 也是如此)。 –enable-elf-stt-common允许BFD生成STT_COMMON类型的ELF符号。[2.19版本新增选项] –enable-checking–disable-checking允许 as 执行运行时检查。正式发布版本默认禁用，快照版本默认启用。 –disable-werror禁止将所有编译器警告当作错误看待(因为当编译器为GCC时默认使用-Werror)。 –enable-got=target|single|negative|multigot指定GOT的处理模式。默认值是”target”。[2.19版本新增选项] –enable-gold使用gold代替GNU ld。gold是Google开发的连接器，2008年捐赠给FSF，目的是取代现有的GNU ld，但目前两者还不能完兼容。[2.19版本新增选项] –enable-plugins启用gold连接器的插件支持。[2.19版本新增选项] –enable-threads编译多线程版本的gold连接器。[2.19版本新增选项] –with-lib-path=dir1:dir2…指定编译出来的binutils工具(比如：ld)将来默认的库搜索路径，在绝大多数时候其默认值是”/lib:/usr/lib”。这个工作也可以通过设置 Makefile 中的 LIB_PATH 变量值完成。 –with-libiconv-prefix[=DIR]–without-libiconv-prefix在 DIR/include 目录中搜索 libiconv 头文件，在 DIR/lib 目录中搜索 libiconv 库文件。或者根本不使用 libiconv 库。 –with-libintl-prefix[=DIR]–without-libintl-prefix在 DIR/include 目录中搜索 libintl 头文件，在 DIR/lib 目录中搜索 libintl 库文件。或者根本不使用 libintl 库。 –with-mmap使用mmap访问BFD输入文件。某些平台上速度较快，某些平台上速度较慢，某些平台上无法正常工作。 –with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。以下选项仅在与GCC联合编译时才有意义，其含义与GCC相应选项的含义完全一样，默认值也相同。 –enable-bootstrap–disable-bootstrap–enable-languages=lang1,lang2,…–enable-stage1-checking–enable-stage1-languages–disable-libada–disable-libgcj–disable-libgomp–disable-libmudflap–disable-libssp–enable-objc-gc–disable-cloog-version-check–disable-ppl-version-check–with-gnu-as–with-gnu-ld–with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR–with-mpfr=MPFRDIR–with-mpfr-include=MPFRINCDIR–with-mpfr-lib=MPFRLIBDIR–with-cloog=CLOOGDIR–with-cloog_include=CLOOGINCDIR–with-cloog_lib=CLOOGLIBDIR–with-ppl=PPLDIR–with-ppl_include=PPLINCDIR–with-ppl_lib=PPLLIBDIR–with-stabs以下选项仅用于交叉编译环境 –enable-serial-[{host,target,build}-]configure强制为 host, target, build 顺序配置子包，如果使用”all”则表示所有子包。 –with-sysroot=dir将 dir 看作目标系统的根目录。目标系统的头文件、库文件、运行时对象都将被限定在其中。 –with-target-subdir=SUBDIR为 target 在 SUBDIR 子目录中进行配置。 –with-newlib将’newlib’(另一种标准C库，主要用于嵌入式环境)指定为目标系统的C库进行使用。 –with-build-sysroot=sysroot在编译时将’sysroot’当作指定 build 平台的根目录看待。仅在已经使用了–with-sysroot选项的时候，该选项才有意义。 –with-build-subdir=SUBDIR为 build 在 SUBDIR 子目录中进行配置。 –with-build-libsubdir=DIR指定 build 平台的库文件目录。默认值是SUBDIR。 –with-build-time-tools=path在给定的path中寻找用于编译Binutils自身的目标工具。该目录中必须包含 ar, as, ld, nm, ranlib, strip 程序，有时还需要包含 objdump 程序。例如，当编译Binutils的系统的文件布局和将来部署Binutils的目标系统不一致时就需要使用此选项。 –with-cross-host=HOST这个选项已经被反对使用，应该使用–with-sysroot来代替其功能。以下选项意义不大，一般不用考虑它们 –disable-dependency-tracking禁止对Makefile规则的依赖性追踪。–disable-largefile禁止支持大文件。[2.19版本新增选项]–disable-libtool-lock禁止 libtool 锁定以加快编译速度(可能会导致并行编译的失败)–disable-build-warnings禁止显示编译时的编译器警告，也就是使用”-w”编译器选项进行编译。–disable-fast-install禁止为快速安装而进行优化。–enable-maintainer-mode启用无用的 make 规则和依赖性(它们有时会导致混淆)–enable-commonbfdlib–disable-commonbfdlib允许或禁止编译共享版本的 BFD/opcodes/libiberty 库。分析configure脚本后发现这个选项事实上没有任何实际效果。–enable-install-libiberty安装 libiberty 的头文件(libiberty.h)，许多程序都会用到这个库中的函数(getopt,strerror,strtol,strtoul)。这个选项经过实验，没有实际效果(相当于disable)。–enable-secureplt使得binutils默认创建只读的 plt 项。相当于将来调用 gcc 时默认使用 -msecure-plt 选项。仅对 powerpc-linux 平台有意义。–enable-targets=TARGET,TARGET,TARGET…使BFD在默认格式之外再支持多种其它平台的二进制文件格式，”all”表示所有已知平台。在32位系统上，即使使用”all”也只能支持所有32位目标，除非同时使用 –enable-64-bit-bfd 选项。由于目前 gas 并不能使用内置的默认平台之外的其它目标，因此这个选项没什么实际意义。此选项在所有目录下都没有默认值。但对于2.19版本，此选项在gold子目录下的默认值是”all”。–with-bugurl=URL–without-bugurl指定发送bug报告的URL/禁止发送bug报告。默认值是”http://www.sourceware.org/bugzilla/&quot;。–with-datarootdir=DATADIR将 DATADIR 用作数据根目录，默认值是[PREFIX/share]–with-docdir=DOCDIR–with-htmldir=HTMLDIR–with-pdfdir=PDFDIR指定各种文档的安装目录。DOCDIR默认值的默认值是DATADIR，HTMLDIR和PDFDIR的默认值是DOCDIR。–with-included-gettext使用软件包中自带的 GNU gettext 库。如果你已经使用了Glibc-2.0以上的版本，或者系统中已经安装了GNU gettext软件包，那么就没有必要使用这个选项。默认不使用。–with-pkgversion=PKG在 bfd 库中使用”PKG”代替默认的”GNU Binutils”作为版本字符串。比如你可以在其中嵌入编译时间或第多少次编译之类的信息。–with-separate-debug-dir=DIR在DIR中查找额外的全局debug信息，默认值：${libdir}/debug–with-debug-prefix-map=’A=B C=D …’在调试信息中建立 A-B,C-D, … 这样的映射关系。默认为空。[2.19版本新增选项]环境变量tooldir可执行文件的安装目录。其默认值是”$(exec_prefix)/$(target_alias)”。 GCC 安装指南(4.3 → 4.4)安装信息的来源源码包内的下列文件：各级目录下的configure脚本 ABOUT-NLS gcc/testsuite/README INSTALL/ libstdc++-v3/docs/html/manual/bk01pt01ch02.htmlhttp://gcc.gnu.org/faq.htmlhttp://gcc.gnu.org/install/http://gcc.gnu.org/onlinedocs/libstdc++/faq.htmlhttp://gcc.gnu.org/onlinedocs/libstdc++/manual/bk01pt01ch02.html 要点提示从GCC-4.3起，安装GCC将依赖于GMP-4.1以上版本和MPFR-2.3.2以上版本。如果将这两个软件包分别解压到GCC源码树的根目录下，并分别命名为”gmp”和”mpfr”，那么GCC的编译程序将自动将两者与GCC一起编译。建议尽可能使用最新的GMP和MPFR版本。 推荐用一个新建的目录来编译GCC，而不是在源码目录中，这一点玩过LFS的兄弟都很熟悉了。另外，如果先前在编译中出现了错误，推荐使用 make distclean 命令进行清理，然后重新运行 configure 脚本进行配置，再在另外一个空目录中进行编译。 如果想要安装C++编译器，那么 libstdc++ 将要求系统的C库必须至少带有 de_DE locale 支持，如果使用了 –enable-clocale=gnu 配置选项(很可能就是默认值)，那么还需要下列 locale ： locale 字符集de_DE ISO-8859-1de_DE@euro ISO-8859-15en_HK ISO-8859-1en_PH ISO-8859-1en_US ISO-8859-1en_US.ISO-8859-1 ISO-8859-1en_US.ISO-8859-15 ISO-8859-15en_US.UTF-8 UTF-8es_ES ISO-8859-1es_MX ISO-8859-1fr_FR ISO-8859-1fr_FR@euro ISO-8859-15is_IS UTF-8it_IT ISO-8859-1ja_JP.eucjp EUC-JPse_NO.UTF-8 UTF-8ta_IN UTF-8zh_TW BIG5 不过，这些locale并非严格必须，即使缺少上述 locale ，C++编译器也不会失效，只是libstdc++就不能提供”named locale”特性了，并且测试程序也会跳过与此相关的测试。 配置选项[注意]这里仅包含适用于 C/C++ 语言编译器、十进制数字扩展库(libdecnumber)、在多处理机上编写并行程序的应用编程接口GOMP库(libgomp)、大杂烩的libiberty库、执行运行时边界检查的库(libmudflap)、保护堆栈溢出的库(libssp)、标准C++库(libstdc++) 相关的选项。也就是相当于 gcc-core 与 gcc-g++ 两个子包的选项。并不包括仅仅适用于其他语言的选项。 每一个 –enable 选项都有一个对应的 –disable 选项，同样，每一个 –with 选项也都用一个对应的 –without 选项。每一对选项中必有一个是默认值(依赖平台的不同而不同)。下面所列选项若未特别说明皆为非默认值。 –help–version–quiet–config-cache–no-create–srcdir=DIR–prefix=PREFIX–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–datadir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–infodir=DIR–mandir=DIR–program-prefix=PREFIX–program-suffix=SUFFIX–program-transform-name=PROGRAM–build=BUILD–host=HOST–target=TARGET这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。 –disable-nls禁用本地语言支持(它允许按照非英语的本地语言显示警告和错误消息)。编译时出现”undefined reference to ‘libintl_gettext’”错误则必须禁用。 –disable-rpath不在二进制文件中硬编码库文件的路径。 –enable-bootstrap–disable-bootstrap“bootstrap”的意思是用第一次编译生成的程序来第二次编译自己，然后又用第二次编译生成的程序来第三次编译自己，最后比较第二次和第三次编译的结果，以确保编译器能毫无差错的编译自身，这通常表明编译是正确的。非交叉编译的情况下enable是默认值；交叉编译的情况下，disable是默认值。提示：stage2出来的结果是”最终结果”。 –enable-checking[=LIST]该选项会在编译器内部生成一致性检查的代码，它并不改变编译器生成的二进制结果。这样导致编译时间增加，并且仅在使用GCC作为编译器的时候才有效，但是对输出结果没有影响。在”gcc”子目录下，对从CVS下载的版本默认值是”yes”(=assert,misc,tree,gc,rtlflag,runtime)，对于正式发布的版本则是”release”(=assert,runtime)，在”libgcc”子目录下，默认值始终是”no”。可以从 “assert,df,fold,gc,gcac,misc,rtlflag,rtl,runtime,tree,valgrind”中选择你想要检查的项目(逗号隔开的列表，”all”表示全部)，其中rtl,gcac,valgrind非常耗时。使用 –disable-checking 完全禁止这种检查会增加未能检测内部错误的风险，所以不建议这样做。 –enable-languages=lang1,lang2,…只安装指定语言的编译器及其运行时库，可以使用的语言是：ada, c, c++, fortran, java, objc, obj-c++ ，若不指定则安装所有默认可用的语言(ada和obj-c++为非默认语言)。 –disable-multilib禁止编译适用于多重目标体系的库。例如，在x86_64平台上，编译器默认既可以生成64位代码，也可以生成32位代码，若使用此选项，那么将只能生成64位代码。 –enable-shared[=PKG[,…]]–disable-shared–enable-static[=PKG[,…]]–disable-static允许/禁止编译共享或静态版本的库，全部可识别的库如下：libgcc,libstdc++,libffi,zlib,boehm-gc,ada,libada,libjava,libobjc,libiberty(仅支持作为静态库)。static在所有目录下的默认值都是”yes”；shared除了在libiberty目录下的默认值是”no”外，在其它目录下的默认值也都是”yes”。 –enable-decimal-float[=bid|dpd]–disable-decimal-float启用或禁用 libdecnumber 库符合 IEEE 754-2008 标准的 C 语言十进制浮点扩展，还可以进一步选择浮点格式(bid是i386与x86_64的默认值；dpd是PowerPC的默认值)。在 PowerPC/i386/x86_64 GNU/Linux 系统默认启用，在其他系统上默认禁用。 –disable-libgomp不编译在多处理机上编写并行程序的应用编程接口GOMP库(libgomp)。 –disable-libmudflap不编译执行运行时边界检查的库(libmudflap)。 –disable-libssp不编译保护缓冲区溢出的运行时库。 –disable-symvers禁用共享库对象中符号包含的版本信息。使用这个选项将导致 ABI 发生改变。禁用版本信息可以减小库的体积，但是将不兼容依赖于老版本库的二进制程序。它还会导致 libstdc++ 的 abi_check 测试失败，但你可以忽略这个失败。 –enable-threads=posix|aix|dce|gnat|mach|rtems|solaris|vxworks|win32|nks–disable-threads启用或禁用线程支持，若启用，则必须同时明确指定线程模型(不同平台支持的线程库并不相同，Linux现在一般使用posix)。这将对Objective-C编译器、运行时库，以及C++/Java等面向对象语言的异常处理产生影响。 –enable-version-specific-runtime-libs将运行时库安装在编译器特定的子目录中(${libdir}/gcc-lib/${target_alias}/${gcc_version})，而不是默认的${libdir}目录中。另外，’libstdc++’的头文件将被安装在 ${libdir}/gcc-lib/${target_alias}/${gcc_version}/include/g++ 目录中(除非同时又指定了 –with-gxx-include-dir)。如果你打算同时安装几个不同版本的 GCC ，这个选项就很有用处了。当前，libgfortran,libjava,libmudflap,libstdc++,libobjc都支持该选项。 –enable-werror–disable-werror是否将所有编译器警告当作错误看待(使用-Werror来编译)。对于开发中的版本和快照默认为”yes”，对于正式发布的版本则默认为”no”。 –with-as=pathname–with-ld=pathname指定将来GCC使用的汇编器/连接器的位置，必须使用绝对路径。如果configure的默认查找过程找不到汇编器/连接器，就会需要该选项。或者系统中有多个汇编器/连接器，也需要它来指定使用哪一个。如果使用GNU的汇编器，那么你必须同时使用GNU连接器。 –with-datarootdir=DATADIR将 DATADIR 用作数据根目录，默认值是[PREFIX/share] –with-docdir=DOCDIR–with-htmldir=HTMLDIR–with-pdfdir=PDFDIR指定各种文档的安装目录。DOCDIR默认值的默认值是DATADIR，HTMLDIR和PDFDIR的默认值是DOCDIR。 –with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR指定 GMP 库的安装目录/头文件目录/库目录。指定GMPDIR相当于同时指定了：GMPINCDIR=GMPDIR/include,GMPLIBDIR=GMPDIR/lib 。 –with-mpfr=MPFRDIR–with-mpfr-include=MPFRINCDIR–with-mpfr-lib=MPFRLIBDIR指定 MPFR 库的安装目录/头文件目录/库目录。指定MPFRDIR相当于同时指定了：MPFRINCDIR=MPFRDIR/include,MPFRLIBDIR=MPFRDIR/lib 。 –with-cloog=CLOOGDIR–with-cloog_include=CLOOGINCDIR–with-cloog_lib=CLOOGLIBDIR指定CLooG(Chunky Loop Generator)的安装目录/头文件目录/库目录。指定CLOOGDIR相当于同时指定了：CLOOGINCDIR=CLOOGDIR/include,CLOOGLIBDIR=CLOOGDIR/lib 。[GCC-4.4新增选项] –with-ppl=PPLDIR–with-ppl_include=PPLINCDIR–with-ppl_lib=PPLLIBDIR指定PPL(Parma Polyhedra Library)的安装目录/头文件目录/库目录。指定PPLDIR相当于同时指定了：PPLINCDIR=PPLDIR/include,PPLLIBDIR=PPLDIR/lib 。[GCC-4.4新增选项] –with-gxx-include-dir=DIRG++头文件的安装目录，默认为”prefix/include/c++/版本”。 –with-libiconv-prefix[=DIR]–without-libiconv-prefix在 DIR/include 目录中搜索 libiconv 头文件，在 DIR/lib 目录中搜索 libiconv 库文件。或者根本不使用 libiconv 库。 –with-libintl-prefix[=DIR]–without-libintl-prefix在 DIR/include 目录中搜索 libintl 头文件，在 DIR/lib 目录中搜索 libintl 库文件。或者根本不使用 libintl 库。 –with-local-prefix=DIR指定本地包含文件的安装目录，不管如何设置–prefix，其默认值都为 /usr/local 。只有在系统已经建立了某些特定的目录规则，而不再是在 /usr/local/include 中查找本地安装的头文件的时候，该选项才使必须的。不能指定为 /usr ，也不能指定为安装GCC自身头文件的目录(默认为$libdir/gcc/$target/$version/include)，因为安装的头文件会和系统的头文件混合，从而造成冲突，导致不能编译某些程序。 –with-long-double-128–without-long-double-128指定long double类型为 128-bit 或 64-bit(等于double) 。基于 Glibc 2.4 或以上版本编译时默认为 128-bit ，其他情况默认为 64-bit ；但是可以使用这个选项强制指定。 –with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。 –with-slibdir=DIR共享库(libgcc)的安装目录，默认等于 –libdir 的值。 –with-system-libunwind使用系统中已经安装的libunwind库，默认自动检测。 –with-system-zlib使用系统中的libz库，默认使用GCC自带的库。 以下选项仅适用于 C++ 语言： –enable-cxa_atexit用 cxa_atexit() 代替 atexit() 来登记 C++ 对象的本地静态和全局析构函数以符合C++标准对析构函数的处理规定。启用它相当于在将来调用 gcc 时默认使用 -fuse-cxa-exit 选项。该选项仅在使用Glibc的时候才有意义。 –disable-c99禁止支持 C99 标准。该选项将导致 ABI 接口发生改变。 –enable-cheaders=c|c_std|c_global为 g++ 创建C语言兼容的头文件，默认为”c_global”。 –enable-clocale[=gnu|ieee_1003.1-2001|generic]指定目标系统的 locale 模块，默认值为自动检测。建议明确设为”gnu”，否则可能会编译出 ABI 不兼容的 C++ 库。 –enable-clock-gettime[=yes|no|rt]指明如何获取C++0x草案里面time.clock中clock_gettime()函数：”yes”表示在libc和libposix4库中检查(而libposix4在需要的时候还可能会链接到libstdc++)。”rt”表示还额外在librt库中查找，这一般并不是一个很好的选择，因为librt经常还会连接到libpthread上，从而使得单线程的程序产生不必要的锁定开销。默认值”no”则完全跳过这个检查。[GCC-4.4新增选项] –enable-concept-checks打开额外的实例化库模板编译时检查(以特定的模板形式)，这可以帮助用户在他们的程序运行之前就发现这些程序在何处违反了STL规则。 –enable-cstdio=PACKAGE使用目标平台特定的 I/O 包，PACKAGE的默认值是”stdio”，也是唯一可用的值。使用这个选项将导致 ABI 接口发生改变。 –enable-cxx-flags=FLAGS编译 libstdc++ 库文件时传递给编译器的编译标志，是一个引号界定的字符串。默认为空，表示使用环境变量 CXXFLAGS 的值。 –enable-fully-dynamic-string该选项启用了一个特殊版本的 basic_string 来禁止在预处理的静态存储区域中放置空字符串的优化手段。参见 PR libstdc++/16612 获取更多细节。 –disable-hosted-libstdcxx默认编译特定于主机环境的C++库。使用该选项将仅编译独立于主机环境的C++运行时库(前者的子集)。 –enable-libstdcxx-allocator[=new|malloc|mt|bitmap|pool]指定目标平台特定的底层 std::allocator ，默认自动检测。使用这个选项将导致 ABI 接口发生改变。 –enable-libstdcxx-debug额外编译调试版本的 libstdc++ 库文件，并默认安装在 ${libdir}/debug 目录中。 –enable-libstdcxx-debug-flags=FLAGS编译调试版本的 libstdc++ 库文件时使用的编译器标志，默认为”-g3 -O0” –disable-libstdcxx-pch禁止创建预编译的 libstdc++ 头文件(stdc++.h.gch)，这个文件包含了所有标准 C++ 的头文件。该选项的默认值等于hosted-libstdcxx的值。 –disable-long-long禁止使用模板支持’long long’类型。’long long’是 C99 新引进的类型，也是 GNU 对 C++98 标准的一个扩展。该选项将导致 ABI 接口发生改变。 –enable-sjlj-exceptions强制使用旧式的 setjmp/longjmp 异常处理模型，使用这个选项将导致 ABI 接口发生改变。默认使用可以大幅降低二进制文件尺寸和内存占用的新式的 libunwind 库进行异常处理。建议不要使用此选项。 –disable-visibility禁止 -fvisibility 编译器选项的使用(使其失效)。 –disable-wchar_t禁止使用模板支持多字节字符类型’wchar_t’。该选项将导致 ABI 接口发生改变。 以下选项仅用于交叉编译： –enable-serial-[{host,target,build}-]configure强制为 host, target, build 顺序配置子包，如果使用”all”则表示所有子包。 –with-sysroot=DIR将DIR看作目标系统的根目录。目标系统的头文件、库文件、运行时对象都将被限定在其中。其默认值是 ${gcc_tooldir}/sys-root 。 –with-target-subdir=SUBDIR为 target 在 SUBDIR 子目录中进行配置。 –with-newlib将’newlib’指定为目标系统的C库进行使用。这将导致 libgcc.a 中的 __eprintf 被忽略，因为它被假定为由’newlib’提供。 –with-build-subdir=SUBDIR为 build 在 SUBDIR 子目录中进行配置。 –with-build-libsubdir=DIR指定 build 平台的库文件目录。默认值是SUBDIR。 –with-build-sysroot=sysroot在编译时将’sysroot’当作指定 build 平台的根目录看待。仅在已经使用了–with-sysroot选项的时候，该选项才有意义。 –with-build-time-tools=path在给定的path中寻找用于编译GCC自身的目标工具。该目录中必须包含 ar, as, ld, nm, ranlib, strip 程序，有时还需要包含 objdump 程序。例如，当编译GCC的系统的文件布局和将来部署GCC的目标系统不一致时就需要使用此选项。 –with-cross-host=HOST这个选项已经被反对使用，应该使用–with-sysroot来代替其功能。 以下选项意义不大，一般不用考虑它们：–enable-cld启用它相当于将来对32位x86平台调用GCC时默认使用-mcld命令行选项，主要用于兼容一些老旧的平台。–disable-cloog-version-check禁止检测CLooG(Chunky Loop Generator)的版本是否满足要求。[GCC-4.4新增选项]–enable-coverage[=opt|noopt]在编译器每次编译时收集自身的 coverage 信息。这个仅用于内部测试的目的，并且仅在使用GCC编译的时候才有效。参数控制着是否在编译编译器时使用优化，在需要进行 coverage 分析的时候使用”noopt”(默认)，在需要进行性能分析的时候使用”opt”。–disable-dependency-tracking禁止对Makefile规则的依赖性追踪。–disable-fast-install禁止为快速安装而进行优化。–enable-fixed-point启用C定点浮点运算(fixed-point arithmetic)，这是一种非常快速的模拟浮点运算的方法，特别是在具有相应硬件支持的处理器(比如MIPS)上。在MIPS平台上默认开启，在其他平台上则默认关闭。–enable-gold仅在与Binutils联合编译时才有意义。使用gold代替GNU ld。gold是Google开发的连接器，2008年捐赠给FSF，目的是取代现有的GNU ld，但目前两者还不能完兼容。[GCC-4.4新增选项]–enable-gather-detailed-mem-stats允许收集详细的内存使用信息，将来在调用 gcc 时如果使用了 -fmem-report 选项就可以打印这些信息。–enable-generated-files-in-srcdir将生成的文件的副本保存在源代码目录中，以便于没有 texinfo, perl, bison, flex 的用户创建源代码的归档(比如创建正式发布的tarball)。–enable-initfini-array为构造函数和析构函数使用 .init_array 和 .fini_array (而不是 .init 和 .fini) 节。该选项的默认值由configure脚本自动检测决定。–enable-intermodule仅用一步来编译 compiler ，以达到内部模块最佳化。(什么意思?)–enable-install-libiberty安装 libiberty 的头文件(libiberty.h)，许多程序都会用到这个库中的函数(getopt,strerror,strtol,strtoul)。这个选项经过实验，没有实际效果(相当于disable)。–disable-largefile禁止支持大文件。[GCC-4.4新增选项]–disable-libada禁止编译GNAT的运行时库(libada，ADA编译器的运行时库)和相应的工具。–disable-libgcj禁止编译GCJ的运行时库(libgcj，Java编译器的运行时库)。–disable-libtool-lock禁止 libtool 锁定以加快编译速度(可能会导致并行编译的失败)–enable-linux-futex在libgomp和libstdc++库中使用Linux的futex系统调用(快速用户空间互斥体)。默认值根据内核头文件sys/syscall.h中是否包含futex函数的定义而定。–enable-maintainer-mode启用无用的 make 规则和依赖性(它们有时会导致混淆)。–enable-objc-gc允许在 Objective-C 运行时库中使用 Boehm 垃圾回收器。当前并不支持Boehm，所以该选项没有实际意义。–disable-ppl-version-check禁止检测PPL(Parma Polyhedra Library)的版本是否满足要求。[GCC-4.4新增选项]–enable-secureplt使编译器默认创建只读的 plt 项，相当于将来调用 gcc 时默认使用 -msecure-plt 选项。仅对 powerpc-linux 平台有意义。–enable-stage1-checking对处于 stage1 状态的编译器执行额外的检查。默认值等于–enable-checking选项的值。–enable-stage1-languages在bootstrap时，在 stage1 时使用系统原有的C编译器编译更多的语言支持，而不是使用stage1编译出来的C编译器来编译他们。该选项一般仅供编译器开发者使用。无默认值，可用的取值为：no, yes, all, ada, c, c++, fortran, java, objc, obj-c++ 。–enable-tls–disable-tls允许或禁止目标系统支持TLS(线程本地存储)，”gcc”子目录下没有默认值，”libgcc libgomp libmudflap libstdc++-v3”子目录下默认为”yes”。一般情况下不需要明确指定，因为 configure 脚本可以自动检测。仅在你认为检测不正确的情况下(比如汇编器支持 TLS 但 C 却不支持或汇编器检测错误)才使用这个选项明确指定。–enable-twoprocessChoose two-process fix methodology(啥意思?)。对于那些不支持双向pipe的系统，必须使用two-process方法。在 mingw32,beos 平台上默认为”yes”，其它平台上默认为”no”。–enable-werror-always不管编译器是否支持，总是使用-Werror来编译，也就是将所有编译器警告当作错误看待。–enable-win32-registry=KEY仅对Windows平台有意义。而且即使在Windows平台上也可以忽略该选项。–with-gnu-as–with-gnu-ld指定编译器将来使用的是GNU汇编器/连接器，默认值为未指定。如果你实际使用的不是GNU汇编器/连接器，指定这个选项会引起混淆；另一方面如果你实际使用的是GNU汇编器/连接器，但是却没有指定这个选项，也有可能会造成混淆。此选项仅在 hppa, sparc, sparc64 平台上才有意义。–with-bugurl=URL提示用户发送bug报告的URL。默认值是”http://gcc.gnu.org/bugs.html&quot;。–with-cpp-install-dir=DIR除了将用户可见的 cpp 程序安装到默认的 PREFIX/bin 目录外，还将安装到 prefix/DIR 目录。–with-debug-prefix-map=’A=B C=D …’在调试信息中将A映射B,C映射到D…–with-demangler-in-ld尝试在 GNU ld 中使用 demangler–with-dwarf2指定编译程序产生的调试信息默认为DWARF2格式。–with-gc=[page|zone]指定编译过程中使用的垃圾回收方案(默认为”page”)。–with-included-gettext使用软件包中自带的 GNU gettext 库。如果你已经使用了Glibc-2.0以上的版本，或者系统中已经安装了GNU gettext软件包，那么就没有必要使用这个选项。默认不使用。–with-pkgversion=PKG使用”PKG”代替默认的”GCC”作为版本字符串，这个信息将会在”gcc –version”命令下显示。比如你可以在其中嵌入编译时间或第多少次编译之类的信息。–with-stabs指定将来编译器产生的调试信息默认为stabs格式，而不是宿主系统的默认格式。通常GCC产生的默认调试信息是ECOFF格式，但是它包含的调试信息没有stabs多。编译、测试、安装除了使用 CFLAGS,LDFLAGS 之外，还可以使用 LIBCFLAGS,LIBCXXFLAGS 控制库文件(由stage3编译)的编译器选项。可以在 make 命令行上使用 BOOT_CFLAGS,BOOT_LDFLAGS 来控制 stage2,stage3 的编译。可以使用 make bootstrap4 来增加步骤以避免 stage1 可能被错误编译所导致的错误。可以使用 make profiledbootstrap 在编译stage1时收集一些有用的统计信息，然后使用这些信息编译最终的二进制文件，这样可以提升编译器和相应库文件的执行效率。 编译完毕后可以使用”make check”运行测试套件，然后可以和http://gcc.gnu.org/buildstat.html里面列出来的结果进行对比，只要&quot;unexpected failures”不要太多就好说。这个测试套件依赖于DejaGnu软件包，而DejaGnu又依赖于expect，expect依赖于tcl。如果只想运行C++测试，可以使用”make check-g++”命令；如果只想运行C编译器测试，可以使用”make check-gcc”。还可以制定只运行某些单项测试：比如使用 make check RUNTESTFLAGS=”compile.exp -v” 运行编译测试。另一方面，GCC并不支持使用”make uninstall”进行卸载，建议你将GCC安装在一个特别的目录中，然后在不需要的时候直接删除这个目录。 因为GCC的安装依赖于GMP和MPFR，所以下面附上GMP和MPFR的安装信息，主要是configure选项。 GMP-4.2.4下面所列选项若未特别说明皆为非默认值。并且仅选择有实际意义的选项介绍： –enable-assert启用断言检查，主要用于调试目的。–enable-alloca=alloca|malloc-reentrant|malloc-notreentrant分配临时工作区内存的方法：alloca - 使用libc或编译器内置的方法malloc-reentrant - 在堆上使用可重入的(re-entrant)方法分配malloc-notreentrant - 在堆上使用全局变量的方法分配默认值是优先使用alloca，不可用时使用malloc-reentrant。–enable-cxx启用C++支持(必须同时拥有C++编译器支持)。也就是将要安装libgmpxx.la库和gmpxx.h头文件。–enable-fat在运行时根据CPU型号选择相应的底层子程序。这将使得代码变得臃肿但可以获得更好的性能。–disable-fft默认情况下，GMP使用 Karatsuba, 3-way Toom, Fermat FFT 三种算法进行乘法运算。而 Fermat FFT 算法仅用于操作数非常巨大的场合，所以，如果你预计到并不需要操作非常巨大的数字，那么可以禁用这个算法，这样可以减小一些二进制文件的体积。–enable-mpbsd编译与Berkeley MP接口兼容的库文件(libmp.{so,a})和头文件(mp.h)–enable-nails=偶数在limbs中使用nail(?何意?)–enable-profile启用 profiling 信息相关的库文件编译。主要用于调试目的。–disable-shared–disable-static禁止编译共享或静态版本的库。–with-readline在calc演示程序中使用readline库，默认值自动检测。–with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。MPFR-2.3.2此包依赖于GMP，并且总是在http://www.mpfr.org/mpfr-current/patches存放最新版本的patch，可以使用 patch -N -Z -p1 &lt; patches命令打补丁。下面所列选项若未特别说明皆为非默认值。并且仅选择有实际意义的选项介绍： –enable-assert启用断言检查，主要用于调试目的。–enable-decimal-float编译与十进制浮点数之间的转换函数(要求GCC&gt;=4.2)–enable-logging启用MPFR日志(必须要有底层操作系统的支持)–disable-shared–disable-static禁止编译共享或静态版本的库。–enable-tests-timeout=NUM设定测试程序的超时秒数(NUM&lt;=9999)，默认没有超时限制。–enable-thread-safe编译线程安全的MPFR库–enable-warnings允许MPFR将错误输出到stderr–with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR指定 GMP 库的安装目录/头文件目录/库目录。指定GMPDIR相当于同时指定了：GMPINCDIR=GMPDIR/include,GMPLIBDIR=GMPDIR/lib 。–with-mulhigh_size=NUMmulhigh的内置阈值表大小，没有默认值。–with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[管理处理器的亲和性（affinity）]]></title>
    <url>%2F2019%2F04%2F09%2F%E7%AE%A1%E7%90%86%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E4%BA%B2%E5%92%8C%E6%80%A7affinity%2F</url>
    <content type="text"><![CDATA[简单地说，CPU 亲和性（affinity） 就是进程要在某个给定的 CPU 上尽量长时间地运行而不被迁移到其他处理器的倾向性。Linux 内核进程调度器天生就具有被称为 软 CPU 亲和性（affinity） 的特性，这意味着进程通常不会在处理器之间频繁迁移。这种状态正是我们希望的，因为进程迁移的频率小就意味着产生的负载小。 2.6 版本的 Linux 内核还包含了一种机制，它让开发人员可以编程实现 硬 CPU 亲和性（affinity）。这意味着应用程序可以显式地指定进程在哪个（或哪些）处理器上运行。 什么是 Linux 内核硬亲和性（affinity）？在 Linux 内核中，所有的进程都有一个相关的数据结构，称为 task_struct。这个结构非常重要，原因有很多；其中与 亲和性（affinity）相关度最高的是 cpus_allowed 位掩码。这个位掩码由 n 位组成，与系统中的 n 个逻辑处理器一一对应。 具有 4 个物理 CPU 的系统可以有 4 位。如果这些 CPU 都启用了超线程，那么这个系统就有一个 8 位的位掩码。 如果为给定的进程设置了给定的位，那么这个进程就可以在相关的 CPU 上运行。因此，如果一个进程可以在任何 CPU 上运行，并且能够根据需要在处理器之间进行迁移，那么位掩码就全是 1。实际上，这就是 Linux 中进程的缺省状态。 Linux 内核 API 提供了一些方法，让用户可以修改位掩码或查看当前的位掩码： sched_set_affinity() （用来修改位掩码）sched_get_affinity() （用来查看当前的位掩码）注意，cpu_affinity 会被传递给子线程，因此应该适当地调用 sched_set_affinity。 #为什么应该使用硬亲和性（affinity）？通常 Linux 内核都可以很好地对进程进行调度，在应该运行的地方运行进程（这就是说，在可用的处理器上运行并获得很好的整体性能）。内核包含了一些用来检测 CPU 之间任务负载迁移的算法，可以启用进程迁移来降低繁忙的处理器的压力。 一般情况下，在应用程序中只需使用缺省的调度器行为。然而，您可能会希望修改这些缺省行为以实现性能的优化。让我们来看一下使用硬亲和性（affinity） 的 3 个原因。 原因 1. 有大量计算要做基于大量计算的情形通常出现在科学和理论计算中，但是通用领域的计算也可能出现这种情况。一个常见的标志是您发现自己的应用程序要在多处理器的机器上花费大量的计算时间。 原因 2. 您在测试复杂的应用程序测试复杂软件是我们对内核的亲和性（affinity）技术感兴趣的另外一个原因。考虑一个需要进行线性可伸缩性测试的应用程序。有些产品声明可以在 使用更多硬件 时执行得更好。 我们不用购买多台机器（为每种处理器配置都购买一台机器），而是可以： 购买一台多处理器的机器不断增加分配的处理器测量每秒的事务数评估结果的可伸缩性如果应用程序随着 CPU 的增加可以线性地伸缩，那么每秒事务数和 CPU 个数之间应该会是线性的关系（例如斜线图 —— 请参阅下一节的内容）。这样建模可以确定应用程序是否可以有效地使用底层硬件。 Amdahl 法则Amdahl 法则是有关使用并行处理器来解决问题相对于只使用一个串行处理器来解决问题的加速比的法则。加速比（Speedup） 等于串行执行（只使用一个处理器）的时间除以程序并行执行（使用多个处理器）的时间： 其中 T(j) 是在使用 j 个处理器执行程序时所花费的时间。 Amdahl 法则说明这种加速比在现实中可能并不会发生，但是可以非常接近于该值。对于通常情况来说，我们可以推论出每个程序都有一些串行的组件。随着问题集不断变大，串行组件最终会在优化解决方案时间方面达到一个上限。 Amdahl 法则在希望保持高 CPU 缓存命中率时尤其重要。如果一个给定的进程迁移到其他地方去了，那么它就失去了利用 CPU 缓存的优势。实际上，如果正在使用的 CPU 需要为自己缓存一些特殊的数据，那么所有其他 CPU 都会使这些数据在自己的缓存中失效。 因此，如果有多个线程都需要相同的数据，那么将这些线程绑定到一个特定的 CPU 上是非常有意义的，这样就确保它们可以访问相同的缓存数据（或者至少可以提高缓存的命中率）。否则，这些线程可能会在不同的 CPU 上执行，这样会频繁地使其他缓存项失效。 原因 3. 您正在运行时间敏感的、决定性的进程我们对 CPU 亲和性（affinity）感兴趣的最后一个原因是实时（对时间敏感的）进程。例如，您可能会希望使用硬亲和性（affinity）来指定一个 8 路主机上的某个处理器，而同时允许其他 7 个处理器处理所有普通的系统调度。这种做法确保长时间运行、对时间敏感的应用程序可以得到运行，同时可以允许其他应用程序独占其余的计算资源。 下面的样例应用程序显示了这是如何工作的。 如何利用硬亲和性（affinity）现在让我们来设计一个程序，它可以让 Linux 系统非常繁忙。可以使用前面介绍的系统调用和另外一些用来说明系统中有多少处理器的 API 来构建这个应用程序。实际上，我们的目标是编写这样一个程序：它可以让系统中的每个处理器都繁忙几秒钟。 清单 1. 让处理器繁忙123456789101112131415161718192021/* This method will create threads, then bind each to its own cpu. */bool do_cpu_stress(int numthreads)&#123; int ret = TRUE; int created_thread = 0; /* We need a thread for each cpu we have... */ while ( created_thread &lt; numthreads - 1 ) &#123; int mypid = fork(); if (mypid == 0) /* Child process */ &#123; printf(&quot;\tCreating Child Thread: #%i\n&quot;, created_thread); break; &#125; else /* Only parent executes this */ &#123; /* Continue looping until we spawned enough threads! */ ; created_thread++; &#125; &#125; /* NOTE: All threads execute code from here down! */ 正如您可以看到的一样，这段代码只是通过 fork 调用简单地创建一组线程。每个线程都执行这个方法中后面的代码。现在我们让每个线程都将亲和性（affinity）设置为自己的 CPU。 清单 2. 为每个线程设置 CPU 亲和性（affinity）12345678910cpu_set_t mask;/* CPU_ZERO initializes all the bits in the mask to zero. */ CPU_ZERO( &amp;mask );/* CPU_SET sets only the bit corresponding to cpu. */ CPU_SET( created_thread, &amp;mask );/* sched_setaffinity returns 0 in success */ if( sched_setaffinity( 0, sizeof(mask), &amp;mask ) == -1 )&#123; printf(&quot;WARNING: Could not set CPU Affinity, continuing...\n&quot;);&#125; 如果程序可以执行到这儿，那么我们的线程就已经设置了自己的亲和性（affinity）。调用 sched_setaffinity 会设置由 pid 所引用的进程的 CPU 亲和性（affinity）掩码。如果 pid 为 0，那么就使用当前进程。 亲和性（affinity）掩码是使用在 mask 中存储的位掩码来表示的。最低位对应于系统中的第一个逻辑处理器，而最高位则对应于系统中最后一个逻辑处理器。 每个设置的位都对应一个可以合法调度的 CPU，而未设置的位则对应一个不可调度的 CPU。换而言之，进程都被绑定了，只能在那些对应位被设置了的处理器上运行。通常，掩码中的所有位都被置位了。这些线程的亲和性（affinity）都会传递给从它们派生的子进程中。 注意不应该直接修改位掩码。应该使用下面的宏。虽然在我们的例子中并没有全部使用这些宏，但是在本文中还是详细列出了这些宏，您在自己的程序中可能需要这些宏。 清单 3. 间接修改位掩码的宏12345678void CPU_ZERO (cpu_set_t *set)这个宏对 CPU 集 set 进行初始化，将其设置为空集。void CPU_SET (int cpu, cpu_set_t *set)这个宏将 cpu 加入 CPU 集 set 中。void CPU_CLR (int cpu, cpu_set_t *set)这个宏将 cpu 从 CPU 集 set 中删除。int CPU_ISSET (int cpu, const cpu_set_t *set)如果 cpu 是 CPU 集 set 的一员，这个宏就返回一个非零值（true），否则就返回零（false）。 对于本文来说，样例代码会继续让每个线程都执行某些计算量较大的操作。 清单 4. 每个线程都执行一个计算敏感的操作123456789101112131415161718/* Now we have a single thread bound to each cpu on the system */ int computation_res = do_cpu_expensive_op(41); cpu_set_t mycpuid; sched_getaffinity(0, sizeof(mycpuid), &amp;mycpuid); if ( check_cpu_expensive_op(computation_res) ) &#123; printf(&quot;SUCCESS: Thread completed, and PASSED integrity check!\n&quot;, mycpuid); ret = TRUE; &#125; else &#123; printf(&quot;FAILURE: Thread failed integrity check!\n&quot;, mycpuid); ret = FALSE; &#125; return ret;&#125; 我们使用一个 main 程序来封装这些方法，它使用一个用户指定的参数来说明要让多少个 CPU 繁忙。我们可以使用另外一个方法来确定系统中有多少个处理器： int NUM_PROCS = sysconf(_SC_NPROCESSORS_CONF); 这个方法让程序能够自己确定要让多少个处理器保持繁忙，例如缺省让所有的处理器都处于繁忙状态，并允许用户指定系统中实际处理器范围的一个子集。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux命令速查表]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[文件和目录cd命令（它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径）cd /home 进入 ‘/ home’ 目录cd .. 返回上一级目录cd ../.. 返回上两级目录cd 进入个人的主目录cd ~user1 进入个人的主目录cd - 返回上次所在的目录 pwd命令pwd 显示工作路径 ls命令（查看文件与目录的命令，list之意）ls 查看目录中的文件ls -l 显示文件和目录的详细资料ls -a 列出全部文件，包含隐藏文件ls -R 连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来ls [0-9] 显示包含数字的文件名和目录名ls -al 长格式显示当前目录下所有文件ls -h 文件大小显示为常见大小单位 B KB MB …ls -d 显示目录本身，而不是里面的子文件 长格式显示项 -rw——- 1 root root 1190 08-10 23:37 anaconda-ks.cfg ① ② ③ ④ ⑤ ⑥ ⑦ 第①项：权限位第②项：引用计数第③项：属主（所有者）第④项：属组第⑤项：大小第⑥项：最后一次修改时间第⑦项：文件名 cp 命令（用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下）-a ：将文件的特性一起复制-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行-r ：递归持续复制，用于目录的复制行为-u ：目标文件与源文件有差异时才会复制 mv命令（用于移动文件、目录或更名，move之意）-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖-i ：若目标文件已经存在，就会询问是否覆盖-u ：若目标文件已经存在，且比目标文件新，才会更新 rm 命令（用于删除文件或目录，remove之意）-f ：就是force的意思，忽略不存在的文件，不会出现警告消息-i ：互动模式，在删除前会询问用户是否操作-r ：递归删除，最常用于目录删除，它是一个非常危险的参数 mkdir命令名称：mkdir命令英文原意：make directories命令所在路径：/bin/mkdir执行权限：所有用户功能描述：建立目录mkdir test 创建名为test的目录mkdir -p test1/test2/test3 递归创建 rmdir命令名称：rmdir命令英文原意：remove empty directories命令所在路径：/bin/rmdir执行权限：所有用户功能描述：删除目录 (只能删除空目录) 查看文件内容touch命令名称：touch命令所在路径：/bin/touch权限：所有用户能描述：创建空文件 或 修改文件时间touch test.py 创建空文件，如果文件存在，则修改文件创建时间 more命令所在路径：/bin/more执行权限：所有用户功能描述：分屏显示文件内容more 文件名 分屏显示文件内容向上翻页 空格键向下翻页 b键退出查看 q键 head命令所在路径：/usr/bin/head执行权限：所有用户功能描述：显示文件头head 文件名 显示文件头几行(默认显示10行)head -n 20 文件名 显示文件前20行head -n -20 文件名 显示文件最后20行ctrl + c 强制终止查看模式ctrl + l 清屏 ln命令所在路径：/bin/ln执行权限：所有用户功能描述：链接文件等同于Windows中的快捷方式新建的链接，占用不同的硬盘位置修改一个文件，两边都会改变删除源文件，软连接文件打不开ln -s 源文件 目标文件 创建链接文件(文件名都必须写绝对路径) cat命令（用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用）cat file1 从第一个字节开始正向查看文件的内容tac file1 从最后一行开始反向查看一个文件的内容cat -n file1 标示文件的行数more file1 查看一个长文件的内容head -n 2 file1 查看一个文件的前两行tail -n 2 file1 查看一个文件的最后两行tail -n +1000 file1 从1000行开始显示，显示1000行以后的cat filename | head -n 3000 | tail -n +1000 显示1000行到3000行cat filename | tail -n +3000 | head -n 1000 从第3000行开始，显示1000(即显示3000~3999行) 文件搜索find命令find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录find / -user user1 搜索属于用户 ‘user1’ 的文件和目录find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件whereis halt 显示一个二进制文件、源码或man的位置which halt 显示一个二进制文件或可执行文件的完整路径 删除大于50M的文件：find /var/mail/ -size +50M -exec rm {} ＼; 文件的权限-rw-r–r–. 1 root root 44736 7月 18 00:38 install.log权限位是十位第一位：代表文件类型 - 普通文件 d 目录文件 l 链接文件其他九位：代表各用户的权限(前三位=属主权限u 中间三位=属组权限g 其他人权限o)r 读 4w 写 2x 执行 1 权限对文件的含义： r：读取文件内容 如：cat、more、head、tail w：编辑、新增、修改文件内容 如：vi、echo 但是不包含删除文件 x：可执行 /tmp/11/22/abc ——— 权限对目录的含义： r：可以查询目录下文件名 如：ls w：具有修改目录结构的权限 如：touch、rm、mv、cp x：可以进入目录 如：cd chmod 命令ls -lh 显示权限chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r，4 ）、写(w，2)和执行(x，1)的权限chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限 chown 命令（改变文件的所有者）chown user1 file1 改变一个文件的所有人属性chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性chown user1:group1 file1 改变一个文件的所有人和群组属性 chgrp 命令（改变文件所属用户组）chgrp group1 file1 改变文件的群组 文本处理grep 命令（分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等）grep Aug /var/log/messages 在文件 ‘/var/log/messages’中查找关键词”Aug”grep ^Aug /var/log/messages 在文件 ‘/var/log/messages’中查找以”Aug”开始的词汇grep [0-9] /var/log/messages 选择 ‘/var/log/messages’ 文件中所有包含数字的行grep Aug -R /var/log/* 在目录 ‘/var/log’ 及随后的目录中搜索字符串”Aug”sed ‘s/stringa1/stringa2/g’ example.txt 将example.txt文件中的 “string1” 替换成 “string2”sed ‘/^$/d’ example.txt 从example.txt文件中删除所有空白行 paste 命令paste file1 file2 合并两个文件或两栏的内容paste -d ‘+’ file1 file2 合并两个文件或两栏的内容，中间用”+”区分 sort 命令sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件) comm 命令comm -1 file1 file2 比较两个文件的内容只删除 ‘file1’ 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 ‘file2’ 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 打包和压缩文件tar 命令（对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压）-c ：新建打包文件-t ：查看打包文件的内容含有哪些文件名-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中-j ：通过bzip2的支持进行压缩/解压缩-z ：通过gzip的支持进行压缩/解压缩-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来-f filename ：filename为要处理的文件-C dir ：指定压缩/解压缩的目录dir压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称查询：tar -jtv -f filename.tar.bz2解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 bunzip2 file1.bz2 解压一个叫做 ‘file1.bz2’的文件bzip2 file1 压缩一个叫做 ‘file1’ 的文件gunzip file1.gz 解压一个叫做 ‘file1.gz’的文件gzip file1 压缩一个叫做 ‘file1’的文件gzip -9 file1 最大程度压缩rar a file1.rar test_file 创建一个叫做 ‘file1.rar’ 的包rar a file1.rar file1 file2 dir1 同时压缩 ‘file1’, ‘file2’ 以及目录 ‘dir1’rar x file1.rar 解压rar包 zip file1.zip file1 创建一个zip格式的压缩包unzip file1.zip 解压一个zip格式压缩包zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包 系统和关机 (系统的关机、重启以及登出 )shutdown -h now 关闭系统(1)init 0 关闭系统(2)telinit 0 关闭系统(3)shutdown -h hours:minutes &amp; 按预定时间关闭系统shutdown -c 取消按预定时间关闭系统shutdown -r now 重启(1)reboot 重启(2)logout 注销time 测算一个命令（即程序）的执行时间 进程相关的命令jps命令（显示当前系统的java进程情况，及其id号）jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。 ps命令（用于将某个时间点的进程运行情况选取下来并输出，process之意）-A ：所有的进程均显示出来-a ：不与terminal有关的所有进程-u ：有效用户的相关进程-x ：一般与a参数一起使用，可列出较完整的信息-l ：较长，较详细地将PID的信息列出 ps aux # 查看系统所有的进程数据ps ax # 查看不与terminal有关的所有进程ps -lA # 查看系统所有的进程数据ps axjf # 查看连同一部分进程树状态 kill命令（用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用） killall命令（向一个命令启动的进程发送一个信号） top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。 如何杀死进程：（1）图形化界面的方式（2）kill -9 pid （-9表示强制关闭）（3）killall -9 程序的名字（4）pkill 程序的名字 查看进程端口号：netstat -tunlp|grep 端口号 普通文件和目录文件的区别文件的类型Linux下面一切皆文件，配置是文件，设备是文件，目录也是特殊的文件，文件有如下几种：d：目录文件的标识是，-：普通文件标识，l：软连接文件，亦称符号链接文件；b，块文件，是设备文件的一种（还有另一种），b是block的简写。c，字符文件，也是设备文件的一种，c是character的文件。 普通文件和目录文件普通文件：存储普通数据，一般就是字符串。目录文件：存储了一张表，该表就是该目录文件下，所有文件名和inode的映射关系。 权限的区别对于普通文件来说，rwx的意义是：r：可以获得这个普通文件的名字和内容。w：可以修改这个文件的内容和文件名。可以删除该文件。x：该文件是否具有被执行的权限。 对于目录文件来说，rwx的意义是：r：表示具有读取目录结构列表的权限，所以当你具有读取(r)一个目录的权限时，表示你可以查询该目录下的文件名。 就可以利用 ls 这个命令将该目录的内容列表显示出来， 必须这个目录有x的权限，才可以进入这个目录。w：移动该目录结构列表的权限（建立新的文件与目录、删除已经存在的文件与目录、更名、移动位置）。x：目录不可以被执行，目录的x代表的是用户能否进入该目录成为工作目录。 Linux 常见目录/ 根目录/bin 命令保存目录（普通用户就可以读取的命令）/boot 启动目录，启动相关文件/dev 设备文件保存目录/etc 配置文件保存目录/home 普通用户的家目录/lib 系统库保存目录/mnt 系统挂载目录/media 挂载目录/root 超级用户的家目录/tmp 临时目录/sbin 命令保存目录（超级用户才能使用的目录）/proc 直接写入内存的/sys 将内核的一些信息映射，可供应用程序所用/usr 系统软件资源目录/usr/bin/ 系统命令（普通用户）/usr/sbin/ 系统命令（超级用户）/var 系统相关文档内容/var/log/ 系统日志位置/var/spool/mail/ 系统默认邮箱位置/var/lib/ 默认安装的库文件目录]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中vector和set使用sort方法进行排序]]></title>
    <url>%2F2019%2F04%2F09%2Fcpp%E4%B8%ADvector%E5%92%8Cset%E4%BD%BF%E7%94%A8sort%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[C++中vector和set都是非常方便的容器， sort方法是algorithm头文件里的一个标准函数，能进行高效的排序，默认是按元素从小到大排序 将sort方法用到vector和set中能实现多种符合自己需求的排序 首先sort方法可以对静态的数组进行排序123456789#include&lt;iostream&gt;using namespace std;int main()&#123; int a[10] = &#123; 9, 0, 1, 2, 3, 7, 4, 5, 100, 10 &#125;; sort(a, a +10); for (int i = 0; i &lt; 10; i++) cout &lt;&lt; a[i] &lt;&lt; endl; return 0;&#125; 运行结果如下： 这里可以看到是sort(a,a+10)，但是数组a一共只有9个元素，为什么是a+10而不是a+9呢？ 因为sort方法实际上最后一位地址对应的数是不取的， 而且vector，set，map这些容器的end()取出来的值实际上并不是最后一个值，而end的前一个才是最后一个值！ 需要用prev(xxx.end())，才能取出容器中最后一个元素。 对vector使用sort函数： 第一种情形：基本类型,如vector,vector,vector也是可以的1234567891011121314151617181920#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;using namespace std;int main()&#123; vector&lt;int&gt; a; int n = 5; while (n--)&#123; int score; cin &gt;&gt; score; a.push_back(score); &#125; //cout &lt;&lt;&quot; a.end()&quot;&lt;&lt; *a.end() &lt;&lt; endl; 执行这句话会报错！ cout &lt;&lt; &quot; prev(a.end)&quot; &lt;&lt; *prev(a.end()) &lt;&lt; endl; sort(a.begin(), a.end()); for (vector&lt;int&gt;::iterator it = a.begin(); it != a.end(); it++)&#123; cout &lt;&lt; *it &lt;&lt; endl; &#125; return 0;&#125; 看到了吗，实际上end的前一个指针指向的元素才是插入时的最后一个值！ 排序后从小大大。 第二种情形：用自定义的结构体进行sort算法， 这时候需要自己定义个比较函数，因为sort算法是基于容器中的元素是可以两两比较的，然后从小到大排序，所以要自定义怎么样才是小于（’&lt;’） 12345678910111213141516171819202122232425262728293031323334353637#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;set&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;struct student&#123; char name[10]; int score;&#125;;//自定义“小于”bool comp(const student &amp;a, const student &amp;b)&#123; return a.score &lt; b.score;&#125;int main()&#123; vector&lt;student&gt; vectorStudents; int n = 5; while (n--)&#123; student oneStudent; string name; int score; cin &gt;&gt; name &gt;&gt; score; strcpy(oneStudent.name, name.c_str()); oneStudent.score = score; vectorStudents.push_back(oneStudent); &#125; cout &lt;&lt; &quot;===========排序前================&quot; &lt;&lt; endl; for (vector&lt;student&gt;::iterator it = vectorStudents.begin(); it != vectorStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; sort(vectorStudents.begin(),vectorStudents.end(),comp); cout &lt;&lt; &quot;===========排序后================&quot; &lt;&lt; endl; for (vector&lt;student&gt;::iterator it = vectorStudents.begin(); it != vectorStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; return 0;&#125; 对于set做类似的操作。 set是一个集合，内部的元素不会重复，同时它会自动进行排序，也是从小到大 而且set的insert方法没有insert(a,cmp)这种重载，所以如果要把结构体插入set中，我们就要重载’&lt;’运算符。 set方法在插入的时候也是从小到大的，那么我们重载一下&lt;运算符让它从大到小排序123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;set&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;struct student&#123; char name[10]; int score;&#125;;//自定义“小于”bool comp(const student &amp;a, const student &amp;b)&#123; return a.score &lt; b.score;&#125;bool operator &lt; (const student &amp; stu1,const student &amp;stu2)&#123; return stu1.score &gt; stu2.score;&#125;int main()&#123; //vector&lt;student&gt; vectorStudents; set&lt;student&gt; setStudents; //int n = 5; int n = 6; while (n--)&#123; student oneStudent; string name; int score; cin &gt;&gt; name &gt;&gt; score; strcpy(oneStudent.name, name.c_str()); oneStudent.score = score; setStudents.insert(oneStudent); &#125; cout &lt;&lt; &quot;===========排序前================&quot; &lt;&lt; endl; for (set&lt;student&gt;::iterator it = setStudents.begin(); it != setStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; //sort(setStudents.begin(), setStudents.end(), comp); //cout &lt;&lt; &quot;===========排序后================&quot; &lt;&lt; endl; //for (set&lt;student&gt;::iterator it = setStudents.begin(); it != setStudents.end(); it++)&#123; // cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; //&#125; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode56. Merge Intervals]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode56-Merge-Intervals%2F</url>
    <content type="text"><![CDATA[Merge IntervalsMedium Given a collection of intervals, merge all overlapping intervals.一些区间，要求合并重叠的区间，返回一个vector保存结果。 Example 1:·123Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. Example 2:123Input: [[1,4],[4,5]]Output: [[1,5]]Explanation: Intervals [1,4] and [4,5] are considered overlapping. 贪心思路，将初始区间序列ins按照左端点的从小到大排序，接着遍历ins。 一开始将第一个区间ins[0]放入结果区间序列res，接着每次遍历到一个新的区间[l,r]，将其与当前合并后的最后一个区间[L,R]比较： 若l &lt;= R，说明新区间与当前最有一个区间有重叠，应该将这两个区间合并，也就需要修改当前最后一个区间为[L，max(r,R)]。若l &gt; R，说明新区间与当前最后一个区间没有重叠，所以不需要合并，直接将新区间加入结果序列res，成为新的最后一个区间。 算法正确性： 在上述贪心思路中，只考虑了新区间的左端点与最后一个区间的右端点的大小比较，最后只会对最后区间的右端点进行修改，却不会修改左端点。之所以不考虑左端点，是因为初始化时已经将ins按照左端点排序，保证后遍历的左端点l &gt;= 之前遍历过的左端点L。 算法复杂度为O(nlogn)。 我的代码：123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for an interval. * struct Interval &#123; * int start; * int end; * Interval() : start(0), end(0) &#123;&#125; * Interval(int s, int e) : start(s), end(e) &#123;&#125; * &#125;; */class Solution &#123;public: static bool comp(const Interval &amp;a, const Interval &amp;b) &#123; return a.start &lt; b.start; &#125; vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; vector&lt;Interval&gt; answer; if(intervals.size()==0) return answer; sort(intervals.begin(),intervals.end(),comp); Interval ttt(intervals[0].start,intervals[0].end); vector&lt;Interval&gt;::iterator it = intervals.begin(); it++; for(; it != intervals.end(); it++)&#123; if(ttt.end&gt;=it-&gt;start)&#123; if(ttt.end&lt;it-&gt;end) ttt.end=it-&gt;end; &#125; else if(ttt.end&lt;it-&gt;start)&#123; answer.push_back(ttt); ttt.start=it-&gt;start; ttt.end = it-&gt;end; &#125; &#125; answer.push_back(ttt); return answer; &#125;&#125;; 题解的代码：1234567891011121314151617181920212223class Solution &#123; public: static bool cmp(const Interval &amp;a, const Interval &amp;b) &#123; return a.start &lt; b.start; &#125; vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; ins) &#123; vector &lt;Interval&gt; res; if (ins.empty()) return res; sort(ins.begin(), ins.end(), cmp); res.push_back(ins[0]); int cnt = ins.size(); for (int i = 1; i &lt; cnt; i++) &#123; if (ins[i].start &lt;= res.back().end) &#123; res.back().end = max(res.back().end, ins[i].end); &#125; else &#123; res.push_back(ins[i]); &#125; &#125; return res; &#125;&#125;; SolutionApproach 1: Connected ComponentsIntuition If we draw a graph (with intervals as nodes) that contains undirected edges between all pairs of intervals that overlap, then all intervals in each connected component of the graph can be merged into a single interval. Algorithm With the above intuition in mind, we can represent the graph as an adjacency list, inserting directed edges in both directions to simulate undirected edges. Then, to determine which connected component each node is it, we perform graph traversals from arbitrary unvisited nodes until all nodes have been visited. To do this efficiently, we store visited nodes in a Set, allowing for constant time containment checks and insertion. Finally, we consider each connected component, merging all of its intervals by constructing a new Interval with start equal to the minimum start among them and end equal to the maximum end. This algorithm is correct simply because it is basically the brute force solution. We compare every interval to every other interval, so we know exactly which intervals overlap. The reason for the connected component search is that two intervals may not directly overlap, but might overlap indirectly via a third interval. See the example below to see this more clearly. Components Example Although (1, 5) and (6, 10) do not directly overlap, either would overlap with the other if first merged with (4, 7). There are two connected components, so if we merge their nodes, we expect to get the following two merged intervals: (1, 10), (15, 20) 123456789101112131415161718192021222324252627class Solution &#123; private Map&lt;Interval, List&lt;Interval&gt; &gt; graph; private Map&lt;Integer, List&lt;Interval&gt; &gt; nodesInComp; private Set&lt;Interval&gt; visited; // return whether two intervals overlap (inclusive) private boolean overlap(Interval a, Interval b) &#123; return a.start &lt;= b.end &amp;&amp; b.start &lt;= a.end; &#125; // build a graph where an undirected edge between intervals u and v exists // iff u and v overlap. private void buildGraph(List&lt;Interval&gt; intervals) &#123; graph = new HashMap&lt;&gt;(); for (Interval interval : intervals) &#123; graph.put(interval, new LinkedList&lt;&gt;()); &#125; for (Interval interval1 : intervals) &#123; for (Interval interval2 : intervals) &#123; if (overlap(interval1, interval2)) &#123; graph.get(interval1).add(interval2); graph.get(interval2).add(interval1); &#125; &#125; &#125; &#125; 12345678910111213141516class Solution: def merge(self, intervals): intervals.sort(key=lambda x: x.start) merged = [] for interval in intervals: # if the list of merged intervals is empty or if the current # interval does not overlap with the previous, simply append it. if not merged or merged[-1].end &lt; interval.start: merged.append(interval) else: # otherwise, there is overlap, so we merge the current and previous # intervals. merged[-1].end = max(merged[-1].end, interval.end) return merged]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树高频面试题和答案]]></title>
    <url>%2F2019%2F04%2F09%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%A2%98%E5%92%8C%E7%AD%94%E6%A1%88%2F</url>
    <content type="text"><![CDATA[先上二叉树的数据结构：1234567class TreeNode&#123; int val; //左孩子 TreeNode left; //右孩子 TreeNode right;&#125; 二叉树的题目普遍可以用递归和迭代的方式来解 求二叉树的最大深度 12345678int maxDeath(TreeNode node)&#123; if(node==null)&#123; return 0; &#125; int left = maxDeath(node.left); int right = maxDeath(node.right); return Math.max(left,right) + 1;&#125; 求二叉树的最小深度 123456789101112131415int getMinDepth(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; return getMin(root); &#125; int getMin(TreeNode root)&#123; if(root == null)&#123; return Integer.MAX_VALUE; &#125; if(root.left == null&amp;&amp;root.right == null)&#123; return 1; &#125; return Math.min(getMin(root.left),getMin(root.right)) + 1; &#125; 求二叉树中节点的个数 12345678int numOfTreeNode(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; int left = numOfTreeNode(root.left); int right = numOfTreeNode(root.right); return left + right + 1; &#125; 求二叉树中叶子节点的个数 123456789 int numsOfNoChildNode(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; if(root.left==null&amp;&amp;root.right==null)&#123; return 1; &#125; return numsOfNodeTreeNode(root.left)+numsOfNodeTreeNode(root.right);&#125; 求二叉树中第k层节点的个数 1234567891011int numsOfkLevelTreeNode(TreeNode root,int k)&#123; if(root == null||k&lt;1)&#123; return 0; &#125; if(k==1)&#123; return 1; &#125; int numsLeft = numsOfkLevelTreeNode(root.left,k-1); int numsRight = numsOfkLevelTreeNode(root.right,k-1); return numsLeft + numsRight; &#125; 判断二叉树是否是平衡二叉树 1234567891011121314boolean isBalanced(TreeNode node)&#123; return maxDeath2(node)!=-1; &#125; int maxDeath2(TreeNode node)&#123; if(node == null)&#123; return 0; &#125; int left = maxDeath2(node.left); int right = maxDeath2(node.right); if(left==-1||right==-1||Math.abs(left-right)&gt;1)&#123; return -1; &#125; return Math.max(left, right) + 1; &#125; 7.判断二叉树是否是完全二叉树1234567891011121314151617181920212223242526272829303132boolean isCompleteTreeNode(TreeNode root)&#123; if(root == null)&#123; return false; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); boolean result = true; boolean hasNoChild = false; while(!queue.isEmpty())&#123; TreeNode current = queue.remove(); if(hasNoChild)&#123; if(current.left!=null||current.right!=null)&#123; result = false; break; &#125; &#125;else&#123; if(current.left!=null&amp;&amp;current.right!=null)&#123; queue.add(current.left); queue.add(current.right); &#125;else if(current.left!=null&amp;&amp;current.right==null)&#123; queue.add(current.left); hasNoChild = true; &#125;else if(current.left==null&amp;&amp;current.right!=null)&#123; result = false; break; &#125;else&#123; hasNoChild = true; &#125; &#125; &#125; return result; &#125; 两个二叉树是否完全相同 1234567891011121314boolean isSameTreeNode(TreeNode t1,TreeNode t2)&#123; if(t1==null&amp;&amp;t2==null)&#123; return true; &#125; else if(t1==null||t2==null)&#123; return false; &#125; if(t1.val != t2.val)&#123; return false; &#125; boolean left = isSameTreeNode(t1.left,t2.left); boolean right = isSameTreeNode(t1.right,t2.right); return left&amp;&amp;right;&#125; 两个二叉树是否互为镜像 123456789101112 boolean isMirror(TreeNode t1,TreeNode t2)&#123; if(t1==null&amp;&amp;t2==null)&#123; return true; &#125; if(t1==null||t2==null)&#123; return false; &#125; if(t1.val != t2.val)&#123; return false; &#125; return isMirror(t1.left,t2.right)&amp;&amp;isMirror(t1.right,t2.left);&#125; 翻转二叉树or镜像二叉树 12345678910 TreeNode mirrorTreeNode(TreeNode root)&#123; if(root == null)&#123; return null; &#125; TreeNode left = mirrorTreeNode(root.left); TreeNode right = mirrorTreeNode(root.right); root.left = right; root.right = left; return root;&#125; 求两个二叉树的最低公共祖先节点 1234567891011121314151617181920212223242526272829TreeNode getLastCommonParent(TreeNode root,TreeNode t1,TreeNode t2)&#123; if(findNode(root.left,t1))&#123; if(findNode(root.right,t2))&#123; return root; &#125;else&#123; return getLastCommonParent(root.left,t1,t2); &#125; &#125;else&#123; if(findNode(root.left,t2))&#123; return root; &#125;else&#123; return getLastCommonParent(root.right,t1,t2) &#125; &#125;&#125;// 查找节点node是否在当前 二叉树中boolean findNode(TreeNode root,TreeNode node)&#123; if(root == null || node == null)&#123; return false; &#125; if(root == node)&#123; return true; &#125; boolean found = findNode(root.left,node); if(!found)&#123; found = findNode(root.right,node); &#125; return found;&#125; 二叉树的前序遍历 迭代解法12345678910111213141516171819ArrayList&lt;Integer&gt; preOrder(TreeNode root)&#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if(root == null)&#123; return list; &#125; stack.push(root); while(!stack.empty())&#123; TreeNode node = stack.pop(); list.add(node.val); if(node.right!=null)&#123; stack.push(node.right); &#125; if(node.left != null)&#123; stack.push(node.left); &#125; &#125; return list; &#125; 递归解法12345678910111213ArrayList&lt;Integer&gt; preOrderReverse(TreeNode root)&#123; ArrayList&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); preOrder2(root,result); return result; &#125; void preOrder2(TreeNode root,ArrayList&lt;Integer&gt; result)&#123; if(root == null)&#123; return; &#125; result.add(root.val); preOrder2(root.left,result); preOrder2(root.right,result); &#125; 二叉树的中序遍历12345678910111213141516ArrayList&lt;Integer&gt; inOrder(TreeNode root)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode current = root; while(current != null|| !stack.empty())&#123; while(current != null)&#123; stack.add(current); current = current.left; &#125; current = stack.peek(); stack.pop(); list.add(current.val); current = current.right; &#125; return list; &#125; 14.二叉树的后序遍历12345678910ArrayList&lt;Integer&gt; postOrder(TreeNode root)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if(root == null)&#123; return list; &#125; list.addAll(postOrder(root.left)); list.addAll(postOrder(root.right)); list.add(root.val); return list; &#125; 15.前序遍历和后序遍历构造二叉树12345678910111213141516171819202122232425TreeNode buildTreeNode(int[] preorder,int[] inorder)&#123; if(preorder.length!=inorder.length)&#123; return null; &#125; return myBuildTree(inorder,0,inorder.length-1,preorder,0,preorder.length-1); &#125; TreeNode myBuildTree(int[] inorder,int instart,int inend,int[] preorder,int prestart,int preend)&#123; if(instart&gt;inend)&#123; return null; &#125; TreeNode root = new TreeNode(preorder[prestart]); int position = findPosition(inorder,instart,inend,preorder[start]); root.left = myBuildTree(inorder,instart,position-1,preorder,prestart+1,prestart+position-instart); root.right = myBuildTree(inorder,position+1,inend,preorder,position-inend+preend+1,preend); return root; &#125; int findPosition(int[] arr,int start,int end,int key)&#123; int i; for(i = start;i&lt;=end;i++)&#123; if(arr[i] == key)&#123; return i; &#125; &#125; return -1; &#125; 16.在二叉树中插入节点123456789101112131415161718192021222324TreeNode insertNode(TreeNode root,TreeNode node)&#123; if(root == node)&#123; return node; &#125; TreeNode tmp = new TreeNode(); tmp = root; TreeNode last = null; while(tmp!=null)&#123; last = tmp; if(tmp.val&gt;node.val)&#123; tmp = tmp.left; &#125;else&#123; tmp = tmp.right; &#125; &#125; if(last!=null)&#123; if(last.val&gt;node.val)&#123; last.left = node; &#125;else&#123; last.right = node; &#125; &#125; return root; &#125; 17.输入一个二叉树和一个整数，打印出二叉树中节点值的和等于输入整数所有的路径1234567891011121314151617181920212223242526void findPath(TreeNode r,int i)&#123; if(root == null)&#123; return; &#125; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int currentSum = 0; findPath(r, i, stack, currentSum); &#125; void findPath(TreeNode r,int i,Stack&lt;Integer&gt; stack,int currentSum)&#123; currentSum+=r.val; stack.push(r.val); if(r.left==null&amp;&amp;r.right==null)&#123; if(currentSum==i)&#123; for(int path:stack)&#123; System.out.println(path); &#125; &#125; &#125; if(r.left!=null)&#123; findPath(r.left, i, stack, currentSum); &#125; if(r.right!=null)&#123; findPath(r.right, i, stack, currentSum); &#125; stack.pop(); &#125; 18.二叉树的搜索区间给定两个值 k1 和 k2（k1 &lt; k2）和一个二叉查找树的根节点。找到树中所有值在 k1 到 k2 范围内的节点。即打印所有x (k1 &lt;= x &lt;= k2) 其中 x 是二叉查找树的中的节点值。返回所有升序的节点值。1234567891011121314151617181920ArrayList&lt;Integer&gt; result; ArrayList&lt;Integer&gt; searchRange(TreeNode root,int k1,int k2)&#123; result = new ArrayList&lt;Integer&gt;(); searchHelper(root,k1,k2); return result; &#125; void searchHelper(TreeNode root,int k1,int k2)&#123; if(root == null)&#123; return; &#125; if(root.val&gt;k1)&#123; searchHelper(root.left,k1,k2); &#125; if(root.val&gt;=k1&amp;&amp;root.val&lt;=k2)&#123; result.add(root.val); &#125; if(root.val&lt;k2)&#123; searchHelper(root.right,k1,k2); &#125; &#125; 19.二叉树的层次遍历123456789101112131415161718192021222324ArrayList&lt;ArrayList&lt;Integer&gt;&gt; levelOrder(TreeNode root)&#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if(root == null)&#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.offer(root); while(!queue.isEmpty())&#123; int size = queue.size(); ArrayList&lt;&lt;Integer&gt; level = new ArrayList&lt;Integer&gt;(): for(int i = 0;i &lt; size ;i++)&#123; TreeNode node = queue.poll(); level.add(node.val); if(node.left != null)&#123; queue.offer(node.left); &#125; if(node.right != null)&#123; queue.offer(node.right); &#125; &#125; result.add(Level); &#125; return result; &#125; 20.二叉树内两个节点的最长距离二叉树中两个节点的最长距离可能有三种情况： 左子树的最大深度+右子树的最大深度为二叉树的最长距离 左子树中的最长距离即为二叉树的最长距离 右子树种的最长距离即为二叉树的最长距离 因此，递归求解即可12345678910111213141516171819202122232425 private static class Result&#123; int maxDistance; int maxDepth; public Result() &#123; &#125; public Result(int maxDistance, int maxDepth) &#123; this.maxDistance = maxDistance; this.maxDepth = maxDepth; &#125; &#125; int getMaxDistance(TreeNode root)&#123; return getMaxDistanceResult(root).maxDistance; &#125; Result getMaxDistanceResult(TreeNode root)&#123; if(root == null)&#123; Result empty = new Result(0,-1); return empty; &#125; Result lmd = getMaxDistanceResult(root.left); Result rmd = getMaxDistanceResult(root.right); Result result = new Result(); result.maxDepth = Math.max(lmd.maxDepth,rmd.maxDepth) + 1; result.maxDistance = Math.max(lmd.maxDepth + rmd.maxDepth,Math.max(lmd.maxDistance,rmd.maxDistance)); return result; &#125; 21.不同的二叉树给出 n，问由 1…n 为节点组成的不同的二叉查找树有多少种？1234567891011int numTrees(int n )&#123; int[] counts = new int[n+2]; counts[0] = 1; counts[1] = 1; for(int i = 2;i&lt;=n;i++)&#123; for(int j = 0;j&lt;i;j++)&#123; counts[i] += counts[j] * counts[i-j-1]; &#125; &#125; return counts[n]; &#125; 22.判断二叉树是否是合法的二叉查找树(BST)一棵BST定义为： 节点的左子树中的值要严格小于该节点的值。 节点的右子树中的值要严格大于该节点的值。 左右子树也必须是二叉查找树。 一个节点的树也是二叉查找树。1234567891011121314151617181920public int lastVal = Integer.MAX_VALUE; public boolean firstNode = true; public boolean isValidBST(TreeNode root) &#123; // write your code here if(root==null)&#123; return true; &#125; if(!isValidBST(root.left))&#123; return false; &#125; if(!firstNode&amp;&amp;lastVal &gt;= root.val)&#123; return false; &#125; firstNode = false; lastVal = root.val; if (!isValidBST(root.right)) &#123; return false; &#125; return true; &#125;]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb调试相关]]></title>
    <url>%2F2019%2F04%2F09%2Fgdb%E8%B0%83%E8%AF%95%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[给师兄debug测试的时候深深觉得自己太垃圾了，gdb用的不熟，所以去找了一篇gdb的博文搬过来整理好，纯当复习了。贴原文链接：https://blog.csdn.net/zb872676223/article/details/37906049 GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具。或许，各位比较喜欢那种图形界面方式的，像VC、BCB等IDE的调试，但如果你是在UNIX平台下做软件，你会发现GDB这个调试工具有比VC、BCB的图形化调试器更强大的功能。所谓“寸有所长，尺有所短”就是这个道理。 一般来说，GDB主要帮忙你完成下面四个方面的功能： 启动你的程序，可以按照你的自定义的要求随心所欲的运行程序。 可让被调试的程序在你所指定的调置的断点处停住。（断点可以是条件表达式） 当程序被停住时，可以检查此时你的程序中所发生的事。 动态的改变你程序的执行环境。 测试程序我们先看看我们的测试程序:123456789101112131415161718192021222324252627282930313233343536373839404142/* in eg1.c */int wib(int no1, int no2)&#123; int result, diff; diff = no1 - no2; result = no1 / diff; return result;&#125;int main()&#123; pid_t pid; pid = fork(); if (pid &lt;0) &#123; printf(&quot;fork err\n&quot;); exit(-1); &#125; else if (pid == 0) &#123; /* in child process */ sleep(60); ------------------ (!) int value = 10; int div = 6; int total = 0; int i = 0; int result = 0; for (i = 0; i &lt; 10; i++) &#123; result = wib(value, div); total += result; div++; value--; &#125; printf(&quot;%d wibed by %d equals %d\n&quot;, value, div, total); exit(0); &#125; else &#123; /* in parent process */ sleep(4); wait(-1); exit(0); &#125;&#125; 该测试程序中子进程运行过程中会在wib函数中出现一个’除0’异常。现在我们就要调试该子进程。 调试原理不知道大家发现没有，在(!)处在我们的测试程序在父进程fork后，子进程调用sleep睡了60秒。这就是关键，这个sleep本来是不该存在于子进程代码中的，而是而了使用GDB调试后加入的，它是我们调试的一个关键点。为什么要让子进程刚刚运行就开始sleep呢？因为我们要在子进程睡眠期间，利用 shell命令获取其process id，然后再利用gdb调试外部进程的方法attach到该process id上，调试该进程。我们现在调试的是mpi程序，intel的mpiexec可以直接-gdb进行调试，但是用gnu的话就不行了，只能gdb attach来调试，下述。 调试过程GDB 调试程序的前提条件就是你编译程序时必须加入调试符号信息，即使用’-g’编译选项。首先编译我们的源程序gcc -g -o eg1 eg1.c。编译好之后，我们就有了我们的调试目标eg1。由于我们在调试过程中需要多个工具配合，所以你最好多打开几个终端窗口，另外一点需要注意的是最好在eg1的working directory下执行gdb程序，否则gdb回提示’No symbol table is loaded’。你还得手工load symbol table。好了，下面我们就’按部就班’的开始调试我们的eg1。 执行eg1:eg1 &amp; --- 让eg1后台运行 查找进程id:ps -fu YOUR_USER_NAME或在linux下使用getpid()函数 运行gdb:12345678910111213141516171819202122232425262728293031323334353637gdb(gdb) attach xxxxx --- xxxxx为利用ps命令获得的子进程process id(gdb) stop --- 这点很重要，你需要先暂停那个子进程，然后设置一些断点和一些Watch(gdb) break 37 -- 在result = wib(value, div);这行设置一个断点,可以使用list命令察看源代码Breakpoint 1 at 0x10808: file eg1.c, line 37.(gdb) continueContinuing.这里一定要continue，要不的话。。。。。。傻呼呼的等那么久还不运行。Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=10, no2=6) at eg1.c:1313 diff = no1 - no2;(gdb) continueContinuing.Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=9, no2=7) at eg1.c:1313 diff = no1 - no2;(gdb) continueContinuing.Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=8, no2=8) at eg1.c:1313 diff = no1 - no2;(gdb) next14 result = no1 / diff;(gdb) print diff$6 = 0 ------- 除数为0，我们找到罪魁祸首了。(gdb) nextProgram received signal SIGFPE, Arithmetic exception.0xff29d830 in .div () from /usr/lib/libc.so.1 至此，我们调试完毕。 GDB调试精粹一、列文件清单list / l列出产生执行文件的源代码的一部分 1234567891011//列出 line1 到 line2 行之间的源代码 (gdb) list line1, line2 //输出从上次调用list命令开始往后的10行程序代码 (gdb) list //输出第 n 行附近的10行程序代码 (gdb) list n //输出函数function前后的10行程序代码 (gdb) list function 二、执行程序run / r运行准备调试的程序，在它后面可以跟随发给该程序的任何参数，包括标准输入和标准输出说明符(&lt;和&gt;)和shell通配符（*、？、[、]）在内。如果你使用不带参数的run命令，gdb就再次使用你给予前一条run命令的参数，这是很有用的。 set args命令就可以修改发送给程序的参数，而使用 show args命令就可以查看其缺省参数的列表。 12(gdb) set args –b –x (gdb) show args 三、显示数据print / p查看变量的值 1234567891011121314151617181920//利用print 命令可以检查各个变量的值。 (gdb) print p (p为变量名) print 是 gdb 的一个功能很强的命令，利用它可以显示被调试的语言中任何有效的表达式。表达式除了包含你程序中的变量外，还可以包含以下内容：//对程序中函数的调用 (gdb) print find_entry(1, 0) //数据结构和其他复杂对象 (gdb) print *table_start $8=&#123;e=reference=’\000’,location=0x0,next=0x0&#125; //值的历史成分 (gdb)print $1 ($1为历史记录变量,在以后可以直接引用 $1 的值) whatis 查看变量的类型//whatis 命令可以显示某个变量的类型 (gdb) whatis p type = int * 四、设置与清除断点break / b可以用来在调试的程序中设置断点，该命令有如下四种形式：123456789101112//使程序恰好在执行给定行之前停止 break line-number //使程序恰好在进入指定的函数之前停止 break function-name //如果condition（条件）是真，程序到达指定行或函数时停止 break line-or-function if condition //在指定例程的入口处设置断点 break routine-name 如果该程序是由很多原文件构成的，你可以在各个原文件中设置断点，而不是在当前的原文件中设置断点，其方法如下：1234(gdb) break filename:line-number (gdb) break filename:function-name break if 要想设置一个条件断点，可以利用break if命令，如下所示：1234(gdb) break line-or-function if expr (gdb) break 46 if testsize==100 clean number 清除原文件中某一代码行上的所有断点 注：number 为原文件的某个代码行的行号 五、断点的管理 显示当前gdb的断点信息info break delete 删除指定的某个断点delete breakpoint 12345//该命令将会删除编号为1的断点 (gdb) delete breakpoint 1 //如果不带编号参数，将删除所有的断点 (gdb) delete breakpoint 禁止、允许使用某个断点12disable breakpoint 1enable breakpoint 1 该命令将禁止、允许断点 1，同时断点信息的 (Enb)域将变为 n、y 六、单步执行next / n不进入的单步执行 step进入的单步执行 finish如果已经进入了某函数，而想退出该函数返回到它的调用函数中，可使用命令finish until结束当前循环 七、函数的调用call name调用和执行一个函数123(gdb) call gen_and_sork( 1234,1,0 ) (gdb) call printf(“abcd”) $1=4 八、 原文件的搜索search text 该命令可显示在当前文件中包含text串的下一行。 reverse-search text 该命令可以显示包含text 的前一行。 小结：常用的 gdb 命令 backtrace / bt 显示程序中的当前位置和表示如何到达当前位置的栈跟踪（同义词：where） breakpoint / b 在程序中设置一个断点 cd 改变当前工作目录 clear 删除刚才停止处的断点 commands 命中断点时，列出将要执行的命令 continue 从断点开始继续执行 delete 删除一个断点或监测点；也可与其他命令一起使用 display 程序停止时显示变量和表达时 down 下移栈帧，使得另一个函数成为当前函数 frame 选择下一条continue命令的帧 info 显示与该程序有关的各种信息 jump 在源程序中的另一点开始运行 kill 异常终止在gdb 控制下运行的程序 list 列出相应于正在执行的程序的原文件内容 next 执行下一个源程序行，从而执行其整体中的一个函数 print 显示变量或表达式的值 pwd 显示当前工作目录 ptype 显示一个数据结构（如一个结构或C++类）的内容 quit 退出gdb reverse-search 在源文件中反向搜索正规表达式 run 执行该程序 search 在源文件中搜索正规表达式 set variable 给变量赋值 signal 将一个信号发送到正在运行的进程 step 执行下一个源程序行，必要时进入下一个函数 undisplay display 命令的反命令，不要显示表达式 until 结束当前循环 up 上移栈帧，使另一函数成为当前函数 watch 在程序中设置一个监测点（即数据断点） whatis 显示变量或函数类型 九、查看运行时数据在你调试程序时，当程序被停住时，你可以使用print命令（简写命令为p），或是同义命令inspect来查看当前程序的运行数据。print命令的格式是：print print /是表达式，是你所调试的程序的语言的表达式（GDB可以调试多种编程语言），是输出的格式，比如，如果要把表达式按16进制的格式输出，那么就是/x。 表达式print和许多GDB的命令一样，可以接受一个表达式，GDB会根据当前的程序运行的数据来计算这个表达式，既然是表达式，那么就可以是当前程序运行中的const常量、变量、函数等内容。可惜的是GDB不能使用你在程序中所定义的宏。表达式的语法应该是当前所调试的语言的语法，由于C/C++是一种大众型的语言，所以，本文中的例子都是关于C/C++的。（而关于用GDB调试其它语言的章节，我将在后面介绍）。在表达式中，有几种GDB所支持的操作符，它们可以用在任何一种语言中。@是一个和数组有关的操作符，在后面会有更详细的说明。::指定一个在文件或是一个函数中的变量。{}表示一个指向内存地址的类型为type的一个对象。 程序变量在GDB中，你可以随时查看以下三种变量的值：1、全局变量（所有文件可见的）2、静态全局变量（当前文件可见的）3、局部变量（当前Scope可见的）如果你的局部变量和全局变量发生冲突（也就是重名），一般情况下是局部变量会隐藏全局变量，也就是说，如果一个全局变量和一个函数中的局部变量同名时，如果当前停止点在函数中，用print显示出的变量的值会是函数中的局部变量的值。如果此时你想查看全局变量的值时，你可以使用“::”操作符： 12file::variable function::variable 可以通过这种形式指定你所想查看的变量，是哪个文件中的或是哪个函数中的。例如，查看文件f2.c中的全局变量x的值：1(gdb) p &apos;f2.c&apos;::x 当然，“::”操作符会和C++中的发生冲突，GDB能自动识别“::” 是否C++的操作符，所以你不必担心在调试C++程序时会出现异常。 另外，需要注意的是，如果你的程序编译时开启了优化选项，那么在用GDB调试被优化过的程序时，可能会发生某些变量不能访问，或是取值错误码的情况。这个是很正常的，因为优化程序会删改你的程序，整理你程序的语句顺序，剔除一些无意义的变量等，所以在GDB调试这种程序时，运行时的指令和你所编写指令就有不一样，也就会出现你所想象不到的结果。对付这种情况时，需要在编译程序时关闭编译优化。一般来说，几乎所有的编译器都支持编译优化的开关，例如，GNU的C/C++编译器GCC，你可以使用“-gstabs”选项来解决这个问题。关于编译器的参数，还请查看编译器的使用说明文档。 数组有时候，你需要查看一段连续的内存空间的值。比如数组的一段，或是动态分配的数据的大小。你可以使用GDB的“@”操作符，“@”的左边是第一个内存的地址的值，“@”的右边则你你想查看内存的长度。例如，你的程序中有这样的语句：int *array = (int *) malloc (len * sizeof (int));于是，在GDB调试过程中，你可以以如下命令显示出这个动态数组的取值： 1p *array@len @的左边是数组的首地址的值，也就是变量array所指向的内容，右边则是数据的长度，其保存在变量len中，其输出结果，大约是下面这个样子的：12(gdb) p *array@len $1 = &#123;2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40&#125; 如果是静态数组的话，可以直接用print数组名，就可以显示数组中所有数据的内容了。 输出格式一般来说，GDB会根据变量的类型输出变量的值。但你也可以自定义GDB的输出的格式。例如，你想输出一个整数的十六进制，或是二进制来查看这个整型变量的中的位的情况。要做到这样，你可以使用GDB的数据显示格式： 1234567891011121314151617181920x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 (gdb) p i $21 = 101 (gdb) p/a i $22 = 0x65 (gdb) p/c i $23 = 101 &apos;e&apos; (gdb) p/f i $24 = 1.41531145e-43 (gdb) p/x i $25 = 0x65 (gdb) p/t i $26 = 1100101 查看内存你可以使用examine命令（简写是x）来查看内存地址中的值。x命令的语法如下所示： 1x/ n、f、u是可选的参数。n 是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容。 f 表示显示的格式，参见上面。如果地址所指的是字符串，那么格式可以是s，如果地址是指令地址，那么格式可以是i。u 表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4个bytes。u参数可以用下面的字符来代替，b表示单字节，h表示双字节，w表示四字节，g表示八字节。当我们指定了字节长度后，GDB会从指内存定的内存地址开始，读写指定字节，并把其当作一个值取出来。 n/f/u三个参数可以一起使用。例如：命令：x/3uh 0x54320 表示，从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示。 自动显示你可以设置一些自动显示的变量，当程序停住时，或是在你单步跟踪时，这些变量会自动显示。相关的GDB命令是display。display格式i和s同样被display支持，一个非常有用的命令是：display/i $pc$pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。于是当程序停下后，就会出现源代码和机器指令码相对应的情形，这是一个很有意思的功能。info display查看display设置的自动显示的信息。GDB会打出一张表格，向你报告当然调试中设置了多少个自动显示设置，其中包括，设置的编号，表达式，是否enable。 设置显示选项GDB中关于显示的选项比较多，这里我只例举大多数常用的选项。 12set print address set print address on 打开地址输出，当程序显示函数信息时，GDB会显出函数的参数地址。系统默认为打开的，如：1234(gdb) f #0 set_quotes (lq=0x34c78 &quot;&lt;&lt;&quot;, rq=0x34c88 &quot;&gt;&gt;&quot;) at input.c:530 530 if (lquote != def_lquote) set print address off1关闭函数的参数地址显示，如： (gdb) set print addr off(gdb) f #0 set_quotes (lq=”&lt;&lt;”, rq=”&gt;&gt;”) at input.c:530530 if (lquote != def_lquote) 1show print address 查看当前地址显示选项是否打开。 12set print array set print array on 打开数组显示，打开后当数组显示时，每个元素占一行，如果不打开的话，每个元素则以逗号分隔。这个选项默认是关闭的。与之相关的两个命令如下，我就不再多说了。set print array offshow print array 1set print elements 这个选项主要是设置数组的，如果你的数组太大了，那么就可以指定一个来指定数据显示的最大长度，当到达这个长度时，GDB就不再往下显示了。如果设置为0，则表示不限制。 1show print elements 查看print elements的选项信息。 1set print null-stop 如果打开了这个选项，那么当显示字符串时，遇到结束符则停止显示。这个选项默认为off。 1set print pretty on 如果打开printf pretty这个选项，那么当GDB显示结构体时会比较漂亮。如：12345678$1 = &#123; next = 0x0, flags = &#123; sweet = 1, sour = 1 &#125;, meat = 0x54 &quot;Pork&quot; &#125; 1set print pretty off 关闭printf pretty这个选项，GDB显示结构体时会如下显示：1$1 = &#123;next = 0x0, flags = &#123;sweet = 1, sour = 1&#125;, meat = 0x54 &quot;Pork&quot;&#125; show print pretty查看GDB是如何显示结构体的。 set print sevenbit-strings设置字符显示，是否按“/nnn”的格式显示，如果打开，则字符串或字符数据按/nnn显示，如“/065”。 show print sevenbit-strings查看字符显示开关是否打开。 set print union设置显示结构体时，是否显式其内的联合体数据。例如有以下数据结构：12345678910111213typedef enum &#123;Tree, Bug&#125; Species; typedef enum &#123;Big_tree, Acorn, Seedling&#125; Tree_forms; typedef enum &#123;Caterpillar, Cocoon, Butterfly&#125; Bug_forms; struct thing &#123; Species it; union &#123;Tree_forms tree; Bug_forms bug; &#125; form; &#125;; struct thing foo = &#123;Tree, &#123;Acorn&#125;&#125;; 当打开这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {tree = Acorn, bug = Cocoon}}当关闭这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {...}} show print union查看联合体数据的显示方式set print object在C++中，如果一个对象指针指向其派生类，如果打开这个选项，GDB会自动按照虚方法调用的规则显示输出，如果关闭这个选项的话，GDB就不管虚函数表了。这个选项默认是off。 show print object查看对象选项的设置。 set print static-members这个选项表示，当显示一个C++对象中的内容是，是否显示其中的静态数据成员。默认是on。 show print static-members查看静态数据成员选项设置。 set print vtbl当此选项打开时，GDB将用比较规整的格式来显示虚函数表时。其默认是关闭的。 show print vtbl查看虚函数显示格式的选项。 历史记录当你用GDB的print查看程序运行时的数据时，你每一个print都会被GDB记录下来。GDB会以$1, $2, $3 …..这样的方式为你每一个print命令编上号。于是，你可以使用这个编号访问以前的表达式，如$1。这个功能所带来的好处是，如果你先前输入了一个比较长的表达式，如果你还想查看这个表达式的值，你可以使用历史记录来访问，省去了重复输入。 GDB环境变量你可以在GDB的调试环境中定义自己的变量，用来保存一些调试程序中的运行数据。要定义一个GDB的变量很简单只需。使用GDB的set命令。GDB的环境变量和UNIX一样，也是以$起头。如：set $foo = *object_ptr 使用环境变量时，GDB会在你第一次使用时创建这个变量，而在以后的使用中，则直接对其賦值。环境变量没有类型，你可以给环境变量定义任一的类型。包括结构体和数组。 show convenience该命令查看当前所设置的所有的环境变量。这是一个比较强大的功能，环境变量和程序变量的交互使用，将使得程序调试更为灵活便捷。例如：12set $i = 0 print bar[$i++]-&gt;contents 于是，当你就不必，print bar[0]-&gt;contents, print bar[1]-&gt;contents地输入命令了。输入这样的命令后，只用敲回车，重复执行上一条语句，环境变量会自动累加，从而完成逐个输出的功能。 查看寄存器要查看寄存器的值，很简单，可以使用如下命令： info registers查看寄存器的情况。（除了浮点寄存器） info all-registers查看所有寄存器的情况。（包括浮点寄存器） info registers查看所指定的寄存器的情况。寄存器中放置了程序运行时的数据，比如程序当前运行的指令地址（ip），程序的当前堆栈地址（sp）等等。你同样可以使用print命令来访问寄存器的情况，只需要在寄存器名字前加一个$符号就可以了。如：p $eip。 改变程序的执行 一旦使用GDB挂上被调试程序，当程序运行起来后，你可以根据自己的调试思路来动态地在GDB中更改当前被调试程序的运行线路或是其变量的值，这个强大的功能能够让你更好的调试你的程序，比如，你可以在程序的一次运行中走遍程序的所有分支。 修改变量值修改被调试程序运行时的变量值，在GDB中很容易实现，使用GDB的print命令即可完成。如：1(gdb) print x=4 x=4这个表达式是C/C++的语法，意为把变量x的值修改为4，如果你当前调试的语言是Pascal，那么你可以使用Pascal的语法：x:=4。在某些时候，很有可能你的变量和GDB中的参数冲突，如： 123456(gdb) whatis width type = double (gdb) p width $4 = 13 (gdb) set width=47 Invalid syntax in expression. 因为，set width是GDB的命令，所以，出现了“Invalid syntax in expression”的设置错误，此时，你可以使用set var命令来告诉GDB，width不是你GDB的参数，而是程序的变量名，如：(gdb) set var width=47 另外，还可能有些情况，GDB并不报告这种错误，所以保险起见，在你改变程序变量取值时，最好都使用set var格式的GDB命令。 跳转执行一般来说，被调试程序会按照程序代码的运行顺序依次执行。GDB提供了乱序执行的功能，也就是说，GDB可以修改程序的执行顺序，可以让程序执行随意跳跃。这个功能可以由GDB的jump命令来完：1jump 指定下一条语句的运行点。可以是文件的行号，可以是file:line格式，可以是+num这种偏移量格式。表式着下一条运行语句从哪里开始。注意，jump命令不会改变当前的程序栈中的内容，所以，当你从一个函数跳到另一个函数时，当函数运行完返回时进行弹栈操作时必然会发生错误，可能结果还是非常奇怪的，甚至于产生程序Core Dump。所以最好是同一个函数中进行跳转。 熟悉汇编的人都知道，程序运行时，有一个寄存器用于保存当前代码所在的内存地址。所以，jump命令也就是改变了这个寄存器中的值。于是，你可以使用“set $pc”来更改跳转执行的地址。如：set $pc = 0x485 产生信号量使用singal命令，可以产生一个信号量给被调试的程序。如：中断信号Ctrl+C。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号非常有利程序的调试。 语法是：signal ，UNIX的系统信号量通常从1到15。所以取值也在这个范围。single命令和shell的kill命令不同，系统的kill命令发信号给被调试程序时，是由GDB截获的，而single命令所发出一信号则是直接发给被调试程序的。 强制函数返回如果你的调试断点在某个函数中，并还有语句没有执行完。你可以使用return命令强制函数忽略还没有执行的语句并返回。return使用return命令取消当前函数的执行，并立即返回，如果指定了，那么该表达式的值会被认作函数的返回值。 强制调用函数 call表达式中可以一是函数，以此达到强制调用函数的目的。并显示函数的返回值，如果函数返回值是void，那么就不显示。 另一个相似的命令也可以完成这一功能——print，print后面可以跟表达式，所以也可以用他来调用函数，print和call的不同是，如果函数返回void，call则不显示，print则显示函数返回值，并把该值存入历史数据中。 GDB支持下列语言：C, C++, Fortran, PASCAL, Java, Chill, assembly, 和 Modula-2。一般说来，GDB会根据你所调试的程序来确定当然的调试语言，比如：发现文件名后缀为“.c”的，GDB会认为是C程序。文件名后缀为“.C, .cc, .cp, .cpp, .cxx, .c++”的，GDB会认为是C++程序。而后缀是“.f, .F”的，GDB会认为是Fortran程序，还有，后缀为如果是“.s, .S”的会认为是汇编语言。 也就是说，GDB会根据你所调试的程序的语言，来设置自己的语言环境，并让GDB的命令跟着语言环境的改变而改变。比如一些GDB命令需要用到表达式或变量时，这些表达式或变量的语法，完全是根据当前的语言环境而改变的。例如C/C++中对指针的语法是*p，而在Modula-2中则是p^。并且，如果你当前的程序是由几种不同语言一同编译成的，那到在调试过程中，GDB也能根据不同的语言自动地切换语言环境。这种跟着语言环境而改变的功能，真是体贴开发人员的一种设计。 下面是几个相关于GDB语言环境的命令：show language查看当前的语言环境。如果GDB不能识为你所调试的编程语言，那么，C语言被认为是默认的环境。 info frame查看当前函数的程序语言。 info source查看当前文件的程序语言。如果GDB没有检测出当前的程序语言，那么你也可以手动设置当前的程序语言。使用set language命令即可做到。当set language命令后什么也不跟的话，你可以查看GDB所支持的语言种类：123456789101112(gdb) set language The currently understood settings are: local or auto Automatic setting based on source file c Use the C language c++ Use the C++ language asm Use the Asm language chill Use the Chill language fortran Use the Fortran language java Use the Java language modula-2 Use the Modula-2 language pascal Use the Pascal language scheme Use the Scheme language 于是你可以在set language后跟上被列出来的程序语言名，来设置当前的语言环境。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由Leetcode807引发的memset问题]]></title>
    <url>%2F2019%2F04%2F09%2F%E7%94%B1Leetcode807%E5%BC%95%E5%8F%91%E7%9A%84memset%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[做Leetcode807时遇到了memset初始化整个数组的问题，好久不用memset了，有些生疏了。 对数组来说，只能初始化为0，或者-1，其他的时候数字是不正确的。而对于字符数组来说，任意字符都可以。 123456789101112131415161718192021222324252627// 1. 字符数组初始化为&apos;A&apos;char a[5];memset(a, &apos;A&apos;, 5); // OK!memset(a, 0, sizeof(char) * 5); // OK! // 2. 整数数组初始化为0int a[5];memset(a, 0, sizeof(int) * 5); // OK!memset(a, 0, 20); // OK! // 3. 动态字符数组初始化为&apos;A&apos;char* a = new char[5];memset(a, &apos;A&apos;, 5); // OK!memset(a, 0, sizeof(char) * 5); // OK! // 错误用法及改正用法示例：memset(a, &apos;A&apos;, sizeof(a)); // wrong! sizeof(a)相当于sizeof(char*)memset(a, &apos;A&apos;, sizeof(a[0]) * 5); // OK! // 4. 整数数组初始化为非0int a[5];fill(a, a+5, 1); // OK!fill_n(a, 5, 1); // OK! // 错误用法示例：memset(a, 1, 5); // wrong!memset(a, 1, sizeof(int) * 5) // wrong! 字符数组是字符型的，字符型占据内存大小是1Byte，而memset函数也是以字节为单位进行赋值的，所以你输出没有问题。而int数组是整型的，使用 memset还是按字节赋值，这样赋值完以后，每个数组元素的值实际上是0x01010101即十进制的16843009 memset主要用于字符型数组的初始化，整数型数组初始化为0时可以用memset。 memset在初始化动态数组时不能sizeof(数组名)，而应该sizeof(元素)*元素个数。 fill (fill_n)是超级大法，万物皆可fill。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode807. Max Increase to Keep City Skyline]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode807-Max-Increase-to-Keep-City-Skyline%2F</url>
    <content type="text"><![CDATA[Max Increase to Keep City SkylineMedium In a 2 dimensional array grid, each value grid[i][j] represents the height of a building located there. We are allowed to increase the height of any number of buildings, by any amount (the amounts can be different for different buildings). Height 0 is considered to be a building as well. At the end, the “skyline” when viewed from all four directions of the grid, i.e. top, bottom, left, and right, must be the same as the skyline of the original grid. A city’s skyline is the outer contour of the rectangles formed by all the buildings when viewed from a distance. See the following example. What is the maximum total sum that the height of the buildings can be increased? Example:123456789101112131415161718Input: grid = [[3,0,8,4],[2,4,5,7],[9,2,6,3],[0,3,1,0]]Output: 35Explanation: The grid is:[ [3, 0, 8, 4], [2, 4, 5, 7], [9, 2, 6, 3], [0, 3, 1, 0] ]The skyline viewed from top or bottom is: [9, 4, 8, 7]The skyline viewed from left or right is: [8, 7, 9, 3]The grid after increasing the height of buildings without affecting skylines is:gridNew = [ [8, 4, 8, 7], [7, 4, 7, 7], [9, 4, 8, 7], [3, 3, 3, 3] ] Notes: 1 &lt; grid.length = grid[0].length &lt;= 50. All heights grid[i][j] are in the range [0, 100]. All buildings in grid[i][j] occupy the entire grid cell: that is, they are a 1 x 1 x grid[i][j] rectangular prism. 这道题非常简单，首先找到每行每列的最大值，然后每个元素要小于对应的最大值中的小者，比如grid[0][0]要小于topmax[0]和leftmax[0]之中的最小值，grid[0][1]要小于topmax[0]和leftmax[1]之中的最小值。为什么花了这么长时间呢，是因为傻逼了，max数组设成了4爆了。。。煞笔。。。 1234567891011121314151617181920212223class Solution &#123;public: int maxIncreaseKeepingSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int length = grid[0].size(); int* topmax,*leftmax; topmax=(int*)malloc(sizeof(int)*length); leftmax=(int*)malloc(sizeof(int)*length); for(int i=0;i&lt;length;i++) topmax[i]=leftmax[i]=0; for(int i=0;i&lt;length;i++) for(int j=0;j&lt;length;j++)&#123; if(grid[i][j]&gt;topmax[i]) topmax[i]=grid[i][j]; if(grid[i][j]&gt;leftmax[j]) leftmax[j]=grid[i][j]; &#125; int result=0; for(int i=0;i&lt;length;i++) for(int j=0;j&lt;length;j++) result += ((leftmax[j]&gt;topmax[i]?topmax[i]:leftmax[j])-grid[i][j]); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++标准库之stack]]></title>
    <url>%2F2019%2F04%2F09%2FC-%E6%A0%87%E5%87%86%E5%BA%93%E4%B9%8Bstack%2F</url>
    <content type="text"><![CDATA[函数名 功能 复杂度 size() 返回栈的元素数 O(1) top() 返回栈顶的元素 O(1) pop() 从栈中取出并删除元素 O(1) push(x) 向栈中添加元素x O(1) empty() 在栈为空时返回true O(1) 贴一些代码12345678910111213141516171819202122#include &quot;stdafx.h&quot;#include&lt;iostream&gt;#include&lt;stack&gt;using namespace std;int main()&#123; stack&lt;int&gt; S; S.push(3); S.push(7); S.push(1); cout &lt;&lt; S.size() &lt;&lt; &quot; &quot;; cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.push(5); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; endl; return 0;&#125;]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1021. Remove Outermost Parentheses]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode1021-Remove-Outermost-Parentheses%2F</url>
    <content type="text"><![CDATA[Remove Outermost ParenthesesEasy A valid parentheses string is either empty (“”), “(“ + A + “)”, or A + B, where A and B are valid parentheses strings, and + represents string concatenation. For example, “”, “()”, “(())()”, and “(()(()))” are all valid parentheses strings. A valid parentheses string S is primitive if it is nonempty, and there does not exist a way to split it into S = A+B, with A and B nonempty valid parentheses strings. Given a valid parentheses string S, consider its primitive decomposition: S = P_1 + P_2 + … + P_k, where P_i are primitive valid parentheses strings. Return S after removing the outermost parentheses of every primitive string in the primitive decomposition of S. Example 1:12345Input: &quot;(()())(())&quot;Output: &quot;()()()&quot;Explanation: The input string is &quot;(()())(())&quot;, with primitive decomposition &quot;(()())&quot; + &quot;(())&quot;.After removing outer parentheses of each part, this is &quot;()()&quot; + &quot;()&quot; = &quot;()()()&quot;. Example 2:12345Input: &quot;(()())(())(()(()))&quot;Output: &quot;()()()()(())&quot;Explanation: The input string is &quot;(()())(())(()(()))&quot;, with primitive decomposition &quot;(()())&quot; + &quot;(())&quot; + &quot;(()(()))&quot;.After removing outer parentheses of each part, this is &quot;()()&quot; + &quot;()&quot; + &quot;()(())&quot; = &quot;()()()()(())&quot;. Example 3:12345Input: &quot;()()&quot;Output: &quot;&quot;Explanation: The input string is &quot;()()&quot;, with primitive decomposition &quot;()&quot; + &quot;()&quot;.After removing outer parentheses of each part, this is &quot;&quot; + &quot;&quot; = &quot;&quot;. Note: S.length &lt;= 10000 S[i] is “(“ or “)” S is a valid parentheses string 比较简单，把最外边的一层括号移走，可以用栈，也可以用计数器。如果遇到左括号且栈不空说明这个左括号不是外边的括号，加到结果中，再把这个左括号压栈；如果是右括号，就先弹出栈，再判断如果栈不空则说明这个右括号也不是外边的括号，加到结果中。 不知道为啥我这个这么慢，反正过了就行。 123456789101112131415161718192021class Solution &#123;public: string removeOuterParentheses(string S) &#123; string result=&quot;&quot;; int length = S.length(); int ss=0; for(int i=0;i&lt;length;i++)&#123; if(S[i]==&apos;(&apos;)&#123; if(ss!=0) result=result+&apos;(&apos;; ss++; &#125; else if(S[i]==&apos;)&apos;)&#123; ss--; if(ss!=0) result=result+&quot;)&quot;; &#125; &#125; return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode9. Palindrome Number]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode9-Palindrome-Number%2F</url>
    <content type="text"><![CDATA[Palindrome NumberEasy Determine whether an integer is a palindrome. An integer is a palindrome when it reads the same backward as forward. Example 1:12Input: 121Output: true Example 2:123Input: -121Output: falseExplanation: From left to right, it reads -121. From right to left, it becomes 121-. Therefore it is not a palindrome. Example 3:123Input: 10Output: falseExplanation: Reads 01 from right to left. Therefore it is not a palindrome. Follow up: Could you solve it without converting the integer to a string? 回文数，如果是负数直接返回false，正数的话转成string再判断。 12345678910111213141516171819202122class Solution &#123;public: bool isPalindrome(int x) &#123; int i=0; if(x&lt;0) return false; int length = 0; int str[100000]; while(x&gt;0)&#123; str[i++]=(x%10); x/=10; &#125; int middle = i/2; int j=0; while(j&lt;middle)&#123; if(str[j]!=str[i-1-j]) return false; j++; &#125; return true; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode26. Remove Duplicates from Sorted Array]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode26-Remove-Duplicates-from-Sorted-Array%2F</url>
    <content type="text"><![CDATA[Remove Duplicates from Sorted ArrayEasy Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1:12345Given nums = [1,1,2],Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively.It doesn&apos;t matter what you leave beyond the returned length. Example 2:12345Given nums = [0,0,1,1,1,2,2,3,3,4],Your function should return length = 5, with the first five elements of nums being modified to 0, 1, 2, 3, and 4 respectively.It doesn&apos;t matter what values are set beyond the returned length. Clarification: Confused why the returned value is an integer but your answer is an array? Note that the input array is passed in by reference, which means modification to the input array will be known to the caller as well. Internally you can think of this:12345678// nums is passed in by reference. (i.e., without making a copy)int len = removeDuplicates(nums);// any modification to nums in your function would be known by the caller.// using the length returned by your function, it prints the first len elements.for (int i = 0; i &lt; len; i++) &#123; print(nums[i]);&#125; 真的是非常简单的一道题，但是因为某种原因WA了好几次。。。去掉重复的数并返回去重之后的长度。12345678910111213141516class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; int length=nums.size(); if(length==0) return 0; int j=0; for(int i=1;i&lt;length;i++)&#123; if(nums[i]!=nums[j])&#123; j++; nums[j]=nums[i]; &#125; &#125; return j+1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1.Two Sum]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode1-Two-Sum%2F</url>
    <content type="text"><![CDATA[Two SumEasy Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example:12345Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 也十分简单，不知道啥时候做的了，现在补上。就是找一对数，使二者之和等于target，可以暴力，也可以用巧妙的方法，下边有巧妙方法，是从solution中找的。 我的方法：12345678910111213141516class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; vector&lt;int&gt; result; int length = nums.size(),j=-1; for(int i=0;i&lt;length;i++)&#123; for(j=i+1;j&lt;length;j++) if(nums[j]==target-nums[i])&#123; result.push_back(i); result.push_back(j); return result; &#125; &#125; return result; &#125;&#125;; 跟我一样的方法，用java实现：12345678910111213public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i], i); &#125; for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement) &amp;&amp; map.get(complement) != i) &#123; return new int[] &#123; i, map.get(complement) &#125;; &#125; &#125; throw new IllegalArgumentException(&quot;No two sum solution&quot;);&#125; 第三种方法：One-pass Hash TableIt turns out we can do it in one-pass. While we iterate and inserting elements into the table, we also look back to check if current element’s complement already exists in the table. If it exists, we have found a solution and return immediately.1234567891011public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement)) &#123; return new int[] &#123; map.get(complement), i &#125;; &#125; map.put(nums[i], i); &#125; throw new IllegalArgumentException(&quot;No two sum solution&quot;);&#125; 反正都是很简单的。。。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode2. Add Two Numbers]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode2-Add-Two-Numbers%2F</url>
    <content type="text"><![CDATA[Add Two NumbersMedium You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example:123Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 非常简单，给两个链表，相当于两个数，不过是倒着的，然后求这两个数的和再转换成链表。只是第一次用类的方法做题，不太习惯，然后对链表的使用也快忘光了，这是一个良好的开始吧。 1234567891011121314151617181920212223242526272829303132/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; long int ll1=0,ll2=0,result = 0; ListNode* head=new ListNode(0); ListNode* curr=head; int t=0;//jinwei while(l1 != NULL || l2 != NULL)&#123; ll1 = (l1!=NULL)? l1-&gt;val:0; ll2 = (l2!=NULL)? l2-&gt;val:0; int sum=t+ll1+ll2; t=sum/10; curr-&gt;next=new ListNode(sum%10); curr=curr-&gt;next; if(l1!=NULL) l1=l1-&gt;next; if(l2!=NULL) l2=l2-&gt;next; &#125; if(t&gt;0) &#123; curr-&gt;next=new ListNode(t); &#125; return head-&gt;next; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给自己的博客加上各种控件]]></title>
    <url>%2F2019%2F04%2F05%2F%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%8A%A0%E4%B8%8A%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[1&lt;!-- &lt;iframe src=&quot;/resource/test_pdf.pdf&quot; width=&quot;700&quot; height=&quot;600&quot;&gt;&lt;/iframe&gt; --&gt; 12&lt;input type=&quot;button&quot; value=&quot;我是一个按钮&quot;onclick=&quot;javascrtpt:window.location.href=&apos;http://blog.sina.com.cn/mleavs&apos;&quot;&gt; 触发一个函数跳转：1234567&lt;script&gt;function jump()&#123; window.location.href=&quot;http://blog.sina.com.cn/mleavs&quot;;&#125;&lt;/script&gt;&lt;input type=&quot;button&quot; value=&quot;我是一个按钮&quot; onclick=javascrtpt:jump()&gt; 如何给自己的博客加上图片，这是一个介绍，也是备忘。 1.首先把blog（hexo）目录下的_config.yml里的post_asset_folder:设置为true； 2.在blog（hexo）目录下执行:1npm install hexo-asset-image --save 3.在blog（hexo）目录下运行hexo n “博客名”来生成md博客时，会在_post目录下看到一个与博客同名的文件夹。 4.将想要上传的图片先扔到文件夹下，然后在博客中使用markdown的格式引入图片：1![你想要输入的替代文字](xxxx/图片名.jpg) ps：因为博客名和文件夹名字相同，所以不需要绝对路径，只要xxxx是文件夹的名字就可以了。 5.然后，使用hexo g部署的时候，进入public\2018\04\19\index.html文件中查看相关字段，可以发现html标签内的语句是img src = “2018/04/19/xxxx/图片名.jpg”而不是img src=”xxxx.图片名.jpg”，这就成功了，当然前面步骤操作正确的话，这一步也不用检查。 6.测试的话当然要拿微博小姐姐来测试啦，附上微博链接严屹南啊 这是第一种方法，也可以在source文件夹下建立img文件夹，把要引用的图片文件放到这个文件夹里，然后使用/img/...使用图片，测试如下 1![微博上最喜欢的小姐姐](/img/1.jpg)]]></content>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统研究的一些视频与文章]]></title>
    <url>%2F2019%2F04%2F05%2F%E5%BE%AE%E5%8D%9A%E7%9C%8B%E5%88%B0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%A0%94%E7%A9%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E8%A7%86%E9%A2%91%E4%B8%8E%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[Videos Perspectives on Research Productivity (In Chinese) What My Mentors Taught Me (In Chinese) A Reflection on First 10 Years in Academia (In Chinese) Articles How (and How Not) to Write a Good Systems Paper (In English) Slides(In Chinese) How to Read a CS Research Paper? (In English) THE PH.D. GRIND (In English) 一名系统研究者的攀登之路 (In Chinese) 与学生合作开展研究的体会 (In Chinese) 对计算机体系结构研究的一点认识 (In Chinese) 印度 Bangalore 之 HPCA/PPoPP-2010 与会小记 (In Chinese) ISCA-2014与北美学术之旅 (In Chinese) PACT-2015 PC讨论会记录 (In Chinese) 博士五年总结 (In Chinese) 系统设计黄金法则: 简单之美 (In Chinese) 你的学生就是你的财富 (In Chinese) Your Students Are Your Legacy(In English) ISCA08见闻 (In Chinese) 与新晋图灵奖得主的虚拟对话 (In Chinese) 关于“国家重点实验室应该追求什么”的讨论 (In Chinese) SOSP 2013 Analysis (In Chinese) OSDI, SOSP与美国著名计算机系的调查 (In Chinese) HIT CS科班对计算机专业领域的汇编 (In Chinese) Prolific System Scholars (to 2013) (In English) ASPLOS系列专访—Mark D. Hill 谈体系结构：中国正从跟随者到创新领导者 (In Chinese) ASPLOS系列专访—Shan Lu谈bug finding：学术研究应超前于产品 (In Chinese) ASPLOS系列专访—李涛谈学术研究和学生培养 (In Chinese)]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What I want to learn]]></title>
    <url>%2F2019%2F04%2F04%2Fbookmark%2F</url>
    <content type="text"><![CDATA[Markdown参考https://blog.csdn.net/u014061630/article/details/81359144 想读的书《深度探索C++对象模型（Inside The C++ Object Model ）》 《algorithm》 《UNIX环境高级编程》 《数据结构与算法经典问题解析》 《高性能并行珠玑》 各种书签矩阵求导刘咏彬分享 汇编语言8086笔记 比较长，正在看 C++智能指针 不基于旋转的treap 数据结构与算法(c++)——跳跃表(skip list) 块状链表 字典树(Trie树) Targan算法 有向图强连通分量 树状数组 2-3-4Tree 后台开发面试问题整理 解读Raft（一 算法基础） Linux进程调度原理 slab机制 Linux的任务调度机制 彻底弄懂HTTP缓存机制及原理 利用CAS操作（Compare &amp; Set）实现无锁队列 TCP的数据流——滑动窗口，拥塞窗口，慢启动，Nagle算法，经受时延的确认等 TCP协议总结–停止等待协议,连续ARQ协议,滑动窗口协议 mysql数据库面试总结 学习笔记数据库设计三大范式与BCNF，学习笔记 常见面试题整理–数据库篇（每位开发者必备） 深入理解计算机系统之虚拟存储器 tcp的半连接与完全连接队列 - go4it - 简书 数位dp总结 之 从入门到模板 类中函数的重载、隐藏和覆盖 参考别人的面试总结：linux C/C++服务器后台开发面试题总结 linux C/C++服务器后台开发面试题总结 IP分片和TCP分片的区别 C++模板元编程（C++ template metaprogramming） - 文章 - 伯乐在线 C++后台开发校招面试常见问题 互斥锁的实现（转） TCP-IP详解：糊涂窗口综合症（Silly Window syndrome） 浅析Linux下的task_struct结构体 C++虚继承的概念 c++ 虚继承与继承的差异 STL源码剖析—红黑树原理详解上 CSDN博客 valgrind 的使用简介 堆排算法的分析与总结 HTTP必知必会——常见面试题总结 ORM框架使用优缺点 高性能服务开发之定时器 Https协议详解 图解SSL/TLS协议 - 阮一峰的网络日志 HTTPS 原理解析 Linux的用户和用户组管理 TCP系列13—重传—3、协议中RTO计算和RTO定时器维护 Linux内核中cache的实现 【经典算法】——KMP，深入讲解next数组的求解 HTTP Session、Cookie机制详解 HttpSession详解 HTTP的长连接和短连接 linux内核之进程的基本概念(进程，进程组，会话关系） Linux–进程组、会话、守护进程 银行家算法学习笔记 linux session 浅谈 关系型数据库到文档型数据库的跨越 数据库设计三大范式 常见面试题整理–数据库篇 谈谈数据库的ACID 关于TCP乱序和重传的问题 DNS 原理入门 - 阮一峰的网络日志 数据结构专题——线段树 一步一步理解线段树 mysql 数据表读锁机制详解 关于C++中公有继承、私有继承、保护继承的讨论 Linux进程同步之记录锁（fcntl） Linux 伙伴算法简介 HTTP详解(1)-工作原理 浅谈数位DP 缓存淘汰算法–LRU算法 - 小程故事多 - ITeye博客 socket编程中write、read和send、recv之间的区别 树状数组彻底入门 浅谈数据库查询优化的几种思路 - 六尺帐篷 - 简书 【经典数据结构】B树与B+树 胜者树与败者树 拓扑排序的原理及其实现 Manacher算法–O(n)回文子串算法 二叉树、B树、B+树、B*树 B树、B-树、B+树、B*树详解（转） 红黑树(一)之 原理和算法详细介绍 平衡二叉树详解]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp的tr1_function使用]]></title>
    <url>%2F2019%2F04%2F04%2Fcpp%E7%9A%84std_tr1_function%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍 function是一种通用、多态的函数封装。std::function的实例可以对任何可以调用的目标 进行存储、复制、和调用操作，这些目标包括函数、lambda表达式、绑定表达式、以及其它函数对象等。（c++11起的版本可用） function（和bind一样）可以实现类似函数指针的功能，却比函数指针更加灵活（体现在占位符上面），尤其是在很多成员调用同一个函数（仅仅是参数类型不同）的时候比较方便。 特点： 1.可以作为函数和成员函数。 2.可做回调函数，取代函数指针。 3.可作为函数的参数，从外部控制函数内部的行为。 示例代码 先看一下下面这块代码： 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;tr1/functional&gt;typedef std::tr1::function&lt;void()&gt; HandleEvent;class Animal&#123;public: Animal()&#123;&#125; ~Animal()&#123;&#125; static void Move()&#123; std::cout&lt;&lt;&quot;I am moving...\n&quot;; &#125;&#125;;class Fish: public Animal&#123;public: Fish()&#123;&#125; ~Fish()&#123;&#125; static void Move()&#123; std::cout&lt;&lt;&quot;I am swimming...\n&quot;; &#125;&#125;;int main()&#123; std::tr1::function&lt;void()&gt; move = &amp;Animal::Move; move(); move = &amp;Fish::Move; move(); return 0;&#125; Animal类是父类，Fish继承于Animal。测试程序中分别将子类和父类的Move()函数地址赋值给function的指针。调用的结果如下： 12I am moving… I am swimming… 为了体现function可以作为函数的参数传入，我们再写一个函数加到原来的代码中进行测试： 1234567891011121314151617181920212223void Moving(int option, std::tr1::function&lt;void()&gt; move)&#123; if(option &amp; 1 == 0)&#123; //如果option为偶数，则执行Animal类中的Move方法 move = &amp;Animal::Move; &#125; else&#123; move = &amp;Fish::Move; &#125; move();&#125;int main()&#123; std::tr1::function&lt;void()&gt; move = &amp;Animal::Move; move(); move = &amp;Fish::Move; move(); std::cout&lt;&lt;&quot;-------------divid line------------\n&quot;; Moving(4,move); return 0;&#125; 测试结果如下： 1234I am moving… I am swimming… ————-divid line———— I am moving…]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
</search>
