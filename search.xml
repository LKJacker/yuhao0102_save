<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Leetcode885. Spiral Matrix III]]></title>
    <url>%2F2019%2F08%2F27%2FLeetcode885%2F</url>
    <content type="text"><![CDATA[On a 2 dimensional grid with R rows and C columns, we start at (r0, c0) facing east. Here, the north-west corner of the grid is at the first row and column, and the south-east corner of the grid is at the last row and column. Now, we walk in a clockwise spiral shape to visit every position in this grid. Whenever we would move outside the boundary of the grid, we continue our walk outside the grid (but may return to the grid boundary later.) Eventually, we reach all R * C spaces of the grid. Return a list of coordinates representing the positions of the grid in the order they were visited. Example 1: Input: R = 1, C = 4, r0 = 0, c0 = 0Output: [[0,0],[0,1],[0,2],[0,3]] Example 2: Input: R = 5, C = 6, r0 = 1, c0 = 4Output: [[1,4],[1,5],[2,5],[2,4],[2,3],[1,3],[0,3],[0,4],[0,5],[3,5],[3,4],[3,3],[3,2],[2,2],[1,2],[0,2],[4,5],[4,4],[4,3],[4,2],[4,1],[3,1],[2,1],[1,1],[0,1],[4,0],[3,0],[2,0],[1,0],[0,0]] 给定起点（r0,c0），螺旋走路，输出经过的点坐标，简单，只是注意细节。按照顺序，先向右走，再向下走，再向左走，再向上走，经观察发现每个方向的步数依次为1,1,2,2,3,3,…，依次类推，按照步骤走即可，发现不在网格内就跳过。 123456789101112131415161718192021222324252627282930class Solution &#123;public: int dir[4][4]=&#123;&#123;0,1&#125;,&#123;1,0&#125;,&#123;0,-1&#125;,&#123;-1,0&#125;&#125;; vector&lt;vector&lt;int&gt;&gt; spiralMatrixIII(int R, int C, int r0, int c0) &#123; vector&lt;vector&lt;int&gt;&gt; res; res.push_back(&#123;r0, c0&#125;); for(int i = 1; res.size() &lt; R * C; i += 2)&#123; for(int j = 0; j &lt; 2; j ++)&#123; for (int k = 0; k &lt; i; k++) &#123; r0 += dir[j][0]; c0 += dir[j][1]; if(0 &lt;= r0 &amp;&amp; r0 &lt; R &amp;&amp; 0 &lt;= c0 &amp;&amp; c0 &lt; C) res.push_back(&#123;r0,c0&#125;); &#125; &#125; for(int j = 2; j &lt; 4; j ++)&#123; for (int k = 0; k &lt; i+1; k++) &#123; r0 += dir[j][0]; c0 += dir[j][1]; if(0 &lt;= r0 &amp;&amp; r0 &lt; R &amp;&amp; 0 &lt;= c0 &amp;&amp; c0 &lt; C) res.push_back(&#123;r0,c0&#125;); &#125; &#125; &#125; return res; &#125;&#125;; 一个大佬给了三种做法： 这道题给了我们一个二维矩阵，还给了其中一个位置，让从这个位置开始螺旋打印矩阵。首先是打印给定的位置，然后向右走一位，打印出来，再向下方走一位打印，再向左边走两位打印，再向上方走三位打印，以此类推，螺旋打印。那仔细观察，可以发现，刚开始只是走一步，后来步子越来越大，若只看每个方向走的距离，可以得到如下数组 1,1,2,2,3,3… 步长有了，下面就是方向了，由于确定了起始是向右走，那么方向就是 右-&gt;下-&gt;左-&gt;上 这样的循环。方向和步长都分析清楚了，现在就可以尝试进行遍历了。由于最终是会遍历完所有的位置的，那么最后结果 res 里面的位置个数一定是等于 RxC 的，所以循环的条件就是当结果 res 中的位置数小于R*C。我们还需要一个变量 step 表示当前的步长，初始化为1。 在循环中，首先要向右走 step 步，一步一步走，走到一个新的位置上，要进行判断，若当前位置没有越界，才能加入结果 res 中，由于每次都要判断，所以把这部分抽取出来，放到一个子函数中。由于是向右走，每走一步之后，c0 都要自增1。右边走完了之后，再向下方走 step 步，同理，每走一步之后，要将 r0 自增1。再向左边走之前，要将步数增1，不然无法形成正确的螺旋，同理，再完成向上方走 step 步之后，step 要再增1，参见代码如下： 解法一：12345678910111213141516171819class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; spiralMatrixIII(int R, int C, int r0, int c0) &#123; vector&lt;vector&lt;int&gt;&gt; res; int step = 1; while (res.size() &lt; R * C) &#123; for (int i = 0; i &lt; step; ++i) add(R, C, r0, c0++, res); for (int i = 0; i &lt; step; ++i) add(R, C, r0++, c0, res); ++step; for (int i = 0; i &lt; step; ++i) add(R, C, r0, c0--, res); for (int i = 0; i &lt; step; ++i) add(R, C, r0--, c0, res); ++step; &#125; return res; &#125; void add(int R, int C, int x, int y, vector&lt;vector&lt;int&gt;&gt;&amp; res) &#123; if (x &gt;= 0 &amp;&amp; x &lt; R &amp;&amp; y &gt;= 0 &amp;&amp; y &lt; C) res.push_back(&#123;x, y&#125;); &#125;&#125;; 可以用两个数组 dirX 和 dirY 来控制下一个方向，就像迷宫遍历中的那样，这样只需要一个变量 cur，来分别到 dirX 和 dirY 中取值，初始化为0，表示向右的方向。从螺旋遍历的机制可以看出，每当向右或者向左前进时，步长就要加1，那么我们只要判断当 cur 为0或者2的时候，step 就自增1。由于 cur 初始化为0，所以刚开始 step 就会增1，那么就可以将 step 初始化为0，同时还需要把起始位置提前加入结果 res 中。此时在 while 循环中只需要一个 for 循环即可，朝当前的 cur 方向前进 step 步，r0 加上 dirX[cur]，c0 加上 dirY[cur]，若没有越界，则加入结果 res 中即可。之后记得 cur 要自增1，为了防止越界，对4取余，就像循环数组一样的操作，参见代码如下： 解法二：1234567891011121314151617class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; spiralMatrixIII(int R, int C, int r0, int c0) &#123; vector&lt;vector&lt;int&gt;&gt; res&#123;&#123;r0, c0&#125;&#125;; vector&lt;int&gt; dirX&#123;0, 1, 0, -1&#125;, dirY&#123;1, 0, -1, 0&#125;; int step = 0, cur = 0; while (res.size() &lt; R * C) &#123; if (cur == 0 || cur == 2) ++step; for (int i = 0; i &lt; step; ++i) &#123; r0 += dirX[cur]; c0 += dirY[cur]; if (r0 &gt;= 0 &amp;&amp; r0 &lt; R &amp;&amp; c0 &gt;= 0 &amp;&amp; c0 &lt; C) res.push_back(&#123;r0, c0&#125;); &#125; cur = (cur + 1) % 4; &#125; return res; &#125;&#125;; 我们也可以不使用方向数组，若仔细观察 右-&gt;下-&gt;左-&gt;上 四个方向对应的值 (0, 1) -&gt; (1, 0) -&gt; (0, -1) -&gt; (-1, 0), 实际上，下一个位置的x值是当前的y值，下一个位置的y值是当前的-x值，因为两个方向是相邻的两个方向是垂直的，由向量的叉乘得到 (x, y, 0) × (0, 0, 1) = (y, -x, 0)。所以可以通过当前的x和y值，来计算出下一个位置的值。同理，根据之前的说的步长数组 1,1,2,2,3,3…，可以推出通项公式为 n/2 + 1，这样连步长变量 step 都省了，不过需要统计当前已经遍历的位置的个数，实在想偷懒，也可以用 res.size() 来代替，参见代码如下： 解法三：123456789101112131415class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; spiralMatrixIII(int R, int C, int r0, int c0) &#123; vector&lt;vector&lt;int&gt;&gt; res&#123;&#123;r0, c0&#125;&#125;; int x = 0, y = 1, t = 0; for (int k = 0; res.size() &lt; R * C; ++k) &#123; for (int i = 0; i &lt; k / 2 + 1; ++i) &#123; r0 += x; c0 += y; if (r0 &gt;= 0 &amp;&amp; r0 &lt; R &amp;&amp; c0 &gt;= 0 &amp;&amp; c0 &lt; C) res.push_back(&#123;r0, c0&#125;); &#125; t = x; x = y; y = -t; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode338. Counting Bits]]></title>
    <url>%2F2019%2F08%2F27%2FLeetcode338%2F</url>
    <content type="text"><![CDATA[Given a non negative integer number num. For every numbers i in the range 0 ≤ i ≤ num calculate the number of 1’s in their binary representation and return them as an array. Example 1: Input: 2Output: [0,1,1]Example 2: Input: 5Output: [0,1,1,2,1,2]Follow up: It is very easy to come up with a solution with run time O(n*sizeof(integer)). But can you do it in linear time O(n) /possibly in a single pass?Space complexity should be O(n).Can you do it like a boss? Do it without using any builtin function like __builtin_popcount in c++ or in any other language. 从低位入手。‘1’的个数等于除了最低位之外的‘1’的个数加上最低位‘1’的个数，即ret[n] = ret[n&gt;&gt;1] + n%2，具体代码：123456789class Solution &#123;public: vector&lt;int&gt; countBits(int num) &#123; vector&lt;int&gt; ret(num+1, 0); for(int i=1; i&lt;=num; ++i) ret[i] = ret[i&gt;&gt;1] + i%2; return ret; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1002. Find Common Characters]]></title>
    <url>%2F2019%2F08%2F27%2FLeetcode1002%2F</url>
    <content type="text"><![CDATA[Given an array A of strings made only from lowercase letters, return a list of all characters that show up in all strings within the list (including duplicates). For example, if a character occurs 3 times in all strings but not 4 times, you need to include that character three times in the final answer. You may return the answer in any order. Example 1: Input: [“bella”,”label”,”roller”]Output: [“e”,”l”,”l”]Example 2: Input: [“cool”,”lock”,”cook”]Output: [“c”,”o”] Note: 1 &lt;= A.length &lt;= 1001 &lt;= A[i].length &lt;= 100A[i][j] is a lowercase letter 这个打表要二维打表，第一次的时候没有注意，用了一维的，所以错了。12345678910111213141516171819202122232425262728293031class Solution &#123;public: vector&lt;string&gt; commonChars(vector&lt;string&gt;&amp; A) &#123; string s; int vis[102][27]=&#123;0&#125;; vector&lt;string&gt; res; for(int i=0;i&lt;A.size();i++)&#123; s = A[i]; for(int j=0;j&lt;A[i].length();j++)&#123; vis[i][s[j]-&apos;a&apos;]++; &#125; &#125; // 打表，记下来每个string中每个字母出现的次数 for(int i=0;i&lt;26;i++)&#123; int minn=1000; for(int j=0;j&lt;A.size();j++) &#123; if(vis[j][i]&lt;minn) minn=vis[j][i]; &#125; //看这个字母在每个string中出现的最少次数， for(int j=0;j&lt;minn;j++)&#123; string s1; s1+=char(&apos;a&apos;+i); res.push_back(s1); &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python的PIL库]]></title>
    <url>%2F2019%2F08%2F27%2Fpython%E7%9A%84PIL%E5%BA%93%2F</url>
    <content type="text"><![CDATA[作者：jiandanjinxin链接：https://www.jianshu.com/p/e8d058767dfa来源：简书 Image读出来的是PIL的类型，而skimage.io读出来的数据是numpy格式的1234567# Image和skimage读图片import Image as imgimport osfrom matplotlib import pyplot as plotfrom skimage import io,transformimg_file1 = img.open(&apos;./CXR_png/MCUCXR_0042_0.png&apos;)img_file2 = io.imread(&apos;./CXR_png/MCUCXR_0042_0.png&apos;) 输出可以看出Img读图片的大小是图片的(width, height)；而skimage的是(height,width, channel), [这也是为什么caffe在单独测试时要要在代码中设置：transformer.set_transpose(‘data’,(2,0,1))，因为caffe可以处理的图片的数据格式是(channel,height,width)，所以要转换数据]123#读图片后数据的大小：print &quot;the picture&apos;s size: &quot;, img_file1.sizeprint &quot;the picture&apos;s shape: &quot;, img_file2.shape 12the picture&apos;s size: (4892, 4020)the picture&apos;s shape: (4020, 4892) 1234#得到像素：print(img_file1.getpixel((500,1000)), img_file2[500][1000])print(img_file1.getpixel((500,1000)), img_file2[1000][500])print(img_file1.getpixel((1000,500)), img_file2[500][1000]) 123(0, 139)(0, 0)(139, 139) Img读出来的图片获得某点像素用getpixel((w,h))可以直接返回这个点三个通道的像素值skimage读出来的图片可以直接img_file2[0][0]获得，但是一定记住它的格式，并不是你想的(channel,height,width) 在图片上面加文字1234567891011#新建绘图对象draw = ImageDraw.Draw(image)，#获取图像的宽和高width, height = image.size；#** ImageFont模块**#选择文字字体和大小setFont = ImageFont.truetype(&apos;C:/windows/fonts/Dengl.ttf&apos;, 20)，#设置文字颜色fillColor = &quot;#ff0000&quot;#写入文字draw.text((40, height - 100), u&apos;广告&apos;, font=setFont, fill=fillColor) 图片信息如果我们想知道一些skimage图片信息12345678910111213from skimage import io, dataimg = data.chelsea()io.imshow(img)print(type(img)) #显示类型print(img.shape) #显示尺寸print(img.shape[0]) #图片高度print(img.shape[1]) #图片宽度print(img.shape[2]) #图片通道数print(img.size) #显示总像素个数print(img.max()) #最大像素值print(img.min()) #最小像素值print(img.mean()) #像素平均值print(img[0][0])#图像的像素值 PIL image 查看图片信息，可用如下的方法123456print type(img)print img.size #图片的尺寸print img.mode #图片的模式print img.format #图片的格式print(img.getpixel((0,0)))#得到像素：#img读出来的图片获得某点像素用getpixel((w,h))可以直接返回这个点三个通道的像素值 123456789101112# 获取图像的灰度值范围width = img.size[0]height = img.size[1]# 输出图片的像素值count = 0 for i in range(0, width): for j in range(0, height): if img.getpixel((i, j))&gt;=0 and img.getpixel((i, j))&lt;=255: count +=1print countprint(height*width) 使用python进行数字图片处理，还得安装Pillow包。虽然python里面自带一个PIL（python images library), 但这个库现在已经停止更新了，所以使用Pillow, 它是由PIL发展而来的。 pil能处理的图片类型pil可以处理光栅图片(像素数据组成的的块)。 通道一个图片可以包含一到多个数据通道，如果这些通道具有相同的维数和深度，Pil允许将这些通道进行叠加12345678910模式1 1位像素，黑和白，存成8位的像素L 8位像素，黑白P 8位像素，使用调色板映射到任何其他模式RGB 3×8位像素，真彩RGBA 4×8位像素，真彩+透明通道CMYK 4×8位像素，颜色隔离YCbCr 3×8位像素，彩色视频格式I 32位整型像素F 32位浮点型像素 坐标Pil采取左上角为(0,0)的坐标系统 图片的打开与显示123from PIL import Imageimg=Image.open(&apos;d:/dog.png&apos;)img.show() 虽然使用的是Pillow，但它是由PIL fork而来，因此还是要从PIL中进行import. 使用open()函数来打开图片，使用show()函数来显示图片。这种图片显示方式是调用操作系统自带的图片浏览器来打开图片，有些时候这种方式不太方便，因此我们也可以使用另上一种方式，让程序来绘制图片。123456789from PIL import Imageimport matplotlib.pyplot as pltimg=Image.open(&apos;d:/dog.png&apos;)plt.figure(&quot;dog&quot;)plt.figure(num=1, figsize=(8,5),)plt.title(&apos;The image title&apos;)plt.axis(&apos;off&apos;) # 不显示坐标轴plt.imshow(img)plt.show() 这种方法虽然复杂了些，但推荐使用这种方法，它使用一个matplotlib的库来绘制图片进行显示。matplotlib是一个专业绘图的库，相当于matlab中的plot,可以设置多个figure,设置figure的标题，甚至可以使用subplot在一个figure中显示多张图片。matplotlib 可以直接安装.figure默认是带axis的，如果没有需要，我们可以关掉1plt.axis(&apos;off&apos;) 图像加标题1plt.title(&apos;The image title&apos;) matplotlib标准模式123456plt.figure(num=5, figsize=(8,5),)#plt.figure(num=&apos;newimage&apos;, figsize=(8,5),)plt.title(&apos;The image title&apos;, color=&apos;#0000FF&apos;)plt.imshow(lena) # 显示图片plt.axis(&apos;off&apos;) # 不显示坐标轴plt.show() PIL image 查看图片信息，可用如下的方法1234print type(img)print img.size #图片的尺寸print img.mode #图片的模式print img.format #图片的格式 图片的保存1img.save(&apos;d:/dog.jpg&apos;) 就一行代码，非常简单。这行代码不仅能保存图片，还是转换格式，如本例中，就由原来的png图片保存为了jpg图片。 图像通道\几何变换\裁剪PIL可以对图像的颜色进行转换，并支持诸如24位彩色、8位灰度图和二值图等模式，简单的转换可以通过Image.convert(mode)函数完 成，其中mode表示输出的颜色模式，例如’’L’’表示灰度，’’1’’表示二值图模式等。但是利用convert函数将灰度图转换为二值图时，是采用 固定的阈 值127来实现的，即灰度高于127的像素值为1，而灰度低于127的像素值为0。 彩色图像转灰度图123456789from PIL import Imageimport matplotlib.pyplot as pltimg=Image.open(&apos;d:/ex.jpg&apos;)gray=img.convert(&apos;L&apos;)plt.figure(&quot;beauty&quot;)plt.imshow(gray,cmap=&apos;gray&apos;)plt.axis(&apos;off&apos;)plt.title(&apos;The color image to gray image&apos;)plt.show() 使用函数convert()来进行转换，它是图像实例对象的一个方法，接受一个 mode 参数，用以指定一种色彩模式，mode 的取值可以是如下几种： 1 (1-bit pixels, black and white, stored with one pixel per byte) L (8-bit pixels, black and white) P (8-bit pixels, mapped to any other mode using a colour palette) RGB (3x8-bit pixels, true colour) RGBA (4x8-bit pixels, true colour with transparency mask) CMYK (4x8-bit pixels, colour separation) YCbCr (3x8-bit pixels, colour video format) I (32-bit signed integer pixels) F (32-bit floating point pixels) 通道分离与合并1234567891011121314151617181920from PIL import Imageimport matplotlib.pyplot as pltimg=Image.open(&apos;d:/ex.jpg&apos;) #打开图像gray=img.convert(&apos;L&apos;) #转换成灰度r,g,b=img.split() #分离三通道pic=Image.merge(&apos;RGB&apos;,(r,g,b)) #合并三通道plt.figure(&quot;beauty&quot;)plt.subplot(2,3,1), plt.title(&apos;origin&apos;)plt.imshow(img),plt.axis(&apos;off&apos;)plt.subplot(2,3,2), plt.title(&apos;gray&apos;)plt.imshow(gray,cmap=&apos;gray&apos;),plt.axis(&apos;off&apos;)plt.subplot(2,3,3), plt.title(&apos;merge&apos;)plt.imshow(pic),plt.axis(&apos;off&apos;)plt.subplot(2,3,4), plt.title(&apos;r&apos;)plt.imshow(r,cmap=&apos;gray&apos;),plt.axis(&apos;off&apos;)plt.subplot(2,3,5), plt.title(&apos;g&apos;)plt.imshow(g,cmap=&apos;gray&apos;),plt.axis(&apos;off&apos;)plt.subplot(2,3,6), plt.title(&apos;b&apos;)plt.imshow(b,cmap=&apos;gray&apos;),plt.axis(&apos;off&apos;)plt.show() 水平拼接图片给老板整理材料，顺手写了两个脚本，拼接图片用的123456789101112131415161718192021222324252627282930313233343536import osfrom PIL import Imageimport sysfile_num = len(sys.argv) - 2;quali = int(sys.argv[1])file_list = sys.argv[2:]print(file_list)min_height=999999sum_width = 0img_list=[]for file_name in file_list: img = Image.open(file_name) img_list.append(img) if(img.size[1]&lt;min_height): min_height = img.size[1] sum_width = sum_width + img.size[0]print(&quot;asdf&quot;)out_list=[]for file_name in file_list: img = Image.open(file_name) out = img.resize((img.size[0],min_height),Image.ANTIALIAS) #resize image with high-quality out.save(file_name)target = Image.new(&apos;RGB&apos;,(sum_width,min_height))left = 0right = 0for file_name in file_list: image = Image.open(file_name) right += image.size[0] target.paste(image,(left,0,right,min_height)) print(&quot;aaa&quot;) left += image.size[0] #right += image.size[1]target.save(&apos;result.jpg&apos;,quality=quali) 竖直拼接图片123456789101112131415161718192021222324252627282930313233343536import osfrom PIL import Imageimport sysfile_num = len(sys.argv) - 2;quali = int(sys.argv[1])file_list = sys.argv[2:]print(file_list)min_width=999999sum_height = 0img_list=[]for file_name in file_list: img = Image.open(file_name) img_list.append(img) if(img.size[0]&lt;min_width): min_width = img.size[0] sum_height = sum_height + img.size[1]print(&quot;asdf&quot;)out_list=[]for file_name in file_list: img = Image.open(file_name) out = img.resize((min_width,img.size[1]),Image.ANTIALIAS) #resize image with high-quality out.save(file_name)target = Image.new(&apos;RGB&apos;,(min_width,sum_height))left = 0right = 0for file_name in file_list: image = Image.open(file_name) right += image.size[1] target.paste(image,(0,left,min_width,right)) print(&quot;aaa&quot;) left += image.size[1] #right += image.size[1]target.save(&apos;result.jpg&apos;,quality=quali) 裁剪图片从原图片中裁剪感兴趣区域（roi),裁剪区域由4-tuple决定，该tuple中信息为(left, upper, right, lower)。 Pillow左边系统的原点（0，0）为图片的左上角。坐标中的数字单位为像素点。1234567891011121314from PIL import Imageimport matplotlib.pyplot as pltimg=Image.open(&apos;d:/ex.jpg&apos;) #打开图像plt.figure(&quot;beauty&quot;)plt.subplot(1,2,1), plt.title(&apos;origin&apos;)plt.imshow(img),plt.axis(&apos;off&apos;)#box变量是一个四元组(左，上，右，下)。 box=(80,100,260,300)roi=img.crop(box)plt.subplot(1,2,2)plt.title(&apos;roi&apos;)plt.imshow(roi)plt.axis(&apos;off&apos;)plt.show() 用plot绘制显示出图片后，将鼠标移动到图片上，会在右下角出现当前点的坐标，以及像素值。 几何变换Image类有resize()、rotate()和transpose()方法进行几何变换。图像的缩放和旋转12dst = img.resize((128, 128))dst = img.rotate(45) # 顺时针角度表示 转换图像12345dst = im.transpose(Image.FLIP_LEFT_RIGHT) #左右互换dst = im.transpose(Image.FLIP_TOP_BOTTOM) #上下互换dst = im.transpose(Image.ROTATE_90) #顺时针旋转dst = im.transpose(Image.ROTATE_180)dst = im.transpose(Image.ROTATE_270) transpose()和rotate()没有性能差别。 python图像处理库Image模块创建一个新的图片12Image.new(mode, size) Image.new(mode, size, color) 层叠图片层叠两个图片，img2和img2,alpha是一个介于[0,1]的浮点数，如果为0，效果为img1，如果为1.0，效果为img2。当然img1和img2的尺寸和模式必须相同。这个函数可以做出很漂亮的效果来，而图形的算术加减后边会说到。1Image.blend(img1, img2, alpha) composite可以使用另外一个图片作为蒙板(mask)，所有的这三张图片必须具备相同的尺寸，mask图片的模式可以为“1”，“L”，“RGBA”1Image.composite(img1, img2, mask) 添加水印添加文字水印12345678from PIL import Image, ImageDraw,ImageFontim = Image.open(&quot;d:/pic/lena.jpg&quot;).convert(&apos;RGBA&apos;)txt=Image.new(&apos;RGBA&apos;, im.size, (0,0,0,0))fnt=ImageFont.truetype(&quot;c:/Windows/fonts/Tahoma.ttf&quot;, 20)d=ImageDraw.Draw(txt)d.text((txt.size[0]-80,txt.size[1]-30), &quot;cnBlogs&quot;,font=fnt, fill=(255,255,255,255))out=Image.alpha_composite(im, txt)out.show() 添加小图片水印1234567from PIL import Imageim = Image.open(&quot;d:/pic/lena.jpg&quot;)mark=Image.open(&quot;d:/logo_small.gif&quot;)layer=Image.new(&apos;RGBA&apos;, im.size, (0,0,0,0))layer.paste(mark, (im.size[0]-150,im.size[1]-60))out=Image.composite(layer,im,layer)out.show() PIL Image 图像互转 numpy 数组将 PIL Image 图片转换为 numpy 数组12im_array = np.array(im)# 也可以用 np.asarray(im) 区别是 np.array() 是深拷贝，np.asarray() 是浅拷贝 numpy image 查看图片信息，可用如下的方法12print img.shape print img.dtype 将 numpy 数组转换为 PIL 图片这里采用 matplotlib.image 读入图片数组，注意这里读入的数组是 float32 型的，范围是 0-1，而 PIL.Image 数据是 uinit8 型的，范围是0-255，所以要进行转换：12345import matplotlib.image as mpimgfrom PIL import Imagelena = mpimg.imread(&apos;lena.png&apos;) # 这里读入的数据是 float32 型的，范围是0-1im = Image.fromarray(np.uinit8(lena*255))im.show() PIL image 查看图片信息，可用如下的方法123456print type(img)print img.size #图片的尺寸print img.mode #图片的模式print img.format #图片的格式print(img.getpixel((0,0))[0])#得到像素：#img读出来的图片获得某点像素用getpixel((w,h))可以直接返回这个点三个通道的像素值 图像中的像素访问前面的一些例子中，我们都是利用Image.open（）来打开一幅图像，然后直接对这个PIL对象进行操作。如果只是简单的操作还可以，但是如果操作稍微复杂一些，就比较吃力了。因此，通常我们加载完图片后，都是把图片转换成矩阵来进行更加复杂的操作。打开图像并转化为矩阵，并显示123456789from PIL import Imageimport numpy as npimport matplotlib.pyplot as pltimg=np.array(Image.open(&apos;d:/lena.jpg&apos;)) #打开图像并转化为数字矩阵plt.figure(&quot;dog&quot;)plt.imshow(img)plt.axis(&apos;off&apos;)plt.title(&apos;The image title&apos;)plt.show() 调用numpy中的array（）函数就可以将PIL对象转换为数组对象。 查看图片信息，可用如下的方法PIL image 查看图片信息，可用如下的方法123456print type(img)print img.size #图片的尺寸print img.mode #图片的模式print img.format #图片的格式print(img.getpixel((0,0))[0])#得到像素：#img读出来的图片获得某点像素用getpixel((w,h))可以直接返回这个点三个通道的像素值 如果是RGB图片，那么转换为array之后，就变成了一个rowscolschannels的三维矩阵,因此，我们可以使用img[i,j,k]来访问像素值。 例1：打开图片，并随机添加一些椒盐噪声12345678910111213141516from PIL import Imageimport numpy as npimport matplotlib.pyplot as pltimg=np.array(Image.open(&apos;d:/ex.jpg&apos;))#随机生成5000个椒盐rows,cols,dims=img.shapefor i in range(5000): x=np.random.randint(0,rows) y=np.random.randint(0,cols) img[x,y,:]=255 plt.figure(&quot;beauty&quot;)plt.imshow(img)plt.axis(&apos;off&apos;)plt.show() 例2：将lena图像二值化，像素值大于128的变为1，否则变为01234567891011121314151617from PIL import Imageimport numpy as npimport matplotlib.pyplot as pltimg=np.array(Image.open(&apos;d:/pic/lena.jpg&apos;).convert(&apos;L&apos;))rows,cols=img.shapefor i in range(rows): for j in range(cols): if (img[i,j]&lt;=128): img[i,j]=0 else: img[i,j]=1 plt.figure(&quot;lena&quot;)plt.imshow(img,cmap=&apos;gray&apos;)plt.axis(&apos;off&apos;)plt.show() 如果要对多个像素点进行操作，可以使用数组切片方式访问。切片方式返回的是以指定间隔下标访问 该数组的像素值。下面是有关灰度图像的一些例子：1234567img[i,:] = im[j,:] # 将第 j 行的数值赋值给第 i 行img[:,i] = 100 # 将第 i 列的所有数值设为 100img[:100,:50].sum() # 计算前 100 行、前 50 列所有数值的和img[50:100,50:100] # 50~100 行，50~100 列（不包括第 100 行和第 100 列）img[i].mean() # 第 i 行所有数值的平均值img[:,-1] # 最后一列img[-2,:] (or im[-2]) # 倒数第二行 直接操作像素点不但可以对每个像素点进行操作，而且，每一个通道都可以独立的进行操作。比如，将每个像素点的亮度(不知道有没有更专业的词)增大20%123456out = img.point(lambda i : i * 1.2)#注意这里用到一个匿名函数(那个可以把i的1.2倍返回的函数) argument * scale + offset e.g out = img.point(lambda i: i*1.2 + 10) 图像直方图我们先来看两个函数reshape和flatten:假设我们先生成一个一维数组：12vec=np.arange(15)print vec 如果我们要把这个一维数组，变成一个3*5二维矩阵，我们可以使用reshape来实现12mat= vec.reshape(3,5)print mat 现在如果我们返过来，知道一个二维矩阵，要变成一个一维数组，就不能用reshape了，只能用flatten. 我们来看两者的区别1234a1=mat.reshape(1,-1) #-1表示为任意，让系统自动计算print a1a2=mat.flatten()print a2 可以看出，用reshape进行变换，实际上变换后还是二维数组，两个方括号，因此只能用flatten.我们要对图像求直方图，就需要先把图像矩阵进行flatten操作，使之变为一维数组，然后再进行统计 画灰度图直方图绘图都可以调用matplotlib.pyplot库来进行，其中的hist函数可以直接绘制直方图。调用方式：1n, bins, patches = plt.hist(arr, bins=50, normed=1, facecolor=&apos;green&apos;, alpha=0.75) hist的参数非常多，但常用的就这五个，只有第一个是必须的，后面四个可选12345arr: 需要计算直方图的一维数组bins: 直方图的柱数，可选项，默认为10normed: 是否将得到的直方图向量归一化。默认为0facecolor: 直方图颜色alpha: 透明度 返回值 ：123n: 直方图向量，是否归一化由参数设定bins: 返回各个bin的区间范围patches: 返回每个bin里面包含的数据，是一个list 12345678910from PIL import Imageimport numpy as npimport matplotlib.pyplot as pltimg=np.array(Image.open(&apos;d:/pic/lena.jpg&apos;).convert(&apos;L&apos;))plt.figure(&quot;lena&quot;)arr=img.flatten()n, bins, patches = plt.hist(arr, bins=256, normed=1, facecolor=&apos;green&apos;, alpha=0.75) plt.title(&apos;The image title&apos;)plt.show() 彩色图片直方图实际上是和灰度直方图一样的，只是分别画出三通道的直方图，然后叠加在一起。1234567891011121314from PIL import Imageimport numpy as npimport matplotlib.pyplot as pltsrc=Image.open(&apos;d:/ex.jpg&apos;)r,g,b=src.split()plt.figure(&quot;lena&quot;)ar=np.array(r).flatten()plt.hist(ar, bins=256, normed=1,facecolor=&apos;r&apos;,edgecolor=&apos;r&apos;,hold=1)ag=np.array(g).flatten()plt.hist(ag, bins=256, normed=1, facecolor=&apos;g&apos;,edgecolor=&apos;g&apos;,hold=1)ab=np.array(b).flatten()plt.hist(ab, bins=256, normed=1, facecolor=&apos;b&apos;,edgecolor=&apos;b&apos;)plt.title(&apos;The image title&apos;)plt.show() Python如何读取指定文件夹下的所有图像1234567891011121314151617181920&apos;&apos;&apos;Load the image files form the folderinput: imgDir: the direction of the folder imgName:the name of the folderoutput: data:the data of the dataset label:the label of the datset&apos;&apos;&apos;def load_Img(imgDir,imgFoldName): imgs = os.listdir(imgDir+imgFoldName) imgNum = len(imgs) data = np.empty((imgNum,1,12,12),dtype=&quot;float32&quot;) label = np.empty((imgNum,),dtype=&quot;uint8&quot;) for i in range (imgNum): img = Image.open(imgDir+imgFoldName+&quot;/&quot;+imgs[i]) arr = np.asarray(img,dtype=&quot;float32&quot;) data[i,:,:,:] = arr label[i] = int(imgs[i].split(&apos;.&apos;)[0]) return data,label 调用方式123craterDir = &quot;./data/CraterImg/Adjust/&quot;foldName = &quot;East_CraterAdjust12&quot;data, label = load_Img(craterDir,foldName) Python图形图像处理库ImageEnhance模块图像增强可以使用ImageEnhance模块，其中包含了大量的预定义的图片加强方式加强器包括，色彩平衡，亮度平衡，对比度，锐化度等。通过使用这些加强器，可以很轻松的做到图片的色彩调整，亮度调整，锐化等操作，google picasa中提供的一些基本的图片加强功能都可以实现。 颜色加强color用于调整图片的色彩平衡，相当于彩色电视机的色彩调整。这个类实现了上边提到的接口的enhance方法。1ImageEnhance.Color(img)#获得色彩加强器实例 然后即可使用enhance(factor)方法进行调整。 亮度加强brightness用于调整图片的明暗平衡。1ImageEnhance.Brightness(img)#获得亮度加强器实例 factor=1返回一个黑色的图片对象，0返回原始图片对象 对比度加强contrast用于调整图片的对比度，相当于彩色电视机的对比度调整。1ImageEnhance.Contrast(image) #获得对比度加强器实例 123import ImageEnhance enh = ImageEnhance.Contrast(im) enh.ehhance(1.5).show(&quot;50% more contrast&quot;) 锐化度加强sharpness用于锐化/钝化图片。1ImageEnhance.Sharpness(image) #返回锐化加强器实例 应该注意的是锐化操作的factor是一个0-2的浮点数，当factor=0时，返回一个完全模糊的图片对象，当factor=1时，返回一个完全锐化的图片对象，factor=1时，返回原始图片对象 Python图像处理库ImageChops模块这个模块主要包括对图片的算术运算，叫做通道运算(channel operations)。这个模块可以用于多种途径，包括一些特效制作，图片整合，算数绘图等等方面。 Invert:1ImageChops.invert(image) 图片反色，类似于集合操作中的求补集，最大值为Max，每个像素做减法，取出反色.公式out = MAX - image lighter:1ImageChops.lighter(image1, image2) darker:1ImageChops.darker(image1, image2) difference1ImageChops.difference(image1, image2) 求出两张图片的绝对值，逐像素的做减法 multiply1ImageChops.multiply(image1, image2) 将两张图片互相叠加，如果用纯黑色与某图片进行叠加操作，会得到一个纯黑色的图片。如果用纯白色与图片作叠加，图片不受影响。计算的公式如下公式out = img1 * img2 / MAX screen:1ImageChops.screen(image1, image2) 先反色，后叠加。公式out = MAX - ((MAX - image1) * (MAX - image2) / MAX) add:1ImageChops.add(img1, img2, scale, offset) 对两张图片进行算术加法，按照一下公式进行计算公式out = (img1+img2) / scale + offset 如果尺度和偏移被忽略的化，scale=1.0, offset=0.0即out = img1 + img2 subtract:1ImageChops.subtract(img1, img2, scale, offset) 对两张图片进行算术减法：公式out = (img1-img2) / scale + offset Python图形图像处理库ImageFilter模块图像滤镜ImageFilter是PIL的滤镜模块，通过这些预定义的滤镜，可以方便的对图片进行一些过滤操作，从而去掉图片中的噪音(部分的消除)，这样可以降低将来处理的复杂度(如模式识别等)。 滤镜名称 含义 ImageFilter.BLUR 模糊滤镜 ImageFilter.CONTOUR 轮廓 ImageFilter.EDGE_ENHANCE 边界加强 ImageFilter.EDGE_ENHANCE_MORE 边界加强(阀值更大) ImageFilter.EMBOSS 浮雕滤镜 ImageFilter.FIND_EDGES 边界滤镜 ImageFilter.SMOOTH 平滑滤镜 ImageFilter.SMOOTH_MORE 平滑滤镜(阀值更大) ImageFilter.SHARPEN 锐化滤镜 要使用PIL的滤镜功能，需要引入ImageFilter模块123456789101112131415import Image, ImageFilter def inHalf(img): w,h = img.size return img.resize((w/2, h/2)) def filterDemo(): img = Image.open(&quot;sandstone_half.jpg&quot;) #img = inHalf(img) imgfilted = img.filter(ImageFilter.SHARPEN) #imgfilted.show() imgfilted.save(&quot;sandstone_sharpen.jpg&quot;) if __name__ == &quot;__main__&quot;: filterDemo()]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode208. Implement Trie (Prefix Tree)]]></title>
    <url>%2F2019%2F08%2F26%2FLeetcode208%2F</url>
    <content type="text"><![CDATA[Implement a trie with insert, search, and startsWith methods. Example:12345678Trie trie = new Trie();trie.insert(&quot;apple&quot;);trie.search(&quot;apple&quot;); // returns truetrie.search(&quot;app&quot;); // returns falsetrie.startsWith(&quot;app&quot;); // returns truetrie.insert(&quot;app&quot;); trie.search(&quot;app&quot;); // returns true Note: You may assume that all inputs are consist of lowercase letters a-z.All inputs are guaranteed to be non-empty strings. 实现一个字典树即可123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class Trie &#123;private: struct Node&#123; Node *next[26]; bool isleaf; Node()&#123; for(int i=0;i&lt;26;i++) next[i]=NULL; isleaf=false; &#125; &#125;; Node* head; public: /** Initialize your data structure here. */ Trie() &#123; head = new Node(); &#125; /** Inserts a word into the trie. */ void insert(string word) &#123; Node* current = head; for(int i=0;i&lt;word.size();i++)&#123; int index = word[i]-&apos;a&apos;; if(current-&gt;next[index]==NULL)&#123; current-&gt;next[index] = new Node(); &#125; current = current-&gt;next[index]; &#125; current-&gt;isleaf = true; &#125; /** Returns if the word is in the trie. */ bool search(string word) &#123; Node* current = head; for(int i=0;i&lt;word.size();i++)&#123; int index = word[i]-&apos;a&apos;; if(current-&gt;next[index]==NULL) return false; else current = current-&gt;next[index]; &#125; return current-&gt;isleaf; &#125; /** Returns if there is any word in the trie that starts with the given prefix. */ bool startsWith(string prefix) &#123; Node* current = head; for(int i=0;i&lt;prefix.size();i++)&#123; int index = prefix[i]-&apos;a&apos;; if(current-&gt;next[index]==NULL) return false; else current = current-&gt;next[index]; &#125; return true; &#125;&#125;;/** * Your Trie object will be instantiated and called as such: * Trie* obj = new Trie(); * obj-&gt;insert(word); * bool param_2 = obj-&gt;search(word); * bool param_3 = obj-&gt;startsWith(prefix); */ 这个实现的内存占用有些高了，抄一下其他人的 12345678910111213141516171819202122232425262728293031Javaclass TrieNode &#123; // R links to node children private TrieNode[] links; private final int R = 26; private boolean isEnd; public TrieNode() &#123; links = new TrieNode[R]; &#125; public boolean containsKey(char ch) &#123; return links[ch -&apos;a&apos;] != null; &#125; public TrieNode get(char ch) &#123; return links[ch -&apos;a&apos;]; &#125; public void put(char ch, TrieNode node) &#123; links[ch -&apos;a&apos;] = node; &#125; public void setEnd() &#123; isEnd = true; &#125; public boolean isEnd() &#123; return isEnd; &#125;&#125; Insertion of a key to a trieWe insert a key by searching into the trie. We start from the root and search a link, which corresponds to the first key character. There are two cases : A link exists. Then we move down the tree following the link to the next child level. The algorithm continues with searching for the next key character.A link does not exist. Then we create a new node and link it with the parent’s link matching the current key character. We repeat this step until we encounter the last character of the key, then we mark the current node as an end node and the algorithm finishes. 1234567891011121314151617181920class Trie &#123; private TrieNode root; public Trie() &#123; root = new TrieNode(); &#125; // Inserts a word into the trie. public void insert(String word) &#123; TrieNode node = root; for (int i = 0; i &lt; word.length(); i++) &#123; char currentChar = word.charAt(i); if (!node.containsKey(currentChar)) &#123; node.put(currentChar, new TrieNode()); &#125; node = node.get(currentChar); &#125; node.setEnd(); &#125;&#125; Search for a key in a trieEach key is represented in the trie as a path from the root to the internal node or leaf. We start from the root with the first key character. We examine the current node for a link corresponding to the key character. There are two cases : A link exist. We move to the next node in the path following this link, and proceed searching for the next key character. A link does not exist. If there are no available key characters and current node is marked as isEnd we return true. Otherwise there are possible two cases in each of them we return false : There are key characters left, but it is impossible to follow the key path in the trie, and the key is missing.No key characters left, but current node is not marked as isEnd. Therefore the search key is only a prefix of another key in the trie.123456789101112131415161718192021222324class Trie &#123; ... // search a prefix or whole key in trie and // returns the node where search ends private TrieNode searchPrefix(String word) &#123; TrieNode node = root; for (int i = 0; i &lt; word.length(); i++) &#123; char curLetter = word.charAt(i); if (node.containsKey(curLetter)) &#123; node = node.get(curLetter); &#125; else &#123; return null; &#125; &#125; return node; &#125; // Returns if the word is in the trie. public boolean search(String word) &#123; TrieNode node = searchPrefix(word); return node != null &amp;&amp; node.isEnd(); &#125;&#125; Search for a key prefix in a trieThe approach is very similar to the one we used for searching a key in a trie. We traverse the trie from the root, till there are no characters left in key prefix or it is impossible to continue the path in the trie with the current key character. The only difference with the mentioned above search for a key algorithm is that when we come to an end of the key prefix, we always return true. We don’t need to consider the isEnd mark of the current trie node, because we are searching for a prefix of a key, not for a whole key. 12345678910class Trie &#123; ... // Returns if there is any word in the trie // that starts with the given prefix. public boolean startsWith(String prefix) &#123; TrieNode node = searchPrefix(prefix); return node != null; &#125;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字典树]]></title>
    <url>%2F2019%2F08%2F25%2F%E5%AD%97%E5%85%B8%E6%A0%91%2F</url>
    <content type="text"><![CDATA[字典树又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来节约存储空间，最大限度地减少无谓的字符串比较，查询效率比哈希表高。 字典树与字典很相似,当你要查一个单词是不是在字典树中,首先看单词的第一个字母是不是在字典的第一层,如果不在,说明字典树里没有该单词,如果在就在该字母的孩子节点里找是不是有单词的第二个字母,没有说明没有该单词,有的话用同样的方法继续查找.字典树不仅可以用来储存字母,也可以储存数字等其它数据。 Trie的数据结构定义：12345678#define MAX 26typedef struct Trie &#123; Trie *next[MAX]; int v; //根据需要变化&#125;; Trie *root; next是表示每层有多少种类的数，如果只是小写字母，则26即可，若改为大小写字母，则是52，若再加上数字，则是62了，这里根据题意来确定。v可以表示一个字典树到此有多少相同前缀的数目，这里根据需要应当学会自由变化。 Trie的查找（最主要的操作）：(1) 每次从根结点开始一次搜索；(2) 取得要查找关键词的第一个字母，并根据该字母选择对应的子树并转到该子树继续进行检索； (3) 在相应的子树上，取得要查找关键词的第二个字母,并进一步选择对应的子树进行检索。 (4) 迭代过程…… (5) 在某个结点处，关键词的所有字母已被取出，则读取附在该结点上的信息，即完成查找。 这里给出生成字典树和查找的模版：生成字典树：123456789101112131415161718192021222324void createTrie(char *str)&#123; int len = strlen(str); Trie *p = root, *q; for(int i=0; i&lt;len; ++i) &#123; int id = str[i]-&apos;0&apos;; if(p-&gt;next[id] == NULL) &#123; q = (Trie *)malloc(sizeof(Trie)); q-&gt;v = 1; //初始v==1 for(int j=0; j&lt;MAX; ++j) q-&gt;next[j] = NULL; p-&gt;next[id] = q; p = p-&gt;next[id]; &#125; else &#123; p-&gt;next[id]-&gt;v++; p = p-&gt;next[id]; &#125; &#125; p-&gt;v = -1; //若为结尾，则将v改成-1表示&#125; 接下来是查找的过程了：123456789101112131415int findTrie(char *str)&#123; int len = strlen(str); Trie *p = root; for(int i=0; i&lt;len; ++i) &#123; int id = str[i]-&apos;0&apos;; p = p-&gt;next[id]; if(p == NULL) //若为空集，表示不存以此为前缀的串 return 0; if(p-&gt;v == -1) //字符集中已有串是此串的前缀 return -1; &#125; return -1; //此串是字符集中某串的前缀&#125; 对于上述动态字典树，有时会超内存，这是就要记得释放空间了：12345678910111213int dealTrie(Trie* T)&#123; int i; if(T==NULL) return 0; for(i=0;i&lt;MAX;i++) &#123; if(T-&gt;next[i]!=NULL) deal(T-&gt;next[i]); &#125; free(T); return 0;&#125; Trie的删除操作就稍微复杂一些，主要分为以下3种情况： 如果单词是另一个单词的前缀如果待删除的单词是另一个单词的前缀，只需要把该单词的最后一个节点的 isWord 的改成false 比如Trie中存在 panda 和 pan 这两个单词，删除 pan ，只需要把字符 n 对应的节点的 isWord 改成 false 即可 如果单词的所有字母的都没有多个分支，删除整个单词如果单词的所有字母的都没有多个分支（也就是说该单词所有的字符对应的Node都只有一个子节点），则删除整个单词 如果单词的除了最后一个字母，其他的字母有多个分支]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode897. Increasing Order Search Tree]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode897%2F</url>
    <content type="text"><![CDATA[Given a binary search tree, rearrange the tree in in-order so that the leftmost node in the tree is now the root of the tree, and every node has no left child and only 1 right child. Example 1:Input: [5,3,6,2,4,null,8,1,null,null,null,7,9]1234567 5 / \ 3 6 / \ \ 2 4 8 / / \ 1 7 9 Output: [1,null,2,null,3,null,4,null,5,null,6,null,7,null,8,null,9]12345678910111213141516171 \ 2 \ 3 \ 4 \ 5 \ 6 \ 7 \ 8 \ 9 Note: The number of nodes in the given tree will be between 1 and 100.Each node will have a unique integer value from 0 to 1000. 本题要求把二叉树的结点重新排列，使其成为从小到大只有右孩子的二叉树。考虑使用中序遍历的迭代方法，对每个结点入栈，出栈时先访问左结点，然后中结点，最后把右指针和下一个入栈的结点链接起来。1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* increasingBST(TreeNode* root) &#123; if(root==NULL) return NULL; if(!root-&gt;left &amp;&amp; !root-&gt;right) return root; stack&lt;TreeNode*&gt; dst; TreeNode *head = new TreeNode(0), *pre = head; while(root || !dst.empty())&#123; while(root)&#123; dst.push(root); root = root-&gt;left; &#125; root = dst.top(); dst.pop(); pre-&gt;right=root; pre = pre -&gt; right; root -&gt; left = NULL; root=root-&gt;right; &#125; return head-&gt;right; &#125;&#125;; 然后朴素的中序遍历是这样12345678910111213141516171819202122232425262728293031323334353637383940/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123; public: TreeNode *s=NULL,*p=NULL; void inorder(TreeNode* root)&#123; if(root)&#123; inorder(root-&gt;left); if(s == NULL) &#123; s = new TreeNode(root-&gt;val); p = s; &#125; else&#123; TreeNode* temp = new TreeNode(root-&gt;val); s-&gt;right = temp; s = s-&gt;right; &#125; inorder(root-&gt;right); &#125; &#125; TreeNode* increasingBST(TreeNode* root) &#123; if(root==NULL) return NULL; inorder(root); return p; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1111. Maximum Nesting Depth of Two Valid Parentheses Strings]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode1111%2F</url>
    <content type="text"><![CDATA[A string is a valid parentheses string (denoted VPS) if and only if it consists of “(“ and “)” characters only, and: It is the empty string, or It can be written as AB (A concatenated with B), where A and B are VPS’s, or It can be written as (A), where A is a VPS. We can similarly define the nesting depth depth(S) of any VPS S as follows: depth(“”) = 0 depth(A + B) = max(depth(A), depth(B)), where A and B are VPS’s depth(“(“ + A + “)”) = 1 + depth(A), where A is a VPS. For example, “”, “()()”, and “()(()())” are VPS’s (with nesting depths 0, 1, and 2), and “)(“ and “(()” are not VPS’s. Given a VPS seq, split it into two disjoint subsequences A and B, such that A and B are VPS’s (and A.length + B.length = seq.length). Now choose any such A and B such that max(depth(A), depth(B)) is the minimum possible value. Return an answer array (of length seq.length) that encodes such a choice of A and B: answer[i] = 0 if seq[i] is part of A, else answer[i] = 1. Note that even though multiple answers may exist, you may return any of them. Example 1: Input: seq = “(()())”Output: [0,1,1,1,1,0]Example 2: Input: seq = “()(())()”Output: [0,0,0,1,1,0,1,1] Constraints: 1 &lt;= seq.size &lt;= 10000 题目很简单，就是将一个集合拆分为两个depth最接近的两个集合。所以我们需要先计算出总的depth(S)是多少，然后将其除2就得到了其中一个集合的depth(A)，然后就可以计算出另外一个集合的depth(B)=depth(S)-depth(A)。 接着考虑如何将两个集合挑选出来，也是非常容易的，我们只需要再次遍历seq，记录遍历的’(‘的数目，如果’(‘的数目超过了As（A集合的depth）的话，我们就将对应的字符标记为B集合的即可（也就是标记为1）。1234567891011121314151617181920212223242526272829class Solution &#123;public: vector&lt;int&gt; maxDepthAfterSplit(string seq) &#123; int ds=0,cur=0; for(int i=0;i&lt;seq.length();i++)&#123; if(seq[i]==&apos;(&apos;)&#123; cur+=1; ds=max(ds,cur); &#125; else cur-=1; &#125; int as=ds/2; vector&lt;int&gt; res(seq.length(),0); for(int i=0;i&lt;seq.length();i++)&#123; if(seq[i]==&apos;(&apos;)&#123; cur+=1; if(cur&gt;as) res[i]=1; &#125; else&#123; if(cur&gt;as) res[i]=1; cur-=1; &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode537. Complex Number Multiplication]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode537%2F</url>
    <content type="text"><![CDATA[Given two strings representing two complex numbers. You need to return a string representing their multiplication. Note i2 = -1 according to the definition. Example 1:Input: “1+1i”, “1+1i”Output: “0+2i”Explanation: (1 + i) (1 + i) = 1 + i2 + 2 i = 2i, and you need convert it to the form of 0+2i.Example 2:Input: “1+-1i”, “1+-1i”Output: “0+-2i”Explanation: (1 - i) (1 - i) = 1 + i2 - 2 i = -2i, and you need convert it to the form of 0+-2i.Note: The input strings will not have extra blank.The input strings will be given in the form of a+bi, where the integer a and b will both belong to the range of [-100, 100]. And the output should be also in this form. 复数相乘，简单。两种做法，第一种我写的，自己实现字符串解析，memory用的少但是时间慢一些，第二种用了库，时间短但是memory用的多。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution &#123;public: pair&lt;int,int&gt; cal(string a)&#123; pair&lt;int ,int&gt; aa; int i; int temp=0; for(i=0;i&lt;a.length();i++)&#123; if(i!=0&amp;&amp;(a[i]&lt;&apos;0&apos;||a[i]&gt;&apos;9&apos;)) break; else if(a[i]&gt;=&apos;0&apos;&amp;&amp;a[i]&lt;=&apos;9&apos;)&#123; temp=temp*10+(a[i]-&apos;0&apos;); &#125; &#125; if(a[0]==&apos;-&apos;) temp=-temp; int j=i+1,temp2=0; for(;j&lt;a.length();j++)&#123; if(j!=i+1&amp;&amp;(a[j]&lt;&apos;0&apos;||a[j]&gt;&apos;9&apos;)) break; else if(a[j]&gt;=&apos;0&apos;&amp;&amp;a[j]&lt;=&apos;9&apos;)&#123; temp2=temp2*10+(a[j]-&apos;0&apos;); &#125; &#125; if(a[i+1]==&apos;-&apos;) temp2=-temp2; aa.first=temp; aa.second=temp2; return aa; &#125; string complexNumberMultiply(string a, string b) &#123; pair&lt;int ,int&gt; aa,bb; //aa=cal(a); //bb=cal(b); //第一种 //第二种 int i; for(i=0;i&lt;a.length();i++) if(a[i]==&apos;+&apos;) break; aa.first=stoi(a.substr(0,i)); aa.second=stoi(a.substr(i+1,a.length()-2-i)); for(i=0;i&lt;b.length();i++) if(b[i]==&apos;+&apos;) break; bb.first=stoi(b.substr(0,i)); bb.second=stoi(b.substr(i+1,b.length()-2-i)); int temp1,temp2; temp1=aa.first*bb.first - aa.second*bb.second; temp2=aa.first*bb.second + aa.second*bb.first; string res=to_string(temp1)+&quot;+&quot;+to_string(temp2)+&quot;i&quot;; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode883. Projection Area of 3D Shapes]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode883%2F</url>
    <content type="text"><![CDATA[On a N N grid, we place some 1 1 * 1 cubes that are axis-aligned with the x, y, and z axes. Each value v = grid[i][j] represents a tower of v cubes placed on top of grid cell (i, j). Now we view the projection of these cubes onto the xy, yz, and zx planes. A projection is like a shadow, that maps our 3 dimensional figure to a 2 dimensional plane. Here, we are viewing the “shadow” when looking at the cubes from the top, the front, and the side. Return the total area of all three projections. Example 1: Input: [[2]]Output: 5Example 2: Input: [[1,2],[3,4]]Output: 17Explanation:Here are the three projections (“shadows”) of the shape made with each axis-aligned plane. Example 3: Input: [[1,0],[0,2]]Output: 8Example 4: Input: [[1,1,1],[1,0,1],[1,1,1]]Output: 14Example 5: Input: [[2,2,2],[2,1,2],[2,2,2]]Output: 21 Note: 1 &lt;= grid.length = grid[0].length &lt;= 500 &lt;= grid[i][j] &lt;= 50 投影题，之前做过类似的，从上往下看的数量是不为零的格子数，从左往右看和从右往左看是每行（或列）最高的，求和。 12345678910111213141516171819202122232425262728class Solution &#123;public: int projectionArea(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int x=grid.size(); int y=grid[0].size(); int res=0; int max; for(int i=0;i&lt;x;i++) for(int j=0;j&lt;y;j++) if(grid[i][j]!=0) res++; for(int i=0;i&lt;x;i++)&#123; max=-1; for(int j=0;j&lt;y;j++) if(grid[i][j]&gt;max) max=grid[i][j]; res+=max; &#125; for(int i=0;i&lt;y;i++)&#123; max=-1; for(int j=0;j&lt;x;j++) if(grid[j][i]&gt;max) max=grid[j][i]; res+=max; &#125; return res; &#125;&#125;; 1234567891011121314151617181920class Solution &#123;public: int projectionArea(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int N = grid.size(); int ans = 0; for (int i = 0; i &lt; N; ++i) &#123; int bestRow = 0; // largest of grid[i][j] int bestCol = 0; // largest of grid[j][i] for (int j = 0; j &lt; N; ++j) &#123; if (grid[i][j] &gt; 0) ans++; // top shadow bestRow = max(bestRow, grid[i][j]); bestCol = max(bestCol, grid[j][i]); &#125; ans += bestRow + bestCol; &#125; return ans; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode999. Available Captures for Rook]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode999%2F</url>
    <content type="text"><![CDATA[On an 8 x 8 chessboard, there is one white rook. There also may be empty squares, white bishops, and black pawns. These are given as characters ‘R’, ‘.’, ‘B’, and ‘p’ respectively. Uppercase characters represent white pieces, and lowercase characters represent black pieces. The rook moves as in the rules of Chess: it chooses one of four cardinal directions (north, east, west, and south), then moves in that direction until it chooses to stop, reaches the edge of the board, or captures an opposite colored pawn by moving to the same square it occupies. Also, rooks cannot move into the same square as other friendly bishops. Return the number of pawns the rook can capture in one move. Example 1: Input:[[“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”p”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”R”,”.”,”.”,”.”,”p”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”p”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”]]Output: 3Explanation:In this example the rook is able to capture all the pawns. Example 2: Input: [ [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”p”,”p”,”p”,”p”,”p”,”.”,”.”], [“.”,”p”,”p”,”B”,”p”,”p”,”.”,”.”], [“.”,”p”,”B”,”R”,”B”,”p”,”.”,”.”], [“.”,”p”,”p”,”B”,”p”,”p”,”.”,”.”], [“.”,”p”,”p”,”p”,”p”,”p”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”]]Output: 0Explanation:Bishops are blocking the rook to capture any pawn. Example 3: Input: [ [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”p”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”p”,”.”,”.”,”.”,”.”], [“p”,”p”,”.”,”R”,”.”,”p”,”B”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”B”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”p”,”.”,”.”,”.”,”.”], [“.”,”.”,”.”,”.”,”.”,”.”,”.”,”.”]]Output: 3Explanation:The rook can capture the pawns at positions b5, d6 and f5. Note: board.length == board[i].length == 8 board[i][j] is either ‘R’, ‘.’, ‘B’, or ‘p’ There is exactly one cell with board[i][j] == ‘R’ 非常无聊，数格子就好了。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class Solution &#123;public: int numRookCaptures(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; int x,y; int res=0; bool bBlack; for (int row = 0; row &lt; 8; row++) for (int col = 0; col &lt; 8; col++) if (board[row][col] == &apos;R&apos; || board[row][col] == &apos;r&apos;) &#123; x = row; y = col; if (board[row][col] == &apos;R&apos;) &#123; bBlack = false; &#125; else &#123; bBlack = true; &#125; break; &#125; for(int j=x-1;j&gt;=0;j--)&#123; if(board[j][y]==&apos;.&apos;) continue; if(board[j][y]==&apos;P&apos; &amp;&amp; bBlack==true)&#123; res++; break; &#125; else if(board[j][y]==&apos;p&apos; &amp;&amp; bBlack==false)&#123; res++; break; &#125; else break; &#125; for(int j=x+1;j&lt;8;j++)&#123; if(board[j][y]==&apos;.&apos;) continue; if(board[j][y]==&apos;P&apos; &amp;&amp; bBlack==true)&#123; res++; break; &#125; else if(board[j][y]==&apos;p&apos; &amp;&amp; bBlack==false)&#123; res++; break; &#125; else break; &#125; for(int j=y-1;j&gt;=0;j--)&#123; if(board[x][j]==&apos;.&apos;) continue; if(board[x][j]==&apos;P&apos; &amp;&amp; bBlack==true)&#123; res++; break; &#125; else if(board[x][j]==&apos;p&apos; &amp;&amp; bBlack==false)&#123; res++; break; &#125; else break; &#125; for(int j=y+1;j&lt;8;j++)&#123; if(board[x][j]==&apos;.&apos;) continue; if(board[x][j]==&apos;P&apos; &amp;&amp; bBlack==true)&#123; res++; break; &#125; else if(board[x][j]==&apos;p&apos; &amp;&amp; bBlack==false)&#123; res++; break; &#125; else break; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode559. Maximum Depth of N-ary Tree]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode559%2F</url>
    <content type="text"><![CDATA[Given a n-ary tree, find its maximum depth. The maximum depth is the number of nodes along the longest path from the root node down to the farthest leaf node. For example, given a 3-ary tree: We should return its max depth, which is 3. Note: The depth of the tree is at most 1000.The total number of nodes is at most 5000. 多叉树最大深度12345678910111213141516171819202122232425262728293031/* // Definition for a Node. class Node &#123; public: int val; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125; &#125;;*/class Solution &#123; public: int maxDepth(Node* root) &#123; if(root==NULL) return 0; if(root-&gt;children.size()==0) return 1; int maxx=-1; for(int i=0;i&lt;root-&gt;children.size();i++)&#123; int temp = maxDepth(root-&gt;children[i]); if(maxx&lt;temp) maxx=temp; &#125; return maxx+1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode811. Subdomain Visit Count]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode811%2F</url>
    <content type="text"><![CDATA[A website domain like “discuss.leetcode.com” consists of various subdomains. At the top level, we have “com”, at the next level, we have “leetcode.com”, and at the lowest level, “discuss.leetcode.com”. When we visit a domain like “discuss.leetcode.com”, we will also visit the parent domains “leetcode.com” and “com” implicitly. Now, call a “count-paired domain” to be a count (representing the number of visits this domain received), followed by a space, followed by the address. An example of a count-paired domain might be “9001 discuss.leetcode.com”. We are given a list cpdomains of count-paired domains. We would like a list of count-paired domains, (in the same format as the input, and in any order), that explicitly counts the number of visits to each subdomain. Example 1:Input:[“9001 discuss.leetcode.com”]Output:[“9001 discuss.leetcode.com”, “9001 leetcode.com”, “9001 com”]Explanation:We only have one website domain: “discuss.leetcode.com”. As discussed above, the subdomain “leetcode.com” and “com” will also be visited. So they will all be visited 9001 times. Example 2:Input:[“900 google.mail.com”, “50 yahoo.com”, “1 intel.mail.com”, “5 wiki.org”]Output:[“901 mail.com”,”50 yahoo.com”,”900 google.mail.com”,”5 wiki.org”,”5 org”,”1 intel.mail.com”,”951 com”]Explanation:We will visit “google.mail.com” 900 times, “yahoo.com” 50 times, “intel.mail.com” once and “wiki.org” 5 times. For the subdomains, we will visit “mail.com” 900 + 1 = 901 times, “com” 900 + 50 + 1 = 951 times, and “org” 5 times. Notes: The length of cpdomains will not exceed 100.The length of each domain name will not exceed 100.Each address will have either 1 or 2 “.” characters.The input count in any count-paired domain will not exceed 10000.The answer output can be returned in any order. 这个题就是非常简单的统计字符串，如果用java和python做的话几分钟就出来了，但是用了原生C++，没有用高级功能，自己手写的一些函数，就当熟悉熟悉了。1234567891011121314151617181920212223242526272829303132333435363738394041424344class Solution &#123; public: vector&lt;string&gt; subdomainVisits(vector&lt;string&gt;&amp; cpdomains) &#123; vector&lt;string&gt; res; unordered_map&lt;string,int&gt; m; for(int i=0;i&lt;cpdomains.size();i++)&#123; int num = 0; string domain=cpdomains[i]; int domain_len = domain.length(); int j=0; while(domain[j]!=&apos; &apos;) j++; for(int i=0;i&lt;j;i++) num = num *10 + (domain[i]-&apos;0&apos;); vector&lt;string&gt; temp; int part_end=j+1; string tt; for(int i=j+1;i&lt;domain_len;i++)&#123; if(domain[i]==&apos;.&apos;)&#123; tt = domain.substr(part_end,part_end-i+1); temp.push_back(tt); part_end=i+1; &#125; &#125; tt=domain.substr(part_end,domain_len-part_end); temp.push_back(tt); for(int i=0;i&lt;temp.size();i++) if(m.find(temp[i])==m.end())&#123; m.insert(pair&lt;string,int&gt;(temp[i],num)); &#125; else m[temp[i]]+=num; &#125; unordered_map&lt;string,int&gt;::iterator it; for(it=m.begin();it!=m.end();it++)&#123; string ddd = to_string(it-&gt;second)+&quot; &quot;+it-&gt;first; res.push_back(ddd); &#125; return res; &#125;&#125;; 贴一下其他解法：123456789101112131415161718192021class Solution &#123; public: vector&lt;string&gt; subdomainVisits(vector&lt;string&gt;&amp; cpdomains) &#123; vector&lt;string&gt; ans; unordered_map&lt;string, int&gt; domains; for(string s:cpdomains)&#123; int count = stoi(s.substr(0, s.find(&apos; &apos;))); domains[s.substr(s.find(&apos; &apos;) + 1)] += count; domains[s.substr(s.find(&apos;.&apos;) + 1)] += count; // try to find the second &apos;.&apos; string sub = s.substr(s.find(&apos;.&apos;) + 1); if(sub.find(&apos;.&apos;) != -1)&#123; domains[sub.substr(sub.find(&apos;.&apos;) + 1)] += count; &#125; &#125; for(auto it = domains.begin(); it!= domains.end(); ++it)&#123; ans.push_back(to_string(it-&gt;second) + &quot; &quot; + it-&gt;first); &#125; return ans; &#125;&#125;; python版本的：12345678910class Solution(object): def subdomainVisits(self, cpdomains): ans = collections.Counter() for domain in cpdomains: count, domain = domain.split() count = int(count) frags = domain.split(&apos;.&apos;) for i in xrange(len(frags)): ans[&quot;.&quot;.join(frags[i:])] += count return [&quot;&#123;&#125; &#123;&#125;&quot;.format(ct, dom) for dom, ct in ans.items()]]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode419. Battleships in a Board]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode419%2F</url>
    <content type="text"><![CDATA[Given an 2D board, count how many battleships are in it. The battleships are represented with ‘X’s, empty slots are represented with ‘.’s. You may assume the following rules:You receive a valid board, made of only battleships or empty slots.Battleships can only be placed horizontally or vertically. In other words, they can only be made of the shape 1xN (1 row, N columns) or Nx1 (N rows, 1 column), where N can be of any size.At least one horizontal or vertical cell separates between two battleships - there are no adjacent battleships.Example:123X..X...X...X In the above board there are 2 battleships.Invalid Example:123...XXXXX...X This is an invalid board that you will not receive - as battleships will always have a cell separating between them.Follow up:Could you do it in one-pass, using only O(1) extra memory and without modifying the value of the board? 利用最简单的方法找有多少个X块，这里用的遍历很方便。12345678910111213141516class Solution &#123; public: int countBattleships(vector&lt;vector&lt;char&gt;&gt;&amp; board) &#123; int x = board.size(); int y = board[0].size(); int res=0; for(int i=0;i&lt;x;i++) for(int j=0;j&lt;y;j++) if(board[i][j]==&apos;X&apos;)&#123; if(j&lt;y-1 &amp;&amp; board[i][j+1]==&apos;X&apos;) continue; if(i&lt;x-1 &amp;&amp; board[i+1][j]==&apos;X&apos;) continue; res++; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1165. Single-Row Keyboard]]></title>
    <url>%2F2019%2F08%2F25%2FLeetcode1165%2F</url>
    <content type="text"><![CDATA[There is a special keyboard with all keys in a single row. Given a string keyboard of length 26 indicating the layout of the keyboard (indexed from 0 to 25), initially your finger is at index 0. To type a character, you have to move your finger to the index of the desired character. The time taken to move your finger from index i to index j is |i - j|. You want to type a string word. Write a function to calculate how much time it takes to type it with one finger. Example 1: Input: keyboard = “abcdefghijklmnopqrstuvwxyz”, word = “cba”Output: 4Explanation: The index moves from 0 to 2 to write ‘c’ then to 1 to write ‘b’ then to 0 again to write ‘a’.Total time = 2 + 1 + 1 = 4.Example 2: Input: keyboard = “pqrstuvwxyzabcdefghijklmno”, word = “leetcode”Output: 73 Constraints: keyboard.length == 26keyboard contains each English lowercase letter exactly once in some order.1 &lt;= word.length &lt;= 10^4word[i] is an English lowercase letter. 简单打表即可。 12345678910111213class Solution &#123; public: int calculateTime(string keyboard, string word) &#123; vector&lt;int&gt; pos(26,-1); int k=0; for(int i=0;i&lt;keyboard.length();i++) pos[keyboard[i]-&apos;a&apos;] = k++; int res=pos[word[0]-&apos;a&apos;]; for(int i=1;i&lt;word.length();i++) res += abs(pos[word[i]-&apos;a&apos;]-pos[word[i-1]-&apos;a&apos;]); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1122. Relative Sort Array]]></title>
    <url>%2F2019%2F08%2F24%2FLeetcode1122%2F</url>
    <content type="text"><![CDATA[Given two arrays arr1 and arr2, the elements of arr2 are distinct, and all elements in arr2 are also in arr1. Sort the elements of arr1 such that the relative ordering of items in arr1 are the same as in arr2. Elements that don’t appear in arr2 should be placed at the end of arr1 in ascending order. Example 1: Input: arr1 = [2,3,1,3,2,4,6,7,9,2,19], arr2 = [2,1,4,3,9,6]Output: [2,2,2,1,4,3,3,9,6,7,19] Constraints: arr1.length, arr2.length &lt;= 10000 &lt;= arr1[i], arr2[i] &lt;= 1000Each arr2[i] is distinct.Each arr2[i] is in arr1. arr2 中的元素各不相同arr2 中的每个元素都出现在 arr1 中对 arr1 中的元素进行排序，使 arr1 中项的相对顺序和 arr2 中的相对顺序相同。未在 arr2 中出现过的元素需要按照升序放在 arr1 的末尾。 基本思路是：1、首先题目的意思是按照arr2的元素顺序返回arr1的元素，假定返回的新数组为arr3，然后把剩余的arr1元素按照升序顺序拼接到arr3后边返回2、遍历一遍arr1使用map [Int:Int] 记录每一个元素的次数3、遍历arr2，把在arr2出现的元素当做key取出value值，arr3 add value次key值4、把剩余的字典键值对所对应的key值排序，添加到arr3后边5、时间复杂度 O(nlogn)6、空间复杂度 O(n) 注意map是有序的，内部是用平衡树存储，而unordered_map是用hash做的，也不能保证插入的顺序因此这里使用了大佬的做法123456789101112131415161718192021222324252627class Solution &#123; public: vector&lt;int&gt; relativeSortArray(vector&lt;int&gt;&amp; arr1, vector&lt;int&gt;&amp; arr2) &#123; int count_arr[1001]; vector&lt;int&gt; ans; memset(count_arr, 0, sizeof(count_arr)); for(int i=0;i&lt;arr1.size();i++) count_arr[arr1[i]]++; for(int i=0;i&lt;arr2.size();i++)&#123; int len = count_arr[arr2[i]]; for(int j=0;j&lt;len;j++) ans.push_back(arr2[i]); count_arr[arr2[i]]=-1; &#125; vector&lt;int&gt; s; for(int i=0; i&lt;arr1.size(); i++)&#123; if(count_arr[arr1[i]] &gt; 0) s.push_back(arr1[i]); &#125; sort(s.begin(), s.end()); for(int i=0;i&lt;s.size();i++) ans.push_back(s[i]); return ans; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode979. Distribute Coins in Binary Tree]]></title>
    <url>%2F2019%2F08%2F24%2FLeetcode979%2F</url>
    <content type="text"><![CDATA[Given the root of a binary tree with N nodes, each node in the tree has node.val coins, and there are N coins total. In one move, we may choose two adjacent nodes and move one coin from one node to another. (The move may be from parent to child, or from child to parent.) Return the number of moves required to make every node have exactly one coin. Example 1: Input: [3,0,0]Output: 2Explanation: From the root of the tree, we move one coin to its left child, and one coin to its right child. Example 2: Input: [0,3,0]Output: 3Explanation: From the left child of the root, we move two coins to the root [taking two moves]. Then, we move one coin from the root of the tree to the right child. Example 3: Input: [1,0,2]Output: 2 Example 4: Input: [1,0,0,null,3]Output: 4 Note: 1&lt;= N &lt;= 1000 &lt;= node.val &lt;= N 给你一个二叉树，对于每个节点的val，每次只能往父亲或者儿子移动1，最后使得所有节点值都为1，求最小的移动次数。 思路：从叶子到根寻找，对于每个节点，只能剩下一个。多了的值肯定要全给父亲，少的值全问父亲要，统计一下就好了。1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;;*/class Solution &#123; public: int ans=0; int distributeCoins(TreeNode* root) &#123; dfs(root); return ans; &#125; int dfs(TreeNode* root)&#123; if(root==NULL) return 0; int left = dfs(root-&gt;left); int right = dfs(root-&gt;right); ans += abs(left) + abs(right); return root-&gt;val -1 + left + right ; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1160. Find Words That Can Be Formed by Characters]]></title>
    <url>%2F2019%2F08%2F24%2FLeetcode1160%2F</url>
    <content type="text"><![CDATA[You are given an array of strings words and a string chars. A string is good if it can be formed by characters from chars (each character can only be used once). Return the sum of lengths of all good strings in words. Example 1: Input: words = [“cat”,”bt”,”hat”,”tree”], chars = “atach”Output: 6Explanation:The strings that can be formed are “cat” and “hat” so the answer is 3 + 3 = 6.Example 2: Input: words = [“hello”,”world”,”leetcode”], chars = “welldonehoneyr”Output: 10Explanation:The strings that can be formed are “hello” and “world” so the answer is 5 + 5 = 10. Note: 1 &lt;= words.length &lt;= 10001 &lt;= words[i].length, chars.length &lt;= 100All strings contain lowercase English letters only. 一道简单题卡了这么久，我真的是太弱鸡了，不过它卡时间很扯淡。。。chars中每个字符出现的次数要大于等于word中每个字符出现的次数，即表示可以组成这个word。 12345678910111213141516171819202122232425class Solution &#123; public: int countCharacters(vector&lt;string&gt;&amp; words, string chars) &#123; int char_len[26]; for(int i=0;i&lt;26;i++) char_len[i]=0; for(int i=0;i&lt;chars.length();i++) char_len[chars[i]-&apos;a&apos;]++; int res=0; int word_len[26]; for(int i=0;i&lt;words.size();i++)&#123; bool flag=true; for(int j=0;j&lt;26;j++) word_len[j]=0; for(int j=0;j&lt;words[i].length();j++) if(++word_len[words[i][j]-&apos;a&apos;] &gt; char_len[words[i][j]-&apos;a&apos;])&#123; flag=false; break; &#125; if(flag) res += words[i].length(); &#125; return res; &#125; &#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux C/C++服务器后台开发面试题总结]]></title>
    <url>%2F2019%2F08%2F14%2FC%2B%2B%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[编程语言 根据熟悉的语言，谈谈两种语言的区别？ 主要浅谈下C/C++和PHP语言的区别: 1)PHP弱类型语言，一种脚本语言，对数据的类型不要求过多，较多的应用于Web应用开发，现在好多互联网开发公司的主流web后台开发语言，主要框架为mvc模型，如smarty,yaf，升级的PHP7速度较快，对服务器的压力要小很多，在新浪微博已经有应用，对比很明显。 2)C/C++开发语言，C语言更偏向硬件底层开发，C++语言是目前为止我认为语法内容最多的一种语言。C/C++在执行速度上要快很多，毕竟其他类型的语言大都是C开发的，更多应用于网络编程和嵌入式编程。 volatile是干啥用的，（必须将cpu的寄存器缓存机制回答的很透彻），使用实例有哪些？（重点） 1）访问寄存器比访问内存单元要快,编译器会优化减少内存的读取，可能会读脏数据。声明变量为volatile，编译器不再对访问该变量的代码优化，仍然从内存读取，使访问稳定。 总结：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不再编译优化，以免出错。 2）使用实例如下(区分C程序员和嵌入式系统程序员的最基本的问题。)：并行设备的硬件寄存器（如：状态寄存器）一个中断服务子程序中会访问到的非自动变量(Non-automatic variables)多线程应用中被几个任务共享的变量 3)一个参数既可以是const还可以是volatile吗？解释为什么。可以。一个例子是只读的状态寄存器。它是volatile因为它可能被意想不到地改变。它是const因为程序不应该试图去修改它。 4）一个指针可以是volatile 吗？解释为什么。可以。尽管这并不很常见。一个例子当中断服务子程序修该一个指向一个buffer的指针时。 下面的函数有什么错误：123int square(volatile int *ptr) &#123; return *ptr * *ptr;&#125; 下面是答案：这段代码有点变态。这段代码的目的是用来返指针*ptr指向值的平方，但是，由于*ptr指向一个volatile型参数，编译器将产生类似下面的代码：123456int square(volatile int *ptr)&#123; int a,b; a = *ptr; b = *ptr; return a * b;&#125; 由于*ptr的值可能被意想不到地该变，因此a和b可能是不同的。结果，这段代码可能返不是你所期望的平方值！正确的代码如下：12345long square(volatile int *ptr)&#123;int a;a = *ptr;return a * a;&#125; static const等等的用法，（能说出越多越好）（重点）首先说说const的用法（绝对不能说是常数） 1）在定义的时候必须进行初始化 2）指针可以是const指针，也可以是指向const对象的指针 3）定义为const的形参，即在函数内部是不能被修改的 4）类的成员函数可以被声明为常成员函数，不能修改类的成员变量 5）类的成员函数可以返回的是常对象，即被const声明的对象 6）类的成员变量是常成员变量不能在声明时初始化，必须在构造函数的列表里进行初始化 （注：千万不要说const是个常数，会被认为是外行人的！！！！哪怕说个只读也行） 下面的声明都是什么意思？12345const int a; a是一个常整型数int const a; a是一个常整型数const int *a; a是一个指向常整型数的指针，整型数是不可修改的，但指针可以int * const a; a为指向整型数的常指针，指针指向的整型数可以修改，但指针是不可修改的int const * a const; a是一个指向常整型数的常指针，指针指向的整型数是不可修改的，同时指针也是不可修改的 通过给优化器一些附加的信息，使用关键字const也许能产生更紧凑的代码。合理地使用关键字const可以使编译器很自然地保护那些不希望被改变的参数，防止其被无意的代码修改。简而言之，这样可以减少bug的出现。 Const如何做到只读？ 这些在编译期间完成，对于内置类型，如int， 编译器可能使用常数直接替换掉对此变量的引用。而对于结构体不一定。 再说说static的用法（三个明显的作用一定要答出来） 1）在函数体，一个被声明为静态的变量在这一函数被调用过程中维持其值不变。2）在模块内（但在函数体外），一个被声明为静态的变量可以被模块内所用函数访问，但不能被模块外其它函数访问。它是一个本地的全局变量。3）在模块内，一个被声明为静态的函数只可被这一模块内的其它函数调用。那就是，这个函数被限制在声明它的模块的本地范围内使用4）类内的static成员变量属于整个类所拥有，不能在类内进行定义，只能在类的作用域内进行定义5）类内的static成员函数属于整个类所拥有，不能包含this指针，只能调用static成员函数 static全局变量与普通的全局变量有什么区别?static局部变量和普通局部变量有什么区别?static函数与普通函数有什么区别? static全局变量与普通的全局变量有什么区别：static全局变量只初使化一次，防止在其他文件单元中被引用;static局部变量和普通局部变量有什么区别：static局部变量只被初始化一次，下一次依据上一次结果值；static函数与普通函数有什么区别：static函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝 extern C作用 告诉编译器该段代码以C语言进行编译。 指针和引用的区别 1）引用是直接访问，指针是间接访问。2）引用是变量的别名，本身不单独分配自己的内存空间，而指针有自己的内存空间3）引用绑定内存空间（必须赋初值），是一个变量别名不能更改绑定，可以改变对象的值。 总的来说：引用既具有指针的效率，又具有变量使用的方便性和直观性 关于静态内存分配和动态内存分配的区别及过程 1) 静态内存分配是在编译时完成的，不占用CPU资源；动态分配内存运行时完成，分配与释放需要占用CPU资源；2)静态内存分配是在栈上分配的，动态内存是堆上分配的；3)动态内存分配需要指针或引用数据类型的支持，而静态内存分配不需要；4)静态内存分配是按计划分配，在编译前确定内存块的大小，动态内存分配运行时按需分配。5)静态分配内存是把内存的控制权交给了编译器，动态内存把内存的控制权交给了程序员；6)静态分配内存的运行效率要比动态分配内存的效率要高，因为动态内存分配与释放需要额外的开销；动态内存管理水平严重依赖于程序员的水平，处理不当容易造成内存泄漏。 头文件中的 ifndef/define/endif 干什么用？ 预处理，防止头文件被重复使用，包括pragma once都是这样的 宏定义求两个元素的最小值 1#define MIN(A,B) （（A） &lt;= (B) ? (A) : (B)) 分别设置和清除一个整数的第三位？ 1234567891011#define BIT3 (0x1&lt;&lt;3)static int a;void set_bit3(void)&#123; a |= BIT3;&#125; void clear_bit3(void)&#123; a &amp;= ~BIT3;&#125; 用预处理指令#define 声明一个常数，用以表明1年中有多少秒 1#define SECONDS_PER_YEAR (60 * 60 * 24 * 365)UL 预处理器标识#error的目的是什么？ 抛出错误提示，标识外部宏是否被定义! 嵌入式系统中经常要用到无限循环，你怎么样用C编写死循环呢？ 记住这是第一方案！！！！123while(1)&#123;&#125; 一些程序员更喜欢如下方案：12for(;;)&#123;&#125; 汇编语言的无线循环是：123Loop:...goto Loop; 用变量a给出下面的定义 一个有10个指针的数组，该指针指向一个函数，该函数有一个整型参数并返回一个整型数 int (*a[10])(int); 中断是嵌入式系统中重要的组成部分，这导致了很多编译开发商提供一种扩展—让标准C支持中断。具代表事实是，产生了一个新的关键字__interrupt memcpy函数的实现 123456789void *memcpy(void *dest, const void *src, size_t count) &#123; char *tmp = dest; const char *s = src; while (count--) *tmp++ = *s++; return dest;&#125; Strcpy函数实现 1234567char *strcpy(char *dst,const char *src) &#123; assert(dst != NULL &amp;&amp; src != NULL); char *ret = dst; while((* dst++ = * src++) != &apos;\0&apos;) ; return ret; &#125; strcat函数的实现 12345678910char *strcat(char *strDes, const char *strSrc)&#123; assert((strDes != NULL) &amp;&amp; (strSrc != NULL)); char *address = strDes; while (*strDes != ‘\0′) ++ strDes; while ((*strDes ++ = *strSrc ++) != ‘\0′); return address;&#125; strncat实现 1234567891011char *strncat(char *strDes, const char *strSrc, int count)&#123; assert((strDes != NULL) &amp;&amp; (strSrc != NULL)); char *address = strDes; while (*strDes != ‘\0′) ++ strDes; while (count — &amp;&amp; *strSrc != ‘\0′ ) *strDes ++ = *strSrc ++; *strDes = ‘\0′; return address;&#125; strcmp函数实现 1234567891011121314int strcmp(const char *str1,const char *str2)&#123; /*不可用while(*str1++==*str2++)来比较，当不相等时仍会执行一次++， return返回的比较值实际上是下一个字符。应将++放到循环体中进行。*/ while(*str1 == *str2)&#123; if(*str1 == &apos;\0&apos;) return 0; ++str1; ++str2; &#125; return *str1 - *str2;&#125; strncmp实现 12345678int strncmp(const char *s, const char *t, int count)&#123; assert((s != NULL) &amp;&amp; (t != NULL)); while (*s &amp;&amp; *t &amp;&amp; *s == *t &amp;&amp; count –) &#123; ++ s; ++ t; &#125; return (*s – *t);&#125; strlen函数实现 1234567int strlen(const char *str)&#123; assert(str != NULL); int len = 0; while (*str ++ != ‘\0′) ++ len; return len;&#125; strpbrk函数实现 1234567891011char * strpbrk(const char * cs,const char * ct)&#123; const char *sc1,*sc2; for( sc1 = cs; *sc1 != &apos;\0&apos;; ++sc1)&#123; for( sc2 = ct; *sc2 != &apos;\0&apos;; ++sc2)&#123; if (*sc1 == *sc2)&#123; return (char *) sc1; &#125; &#125; &#125; return NULL;&#125; strstr函数实现 1234567891011char *strstr(const char *s1,const char *s2)&#123; int len2; if(!(len2=strlen(s2)))//此种情况下s2不能指向空，否则strlen无法测出长度，这条语句错误 return(char*)s1; for(;*s1;++s1) &#123; if(*s1==*s2 &amp;&amp; strncmp(s1,s2,len2)==0) return (char*)s1; &#125; return NULL;&#125; string实现（注意：赋值构造，operator=是关键） 12345678910111213class String&#123;public: //普通构造函数 String(const char *str = NULL); //拷贝构造函数 String(const String &amp;other); //赋值函数 String &amp; operator=(String &amp;other) ; //析构函数 ~String(void);private: char* m_str;&#125;; 分别实现以上四个函数123456789101112131415161718192021222324252627282930313233343536373839//普通构造函数String::String(const char* str)&#123; if(str==NULL) //如果str为NULL，存空字符串&#123; m_str = new char[1]; //分配一个字节 *m_str = ‘\0′; //赋一个’\0′ &#125;else&#123; str = new char[strlen(str) + 1];//分配空间容纳str内容 strcpy(m_str, str); //复制str到私有成员m_str中 &#125;&#125;//析构函数String::~String()&#123; if(m_str!=NULL) //如果m_str不为NULL，释放堆内存&#123; delete [] m_str; m_str = NULL; &#125;&#125;//拷贝构造函数String::String(const String &amp;other)&#123; m_str = new char[strlen(other.m_str)+1]; //分配空间容纳str内容 strcpy(m_str, other.m_str); //复制other.m_str到私有成员m_str中 &#125;//赋值函数String &amp; String::operator=(String &amp;other)&#123; if(this == &amp;other) //若对象与other是同一个对象，直接返回本&#123; return *this &#125; delete [] m_str; //否则，先释放当前对象堆内存 m_str = new char[strlen(other.m_str)+1]; //分配空间容纳str内容 strcpy(m_str, other.m_str); //复制other.m_str到私有成员m_str中 return *this；&#125; C语言同意一些令人震惊的结构,下面的结构是合法的吗，如果是它做些什么？12int a = 5, b = 7, c;c = a+++b; 等同于 c = a++ + b; 因此, 这段代码持行后a = 6, b = 7, c = 12。 用struct关键字与class关键定义类以及继承的区别 （1）定义类差别struct关键字也可以实现类，用class和struct关键字定义类的唯一差别在于默认访问级别：默认情况下，struct成员的访问级别为public，而class成员的为private。语法使用也相同，直接将class改为struct即可。 （2）继承差别使用class保留字的派生类默认具有private继承，而用struct保留字定义的类某人具有public继承。其它则没有任何区别。 主要点就两个：默认的访问级别和默认的继承级别 class都是private 派生类与虚函数概述 (1) 派生类继承的函数不能定义为虚函数。虚函数是希望派生类重新定义。如果派生类没有重新定义某个虚函数，则在调用的时候会使用基类中定义的版本。 (2)派生类中函数的声明必须与基类中定义的方式完全匹配。 (3) 基类中声明为虚函数，则派生类也为虚函数。 虚函数与纯虚函数区别 1）虚函数在子类里面也可以不重载的；但纯虚必须在子类去实现 2）带纯虚函数的类叫虚基类也叫抽象类，这种基类不能直接生成对象，只能被继承，重写虚函数后才能使用，运行时动态动态绑定！ 深拷贝与浅拷贝浅拷贝：12char ori[]=“hello”;char *copy=ori; 深拷贝：123char ori[]=&quot;hello&quot;; char *copy=new char[]; copy=ori; 浅拷贝只是对指针的拷贝，拷贝后两个指针指向同一个内存空间，深拷贝不但对指针进行拷贝，而且对指针指向的内容进行拷贝，经深拷贝后的指针是指向两个不同地址的指针。 浅拷贝可能出现的问题： 1） 浅拷贝只是拷贝了指针，使得两个指针指向同一个地址，这样在对象块结束，调用函数析构的时，会造成同一份资源析构2次，即delete同一块内存2次，造成程序崩溃。 2） 浅拷贝使得两个指针都指向同一块内存，任何一方的变动都会影响到另一方。 3） 同一个空间，第二次释放失败，导致无法操作该空间，造成内存泄漏。 stl各容器的实现原理（必考） 1) Vector顺序容器，是一个动态数组，支持随机插入、删除、查找等操作，在内存中是一块连续的空间。在原有空间不够情况下自动分配空间，增加为原来的两倍。vector随机存取效率高，但是在vector插入元素，需要移动的数目多，效率低下。 注：vector动态增加大小时是以原大小的两倍另外配置一块较大的空间，然后将原内容拷贝过来，然后才开始在原内容之后构造新元素，并释放原空间。因此，对vector空间重新配置，指向原vector的所有迭代器就都失效了。 2) Map关联容器，以键值对的形式进行存储，方便进行查找。关键词起到索引的作用，值则表示与索引相关联的数据。红黑树的结构实现，插入删除等操作都在O(logn)时间内完成。 3) Set是关联容器，set每个元素只包含一个关键字。set支持高效的关键字检查是否在set中。set也是以红黑树的结构实现，支持高效插入、删除等操作。 哪些库函数属于高危函数，为什么？ strcpy 赋值到目标区间可能会造成缓冲区溢出！ STL有7种主要容器：vector,list,deque,map,multimap,set,multiset 你如何理解MVC。简单举例来说明其应用。 MVC模式是observer 模式的一个特例,现在很多都是java的一些框架，MFC的，PHP的。 C++特点是什么，多态实现机制？（面试问过）多态作用？两个必要条件？ C++中多态机制主要体现在两个方面，一个是函数的重载，一个是接口的重写。接口多态指的是“一个接口多种形态”。每一个对象内部都有一个虚表指针，该虚表指针被初始化为本类的虚表。所以在程序中，不管你的对象类型如何转换，但该对象内部的虚表指针是固定的，所以呢，才能实现动态的对象函数调用，这就是C++多态性实现的原理。 多态的基础是继承，需要虚函数的支持，简单的多态是很简单的。子类继承父类大部分的资源，不能继承的有构造函数，析构函数，拷贝构造函数，operator=函数，友元函数等等 作用： 隐藏实现细节，代码能够模块化； 接口重用：为了类在继承和派生的时候正确调用。 必要条件： 一个基类的指针或者引用指向派生类的对象 虚函数 多重继承有什么问题? 怎样消除多重继承中的二义性? 1)增加程序的复杂度，使程序的编写和维护比较困难，容易出错；2)继承类和基类的同名函数产生了二义性，同名函数不知道调用基类还是继承类，C++中使用虚函数解决这个问题3)继承过程中可能会继承一些不必要的数据，对于多级继承，可能会产生数据很长 可以使用成员限定符和虚函数解决多重继承中函数的二义性问题。 求两个数的乘积和商数，该作用由宏定义来实现 12#define product(a,b) ((a)*(b))#define divide(a,b) ((a)/(b)) 什么叫静态关联，什么叫动态关联 多态中，静态关联是程序在编译阶段就能确定实际执行动作，程序运行才能确定叫动态关联 什么叫智能指针?常用的智能指针有哪些？智能指针的实现？ 智能指针是一个存储指向动态分配（堆）对象指针的类，构造函数传入普通指针，析构函数释放指针。栈上分配，函数或程序结束自动释放，防止内存泄露。使用引用计数器，类与指向的对象相关联，引用计数跟踪该类有多少个对象共享同一指针。创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建，增加引用计数；对一个对象进行赋值时，减少引用计数，并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数，当引用计数减至0，则删除基础对象。 std::auto_ptr，不支持复制（拷贝构造函数）和赋值（operator =），编译不会提示出错。 C++11引入的unique_ptr， 也不支持复制和赋值，但比auto_ptr好，直接赋值会编译出错。 C++11或boost的shared_ptr，基于引用计数的智能指针。可随意赋值，直到内存的引用计数为0的时候这个内存会被释放。还有Weak_ptr 枚举与#define 宏的区别 1）#define 宏常量是在预编译阶段进行简单替换。枚举常量则是在编译的时候确定其值。2）可以调试枚举常量，但是不能调试宏常量。3）枚举可以一次定义大量相关的常量，而#define 宏一次只能定义一个。 介绍一下函数的重载重载是在不同类型上作不同运算而又用同样的名字的函数。重载函数至少在参数个数，参数类型，或参数顺序上有所不同。 派生新类的过程要经历三个步骤 吸收基类成员 改造基类成员 添加新成员 面向对象的三个基本特征，并简单叙述之? 封装：将客观事物抽象成类，每个类对自身的数据和方法实行 继承 多态：允许一个基类的指针或引用指向一个派生类对象 多态性体现都有哪些？动态绑定怎么实现？ 多态性是一个接口,多种实现，是面向对象的核心。 编译时多态性：通过重载函数实现。运行时多态性：通过虚函数实现,结合动态绑定。 虚函数，虚函数表里面内存如何分配？ 编译时若基类中有虚函数，编译器为该的类创建一个一维数组的虚表，存放是每个虚函数的地址。基类和派生类都包含虚函数时，这两个类都建立一个虚表。构造函数中进行虚表的创建和虚表指针的初始化。在构造子类对象时，要先调用父类的构造函数，初始化父类对象的虚表指针，该虚表指针指向父类的虚表。执行子类的构造函数时，子类对象的虚表指针被初始化，指向自身的虚表。每一个类都有虚表。虚表可以继承，如果子类没有重写虚函数，那么子类虚表中仍然会有该函数的地址，只不过这个地址指向的是基类的虚函数实现。派生类的虚表中虚函数地址的排列顺序和基类的虚表中虚函数地址排列顺序相同。 当用一个指针/引用调用一个函数的时候，被调用的函数是取决于这个指针/引用的类型。即如果这个指针/引用是基类对象的指针/引用就调用基类的方法；如果指针/引用是派生类对象的指针/引用就调用派生类的方法，当然如果派生类中没有此方法，就会向上到基类里面去寻找相应的方法。这些调用在编译阶段就确定了。当涉及到多态性的时候，采用了虚函数和动态绑定，此时的调用就不会在编译时候确定而是在运行时确定。不在单独考虑指针/引用的类型而是看指针/引用的对象的类型来判断函数的调用，根据对象中虚指针指向的虚表中的函数的地址来确定调用哪个函数。 纯虚函数如何定义？含有纯虚函数的类称为什么？为什么析构函数要定义成虚函数？ 纯虚函数是在基类中声明的虚函数，它在基类中没有定义，但要求任何派生类都要定义自己的实现方法。纯虚函数是虚函数再加上= 0。virtual void fun ()=0。含有纯虚函数的类称为抽象类在很多情况下，基类本身生成对象是不合情理的。例如，动物作为一个基类可以派生出老虎、孔雀等子类，但动物本身生成对象明显不合常理。同时含有纯虚拟函数的类称为抽象类，它不能生成对象。如果析构函数不是虚函数，那么释放内存时候，编译器会使用静态联编，认为p就是一个基类指针，调用基类析构函数，这样子类对象的内存没有释放，造成内存泄漏。定义成虚函数以后，就会动态联编，先调用子类析构函数，再基类。 C++中哪些不能是虚函数？ 1）普通函数只能重载，不能被重写，因此编译器会在编译时绑定函数。2）构造函数是知道全部信息才能创建对象，然而虚函数允许只知道部分信息。3）内联函数在编译时被展开，虚函数在运行时才能动态绑定函数。4）友元函数 因为不可以被继承。5）静态成员函数 只有一个实体，不能被继承。父类和子类共有。 类型转换有哪些？各适用什么环境？dynamic_cast转换失败时，会出现什么情况(对指针，返回NULL.对引用，抛出bad_cast异常)？ 静态类型转换，static_cast，基本类型之间和具有继承关系的类型。例子A,double类型转换成int。B,将子类对象转换成基类对象。常量类型转换，const_cast, 去除指针变量的常量属性。无法将非指针的常量转换为普通变量。动态类型转换，dynamic_cast，运行时进行转换分析的，并非在编译时进行。dynamic_cast转换符只能用于含有虚函数的类。dynamic_cast用于类层次间的向上转换和向下转换，还可以用于类间的交叉转换。在类层次间进行向上转换，即子类转换为父类，此时完成的功能和static_cast是相同的，因为编译器默认向上转换总是安全的。向下转换时，dynamic_cast具有类型检查的功能，更加安全。类间的交叉转换指的是子类的多个父类之间指针或引用的转换。该函数只能在继承类对象的指针之间或引用之间进行类型转换，或者有虚函数的类。 如何判断一段程序是由C 编译程序还是由C++编译程序编译的？ 12345#ifdef __cpluspluscout&lt;&lt;&quot;C++&quot;;#elsecout&lt;&lt;&quot;c&quot;;#endif 为什么要用static_cast转换而不用c语言中的转换？static_cast转换，它会检查类型看是否能转换，有类型安全检查。比如，这个在C++中合法，但是确实错误的。 12A* a= new A;B* b = (B*)a; 操作符重载（+操作符），具体如何去定义？除了类属关系运算符.、成员指针运算符*、作用域运算符::、sizeof运算符和三目运算符?:。以外，C++中的所有运算符都可以重载。&lt;返回类型说明符&gt; operator &lt;运算符符号&gt;(&lt;参数表&gt;){}重载为类的成员函数和重载为类的非成员函数。参数个数会不同，应为this指针。 内存对齐的原则？ 结构体的大小为最大成员的整数倍。 成员首地址的偏移量为其类型大小整数倍。 内联函数与宏定义的区别？内联函数是用来消除函数调用时的时间开销。频繁被调用的短小函数非常受益。 宏定义不检查函数参数，返回值什么的，只是展开，相对来说，内联函数会检查参数类型，所以更安全。 宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的 动态分配对象和静态分配对象的区别？动态分配就是用运算符new来创建一个类的对象，在堆上分配内存。静态分配就是A a;这样来由编译器来创建一个对象，在栈上分配内存。 explicit是干什么用的 ?构造器 ，可以阻止不应该允许的经过转换构造函数进行的隐式转换的发生。explicit是用来防止外部非正规的拷贝构造的，要想不存在传值的隐式转换问题。 内存溢出有那些因素？(1) 使用非类型安全(non-type-safe)的语言如 C/C++ 等。(2) 以不可靠的方式存取或者复制内存缓冲区。(3) 编译器设置的内存缓冲区太靠近关键数据结构。 new与malloc的区别，delete和free的区别？ malloc/free是C/C++语言的标准库函数，new/delete是C++的运算符 new能够自动分配空间大小，malloc传入参数。 new/delete能进行对对象进行构造和析构函数的调用进而对内存进行更加详细的工作，而malloc/free不能。 既然new/delete的功能完全覆盖了malloc/free，为什么C++还保留malloc/free呢？因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。 必须使用初始化列表初始化数据成员的情况 是对象的情况； const修饰的类成员； 引用成员数据； 类成员变量的初始化不是按照初始化表顺序被初始化，是按照在类中声明的顺序被初始化的。 深入谈谈堆和栈 1).分配和管理方式不同 ： 堆是动态分配的，其空间的分配和释放都由程序员控制。 栈由编译器自动管理。栈有两种分配方式：静态分配和动态分配。静态分配由编译器完成，比如局部变量的分配。动态分配由alloca()函数进行分配，但是栈的动态分配和堆是不同的，它的动态分配是由编译器进行释放，无须手工控制。2).产生碎片不同 对堆来说，频繁的new/delete或者malloc/free势必会造成内存空间的不连续，造成大量的碎片，使程序效率降低。 对栈而言，则不存在碎片问题，因为栈是先进后出的队列，永远不可能有一个内存块从栈中间弹出。3).生长方向不同 堆是向着内存地址增加的方向增长的，从内存的低地址向高地址方向增长。 栈是向着内存地址减小的方向增长，由内存的高地址向低地址方向增长。 内存的静态分配和动态分配的区别？时间不同。静态分配发生在程序编译和连接时。动态分配则发生在程序调入和执行时。空间不同。堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。alloca，可以从栈里动态分配内存，不用担心内存泄露问题，当函数返回时，通过alloca申请的内存就会被自动释放掉。 模版怎么实现？模版作用？实现：template void swap(T&amp; a, T&amp; b){}作用：将算法与具体对象分离，与类型无关，通用，节省精力 多重类构造和析构的顺序 记住析构函数的调用顺序与构造函数是相反的。 迭代器删除元素的会发生什么？ 迭代器失效 静态成员函数和数据成员有什么意义？1）非静态数据成员，每个对象都有自己的拷贝。而静态数据成员被当作是类的成员，是该类的所有对象所共有的，在程序中只分配一次内存只有一份拷贝，所以对象都共享，值对每个对象都是一样的，它的值可以更新。 2）静态数据成员存储在全局数据区，所以不能在类声明中定义，应该在类外定义。由于它不属于特定的类对象，在没有产生类对象时作用域就可见，即在没有产生类的实例时，我们就可以操作它。 3）静态成员函数与静态数据成员一样，都是在类的内部实现，属于类定义的一部分。因为普通成员函数总是具体的属于具体对象的，每个有this指针。静态成员函数没有this指针，它无法访问属于类对象的非静态数据成员，也无法访问非静态成员函数。静态成员之间可以互相访问，包括静态成员函数访问静态数据成员和访问静态成员函数； 4）非静态成员函数可以任意地访问静态成员函数和静态数据成员； 5）没有this指针的额外开销，静态成员函数与类的全局函数相比，速度上会有少许的增长； 6）调用静态成员函数，可以用成员访问操作符(.)和(-&gt;)为一个类的对象或指向类对象的指调用静态成员函数。 sizeof一个类求大小（注意成员变量，函数，虚函数，继承等等对大小的影响） 以下运行环境都是一般的，在32位编译环境中基本数据类型的sizeof1234567cout&lt;&lt;sizeof(char)&lt;&lt;endl; 结果是1cout&lt;&lt;sizeof(int)&lt;&lt;endl; 结果是4cout&lt;&lt;sizeof(unsigned int)&lt;&lt;endl; 结果是4 cout&lt;&lt;sizeof(long int)&lt;&lt;endl; 结果是4cout&lt;&lt;sizeof(short int)&lt;&lt;endl; 结果是2cout&lt;&lt;sizeof(float)&lt;&lt;endl; 结果是4cout&lt;&lt;sizeof(double)&lt;&lt;endl; 结果是8 指针变量的sizeof123456789101112char *pc =&quot;abc&quot;;sizeof( pc ); // 结果为4sizeof(*pc); // 结果为1int *pi;sizeof( pi ); //结果为4sizeof(*pi); //结果为4char **ppc = &amp;pc; sizeof( ppc ); // 结果为4 sizeof( *ppc ); // 结果为4 sizeof( **ppc ); // 结果为1void (*pf)();// 函数指针sizeof( pf );// 结果为4 数组的sizeof数组的sizeof值等于数组所占用的内存字节数，如：1234char a1[] = &quot;abc&quot;;int a2[3];sizeof( a1 ); // 结果为4，字符 末尾还存在一个NULL终止符sizeof( a2 ); // 结果为3*4=12（依赖于int） 写到这里，提一问，下面的c3，c4值应该是多少呢12345678void foo3(char a3[3])&#123; int c3 = sizeof( a3 ); // c3 == 4&#125;void foo4(char a4[])&#123; int c4 = sizeof( a4 ); // c4 == 4&#125; 也许当你试图回答c4的值时已经意识到c3答错了，是的，c3!=3。这里函数参数a3已不再是数组类型，而是蜕变成指针，相当于char* a3，为什么仔细想想就不难明白，我们调用函数foo1时，程序会在栈上分配一个大小为3的数组吗不会！数组是“传址”的，调用者只需将实参的地址传递过去，所以a3自然为指针类型char*，c3的值也就为4。 结构体的sizeof123456struct MyStruct&#123; double dda1; char dda; int type&#125;; //结果为16，为上面的结构分配空间的时候，VC根据成员变量出现的顺序和对齐方式，先为第一个成员dda1分配空间，其起始地址跟结构的起始地址相同（刚好偏移量0刚好为sizeof(double)的倍数），该成员变量占用sizeof(double)=8个字节；接下来为第二个成员dda分配空间，这时下一个可以分配的地址对于结构的起始地址的偏移量为8，是sizeof(char)的倍数，所以把dda存放在偏移量为8的地方满足对齐方式，该成员变量占用sizeof(char)=1个字节；接下来为第三个成员type分配空间，这时下一个可以分配的地址对于结构的起始地址的偏移量为9，不是sizeof(int)=4的倍数，为了满足对齐方式对偏移量的约束问题，VC自动填充3个字节（这三个字节没有放什么东西），这时下一个可以分配的地址对于结构的起始地址的偏移量为12，刚好是sizeof(int)=4的倍数，所以把type存放在偏移量为12的地方，该成员变量占用sizeof(int)=4个字节；这时整个结构的成员变量已经都分配了空间，总的占用的空间大小为：8+1+3+4=16，刚好为结构的字节边界数（即结构中占用最大空间的类型所占用的字节数sizeof(double)=8）的倍数，所以没有空缺的字节需要填充。所以整个结构的大小为：sizeof(MyStruct)=8+1+3+4=16，其中有3个字节是VC自动填充的，没有放任何有意义的东西。 含位域结构体的sizeof示例1：123456struct BF1&#123;char f1 : 3;char f2 : 4;char f3 : 5;&#125;; 位域类型为char，第1个字节仅能容纳下f1和f2，所以f2被压缩到第1个字节中，而f3只能从下一个字节开始。因此sizeof(BF1)的结果为2。 含有联合体的结构体的sizeof12345678910struct s1&#123; char *ptr,ch; //有指针变成4＋4 union A //后面跟了A定义了一个类型,不占内存，而后面不跟A,是声明了结构体的一个成员,占内存, &#123; short a,b; unsigned int c:2, d:1; &#125;; struct s1* next; //指针占4&#125;; 这样是8＋4＝12个字节12345678910struct s1&#123; char *ptr,ch; union //联合体是结构体的成员，占内存，并且最大类型是unsigned int，占4 &#123; short a,b; unsigned int c:2, d:1; &#125;; struct s1* next; &#125;; 这样是8＋4＋4＝16个字节 结构体体含有结构体的sizeof123456789101112struct S1 &#123; char c; int i; &#125;;struct S3 &#123; char c1; S1 s; char c2; &#125;;cout&lt;&lt;sizeof(S3); //S3=16 S1的最宽简单成员的类型为int，S3在考虑最宽简单类型成员时是将S1“打散”看的，所以S3的最宽简单类型为int，这样，通过S3定义的变量，其存储空间首地址需要被4整除，整个sizeof(S3)的值也应该被4整除。c1的偏移量为0，s的偏移量呢这时s是一个整体，它作为结构体变量也满足前面三个准则，所以其大小为8，偏移量为4，c1与s之间便需要3个填充字节，而c2与s之间就不需要了，所以c2的偏移量为12，算上c2的大小为13，13是不能被4整除的，这样末尾还得补上3个填充字节。最后得到sizeof(S3)的值为16。 带有#pragma pack的sizeof它是用来调整结构体对齐方式的，不同编译器名称和用法略有不同，VC6中通过#pragma pack实现，也可以直接修改/Zp编译开关。#pragma pack的基本用法为：#pragma pack( n )，n为字节对齐数，其取值为1、2、4、8、16，默认是8，如果这个值比结构体成员的sizeof值小，那么该成员的偏移量应该以此值为准，即是说，结构体成员的偏移量应该取二者的最小值， 再看示例：1234567891011121314#pragma pack(push) // 将当前pack设置压栈保存#pragma pack(2)// 必须在结构体定义之前使用struct S1&#123; char c; int i;&#125;;struct S3&#123; char c1; S1 s; char c2&#125;;#pragma pack(pop) // 恢复先前的pack设置 计算sizeof(S1)时，min(2, sizeof(i))的值为2，所以i的偏移量为2，加上sizeof(i)等于6，能够被2整除，所以整个S1的大小为6。同样，对于sizeof(S3)，s的偏移量为2，c2的偏移量为8，加上sizeof(c2)等于9，不能被2整除，添加一个填充字节，所以sizeof(S3)等于10。 空结构体的sizeof12struct S5 &#123; &#125;;sizeof( S5 ); // 结果为1 类的sizeof类的sizeof值等于类中成员变量所占用的内存字节数。如：1234567891011121314class A&#123;public: int b; float c; char d;&#125;;int main(void)&#123; A object; cout &lt;&lt; &quot;sizeof(object) is &quot; &lt;&lt; sizeof(object) &lt;&lt; endl; return 0 ;&#125; 输出结果为12（我的机器上sizeof(float)值为4，字节对其前面已经讲过）。 不过需要注意的是，如果类中存在静态成员变量，结果又会是什么样子呢？123456789101112131415class A&#123;public: static int a; int b; float c; char d;&#125;;int main()&#123; A object; cout &lt;&lt; &quot;sizeof(object) is &quot; &lt;&lt; sizeof(object) &lt;&lt; endl; return 0 ;&#125; 16？不对。结果仍然是12. 因为在程序编译期间，就已经为static变量在静态存储区域分配了内存空间，并且这块内存在程序的整个运行期间都存在。 而每次声明了类A的一个对象的时候，为该对象在堆上，根据对象的大小分配内存。 如果类A中包含成员函数，那么又会是怎样的情况呢？看下面的例子123456789101112131415161718192021class A&#123;public: static int a; int b; float c; char d; int add(int x,int y) &#123; return x+y; &#125;&#125;;int main()&#123; A object; cout &lt;&lt; &quot;sizeof(object) is &quot; &lt;&lt; sizeof(object) &lt;&lt; endl; b = object.add(3,4); cout &lt;&lt; &quot;sizeof(object) is &quot; &lt;&lt; sizeof(object) &lt;&lt; endl; return 0 ;&#125; 结果仍为12。 因为只有非静态类成员变量在新生成一个object的时候才需要自己的副本。所以每个非静态成员变量在生成新object需要内存，而function是不需要的。 请用C/C++实现字符串反转（不调用库函数）”abc”类型的 1234567891011121314151617181920212223char *reverse_str(char *str) &#123; if(NULL == str) &#123; //字符串为空直接返回 return str; &#125; char *begin; char *end; begin = end = str; while(*end != &apos;\0&apos;) &#123; //end指向字符串的末尾 end++; &#125; --end; char temp; while(begin &lt; end) &#123; //交换两个字符 temp = *begin; *begin = *end; *end = temp; begin++; end--; &#125; return str; //返回结果&#125; 写一个函数，将字符串翻转，翻转方式如下：“I am a student”反转成“student a am I”，不借助任何库函数 12345678910111213141516171819202122232425262728293031323334353637383940#include &quot;stdio.h&quot;#include &lt;iostream&gt;using namespace std;void revesal(char * start, char* end)&#123; char *temp_s = start; char *temp_e = end; while(temp_s &lt; temp_e)&#123; char temp= *temp_s; *temp_s= *temp_e; *temp_e = temp; ++temp_s; --temp_e; &#125; return;&#125;void revesal_str(char *str)&#123; if(str == NULL)&#123; return; &#125; char *start = str; char *end = str; while(*++end !=&apos;\0&apos;); revesal(start, end-1); cout &lt;&lt; str &lt;&lt; endl; char *sub_start = str; while(start &lt; end + 1 )&#123; if(*start == &apos; &apos; || *start == &apos;\0&apos;)&#123; char *temp = start - 1; revesal(sub_start,temp); while(*++start ==&apos; &apos;); sub_start = start; continue; &#125; ++start; &#125;&#125; 析构函数可以抛出异常吗？为什么不能抛出异常？除了资源泄露，还有其他需考虑的因素吗？C++标准指明析构函数不能、也不应该抛出异常。C++异常处理模型最大的特点和优势就是对C++中的面向对象提供了最强大的无缝支持。那么如果对象在运行期间出现了异常，C++异常处理模型有责任清除那些由于出现异常所导致的已经失效了的对象(也即对象超出了它原来的作用域)，并释放对象原来所分配的资源， 这就是调用这些对象的析构函数来完成释放资源的任务，所以从这个意义上说，析构函数已经变成了异常处理的一部分。 1）如果析构函数抛出异常，则异常点之后的程序不会执行，如果析构函数在异常点之后执行了某些必要的动作比如释放某些资源，则这些动作不会执行，会造成诸如资源泄漏的问题。 2）通常异常发生时，c++的机制会调用已经构造对象的析构函数来释放资源，此时若析构函数本身也抛出异常，则前一个异常尚未处理，又有新的异常，会造成程序崩溃的问题。 拷贝构造函数作用及用途？什么时候需要自定义拷贝构造函数？ 一般如果构造函数中存在动态内存分配，则必须定义拷贝构造函数。否则，可能会导致两个对象成员指向同一地址，出现“指针悬挂问题”。 100万个32位整数，如何最快找到中位数。能保证每个数是唯一的，如何实现O(N)算法？ 1).内存足够时：快排 2).内存不足时：分桶法：化大为小，把所有数划分到各个小区间，把每个数映射到对应的区间里，对每个区间中数的个数进行计数，数一遍各个区间，看看中位数落在哪个区间，若够小，使用基于内存的算法，否则 继续划分 OFFSETOF(s, m)的宏定义，s是结构类型，m是s的成员，求m在s中的偏移量。 1#define OFFSETOF（s, m） size_t（&amp;((s*)0)-&gt;m） C++虚函数是如何实现的？使用虚函数表。 C++对象使用虚表， 如果是基类的实例，对应位置存放的是基类的函数指针；如果是继承类，对应位置存放的是继承类的函数指针（如果在继承类有实现）。所以 ，当使用基类指针调用对象方法时，也会根据具体的实例，调用到继承类的方法。 C++的虚函数有什么作用？虚函数作用是实现多态，虚函数其实是实现封装，使得使用者不需要关心实现的细节。在很多设计模式中都是这样用法，例如Factory、Bridge、Strategy模式。 MFC中CString是类型安全类吗，为什么？ 不是，其他数据类型转换到CString可以使用CString的成员函数Format来转换 动态链接库的两种使用方法及特点？1)．载入时动态链接，模块非常明确调用某个导出函数，使得他们就像本地函数一样。这需要链接时链接那些函数所在DLL的导入库，导入库向系统提供了载入DLL时所需的信息及DLL函数定位。 2)运行时动态链接。 服务器编程 多线程和多进程的区别（重点 必须从cpu调度，上下文切换，数据共享，多核cup利用率，资源占用，等等各方面回答，然后有一个问题必须会被问到：哪些东西是一个线程私有的？答案中必须包含寄存器，否则悲催）！ 1）进程数据是分开的:共享复杂，需要用IPC，同步简单；多线程共享进程数据：共享简单，同步复杂2）进程创建销毁、切换复杂，速度慢 ；线程创建销毁、切换简单，速度快3）进程占用内存多， CPU利用率低；线程占用内存少， CPU利用率高4）进程编程简单，调试简单；线程 编程复杂，调试复杂5）进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉6）进程适应于多核、多机分布；线程适用于多核 线程所私有的： 线程id、寄存器的值、栈、线程的优先级和调度策略、线程的私有数据、信号屏蔽字、errno变量、 多线程锁的种类有哪些？ a.互斥锁（mutex）b.递归锁 c.自旋锁 d.读写锁 自旋锁和互斥锁的区别？ 当锁被其他线程占用时，其他线程并不是睡眠状态，而是不停的消耗CPU，获取锁；互斥锁则不然，保持睡眠，直到互斥锁被释放激活。 自旋锁，递归调用容易造成死锁，对长时间才能获得到锁的情况，使用自旋锁容易造成CPU效率低，只有内核可抢占式或SMP情况下才真正需要自旋锁。 进程间通信和线程间通信 1）.管道 2）消息队列 3)共享内存 4)信号量 5)套接字 6)条件变量 多线程程序架构，线程数量应该如何设置？ 应尽量和CPU核数相等或者为CPU核数+1的个数 什么是原子操作，gcc提供的原子操作原语，使用这些原语如何实现读写锁？ 原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch。 网络编程设计模式，reactor/proactor/半同步半异步模式？ reactor模式：同步阻塞I/O模式，注册对应读写事件处理器，等待事件发生进而调用事件处理器处理事件。 proactor模式：异步I/O模式。Reactor和Proactor模式的主要区别就是真正的读取和写入操作是有谁来完成的，Reactor中需要应用程序自己读取或者写入数据，Proactor模式中，应用程序不需要进行实际读写过程。 Reactor是： 主线程往epoll内核上注册socket读事件，主线程调用epoll_wait等待socket上有数据可读，当socket上有数据可读的时候，主线程把socket可读事件放入请求队列。睡眠在请求队列上的某个工作线程被唤醒，处理客户请求，然后往epoll内核上注册socket写请求事件。主线程调用epoll_wait等待写请求事件，当有事件可写的时候，主线程把socket可写事件放入请求队列。睡眠在请求队列上的工作线程被唤醒，处理客户请求。 Proactor: 主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读完成后如何通知应用程序，主线程继续处理其他逻辑，当socket上的数据被读入用户缓冲区后，通过信号告知应用程序数据已经可以使用。应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后调用aio_write函数向内核注册socket写完成事件，并告诉内核写缓冲区的位置，以及写完成时如何通知应用程序。主线程处理其他逻辑。当用户缓存区的数据被写入socket之后内核向应用程序发送一个信号，以通知应用程序数据已经发送完毕。应用程序预先定义的数据处理函数就会完成工作。 半同步半异步模式： 上层的任务（如：数据库查询，文件传输）使用同步I/O模型，简化了编写并行程序的难度。而底层的任务（如网络控制器的中断处理）使用异步I/O模型，提供了执行效率。 有一个计数器，多个线程都需要更新，会遇到什么问题，原因是什么，应该如何做？如何优化？ 有可能一个线程更新的数据已经被另外一个线程更新了，更新的数据就会出现异常，可以加锁，保证数据更新只会被一个线程完成。 如果select返回可读，结果只读到0字节，什么情况？ 某个套接字集合中没有准备好，可能会select内存用FD_CLR清为0. connect可能会长时间阻塞，怎么解决? 1.使用定时器；（最常用也最有效的一种方法）2.采用非阻塞模式：设置非阻塞，返回之后用select检测状态。 keepalive 是什么东西？如何使用？ keepalive，是在TCP中一个可以检测死连接的机制。 1）.如果主机可达，对方就会响应ACK应答，就认为是存活的。2）.如果可达，但应用程序退出，对方就发RST应答，发送TCP撤消连接。3）.如果可达，但应用程序崩溃，对方就发FIN消息。4）.如果对方主机不响应ack, rst，继续发送直到超时，就撤消连接。默认二个小时。 socket什么情况下可读？ 1.socket接收缓冲区中已经接收的数据的字节数大于等于socket接收缓冲区低潮限度的当前值;对这样的socket的读操作不会阻塞,并返回一个大于0的值(准备好读入的数据的字节数).2.连接的读一半关闭(即:接收到对方发过来的FIN的TCP连接),并且返回0;3.socket收到了对方的connect请求已经完成的连接数为非0.这样的soocket处于可读状态；4.异常的情况下socket的读操作将不会阻塞,并且返回一个错误(-1)。 udp调用connect有什么作用？ 1).因为UDP可以是一对一，多对一，一对多，或者多对多的通信，所以每次调用sendto()/recvfrom()时都必须指定目标IP和端口号。通过调用connect()建立一个端到端的连接，就可以和TCP一样使用send()/recv()传递数据，而不需要每次都指定目标IP和端口号。但是它和TCP不同的是它没有三次握手的过程。 2).可以通过在已建立连接的UDP套接字上，调用connect()实现指定新的IP地址和端口号以及断开连接。 socket编程，如果client断电了，服务器如何快速知道？ 使用定时器（适合有数据流动的情况）； 使用socket选项SO_KEEPALIVE（适合没有数据流动的情况）; 1）、自己编写心跳包程序,简单的说就是自己的程序加入一条线程,定时向对端发送数据包,查看是否有ACK,根据ACK的返回情况来管理连接。此方法比较通用,一般使用业务层心跳处理,灵活可控,但改变了现有的协议;2）、使用TCP的keepalive机制,UNIX网络编程不推荐使用SO_KEEPALIVE来做心）跳检测。keepalive原理:TCP内嵌有心跳包,以服务端为例,当server检测到超过一定时间(/proc/sys/net/ipv4/tcp_keepalive_time 7200 即2小时)没有数据传输,那么会向client端发送一个keepalive packet。 liunx操作系统 熟练netstat tcpdump ipcs ipcrm netstat:检查网络状态，tcpdump:截获数据包，ipcs:检查共享内存，ipcrm:解除共享内存 共享内存段被映射进进程空间之后，存在于进程空间的什么位置？共享内存段最大限制是多少？ 将一块内存映射到两个或者多个进程地址空间。通过指针访问该共享内存区。一般通过mmap将文件映射到进程地址共享区。 存在于进程数据段，最大限制是0x2000000Byte ELF是什么？其大小与程序中全局变量的是否初始化有什么关系（注意未初始化的数据放在bss段） 可执行连接格式。可以减少重新编程重新编译的代码。 动态链接和静态链接的区别？ 动态链接是只建立一个引用的接口，而真正的代码和数据存放在另外的可执行模块中，在可执行文件运行时再装入；而静态链接是把所有的代码和数据都复制到本模块中，运行时就不再需要库了 32位系统一个进程最多有多少堆内存 32位意味着4G的寻址空间，Linux把它分为两部分：最高的1G(虚拟地址从0xC0000000到0xffffffff)用做内核本身，成为“系统空间”，而较低的3G字节（从0x00000000到0xbffffff）用作各进程的“用户空间”。每个进程可以使用的用户空间是3G。虽然各个进程拥有其自己的3G用户空间，系统空间却由所有的进程共享。从具体进程的角度看，则每个进程都拥有4G的虚拟空间，较低的3G为自己的用户空间，最高的1G为所有进程以及内核共享的系统空间。实际上有人做过测试也就2G左右。 写一个c程序辨别系统是64位 or 32位1void* number = 0; printf(&quot;%d\n&quot;,sizeof(&amp;number)); 输出8就是64位 输出4就是32位的 根据逻辑地址判断的 写一个c程序辨别系统是大端or小端字节序 123456789union&#123; short value; char a[sizeof(short)];&#125;test;test.value= 0x0102;if((test.a[0] == 1) &amp;&amp; (test.a[1] == 2)) cout &lt;&lt; &quot;big&quot;&lt;&lt;endl; else cout &lt;&lt; &quot;little&quot; &lt;&lt; endl; 信号：列出常见的信号，信号怎么处理？ 1).进程终止的信号 2).跟踪进程的信号 3).与进程例外事件相关的信号等 对于信号的处理或者执行相关的操作进行处理或者直接忽略 i++ 是否原子操作?并解释为什么? 答案肯定不是原子操作，i++主要看三个步骤 首先把数据从内存放到寄存器上，在寄存器上进行自增处理，放回到寄存器上，每个步骤都可能会被中断分离开！ 说出你所知道的各类linux系统的各类同步机制（重点），什么是死锁？如何避免死锁（每个技术面试官必问） 1).原子操作 2).信号量（其实就是互斥锁也就是锁的机制）3).读写信号量（就是读写锁） 4）.自旋锁 5.内核锁 6）.顺序锁 死锁就是几个进程申请资源，出现了循环等待的情况！ 避免死锁的方法： 1）.资源是互斥的 2）.不可抢占 3）占有且申请 4）.循环等待 如何实现守护进程？ 1）创建子进程，父进程退出 2）在子进程中创建新会话 3）改变当前目录为根目 4）重设文件权限掩码 5) 关闭文件描述符 6) 守护进程退出处理 当用户需要外部停止守护进程运行时，往往会使用 kill命令停止该守护进程。所以，守护进程中需要编码来实现kill发出的signal信号处理，达到进程的正常退出。 linux的任务调度机制是什么？ Linux 分实时进程和普通进程，实时进程应该先于普通进程而运行。实时进程： 1） FIFO(先来先服务调度)2） RR（时间片轮转调度）。 每个进程有两个优先级（动态优先级和实时优先级），实时优先级就是用来衡量实时进程是否值得运行的。 非实时进程有两种优先级，一种是静态优先级，另一种是动态优先级。实时进程又增加了第三种优先级，实时优先级。优先级越高，得到CPU时间的机会也就越大。 标准库函数和系统调用的区别？系统调用：是操作系统为用户态运行的进程和硬件设备(如CPU、磁盘、打印机等)进行交互提供的一组接口，即就是设置在应用程序和硬件设备之间的一个接口层。inux内核是单内核，结构紧凑，执行速度快，各个模块之间是直接调用的关系。linux系统上到下依次是用户进程-&gt;linux内核-&gt;硬件。其中系统调用接口是位于Linux内核中的，整个linux系统从上到下可以是：用户进程-&gt;系统调用接口-&gt;linux内核子系统-&gt;硬件，也就是说Linux内核包括了系统调用接口和内核子系统两部分；或者从下到上可以是：物理硬件-&gt;OS内核-&gt;OS服务-&gt;应用程序，操作系统起到“承上启下”作用，向下管理物理硬件，向上为操作系服务和应用程序提供接口，这里的接口就是系统调用了。库函数：把函数放到库里。是把一些常用到的函数编完放到一个lib文件里，供别人用。别人用的时候把它所在的文件名用#include&lt;&gt;加到里面就可以了。一类是c语言标准规定的库函数，一类是编译器特定的库函数。系统调用是为了方便使用操作系统的接口，而库函数则是为了人们编程的方便。 系统如何将一个信号通知到进程？ 内核给进程发送信号，是在进程所在的进程表项的信号域设置对应的信号的位。进程处理信号的时机就是从内核态即将返回用户态度的时候。执行用户自定义的信号处理函数的方法很巧妙。把该函数的地址放在用户栈栈顶，进程从内核返回到用户态的时候，先弹出信号处理函数地址，于是就去执行信号处理函数了，然后再弹出，才是返回进入内核时的状态。 fork()一子进程程后父进程的全局变量能不能使用？ fork后子进程将会拥有父进程的几乎一切资源，父子进程的都各自有自己的全局变量。不能通用，不同于线程。对于线程，各个线程共享全局变量。 网络编程 使用udp和tcp进程网络传输，为什么tcp能保证包是发送顺序，而 udp无法保证？ 因为TCP发送的数据包是按序号发送，有确认机制和丢失重传机制，而udp是不可靠的发送机制，发送的对应端口的数据包不是按顺序发送的。 epoll哪些触发模式，有啥区别？（必须非常详尽的解释水平触发和边缘触发的区别，以及边缘触发在编程中要做哪些更多的确认） epoll有EPOLLLT和EPOLLET两种触发模式，LT是默认的模式，ET是“高速”模式。LT模式下，只要这个fd还有数据可读，每次 epoll_wait都会返回它的事件，提醒用户程序去操作，而在ET（边缘触发）模式中，它只会提示一次，直到下次再有数据流入之前都不会再提示了，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读光，也就是说一直读到read的返回值小于请求值。 也就是说在LT模式的情况下一定要确认收发的数据包的buffer是不是足够大如果收发数据包大小大于buffer的大小的时候就可能会出现数据丢失的情况。 tcp与udp的区别（必问）为什么TCP要叫做数据流？ 1）．基于连接与无连接2）．对系统资源的要求（TCP较多，UDP少）3）．UDP程序结构较简单4）．流模式与数据报模式5）．TCP保证数据正确性，UDP可能丢包，TCP保证数据顺序，UDP不保证6）.TCP有拥塞控制和流量控制，UDP没有 TCP提供的是面向连接、可靠的字节流服务。当客户和服务器彼此交换数据前，必须先在双方之间建立一个TCP连接，之后才能传输数据。TCP提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。 是一个简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，但是并不能保证它们能到达目的地。由于UDP在传输数据报前不用在客户和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快 流量控制和拥塞控制的实现机制 网络拥塞现象是指到达通信子网中某一部分的分组数量过多,使得该部分网络来不及处理,以致引起这部分乃至整个网络性能下降的现象,严重时甚至会导致网络通信业务陷入停顿,即出现死锁现象。拥塞控制是处理网络拥塞现象的一种机制。数据的传送与接收过程当中很可能出现收方来不及接收的情况,这时就需要对发方进行控制,以免数据丢失。 滑动窗口的实现机制 滑动窗口机制，窗口的大小并不是固定的而是根据我们之间的链路的带宽的大小，这个时候链路是否拥护塞。接受方是否能处理这么多数据了。 滑动窗口协议，是TCP使用的一种流量控制方法。该协议允许发送方在停止并等待确认前可以连续发送多个分组。由于发送方不必每发一个分组就停下来等待确认，因此该协议可以加速数据的传输。 epoll和select的区别？ 1）select在一个进程中打开的最大fd是有限制的，由FD_SETSIZE设置，默认值是2048。不过 epoll则没有这个限制，内存越大，fd上限越大，1G内存都能达到大约10w左右。 2）select的轮询机制是系统会去查找每个fd是否数据已准备好，当fd很多的时候，效率当然就直线下降了，epoll采用基于事件的通知方式，一旦某个fd数据就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，高效。 3）select还是epoll都需要内核把FD消息通知给用户空间，epoll是通过内核于用户空间mmap同一块内存实现的，而select则做了不必要的拷贝 网络中，如果客户端突然掉线或者重启，服务器端怎么样才能立刻知道？ 若客户端掉线或者重新启动，服务器端会收到复位信号，每一种tcp/ip得实现不一样，控制机制也不一样。 TTL是什么？有什么用处，通常那些工具会用到它？ping? traceroute? ifconfig? netstat? TTL是Time To Live，每经过一个路由就会被减去一，如果它变成0，包会被丢掉。它的主要目的是防止包在有回路的网络上死转，浪费网络资源。ping和traceroute用到它。 linux的五种IO模式/异步模式. 1）同步阻塞I/O2）同步非阻塞I/O3）同步I/O复用模型4） 同步信号驱动I/O5） 异步I/O模型 请说出http协议的优缺点. 支持客户/服务器模式。 简单快速：客户向服务器请求服务时，只需传送请求方法和路径，通信速度很快。 灵活：HTTP允许传输任意类型的数据对象。 无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，导致每次连接传送的数据量增大。缺点就是不够安全，可以使用https完成使用 NAT类型，UDP穿透原理。 1）Full cone NAT （全克隆nat）:一对一NAT一旦一个内部地址（iAddr:port1）映射到外部地址（eAddr:port2）。 2）Address-Restricted cone NAT（地址受限克隆nat）:任意外部主机（hostAddr:any）都能通过给eAddr:port2发包到达iAddr:port1的前提是：iAddr:port1之前发送过包到hostAddr:any. “any”也就是说端口不受限制 3). Port-Restricted cone NAT:内部地址（iAddr:port1）映射到外部地址（eAddr:port2），所有发自iAddr:port1的包都经eAddr:port2向外发送。一个外部主机（hostAddr:port3）能够发包到达iAddr:port1的前提是：iAddr:port1之前发送过包到hostAddr:port3. 4). Symmetric NAT（对称NAT）:同内部IP与port的请求到一个特定目的地的IP地址和端口，映射到一个独特的外部来源的IP地址和端口。同一个内部主机发出一个信息包到不同的目的端，不同的映射使用外部主机收到了一封包从一个内部主机可以送一封包回来 大规模连接上来，并发模型怎么设计 Epoll+线程池（epoll可以采用libevent处理） 流量控制与拥塞控制的区别，节点计算机怎样感知网络拥塞了？拥塞控制是把整体看成一个处理对象的，流量控制是对单个的节点。 感知的手段应该不少，比如在TCP协议里，TCP报文的重传本身就可以作为拥塞的依据。依据这样的原理， 应该可以设计出很多手段。 算法和数据结构 给定一个单向链表（长度未知），请设计一个既节省时间又节省空间的算法来找出该链表中的倒数第m个元素。实现这个算法，并为可能出现的特例情况安排好处理措施。“倒数第m个元素”是这样规定的：当m=0时，链表的最后一个元素将被返回。 解决问题方法思路如下： 方法一、如果我们知道链表的长度n，查找倒数第m个元素，也就是查找正序的第（n - m）个元素（这里的序号只是为了分析，可能跟题目不一定正确的符合）。那么这样来说就简单很多。首先遍历链表得到链表长度，然后重新遍历一次，查找正数第（n-m）个元素。时间复杂度大约是O(2n)。 方法二、我们是不是可以提供一个辅助存储空间，是的我们在遍历到链表结束的时候可以回溯到倒数第m个元素。比如用一个支持随机访问的容器记录链表每一个节点的地址。那么这样的就可以只遍历一次链表就能得到结果。时间复杂度大约是O(n)，但是我们是用空间换取时间的，辅助存储空间的大小由m决定，如果m过大也是不可取的。 方法三、头结点指针为当前指针，尾节点指针为拖后指针。开始的时候当前指针和拖后指针初始化为链表的头结点，首先我们让当前指针遍历到第m个元素，拖后指针不变；然后同步更新当前指针和拖后指针；直到当前指针为链表结尾。这样我们就能保证当前指针和拖尾指针之间的距离是m。 代码如下：12345678910111213141516171819202122Node* FindMToLastNode(Node* pHead, int m) &#123; // 查找到第m个元素 Node* pCurrent = pHead; for (int i = 0; i &lt; m; ++i) &#123; if (pCurrent) &#123; pCurrent = pCurrent-&gt;next; &#125; else &#123; return NULL; &#125; &#125; Node* pFind = pHead; while (pCurrent) &#123; pFind = pFind-&gt;next; pCurrent = pCurrent-&gt;next; &#125; return pFind; &#125; 给定一个单向链表（长度未知），请遍历一次就找到中间的指针，假设该链表存储在只读存储器，不能被修改 设置两个指针，一个每次移动两个位置，一个每次移动一个位置，当第一个指针到达尾节点时，第二个指针就达到了中间节点的位置 处理链表问题时，”快行指针“是一种很常见的技巧，快行指针指的是同时用两个指针来迭代访问链表，只不过其中一个比另一个超前一些。快指针往往先行几步，或与慢指针相差固定的步数。1234567891011121314151617181920212223242526272829303132333435363738node *create() &#123; node *p1, *p2, *head; int cycle = 1, x; head = (node*)malloc(sizeof(node)); p1 = head; while (cycle) &#123; cout &lt;&lt; &quot;please input an integer: &quot;; cin &gt;&gt; x; if (x != 0) &#123; p2 = (node*)malloc(sizeof(node)); p2-&gt;data = x; p1-&gt;next = p2; p1 = p2; &#125; else &#123; cycle = 0; &#125; &#125; head = head-&gt;next; p1-&gt;next = NULL; return head; &#125; void findmid(node* head) &#123; node *p1, *p2, *mid; p1 = head; p2 = head; while (p1-&gt;next-&gt;next != NULL) &#123; p1 = p1-&gt;next-&gt;next; p2 = p2-&gt;next; mid = p2; &#125; &#125; 将一个数组生成二叉排序树 排序，选数组中间的一个元素作为根节点，左边的元素构造左子树，右边的节点构造有子树。 查找数组中第k大的数字？ 因为快排每次将数组划分为两组加一个枢纽元素，每一趟划分你只需要将k与枢纽元素的下标进行比较，如果比枢纽元素下标大就从右边的子数组中找，如果比枢纽元素下标小从左边的子数组中找，如果一样则就是枢纽元素，找到，如果需要从左边或者右边的子数组中再查找的话，只需要递归一边查找即可，无需像快排一样两边都需要递归，所以复杂度必然降低。 最差情况如下：假设快排每次都平均划分，但是都不在枢纽元素上找到第k大第一趟快排没找到，时间复杂度为O(n)，第二趟也没找到，时间复杂度为O(n/2)，第k趟找到，时间复杂度为O(n/2k)，所以总的时间复杂度为O(n(1+1/2+….+1/2k))=O(n)，明显比冒泡快，虽然递归深度是一样的，但是每一趟时间复杂度降低。 红黑树的定义和解释？B树的基本性质？ 红黑树： 性质1. 节点是红色或黑色。性质2. 根节点是黑色。性质3. 每个叶子结点都带有两个空的黑色结点（被称为黑哨兵），如果一个结点n的只有一个左孩子，那么n的右孩子是一个黑哨兵；如果结点n只有一个右孩子，那么n的左孩子是一个黑哨兵。性质4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点)性质5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 B树： 所有非叶子结点至多拥有两个儿子（Left和Right）； 所有结点存储一个关键字； 非叶子结点的左指针指向小于其关键字的子树，右指针指向大于其关键字的子树； 常见的加密算法？ 对称式加密就是加密和解密使用同一个密钥。非对称式加密就是加密和解密所使用的不是同一个密钥，通常有两个密钥，称为“公钥”和“私钥”，它们两个必需配对使用。DES：对称算法，数据加密标准，速度较快，适用于加密大量数据的场合；MD5的典型应用是对一段Message产生fingerprint(指纹)，以防止被“篡改”。RSA是第一个既能用于数据加密也能用于数字签名的算法。 https? HTTP下加入SSL层，HTTPS的安全基础是SSL。 简述一致性hash算法。 1）首先求memcached服务器（节点）的哈希值，并将其配置到0～232的圆（continuum）。 2）然后采用同样的方法求出存储数据的键的哈希值，并映射到相同的圆上。 3）然后从数据映射到的位置开始顺时针查找，将数据保存到找到的第一个服务器上。如果超过232仍然找不到服务器，就会保存到第一台memcached服务器上。 描述一种hash table的实现方法 1） 除法散列法: p ，令 h(k ) = k mod p ，这里， p 如果选取的是比较大的素数，效果比较好。而且此法非常容易实现，因此是最常用的方法。最直观的一种，上图使用的就是这种散列法，公式： index = value % 16，求模数其实是通过一个除法运算得到的。 2） 平方散列法 :求index频繁的操作，而乘法的运算要比除法来得省时。公式： index = (value * value) &gt;&gt; 28 （右移，除以2^28。记法：左移变大，是乘。右移变小，是除） 3） 数字选择法:如果关键字的位数比较多，超过长整型范围而无法直接运算，可以选择其中数字分布比较均匀的若干位，所组成的新的值作为关键字或者直接作为函数值。 4） 斐波那契（Fibonacci）散列法:平方散列法的缺点是显而易见的，通过找到一个理想的乘数index = (value * 2654435769) &gt;&gt; 28 冲突处理：令数组元素个数为 S ，则当 h(k) 已经存储了元素的时候，依次探查 (h(k)+i) mod S , i=1,2,3…… ，直到找到空的存储单元为止（或者从头到尾扫描一圈仍未发现空单元，这就是哈希表已经满了，发生了错误。当然这是可以通过扩大数组范围避免的）。 各类树结构的实现和应用 hash，任何一个技术面试官必问（例如为什么一般hashtable的桶数会取一个素数？如何有效避免hash结果值的碰撞） 不选素数的话可能会造成hash出值的范围和原定义的不一致 什么是平衡二叉树? 左右子树都是平衡二叉树，而且左右子树的深度差值的约对值不大于1。 数组和链表的优缺点 数组，在内存上给出了连续的空间。链表，内存地址上可以是不连续的，每个链表的节点包括原来的内存和下一个节点的信息(单向的一个，双向链表的话，会有两个)。 数组优于链表的: A. 内存空间占用的少。B. 数组内的数据可随机访问，但链表不具备随机访问性。C. 查找速度快 链表优于数组的: A. 插入与删除的操作方便。B. 内存地址的利用率方面链表好。C. 方便内存地址扩展。 4G的long型整数中找到一个最大的，如何做？ 每次从磁盘上尽量多读一些数到内存区，然后处理完之后再读入一批。减少IO次数，自然能够提高效率。分批读入选取最大数，再对缓存的最大数进行快排。 有千万个string在内存怎么高速查找，插入和删除？ 对千万个string做hash，可以实现高速查找，找到了，插入和删除就很方便了。关键是如何做hash，对string做hash，要减少碰撞频率。 100亿个数，求最大的1万个数，并说出算法的时间复杂度在内存中维护一个大小为10000的最小堆，每次从文件读一个数，与最小堆的堆顶元素比较，若比堆顶元素大，则替换掉堆顶元素，然后调整堆。最后剩下的堆内元素即为最大的1万个数，算法复杂度为O(NlogN)]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1104. Path In Zigzag Labelled Binary Tree]]></title>
    <url>%2F2019%2F08%2F13%2FLeetcode1104%2F</url>
    <content type="text"><![CDATA[In an infinite binary tree where every node has two children, the nodes are labelled in row order. In the odd numbered rows (ie., the first, third, fifth,…), the labelling is left to right, while in the even numbered rows (second, fourth, sixth,…), the labelling is right to left. Given the label of a node in this tree, return the labels in the path from the root of the tree to the node with that label. Example 1: Input: label = 14Output: [1,3,4,14]Example 2: Input: label = 26Output: [1,2,6,10,26] Constraints: 1 &lt;= label &lt;= 10^6 1234567891011121314151617181920class Solution &#123; public: vector&lt;int&gt; res; vector&lt;int&gt; pathInZigZagTree(int label) &#123; build(label); return res; &#125; void build(int label)&#123; int level; int lastMin; res.insert(res.begin(), label); if(label != 1)&#123; level = (int)(log(label)/log(2)); lastMin = pow(2, level)/2; printf(&quot;%d %d\n&quot;,level,lastMin); build( lastMin + (lastMin*2)-1 - label/2 ); &#125; &#125;&#125;; 因为不管是奇数行还是偶数行，该行与上一行的方向都是反着来的 可以先求出顺着来时这个结点对应的父结点，再求出对应父结点在它所在行对称的结点 这里有个求对称的方法：按顺序排列且每个数都能找到对称数的一系列数，每一对对陈数的和都相同，所以求某个数的在某一行的对称数，只用找出这一行两端的数，求出和，再减去这个数就能得到这个数的对称数 所以只用从传进来的这个结点递归，每次递归求出自己对应的父结点，递归到1时结束，每次递归记录一次当前结点的号码 最后得到的一系列结点号码就是路径]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1079. Letter Tile Possibilities]]></title>
    <url>%2F2019%2F08%2F13%2FLeetcode1079%2F</url>
    <content type="text"><![CDATA[Letter Tile Possibilities You have a set of tiles, where each tile has one letter tiles[i] printed on it. Return the number of possible non-empty sequences of letters you can make. Example 1: Input: “AAB”Output: 8Explanation: The possible sequences are “A”, “B”, “AA”, “AB”, “BA”, “AAB”, “ABA”, “BAA”.Example 2: Input: “AAABBC”Output: 188 Note: 1 &lt;= tiles.length &lt;= 7tiles consists of uppercase English letters. 求一个字符串的所有子串。第一想法优先使用全排列，即深度优先，但有一个核心问题：子串怎么办？全排列无法解决，子串的检索问题，这是我一开始苦思而不得解的地方。 解法一： 这是本题区别于普通全排列中，最隐蔽而又最有趣的一个点：字符串的全排列出来了，那字符串的所有不同子串，还会远吗？ 答案就是，全排列字符串的所有前缀子串里！检索全排列的全部不同子串（包含全排列本身），即为所求。 解法二： 因为问题的规模在7个字符内，解法一在时间和内存上均可接受。但当问题规模快速扩大时，基于解法一，如何优化？ 优化核心是，首先将字符串排序（排序大法好），一旦发生不同字符间的交换，则自字符串起始位置至交换发生的位置为前缀的子串，均发生变化！ 1234567891011121314151617181920class Solution &#123; public: int res=0; void dfs(string tiles, int i)&#123; res++; for (int j = i; j &lt; tiles.size(); j++)&#123; if(i!=j &amp;&amp; tiles[i]==tiles[j]) continue; swap(tiles[i], tiles[j]); dfs(tiles, i+1); &#125; &#125; int numTilePossibilities(string tiles) &#123; sort(tiles.begin(),tiles.end()); dfs(tiles,0); return res-1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1008. Construct Binary Search Tree from Preorder Traversal]]></title>
    <url>%2F2019%2F08%2F13%2FLeetcode1008%2F</url>
    <content type="text"><![CDATA[Return the root node of a binary search tree that matches the given preorder traversal. (Recall that a binary search tree is a binary tree where for every node, any descendant of node.left has a value &lt; node.val, and any descendant of node.right has a value &gt; node.val. Also recall that a preorder traversal displays the value of the node first, then traverses node.left, then traverses node.right.) Example 1: Input: [8,5,1,7,10,12]Output: [8,5,10,1,7,null,12] 123456789101112131415161718192021222324252627282930313233/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;;*/class Solution &#123; public: TreeNode* build(vector&lt;int&gt;&amp; preorder,int i,int j)&#123; if(i&gt;=j)&#123; return NULL; &#125; int temp=preorder[i]; int ii; for(ii=i+1;ii&lt;j;ii++) if(temp&lt;preorder[ii]) break; TreeNode* root = new TreeNode(preorder[i]); root-&gt;left = build(preorder,i+1,ii); root-&gt;right = build(preorder,ii,j); return root; &#125; TreeNode* bstFromPreorder(vector&lt;int&gt;&amp; preorder) &#123; if(preorder.empty()) return NULL; return build(preorder,0,preorder.size()); &#125;&#125;; 一道简单的中序遍历题竟然做了这么久。。。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode2. Defanging an IP Address]]></title>
    <url>%2F2019%2F08%2F13%2FLeetcode1108%2F</url>
    <content type="text"><![CDATA[Defanging an IP AddressEasy Given a valid (IPv4) IP address, return a defanged version of that IP address. A defanged IP address replaces every period “.” with “[.]”. Example 1: Input: address = “1.1.1.1”Output: “1[.]1[.]1[.]1”Example 2: Input: address = “255.100.50.0”Output: “255[.]100[.]50[.]0” Constraints: The given address is a valid IPv4 address. 把IP地址中的“.”换成“[.]”，没有难度。 12345678910111213141516class Solution &#123; public: string defangIPaddr(string address) &#123; string answer(address.length()+6,&apos;\0&apos;); for(int i=0, j=0;i&lt;address.length();i++)&#123; if(address[i]==&apos;.&apos;)&#123; answer[j++]=&apos;[&apos;; answer[j++]=&apos;.&apos;; answer[j++]=&apos;]&apos;; &#125; else answer[j++]=address[i]; &#125; return answer; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用CAS操作（Compare And Set）实现无锁队列]]></title>
    <url>%2F2019%2F08%2F12%2F%E5%88%A9%E7%94%A8CAS%E6%93%8D%E4%BD%9C%EF%BC%88Compare%20And%20Set%EF%BC%89%E5%AE%9E%E7%8E%B0%E6%97%A0%E9%94%81%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[关于CAS等原子操作在开始说无锁队列之前，我们需要知道一个很重要的技术就是CAS操作——Compare &amp; Set，或是 Compare &amp; Swap，现在几乎所有的CPU指令都支持CAS的原子操作，X86下对应的是 CMPXCHG 汇编指令。有了这个原子操作，我们就可以用其来实现各种无锁（lock free）的数据结构。 这个操作用C语言来描述就是下面这个样子：（代码来自Wikipedia的Compare And Swap词条）意思就是说，看一看内存*reg里的值是不是oldval，如果是的话，则对其赋值newval。 1234567int compare_and_swap (int* reg, intoldval, intnewval)&#123; intold_reg_val = *reg; if(old_reg_val == oldval) *reg = newval; returnold_reg_val;&#125; 这个操作可以变种为返回bool值的形式（返回 bool值的好处在于，可以调用者知道有没有更新成功）：12345678bool compare_and_swap (int*accum, int*dest, intnewval)&#123; if( *accum == *dest ) &#123; *dest = newval; returntrue; &#125; returnfalse;&#125; 与CAS相似的还有下面的原子操作：（这些东西大家自己看Wikipedia吧） Fetch And Add，一般用来对变量做 +1 的原子操作 Test-and-set，写值到某个内存位置并传回其旧值。汇编指令BST Test and Test-and-set，用来低低Test-and-Set的资源争夺情况 注：在实际的C/C++程序中，CAS的各种实现版本如下： 1）GCC的CAS GCC4.1+版本中支持CAS的原子操作（完整的原子操作可参看 GCC Atomic Builtins）12bool __sync_bool_compare_and_swap (type *ptr, type oldval type newval, ...)type __sync_val_compare_and_swap (type *ptr, type oldval type newval, ...) 2）Windows的CAS 在Windows下，你可以使用下面的Windows API来完成CAS：（完整的Windows原子操作可参看MSDN的InterLocked Functions）123Interlocked CompareExchange ( __inoutLONGvolatile *Target, __inLONGExchange, __inLONGComperand); 3) C++11中的CAS C++11中的STL中的atomic类的函数可以让你跨平台。（完整的C++11的原子操作可参看 Atomic Operation Library）123456template&lt;classT &gt;bool atomic_compare_exchange_weak( std::atomic&lt;T&gt;* obj, T* expected, T desired );template&lt;classT &gt;bool atomic_compare_exchange_weak( volatilestd::atomic&lt;T&gt;* obj, T* expected, T desired ); 无锁队列的链表实现下面的东西主要来自John D. Valois 1994年10月在拉斯维加斯的并行和分布系统系统国际大会上的一篇论文——《Implementing Lock-Free Queues》。 我们先来看一下进队列用CAS实现的方式：12345678910111213EnQueue(x)//进队列&#123; //准备新加入的结点数据 q = newrecord(); q-&gt;value = x; q-&gt;next = NULL; do&#123; p = tail; //取链表尾指针的快照 &#125;while( CAS(p-&gt;next, NULL, q) != TRUE); //如果没有把结点链上，再试 CAS(tail, p, q); //置尾结点&#125; 我们可以看到，程序中的那个 do-while 的 Re-Try-Loo。就是说，很有可能我在准备在队列尾加入结点时，别的线程已经加成功了，于是tail指针就变了，于是我的CAS返回了false，于是程序再试，直到试成功为止。这个很像我们的抢电话热的不停重播的情况。 你会看到，为什么我们的“置尾结点”的操作不判断是否成功，因为： 如果有一个线程T1，它的while中的CAS如果成功的话，那么其它所有的随后线程的CAS都会失败，然后就会再循环， 此时，如果T1 线程还没有更新tail指针，其它的线程继续失败，因为tail-&gt;next不是NULL了。 直到T1线程更新完tail指针，于是其它的线程中的某个线程就可以得到新的tail指针，继续往下走了。 这里有一个潜在的问题——如果T1线程在用CAS更新tail指针的之前，线程停掉了，那么其它线程就进入死循环了。下面是改良版的EnQueue() 123456789101112131415EnQueue(x)//进队列改良版&#123; q = newrecord(); q-&gt;value = x; q-&gt;next = NULL; p = tail; oldp = p do&#123; while(p-&gt;next != NULL) p = p-&gt;next; &#125;while( CAS(p.next, NULL, q) != TRUE); //如果没有把结点链上，再试 CAS(tail, oldp, q); //置尾结点&#125; 我们让每个线程，自己fetch 指针 p 到链表尾。但是这样的fetch会很影响性能。而通实际情况看下来，99.9%的情况不会有线程停转的情况，所以，更好的做法是，你可以接合上述的这两个版本，如果retry的次数超了一个值的话（比如说3次），那么，就自己fetch指针。 好了，我们解决了EnQueue，我们再来看看DeQueue的代码：（很简单，我就不解释了） 12345678910DeQueue()//出队列&#123; do&#123; p = head; if(p-&gt;next == NULL)&#123; returnERR_EMPTY_QUEUE; &#125; while( CAS(head, p, p-&gt;next) != TRUE ); returnp-&gt;next-&gt;value;&#125; 我们可以看到，DeQueue的代码操作的是 head-&gt;next，而不是head本身。这样考虑是因为一个边界条件，我们需要一个dummy的头指针来解决链表中如果只有一个元素，head和tail都指向同一个结点的问题，这样EnQueue和DeQueue要互相排斥了。 CAS的ABA问题所谓ABA（见维基百科的ABA词条），问题基本是这个样子： 进程P1在共享变量中读到值为A P1被抢占了，进程P2执行 P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占。 P1回来看到共享变量里的值没有被改变，于是继续执行。 虽然P1以为变量值没有改变，继续执行了，但是这个会引发一些潜在的问题。ABA问题最容易发生在lock free 的算法中的，CAS首当其冲，因为CAS判断的是指针的地址。如果这个地址被重用了呢，问题就很大了。 比如上述的DeQueue()函数，因为我们要让head和tail分开，所以我们引入了一个dummy指针给head，当我们做CAS的之前，如果head的那块内存被回收并被重用了，而重用的内存又被EnQueue()进来了，这会有很大的问题。（内存管理中重用内存基本上是一种很常见的行为） 这个例子你可能没有看懂，维基百科上给了一个活生生的例子—— 你拿着一个装满钱的手提箱在飞机场，此时过来了一个火辣性感的美女，然后她很暖昧地挑逗着你，并趁你不注意的时候，把用一个一模一样的手提箱和你那装满钱的箱子调了个包，然后就离开了，你看到你的手提箱还在那，于是就提着手提箱去赶飞机去了。 解决ABA的问题维基百科上给了一个解——使用double-CAS（双保险的CAS），例如，在32位系统上，我们要检查64位的内容 一次用CAS检查双倍长度的值，前半部是指针，后半部分是一个计数器。 只有这两个都一样，才算通过检查，要吧赋新的值。并把计数器累加1。 这样一来，ABA发生时，虽然值一样，但是计数器就不一样（但是在32位的系统上，这个计数器会溢出回来又从1开始的，这还是会有ABA的问题） 当然，我们这个队列的问题就是不想让那个内存重用，这样明确的业务问题比较好解决，论文《Implementing Lock-Free Queues》给出一这么一个方法——使用结点内存引用计数refcnt！1234567891011121314151617SafeRead(q)&#123; loop: p = q-&gt;next; if(p == NULL)&#123; returnp; &#125; Fetch&amp;Add(p-&gt;refcnt, 1); if(p == q-&gt;next)&#123; returnp; &#125;else&#123; Release(p); &#125; gotoloop;&#125; 其中的 Fetch&amp;Add和Release分是是加引用计数和减引用计数，都是原子操作，这样就可以阻止内存被回收了。 用数组实现无锁队列本实现来自论文《Implementing Lock-Free Queues》 使用数组来实现队列是很常见的方法，因为没有内存的分部和释放，一切都会变得简单，实现的思路如下： 数组队列应该是一个ring buffer形式的数组（环形数组） 数组的元素应该有三个可能的值：HEAD，TAIL，EMPTY（当然，还有实际的数据） 数组一开始全部初始化成EMPTY，有两个相邻的元素要初始化成HEAD和TAIL，这代表空队列。 EnQueue操作。假设数据x要入队列，定位TAIL的位置，使用double-CAS方法把(TAIL, EMPTY) 更新成 (x, TAIL)。需要注意，如果找不到(TAIL, EMPTY)，则说明队列满了。 DeQueue操作。定位HEAD的位置，把(HEAD, x)更新成(EMPTY, HEAD)，并把x返回。同样需要注意，如果x是TAIL，则说明队列为空。 算法的一个关键是——如何定位HEAD或TAIL？ 我们可以声明两个计数器，一个用来计数EnQueue的次数，一个用来计数DeQueue的次数。 这两个计算器使用使用Fetch&amp;ADD来进行原子累加，在EnQueue或DeQueue完成的时候累加就好了。 累加后求个模什么的就可以知道TAIL和HEAD的位置了。 如下图所示： 小结以上基本上就是所有的无锁队列的技术细节，这些技术都可以用在其它的无锁数据结构上。 无锁队列主要是通过CAS、FAA这些原子操作，和Retry-Loop实现。 对于Retry-Loop，我个人感觉其实和锁什么什么两样。只是这种“锁”的粒度变小了，主要是“锁”HEAD和TAIL这两个关键资源。而不是整个数据结构。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode25. Reverse Nodes in k-Group]]></title>
    <url>%2F2019%2F08%2F12%2FLeetcode25%2F</url>
    <content type="text"><![CDATA[Reverse Nodes in k-GroupHard Given a linked list, reverse the nodes of a linked list k at a time and return its modified list. k is a positive integer and is less than or equal to the length of the linked list. If the number of nodes is not a multiple of k then left-out nodes in the end should remain as it is. Example: Given this linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5 For k = 2, you should return: 2-&gt;1-&gt;4-&gt;3-&gt;5 For k = 3, you should return: 3-&gt;2-&gt;1-&gt;4-&gt;5 Note: Only constant extra memory is allowed.You may not alter the values in the list’s nodes, only nodes itself may be changed. 给你一个链表，每 k 个节点一组进行翻转，请你返回翻转后的链表。k 是一个正整数，它的值小于或等于链表的长度。如果节点总数不是 k 的整数倍，那么请将最后剩余的节点保持原有顺序。 把一个很长的链表分成很多个小链表，每一份的长度都是 k (最后一份的长度如果小于 k 则不需要反转)，然后对每个小链表进行反转，最后将所有反转后的小链表按之前的顺序拼接在一起。 第一，在反转子链表的时候，上一个子链表的尾必须知道 第二，下一个子链表的头也必须知道 第三，当前反转的链表的头尾都必须知道 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* reverseKGroup(ListNode* head, int k) &#123; if(head==NULL || head-&gt;next==NULL || k&lt;=1)&#123; return head; &#125; ListNode* dummy = new ListNode(0); dummy-&gt;next = head; ListNode* pointer = dummy; // 强行找一个前驱，整个链表的前驱 while(pointer != NULL)&#123; ListNode* lastGroup = pointer; // 记录上一个子链表的尾 int i; for(i=0;i&lt;k;i++)&#123; pointer = pointer-&gt;next; if(pointer==NULL) break; &#125; // 如果当前子链表的节点数满足 k, 就进行反转 // 反之，说明程序到尾了，节点数不够，不用反转 // 每次进行交换时记得把这个子链表前一个和后一个记下来 if(i==k)&#123; // 记录下一个子链表的头，作为反转时的“哨兵” // 并且在反转完之后把反转完之后的链表接起来 ListNode* nextGroup = pointer-&gt;next; // 反转当前子链表，reverse 函数返回反转后子链表的头 ListNode* reversedList = reverse(lastGroup-&gt;next, nextGroup); // lastGroup 是上一个子链表的尾，其 next 指向当前反转子链表的头 // 但是因为当前链表已经被反转，所以它指向的是反转后的链表的尾 pointer = lastGroup-&gt;next; // 将上一个链表的尾连向反转后链表的头 lastGroup-&gt;next = reversedList; // 当前反转后的链表的尾连向下一个子链表的头 pointer-&gt;next = nextGroup; &#125; &#125; return dummy-&gt;next; &#125; ListNode* reverse(ListNode* head, ListNode* tail) &#123; if(head==NULL || head-&gt;next==NULL)&#123; return head; &#125; ListNode* prev = NULL, *temp = NULL; while(head!=NULL &amp;&amp; head!=tail)&#123; temp = head-&gt;next; head-&gt;next = prev; prev = head; head = temp; &#125; return prev; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode322. Coin Change]]></title>
    <url>%2F2019%2F08%2F12%2FLeetcode322%2F</url>
    <content type="text"><![CDATA[简单dp You are given coins of different denominations and a total amount of money amount. Write a function to compute the fewest number of coins that you need to make up that amount. If that amount of money cannot be made up by any combination of the coins, return -1. Example 1: Input: coins = [1, 2, 5], amount = 11Output: 3Explanation: 11 = 5 + 5 + 1Example 2: Input: coins = [2], amount = 3Output: -1Note:You may assume that you have an infinite number of each kind of coin. 我们希望既避免重复地计算，又避免无意义的计算（没有答案的子问题）。生成所有可能的金钱总量就可以避免无意义的计算。dp[i]表示金钱i对应的最少硬币数。 初始的金钱总量为0，硬币面值为 coins = [1, 2, 5]。 只有一个硬币可以组成的金钱分别为[1, 2, 5]，dp[1]=dp[2]=dp[5]=1 在金钱为1的基础上继续生成[2, 3, 6]，即dp[3]=dp[6]=2，而dp[2]=min(dp[2],dp[1]+1)=1 在金钱为2的基础上生成[3, 4, 7]，即dp[4]=dp[7]=dp[2]+1=2 在金钱为3的基础上生成[4, 5, 8]，即dp[8]=2 依次更新，直到计算到以金钱amount为基础时，结束。 当以某个金钱为基础生成接下来的金钱时，这个金钱对应的最少硬币数已经得到。通过这种递推的方式可以生成所有的小于amount的有解金钱总量，反证法证明之 假设某个金钱m是有解的，但是并没有被上述的递推过程生成 m一定是由{ m-coins[i] | 0 &lt;= i &lt; coins.size() }中某个金钱生成的，这些金钱中一定有某几个（或一个）是有解的，但是也没有被递推过程生成，这样反向推理肯定可以到初始金钱数为0 既然能反推到初始金钱数，那么m一定是有解的。 解题的思想有点类似有向图的宽度优先搜索找最短路径 所有的小于amount的有解金钱总量对应于有向图中的结点 m &lt; n ,结点m和n之前有边m -&gt; n当且仅当 m + coins[i] = n 每条边的权值为1，对应于每次硬币数加1 123456789101112131415161718class Solution &#123;public: int coinChange(vector&lt;int&gt;&amp; coins, int amount) &#123; sort(coins.begin(), coins.end()); vector&lt;int&gt; dp(amount+1,INT_MAX); dp[0]=0; for(int i=0;i&lt;amount;i++)&#123; if(dp[i]==INT_MAX) continue; for(auto&amp; num: coins)&#123; if(i+(long long)num&gt;amount) break; dp[i+num] = min(dp[i]+1,dp[i+num]); &#125; &#125; return dp[amount]==INT_MAX?-1:dp[amount]; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[谈谈数据库的ACID]]></title>
    <url>%2F2019%2F08%2F12%2F%E8%B0%88%E8%B0%88%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84ACID%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/shuaihj/article/details/14163713 事务定义：所谓事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。 准备工作：为了说明事务的ACID原理，我们使用银行账户及资金管理的案例进行分析。12345678910// 创建数据库create table account( idint primary key not null, namevarchar(40), moneydouble);// 有两个人开户并存钱insert into account values(1,&apos;A&apos;,1000);insert into account values(2,&apos;B&apos;,1000); ACIDACID，是指在可靠数据库管理系统（DBMS）中，事务(transaction)所应该具有的四个特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）.这是可靠数据库所应具备的几个特性.下面针对这几个特性进行逐个讲解. 原子性原子性是指事务是一个不可再分割的工作单位，事务中的操作要么都发生，要么都不发生。 案例A给B转帐100元钱 1234567begin transactionupdate account set money= money - 100where name=&apos;A&apos;;update account set money= money +100where name=&apos;B&apos;;if Error then rollbackelse commit 分析在事务中的扣款和加款两条语句，要么都执行，要么就都不执行。否则如果只执行了扣款语句，就提交了，此时如果突然断电，A账号已经发生了扣款，B账号却没收到加款，在生活中就会引起纠纷。 解决方法在数据库管理系统（DBMS）中，默认情况下一条SQL就是一个单独事务，事务是自动提交的。只有显式的使用start transaction开启一个事务，才能将一个代码块放在事务中执行。保障事务的原子性是数据库管理系统的责任，为此许多数据源采用日志机制。例如，SQL Server使用一个预写事务日志，在将数据提交到实际数据页面前，先写在事务日志上。 一致性一致性是指在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。这是说数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。 案例对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNT表中aaa和bbb的存款总额为2000元。 解决方法保障事务的一致性，可以从以下两个层面入手 数据库机制层面数据库层面的一致性是，在一个事务执行之前和之后，数据会符合你设置的约束（唯一约束，外键约束,Check约束等)和触发器设置。这一点是由SQL SERVER进行保证的。比如转账，则可以使用CHECK约束两个账户之和等于2000来达到一致性目的 业务层面对于业务层面来说，一致性是保持业务的一致性。这个业务一致性需要由开发人员进行保证。当然，很多业务方面的一致性，也可以通过转移到数据库机制层面进行保证。 隔离性多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。 这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。 在Windows中，如果多个进程对同一个文件进行修改是不允许的，Windows通过这种方式来保证不同进程的隔离性。 企业开发中，事务最复杂问题都是由事务隔离性引起的。当多个事务并发时，SQL Server利用加锁和阻塞来保证事务之间不同等级的隔离性。一般情况下，完全的隔离性是不现实的，完全的隔离性要求数据库同一时间只执行一条事务，这样会严重影响性能。想要理解SQL Server中对于隔离性的保障，首先要了解并发事务之间是如何干扰的. 事务之间的相互影响事务之间的相互影响分为几种，分别为：脏读，不可重复读，幻读，丢失更新 脏读脏读意味着一个事务读取了另一个事务未提交的数据，而这个数据是有可能回滚的；如下案例，此时如果事务1回滚，则B账户必将有损失。 不可重复读不可重复读意味着，在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。如下案例，事务1必然会变得糊涂，不知道发生了什么。 幻读（虚读）幻读，是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入一行新数据。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样. 丢失更新两个事务同时读取同一条记录，A先修改记录，B也修改记录（B是不知道A修改过），B提交数据后B的修改结果覆盖了A的修改结果。 理解SQL SERVER中的隔离级别数据库的事务隔离级别（TRANSACTION ISOLATION LEVEL）是一个数据库上很基本的一个概念。为什么会有事务隔离级别，SQL Server上实现了哪些事务隔离级别？事务隔离级别的前提是一个多用户、多进程、多线程的并发系统，在这个系统中为了保证数据的一致性和完整性，我们引入了事务隔离级别这个概念，对一个单用户、单线程的应用来说则不存在这个问题。 为了避免上述几种事务之间的影响，SQL Server通过设置不同的隔离级别来进行不同程度的避免。因为高的隔离等级意味着更多的锁，从而牺牲性能。所以这个选项开放给了用户根据具体的需求进行设置。不过默认的隔离级别Read Commited符合了多数的实际需求. SQL Server隔离事务之间的影响是通过锁来实现的，通过阻塞来阻止上述影响。不同的隔离级别是通过加不同的锁，造成阻塞来实现的，所以会以付出性能作为代价；安全级别越高，处理效率越低；安全级别越低，效率高。 使用方法：SET TRANSACTIONISOLATION LEVEL REPEATABLE READ 未提交读： 在读数据时不会检查或使用任何锁。因此，在这种隔离级别中可能读取到没有提交的数据。 已提交读：只读取提交的数据并等待其他事务释放排他锁。读数据的共享锁在读操作完成后立即释放。已提交读是SQL Server的默认隔离级别。 可重复读： 像已提交读级别那样读数据，但会保持共享锁直到事务结束。 可串行读：工作方式类似于可重复读。但它不仅会锁定受影响的数据，还会锁定这个范围。这就阻止了新数据插入查询所涉及的范围。 持久性持久性，意味着在事务完成以后，该事务所对数据库所作的更改便持久的保存在数据库之中，并不会被回滚。 即使出现了任何事故比如断电等，事务一旦提交，则持久化保存在数据库中。 SQL SERVER通过write-ahead transaction log来保证持久性。write-ahead transaction log的意思是，事务中对数据库的改变在写入到数据库之前，首先写入到事务日志中。而事务日志是按照顺序排号的（LSN）。当数据库崩溃或者服务器断点时，重启动SQL SERVER，SQLSERVER首先会检查日志顺序号，将本应对数据库做更改而未做的部分持久化到数据库，从而保证了持久性。 总结事务的（ACID）特性是由关系数据库管理系统（RDBMS，数据库系统）来实现的。数据库管理系统采用日志来保证事务的原子性、一致性和持久性。日志记录了事务对数据库所做的更新，如果某个事务在执行过程中发生错误，就可以根据日志，撤销事务对数据库已做的更新，使数据库退回到执行事务前的初始状态。 数据库管理系统采用锁机制来实现事务的隔离性。当多个事务同时更新数据库中相同的数据时，只允许持有锁的事务能更新该数据，其他事务必须等待，直到前一个事务释放了锁，其他事务才有机会更新该数据。 数据库查询优化使用索引应尽量避免全表扫描，首先应考虑在 where 及 order by ,group by 涉及的列上建立索引 优化 SQL 语句 通过 explain(查询优化神器)用来查看 SQL 语句的执行效果 可以帮助选择更好的索引和优化查询语句， 写出更好的优化语句。 通常我们可以对比较复杂的尤其是涉及到多表的 SELECT 语句， 把关键字 EXPLAIN 加到前面， 查看执行计划。例如： explain select * from news; 任何地方都不要使用 select * from t。用具体的字段列表代替* ，不要返回用不到的任何字段。 不需要的字段会增加数据传输的时间，即使mysql服务器和客户端是在同一台机器上，使用的协议还是tcp，通信也是需要额外的时间。 要取的字段、索引的类型，和这两个也是有关系的。举个例子，对于user表，有name和phone的联合索引，select name from user where phone=12345678912 和 select * from user where phone=12345678912，前者要比后者的速度快，因为name可以在索引上直接拿到，不再需要读取这条记录了。 大字段，例如很长的varchar，blob，text。准确来说，长度超过728字节的时候，会把超出的数据放到另外一个地方，因此读取这条记录会增加一次io操作。 索引列不能参与计算，保持列“干净” 比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’); 查询尽可能使用 limit 减少返回的行数， 减少数据传输时间和带宽浪费。 优化数据库对象 优化表的数据类型 使用 procedure analyse()函数对表进行分析， 该函数可以对表中列的数据类型提出优化建议。 能小就用小。 表数据类型第一个原则是： 使用能正确的表示和存储数据的最短类型。 这样可以减少对磁盘空间、 内存、 cpu 缓存的使用。 使用方法： select * from 表名 procedure analyse(); 对表进行拆分 通过拆分表可以提高表的访问效率。 有 2 种拆分方法 垂直拆分。把主键和一些列放在一个表中， 然后把主键和另外的列放在另一个表中。 如果一个表中某些列常用， 而另外一些不常用， 则可以采用垂直拆分。 水平拆分。根据一列或者多列数据的值把数据行放到二个独立的表中。 使用中间表来提高查询速度 创建中间表， 表结构和源表结构完全相同， 转移要统计的数据到中间表， 然后在中间表上进行统计， 得出想要的结果。 硬件优化 CPU 的优化 选择多核和主频高的 CPU。 内存的优化 使用更大的内存。 将尽量多的内存分配给 MYSQL 做缓存。 磁盘 I/O 的优化 使用磁盘阵列。RAID 0 没有数据冗余， 没有数据校验的磁盘陈列。 实现 RAID 0至少需要两块以上的硬盘，它将两块以上的硬盘合并成一块， 数据连续地分割在每块盘上。 RAID1 是将一个两块硬盘所构成 RAID 磁盘阵列， 其容量仅等于一块硬盘的容量， 因为另一块只是当作数据“镜像”。使用 RAID-0+1 磁盘阵列。 RAID 0+1 是 RAID 0 和 RAID 1 的组合形式。 它在提供与 RAID 1 一样的数据安全保障的同时， 也提供了与 RAID 0 近似的存储性能。 调整磁盘调度算法 选择合适的磁盘调度算法， 可以减少磁盘的寻道时间 MySQL 自身的优化 对 MySQL 自身的优化主要是对其配置文件 my.cnf 中的各项参数进行优化调整。 如指定 MySQL 查询缓冲区的大小， 指定 MySQL 允许的最大连接进程数等。 应用优化 使用数据库连接池 使用查询缓存 它的作用是存储 select 查询的文本及其相应结果。 如果随后收到一个相同的查询， 服务器会从查询缓存中直接得到查询结果。 查询缓存适用的对象是更新不频繁的表， 当表中数据更改后， 查询缓存中的相关条目就会被清空。 附录什么是存储过程？有哪些优缺点？存储过程是一些预编译的SQL语句。 更加直白的理解：存储过程可以说是一个记录集，它是由一些T-SQL语句组成的代码块，这些T-SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。 存储过程是一个预编译的代码块，执行效率比较高一个存储过程替代大量T_SQL语句 ，可以降低网络通信量，提高通信速率可以一定程度上确保数据安全 索引是什么？有什么作用以及优缺点？索引是对数据库表中一或多个列的值进行排序的结构，是帮助MySQL高效获取数据的数据结构 你也可以这样理解：索引就是加快检索表中数据的方法。数据库的索引类似于书籍的索引。在书籍中，索引允许用户不必翻阅完整个书就能迅速地找到所需要的信息。在数据库中，索引也允许数据库程序迅速地找到表中的数据，而不必扫描整个数据库。 MySQL数据库几个基本的索引类型：普通索引、唯一索引、主键索引、全文索引 索引加快数据库的检索速度索引降低了插入、删除、修改等维护任务的速度唯一索引可以确保每一行数据的唯一性通过使用索引，可以在查询的过程中使用优化隐藏器，提高系统的性能索引需要占物理和数据空间 什么是事务？事务（Transaction）是并发控制的基本单位。所谓的事务，它是一个操作序列，这些操作要么都执行，要么都不执行，它是一个不可分割的工作单位。事务是数据库维护数据一致性的单位，在每个事务结束时，都能保持数据一致性。 数据库的乐观锁和悲观锁是什么？数据库管理系统（DBMS）中的并发控制的任务是确保在多个事务同时存取数据库中同一数据时不破坏事务的隔离性和统一性以及数据库的统一性。 乐观并发控制(乐观锁)和悲观并发控制（悲观锁）是并发控制主要采用的技术手段。 悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 触发器的作用？触发器是一中特殊的存储过程，主要是通过事件来触发而被执行的。它可以强化约束，来维护数据的完整性和一致性，可以跟踪数据库内的操作从而不允许未经许可的更新和变化。可以联级运算。如，某表上的触发器上包含对另一个表的数据操作，而该操作又会导致该表触发器被触发。 索引的作用？和它的优点缺点是什么？数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。 为表设置索引要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间(因为索引也要随之变动)。 创建索引可以大大提高系统的性能（优点）： 第一，通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。 第二，可以大大加快数据的检索速度，这也是创建索引的最主要的原因。 第三，可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。 第四，在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。 第五，通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。 也许会有人要问：增加索引有如此多的优点，为什么不对表中的每一个列创建一个索引呢？因为，增加索引也有许多不利的方面： 第一，创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 第二，索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，如果要建立聚簇索引，那么需要的空间就会更大。 第三，当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。 索引是建立在数据库表中的某些列的上面。在创建索引的时候，应该考虑在哪些列上可以创建索引，在哪些列上不能创建索引。 一般来说，应该在这些列上创建索引： 在经常需要搜索的列上，可以加快搜索的速度； 在作为主键的列上，强制该列的唯一性和组织表中数据的排列结构； 在经常用在连接的列上，这些列主要是一些外键，可以加快连接的速度； 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，其指定的范围是连续的； 在经常需要排序的列上创建索引，因为索引已经排序，这样查询可以利用索引的排序，加快排序查询时间； 在经常使用在WHERE子句中的列上面创建索引，加快条件的判断速度。 同样，对于有些列不应该创建索引： 第一，对于那些在查询中很少使用或者参考的列不应该创建索引。这是因为，既然这些列很少使用到，因此有索引或者无索引，并能提高查询速度。相反，由于增加了索引，反而降低了系统的维护速度和增大了空间需求。 第二，对于那些只有很少数据值的列也不应该增加索引。这是因为，由于这些列的取值很少，例如人事表的性别列，在查询的结果中，结果集的数据行占了表中数据行的很大比例，即需要在表中搜索的数据行的比例很大。增加索引，并不能明显加快检索速度。 第三，对于那些定义为text, image和bit数据类型的列不应该增加索引。这是因为，这些列的数据量要么相当大，要么取值很少。 第四，当修改性能远远大于检索性能时，不应该创建索引。这是因为，修改性能和检索性能是互相矛盾的。当增加索引时，会提高检索性能，但是会降低修改性能。当减少索引时，会提高修改性能，降低检索性能。因此，当修改性能远远大于检索性能时，不应该创建索引。 使用索引查询一定能提高查询的性能吗？为什么通常,通过索引查询数据比全表扫描要快.但是我们也必须注意到它的代价. 索引需要空间来存储,也需要定期维护, 每当有记录在表中增减或索引列被修改时,索引本身也会被修改. 这意味着每条记录的INSERT,DELETE,UPDATE将为此多付出4,5 次的磁盘I/O. 因为索引需要额外的存储空间和处理,那些不必要的索引反而会使查询反应时间变慢.使用索引查询不一定能提高查询性能,索引范围查询(INDEX RANGE SCAN)适用于两种情况: 基于一个范围的检索,一般查询返回结果集小于表中记录数的30%基于非唯一性索引的检索 简单说一说drop、delete与truncate的区别SQL中的drop、delete、truncate都表示删除，但是三者有一些差别 delete和truncate只删除表的数据不删除表的结构速度,一般来说: drop&gt; truncate &gt;deletedelete语句是dml,这个操作会放到rollback segement中,事务提交之后才生效;如果有相应的trigger,执行的时候将被触发. truncate,drop是ddl, 操作立即生效,原数据不放到rollback segment中,不能回滚. 操作不触发trigger. drop、delete与truncate分别在什么场景之下使用？不再需要一张表的时候，用drop想删除部分数据行时候，用delete，并且带上where子句保留表而删除所有数据的时候用truncate 超键、候选键、主键、外键分别是什么？超键：在关系中能唯一标识元组的属性集称为关系模式的超键。一个属性可以为作为一个超键，多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。 候选键：是最小超键，即没有冗余元素的超键。 主键：数据库表中对储存数据对象予以唯一和完整标识的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。 外键：在一个表中存在的另一个表的主键称此表的外键。 什么是视图？以及视图的使用场景有哪些？视图是一种虚拟的表，具有和物理表相同的功能。可以对视图进行增，改，查，操作，试图通常是有一个表或者多个表的行或列的子集。对视图的修改不影响基本表。它使得我们获取数据更容易，相比多表查询。 只暴露部分字段给访问者，所以就建一个虚表，就是视图。查询的数据来源于不同的表，而查询者希望以统一的方式查询，这样也可以建立一个视图，把多个表查询结果联合起来，查询者只需要直接从视图中获取数据，不必考虑数据来源于不同表所带来的差异 说一说三个范式。第一范式（1NF，确保每列保持原子性）：数据库表中的字段都是单一属性的，不可再分。这个单一属性由基本类型构成，包括整型、实数、字符型、逻辑型、日期型等。 第一范式的合理遵循需要根据系统的实际需求来定。比如某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就非要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。这样设计才算满足了数据库的第一范式，如下表所示。上表所示的用户信息遵循了第一范式的要求，这样在对用户使用城市进行分类的时候就非常方便，也提高了数据库的性能。 第二范式（2NF，确保表中的每列都和主键相关）：数据库表中不存在非关键字段对任一候选关键字段的部分函数依赖（部分函数依赖指的是存在组合关键字中的某些字段决定非关键字段的情况），也即所有非关键字段都完全依赖于任意一组候选关键字。 第二范式在第一范式的基础之上更进一层。第二范式需要确保数据库表中的每一列都和主键相关，而不能只与主键的某一部分相关（主要针对联合主键而言）。也就是说在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 比如要设计一个订单信息表，因为订单中可能会有多种商品，所以要将订单编号和商品编号作为数据库表的联合主键，如下表所示。 这样就产生一个问题：这个表中是以订单编号和商品编号作为联合主键。这样在该表中商品名称、单位、商品价格等信息不与该表的主键相关，而仅仅是与商品编号相关。所以在这里违反了第二范式的设计原则。 而如果把这个订单信息表进行拆分，把商品信息分离到另一个表中，把订单项目表也分离到另一个表中，就非常完美了。如下所示。 这样设计，在很大程度上减小了数据库的冗余。如果要获取订单的商品信息，使用商品编号到商品信息表中查询即可。 第三范式（3NF，确保每列都和主键列直接相关，而不是间接相关）：在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式。所谓传递函数依赖，指的是如 果存在”A → B → C”的决定关系，则C传递函数依赖于A。因此，满足第三范式的数据库表应该不存在如下依赖关系： 关键字段 → 非关键字段 x → 非关键字段y 比如在设计一个订单数据表的时候，可以将客户编号作为一个外键和订单表建立相应的关系。而不可以在订单表中添加关于客户其它信息（比如姓名、所属公司等）的字段。如下面这两个表所示的设计就是一个满足第三范式的数据库表。 这样在查询订单信息的时候，就可以使用客户编号来引用客户信息表中的记录，也不必在订单信息表中多次输入客户信息的内容，减小了数据冗余。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1161. Maximum Level Sum of a Binary Tree]]></title>
    <url>%2F2019%2F08%2F11%2FLeetcode1161%2F</url>
    <content type="text"><![CDATA[Given the root of a binary tree, the level of its root is 1, the level of its children is 2, and so on. Return the smallest level X such that the sum of all the values of nodes at level X is maximal. Example 1: Input: [1,7,0,7,-8,null,null]Output: 2Explanation:Level 1 sum = 1.Level 2 sum = 7 + 0 = 7.Level 3 sum = 7 + -8 = -1.So we return the level with the maximum sum which is level 2. 很简单的层次遍历，就当熟悉一下queue的用法。 12345678910111213141516171819202122232425262728293031323334353637/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;;*/class Solution &#123; public: int maxLevelSum(TreeNode* root) &#123; queue&lt;TreeNode*&gt; q; q.push(root); int maxx = -99999; int layer=0,max_layer=0; while(!q.empty())&#123; int len = q.size(); int sum = 0; layer++; for(int i=0;i&lt;len;i++)&#123; TreeNode* temp = q.front(); q.pop(); if(temp-&gt;left!=NULL) q.push(temp-&gt;left); if(temp-&gt;right!=NULL) q.push(temp-&gt;right); sum += temp-&gt;val; &#125; if(sum&gt;maxx)&#123; maxx=sum; max_layer=layer; &#125; &#125; return max_layer; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[库打桩机制]]></title>
    <url>%2F2019%2F08%2F11%2F%E5%BA%93%E6%89%93%E6%A1%A9%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言假如由于调试需要，你希望原先代码中的malloc函数更换为你自己写好的malloc函数，该怎么办呢？如何对程序进行”偷梁换柱“？ 打桩机制LInux链接器有强大的库打桩机制，它允许你对共享库的代码进行截取，从而执行自己的代码。而为了调试，你通常可以在自己的代码中加入一些调试信息，例如，调用次数，打印信息，调用时间等等。本文将介绍三种打桩机制，分别在编译的不同阶段。 编译时打桩编译时打桩在源代码级别进行替换。我们很容易通过#define指令来完成这件事情。首先我们定义自己的头文件mymalloc.h:12#define malloc(size) mymalloc(size)void *mymalloc(size_t size) 由于在这里使用了#define指令，我们后面需要malloc的地方都会被mymalloc替代。而mymalloc.c代码如下：1234567891011#ifdef MYMOCK //只有MYMOC#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;/*打桩函数*/void *mymalloc(size_t size)&#123; void *ptr = malloc(size); printf(&quot;ptr is %p\n&quot;,ptr); return ptr;&#125;#endif 注意第一行，我们需要在gcc中传入编译选项MYMOCK（自定义，代码与传入的一致即可）。 我们在main.c中调用它：12345678#include&lt;stdio.h&gt;#include&quot;malloc.h&quot;int main()&#123; char *p = malloc(64); free(p); return 0;&#125; 编译运行：1234$ gcc -DMYMOCK -c mymalloc.c $ gcc -I . -o main main.c mymalloc.o$ ./mainptr is 0xdbd010 编译时还使用-I参数，告诉编译器从当前目录下寻找头文件malloc.h，因此，main函数中的malloc调用将会被替换成mymalloc。而在mymalloc.c中的则使用原始的malloc函数，最终达到“偷梁换柱”的效果。 实际上你也可以通过仅仅预编译来很清楚的看到其中的变化：1$ gcc -I . -E -o main.i main.c 查看main.i，你会发现，使用malloc的地方，都被替换成了mymalloc。 小结一下前面的步骤： 打桩函数内部不要打桩，即mymalloc.c中要使用原始的malloc函数，不然会造成循环调用 通过#define指令，将外部调用malloc的地方都替换为mymalloc 分开编译mymalloc.c和外部调用代码，最终链接 这种方式打桩需要能够访问源代码才能完成。 链接时打桩顾名思义，链接时打桩是在链接时替换需要的函数。Linux链接器支持用–wrap,f的方式来进行打桩，链接时符号f解析成wrap_f，还会把real_f解析成f。什么意思呢？我们修改前面mymalloc.c的代码如下：123456789101112#ifdef MYMOCK //只有MYMOCK编译选项是，这段代码才会编译进去#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;void *__real_malloc(size_t size);//注意声明/*打桩函数*/void *__wrap_malloc(size_t size) &#123; void *ptr = __real_malloc(size);//最后会被解析成malloc printf(&quot;ptr is %p\n&quot;,ptr); return ptr;&#125;#endif 注意将main.c中包含的malloc.h那一行去掉。 编译运行：12345$ gcc -DMYMOCK mymalloc.c$ gcc -c main.c$ gcc -Wl,--wrap,malloc -o main main.o mymalloc.o$ ./mainptr is 0x95f010 我们特别关注mymalloc.c中的代码，利用链接器的打桩机制，最后在main函数中调用malloc，将会去调用wrap_malloc，而real_malloc将会被解析成真正的malloc，从而达到“偷梁换柱”的效果。 可以看到的是，这种打桩方式至少需要能够访问可重定位文件。 运行时打桩前面两种打桩方式，一种需要访问源代码，另外一种至少要访问可重定位文件。可运行时打桩没有这么多要求。运行时打桩可以通过设置LD_PRELOAD环境变量，达到在你加载一个动态库或者解析一个符号时，先从LD_PRELOAD指定的目录下的库去寻找需要的符号，然后再去其他库中寻找。同样我们修改mymalloc.c:1234567891011121314151617181920212223242526272829303132#ifdef MYMOCK //只有MYMOCK编译选项是，这段代码才会编译进去#define _GNU_SOURCE //这行特别注意加上#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;dlfcn.h&gt;extern FILE *stdout;/*打桩的malloc函数*/void *malloc(size_t size)&#123; static int calltimes; calltimes++; /*函数指针*/ void *(*realMalloc)(size_t size) = NULL; char *error; realMalloc = dlsym(RTLD_NEXT,&quot;malloc&quot;);//RTLD_NEXT if(NULL == realMalloc) &#123; error = dlerror(); fputs(error,stdout); return NULL; &#125; void *ptr = realMalloc(size); if(1 == calltimes) &#123; printf(&quot;ptr is %p\n&quot;,ptr); &#125; calltimes = 0; return ptr;&#125;#endif 在mymalloc.c的代码中，由于我们自己的打桩函数也叫malloc，因此我们通过运行时链接调用malloc函数，以便获取malloc的地址，而不是直接调用。并且是以RTLD_NEXT方式。 将mymalloc.c制作成动态库12345$ gcc -DMYMOCK -shared -fPIC -o libmymalloc.so mymalloc.c -ldl$ gcc -o main main.c //重新编译main$ LD_PRELOAD=&quot;./libmymalloc.so&quot; $ ./mainSegmentation fault (core dumped) 然而非常不幸的是，最后core dumped了，我们用gdb（参考《Linux常用命令-开发调试篇》）查看调用栈：12345678910111213141516(gdb)bt#0 0x00007fe0ca83518e in _IO_vfprintf_internal ( s=0x7fe0cabad620 &lt;_IO_2_1_stdout_&gt;, format=0x7fe0cabb26dd &quot;ptr is %p\n&quot;, ap=ap@entry=0x7ffcbd652058) at vfprintf.c:1267#1 0x00007fe0ca83d899 in __printf (format=&lt;optimised out&gt;) at printf.c:33#2 0x00007fe0cabb26cc in malloc () from ./mymalloc.so#3 0x00007fe0ca8551d5 in __GI__IO_file_doallocate ( fp=0x7fe0cabad620 &lt;_IO_2_1_stdout_&gt;) at filedoalloc.c:127#4 0x00007fe0ca863594 in __GI__IO_doallocbuf ( fp=fp@entry=0x7fe0cabad620 &lt;_IO_2_1_stdout_&gt;) at genops.c:398#5 0x00007fe0ca8628f8 in _IO_new_file_overflow ( f=0x7fe0cabad620 &lt;_IO_2_1_stdout_&gt;, ch=-1) at fileops.c:820#6 0x00007fe0ca86128d in _IO_new_file_xsputn ( f=0x7fe0cabad620 &lt;_IO_2_1_stdout_&gt;, data=0x7fe0cabb26dd, n=7) at fileops.c:1331#7 0x00007fe0ca835241 in _IO_vfprintf_internal ( 我们从调用栈基本可以推断，其中有反复调用，那就是说在mymalloc.c中的malloc函数中，有的语句也调用了malloc，导致了最终的反复调用。解决这种问题有两个方法： 避免反复调用 使用不调用打桩函数的函数，即不调用其中的printf 我们采用下面这种方式来避免反复调用，开始调用时，置调用次数为1，最后置0，如果发现调用次数不为0 ，则不调用。12345678910111213141516171819202122232425262728293031323334#ifdef MYMOCK //只有MYMOCK编译选项是，这段代码才会编译进去#define _GNU_SOURCE //这行特别注意加上#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;dlfcn.h&gt;extern FILE *stdout;/*打桩的malloc函数*/void *malloc(size_t size)&#123; /*调用次数+1*/ static int calltimes; calltimes++; /*函数指针*/ void *(*realMalloc)(size_t size) = NULL; char *error; realMalloc = dlsym(RTLD_NEXT,&quot;malloc&quot;);//RTLD_NEXT if(NULL == realMalloc) &#123; error = dlerror(); fputs(error,stdout); return NULL; &#125; void *ptr = realMalloc(size); /*如果是第一次调用，则调用printf，否则不调用*/ if(1 == calltimes) &#123; printf(&quot;ptr is %p\n&quot;,ptr); &#125; calltimes = 0; return ptr;&#125;#endif 当然这样的写法在多线程中也是有问题的，如何改进？ 至此，就达到了我们需要的结果：12./mainptr is 0x245c010 实际上，你会发现，在设置了这个环境变量的终端下，这个打桩的动作对所有程序都生效：1234567$ lsptr is 0x1f1a040ptr is 0x1f1a680ptr is 0x1f1a700ptr is 0x1f1a040ptr is 0x1f1a060ptr is 0x1f1a040 那么怎么取消呢：1$ unset LD_PRELOAD 在这里也可以看到，这个机制虽然强大，同样也非常危险，因为不怀好意者可以通过这种方式恶意攻击你的程序。比如说，有个程序中checkPass的接口用来校验密码，如果这个时候使用另外一个动态库，实现自己的checkPass函数，并且设置LD_PRELOAD环境变量，就可以达到跳过密码检查的目的。 总结怎么样，是不是觉得很神奇？尤其是最后一种方式，可以达到对任何程序进行”偷梁换柱“，对于问题的定位和程序的调试非常有帮助。但是，需要特别注意的是，采用最后一种方式打桩时，最好避免打桩函数内部还调用了打桩函数，这样会导致难以预料的后果，另外由于这种打桩机制对所有程序都有效，因此也非常危险，需要特别注意。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[转-字节跳动面试]]></title>
    <url>%2F2019%2F08%2F10%2F%5B%E8%BD%AC%5D%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E9%9D%A2%E8%AF%95%2F</url>
    <content type="text"><![CDATA[本硕985科班，面的是base深圳的后端开发，为了做好准备，一直拖到提前批截止前一周才递简历，30号四面完后等了一个星期，终于拿到了意向书，没有hr面。贡献一波面经，还在等待的兄弟们不要着急，一般面试完没立刻收到感谢信就已经成功了一半，拿offer的希望还是挺大的！ 一面（60min)7月15日： TCP如何实现可靠传输TCP拥塞控制过程UDP如何设计可靠传输系统调用的底层过程Linux读写文件的整个底层过程进程切换为什么开销大（必须说到TLB）进程切换需要保存什么信息，线程切换需要保存什么信息操作系统内存管理线程同步方法讲讲互斥锁和自旋锁，linux自旋锁底层实现有没有研究过无锁同步mysql有没有了解有哪些用于排序的数据结构讲讲lsmtree（项目相关）手撕快排快排应用场景、如何保证快排效率 二面（60min）7月15日： 系统调用的底层过程TCP四次挥手进程与线程区别讲讲协程如何实现哈希表，redis有没有了解？redis如何实现哈希表在线扩容cpp程序生成过程，本文件外的函数在什么阶段才引用（记不清楚，回答extern方面的）epoll使用流程epoll LT与ET区别哪些知名项目用到epollgdb调试core、git使用C 11新特性项目最难的部分、最有成就感的部分（疯狂被怼）手撕最大连续子序列和（剑指offer原题）面试官在结束前还朝我挥挥手，估计凉了。前两面表现很差，觉得肯定挂了，但出乎意料过了几天hr打来约三面…… 三面（75min）7月26日： 项目为主，网络编程和键值存储相关的聊了30minC 多态C 虚函数实现机制类的内存模型 代码题，关于C 成员函数调用（静态绑定，使用空的类指针调用成员函数是否会报错）找出1000W整型数据的中位数（说了快排，面试官说有比nlogn快的，但没想出来，希望大佬们讲解一下）手撕复杂链表的复制（给剑指offer跪了）有什么想问的？ 一小时后接到hr电话约四面，还是技术面（估计是前两面表现的比较差加面吧，没细问hr）…… 7月30日： 面试官说前三面已经聊过一些基础知识了，所有以网络的项目为主 Reactor模式在编程中遇到的问题（面试官说事件驱动机制的开发麻烦，redis这种直接返回还好，如果涉及到其他服务的调用就麻烦） 系统收到网络数据交付给应用程序的整个过程（从网卡说起，面试官说我对底层了解的挺深） UDP发送100个字节，对方的应用程序只recv了90个字节，剩下的10个字节怎么处理（没太明白正常情况下为什么会剩10个字节，跟面试官讨论了半天，他说这个问题太刁钻就过了） TCP的传输速率受什么影响（先扯了硬件，再扯了Nagle算法，面试官说知道这个不错，最后扯数据分片，面试官说这个没关系就过了） TCP发送消息如果对方不接收，我们这边会有什么情况发生（扯了应用层相关的，其实面试官只是为了引导我回答TCP的传输速率与接收窗口有关） TCP的拥塞控制TCP的滑动窗口TCP的超时时间计算手撕跳台阶（剑指offer原题……）手撕N个“(”和N个“)”的排列组合（就是有重复数据的全排列，不需要括号匹配） 字节跳动的面试体验很好，视频面试很方便，面试官都挺nice，答不上来也不会表现得不耐烦。 自认为运气很好，几道算法题都很简单，因为项目原因没什么时间刷题，这方面比不上其他大佬。第一次面大厂准备不充分，一二面被问懵，之后回去狂补网络和操作系统的底层知识，三四面表现好多了，四面面试官居然还说我基础扎实，弄得我有点尴尬…… 个人的教训就是细节决定成败，只会调接口、不熟悉的技术千万不要随意往简历上写，写了就要尽可能深挖原理，做好觉悟不怕被面试官“夺命连环怼”~]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[批量删除微博]]></title>
    <url>%2F2019%2F08%2F10%2F%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E5%BE%AE%E5%8D%9A%2F</url>
    <content type="text"><![CDATA[心情不佳，所以搞了一个批量删除微博的代码把微博删了，正好微博也封号了，消停了。123456789101112var s = document.createElement(&quot;script&quot;);s.setAttribute(&quot;src&quot;,&quot;https://lib.sinaapp.com/js/jquery/2.0.3/jquery-2.0.3.min.js&quot;);s.onload = function()&#123; for(var i=0;i&lt;100;i++)&#123; setTimeout(function()&#123; $(&apos;a[action-type=&quot;fl_menu&quot;]&apos;)[0].click(); $(&apos;a[title=&quot;删除此条微博&quot;]&apos;)[0].click(); $(&apos;a[action-type=&quot;ok&quot;]&apos;)[0].click(); &#125;,1000*i); &#125;&#125;document.head.appendChild(s);]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言并发之道第6章笔记]]></title>
    <url>%2F2019%2F07%2F08%2FGo%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%936%2F</url>
    <content type="text"><![CDATA[goroutine和Go语言进行时工作窃取为了确保所有CPU有相同的使用率，可以在所有可用的处理器上平均分配负载。在实际使用过程中，基于朴素策略在处理器上分配任务可能会导致其中一个处理器利用率不足。不仅如此，还可能导致缓存的位置偏差，因为需要调用这些数据的任务跑在其他处理器上。 可以采取：工作任务加入队列中进行调度，处理器在有空闲的时候将任务出队，或者阻塞连接。这样引入了一个集中化的队列，所有的处理器都必须使用这个数据结构，每次想要入队或出队一个任务时继续要将这个队列加载到每个处理器的缓存中。 也可以拆分工作队列，给每个处理器一个独立线程和双端队列。 首先需要强调，Go遵循fork-join模型进行并发，在goroutine开始的时候fork，join点事两个或更多的goroutine通过channel或sync包中的类型进行同步。工作窃取算法对于给定线程： 在fork点，将任务添加到与线程相关的双端队列尾部； 如果线程空闲则随机选取一个线程，从它关联的双端队列头部窃取工作； 如果在未准备好的join点则将工作从线程的双端队列尾部出栈； 如果线程的双端队列是空的，则暂停加入或从随机线程关联的双端队列中窃取工作。 以下是计算fibonacci数列的程序1234567891011121314151617func main() &#123; var fib func(n int) &lt;-chan int fib = func(n int) &lt;-chan int &#123; result := make(chan int) go func() &#123; defer close(result) if n &lt;= 2 &#123; result &lt;- 1 return &#125; result &lt;- &lt;-fib(n-1) + &lt;-fib(n-2) &#125;() return result &#125; fmt.Printf(&quot;fib(4) = %d.\n&quot;, &lt;-fib(4))&#125; 首先只有一个goroutine，main goroutine，假设在处理器1上；接下来调用fib(4)，这个goroutine被安排在T1的工作队列尾部，并且父goroutine将继续运行；此时根据时机不同，可能会发生T1或T2盗取调用fib(4)的goroutine，如果fib(4)在T1上，则在T1的工作队列上将添加fib(3)和fib(2)。 此时T2仍然是空闲的，所以从T1的队列头部取出fib(3)。此时fib(2)是fib(4)推入队列的最后一个任务，因此T1最有可能需要计算的第一个任务仍然在T1上！与此同时，由于在fib(3)和fib(2)返回的channel上等待着，T1不足以继续处理fib(4)，它会自己从队列中出栈一个fib(2)。 T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3) fib(4)(等待join) fib(2) 调用fib(3)的goroutine： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3) fib(2) fib(4)(等待join) fib(1) fib(2) T1到达了Fibonacci收敛处，返回1： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3) fib(2) fib(4)(等待join) fib(1) fib(1) T2到达了join点，并从其队列的尾部出栈一个任务： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3)(等待join) fib(2) fib(4)(等待join) fib(1) return 1 T1又一次处于空闲所以从T2的队列中窃取工作： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3)(等待join) fib(4)(等待join) fib(1) fib(2) T2到达终点返回1： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3)(等待join) fib(4)(等待join) return 1 fib(2) T1到达终点返回1： T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) fib(3)(等待join) fib(4)(等待join) return 1 return 1 T2对fib(3)的调用现在有两个已完成的join点，fib(2)和fib(1)已经通过channel返回了结果，并且fib(3)产生的两个goroutine已经运行结束。 T1调用栈 T1工作队列 T2调用栈 T2工作队列 (main goroutine)(等待join) return 2 fib(4)(等待join) fib(4)调用的goroutine有两个join点，fib(3)和fib(2)，在T2最后一个任务结束时完成了fib(2)的join。执行加法，通过fib(4)的channel返回。 位于队列尾部的任务： 最有可能完成父进程join的任务 最有可能存在于处理器缓存中的任务 当一个线程到达join时，必须暂停等待回调以窃取任务。 Go中的调度器G：goroutine M：OS线程，在源代码中也称为机器 P：上下文，在源代码中也被称为处理器 在Go的运行时中，首先启动M，然后是P，最后是调度运行G。 正如之前说的，设置GOMAXPROCS可以控制运行时使用多少上下文。默认设置是主机上每个逻辑CPU分配一个上下文。并且总会有足够的系统线程可以用来处理每个上下文。这使运行时可以进行一些重要的优化。 如果一个goroutine被阻塞，管理goroutine的系统线程也会被阻塞，并且无法继续执行或切换到其他的goroutine。从性能上，Go会进行更多的处理以尽可能让机器上的处理器保持活跃，Go会从系统线程分离上下文，将上下文切换到另一个无阻塞的系统线程上。当goroutine阻塞最终结束时，主机系统线程会尝试使用一个其他系统线程来回退上下文，以便它可以继续执行先前被阻塞的goroutine。或者把它的goroutine放在全局上下文中然后线程进入休眠状态，并将其放入运行时的线程池以供将来使用。 竞争检测在Go中为大多数命令增加了race参数。 竞争检测器可以自动检测代码中的竞态条件。123456789func main() &#123; var data int go func() &#123; data++ &#125;() if data == 0 &#123; fmt.Printf(&quot;the value is %d.\n&quot;, data) &#125;&#125; 执行go run -race test19.go1234567891011121314151617the value is 0.==================WARNING: DATA RACEWrite at 0x00c0000200c8 by goroutine 6: main.main.func1() /home/yuhao/tool/go/test/test19.go:8 +0x4ePrevious read at 0x00c0000200c8 by main goroutine: main.main() /home/yuhao/tool/go/test/test19.go:10 +0x88Goroutine 6 (running) created at: main.main() /home/yuhao/tool/go/test/test19.go:7 +0x7a==================Found 1 data race(s)exit status 66 分别表示goroutine试图进行非同步内存写入，或者试图读取相同的内存。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python netcdf4包的使用]]></title>
    <url>%2F2019%2F07%2F08%2Fpython_netcdf%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[netCDF4包的文档：http://unidata.github.io/netcdf4-python/netCDF4/index.html 因为要使用netCDF4格式的文件，所以学了一下如何把一个nc文件复制成另一个。在创建新文件时，format只能设置成“NETCDF3_CLASSIC”，否则在public2机器上无法读取，应该是HDF5的问题。下边的程序就比较齐全了，无论是维度的设置、变量及其属性的设置、全局属性的设置等都有了。复制出来的两个nc文件是一样的。 12345678910111213141516171819202122232425from netCDF4 import Datasetnc = Dataset(&quot;wind2018100700.nc&quot;)newnc = Dataset(&quot;new_wind.nc&quot;, &quot;w&quot;, format=&apos;NETCDF3_CLASSIC&apos;)ncdimensions = nc.dimensionsfor dim in nc.dimensions.values(): newncdim_sample = newnc.createDimension(dim.name, dim.size)for var in nc.variables.values(): print(var) print(var.datatype) print(var.ncattrs()) print(var.dimensions) new_var = newnc.createVariable(var.name, var.datatype, var.dimensions, shuffle=False) for attr in var.ncattrs(): new_var.setncattr(attr, var.getncattr(attr)) newnc[var.name][:] = nc[var.name][:]for attr in nc.ncattrs(): newnc.setncattr(attr,nc.getncattr(attr))nc.close()newnc.close()]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言并发之道第5章笔记]]></title>
    <url>%2F2019%2F07%2F06%2FGo%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%935%2F</url>
    <content type="text"><![CDATA[异常传递我们需要对传入的异常信息进行传递和处理，如：123456789func PostReport(id string) error &#123; result, err := lowlevel.DoWork() if err != nil&#123; if _, ok := err.(lowlevel.Error); ok &#123; err = WrapErr(err, &quot;cannot post report with id %q&quot;, id) &#125; return err &#125;&#125; 在这里检查接收到的异常信息，确保结构良好，使用一个假设的函数将传入的异常和模块相关信息封装起来，并赋予一个新类型。 创建一个异常类型：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566type MyError struct &#123; Inner error Message string StackTrace string Misc map[string]interface&#123;&#125;&#125;func wrapError(err error, messagef string, msgArgs ...interface&#123;&#125;) MyError &#123; return MyError&#123; Inner: err, Message: fmt.Sprintf(messagef, msgArgs...), StackTrace: &quot;stack!!!&quot;, Misc: make(map[string]interface&#123;&#125;), &#125;&#125;func (err MyError) Error() string &#123; return err.Message&#125;type LowLevelErr struct &#123; error&#125;func isGloballyExec(path string) (bool, error) &#123; info, err := os.Stat(path) if err != nil &#123; return false, LowLevelErr&#123;(wrapError(err, err.Error()))&#125; &#125; return info.Mode().Perm()&amp;0100 == 0100, nil&#125;type IntermediateErr struct &#123; error&#125;func runJob(id string) error &#123; const jobBinPath = &quot;/bad/job/binary&quot; isExecutable, err := isGloballyExec(jobBinPath) if err != nil &#123; return IntermediateErr&#123;wrapError(err, &quot;cannot run job %q: requisite binaries not available&quot;, id)&#125; &#125; else if isExecutable == false &#123; return wrapError(nil, &quot;job binary is not executable&quot;, id) &#125; return exec.Command(jobBinPath, &quot;--id=&quot;+id).Run()&#125;func handleError(key int, err error, message string) &#123; log.SetPrefix(fmt.Sprintf(&quot;[logID: %v]: &quot;, key)) log.Printf(&quot;%#v&quot;, err) fmt.Printf(&quot;[%v] %v&quot;, key, message)&#125;func main() &#123; log.SetOutput(os.Stdout) log.SetFlags(log.Ltime | log.LUTC) err := runJob(&quot;1&quot;) if err != nil &#123; msg := &quot;There was an unexpected issue; please report this as a bug.&quot; if _, ok := err.(IntermediateErr); ok &#123; msg = err.Error() &#125; handleError(1, err, msg) &#125;&#125; 超时和取消有几个原因使我们需要支持超时： 系统饱和：希望超出的请求返回超时，而不是花很长时间等待响应。请求在超时时不太可能重复，或没有资源来存储请求，或者对系统响应或请求发送数据有时效性的要求时，需要超时操作。 陈旧的数据：数据通常有窗口期，如果并发进程处理数据需要的时间比这个窗口期长，则会想返回超时并取消并发进程。可以使用context.WithDeadline或者context.WithTimeout创建的context.Context传递给并发进程。 试图防止死锁：为了防止死锁，建议在所有并发操作中增加超时操作。 心跳有两种不同的心跳： 一段时间间隔内发出的心跳 在工作单元开始时发出的心跳 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677func main() &#123; doWork := func( done &lt;-chan interface&#123;&#125;, pulseInterval time.Duration, ) (&lt;-chan interface&#123;&#125;, &lt;-chan time.Time) &#123;// 建立一个发送心跳的channel，返回给doWork heartbeat := make(chan interface&#123;&#125;) results := make(chan time.Time) go func() &#123; defer close(heartbeat) defer close(results) pulse := time.Tick(pulseInterval) workGen := time.Tick(2 * pulseInterval)// 设定心跳间隔 sendPulse := func() &#123; select &#123; case heartbeat &lt;- struct&#123;&#125;&#123;&#125;: default: // 可能没有人接收心跳，所以加一个default &#125; &#125; sendResult := func(r time.Time) &#123; for &#123; select &#123; case &lt;-done: return case &lt;-pulse: sendPulse() case results &lt;- r: return &#125; &#125; &#125; for &#123; select &#123; case &lt;-done: return case &lt;-pulse: sendPulse() case r := &lt;-workGen: sendResult(r) &#125; &#125; &#125;() return heartbeat, results &#125; done := make(chan interface&#123;&#125;) time.AfterFunc(10*time.Second, func() &#123; close(done) &#125;) const timeout = 2 * time.Second // 设置了超时时间 heartbeat, results := doWork(done, timeout/2) // timeout/2 使我们的心跳有额外的响应时间 for &#123; select &#123; // 处理心跳，如果没有消息时，至少timeout/2后会从心跳channel发出一条消息 case _, ok := &lt;-heartbeat: if ok == false &#123; return &#125; fmt.Println(&quot;pulse&quot;) case r, ok := &lt;-results: if ok == false &#123; return &#125; fmt.Printf(&quot;result %v\n&quot;, r.Second()) case &lt;-time.After(timeout): return &#125; &#125;&#125; 以下是每个工作单元开始之前发出的心跳12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152func main() &#123; doWork := func( done &lt;-chan interface&#123;&#125;, ) (&lt;-chan interface&#123;&#125;, &lt;-chan int) &#123; heartbeatStream := make(chan interface&#123;&#125;, 1)// 创建一个缓冲区大小为1的heartbeat channel，确保了即使没有及时接收发送消息也能发出一个心跳 workStream := make(chan int) go func() &#123; defer close(heartbeatStream) defer close(workStream) for i := 0; i &lt; 10; i++ &#123; select &#123; case heartbeatStream &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; select &#123; case &lt;-done: return case workStream &lt;- rand.Intn(10): &#125; &#125;// 这里为心跳设置了单独的select块，将发送result和发送心跳分开，如果接收者没有准备好接受结果，作为替代它将收到一个心跳，而代表当前结果的值将会丢失。// 为了防止没人接收心跳，增加了default，因为我们的heart channel创建时有一个缓冲区，所以如果有人正在监听暗示没有及时收到第一个心跳，接收者也可以收到心跳。 &#125;() return heartbeatStream, workStream &#125; done := make(chan interface&#123;&#125;) defer close(done) heartbeat, results := doWork(done) for &#123; select &#123; case _, ok := &lt;-heartbeat: if ok == false &#123; return &#125; else &#123; fmt.Println(&quot;pulse&quot;) &#125; case r, ok := &lt;-results: if ok == false &#123; return &#125; else &#123; fmt.Printf(&quot;result %v\n&quot;, r) &#125; &#125; &#125;&#125; 一些外部因素会导致goroutine花费更长的时间来进行第一次迭代，无论goroutine在调度上是否是第一位执行的。使用goroutine来解决这个问题。 复制请求可以将请求分发到多个处理程序，其中一个将比其他处理程序返回更快，可以立即返回结果。1234567891011121314151617181920212223242526272829303132333435363738394041424344func main() &#123; doWork := func( done &lt;-chan interface&#123;&#125;, id int, wg *sync.WaitGroup, result chan&lt;- int, ) &#123; started := time.Now() defer wg.Done() simulatedLoadTime := time.Duration(1+rand.Intn(5)) * time.Second select &#123; case &lt;-done: case &lt;-time.After(simulatedLoadTime): &#125; select &#123; case &lt;-done: case result &lt;- id: &#125; took := time.Since(started) if took &lt; simulatedLoadTime &#123; took = simulatedLoadTime &#125; fmt.Printf(&quot;%v took %v.\n&quot;, id, took) &#125; done := make(chan interface&#123;&#125;) result := make(chan int) var wg sync.WaitGroup wg.Add(10) for i := 0; i &lt; 10; i++ &#123; go doWork(done, i, &amp;wg, result) &#125; firstReturned := &lt;-result close(done) wg.Wait() fmt.Printf(&quot;Received an answer from #%v.\n&quot;, firstReturned)&#125; 在这里我们启动了10个处理程序来处理请求，并获得了第一个返回值，如果得到了第一个返回值，则取消其它的处理程序，以保证不会做多余的工作。 速率限制速率限制允许你将系统的性能和稳定性平衡在可控范围内。Go中大多数的限速是基于令牌算法的。 如果要访问资源，必须拥有资源的访问令牌，没有令牌的请求会被拒绝。假设令牌存储在一个等待被检索使用的桶中，桶的深度是d，表示一个桶可以容纳d个访问令牌。 每当需要访问资源时，都会在桶中删除一个令牌，请求必须排队等待直到有令牌可以用，或者被拒绝操作。将r定义为向桶中添加令牌的速率。只要用户拥有可用的令牌，集中的请求可能会使用户突破系统的可用范围。有些用户会间歇性访问系统，但是又想要尽可能快的获得结果，就会出现突发性的事件，只需要确保系统能同时处理所有用户的突发请求，或者在统计上不会有太多用户同时突发访问。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647func Open() *APIConnection &#123; return &amp;APIConnection&#123;&#125;&#125;type APIConnection struct&#123;&#125;func (a *APIConnection) ReadFile(ctx context.Context) error &#123; return nil&#125;func (a *APIConnection) ResolveAddress(ctx context.Context) error &#123; return nil&#125;func main() &#123; defer log.Printf(&quot;Done.&quot;) log.SetOutput(os.Stdout) log.SetFlags(log.Ltime | log.LUTC) apiConnection := Open() var wg sync.WaitGroup wg.Add(20) for i := 0; i &lt; 10; i++ &#123; go func() &#123; defer wg.Done() err := apiConnection.ReadFile(context.Background()) if err != nil &#123; log.Printf(&quot;cannot ReadFile: %v&quot;, err) &#125; log.Printf(&quot;ReadFile&quot;) &#125;() &#125; for i := 0; i &lt; 10; i++ &#123; go func() &#123; defer wg.Done() err := apiConnection.ResolveAddress(context.Background()) if err != nil &#123; log.Printf(&quot;cannot ResolveAddress: %v&quot;, err) &#125; log.Printf(&quot;ResolveAddress&quot;) &#125;() &#125; wg.Wait()&#125; 所有的API请求同时进行，没有进行限速，所以客户端可以自由访问系统，下面引入限速器，把限速器放在APIConnection中。这里用到了golang.org/x/time/rate包中的令牌桶限速器实现，具体安装如下： golang.org/x包放到了https://github.com/golang/time.git中，下载时需要先在本地建立golang.org/x的目录后，再下载。12mkdir -p golang.org/xgit clone https://github.com/golang/time.git 我们使用了这个包的两个部分，分别是Limit类型和NewLimiter函数。Limit表示某个事件的最大频率，每秒事件数；NewLimiter返回一个新的Limit，允许事件速率为r，并允许最大为b的token。 rate包也包含一个辅助方法Every，将时间间隔转换为Limit。针对每次操作的间隔时间进行测量：123func Per(eventCount int, duration time.Duration) rate.Limit &#123; return rate.Every(duration / time.Duration(eventCount))&#125; 创建rate.Limiter后，使用它来阻塞我们的请求，直到获得访问令牌，使用Wait实现。123456func (lim *Limiter) Wait(ctx context.Context) // Wait是WaitN(ctx, 1)的缩写// WaitN会执行直到有n个事件发生，// 如果n超过Limiter的突发大小，ctx被取消，或者逾期等待时间超过context的deadline，会返回一个错误func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) 修改后的APIConnection：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func Open() *APIConnection &#123; return &amp;APIConnection&#123; rateLimiter: rate.NewLimiter(rate.Limit(1), 1), &#125;&#125;type APIConnection struct &#123; rateLimiter *rate.Limiter&#125;func (a *APIConnection) ReadFile(ctx context.Context) error &#123; if err := a.rateLimiter.Wait(ctx); err != nil &#123; return err &#125; return nil&#125;func (a *APIConnection) ResolveAddress(ctx context.Context) error &#123; if err := a.rateLimiter.Wait(ctx); err != nil &#123; return err &#125; return nil&#125;func main() &#123; defer log.Printf(&quot;Done.&quot;) log.SetOutput(os.Stdout) log.SetFlags(log.Ltime | log.LUTC) apiConnection := Open() var wg sync.WaitGroup wg.Add(20) for i := 0; i &lt; 10; i++ &#123; go func() &#123; defer wg.Done() err := apiConnection.ReadFile(context.Background()) if err != nil &#123; log.Printf(&quot;cannot ReadFile: %v&quot;, err) &#125; log.Printf(&quot;ReadFile&quot;) &#125;() &#125; for i := 0; i &lt; 10; i++ &#123; go func() &#123; defer wg.Done() err := apiConnection.ResolveAddress(context.Background()) if err != nil &#123; log.Printf(&quot;cannot ResolveAddress: %v&quot;, err) &#125; log.Printf(&quot;ResolveAddress&quot;) &#125;() &#125; wg.Wait()&#125; 这样实现了所有API连接的速率限制为每秒一次。 聚合限速器：1234567891011121314151617181920212223242526272829type RateLimiter interface &#123; Wait(context.Context) error Limit() rate.Limit&#125;func MultiLimiter(limiters ...RateLimiter) *multiLimiter &#123; byLimit := func(i, j int) bool &#123; return limiters[i].Limit() &lt; limiters[j].Limit() &#125; sort.Slice(limiters, byLimit) return &amp;multiLimiter&#123;limiters: limiters&#125;&#125;type multiLimiter struct &#123; limiters []RateLimiter&#125;func (l *multiLimiter) Wait(ctx context.Context) error &#123; for _, l := range l.limiters &#123; if err := l.Wait(ctx); err != nil &#123; return err &#125; &#125; return nil&#125;func (l *multiLimiter) Limit() rate.Limit &#123; return l.limiters[0].Limit()&#125; 定义了一个RateLimiter接口，使MultiLimiter可以递归定义其他的MultiLimiter实例，并且实现了一个优化，根据每个RateLimiter的Limit()排序，可以直接返回限制最多的限制器，这将是切片（slice）的第一个元素。 Wait犯法会遍历所有的子限速器，并调用Wait。 可以考虑增加对API请求的限制，对磁盘的限制：12345678910111213141516171819202122232425262728func Open() *APIConnection &#123; return &amp;APIConnection&#123; apiLimit: MultiLimiter( rate.NewLimiter(Per(2, time.Second), 2) rate.NewLimiter(Per(10, time.Minute), 10), ), diskLimit: MultiLimiter( rate.NewLimiter(rate.Limit(1), 1) ), networkLimit: MultiLimiter( rate.NewLimiter(Per(3, time.Second), 3), ), &#125;&#125;func (a *APIConnection) ReadFile(ctx context.Context) error &#123; if err := MultiLimiter(a.apiLimit,a.diskLimit).Wait(ctx); err != nil &#123; return err &#125; return nil&#125;func (a *APIConnection) ResolveAddress(ctx context.Context) error &#123; if err := MultiLimiter(a.apiLimit,a.diskLimit).Wait(ctx); err != nil &#123; return err &#125; return nil&#125; 上面为API调用和磁盘读取设置了限速器。 治愈异常的goroutine建立一个机制来监控goroutine是否处于健康的状态，当它们变得异常时就可以尽快重启。需要使用心跳模式来检查正在监控的goroutine是否活跃，心跳的类型取决于想要监控的内容，如果goroutine有可能会产生活锁，需要确保心跳包含某些信息，表明goroutine正在工作而不是只是活着。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687type startGoroutineFn func( done &lt;-chan interface&#123;&#125;, pulseInterval time.Duration,) (heartbeat &lt;-chan interface&#123;&#125;)//定义一个可以监控和重启goroutine的信号。func main() &#123; newSteward := func( timeout time.Duration, startGoroutine startGoroutineFn, ) startGoroutineFn &#123; return func( done &lt;-chan interface, pulseInterval time.Duration,// 监控goroutine需要timeout变量，一个函数startGoroutineFn表示管理员本身也是可监控的 ) (&lt;-chan interface&#123;&#125;) &#123; heartbeat :=make(chan interface&#123;&#125;) go func() &#123; defer close(heartbeat) var wardDone chan interface&#123;&#125; var wardHeartbeat &lt;- chan interface&#123;&#125; startWard := func() &#123; wardDone = make(chan interface&#123;&#125;) wardHeartbeat = startGoroutine(or(wardDone, done),timeout/2) &#125;// 定义了一个闭包，实现了统一的方法来启动正在监视的goroutine// 创建一个新的channel，如果需要发出停止信号则使用它传入goroutine// 启动将要监控的goroutine，如果管理员被停止或者想要停止goroutine，希望这些信息能传给管理区的goroutine// 所以使用了逻辑或来包装。 startWard() pulse := time.Tick(pulseInterval) monitorLoop: for &#123; timeoutSignal := time.After(timeout) for &#123; select &#123; case &lt;-pulse: select&#123; case heartbeat &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; case &lt;-wardHeartbeat: continue monitorLoop case &lt;-timeoutSignal: log.Println(&quot;steward: ward unhealthy; restarting&quot;) close(wardDone) startWard() continue monitorLoop case &lt;-done: return &#125; &#125; &#125; &#125;() return heartbeat &#125; &#125; log.SetOutput(os.Stdout) log.SetFlags(log.Ltime | log.LUTC) doWork := func(done &lt;-chan interface&#123;&#125;, _ time.Duration) &lt;-chan interface&#123;&#125; &#123; log.Println(&quot;ward: hello, I&apos;m irresponsible!&quot;) go func()&#123; &lt;-done log.Println(&quot;ward: I am halting&quot;) &#125;() retunr nil &#125; doWorkWithSteward := newSteward(4*time.Second, doWork)// 超时时间是4s done := make(chan interface&#123;&#125;) time.AfterFunc(9*time.Second, func()&#123; log.Println(&quot;main: halting steward and ward.&quot;) close(done) &#125;)// 9s后停止管理员和goroutine for range doWorkWithSteward(done, 4*time.Second) &#123;&#125; log.Println(&quot;done&quot;)&#125; 管理区可以使用桥接channel模式向消费者提供公用的channel，避免中断，使用这些技术，管理区可以简单的通过组合各种模式变得任意复杂：123456789101112131415161718log.SetOutput(os.Stdout)log.SetFlags(log.Ltime | log.LUTC)done := make(chan interface&#123;&#125;)defer close(done)doWork, intStream := doWorkFn(done, 1, 2, -1, 3, 4, 5)// 创建管理区函数，允许结束可变整数切片，返回用来返回的流doWorkWithSteward := newSteward(1*time.Millisecond, doWork)// 创建管理员，监听doWork doWorkWithSteward(done, 1*time.Hour)// 启动管理区并开始监控for intVal := range take(done, intStream, 6) &#123; fmt.Println(&quot;Received %v.\n&quot;, intVal)&#125;]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言并发之道第4章笔记]]></title>
    <url>%2F2019%2F07%2F02%2FGo%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%934%2F</url>
    <content type="text"><![CDATA[提示：interface{}可用于向函数传递任意类型的变量，但对于函数内部，该变量仍然为interface{}类型（空接口类型）， Go的并发模式约束约束是一种确保了信息只能从一个并发过程中获取到的简单且强大的方法，特定约束是指通过公约实现约束，词法约束涉及使用词法作用域仅公开用于多个并发进程的正确数据和并发原语。 for-select循环123456for &#123; // 要不就无限循环，要不就使用range循环 select &#123; //使用channel作业 &#125;&#125; 向channel发送迭代变量1234567for _, s := range []string&#123;&quot;a&quot;, &quot;b&quot;, &quot;c&quot;&#125; &#123; select &#123; case &lt;- done: return case stringStream &lt;- s: &#125;&#125; 循环等待停止创建循环，无限直至停止。12345678for &#123; select &#123; case &lt;- done: return default: &#125; // 非抢占式任务&#125; 防止goroutine泄露main goroutine可能会在其生命周期内将其他的goroutine设置为自旋，导致内存利用率下降。减轻这种情况的方法是在父goroutine和子goroutine之间建立一个信号，让父goroutine向其子goroutine发出信号通知。父goroutine将该channel发送给子goroutine，然后在想要取消子goroutine时关闭该channel。 确保：如果goroutine负责创建goroutine，那么它也负责确保可以停止goroutine。 or-channel使用or-channel模式将多个channel组合起来。通过递归和goroutine创建一个符合done channel 1234567891011121314151617181920212223 var or func(channels ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; or = func(channels ...&lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; switch len(channels) &#123; case 0: return nil case 1: return channels[0] &#125; orDone := make(chan interface&#123;&#125;) go func() &#123; defer close() switch len(channels): case 2: select&#123; case &lt;-channels[0]: case &lt;-channels[1]: case &lt;-channels[1]: case &lt;-channels[2]: &#125; &#125;() &#125;&#125; 错误处理123456789101112131415161718192021222324252627282930313233343536373839type Result struct &#123; Error error Response *http.Response&#125;func main() &#123; checkStatus := func( done &lt;-chan interface&#123;&#125;, urls ...string, ) &lt;-chan Result &#123; results := make(chan Result) go func()&#123; defer close(results) for _, url := range urls &#123; var result Result resp, err := http.Get(url) result = Result&#123;Error: err, Response: resp&#125; select &#123; case &lt;-done: return case results &lt;-result: &#125; &#125; &#125;() return results &#125; done := make(chan interface&#123;&#125;) defer close(done) urls := []string&#123;&quot;https://www.baidu.com&quot;, &quot;https://badhost&quot;&#125; for result := range checkStatus(done, urls...)&#123; if result.Error != nil &#123; fmt.Printf(&quot;Error: %v.\n&quot;, result.Error) continue &#125; fmt.Printf(&quot;Response: %v.\n&quot;, result.Response.Status) &#125;&#125; pipeline一个stage是将数据输入，对其进行转换并将数据发回。1234567multiply := func(values []int, len(values)) []int &#123;&#125;add := func(values []int, additive int) []int &#123;&#125;ints := []int&#123;1, 2, 3, 4&#125;for _, v := range add(multiply(ints, 2), 1) &#123; fmt.Println(v)&#125; 在range子句中结合加法和乘法，这样构建了一个具有pipeline stage的属性，组合形成pipeline。 pipeline stage的属性是： 一个stage消耗并返回相同的类型； 一个stage必须用语言来表达，以便可以被传递； channel适合在Go中构建pipeline，可以接受和产生值，且可以安全的使用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657func main() &#123; generator := func(done &lt;-chan interface&#123;&#125;, integers ...int) &lt;-chan int &#123; intStream := make(chan int) go func() &#123; defer close(intStream) for _, i := range integers &#123; select &#123; case &lt;-done: return case intStream &lt;- i: &#125; &#125; &#125;() return intStream &#125; multiply := func(done &lt;-chan interface&#123;&#125;, intStream &lt;-chan int, multiplier int) &lt;-chan int &#123; multipliedStream := make(chan int) go func() &#123; defer close(multipliedStream) for i := range intStream &#123; select &#123; case &lt;-done: return case multipliedStream &lt;- i * multiplier: &#125; &#125; &#125;() return multipliedStream &#125; add := func(done &lt;-chan interface&#123;&#125;, intStream &lt;-chan int, additive int) &lt;-chan int &#123; addedStream := make(chan int) go func() &#123; defer close(addedStream) for i := range intStream &#123; select &#123; case &lt;-done: return case addedStream &lt;- i + additive: &#125; &#125; &#125;() return addedStream &#125; done := make(chan interface&#123;&#125;) defer close(done) intStream := generator(done, 1, 2, 3, 4) pipeline := multiply(done, add(done, multiply(done, intStream, 2), 1), 2) for v := range pipeline &#123; fmt.Println(v) &#125;&#125; 挺有意思的，显示了流水线的操作。 generator接受一个可变的整数切片，构造一个缓存长度等于输入片段的整数channel，启动goroutine并返回构造的channel，将一组离散值转化成一个channel上的数据流。 扇入扇出扇出是描述启动多个goroutine以处理来自pipeline的输入的过程；扇入是描述将多个结果组合到一个channel的过程中。 1234567primeStream := primeFinder(done, randIntStream)numFinders := runtime.NumCPU()finders := make([]&lt;-chan int, numFinders)for i := 0; i &lt; numFinders; i ++ &#123; finders[i] = primeFinder(done, randIntStream)&#125; 这里启动了stage的多个副本，有n个goroutine从随机数发生器中拉出并试图确定数字是否为素数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128package pipsimport ( &quot;sync&quot;)type PrimePip struct &#123;&#125;func NewPrimePip() *PrimePip &#123; primePip := &amp;PrimePip&#123;&#125; return primePip&#125;func (primePip *PrimePip) RepeatFn( done &lt;-chan interface&#123;&#125;, fn func() interface&#123;&#125;,) &lt;-chan interface&#123;&#125; &#123; valueStream := make(chan interface&#123;&#125;) go func() &#123; defer close(valueStream) for &#123; select &#123; case &lt;-done: return case valueStream &lt;- fn(): &#125; &#125; &#125;() return valueStream&#125;func (primePip *PrimePip) Take( done &lt;-chan interface&#123;&#125;, valueStream &lt;-chan interface&#123;&#125;, num int,) &lt;-chan interface&#123;&#125; &#123; takeStream := make(chan interface&#123;&#125;) go func() &#123; defer close(takeStream) for i := 0; i &lt; num; i++ &#123; select &#123; case &lt;-done: return case takeStream &lt;- &lt;-valueStream: &#125; &#125; &#125;() return takeStream&#125;func (primePip *PrimePip) ToInt( done &lt;-chan interface&#123;&#125;, valueStream &lt;-chan interface&#123;&#125;,) &lt;-chan int &#123; intStream := make(chan int) go func() &#123; defer close(intStream) for v := range valueStream &#123; select &#123; case &lt;-done: return case intStream &lt;- v.(int): &#125; &#125; &#125;() return intStream&#125;func (primePip *PrimePip) PrimeFinder( done &lt;-chan interface&#123;&#125;, intStream &lt;-chan int,) &lt;-chan interface&#123;&#125; &#123; primeStream := make(chan interface&#123;&#125;) go func() &#123; defer close(primeStream) for integer := range intStream &#123; integer -= 1 prime := true for divisor := integer - 1; divisor &gt; 1; divisor-- &#123; if integer%divisor == 0 &#123; prime = false break &#125; &#125; if prime &#123; select &#123; case &lt;-done: return case primeStream &lt;- integer: &#125; &#125; &#125; &#125;() return primeStream&#125;func (primePip *PrimePip) FanIn( done &lt;-chan interface&#123;&#125;, channels ...&lt;-chan interface&#123;&#125;,) &lt;-chan interface&#123;&#125; &#123; var wg sync.WaitGroup multiplexedStream := make(chan interface&#123;&#125;) multiplexed := func(c &lt;-chan interface&#123;&#125;) &#123; defer wg.Done() for i := range c &#123; select &#123; case &lt;-done: return case multiplexedStream &lt;- i: &#125; &#125; &#125; wg.Add(len(channels)) for _, c := range channels &#123; go multiplexed(c) &#125; go func() &#123; wg.Wait() close(multiplexedStream) &#125;() return multiplexedStream&#125; or-done-channel用于处理来自系统各个分散部分的channel，需要用channel中的select语句来包装我们的读操作，并从已完成的channel中进行选择。 123456789101112131415161718192021orDone := func(done, c &lt;-chan interface&#123;&#125;) &lt;-chan interface&#123;&#125; &#123; valStream := make(chan interface&#123;&#125;) go func() &#123; defer close(valStream) for &#123; select &#123; case &lt;-done: return case v, ok := &lt;-c: if ok == false&#123; return &#125; select &#123; case valStream &lt;- v: case &lt;-done: &#125; &#125; &#125; &#125; () return valStream&#125; tee-channel分割一个来自channel的值，以便将他们发送到代码的两个独立区域。 队列排队在队列尚未准备好的时候开始接受请求，只要stage完成了工作，就会把结果存放在一个稍后其他stage可以获取到的临时位置。 在一个stage批处理请求节省时间 如果stage中的延迟产生反馈回路进入系统。 context包主要包括：123456789101112var Canceled = errors.New(&quot;context canceled&quot;)var DeadlineExceeded error = deadlineExceededError&#123;&#125;type CancelFunctype Contextfunc Background() Contextfunc TODO() Contextfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func WithValue(parent Context, key, val interface&#123;&#125;) Context 上下文包有两个目的： 提供可以取消调用图中分支的API 提供用于通过呼叫传输请求范围数据的数据包 context类型将是函数的第一个参数，此外，接收context的函数并不能取消它，这保护了调用堆栈上的函数被子函数取消上下文的情况。 上述context包中的函数都接收一个Context参数，并返回一个Context。WithCancel返回新Context，它在调用返回的cancel函数时关闭其done channel。WithDeadline返回一个新的Context，当机器的时钟超过给定的最后期限时，它关闭完成的channel。WithTimeout返回一个新的Context，它在给定的超时时间后关闭完成的channel。 如果函数以某种方式在调用图中取消它后面的函数，它将调用其中一个函数并传递给它的上下文，然后将返回的上下文传递给它的子元素，如果函数不需要修改取消行为，则只传递给定的上下文。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778func main() &#123; var wg sync.WaitGroup ctx, cancel := context.WithCancel(context.Background()) defer cancel() wg.Add(1) go func() &#123; defer wg.Done() if err := printGreeting(ctx); err != nil &#123; fmt.Printf(&quot;cannot print greeting: %v\n&quot;, err) cancel() &#125; &#125;() wg.Add(1) go func() &#123; defer wg.Done() if err := printFarewell(ctx); err != nil &#123; fmt.Printf(&quot;cannot print greeting: %v\n&quot;, err) cancel() &#125; &#125;() wg.Wait()&#125; func printGreeting(ctx context.Context) error &#123; greeting, err := genGreeting(ctx) if err != nil &#123; return err &#125; fmt.Printf(&quot;%s world!\n&quot;, greeting) return nil&#125;func printFarewell(ctx context.Context) error &#123; farewell, err := genFarewell(ctx) if err != nil &#123; return err &#125; fmt.Printf(&quot;%s world!\n&quot;, farewell) return nil&#125;func genGreeting(ctx context.Context) (string, error) &#123; ctx, cancel := context.WithTimeout(ctx, 1*time.Second) defer cancel() switch locale, err := locale(ctx); &#123; case err != nil: return &quot;&quot;, err case locale == &quot;EN/US&quot;: return &quot;hello&quot;, nil &#125; return &quot;&quot;, fmt.Errorf(&quot;unsupported locale&quot;)&#125;func genFarewell(ctx context.Context) (string, error) &#123; switch locale, err := locale(ctx); &#123; case err != nil: return &quot;&quot;, err case locale == &quot;EN/US&quot;: return &quot;godbye&quot;, nil &#125; return &quot;&quot;, fmt.Errorf(&quot;unsupported locale&quot;)&#125;func locale(ctx context.Context) (string, error) &#123; if deadline, ok := ctx.Deadline(); ok &#123; if deadline.Sub(time.Now().Add(1*time.Minute)) &lt;= 0 &#123; return &quot;&quot;, context.DeadlineExceeded &#125; &#125; select &#123; case &lt;-ctx.Done(): return &quot;&quot;, ctx.Err() case &lt;-time.After(1 * time.Minute): &#125; return &quot;EN/US&quot;, nil&#125; 上述程序允许locale函数快速失败，不必实际等待超时发生。 context包的另一个功能是用于存储和检索请求范围数据的Context数据包。1234567891011func ProcessRequest(userID, authToken string) &#123; ctx := context.WithValue(context.Background(), &quot;userID&quot;, userID) ctx = context.WithValue(ctx, &quot;authToken&quot;, authToken) HandleResponse(ctx)&#125;func HandleResponse(ctx context.Context) &#123; fmt.Printf(&quot;handling response for %v (%v)\n&quot;, ctx.Value(&quot;userID&quot;), ctx.Value(&quot;authToken&quot;))&#125; 我们使用的键值必须满足Go的可比性概念，即==和!=在使用时需要返回正确的结果。 返回值必须安全，才能从多个goroutine访问 由于context的键和值都被定义为interface{}，所以当试图检索值时，我们会失去Go的类型安全性，key可以是不同的类型，或者与我们提供的key略有不同。建议在软件包里定义一个自定义键类型：12345678type foo inttype bar intm := make(map[interface&#123;&#125;] int)m[foo(1)] = 1m[bar(1)] = 1fmt.Printf(&quot;%v&quot;, m) 输出为：1map[1:1, 2:2] 虽然基础值是相同的，但是科通通过不同的类型信息在map中区分它们。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++虚继承的概念]]></title>
    <url>%2F2019%2F07%2F02%2Fcpp%E8%99%9A%E7%BB%A7%E6%89%BF%E7%9A%84%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[为了解决从不同途径继承来的同名的数据成员在内存中有不同的拷贝造成数据不一致问题，将共同基类设置为虚基类。这时从不同的路径继承过来的同名数据成员在内存中就只有一个拷贝，同一个函数名也只有一个映射。这样不仅就解决了二义性问题，也节省了内存，避免了数据不一致的问题。 class 派生类名：virtual 继承方式 基类名 virtual是关键字，声明该基类为派生类的虚基类。 在多继承情况下，虚基类关键字的作用范围和继承方式关键字相同，只对紧跟其后的基类起作用。 声明了虚基类之后，虚基类在进一步派生过程中始终和派生类一起，维护同一个基类子对象的拷贝。 执行顺序首先执行虚基类的构造函数，多个虚基类的构造函数按照被继承的顺序构造； 执行基类的构造函数，多个基类的构造函数按照被继承的顺序构造； 执行成员对象的构造函数，多个成员对象的构造函数按照申明的顺序构造； 执行派生类自己的构造函数； 析构以与构造相反的顺序执行； mark从虚基类直接或间接派生的派生类中的构造函数的成员初始化列表中都要列出对虚基类构造函数的调用。但只有用于建立对象的最派生类的构造函数调用虚基类的构造函数，而该派生类的所有基类中列出的对虚基类的构造函数的调用在执行中被忽略，从而保证对虚基类子对象只初始化一次。 在一个成员初始化列表中同时出现对虚基类和非虚基类构造函数的调用时，虚基类的构造函数先于非虚基类的构造函数执行。 虚继承与继承的差异首先，虚拟继承与普通继承的区别有： 假设derived 继承自base类，那么derived与base是一种“is a”的关系，即derived类是base类，而反之错误； 假设derived 虚继承自base类，那么derivd与base是一种“has a”的关系，即derived类有一个指向base类的vptr。（貌似有些牵强！某些编译器确实如此，关于虚继承与普通继承的差异见：c++ 虚继承与继承的差异 ） 因此虚继承可以认为不是一种继承关系，而可以认为是一种组合的关系。正是因为这样的区别，下面我们针对虚拟继承来具体分析。虚拟继承中遇到最广泛的是菱形结构。下面从菱形虚继承结构说起吧： 1234567891011121314151617181920212223242526272829class stream&#123;public: stream()&#123;cout&lt;&lt;&quot;stream::stream()!&quot;&lt;&lt;endl;&#125;&#125;; class iistream:virtual stream&#123;public: iistream()&#123;cout&lt;&lt;&quot;istream::istream()!&quot;&lt;&lt;endl;&#125;&#125;; class oostream:virtual stream&#123;public: oostream()&#123;cout&lt;&lt;&quot;ostream::ostream()!&quot;&lt;&lt;endl;&#125;&#125;; class iiostream:public iistream,public oostream&#123;public: iiostream()&#123;cout&lt;&lt;&quot;iiostream::iiostream()!&quot;&lt;&lt;endl;&#125;&#125;; int main(int argc, const char * argv[])&#123; iiostream oo;&#125; 程序运行的输出结果为：stream::stream()! istream::istream()! ostream::ostream()! iiostream::iiostream()! 输出这样的结果是毫无悬念的！本来虚拟继承的目的就是当多重继承出现重复的基类时，其只保存一份基类。减少内存开销。其继承结构为： stream / \ istream ostream \ / iiostream 这样子的菱形结构，使公共基类只产生一个拷贝。 从基类 stream 派生新类时，使用 virtual 将类stream说明为虚基类,这时派生类istream、ostream包含一个指向虚基类的vptr，而不会产生实际的stream空间。所以最终iiostream也含有一个指向虚基类的vptr，调用stream中的成员方法时，通过vptr去调用，不会产生二义性。而现在我们换种方式使用虚继承：12345678910111213141516171819202122232425262728class stream&#123;public: stream()&#123;cout&lt;&lt;&quot;stream::stream()!&quot;&lt;&lt;endl;&#125;&#125;; class iistream:public stream&#123;public: iistream()&#123;cout&lt;&lt;&quot;istream::istream()!&quot;&lt;&lt;endl;&#125;&#125;; class oostream:public stream&#123;public: oostream()&#123;cout&lt;&lt;&quot;ostream::ostream()!&quot;&lt;&lt;endl;&#125;&#125;; class iiostream:virtual iistream,virtual oostream&#123;public: iiostream()&#123;cout&lt;&lt;&quot;iiostream::iiostream()!&quot;&lt;&lt;endl;&#125;&#125;;int main(int argc, const char * argv[])&#123; iiostream oo;&#125; 其输出结果为：stream::stream()! istream::istream()! stream::stream()! ostream::ostream()! iiostream::iiostream()! 从结果可以看到，其构造过程中重复出现基类stream的构造过程。这样就完全没有达到虚拟继承的目的。其继承结构为： stream stream \ / istream ostream \ / iiostream 从继承结构可以看出，如果iiostream对象调用基类stream中的成员方法，会导致方法的二义性。因为iiostream含有指向其虚继承基类 istream，ostream的vptr。而 istream，ostream包含了stream的空间，所以导致iiostream不知道导致是调用那个stream的方法。要解决改问题，可以指定vptr，即在调用成员方法是需要加上作用域，例如123456789class stream&#123; void f()&#123;cout&lt;&lt;&quot;here!&quot;&lt;&lt;endl;&#125;&#125; main()&#123; iiostream ii； ii.f();&#125; 编译器提示调用f方法错误。而采用1ii.istream::f(); 编译通过，并且会调用istream类vptr指向的f()方法。 前面说了这么多，在实际的应用中虚拟继承的胡乱使用，更是会导致继承顺序以及基类构造顺序的混乱。如下面的代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class B1&#123;public: B1()&#123;cout&lt;&lt;&quot;B1::B1()!&lt;&quot;&lt;&lt;endl;&#125; void f() &#123;cout&lt;&lt;&quot;i&apos;m here!&quot;&lt;&lt;endl;&#125;&#125;; class V1: public B1&#123;public: V1()&#123;cout&lt;&lt;&quot;V1::V1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class D1: virtual public V1&#123;public: D1()&#123;cout&lt;&lt;&quot;D1::D1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;;class B2&#123;public: B2()&#123;cout&lt;&lt;&quot;B2::B2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class B3&#123;public: B3()&#123;cout&lt;&lt;&quot;B3::B3()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class V2:public B1, public B2&#123;public: V2()&#123;cout&lt;&lt;&quot;V2::V2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class D2:virtual public V2, public B3&#123;public: D2()&#123;cout&lt;&lt;&quot;D2::D2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class M1&#123;public: M1()&#123;cout&lt;&lt;&quot;M1::M1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class M2&#123;public: M2()&#123;cout&lt;&lt;&quot;M2::M2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class X:public D1, public D2&#123; M1 m1; M2 m2;&#125;;int main(int argc, const char * argv[])&#123; X x;&#125; 上面的代码是来自《Exceptional C++ Style》中关于继承顺序的一段代码。可以看到，上面的代码继承关系非常复杂，而且层次不是特别的清楚。而虚继承的加入更是让继承结构更加无序。不管怎么样，我们还是可以根据c++的标准来分析上面代码的构造顺序。c++对于创建一个类类型的初始化顺序是这样子的： 最上层派生类的构造函数负责调用虚基类子对象的构造函数。所有虚基类子对象会按照深度优先、从左到右的顺序进行初始化； 直接基类子对象按照它们在类定义中声明的顺序被一一构造起来； 非静态成员子对象按照它们在类定义体中的声明的顺序被一一构造起来； 最上层派生类的构造函数体被执行。 根据上面的规则，可以看出，最先构造的是虚继承基类的构造函数，并且是按照深度优先，从左往右构造。因此，我们需要将继承结构划分层次。显然上面的代码可以认为是4层继承结构。其中最顶层的是B1,B2类。第二层是V1,V2,V3。第三层是D1,D2.最底层是X。而D1虚继承V1，D2虚继承V2，且D1和D2在同一层。所以V1最先构造，其次是V2.在V2构造顺序中，B1先于B2.虚基类构造完成后，接着是直接基类子对象构造，其顺序为D1,D2.最后为成员子对象的构造，顺序为声明的顺序。构造完毕后，开始按照构造顺序执行构造函数体了。所以其最终的输出结果为：12345678910111213141516171819B1::B1()!&lt;V1::V1()!&lt;B1::B1()!&lt;B2::B2()!&lt;V2::V2()!&lt;D1::D1()!&lt;B3::B3()!&lt;D2::D2()!&lt;M1::M1()!&lt;M2::M2()!&lt; 从结果也可以看出其构造顺序完全符合上面的标准。而在结果中，可以看到B1重复构造。还是因为没有按照要求使用virtual继承导致的结果。要想只构造B1一次，可以将virtual全部改在B1上，如下面的代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class B1&#123;public: B1()&#123;cout&lt;&lt;&quot;B1::B1()!&lt;&quot;&lt;&lt;endl;&#125; void f() &#123;cout&lt;&lt;&quot;i&apos;m here!&quot;&lt;&lt;endl;&#125;&#125;; class V1: virtual public B1 //public修改为virtual&#123;public: V1()&#123;cout&lt;&lt;&quot;V1::V1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class D1: public V1&#123;public: D1()&#123;cout&lt;&lt;&quot;D1::D1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class B2&#123;public: B2()&#123;cout&lt;&lt;&quot;B2::B2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class B3&#123;public: B3()&#123;cout&lt;&lt;&quot;B3::B3()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class V2:virtual public B1, public B2 //public B1修改为virtual public B1&#123;public: V2()&#123;cout&lt;&lt;&quot;V2::V2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class D2: public V2, public B3&#123;public: D2()&#123;cout&lt;&lt;&quot;D2::D2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class M1&#123;public: M1()&#123;cout&lt;&lt;&quot;M1::M1()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class M2&#123;public: M2()&#123;cout&lt;&lt;&quot;M2::M2()!&lt;&quot;&lt;&lt;endl;&#125;&#125;; class X:public D1, public D2&#123; M1 m1; M2 m2;&#125; 根据上面的代码，其输出结果为：1234567891011121314151617B1::B1()!&lt;V1::V1()!&lt;D1::D1()!&lt;B2::B2()!&lt;V2::V2()!&lt;B3::B3()!&lt;D2::D2()!&lt;M1::M1()!&lt;M2::M2()!&lt; 由于虚继承导致其构造顺序发生比较大的变化。不管怎么，分析的规则还是一样。 上面分析了这么多，我们知道了虚继承有一定的好处，但是虚继承会增大占用的空间。这是因为每一次虚继承会产生一个vptr指针。空间因素在编程过程中，我们很少考虑，而构造顺序却需要小心，因此使用未构造对象的危害是相当大的。因此，我们需要小心的使用继承，更要确保在使用继承的时候保证构造顺序不会出错。下面我再着重强调一下基类的构造顺序规则： 最上层派生类的构造函数负责调用虚基类子对象的构造函数。所有虚基类子对象会按照深度优先、从左到右的顺序进行初始化； 直接基类子对象按照它们在类定义中声明的顺序被一一构造起来； 非静态成员子对象按照它们在类定义体中的声明的顺序被一一构造起来； 最上层派生类的构造函数体被执行。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言并发之道1-3章笔记]]></title>
    <url>%2F2019%2F06%2F30%2FGo%E5%B9%B6%E5%8F%91%E4%B9%8B%E9%81%931-3%2F</url>
    <content type="text"><![CDATA[原子性原子性是指一个操作在运行的环境中是不可被分割的或不可被中断的。操作的原子性是根据当前定义的范围而改变的，上下文不同则一个操作可能不是原子性的。 使一个操作变为原子操作取决于你想让它在哪个上下文中，如果上下文是没有并发的，则该代码是原子性的。 内存访问同步程序中需要独占访问共享资源的部分叫做“临界区”，看一个例子123456789101112131415161718func main() &#123; var memoryAccess sync.Mutex var value int go func() &#123; memoryAccess.Lock() value++ memoryAccess.Unlock() &#125;() memoryAccess.Lock() if value == 0 &#123; fmt.Printf(&quot;the value is %v.\n&quot;, value) &#125; else &#123; fmt.Printf(&quot;the value is %v.\n&quot;, value) &#125; memoryAccess.Unlock()&#125; 这里我们添加了一个sync.Mutex类型，声明一下在哪个部分里应该独占value这个变量。如果想要访问value这个变量，就要首先调用Lock，当访问结束后，调用Unlock。当然，也可能造成维护和性能的问题。 defer关键字defer代码块会在函数调用链表中增加一个函数调用。这个函数调用不是普通的函数调用，而是会在函数正常返回，也就是return之后添加一个函数调用。因此，defer通常用来释放函数内部变量。 当defer被声明时，其参数就会被实时解析我们通过以下代码来解释这条规则:123456func a() &#123; i := 0 defer fmt.Println(i) i++ return&#125; 虽然我们在defer后面定义的是一个带变量的函数: fmt.Println(i). 但这个变量在defer被声明的时候，就已经确定其确定的值了。 换言之，上面的代码等同于下面的代码:123456func a() &#123; i := 0 defer fmt.Println(0) //因为i=0，所以此时就明确告诉golang在程序退出时，执行输出0的操作 i++ return&#125; 为了更为明确的说明这个问题，我们继续定义一个defer:1234567func a() &#123; i := 0 defer fmt.Println(i) //输出0，因为i此时就是0 i++ defer fmt.Println(i) //输出1，因为i此时就是1 return&#125; 通过运行结果，可以看到defer输出的值，就是定义时的值。而不是defer真正执行时的变量值(很重要，搞不清楚的话就会产生于预期不一致的结果) 但为什么是先输出1，在输出0呢？ 看下面的规则二。 defer执行顺序为先进后出当同时定义了多个defer代码块时，golang安装先定义后执行的顺序依次调用defer。不要为什么，golang就是这么定义的。我们用下面的代码加深记忆和理解:12345func b() &#123; for i := 0; i &lt; 4; i++ &#123; defer fmt.Print(i) &#125;&#125; 在循环中，依次定义了四个defer代码块。结合规则一，我们可以明确得知每个defer代码块应该输出什么值。 安装先进后出的原则，我们可以看到依次输出了3210. defer可以读取有名返回值先看下面的代码:1234func c() (i int) &#123; defer func() &#123; i++ &#125;() return 1&#125; 输出结果是12. 在开头的时候，我们说过defer是在return调用之后才执行的。 这里需要明确的是defer代码块的作用域仍然在函数之内，结合上面的函数也就是说，defer的作用域仍然在c函数之内。因此defer仍然可以读取c函数内的变量(如果无法读取函数内变量，那又如何进行变量清除呢….)。 当执行return 1 之后，i的值就是1. 此时此刻，defer代码块开始执行，对i进行自增操作。 因此输出2. 掌握了defer以上三条使用规则，那么当我们遇到defer代码块时，就可以明确得知defer的预期结果。 死锁、活锁、饥饿死锁是所有并发进程等待的程序，在这种情况下，如果没有外界干预，这个程序将无法恢复。 Coffman条件出现死锁的条件有以下几个必要条件： 相互排斥：并发进程同时拥有资源的独占权 等待条件：并发进程必须同时拥有一个资源，并等待额外的资源 没有抢占：并发进程拥有的资源只能被该进程释放 循环等待：一个并发进程只能等待一系列其他并发进程，这些并发进程也在等待 活锁正在主动执行并发操作的程序，但是无法向前推进程序的状态。看起来程序在工作。 饥饿在任何情况下，并发进程欧步伐获得执行工作所需的所有资源。饥饿通常意味着有一个或多个贪婪的并发进程，它们不公平地阻止一个或多个并发进程，以尽可能地有效完成工作，或者阻止全部并发进程。 通信顺序进程并行与并发并行属于一个运行中的程序，并发属于代码。 并发哲学CSP即Communicating Sequential Process，通信顺序进程。 Go的运行时自动将goroutine映射到系统的线程上，并管理调度，因此可以在像goroutine阻塞等待IO之类的事情上进行内省，从而智能的把OS的线程分配到没有阻塞的goroutine上。 如果有一块产生计算结果并想共享结果给其他代码块的代码，则需要传递数据的所有权。并发程序安全就是保证同时只有一个并发上下文拥有数据的所有权。通过channel类型解决，可以创建一个带缓存的channel实现低成本的在内存中的队列来解耦生产者和消费者。 使用channel时可以更简单的控制软件中出现的复杂性。 并发组件goroutine每个Go程序中都有至少一个goroutine： main goroutine。goroutine是一个并发的函数，在一个函数前添加go关键字来触发。匿名函数也行：123go func() &#123; fmt.Println(&quot;hello&quot;)&#125; () 函数赋值也行：12345sayhello := func() &#123; fmt.Println(&quot;hello&quot;)&#125;go sayhello() go中的goroutine是一个更高级别的抽象，称为协程，一中非抢占式的简单并发子程序，不能被中断，允许暂停或重入。Go的运行时会观察goroutine的运行时行为，并在它们阻塞时自动挂起它们，然后在它们不被阻塞时自动恢复它们。 go的主机托管机制是一个名为M:N调度器的实现。将M个绿色线程映射到N个OS线程，然后将goroutine安排在绿色线程上。 go遵循一个fork-join并发模型，将执行的子分支与其父节点同时运行，这些并发的执行分支将会在未来合并在一起。为了创建一个join点，必须对程序进行同步，这里可以通过sync.Watigroup实现。 在下边这个程序中，输出的是“world”，因此可以说明goroutine在它们所创建的相同地址空间内执行。1234567891011func main() &#123; var wg sync.WaitGroup salutation := &quot;hello&quot; wg.Add(1) go func()&#123; defer wg.Done() salutation = &quot;world&quot; &#125;() wg.Wait() fmt.Println(salutation)&#125; 可以以如下方式将参数传到函数中，以输出正确结果。12345678for _, salt := range []string&#123;&quot;hello&quot;, &quot;greetings&quot;, &quot;good day&quot;&#125; &#123; wg.Add(1) go func(salt string) &#123; defer wg.Done() fmt.Println(salt) &#125; (salt)&#125;wg.Wait() sync包sync包包含了对低级别内存访问同步最有用的并发原语。 WaitGroup可以调用Add表明n个goroutine已经开始了，使用defer关键字确保在goroutine退出之前执行Done操作。执行Wait操作将会阻塞main goroutine直到所有goroutine表明它们已经退出。12345678910111213141516wg.Add(1)go func() &#123; defer wg.Done() fmt.Println(&quot;1st goroutine sleeping&quot;) time.Sleep(1)&#125; ()wg.Add(1)go func() &#123; defer wg.Done() fmt.Println(&quot;2nd goroutine sleeping&quot;) time.Sleep(2)&#125;()wg.Wait()fmt.Println(&quot;All goroutine complete&quot;) WaitGroup调用通过传入的整数执行Add操作增加计数器的增量，并调用Done递减，Wait阻塞，直到计数器为0. 互斥锁和读写锁channel通过通信共享内存，而Mutex通过开发人员的约定同步访问共享内存。 Mutex有两个函数，Lock和Unlock，在defer中调用Unlock保证即使出现了panic，也可以及时调用Unlock，避免死锁。 进入和退出一个临界区是有开销的，所以要减少临界区的范围，可能存在多个并发进程之间共享内存，但这些进程不是都需要读写此内存，可以利用不同类型的互斥对象，sync.RWMutex。可以请求一个锁用于读或者写。 condcond是一个goroutine的集合点，等待或发布一个event，在这里一个event是两个或两个以上的goroutine之间的任意信号。123456c := sync.NewCond(&amp;sync.Mutex&#123;&#125;)c.L.Lock()for conditionTrue() == false &#123; c.Wait()&#125;c.L.Unlock() 上述代码实例化一个cond，NewCond创建一个类型，cond类型能够以一种并发安全的方式与其他goroutine协调。 Broadcast提供了同时与多个goroutine通信的方法，在Clicked Cond上调用Broadcast，则所有三个函数都将运行。它内部维护一个FIFO列表，等待接收信号，向所有等待的goroutine发送信号。12345678910111213141516171819202122232425262728293031323334353637func main() &#123; type Button struct &#123; Clicked *sync.Cond &#125; button := Button&#123; Clicked: sync.NewCond(&amp;sync.Mutex&#123;&#125;) &#125; subscribe := func(c *sync.Cond, fn func()) &#123; var goroutineRunning sync.WaitGroup goroutineRunning.Add(1) go func()&#123; goroutineRunning.Done() c.L.Lock() defer c.L.Unlock() c.Wait() fn() &#125;() goroutineRunning.Wait() &#125; var clickRegistered sync.WaitGroup clickRegistered.Add(3) subscribe(button.Clicked, func() &#123; fmt.Println(&quot;Maximizing window&quot;) clickRegistered.Done() &#125;) subscribe(button.Clicked, func() &#123; fmt.Println(&quot;Displaying annoying dialog box!&quot;) clickRegistered.Done() &#125;) subscribe(button.Clicked, func() &#123; fmt.Println(&quot;Mouse clicked&quot;) clickRegistered.Done() &#125;) button.Clicked.Broadcast() clickRegistered.Wait()&#125; oncesync.Once在内部调用一些原语，确保即使在不同的goroutine上也只会调用一次Do方法处理传进来的函数。1234567var count intincrement := func() &#123;count++&#125;decrement := func() &#123;count--&#125;var once sync.Onceonce.Do(increment)once.Do(decrement) 上述程序输出的是1，因为once只计算Do调用的次数，不管Do函数里边的参数是什么。 池Pool模式是一种创建和提供可供使用的固定数量实例或Pool实例的方法，用于约束创建昂贵的场景，以便只创建固定数量的实例，但不确定数量的操作仍然可以请求访问这些场景。 Pool的主接口是Get方法，首先检查池中是否有可用的实例，如果没有则调用new方法创建一个，完成时调用者调用Put方法将实例归还。 Pool也用来尽可能快地将预先分配的对象缓存加载启动，通过提前加载获取引用到另一个对象所需的时间，来节省消费者的时间。 实例化sync.Pool时，使用new方法创建一个成员变量，在调用时是线程安全的。 收到来自Get的实例时，不要对接收的对象的状态做出任何假设。 当你用完了从Pool中取出的对象时一定要调用Put否则Pool无法复用这个实例。 Pool内的分布大致均匀。 channelchannel充当着信息传送的管道，值可以沿着channel传递。12var dataStream chan interface&#123;&#125;dataStream = make(chan interface&#123;&#125;) 上面声明了一个新channel，因为声明的类型是空接口，所以类型是interface{}，并且使用内置的make函数实例化channel。 声明一个单向channel只需包含“&lt;-”，声明一个只能读取的channel，将“&lt;-”放在左边：12var dataStream &lt;-chan interface&#123;&#125;dataStream = make(&lt;-chan interface&#123;&#125;) 声明一个只能发送的channel，则将“&lt;-”放在右边。 通过将“&lt;-”放到channel的右边实现发送操作，通过将“&lt;-”放到channel的左边实现接收操作。另一种方法是数据流向箭头所指方向的变量。12345stringStream := make(chan string)go func()&#123; stringStream &lt;- &quot;hello&quot;&#125;()fmt.Println(&lt;-stringStream) 上述代码实现了将字符串文本传递到stringStream channel并读取channel的字符串并打印到stdout。 可以从channel中获取，然后通过range遍历，并且在channel关闭时自动中断循环：12345678910intStream := make(chan int)go func() &#123; defer close(intStream) for i:= 1; i &lt;= 5; i ++ &#123; intStream &lt;- i &#125;&#125;()for integer := range intStream &#123; fmt.Printf(&quot;%v &quot;,integer)&#125; 关闭channel也是一种同时给多个goroutine发信号的方法，如果有n个goroutine在一个channel上等待，而不是在channel上写n次来打开每个goroutine，可以简单地关闭channel。 更可以创建buffered channel，在实例化时提供容量。即使没有在channel上执行读取操作，goroutine仍然可以写入n次。 如果说channel是满的，那么写入channel阻塞。无缓冲的channel容量为0，因此在任何写入之前就已经满了，缓冲channel是一个内存中的FIFO队列，用于并发进程通信。 我们需要在正确的环境中配置channel，channel的所有者对channel拥有写访问视图，使用者只有读访问视图。拥有channel的goroutine应该： 实例化channel； 执行写操作，或将所有权传递给另一个goroutine； 关闭channel 通过只读channel将上述三件事暴露出来。 selectselect是将channel绑定在一起的粘合剂，在一个系统中两个或多个组件的交集中，可以在本地、单个函数或类型以及全局范围内找到select语句绑定在一起的channel。12345678910var c1, c2 &lt;-chan interface&#123;&#125;var c3 chan&lt;- interface&#123;&#125;select &#123; case &lt;- c1: .... case &lt;- c2: .... case &lt;- c3: ....&#125; 如果多个channel是可用的，则执行伪随机选择，每一个都可能被执行到。如果没有任何channel可用，则我们需要使用time包中的超时机制，time.After。 GOMAXPROCS控制这是runtime中的一个函数，这个函数控制的OS线程的数量将承载所谓的“工作队列”。runtime.GOMAXPROCS总是被设置成为主机上逻辑CPU的数量。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记六]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%85%AD%2F</url>
    <content type="text"><![CDATA[第二十一讲 文件系统文件系统和文件文件系统是操作系统中管理持久性数据的子系统，提供数据存储和访问功能。 组织、检索、读写访问数据； 大多数计算机系统都有文件系统； Google也是一个文件系统。 文件是具有符号名，由字节序列组成的数据项集合，它是文件系统的基本单位，文件名是其标识符号。 文件系统的功能： 分配文件磁盘空间 管理文件块 管理空间控件 分配算法，磁盘上有很多空间块，如何选择空闲块 管理文件集合 定位：通过文件名找到内容 命名：通过名字找到文件 文件系统结构：文件的组织方式 数据可靠与安全 安全 可靠：持久保存文件并在系统崩溃时恢复 文件属性：名称、类型、位置、大小、保护、创建者、创建时间等。把文件的信息分成两部分，文件头是文件系统元数据中的文件信息，文件存储位置和顺序。 文件描述符读写数据之前必须打开文件。操作系统内核跟踪进程打开的文件，维护了一个打开文件表，文件描述符是打开文件的标识，程序打开文件的数目和文件系统里的数目是有量级上的区别的，所以单独设计了一个文件描述符方便设计。 操作系统在打开文件表中维护了打开文件的状态信息。 文件指针：最近一次读写位置，每个进程分别维护自己的打开文件指针。每个进程读写一个文件都有自己的打开文件指针。 文件打开计数：当前打开文件打开的次数，最后一个进程关闭这个文件指针后，这个文件就可以被从打开文件表中移除。 文件的磁盘位置：缓存文件的位置，下次就可以省事了 访问权限：可读可写？ 文件的用户视图：在用户看来，它是一个持久的数据结构。 从系统来看，它是一个字节序列的集合，系统不关心存储在磁盘上的数据结构，只是看成一个数据块的集合，数据块是逻辑的存储单位，这里与扇区有区别，扇区是物理存储单元。 进程读文件时，首先获取字节所在的数据块，因为读写的时候必须是以块为单位的。然后把其中需要的内容返回给进程，写文件时，首先获取字节所在的数据块，修改数据块中的对应部分，再写回。因此文件系统的基本操作单位是数据块。例如，getc和putc即使每次只访问1字节的内容也要缓存目标块的4096字节，因此，一个可行的优化是充分利用读进来缓存的这一个块。 操作系统需要了解进程如何访问文件 顺序访问：按字节依次读取 随机访问：从中间读写，不常用，但是也很重要，例如，虚拟内存中把内存也存储在文件中。 索引访问：通常不提供，数据库是建立在索引内容上的磁盘访问。 文件内部结构： 无结构：单词、字节序列 简单记录结构：分列、固定长度或可变长度 复杂结构：格式化文档或者可执行文件等，操作系统并不关心 多用户系统中的文件共享是很重要的，但是如何进行访问控制？每个用户能够获得哪些文件的哪些权限？访问模式分为：读、写、执行、删除、列表信息等。文件访问控制列表（ACL）指明了文件实体和权限的关系 多个进程同时访问一个文件时，语义一致性的问题。规定了多进程如何同时访问共享文件，与同步算法相似， Unix文件系统（UFS）语义： 对打开文件的写入内容立即对其他打开同一个文件的用户可见， 共享文件指针允许多个用户同时读取和写入文件。但是靠应用程序自己保证写入的完整性 会话语义只有当关闭文件时才能看到写入的文件。 目录、文件别名和文件系统种类文件比较多时，需要引入文件系统，比如分层文件系统，把若干个文件以目录的形式组织起来，目录也是一种特殊的文件，这个特殊文件中存的内容是文件的索引表，一个索引是文件名+文件指针，这样就可以把文件系统组织成一颗树。早期的文件系统是扁平的，只有一层目录，现在可以组织成一颗很深的树。 用这种方式组织之后，需要在目录下进行额外的搜索，创建，删除等操作，对文件进行操作之后需要对目录进行相应的修改，操作系统应该只允许内核对目录进行修改，这样确保了映射的完整性，用户通过系统调用实现对目录的操作。 最简单的目录组织是线性表，但是如果检索和增删比较耗时；哈希表（哈希数据结构的线性表）可以减少目录搜索时间，且目录表中的每一项长度都相同。但是可能冲突，需要有相应解决。 如果两个或多个文件名关联同一个文件，本来是为了方便共享，但是需要特殊实现： 硬链接，多个文件项指向同一个文件，如果删除的时候把所有的链接都删了，那这个文件也就删了 软链接：以快捷方式的形式指向其他文件，通过存储真实文件的路径（逻辑名称）来实现。删除的时候文件不受影响，但删除了文件的话这个链接就失效了。 文件目录中的循环：父子文件目录相互指向，形成循环，需要保证不存在循环，一种是只允许到文件的链接，不允许在子目录的链接，另一种是增加链接时用循环检测算法进行检测，不过在实际系统中使用的是限制向下查找的深度。 名字解析：把逻辑名字转换成物理资源（如文件），给定路径，说明文件存在哪里并输出文件内容。遍历文件目录直到找到目标文件。读取根目录的文件头（在磁盘固定位置），读取目录的文件头及其数据块，继续搜索下一个目录，直到找到文件。 当前工作目录：每个进程都会指向一个文件目录用于解析文件名，这样就不用每次都从根目录下查找了 文件系统需要先挂载才能被访问，系统启动时，未被挂载的文件系统需要挂载到操作系统的根目录下。 文件系统种类： 磁盘文件系统：文件存储在数据存储设备中（如磁盘）。主要有FAT，NTFS，ext2/3，等。不同文件系统对文件的优化不同，安全要求级别也不同，访问效率也不同。 数据库文件系统：文件特征是可被检索的，如WinFS 日志文件系统：记录文件系统的修改和事件，对文件的操作是原子性的 网络/分布式文件系统：如NFS、SMB、AFS、GFS等，文件可以通过网络被共享，文件被存到远端的服务器上，客户端远程挂载服务器文件系统，标准文件访问被转换成网络远程访问。 用户安全问题 一致性问题 错误处理模式问题 虚拟文件系统操作系统希望对不同文件系统提供统一的接口，文件系统对上层应用提供统一的接口，下边对不同的文件系统提供相应的访问接口。虚拟文件系统的目的是对所有不同文件系统提供抽象，功能有： 提供相同的文件和文件系统接口 管理所有文件和文件系统关联的数据结构 提供高效查询例程，实现文件系统遍历 与特定文件系统模块交互 文件系统基本数据结构： 文件卷控制块 每个文件系统一个 文件系统的详细信息 提供了块、块大小、空余块等信息 文件系统挂载时进入内存 文件控制块（inode）： 每个文件一个 提供了文件的详细信息 访问权限，拥有者，大小，数据块位置等 访问文件时进入内存 目录项： 每个目录项一个 目录项数据结构及树形布局编码成树形数据结构 指向文件控制块、父目录、子目录等。 在遍历一个文件路径时加载 这些数据结构都是持久的存储在外存中的。 可以通过一个统一的接口访问各种各样的文件系统。 文件缓存和打开文件文件缓存是指从磁盘读数据到CPU使用中间经过的缓存。磁盘控制器中有缓存，磁盘通过磁盘控制器完成数据的读写到内存和缓存，内存中有打开文件表，也有数据块缓存，从磁盘中读入数据块，数据块按需读入内存，也可采用“预读”机制提前读入。数据块也会在使用后被缓存，以防数据将会再次使用，写操作可能也会被缓存和延迟写入，这样可以将多次磁盘访问合并成一次，这存在写入失败和一致性的风险。 两种数据块缓存机制： 数据块缓存，每次读一个块时先看这个缓存中有没有。和虚拟存储隔离开。 页缓存：统一缓存数据块和内存页。把虚拟页面映射到外存文件中，也可把文件缓存到虚拟页中，文件读写转换成对内存的访问，可能导致缺页和设置成脏页。 文件系统中打开文件的数据结构： 文件描述符 每个被打开的文件都有一个文件描述符 保存了文件状态信息：目录项、当前文件指针等 打开文件表 每个进程有一个打开文件表 也有一个系统级的打开文件表 有文件被打开的时候，文件卷就不能被卸载 打开一个文件时，目录项和文件信息都在内存中有缓存，系统打开文件表中有一部分是各个进程不一样的，这就组成了进程的打开文件表。 一些文件系统提供了文件锁，用于协调多进程的文件访问： 强制：根据锁保持情况和访问需求确定是否拒绝访问 劝告：进程可以根据锁的状态决定怎么做 文件分配内存块分配给文件的情况与文件大小有关，文件系统需要对小文件提供很好的支持，且块空间不能过大。文件大小的分布有规律，大部分文件都很小，如果大部分文件存放在一个数据块里都有空闲，则这种分块方法是低效的。也有很大的文件，必须考虑如何支持大文件，表示文件使用n位，这个n与支持的最大的文件有关。 文件分配是指把哪些数据块分配给一个文件，即分配给一个文件数据块的位置和顺序。 连续分配：连续的一些块。文件头指定了起始块和长度。最先匹配，最佳匹配等。文件读取表现好，高效的顺序和随机访问。但是文件增长不方便，可以预分配或者按需分配。 链式分配：文件以数据库链表的方式存储。每个块中包含指向下一个块的指针。优点是创建、增大、缩小方便，且没有碎片，但是无法实现真正的随机访问，且破坏一个块，则后边的数据就都丢了。 索引分配：先分配一个索引块，说明哪些块里存了这个数据，即是指向文件数据块的指针列表。优点是创建、增大、缩小很简单，没有碎片，支持直接访问；但是文件很小到一个块就能存下时，这样就很浪费。文件比较大时需要多个索引块。 指标： 存储效率，第一种连续分配可能会存在外部碎片问题 读写性能，后两种可能在检索文件中间的内容的时候比较低效 UFS多级索引分配： 前边10个是直接索引 第11个是一级间接索引，这个块中保存了n个索引，每个索引指向一个块 第12个是二级间接索引，这个块中保存了n个一级索引 第13个是三级间接索引，这个块中保存了n个二级索引 效果： 提高了文件大小限制阈值 动态分配数据块，文件扩展简单 小文件开销小-只为大文件分配间接数据块，大文件在访问时需要大量索引 空闲空间管理和冗余磁盘阵列RAID空间空间管理需要记录或跟踪文件卷中未分配的数据块。 可以使用位图，Di=0表明数据块i是空闲的，否则是已分配的。这种方法使用简单但是可能是一个很大的向量表。 5M的位图表示40M数据块，表示了160G的磁盘。 假定空闲空间在磁盘中均匀分布，则找到0之前要扫描n/r，n是数据块总数，r是空闲块的数目 链式索引法：第一个块是空闲块的索引，指向空闲块。 通常磁盘通过分区来限制寻道时间，分区是一组柱面的集合，一个磁盘可以分成多个分区，每一个分区可以视为逻辑上独立的分区。如果只在一个分区上操作，那是可以提高性能的。 文件卷是一个拥有完整文件系统实例的空间，通常常驻在磁盘的单个分区上。 多磁盘可以改善吞吐量（通过并行），通过冗余提高可靠性和可用性。RAID（冗余磁盘阵列）是一组磁盘管理的技术，通过条带化、映像、带校验的条带化实现磁盘性能的提升。有两种实现：操作系统内核的文件卷管理或者硬件的RAID控制器。 RAID-0:磁盘条带化：把数据块分成若干个子块，存储在独立的磁盘上，通过独立磁盘的并行数据块访问提供更大的磁盘带宽，多个磁盘一起读取或写入一个文件的一部分。 RAID-1:磁盘镜像：像两个磁盘写入相同的数据，提高可靠性，从任何一个读取，可靠性成倍增加，读入性能线性增加。 RAID-4:带校验的磁盘条带化：数据块级的磁盘条带化加专用的奇偶校验磁盘，允许从任意一个故障磁盘中恢复数据。存校验和需要使用一个单独的校验磁盘，从之前的所有磁盘中读取数据进行校验和的计算。 RAID-5:分布式校验的磁盘条带化：不是把校验和固定存储在校验磁盘上，而是分开存放，提高校验和的读取性能。每组条带块有一个奇偶校验位，RAID-6中每组条带块有两个冗余块，允许两个磁盘块错误。 第二十二讲总体介绍操作系统提出了文件系统的抽象简化了对底层的访问。文件组织成目录，每一个目录项也是一个文件。文件和目录是应用程序看到的，索引节点是硬盘上的描述，安装点是一个访问文件系统包含文件的起始点。需要有针对这些抽象的操作，对于文件和目录，有open/close，read/write，对于索引节点，把磁盘中的数据和应用程序看到的文件建立对应关系，有lookup，安装点有mount和umount实现了对文件系统的挂载和卸载。 主要初始化的流程有：idle的初始化，init的初始化和文件系统磁盘外设的初始化，把文件系统的程序放到内存中来，变为进程在用户空间执行。virtual-system可以提供一个抽象，不管底层如何。 在lab5中，bootloader一开始就把应用程序加载到内存中来了，在lab8中通过文件系统执行。 在qemu模拟生成的硬盘上，有一个具体文件系统SFS，其上实现了一系列的层次，比如IO层次可以实现访问硬盘，通过simpleFS读取硬盘的结构，通过VFS给上层应用提供一致的接口，从而实现了syscall。 ucore文件系统架构首先，通用文件系统的访问接口为应用程序提供了API，放在了C库了，这个C库调用了系统调用，从而获得了ucore关于文件的服务，跳转到内核态中文件系统的相关实现。 接下来的控制交给了虚拟文件系统，包括了file接口，dir接口，inode接口，fs接口，外设接口，这个屏蔽了底层具体文件系统的差异性，比如，一个write函数会调用sys_write，接下来会访问sysfile_write、file_write、vop_write（面向用户的文件转换成面向文件系统的inode），这样转变成对inode的写操作，进一步转换成具体文件系统的inode的操作，即到了SimpleFS文件系统的实现。 在SimpleFS文件系统中，有sfs的inode实现和sfs的外设访问接口，调用sfs_write -&gt; sfs_wbuf，数据内容就被写到了设备中。 通过上述的外设访问接口实现了对文件系统IO设备接口的访问，这个也是在硬盘上建立的抽象，在上层发起sfs_wbuf操作之后，把这个操作转换成针对devices的操作，有面向串口的、面向disk的、面向屏幕的，甚至面向NULL的。这层IO设备接口是抽象的接口，可以包含很多种类，比如，最终disk0会访问一个驱动，这个驱动是硬盘驱动，完成实际的硬盘读写。 在进程控制块中扩展了与文件相关的结构，files_struct* filesp，包括了打开文件指针集合。 Simple FS分析关注一个一般文件的读写。采用自下而上的方法，从硬盘到内存。 SimpleFS在文件系统的中间部分，主要内容存储在硬盘上，包括了superblock、root-dir inode、freemap等，SimpleFS被操作时，涉及了file、dir、inode、iobuffer等。 superblock是对SimpleFS整体描述，包括了标识magic_number，空闲了多少块，这些信息需要读入到内存中去，通过sfs_do_mount把文件系统加载到操作系统kernel中。紧接着在内存中建立一个Simple File System的整体框架：sfs_fs，在这个结构里，放入了之前所说的superblock的信息，这个文件系统所在的devices，freemap是这个文件系统中还有哪些空闲的数据块，一个bit表示一个空闲块，用一个hash或链表保存inode的情况。1234567struct sfs_fs&#123; struct sfs_super super; struct device *dev; struct bitmap *freemap; void *sfs_buffer; list_entry_t inode_list;&#125; 在硬盘块上也有root-dir inode，表明了根目录信息，其中有直接索引和间接索引信息，表明了文件块在哪，通过inode的index可以查找数据块的位置。inode包含了两个层面的信息，第一个是在内存中，它有一个sfs_inode，第二个层面是在硬盘上有disk_inode，通过sfs_disk_inode完成进一步的对文件读写， Virtual FS分析VFS在SimpleFS之上，应用程序之下，起到一个承上启下的作用，可以管理其他的设备和文件系统，也提供了统一接口供应用程序调用。在VFS建立与进程的联系，并与底层对接。一个数据结构file，提供了文件信息。通过file可以找到inode，实现对具体文件系统的映射。inode中有对这个inode的引用计数，针对一个inode有多少进程与之关联，换句话说，有多少进程打开了这个文件？1234567891011struct file&#123; enum &#123; FD_NONE, FD_INIT, FD_OPENED, FD_CLOSED &#125; status; bool readable; bool writable; int fd; off_t pos; struct inode *node; atmoic_t open_count;&#125; 从进程角度而言，它需要知道打开了哪些文件，上边的fd代表了执行文件函数之后的返回值，也就是代表了这个文件，应用程序通过这个fd可以获取进一步的文件信息。 也有一个struct中包含了对文件的一些操作，有了这个接口实现了对设备的隔离，方便了应用程序对文件的操作。 IO设备接口分析IO接口在文件系统的底层，与具体文件系统和VFS有接口，也与底层的设备有接口。IO设备数据结构如下，ioctl表示了通常读写之外的操作，12345678struct device&#123; size_t d_blocks; size_t d_blocksize; int (*d_open); int (*d_close); int (*d_io); int (*d_ioctl);&#125; 启动中函数调用过程：kern_init -&gt; fs_init -&gt; dev_init -&gt; dev_init_stdout -&gt; dev_create_inode,stdout_device_init,vfs_add_dev，这样在vfs就可以访问设备了。 执行流程分析在总控函数kern_init内增加了一个fs_init，在fs_init中实现了虚拟文件系统的初始化vfs_init，设备初始化dev_init，simple_fs的初始化sfs_init。 在vfs_init中，建立一个链表，针对dev的list，管理devices的fs；设置信号量对操作进行保护。 在dev_init中，初始化disk和stdin、stdout，分别代表了三类不同的设备。 在sfs_init中，最主要的是完成mount，加载这个文件系统。把sfs和vfs完成连接， 对一个文件，应用程序执行open，返回fd，代表了文件在文件列表中的位置，根据这个fd可以访问更详细的信息。open发出sys_open调用，发出syscall系统调用，操作系统进一步调用sys_open往下处理，把文件名的字符串向下传，分配一个fd_array的一项给他，把文件名实际对应的inode建立起来。vfs_open找到具体的文件系统，调用lookup查找函数，在simple_FS中递归查找一个文件对应的inode是多少，首先查找到目录的inode看目录项的文件名是不是跟要找的一致，如果一致就调用sfs_load_inode，再一层一层返回应用程序。 第二十三讲 I/O子系统23.1 I/O特点IO子系统是与外设交互的部分。三种常见的设备接口类型： 字符设备：以字节为单位顺序访问，每次只能一个字节输入，访问通常由get()，put()执行，使用文件访问接口和语义。 块设备：以均匀的数据块闻单位访问，访问通常使用原始IO或文件系统接口，内存映射文件访问。比如存储设备，磁盘磁带等 网络设备：格式化报文交换，IO命令是send/receive，通过网络接口支持多种网络协议。比如以太网、无线、蓝牙等。 同步与异步IO：用户发出IO请求，送入操作系统内核的设备驱动，设备驱动进行硬件控制数据传送。进行完之后，发出中断，返回进程。 阻塞IO：从发出请求到接收数据，进程需要等待。读数据时，进程进入等待状态，知道完成数据读出，写数据时，进程也进入等待，知道完成数据写入。 非阻塞IO：立即从read或write系统调用返回，返回值为成功传输字节数，read或write的传输字节数可能为0，这种方式可能不成功或者数据量与我们想的不一样。 异步IO：结合阻塞与非阻塞，读数据时，使用指针标记好缓冲区，立即返回，稍后操作系统将填充缓冲区并发出中断通知用户；写数据时，使用指针标记好缓冲区，立即返回。操作系统完成写入后将通知用户。 23.2 I/O结构CPU为了与外界相连，北桥与显卡，内存相连，速度快，南桥与PCI总线等IO设备相连。设备上有IO控制器，提供了CPU和设备的接口，这里就是总线接口，然后有一组寄存器，可以进行数据交互，也可以映射到内存中，对内存的访问就是对IO设备的访问，这就是说的IO地址，它提供了一个内存映射的关系。 从设备到CPU：设备产生中断，在中断控制器进行汇总，CPU进行响应。 CPU和设备一共三种通信方式： 轮询：不用中断控制器，CPU直接访问IO端口或内存映射 设备中断：采用中断方式 DMA：外部设备把数据直接放到内存单元 IO指令是通过IO端口号访问设备寄存器。在CPU执行out、in，对应了读写指令和设备控制。 内存映射IO是把设备的寄存器或存储映射到内存物理地址空间，通过内存load和store指令完成IO操作，由MMU设置映射。 每一个设备有对应的设备控制器，在这之上有驱动、IO子系统（请求转换，设备缓存）、内核。 IO请求生存周期：用户发出IO请求，操作系统中的IO子系统判断是否在缓存中有结果，如果有则直接返回，如果没有，给驱动发出IO请求，驱动转换成设备控制命令，等到硬件设备完成时，产生中断，由中断处理例程响应，保存结果并通知设备驱动层，把结果返回给IO子系统，最终返回给用户。 23.3 I/O数据传输CPU和设备的数据传输有两种，一种是程序控制IO，通过CPU的in/out和load/store传输所有数据，硬件简单但是消耗的CPU时间与传输数据量成正比，适用于简单的小型IO。第二种是DMA，设备控制器直接访问系统总线，控制器直接访问内存，这样的话设备传输数据不影响CPU，但是需要CPU参与设置开始结束过程，适用于高吞吐量的IO。 直接IO寻址读取磁盘数据：产生磁盘读取请求，转到设备驱动在内核里执行，转换成对磁盘控制器的操作，磁盘开始读取数据，初始化DMA传送，磁盘控制器传送数据到DMA控制器，DMA控制器再把数据传输到指定的内存地址，完成传送后产生中断，CPU判断相应信息。 设备如何通知CPU： 轮询：IO设备在特定状态寄存器中放置了状态和错误信息，操作系统定期检测设备寄存器，简单但是IO操作频繁时开销大延时高。 设备中断：CPU在IO之前设置参数，由IO设备进行处理，处理完之后产生中断，CPU响应中断并调用中断处理例程响应，开销高。在高速设备中，第一次采用中断，之后采用轮询方式，有数据直接处理，直到硬件缓存为空。 中断IO的处理流程：产生IO请求，设备驱动初始化IO请求，IO控制器初始化IO操作，设备进行操作，操作完成或者出错产生中断，CPU每执行一条指令都会检查中断请求，如果有则转到中断处理，分发给中断处理例程，处理完之后CPU恢复被中断的进程的执行。 23.4 磁盘调度读取或写入时，磁头被定位到期望的磁道，并从所期望的柱面和扇区开始，时间最长的是寻道时间，定位到期望的磁道。 平均旋转延迟时间=磁盘旋转一周时间的一半。 磁盘IO传输时间：等待设备可用、等待DMA通道或IO通道可用、寻道时间、旋转延时、数据传输的时间。 数据传输时间 = b/rN，b是传输的比特数，N是磁道上的比特数，r是磁盘的转数。 通过磁盘调度算法优化磁盘访问请求，提高磁盘访问性能，寻道时间是磁盘访问最耗时的部分。 先进先出：按照请求顺序处理，公平对待所有进程，接近随机访问的性能。 最短服务时间优先：选择从磁臂当前位置需要移动最少的IO请求，总是选择最短寻道时间。 扫描算法：磁臂在一个方向上移动，访问所有未完成的请求，直到磁臂到达该方向上最后的磁道，换方向之后再走到头。中间的磁道会更好，但是两边的磁道会访问时间长。 循环扫描算法：限制了仅在一个方向上扫描，当最后一个磁道也被访问过之后，磁臂返回到起点再次扫描。 C-Look：磁臂先到达该方向上最后一个请求的位置，然后立即反转，而不是到磁道的最后点路径。 N-step-SCAN：对付磁头黏着：可能出现磁头停留在某处不动的情况，只对该处的请求作出快速响应，比如进程反复请求对某一磁道的IO操作。将磁盘请求队列分成长度为N的子队列，按FIFO算法依次处理所有子队列，扫描算法处理每个队列。 双队列扫描：只把磁盘IO请求分成两个队列，交替使用扫描算法处理一个队列，新生成的磁盘IO请求放入另一个没有正在被处理的队列中，所有的新请求都被推迟到下一次扫描时处理。平均等待时间会减少。 23.5 磁盘缓存双方访问速度大时，引入的速度匹配中间层。磁盘缓存是磁盘扇区在内存中的缓存区，磁盘缓存的调度算法类似虚拟存储调度算法。磁盘的访问频率远低于虚拟存储中的内存访问频率。 单缓存：设置一个缓冲区，一头是CPU一头是设备，设备开始写时CPU不能操作，CPU开始读时设备不能写，类似生产者消费者问题，只有一个能进行操作，限制了效率。 双缓存：IO设备向缓冲区1里写数据的同时，CPU从缓冲区2中读取数据，完成之后交换。 访问频率置换算法：在一段密集磁盘访问后，LFU算法的引用计数无法反映当前的引用情况。这种算法考虑了磁盘访问的密集特性，对密集引用不做计数，在短周期中使用LRU算法，在长周期中使用LFU。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记二]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[第八讲 虚拟存储概念8.1 虚拟存储的需求背景对存储容量的需求，需要容量更大、速度更快、价格更便宜的非易失性存储器。 8.2 覆盖和交换覆盖：在较小的内存中运行较大的程序，依据程序逻辑结构，将程序划分为若干功能独立的模块，不会同时执行的模块共享同一块内存。必要部分通常是常用功能，常驻内存，可选部分不常用只需要在用到时装入内存。不存在调用关系的部分共享一部分内存。将程序分成多组，每组按照这一组里最大的内存进行分配。开发难度增加，由程序员进行模块划分，确定模块间的覆盖关系；也增加了执行时间，从外存装入覆盖模块。交换：增加正在运行或需要运行的程序的内存，将暂时不运行的程序放到外存。这是以进程为单位的交换技术。只有当内存空间不够或有不够的可能时才换出。交换区是用来存放所有用户进程的所有内存映像的拷贝。程序换入时采用动态地址映射的方法，重定位。 8.3 局部性原理把内存中的信息放到外存中来需要准备工作。只把部分程序放到内存中，从而运行比物理内存大的程序，操作系统自动加载而不需要程序猿干预。实现进程在内外存之间的交换，从而获得更多的空闲内存空间。局部性原理：所谓局部性原理呢是指程序在执行的过程当中在一个较短的时间里，它所执行的指令和指令操作数的地址分别局限于在一定区域里，因为通常情况下我们指令是存在代码段里的，指令所访问的操作数呢通常是存在数据段里的，这两个各是一个地方，那这两个的地方分别局限在一定区域里头。 第一个叫时间局部性，也就是说我一条指令的连续两次执行和一个数据的连续两次访问通常情况下都集中在一段较短的时间里； 空间局部性，我相邻的几条指令访问的相邻的几个数据通常情况下是局限在一个较小的区域里头； 叫分支局部性，一条跳转指令的两次执行很多时候是会跳转到同一个地址的。如果能判断他们局部的地区在哪，就可以充分利用这种局部性，虚拟存储也具有可行性。 8.4 虚拟存储概念将不常用的内存块暂存到外存。装载程序时只需将当前指令所需要的页面加载到内存，指令执行中需要的指令或数据不在内存时处理器通知操作系统将相应的页面调入内存。基本特征： 不连续性：物理内存分配非连续，虚拟地址空间使用非连续； 大用户空间：提供给用户的虚拟内存可以大于实际的物理内存； 部分交换：只对部分虚拟地址空间进行调入和调出。 硬件支持：页式或短时存储的地址转换机制。操作系统：管理内存和外存页面或段的换入换出。 8.5 虚拟页式存储在页式存储管理的基础上增加请求调页和页面置换。当用户程序要装载到内存中时只装入部分页面就启动程序运行，进程在发现运行中需要的代码或数据不在内存中时，发送缺页异常请求，操作系统在处理缺页异常时将外村中相应的页面调入内存，使进程能继续运行。需要一个缺页异常的处理例程。造成的修改：原来以逻辑页号为序号就可以找到物理帧号，有了这个物理页帧号之后，就能转换出相应的物理地址。现在增加一些标志位： 驻留位：它是表示该页面是否在内存当中，如果是1表示在内存当中，此时一定可以找到它的页帧号，可以转换成物理内存单元的地址；如果它是0，表示这一页在外存中这时候就会导致缺页。 修改位：表示这一页在内存当中是否被修改，这必须是驻留位有效的情况下。这一页如果被修改过，若想把这一页淘汰，必须把内存当中修改的内容写回到外存当中。 访问位：表示是否被访问过，用于页面置换算法； 保护位：可读可写可执行等。 在32位x86系统中，有12位的页内偏移，两个10位的二级页表项，物理地址也是32位，其中20位是物理页帧号。这时使用二级页表。页表项的起始地址是CR3，一个页表项四字节，4k为一页，一页里有1024页表项，刚好是10位。地址转换：先是一级页表项里头的页号到以及页表中，作为它的偏移找到相应的页表项。这个页表项里有一个第二级页表项的物理页号，这时再加上第二级的页号，第二级页表项里 以它页号作为偏移找到相应的页表项，这时就是要访问的物理页面的物理帧号，帧号和偏移加在一起得到你的物理地址。变化的是页表项内部的东西：前20位的物理页帧号无变化，后边的标志位有变化。用户态标志U表示是否可以在用户态访问；保留位AVL；WT位写出到缓存还是直接写出到内存，CD缓存是否有效。 8.6 缺页异常在CPU要访问一条指令，load M，去找M对应的表项，如果M无效，抛出异常调用缺页异常服务例程。首先找到对应的一页在外存中的位置，找到了且有空闲页则读进来并修改对应的页表项。如果空闲页没找到，则根据页面替换算法找到被替换的物理页帧，再判断这个物理页帧是否修改过，如果修改过，就写回。修改各种驻留位。重新执行产生缺页的指令。外存管理：在何处保存未被映射的页？外存中有对换区。虚拟页式存储中的外存选择：代码段直接指向可执行文件；动态加载的共享库指向动态库文件；其他段就可以放到对换区中。有效存储访问时间：访存时间*(1-p) + 缺页异常处理时间*缺页率p 第九讲 页面置换算法9.1 页面置换算法的概念出现缺页异常时，调入新页面且内存已满时置换页面。尽可能减少页面调入调出次数。把近期不再访问的页面调出。有些页面必须常驻内存，或是操作系统的关键部分，或是要求响应速度的页面，加上一个锁定位。 局部页面置换：置换页面的选择仅限于当前进程占用的物理页面；最优算法、先进先出、最近最久未使用全局置换算法：选择所有可换出的物理页面 9.2 最优算法、先进先出算法和最近最久未使用算法 最优算法：缺页时计算内存中每个页面的下一次访问时间，选择未来最长时间不被访问的页面。缺页次数最少，但无法实现，无法预知每个页面在下次访问的间隔时间。可以作为置换算法的评测依据。 先进先出算法：选择在内存中驻留时间最长的页面进行置换。维护一个记录所有位于内存中的逻辑页面链表，链表元素按照驻留内存时间排序，链首时间最长。出现缺页时把链首页面进行置换，新加的页面加到链尾。性能差，调出的页面可能是经常访问的，可能出现belady现象。 最近最久未使用算法：选择最长时间没有被引用的页面进行替换，如果某些页面长时间未访问，那在未来可能也不访问。缺页时计算每个逻辑页面上次访问时间。 LRU可能的实现： 页面链表。系统维护一个按最近一次访问时间排序的页面链表，链表首节点是最近刚刚使用过的页面，尾节点是最久未使用的页面。访问内存时，找到相应页面并将其移动到链表之首，缺页时替换尾节点的页面。 活动页面栈，访问时将页号压入栈顶，并将栈内相同页号抽出，缺页时置换栈底页面。开销大！ 9.3 时钟置换算法和最不常用算法 时钟置换算法：对页面访问进行大致统计，过去一段时间访问过就不管它，如果没访问过就按照时间踢出去。先对数据结构做了一些改动，页表项里增加了一个访问位，用来描述在过去一段时间里这个页是否被访问过，把这些页面组织成一个环形链表，定义指针在环形链表上进行周期性的循环，这也是我们这个时钟这个词的。指针指向最先调入的页面。访问页面时在页表项中记录页面访问，缺页时从指针处开始顺序查找未被访问的页面进行置换。 装入页面时访问位初始化为0，访问时页面置为1，缺页时，从指针当前顺序检查环形链表，访问位为0则置换，访问位为1，则访问位置为0，指针移动到下一个页面，直到找到可替换的页面。 改进的Clock算法：减少修改页的缺页处理开销。在页表项中加入修改位，并在访问时进行修改，缺页时，修改页面标志位，跳过有修改的页面。如果访问位和修改位都是0，那就直接替换。访问1修改0的改成访问0修改0，访问1修改1的改成访问0修改1，改修改标志的时候并不写出，由系统执行写出。主要修改时考虑了修改的页面，推迟了被修改页面的替换。 最不常用算法（LFU）：每个页面设置一个访问计数，访问页面时访问次数加一，缺页时置换计数最小的页面。可能有开始常用但是之后不常用的，这时需要定期对计数器进行衰减。LRU关注多久未访问，LFU关注访问次数。 9.4 BELADY现象和局部置换算法比较belady现象是指采用FIFO等算法时，可能出现随着分配的页面增加，缺页次数反而升高的现象。原因是FIFO算法的置换特征与进程访问内存的动态特征矛盾，被他置换出去的页面并不一定是进程近期不会访问的。LRU是没有belady现象的。类似于栈的算法（LRU）一般不会有belady现象。比较： LRU依据页面的最近访问时间排序，动态调整；FIFO依据页面进入内存时间排序，页面进入时间固定不变；CLOCK是折中，页面访问时不动态调整页面在链表中的顺序，缺页时再把它移动到链表末尾。 9.5 工作集置换算法全局置换算法之一：工作集置换算法为进程非配可变数目的物理页面。进程的内存需求时有变化，分配给进程的内存也要在不同阶段变化，全局置换算法需要确定分配给进程的物理页面数量。CPU利用率和并发进程的关系： 随着并发进程增加CPU利用率增加；但是之后随着内存吃紧，利用率下降；进程数少时提高并发进程数，可以提高CPU利用率；并发进程导致了内存访问增加；并发进程的内存访问会降低访存的局部性特征，导致了缺页率上升。 工作集是进程当前使用的逻辑页面集合，表示为二元函数（t, delta），t是当前执行时刻，delta是工作集窗口，代表定长页面访问时间窗口。W(t, delta)是当前时刻t前的delta时间窗口的所有访问页面组成的集合。工作集变化： 进程开始执行时，随着访问新页面逐步建立稳定的工作集；当内存访问的局部性区域位置大致稳定时，工作及大小也逐步稳定；局部性区域改变位置时，工作集快速扩张和收缩过渡到下一个稳定值。 令全局置换算法与工作集变化曲线相拟合。常驻集是进程实际驻留内存的页面集合，工作集是进程在运行中的固有属性，而常驻集是取决于系统分配给进程的物理页面数目和页面置换算法。常驻集如果包含了工作集，缺页率比较小；工作集发生剧烈变动时，缺页较多；进程常驻集达到一定大小之后，缺页率也不会明显下降。 工作集置换算法换出不在工作集中的页面。维护一个访存页面链表，访存时换出不在工作集的页面，更新访存链表，缺页时换入页面，更新访存链表。 工作集的大小是变化的。 相对比较稳定的阶段和快速变化的阶段交替出现。 根据局部性原理，进程会在一段时间内相对稳定在某些页面构成的工作集上。 当局部性区域的位置改变时，工作集大小快速变化。 当工作集窗口滑过这些页面后，工作集又稳定在一个局部性阶段。 工作集精确度与窗口尺寸 ∆ 的选择有关。如果 ∆ 太小，那么它不能表示进程的局部特征；如果 ∆ 为无穷大，那么工作集合是进程执行需要的所有页面的集合。 如果页面正在使用，它就落在工作集中；如果不再使用，它将不出现在相应的工作集中。 工作集是局部性原理的近似表示。 如果能找出一个作业的各个工作集，并求出其页面数最大者，就可估计出该进程所需的物理块数。 利用工作集模型可以进行页面置换。工作集页面置换法的基本思想：找出一个不在工作集中的页面，把它淘汰。 9.6 缺页率置换算法缺页率：缺页次数与内存访问次数的比值，或缺页平均时间间隔的倒数，受到页面置换算法、分配给进程的物理页面数目、页面大小和程序本身的影响。缺页率随着物理页面的增加而降低。通过调节常驻集的大小，使每个进程的缺页率保持在合理范围内，若进程缺页率过高，则增加常驻集以分配更多物理页面，若进程缺页率过低，则减少常驻集以给其他进程分配更多物理页面。方法：访存时设置引用位标志，出现缺页时计算从上次缺页时间到现在时间的时间间隔，如果隔的时间比较长，则置换这段时间被没有被引用的页，认为这段时间的缺页率比较低；如果这段时间大于特定的值，则认为这段时间的缺页率较高，则增加常驻集。进程驻留在内存中的页面是有变化的。与前边的工作集算法的区别主要在于缺页率置换把置换放到缺页中断中完成 9.7 抖动和负载控制抖动是指进程物理页面较少，不能包含工作集，造成大量缺页，频繁置换，使进程运行速度变慢。主要原因是随着驻留内存进程数目不断增加，分配给每个进程的物理页面数量不断减少，缺页率不断上升。因此，操作系统需要在并发数目和缺页率之间达到一个平衡，选择适当的进程数目和进程需要的物理页面数。通过调节并发进程数来进行系统负载均衡。平均缺页间隔时间（MTBF） 是否等于 缺页异常处理时间（PFST）。间隔大于处理时间则处理是可以完成的，比较好。 第十讲 实验三 虚拟内存管理10.1 实验目标：虚存管理有关虚拟内存管理。提供给比实际物理内存空间更大的虚拟内存空间。完成Page Fault异常和FIFO页替换算法。 10.2 回顾历史和了解当下Lab1 完成了保护模式和段机制的建立，完成了中断机制，可以输出字符串。中断描述符表寄存器存了中断门，记录了当产生一个中断时用哪个例程处理这个中断。一旦产生中断，根据它的编号找到IDT，记录了一个offset和一个选择子，这个选择子作为一个索引来查找另外一个表GDT全局描述符表（段表），找到基址，这个基址加上offset形成了中断服务例程的入口地址。Lab2完成物理内存管理，查找物理内存，建立基于连续物理内存空间的动态内存分配与释放算法，完成了页机制的建立。页表的起始地址放在CR3寄存器中，页目录表中每一项是一个页目录项，其中的address指向对应页表的起始地址，对页表项，存放着物理页页帧的起始地址，加上页内偏移形成最终地址。初始化函数在kern_init中，vmm_init。关键数据结构：vma_struct和mm_struct。swap.c和swap.h中有相应说明。 10.3 处理流程、关键数据结构和功能swap_init：如何建立交换分区并完成以页为单位的硬盘读写。vmm_init：分配一定物理页，如何建立模拟访问机制访问特定虚拟页。 10.4 页访问异常产生页访问异常时，调用_alltrap的trap进行处理，调用pgfault_handler，进一步调用do_pgfault，建立一个使用者的虚拟环境，根据缺页异常的地址查找，看是不是硬盘中的一个页，把这一页读到内存中，建立映射关系，这样可以正确访问内存了。重新执行产生缺页异常的指令。 10.5 页换入换出机制应该换出哪个页？在kern/mm/swap.c中有具体说明。建立虚拟页和磁盘扇区的对应关系：用到了swap_entry_t，其中有24bit代表磁盘扇区的编号，虚拟页编号在页表的index中，磁盘扇区的index可以写到页表项（PTE）中，虚拟页和磁盘扇区的对应也可以放到页表项中。 页表项多了一个功能，是虚拟页和磁盘扇区的对应关系，如果present位是0，代表没有映射关系，不存在物理页和虚拟页帧的对应关系，这样就可以代表虚拟页和硬盘扇区的关系。页替换算法：FIFO、Clock等。何时进行页换入换出：主动、被动。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记五]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%BA%94%2F</url>
    <content type="text"><![CDATA[第十七讲 同步互斥背景独立进程：不和其他进程共享资源或状态，具有确定性（输入决定结果）；可重现（能够重现起始条件）；调度顺序不重要。 并发进程：多个进程之间有资源共享；不确定性；不可重现。某些情况下调度的不一致会造成结果的不一致，也可能出现不可重现性。程序错误也可能是间歇性发生的。 进程需要与计算机中的其他进程和设备合作。有几个好处： 共享资源。多个用户使用同一个计算机； 提高速度。IO和计算可以重叠；程序可划分为多个模块放在多个处理器上并行执行； 模块化。将大程序分解成小程序。 并发创建新进程时的标识分配：程序调用fork()创建进程，操作系统需要分配一个新的且唯一的进程ID，在内核中，这个系统调用会执行new_pid = next_pid++。 原子操作是一次不存在任何中断或失败的操作。要么成功要么不执行，不会出现部分执行的情况。操作系统需要利用同步机制在并发执行的同时，保证一些操作是原子操作。 现实生活中的同步问题利用原子操作实现一个锁。 Lock.Acquire() 在锁被释放前一直等待，然后获得锁； 如果两个线程都在等待同一个锁，那如果锁被释放了，只有一个进程能得到锁 Lock.Release() 解锁并唤醒任何等待中的进程。 过程： 进入临界区 操作 退出临界区 进程之间的交互关系：相互感知程度。 相互不感知（完全不了解其他进程）：独立 间接感知（双方与第三方交互）：通过共享合作 直接感知（直接交互，如通信）：通过通信合作 可能会出现如下几种： 互斥：一个进程占用，则其他进程不能使用 死锁：多个进程各自占用部分资源，形成循环等待 饥饿：其他进程轮流占用资源，一个进程一直得不到资源 临界区和禁用硬件中断同步方法临界区是互斥执行的代码，进入区检查进程进入临界区的条件是否成立，进入之前设置相应“正在访问临界区”的标志；退出区清除“正在访问临界区”标志。 临界区访问规则： 空闲则入：没有进程在临界区时任何进程可以进入； 忙则等待：有进程在临界区，则其他进程均不能进入临界区； 有限等待：等待进入临界区的进程不能无线等待； 让权等待：不能进入临界区的进程，需要及时释放CPU； 实现方法： 禁用硬件中断：没有中断和上下文切换，因此没有并发，硬件将中断处理延迟到中断被启用之后，现在计算机体系结构都提供指令来实现禁用中断，进入临界区时禁止所有中断，退出临界区时使能所有中断。这种办法有局限性，关中断之后进程无法停止，也可能导致其他进程处于饥饿状态；临界区可能很长，无法确定相应中断所需的时间。 基于软件的同步方法 软件方法：两个线程，T0和T1，线程可以通过共享一些共有变量来同步行为。 采用共享变量，设置一个共享变量表示允许进入临界区的线程； 设置一个共享变量数组，描述每个变量是否在临界区中，先判断另一个线程的flag是否是1，如果可以进入了，设置自己的flag；可能会同时等待或同时进入； Peterson算法：turn表示该哪个进程进入临界区，flag[]表示进程是否准备好进入临界区。在进入区进程i要设置flag[i]=true，且turn=j，判断（flag[i] &amp;&amp; turn==j），如果j没有申请进入，则i直接进去没问题。如果j也申请了，看谁先向trun里写数据，谁先写谁进入，由总线仲裁决定先后顺序！ N线程时，采用Eisenberg和McGuire算法，采用一个处理循环。 基于软件的方法很复杂，是一个忙等待 高级抽象的同步方法 借用操作系统的支持采用更高级的抽象方法，例如，锁、信号量等，用硬件原语来实现 锁：一个二进制变量（锁定，解锁），Acquire和Release，使用锁控制临界区访问。 原子操作指令：CPU体系结构中一类特殊的指令，把若干操作合成一个原子操作，不会出现部分执行的情况 测试和置位（TS），从内存中读取，测试值是否为1并返回T/F，内存单元置为1。 交换指令：交换内存中的两个值。 使用TS指令实现自旋锁：12345678910class Lock &#123; int value = 0;&#125;Lock::Acquire() &#123; while(test_and_set(value)) ; // spin&#125;Lock::Release() &#123; value = 0;&#125; 用TS指令把value读出来，向里边写入1。 如果锁被释放，那么TS指令读取0并将值设置为1 锁被设置为忙并且需要等待完成 如果锁处于忙状态，那么TS指令读取1并将指令设置为1 不改变锁的状态并且需要循环 无忙等待锁：123456789101112131415class Lock &#123; int value = 0; WaitQueue q;&#125;Lock::Acquire() &#123; while(test_and_set(value))&#123; add this TCP to wait queue schedule(); &#125;&#125;Lock::Release() &#123; value = 0; remove one thread t from q wakeup(t)&#125; 原子操作指令锁的特征： 优点： 适用于单处理器或共享内存的多处理器中任意数量的进程 支持多临界区 缺点： 忙等待的话占用了CPU时间 可能导致饥饿，进程离开临界区时有多个等待进程的话？ 可能死锁，低优先级的进程占用了临界区，但是请求访问临界区的高优先级进程获得了处理器并等待临界区。 第十八讲 信号量与管程信号量多线程的引入导致了资源的竞争，同步是协调多线程对共享数据的访问，在任何时候只能有一个线程执行临界区代码。 信号量是操作系统提供的协调共享资源访问的方法，软件同步是平等线程间的一种同步协商机制。信号量是由OS负责管理的，OS作为管理者，地位高于进程。用信号量表示一类资源，信号量的大小表示资源的可用量。 信号量是一种抽象数据类型，由一个整型变量（共享资源数目）和两个原子操作组成。 P()（荷兰语尝试减少） sem减一 如sem&lt;0，进入等待，否则继续 V()（荷兰语增加） sem加一 如sem&lt;=0，唤醒一个等待进程 信号量是被保护的整型变量，初始化完成后只能通过PV操作修改，是由操作系统保证PV操作是原子操作的。 P操作可能阻塞，V操作不会阻塞。P操作中sem可以等于0，但是如果小于0的话，说明我没有资源了，把这个进程放入等待队列，并且阻塞。退出时执行V操作，如果sem++后还小于0，则说明还有等着的，就把一个进程唤醒开始执行。123456789101112131415161718class Semaphore&#123; int sem; WaitQueue q;&#125;Semaphore::P()&#123; sem --; if(sem&lt;0)&#123; Add this thread t to q; block(p) &#125;&#125;Semaphore::V()&#123; sem++; if(sem&lt;=0)&#123; remove a thread t from q; wakeup(t) &#125;&#125; 它的原子性是操作系统保证的，执行不会被打断。 信号量使用两种：二进制信号量，资源数目是0或1；资源信号量，资源数目为任意非负值。 一种是临界区的互斥访问。每类资源设置一个信号量，对应一个临界区，信号量初值为1，12345mutex = new Semaphore(1)mutex-&gt;P();Critical Sectionmutex-&gt;V() 第一个进程进来之后，mutex是0了，第二个进程再执行到P操作时，mutex变成-1，则会等待。第一个进程执行结束后，执行V操作，-1变成0，这时候唤醒第二个进程。 必须成对使用P()和V()操作。P()保证互斥访问，V()操作保证使用后及时释放。 一种是条件同步，初值设置为0。事件出现时设置为1。这个事件就相当于是一种资源。1condition = new Semaphore(0) 生产者-消费者：一个或多个生产者在生成数据后放在缓冲区总，单个消费者从缓冲区中取出数据，任何时刻只能有一个生产者或消费者可访问缓冲区（互斥关系），也就是缓冲区是一个临界区。缓冲区空时必须等待生产者（条件同步），缓冲区满时生产者必须等待消费者（条件同步）。 三个信号量：二进制信号量mutex描述互斥关系；资源信号量fullBuffer和emptyBuffer代表了条件同步关系。 刚开始时缓冲区都是空的，所以fullBuffers为0，emptyBuffers为n12345class BounderBuffer&#123; mutex = new Semaphore(1); fullBuffers = new Semphore(0); emptyBuffers = new Semphore(n);&#125; mutex实现了对缓冲区的互斥访问，但是只是这样是不够的，先检查是否有空缓冲区，有的话则检查是否有另外的消费者占用缓冲区。1234567891011121314BounderBuffer::Deposit(c)&#123; emptyBuffers-&gt;P(); mutex-&gt;P(); Add c to the buffer mutex-&gt;V(); fullBuffers-&gt;V();//生产者写了之后就释放一个资源&#125;BounderBuffer::Remove(c)&#123; fullBuffers-&gt;P(); mutex-&gt;P(); Remove c from buffer mutex-&gt;V(); emptyBuffers-&gt;V();//消费者用了一个之后释放一个&#125; 管程在管程内部使用了条件变量，管程是一种用于多线程互斥访问共享资源的程序结构，采用了面向对象的方法，简化了线程间的同步控制，在任意时刻最多只有一个线程执行管程代码。正在管程中的线程可临时放弃管程的互斥访问，等待事件出现时恢复。 收集现在要同步的进程之间共享的数据，放到一起处理。在入口加一个互斥访问的锁，任何一个线程到临界区后排队，挨个进入。管理共享数据的并发访问。需要共享资源时对应相应的条件变量，使用管程中的程序。 条件变量是管程内的等待机制，进入管程的线程因资源占用而进入等待，每个条件变量表示一种等待原因，对应一个等待队列。两个操作： Wait()：将自己阻塞到等待队列中，唤醒一个等待者或释放管程的互斥访问。 Signal()：将等待队列中的一个线程唤醒；如果等待队列为空，则相当于空操作。123456789101112131415161718Class Condition&#123; int numWaiting = 0; WaitQueue q;&#125;Condition::Wait(lock)&#123; numWaiting ++; Add this thread t to q; release(); schedule(); require(lock);&#125;Condition::Signal()&#123; if(numWaiting &gt; 0)&#123; Remove a thread t from q; wakeup(t); numWaiting --; &#125;&#125; numWaiting为正表示有线程处于等待状态；把它自己放到等待队列中，释放管程使用权，开始调度。在Signal中，把一个进程从等待队列中拿出来，开始执行，numWaiting减一，等待的线程数目减少。 用信号量解决生产者-消费者问题的话，生产者消费者各对应一个函数，其他地方要使用的话直接调用这两个函数即可。首先放到一个管程里，这是由管程进入的申请和释放，如果没有空的，就在条件变量上等待。123456789101112131415161718192021222324class BoundedBuffer&#123; ... Lock lock; int count = 0; Condition notFull, notEmpty;&#125;BoundedBuffer::Deposit(c)&#123; lock-&gt;Acquire(); while(count == n) notFull.Wait(&amp;lock); Add c to the buffer; count ++; notEmpty.Signal(); lock-&gt;Release();&#125;BoundedBuffer::Remove(c)&#123; lock-&gt;Acquire(); while(count == 0) notEmpty.Wait(&amp;lock); Remove c from buffer; count --; notFull.Signal(); lock-&gt;Release();&#125; 管程可以把PV操作集中在一个函数里。 哲学家就餐问题1234567891011121314151617#define N 5semphore fork[N];void philosopher(int i)&#123; while(TRUE)&#123; think(); if(i%2 == 0)&#123; P(fork[i]); P(fork[(i+1)%N]); &#125; else&#123; P(fork[(i+1)%N]); P(fork[i]); &#125; eat(); V(fork[i]); V(fork[(i+1)%N]); &#125;&#125; 读者-写者问题共享数据的两种使用者：读者只读取数据，不修改；写者读取和修改数据。 有三种情况： 读读允许：同一时刻允许多个读者同时读 读写互斥：没有读者时写者才能写，没有写者时读者才能读 写写互斥：没有其他写者时写者才能写 用信号量描述每个约束。信号量WriteMutex是控制读写操作的互斥，初始化为1.读者计数Rcount是对正在读操作的读者数目，初始化为0。信号量CountMutex控制对读者计数的互斥修改，初始化为1。Writer：123P(WriteMutex); write();V(WriteMutex); Reader:123456789101112P(CountMutex); if(Rcount == 0) P(WriteMutex); ++Rcount;V(CountMutex);read();P(CountMutex); --Rcount; if(Rcount == 0) V(WriteMutex); ++Rcount;V(CountMutex); 管程实现读者-写者问题：1234567Database::Read()&#123; StartRead(); //Wait until no writers; read database; DoneRead(); //checkout - wakeup waiting writers;&#125; 12345Database::Write()&#123; Wait until no reader/writer; write database; checkout - wakeup waiting reader/writer&#125; 状态变量。正在读和正在写只有一个大于等于0123456AR = 0; # of active readerAW = 0; # of active writerWR = 0; # of waiting readerWW = 0; # of waiting writerLock lock;Condition okToRead, okToWrite 12345678910Private Database::StartRead()&#123; lock.Acquire(); while(AW + WW &gt; 0)&#123;//写者优先 WR++; okToRead.wait(&amp;lock); WR--; &#125; AR++; lock.Release()&#125; 1234567Private Database::DoneRead()&#123; lock.Acquire(); AR --; if(AR==0 &amp;&amp; WW&gt;0) //没有读者，写者在等 okToWrite.Signal(); lock.Release();&#125; 12345678910Private Database::StartWrite()&#123; lock.Acquire(); while(AW + AR &gt; 0)&#123;//有正在写的写者或正在读的读者 WW++; okToWrite.wait(&amp;lock); WW--; &#125; AW++; lock.Release()&#125; 123456789Private Database::DoneWrite()&#123; lock.Acquire(); AW --; if(WW&gt;0) //写者优先 okToWrite.Signal(); else if(WR &gt; 0) okToRead.broadcase(); lock.Release();&#125; 第十九讲 实验七 同步互斥总体介绍底层支撑定时器：进程睡眠，进入等待状态（do_sleep）。可以添加一个timer。 时钟中断时会遍历timer链表，看哪个进程的定时器到期了。12345typedef struct&#123; unsigned int expires; struct proc_struct* proc; list_entry_t timer_link;&#125; timer_t; 屏蔽中断完成了互斥的保护，使得这个进程不会被调度或打断。有一个Eflag寄存器，有一个bit叫做Interrupt Enable Flag，这个flag如果置成1，当前允许中断，置成0表示不允许中断。两个指令CLI和STI分别屏蔽中断和使能中断。uCore中使用local_intr_save和local_intr_restore封装。 等待项和等待队列：123456789typedef struct &#123; struct proc_struct* proc; uint32_t wakeup_flags;//等待的原因 wait_queue_t* wait_queue;//等待项在哪个队列中 list_entry_t wait_link;&#125; wait_ttypedef struct &#123; list_entry_t wait_head;&#125; wait_queue_t; 信号量设计实现123456789101112131415161718class Semaphore&#123; int sem; WaitQueue q;&#125;Semaphore::P()&#123; sem --; if(sem&lt;0)&#123; Add this thread t to q; block(t); &#125;&#125;Semaphore::V()&#123; sem++; if(sem&lt;=0)&#123; Remove a thread t from q; wakeup(t); &#125;&#125; 管程和条件变量设计实现123456typedef struct monitor&#123; semaphore_t mutex; semaphore_t next; int next_count; condvar_t *cv;&#125; 哲学家就餐问题第十九讲 实验七 同步互斥第二十讲 死锁和进程通信 死锁概念由于竞争资源或通信关系，两个或更多线程在执行中弧线，永远相互等待只能由其他进程引发的事件。 进程访问资源的流程：资源类型有R1、R2、R3等，每类资源Ri有Wi个实例，进程访问资源时先申请空闲的资源，再占用，最后释放资源。 可重用资源是不能被删除且在任何时刻都只能有一个进程使用，一个进程释放之后其他进程就可以使用了，比如CPU，文件、数据库等，可以被多个进程交替使用。可能出现死锁。 消耗资源：一个进程创建，并有其他进程使用，比如消息等，可能出现死锁。 资源分配图描述了资源和进程之间的分配和占用关系，是一个有向图。一类顶点是系统中的进程，另一类顶点是资源；一类有向边是资源请求边，另一类有向边是资源分配边。如果有循环等待的话，就会出现死锁。但是有循环也可能不会出现死锁。 出现死锁的条件： 互斥：任何时刻只能由一个进程使用一个资源实例，如果资源是共享的不会互斥的则不会死锁； 持有并等待：进程保持至少一个资源并正在等待获取其他进程持有的资源； 非抢占：资源只在进程使用后自愿放弃，不可以强行剥夺； 循环等待：存在等待进程集合，0等1，1等2，。。。n-1等n，n等0，类似这样。 死锁处理方法 死锁预防：确保系统永远不会进入死锁状态，四个必要条件的任何一个去掉都可以避免死锁，但是这样的话资源利用率低； 死锁避免：在使用前进行判断，只允许不会出现死锁的进程请求资源； 死锁检测和恢复：在检测到死锁后，进行恢复； 通常由应用进程来处理死锁，操作系统忽略死锁的存在。 死锁预防：采用某种机制，限制并发进程对资源的请求，使系统不满足死锁的必要条件。 比如可以把互斥的共享资源封装成可以同时访问的，比如打印机，加上缓冲区，在打印机内部协调先后； 持有并等待，进程请求资源时，不能占用其他任何资源，想申请资源时，必须把全部资源都申请到，也可以在进程开始执行时一次请求所有需要的资源，资源利用效率低； 非抢占：如进程请求不能立即分配的资源，则立即释放自己已占有的资源，只有能同时获取到所有需要资源时，才执行分配操作； 循环等待：对资源排序，进程需要按照顺序请求资源，可能先申请的资源后续才用到； 死锁避免：利用额外的先验信息，在分配资源时判断是否会出现死锁，如果可能会出现死锁，则不分配。要求进程声明资源需求的最大数目，限定提供与分配的资源数目，确保满足进程的最大需求，且动态检查资源分配状态，确保不会出现死锁。 进程请求资源时，系统判断是否处于安全状态。 针对所有已占用进程，存在安全序列； 序列&lt;P1,P2,P3…,Pn&gt;是安全的，则Pi要求的资源&lt;=当前可用资源+所有Pj持有资源（j&lt;\i），如果Pi的资源不能立即分配，则要等待。 银行家算法判断并保证系统处于安全状态。 n=线程数量，m=资源类型数量； Max（总需求量）：n*m矩阵，线程Ti最多请求类型Rj的资源Max[i,j]个实例 Available(剩余空闲量)：长度为m的向量，当前有Available[i]个类型Ri的资源实例可用 Allocation(已分配量)：n*m矩阵，线程Ti当前分配了Allocation[i,j]个Rj的实例 Need(未来需求量)：n*m矩阵，线程Ti未来需要Need[i,j]个Rj资源实例； Need[i,j]=Max[i,j]-Allcation[i,j] 安全状态判断： Work 和 Finish 分别是长度为 m 和 n 的向量初始化： Work = Available，Finish = false for i = 1,2,…,n 寻找线程 Ti ，Finish[i] = false，Need[i] &lt;= Work，找到 Need 比 Work 小的线程 i ，如果没有找到符合条件的 Ti ，转4 Work = Work + Allocation[i] ，Finish[i] = true，线程i的资源需求量小于当前系统剩余空闲资源，所以配置给他再回收。转2 如果所有线程Ti满足Finish[i]=true，则系统处于安全状态。 这种迭代循环到最后，则是安全的 初始化：Requesti：线程Ti的资源请求向量，Requesti[j]：线程Ti请求资源Rj的实例 循环： 如果Requesti &lt; Need[i]，转到2，否则拒绝资源申请，因为县城已经超过了其最大要求； 如果Requesti &lt;= Available，转到3，否则Ti必须等待，因为资源部可用； 通过安全状态判断是否分配资源给Ti，生成一个需要判断状态是否安全的资源分配环境： Available=Available-Requesti Allocation[i] = Allocation[i]+Requesti Need[i] = Need[i]-Requesti 死锁检测允许系统进入死锁状态，并维护一个资源分配图，周期性调用死锁检测算法，如果有死锁，就调用死锁处理。 Available：长度为m的向量，表示每种类型可用资源的数量； Allocation：一个n*m矩阵，表示当前分配给各个进程每种类型资源的数量，当前Pi拥有资源Rj的Allocation[i,j]个实例。 死锁监测算法： Work是系统中的空闲资源量，Finish时线程是否结束。Work = Available，Allocation[i] &gt; 0时，Finish[i] = false；否哦则Finish[i] = true； 寻找线程Ti满足Finish[i] = false且Requesti &lt;= Work，线程没结束且能满足线程资源请求量。 Work = Work + Allocation[i]，Finish[i] = true，转到2。 如果某个Finish[i] = false，则系统会死锁。 死锁检测的使用： 多长时间检测一次 多少进程需要回滚 难以分辨造成死锁的关键进程 死锁恢复： 终止所有的死锁进程 一次终止一个进程，看还会不会死锁 终止进程的顺序应该是 进程优先级 进程已运行的时间和还需运行的时间 进程已占用资源 进程完成所需要的资源 进程终止数目 进程是交互还是批处理方法 选择被抢占的资源 进程回退 进程通信（IPC）概念IPC提供两个基本操作： 发送：send(message) 接收：recv(message) 流程： 建立通信链路 通过send/recv交换 通信方式： 间接通信：在通信进程和内核之间建立联系，一个进程把信息发送到内核的消息队列中，另一个进程读取，接受发送的时间可以不一样。通过操作系统维护的消息队列通信，每个消息队列有一个唯一的标识，只有共享了相同消息队列的进程，才能够通信。 链接可以单向，也可以双向 每对进程可以共享多个消息队列 创建消息队列、通过消息队列收发消息、撤销消息队列 send(A, message)、recv(A, message)，A是消息队列 阻塞发送是发送方发送后进入等待，直到成功发送 阻塞接受是接收后进入等待，直到成功接受 非阻塞发送是发送方发送后返回 非阻塞接受是没有消息发送时，接收者在请求接受消息后，接受不到消息。 直接通信：两个进程同时存在，发方向共享信道里发送，收方读取。进程必须正确的命名接收方。 一般自动建立链路 一条链路对应一对通信进程 每对进程之间只有一个链路存在 链路可能单向，也可以双向 进程发送的消息在链路上可能有三种缓冲方式： 0容量：发送方必须等待接收方 有限容量：通信链路缓冲队列满了，发送方必须等待 无限容量：发送方不需等待 信号和管道信号是进程间软件中断通知和处理机制，如果执行过程中有意外需要处理，则需要信号，Ctrl-C可以使进程停止，这个处理是通过信号实现。如SIGKILL，SIGSTOP等。 信号的接收处理： 捕获：执行进程指定的信号处理函数被调用 忽略：执行操作系统的缺省处理，例如进程终止和挂起等 屏蔽：禁止进程接受和处理信号，可能是暂时的。 传送的信息量小，只有一个信号类型，只能做快速的响应知己。 首先进程启动时注册相应的信号处理例程到操作系统； 其他程序发出信号时，操作系统分发信号到进程的信号处理函数； 进程执行信号处理函数。 管道：进程间基于内存文件的通信机制，内存中建立一个临时文件，子进程从父进程继承文件描述符，缺省文件描述符：0 1 2 进程不知道另一端，可能时从键盘、文件等。 系统调用： 读管道read(fd,buffer,nbytes) 写管道write(fd,buffer,nbytes) 创建管道pipe(rgfd)，rgfd时两个文件描述符组成的数组，rgfd[0]是读文件描述符，rgfd[1]是写文件描述符。利用继承的关系在两个进城之间继承文件描述符。 消息队列和共享内存消息队列是操作系统维护的字节序列为基本单位的间接通信机制，若干个进程可以发送到消息队列中，每个消息是一个字节序列，相同标识的消息组成先进先出顺序的队列。系统调用如下： msgget(key,flags)：获取消息队列标识 msgsnd(QID,buf,size,flags)：发送消息 msgrcv(QID,buf,size,flags)：接收消息 消息队列独立于进程，进程结束了之后消息队列可以继续存在，实现两个不同生命周期的进程之间的通信。 共享内存是把同一个物理内存区域同时映射到多个进程的内存地址空间的通信机制。每个进程都有私有内存地址空间，需要明确设置共享内存段。同一进程的线程总是共享相同的内存地址空间。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验五]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%BA%94%2F</url>
    <content type="text"><![CDATA[实验五：用户进程管理实验目的了解第一个用户进程创建过程了解系统调用框架的实现机制了解ucore如何实现系统调用sys_fork/sys_exec/sys_exit/sys_wait来进行进程管理 实验内容实验4的线程运行都在内核态。实验5创建了用户进程，让用户进程在用户态执行，且在需要ucore支持时，可通过系统调用来让ucore提供服务。为此需要构造出第一个用户进程，并通过系统调用sys_fork/sys_exec/sys_exit/sys_wait来支持运行不同的应用程序，完成对用户进程的执行过程的基本管理。 预备知识实验执行流程概述提供各种操作系统功能的内核线程只能在CPU核心态运行是操作系统自身的要求，操作系统就要呆在核心态，才能管理整个计算机系统。ucore提供了用户态进程的创建和执行机制，给应用程序执行提供一个用户态运行环境。显然，由于进程的执行空间扩展到了用户态空间，且出现了创建子进程执行应用程序等与lab4有较大不同的地方，所以具体实现的不同主要集中在进程管理和内存管理部分。 首先，我们从ucore的初始化部分来看，kern_init中调用的物理内存初始化，进程管理初始化等都有一定的变化。在内存管理部分，与lab4最大的区别就是增加用户态虚拟内存的管理。 首先为了管理用户态的虚拟内存，需要对页表的内容进行扩展，能够把部分物理内存映射为用户态虚拟内存。如果某进程执行过程中，CPU在用户态下执行（在CS段寄存器最低两位包含有一个2位的优先级域，如果为0，表示CPU运行在特权态；如果为3，表示CPU运行在用户态。），则可以访问本进程页表描述的用户态虚拟内存，但由于权限不够，不能访问内核态虚拟内存。 另一方面，在用户态内存空间和内核态内核空间之间需要拷贝数据，让CPU处在内核态才能完成对用户空间的读或写，为此需要设计专门的拷贝函数（copy_from_user和copy_to_user）完成。但反之则会导致违反CPU的权限管理，导致内存访问异常。 在进程管理方面，主要涉及到的是进程控制块中与内存管理相关的部分，包括建立进程的页表和维护进程可访问空间（可能还没有建立虚实映射关系）的信息； 加载一个ELF格式的程序到进程控制块管理的内存中的方法； 在进程复制（fork）过程中，把父进程的内存空间拷贝到子进程内存空间的技术； 另外一部分与用户态进程生命周期管理相关，包括让进程放弃CPU而睡眠等待某事件、让父进程等待子进程结束、一个进程杀死另一个进程、给进程发消息、建立进程的血缘关系链表。 在用户进程管理中，首先，构造出第一个进程idle_proc，作为所有后续进程的祖先；然后，在proc_init函数中，对idle_proc进行进一步初始化，通过alloc把当前ucore的执行环境转变成idle内核线程的执行现场；然后调用kernl_thread来创建第二个内核线程init_main，而init_main内核线程有创建了user_main内核线程。到此，内核线程创建完毕。1234567891011121314151617181920212223242526272829303132333435// proc_init - set up the first kernel thread idleproc &quot;idle&quot; by itself and// - create the second kernel thread init_mainvoidproc_init(void) &#123; int i; list_init(&amp;proc_list); for (i = 0; i &lt; HASH_LIST_SIZE; i ++) &#123; list_init(hash_list + i); &#125; if ((idleproc = alloc_proc()) == NULL) &#123; panic(&quot;cannot alloc idleproc.\n&quot;); &#125; idleproc-&gt;pid = 0; idleproc-&gt;state = PROC_RUNNABLE; idleproc-&gt;kstack = (uintptr_t)bootstack; idleproc-&gt;need_resched = 1; set_proc_name(idleproc, &quot;idle&quot;); nr_process ++; current = idleproc; int pid = kernel_thread(init_main, NULL, 0); if (pid &lt;= 0) &#123; panic(&quot;create init_main failed.\n&quot;); &#125; initproc = find_proc(pid); set_proc_name(initproc, &quot;init&quot;); assert(idleproc != NULL &amp;&amp; idleproc-&gt;pid == 0); assert(initproc != NULL &amp;&amp; initproc-&gt;pid == 1);&#125; 接下来是用户进程的创建过程。第一步实际上是通过user_main函数调用kernel_tread创建子进程，通过kernel_execve调用来把某一具体程序的执行内容放入内存。 具体的放置方式是根据ld在此文件上的地址分配为基本原则，把程序的不同部分放到某进程的用户空间中，从而通过此进程来完成程序描述的任务。一旦执行了这一程序对应的进程，就会从内核态切换到用户态继续执行。 以此类推： CPU在用户空间执行的用户进程，其地址空间不会被其他用户的进程影响，但由于系统调用（用户进程直接获得操作系统服务的唯一通道）、外设中断和异常中断的会随时产生，从而间接推动了用户进程实现用户态到到内核态的切换工作。当进程执行结束后，需回收进程占用和没消耗完毕的设备整个过程，且为新的创建进程请求提供服务。 创建用户进程应用程序的组成和编译lab5中新增了一个文件夹user，其中是用于本实验的用户程序。如hello.c123456789#include &lt;stdio.h&gt;#include &lt;ulib.h&gt;int main(void) &#123; cprintf(&quot;Hello world!!.\n&quot;); cprintf(&quot;I am process %d.\n&quot;, getpid()); cprintf(&quot;hello pass.\n&quot;); return 0;&#125; 按照手册，注释掉Makefile的第六行，编译，（部分）输出如下：1234567891011121314151617181920212223gcc -Iuser/ -fno-builtin -Wall -ggdb -m32 -gstabs -nostdinc -fno-stack-protector -Ilibs/ -Iuser/include/ -Iuser/libs/ -c user/pgdir.c -o obj/user/pgdir.old -m elf_i386 -nostdlib -T tools/user.ld -o obj/__user_pgdir.out obj/user/libs/panic.o obj/user/libs/syscall.o obj/user/libs/ulib.o obj/user/libs/initcode.o obj/user/libs/stdio.o obj/user/libs/umain.o obj/libs/string.o obj/libs/printfmt.o obj/libs/hash.o obj/libs/rand.o obj/user/pgdir.o+ ld bin/kernelld -m elf_i386 -nostdlib -T tools/kernel.ld -o bin/kernel obj/kern/init/entry.o obj/kern/init/init.o obj/kern/libs/stdio.o obj/kern/libs/readline.o obj/kern/debug/panic.o obj/kern/debug/kdebug.o obj/kern/debug/kmonitor.o obj/kern/driver/ide.o obj/kern/driver/clock.o obj/kern/driver/console.o obj/kern/driver/picirq.o obj/kern/driver/intr.o obj/kern/trap/trap.o obj/kern/trap/vectors.o obj/kern/trap/trapentry.o obj/kern/mm/pmm.o obj/kern/mm/swap_fifo.o obj/kern/mm/vmm.o obj/kern/mm/kmalloc.o obj/kern/mm/swap.o obj/kern/mm/default_pmm.o obj/kern/fs/swapfs.o obj/kern/process/entry.o obj/kern/process/switch.o obj/kern/process/proc.o obj/kern/schedule/sched.o obj/kern/syscall/syscall.o obj/libs/string.o obj/libs/printfmt.o obj/libs/hash.o obj/libs/rand.o -b binary obj/__user_badarg.out obj/__user_forktree.out obj/__user_faultread.out obj/__user_divzero.out obj/__user_exit.out obj/__user_hello.out obj/__user_waitkill.out obj/__user_softint.out obj/__user_spin.out obj/__user_yield.out obj/__user_badsegment.out obj/__user_testbss.out obj/__user_faultreadkernel.out obj/__user_forktest.out obj/__user_pgdir.out 从中可以看出，hello应用程序不仅仅是hello.c，还包含了支持hello应用程序的用户态库： user/libs/initcode.S：所有应用程序的起始用户态执行地址“_start”，调整了EBP和ESP后，调用umain函数。 user/libs/umain.c：实现了umain函数，这是所有应用程序执行的第一个C函数，它将调用应用程序的main函数，并在main函数结束后调用exit函数，而exit函数最终将调用sys_exit系统调用，让操作系统回收进程资源。 user/libs/ulib.[ch]：实现了最小的C函数库，除了一些与系统调用无关的函数，其他函数是对访问系统调用的包装。 user/libs/syscall.[ch]：用户层发出系统调用的具体实现。 user/libs/stdio.c：实现cprintf函数，通过系统调用sys_putc来完成字符输出。 user/libs/panic.c：实现__panic/__warn函数，通过系统调用sys_exit完成用户进程退出。 在make的最后一步执行了一个ld命令，把hello应用程序的执行码obj/__user_hello.out连接在了ucore kernel的末尾。且ld命令会在kernel中会把__user_hello.out的位置和大小记录在全局变量_binary_obj___user_hello_out_start和_binary_obj___user_hello_out_size中，这样这个hello用户程序就能够和ucore内核一起被 bootloader加载到内存里中，并且通过这两个全局变量定位hello用户程序执行码的起始位置和大小。 用户进程的虚拟地址空间在tools/user.ld描述了用户程序的用户虚拟空间的执行入口虚拟地址：123SECTIONS &#123; /* Load programs at this address: &quot;.&quot; means the current address */ . = 0x800020; 在tools/kernel.ld描述了操作系统的内核虚拟空间的起始入口虚拟地址：123SECTIONS &#123; /* Load the kernel at this address: &quot;.&quot; means the current address */ . = 0xC0100000; 这样ucore把用户进程的虚拟地址空间分了两块: 一块与内核线程一样，是所有用户进程都共享的内核虚拟地址空间，映射到同样的物理内存空间中，这样在物理内存中只需放置一份内核代码，使得用户进程从用户态进入核心态时，内核代码可以统一应对不同的内核程序； 另外一块是用户虚拟地址空间，虽然虚拟地址范围一样，但映射到不同且没有交集的物理内存空间中。这样当ucore把用户进程的执行代码（即应用程序的执行代码）和数据（即应用程序的全局变量等）放到用户虚拟地址空间中时，确保了各个进程不会“非法”访问到其他进程的物理内存空间。 这样ucore给一个用户进程具体设定的虚拟内存空间（kern/mm/memlayout.h）如下所示：12345678910111213141516171819202122232425262728293031323334353637383940 Virtual memory map: Permissions kernel/user 4G ------------------&gt; +---------------------------------+ | | | Empty Memory (*) | | | +---------------------------------+ 0xFB000000 | Cur. Page Table (Kern, RW) | RW/-- PTSIZE VPT -----------------&gt; +---------------------------------+ 0xFAC00000 | Invalid Memory (*) | --/-- KERNTOP -------------&gt; +---------------------------------+ 0xF8000000 | | | Remapped Physical Memory | RW/-- KMEMSIZE | | KERNBASE ------------&gt; +---------------------------------+ 0xC0000000 | Invalid Memory (*) | --/-- USERTOP -------------&gt; +---------------------------------+ 0xB0000000 | User stack | +---------------------------------+ | | : : | ~~~~~~~~~~~~~~~~ | | ~~~~~~~~~~~~~~~~ | : : | | ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ | User Program &amp; Heap | UTEXT ---------------&gt; +---------------------------------+ 0x00800000 | Invalid Memory (*) | --/-- | - - - - - - - - - - - - - - - | | User STAB Data (optional) | USERBASE, USTAB------&gt; +---------------------------------+ 0x00200000 | Invalid Memory (*) | --/-- 0 -------------------&gt; +---------------------------------+ 0x00000000(*) Note: The kernel ensures that &quot;Invalid Memory&quot; is *never* mapped. &quot;Empty Memory&quot; is normally unmapped, but user programs may map pages there if desired.*/ 创建并执行用户进程在确定了用户进程的执行代码和数据，以及用户进程的虚拟空间布局后，我们可以来创建用户进程了。在本实验中第一个用户进程是由第二个内核线程initproc通过把hello应用程序执行码覆盖到initproc的用户虚拟内存空间来创建的，相关代码如下所示：1234567891011121314151617181920212223242526272829303132333435 // kernel_execve - do SYS_exec syscall to exec a user program called by user_main kernel_thread static int kernel_execve(const char *name, unsigned char *binary, size_t size) &#123; int ret, len = strlen(name); asm volatile ( &quot;int %1;&quot; : &quot;=a&quot; (ret) : &quot;i&quot; (T_SYSCALL), &quot;0&quot; (SYS_exec), &quot;d&quot; (name), &quot;c&quot; (len), &quot;b&quot; (binary), &quot;D&quot; (size) : &quot;memory&quot;); return ret; &#125; #define __KERNEL_EXECVE(name, binary, size) (&#123; \ cprintf(&quot;kernel_execve: pid = %d, name = \&quot;%s\&quot;.\n&quot;, \ current-&gt;pid, name); \ kernel_execve(name, binary, (size_t)(size)); \ &#125;) #define KERNEL_EXECVE(x) (&#123; \ extern unsigned char _binary_obj___user_##x##_out_start[], \ _binary_obj___user_##x##_out_size[]; \ __KERNEL_EXECVE(#x, _binary_obj___user_##x##_out_start, \ _binary_obj___user_##x##_out_size); \ &#125;)……// init_main - the second kernel thread used to create kswapd_main &amp; user_main kernel threadsstatic int init_main(void *arg) &#123; #ifdef TEST KERNEL_EXECVE2(TEST, TESTSTART, TESTSIZE); #else KERNEL_EXECVE(hello); #endif panic(&quot;kernel_execve failed.\n&quot;); return 0;&#125; ##的作用是参数的连接，把“exit”这个字符串连接到这个宏中的x对应位置#的作用是使一个东西字符串化 Initproc的执行主体是init_main函数，这个函数在缺省情况下是执行宏KERNEL_EXECVE(hello)，而这个宏最终是调用kernel_execve函数来调用SYS_exec系统调用，由于ld在链接hello应用程序执行码时定义了两全局变量：12_binary_obj___user_hello_out_start：hello执行码的起始位置_binary_obj___user_hello_out_size中：hello执行码的大小 kernel_execve把这两个变量作为SYS_exec系统调用的参数，让ucore来创建此用户进程。当ucore收到此系统调用后，将依次调用如下函数：12vector128(vectors.S) --&gt;__alltraps(trapentry.S) --&gt; trap(trap.c) --&gt; trap_dispatch(trap.c) --&gt; syscall(syscall.c) --&gt; sys_exec（syscall.c）--&gt; do_execve(proc.c) 最终通过do_execve函数来完成用户进程的创建工作。此函数的主要工作流程如下： 为加载新的执行码做好用户态内存空间清空准备。如果mm不为NULL，则设置页表为内核空间页表，且进一步判断mm的引用计数减1后是否为0，如果为0，则表明没有进程再需要此进程所占用的内存空间，为此将根据mm中的记录，释放进程所占用户空间内存和进程页表本身所占空间。最后把当前进程的mm内存管理指针为空。由于此处的initproc是内核线程，所以mm为NULL，整个处理都不会做。 加载应用程序执行码到当前进程的新创建的用户态虚拟空间中。这里涉及到读ELF格式的文件，申请内存空间，建立用户态虚存空间，加载应用程序执行码等。load_icode函数完成了整个复杂的工作。 load_icode函数的主要工作就是给用户进程建立一个能够让用户进程正常运行的用户环境。此函数有一百多行，完成了如下重要工作： 调用mm_create函数来申请进程的内存管理数据结构mm所需内存空间，并对mm进行初始化； 调用setup_pgdir来申请一个页目录表所需的一个页大小的内存空间，并把描述ucore内核虚空间映射的内核页表（boot_pgdir所指）的内容拷贝到此新目录表中，最后让mm-&gt;pgdir指向此页目录表，这就是进程新的页目录表了，且能够正确映射内核虚空间； 根据应用程序执行码的起始位置来解析此ELF格式的执行程序，并调用mm_map函数根据ELF格式的执行程序说明的各个段（代码段、数据段、BSS段等）的起始位置和大小建立对应的vma结构，并把vma插入到mm结构中，从而表明了用户进程的合法用户态虚拟地址空间； 调用根据执行程序各个段的大小分配物理内存空间，并根据执行程序各个段的起始位置确定虚拟地址，并在页表中建立好物理地址和虚拟地址的映射关系，然后把执行程序各个段的内容拷贝到相应的内核虚拟地址中，至此应用程序执行码和数据已经根据编译时设定地址放置到虚拟内存中了； 需要给用户进程设置用户栈，为此调用mm_mmap函数建立用户栈的vma结构，明确用户栈的位置在用户虚空间的顶端，大小为256个页，即1MB，并分配一定数量的物理内存且建立好栈的虚地址物理地址映射关系； 至此,进程内的内存管理vma和mm数据结构已经建立完成，于是把mm-&gt;pgdir赋值到cr3寄存器中，即更新了用户进程的虚拟内存空间，此时的initproc已经被hello的代码和数据覆盖，成为了第一个用户进程，但此时这个用户进程的执行现场还没建立好； 先清空进程的中断帧，再重新设置进程的中断帧，使得在执行中断返回指令“iret”后，能够让CPU转到用户态特权级，并回到用户态内存空间，使用用户态的代码段、数据段和堆栈，且能够跳转到用户进程的第一条指令执行，并确保在用户态能够响应中断； 至此，用户进程的用户环境已经搭建完毕。此时initproc将按产生系统调用的函数调用路径原路返回，执行中断返回指令“iret”（位于trapentry.S的最后一句）后，将切换到用户进程hello的第一条语句位置_start处（位于user/libs/initcode.S的第三句）开始执行。 进程退出和等待进程ucore分了两步来完成进程退出工作，首先，进程本身完成大部分资源的占用内存回收工作，然后父进程完成剩余资源占用内存的回收工作。为何不让进程本身完成所有的资源回收工作呢？这是因为进程要执行回收操作，就表明此进程还存在，还在执行指令，这就需要内核栈的空间不能释放，且表示进程存在的进程控制块不能释放。所以需要父进程来帮忙释放子进程无法完成的这两个资源回收工作。 为此在用户态的函数库中提供了exit函数，此函数最终访问sys_exit系统调用接口让操作系统来帮助当前进程执行退出过程中的部分资源回收。 首先，exit函数会把一个退出码error_code传递给ucore，ucore通过执行内核函数do_exit来完成对当前进程的退出处理，主要工作是回收当前进程所占的大部分内存资源，并通知父进程完成最后的回收工作，具体流程如下： 如果current-&gt;mm != NULL，表示是用户进程，则开始回收此用户进程所占用的用户态虚拟内存空间； 首先执行“lcr3(boot_cr3)”，切换到内核态的页表上，这样当前用户进程目前只能在内核虚拟地址空间执行了，这是为了确保后续释放用户态内存和进程页表的工作能够正常执行； 如果当前进程控制块的成员变量mm的成员变量mm_count减1后为0（表明这个mm没有再被其他进程共享，可以彻底释放进程所占的用户虚拟空间了。），则开始回收用户进程所占的内存资源： 调用exit_mmap函数释放current-&gt;mm-&gt;vma链表中每个vma描述的进程合法空间中实际分配的内存，然后把对应的页表项内容清空，最后还把页表所占用的空间释放并把对应的页目录表项清空； 调用put_pgdir函数释放当前进程的页目录所占的内存； 调用mm_destroy函数释放mm中的vma所占内存，最后释放mm所占内存； 此时设置current-&gt;mm为NULL，表示与当前进程相关的用户虚拟内存空间和对应的内存管理成员变量所占的内核虚拟内存空间已经回收完毕； 这时，设置当前进程的执行状态current-&gt;state=PROC_ZOMBIE，当前进程的退出码current-&gt;exit_code=error_code。此时当前进程已经不能被调度了，需要此进程的父进程来做最后的回收工作（即回收描述此进程的内核栈和进程控制块）； 如果当前进程的父进程current-&gt;parent处于等待子进程状态：current-&gt;parent-&gt;wait_state==WT_CHILD，则唤醒父进程（即执行“wakup_proc(current-&gt;parent)”），让父进程帮助自己完成最后的资源回收； 如果当前进程还有子进程，则需要把这些子进程的父进程指针设置为内核线程initproc，且各个子进程指针需要插入到initproc的子进程链表中。如果某个子进程的执行状态是PROC_ZOMBIE，则需要唤醒initproc来完成对此子进程的最后回收工作。 执行schedule()函数，选择新的进程执行。 那么父进程如何完成对子进程的最后回收工作呢？这要求父进程要执行wait用户函数或wait_pid用户函数，这两个函数的区别是，wait函数等待任意子进程的结束通知，而wait_pid函数等待进程id号为pid的子进程结束通知。这两个函数最终访问sys_wait系统调用接口让ucore来完成对子进程的最后回收工作，即回收子进程的内核栈和进程控制块所占内存空间，具体流程如下： 如果pid!=0，表示只找一个进程id号为pid的退出状态的子进程，否则找任意一个处于退出状态的子进程； 如果此子进程的执行状态不为PROC_ZOMBIE，表明此子进程还没有退出，则当前进程只好设置自己的执行状态为PROC_SLEEPING，睡眠原因为WT_CHILD（即等待子进程退出），调用schedule()函数选择新的进程执行，自己睡眠等待，如果被唤醒，则重复跳回步骤1处执行； 如果此子进程的执行状态为PROC_ZOMBIE，表明此子进程处于退出状态，需要当前进程（即子进程的父进程）完成对子进程的最终回收工作，即首先把子进程控制块从两个进程队列proc_list和hash_list中删除，并释放子进程的内核堆栈和进程控制块。自此，子进程才彻底地结束了它的执行过程，消除了它所占用的所有资源。 系统调用实现用户进程只能在操作系统给它圈定好的“用户环境”中执行，但“用户环境”限制了用户进程能够执行的指令，即用户进程只能执行一般的指令，无法执行特权指令。如果用户进程想执行一些需要特权指令的任务，比如通过网卡发网络包等，只能让操作系统来代劳了。于是就需要一种机制来确保用户进程不能执行特权指令，但能够请操作系统“帮忙”完成需要特权指令的任务，这种机制就是系统调用。 采用系统调用机制为用户进程提供一个获得操作系统服务的统一接口层： 一来可简化用户进程的实现，把一些共性的、繁琐的、与硬件相关、与特权指令相关的任务放到操作系统层来实现，但提供一个简洁的接口给用户进程调用； 二来这层接口事先可规定好，且严格检查用户进程传递进来的参数和操作系统要返回的数据，使得让操作系统给用户进程服务的同时，保护操作系统不会被用户进程破坏。 从硬件层面上看，需要硬件能够支持在用户态的用户进程通过某种机制切换到内核态。 初始化系统调用对应的中断描述符在ucore初始化函数kern_init中调用了idt_init函数来初始化中断描述符表，并设置一个特定中断号的中断门，专门用于用户进程访问系统调用。此事由ide_init函数完成：12345678910voididt_init(void) &#123; extern uintptr_t __vectors[]; int i; for (i = 0; i &lt; sizeof(idt) / sizeof(struct gatedesc); i ++) &#123; SETGATE(idt[i], 0, GD_KTEXT, __vectors[i], DPL_KERNEL); &#125; SETGATE(idt[T_SYSCALL], 1, GD_KTEXT, __vectors[T_SYSCALL], DPL_USER); lidt(&amp;idt_pd);&#125; 在上述代码中，可以看到在执行加载中断描述符表lidt指令前，专门设置了一个特殊的中断描述符idt[T_SYSCALL]，它的特权级设置为DPL_USER，中断向量处理地址在vectors[T_SYSCALL]处。这样建立好这个中断描述符后，一旦用户进程执行“INT T_SYSCALL”后，由于此中断允许用户态进程产生（注意它的特权级设置为DPL_USER），所以CPU就会从用户态切换到内核态，保存相关寄存器，并跳转到vectors[T_SYSCALL]处开始执行，形成如下执行路径：12vector128(vectors.S) --&gt; __alltraps(trapentry.S) --&gt; trap(trap.c) --&gt; trap_dispatch(trap.c) --&gt; syscall(syscall.c) 建立系统调用的用户库准备在操作系统中初始化好系统调用相关的中断描述符、中断处理起始地址等后，还需在用户态的应用程序中初始化好相关工作，简化应用程序访问系统调用的复杂性。为此在用户态建立了一个中间层，即简化的libc实现，在user/libs/ulib.[ch]和user/libs/syscall.[ch]中完成了对访问系统调用的封装。用户态最终的访问系统调用函数是syscall，实现如下：123456789101112131415161718192021222324static inline intsyscall(int num, ...) &#123; va_list ap; va_start(ap, num); uint32_t a[MAX_ARGS]; int i, ret; for (i = 0; i &lt; MAX_ARGS; i ++) &#123; a[i] = va_arg(ap, uint32_t); &#125; va_end(ap); asm volatile ( &quot;int %1;&quot; : &quot;=a&quot; (ret) : &quot;i&quot; (T_SYSCALL), &quot;a&quot; (num), &quot;d&quot; (a[0]), &quot;c&quot; (a[1]), &quot;b&quot; (a[2]), &quot;D&quot; (a[3]), &quot;S&quot; (a[4]) : &quot;cc&quot;, &quot;memory&quot;); return ret;&#125; 从中可以看出，应用程序调用的exit/fork/wait/getpid等库函数最终都会调用syscall函数，只是调用的参数不同而已，如果看最终的汇编代码会更清楚：12345678910…… 34: 8b 55 d4 mov -0x2c(%ebp),%edx 37: 8b 4d d8 mov -0x28(%ebp),%ecx 3a: 8b 5d dc mov -0x24(%ebp),%ebx 3d: 8b 7d e0 mov -0x20(%ebp),%edi 40: 8b 75 e4 mov -0x1c(%ebp),%esi 43: 8b 45 08 mov 0x8(%ebp),%eax 46: cd 80 int $0x80 48: 89 45 f0 mov %eax,-0x10(%ebp)…… 可以看到其实是把系统调用号放到EAX，其他5个参数a[0]~a[4]分别保存到EDX/ECX/EBX/EDI/ESI五个寄存器中，及最多用6个寄存器来传递系统调用的参数，且系统调用的返回结果是EAX。比如对于getpid库函数而言，系统调用号（SYS_getpid=18）是保存在EAX中，返回值（调用此库函数的的当前进程号pid）也在EAX中。 与用户进程相关的系统调用在本实验中，与进程相关的各个系统调用属性如下所示：|系统调用名 | 含义 | 具体完成服务的函数 ||—-|—-|—-||SYS_exit | process exit | do_exit ||SYS_fork | create child process, dup mm | do_fork–&gt;wakeup_proc ||SYS_wait | wait child process | do_wait ||SYS_exec | after fork, process execute a new program | load a program and refresh the mm ||SYS_yield | process flag itself need resecheduling | proc-&gt;need_sched=1, then scheduler will rescheule this process ||SYS_kill | kill process | do_kill–&gt;proc-&gt;flags |= PF_EXITING, –&gt;wakeup_proc–&gt;do_wait–&gt;do_exit ||SYS_getpid | get the process’s pid | | 系统调用的执行过程与用户态的函数库调用执行过程相比，系统调用执行过程的有四点主要的不同： 不是通过“CALL”指令而是通过“INT”指令发起调用； 不是通过“RET”指令，而是通过“IRET”指令完成调用返回； 当到达内核态后，操作系统需要严格检查系统调用传递的参数，确保不破坏整个系统的安全性； 执行系统调用可导致进程等待某事件发生，从而可引起进程切换； 下面我们以getpid系统调用的执行过程大致看看操作系统是如何完成整个执行过程的。当用户进程调用getpid函数，最终执行到INT T_SYSCALL指令后，CPU根据操作系统建立的系统调用中断描述符，转入内核态，并跳转到vector128处（kern/trap/vectors.S），开始了操作系统的系统调用执行过程，函数调用和返回操作的关系如下所示：12vector128(vectors.S) --&gt; __alltraps(trapentry.S) --&gt; trap(trap.c) --&gt; trap_dispatch(trap.c) --&gt; syscall(syscall.c) --&gt; sys_getpid(syscall.c) --&gt; …… --&gt; __trapret(trapentry.S) 在执行trap函数前，软件还需进一步保存执行系统调用前的执行现场，即把与用户进程继续执行所需的相关寄存器等当前内容保存到当前进程的中断帧trapframe中（注意，在创建进程是，把进程的trapframe放在给进程的内核栈分配的空间的顶部）。软件做的工作在vector128和__alltraps的起始部分：123456789vectors.S::vector128起始处: pushl $0 pushl $128......trapentry.S::__alltraps起始处:pushl %ds pushl %es pushal…… 自此，用于保存用户态的用户进程执行现场的trapframe的内容填写完毕，操作系统可开始完成具体的系统调用服务。在sys_getpid函数中，简单地把当前进程的pid成员变量做为函数返回值就是一个具体的系统调用服务。完成服务后，操作系统按调用关系的路径原路返回到__alltraps中。然后操作系统开始根据当前进程的中断帧内容做恢复执行现场操作。其实就是把trapframe的一部分内容保存到寄存器内容。恢复寄存器内容结束后，调整内核堆栈指针到中断帧的tf_eip处，这是内核栈的结构如下：123456789/* below here defined by x86 hardware */ uintptr_t tf_eip; uint16_t tf_cs; uint16_t tf_padding3; uint32_t tf_eflags;/* below here only when crossing rings */ uintptr_t tf_esp; uint16_t tf_ss; uint16_t tf_padding4; 这时执行IRET指令后，CPU根据内核栈的情况回复到用户态，并把EIP指向tf_eip的值，即INT T_SYSCALL后的那条指令。这样整个系统调用就执行完毕了。 读load_icode有感123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167/* load_icode - load the content of binary program(ELF format) as the new content of current process * @binary: the memory addr of the content of binary program * @size: the size of the content of binary program * 读取一个二进制elf文件并为其设置执行场景，并执行 */static intload_icode(unsigned char *binary, size_t size) &#123; if (current-&gt;mm != NULL) &#123; panic(&quot;load_icode: current-&gt;mm must be empty.\n&quot;); &#125; int ret = -E_NO_MEM; struct mm_struct *mm; //(1) create a new mm for current process if ((mm = mm_create()) == NULL) &#123; goto bad_mm; &#125; //(2) create a new PDT, and mm-&gt;pgdir= kernel virtual addr of PDT if (setup_pgdir(mm) != 0) &#123; goto bad_pgdir_cleanup_mm; &#125; //(3) copy TEXT/DATA section, build BSS parts in binary to memory space of process struct Page *page; //(3.1) get the file header of the bianry program (ELF format) // 将二进制串转成描述elf的结构体 struct elfhdr *elf = (struct elfhdr *)binary; //(3.2) get the entry of the program section headers of the bianry program (ELF format) // 获取elf头的起始地址 struct proghdr *ph = (struct proghdr *)(binary + elf-&gt;e_phoff); // 代码段的头 //(3.3) This program is valid? // 第一个实验中说了elf的这个域是ELF_MAGIC if (elf-&gt;e_magic != ELF_MAGIC) &#123; ret = -E_INVAL_ELF; goto bad_elf_cleanup_pgdir; &#125; uint32_t vm_flags, perm; struct proghdr *ph_end = ph + elf-&gt;e_phnum; for (; ph &lt; ph_end; ph ++) &#123; //(3.4) find every program section headers // 每一个程序段 if (ph-&gt;p_type != ELF_PT_LOAD) &#123; //程序段头里的这个程序段的类型，如可加载的代码、数据、动态链接信息等 continue ; &#125; if (ph-&gt;p_filesz &gt; ph-&gt;p_memsz) &#123; ret = -E_INVAL_ELF; goto bad_cleanup_mmap; &#125; if (ph-&gt;p_filesz == 0) &#123; // 这个段的大小 continue ; &#125; //(3.5) call mm_map fun to setup the new vma ( ph-&gt;p_va, ph-&gt;p_memsz) vm_flags = 0, perm = PTE_U; if (ph-&gt;p_flags &amp; ELF_PF_X) vm_flags |= VM_EXEC; if (ph-&gt;p_flags &amp; ELF_PF_W) vm_flags |= VM_WRITE; if (ph-&gt;p_flags &amp; ELF_PF_R) vm_flags |= VM_READ; // 可读、可写、可执行？ if (vm_flags &amp; VM_WRITE) perm |= PTE_W; if ((ret = mm_map(mm, ph-&gt;p_va, ph-&gt;p_memsz, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; // 创建一个vma，并把这个vma加入到mm的list中 &#125; unsigned char *from = binary + ph-&gt;p_offset; size_t off, size; uintptr_t start = ph-&gt;p_va, end, la = ROUNDDOWN(start, PGSIZE); // ret = -E_NO_MEM; //(3.6) alloc memory, and copy the contents of every program section (from, from+end) to process&apos;s memory(la, la+end) end = ph-&gt;p_va + ph-&gt;p_filesz; //(3.6.1) copy TEXT/DATA section of bianry program // 分配页 while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; memcpy(page2kva(page) + off, from, size); start += size, from += size; &#125; //(3.6.2) build BSS section of binary program end = ph-&gt;p_va + ph-&gt;p_memsz; if (start &lt; la) &#123; /* ph-&gt;p_memsz == ph-&gt;p_filesz */ if (start == end) &#123; continue ; &#125; off = start + PGSIZE - la, size = PGSIZE - off; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page) + off, 0, size); start += size; assert((end &lt; la &amp;&amp; start == end) || (end &gt;= la &amp;&amp; start == la)); &#125; while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page) + off, 0, size); start += size; &#125; &#125; //(4) build user stack memory vm_flags = VM_READ | VM_WRITE | VM_STACK; if ((ret = mm_map(mm, USTACKTOP - USTACKSIZE, USTACKSIZE, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; &#125; assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-2*PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-3*PGSIZE , PTE_USER) != NULL); assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-4*PGSIZE , PTE_USER) != NULL); //(5) set current process&apos;s mm, sr3, and set CR3 reg = physical addr of Page Directory mm_count_inc(mm); // mm的count加1，计算有多少进程同时使用这个mm current-&gt;mm = mm; // 当前进程的mm是这个mm current-&gt;cr3 = PADDR(mm-&gt;pgdir); // 虚拟地址转换成物理地址 lcr3(PADDR(mm-&gt;pgdir)); //(6) setup trapframe for user environment struct trapframe *tf = current-&gt;tf; memset(tf, 0, sizeof(struct trapframe)); /* LAB5:EXERCISE1 YOUR CODE * should set tf_cs,tf_ds,tf_es,tf_ss,tf_esp,tf_eip,tf_eflags * NOTICE: If we set trapframe correctly, then the user level process can return to USER MODE from kernel. So * tf_cs should be USER_CS segment (see memlayout.h) * tf_ds=tf_es=tf_ss should be USER_DS segment * tf_esp should be the top addr of user stack (USTACKTOP) * tf_eip should be the entry point of this binary program (elf-&gt;e_entry) * tf_eflags should be set to enable computer to produce Interrupt */ tf-&gt;tf_cs = USER_CS; tf-&gt;tf_ds = tf-&gt;tf_es = tf-&gt;tf_ss = USER_DS; tf-&gt;tf_esp = USTACKTOP; tf-&gt;tf_eip = elf-&gt;e_entry; tf-&gt;tf_eflags = 0x00000002 | FL_IF; // to enable interrupt //网上这里有的是这么写的，不知道为啥，我觉得应该只要FL_IF就够了，可能是我考虑不周/* #define FL_IF 0x00000200 // Interrupt Flag tf-&gt;tf_eflags = FL_IF;*/ ret = 0;out: return ret;bad_cleanup_mmap: exit_mmap(mm);bad_elf_cleanup_pgdir: put_pgdir(mm);bad_pgdir_cleanup_mm: mm_destroy(mm);bad_mm: goto out;&#125; 练习1：加载应用程序并执行do_execv函数调用了load_icode函数（位于kern/process/proc.c中）来加载并解析一个处于内存中的ELF执行文件格式的应用程序，并建立了相应的用户内存空间来存放应用程序的代码段、数据段 等，且要设置好proc_struct结构中的成员变量trapframe中的内容，确保在执行此进程后，能够从应用程序设定的起始执行地址开始执行。 load_icode函数是由do_execve函数调用的，而该函数是exec系统调用的最终处理的函数，功能为将某一个指定的ELF可执行二进制文件加载到当前内存中来，然后当前进程执行这个可执行文件（先前执行的内容全部清空），而load_icode函数的功能则在于为执行新的程序初始化好内存空间，在调用该函数之前，do_execve中已经退出了当前进程的内存空间，改使用了内核的内存空间，这样使得对原先用户态的内存空间的操作成为可能； 由于最终是在用户态下运行的，所以需要将段寄存器初始化为用户态的代码段、数据段、堆栈段；esp应当指向先前的步骤中创建的用户栈的栈顶；eip应当指向ELF可执行文件加载到内存之后的入口处；eflags中应当初始化为中断使能，注意eflags的第1位是恒为1的；设置ret为0，表示正常返回；见上边的函数代码。 首先在初始化IDT的时候，设置系统调用对应的中断描述符，使其能够在用户态下被调用，并且设置为trap类型。设置系统调用中断是用户态的。12345678910111213141516171819202122232425262728 extern uintptr_t __vectors[]; int i; for (i = 0; i &lt; sizeof(idt) / sizeof(struct gatedesc); i ++) &#123; SETGATE(idt[i], 0, GD_KTEXT, __vectors[i], DPL_KERNEL); &#125; SETGATE(idt[T_SYSCALL], 1, GD_KTEXT, __vectors[T_SYSCALL], DPL_USER); lidt(&amp;idt_pd);/* * * Set up a normal interrupt/trap gate descriptor * - istrap: 1 for a trap (= exception) gate, 0 for an interrupt gate * - sel: Code segment selector for interrupt/trap handler * - off: Offset in code segment for interrupt/trap handler * - dpl: Descriptor Privilege Level - the privilege level required * for software to invoke this interrupt/trap gate explicitly * using an int instruction. * */#define SETGATE(gate, istrap, sel, off, dpl) &#123; \ (gate).gd_off_15_0 = (uint32_t)(off) &amp; 0xffff; \ (gate).gd_ss = (sel); \ (gate).gd_args = 0; \ (gate).gd_rsv1 = 0; \ (gate).gd_type = (istrap) ? STS_TG32 : STS_IG32; \ (gate).gd_s = 0; \ (gate).gd_dpl = (dpl); \ (gate).gd_p = 1; \ (gate).gd_off_31_16 = (uint32_t)(off) &gt;&gt; 16; \ &#125; 同样是在trap.c里，设置当计时器到点之后，也就是100个时钟周期之后，这个进程就是可以被重新调度的了，实现多线程的并发执行。12345678910111213 case IRQ_OFFSET + IRQ_TIMER: ticks++; if(ticks&gt;=TICK_NUM)&#123; assert(current != NULL); current-&gt;need_resched = 1; //print_ticks(); ticks=0; &#125; /* LAB5 YOUR CODE */ /* you should upate you lab1 code (just add ONE or TWO lines of code): * Every TICK_NUM cycle, you should set current process&apos;s current-&gt;need_resched = 1 */- 在proc_alloc函数中，额外对进程控制块中新增加的wait_state, cptr, yptr, optr成员变量进行初始化；在alloc_proc(void)函数中，对新增的几个变量初始化12345678 //LAB5 YOUR CODE : (update LAB4 steps)/* * below fields(add in LAB5) in proc_struct need to be initialized * uint32_t wait_state; // waiting state * struct proc_struct *cptr, *yptr, *optr; // relations between processes */ proc-&gt;wait_state = 0; proc-&gt;cptr = proc-&gt;optr = proc-&gt;yptr = NULL; 在do_fork函数中，使用set_links函数来完成将fork的线程添加到线程链表中的过程，值得注意的是，该函数中就包括了将其加入list和对进程总数加1这一操作，因此需要将原先的这个操作给删除掉；1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// set_links - set the relation links of processstatic voidset_links(struct proc_struct *proc) &#123; list_add(&amp;proc_list, &amp;(proc-&gt;list_link)); proc-&gt;yptr = NULL; if ((proc-&gt;optr = proc-&gt;parent-&gt;cptr) != NULL) &#123; proc-&gt;optr-&gt;yptr = proc; &#125; proc-&gt;parent-&gt;cptr = proc; nr_process ++;&#125;//LAB5 YOUR CODE : (update LAB4 steps)/* Some Functions * set_links: set the relation links of process. ALSO SEE: remove_links: lean the relation links of process * ------------------- * update step 1: set child proc&apos;s parent to current process, make sure current process&apos;s wait_state is 0 * update step 5: insert proc_struct into hash_list &amp;&amp; proc_list, set the relation links of process */// 1. call alloc_proc to allocate a proc_struct proc = alloc_proc(); if(proc == NULL) goto fork_out;// 2. call setup_kstack to allocate a kernel stack for child process proc-&gt;parent = current; assert(current-&gt;wait_state == 0); int status = setup_kstack(proc); if(status != 0) goto bad_fork_cleanup_kstack;// 3. call copy_mm to dup OR share mm according clone_flag status = copy_mm(clone_flags, proc); if(status != 0) goto bad_fork_cleanup_proc;// 4. call copy_thread to setup tf &amp; context in proc_struct copy_thread(proc, stack, tf);// 5. insert proc_struct into hash_list &amp;&amp; proc_list proc-&gt;pid = get_pid(); hash_proc(proc); set_links(proc);// delete thses two lines !!! //nr_process ++; //list_add(&amp;proc_list, &amp;proc-&gt;list_link);// delete thses two lines !!!// 6. call wakeup_proc to make the new child process RUNNABLE wakeup_proc(proc);// 7. set ret vaule using child proc&apos;s pid ret = proc-&gt;pid; 请在实验报告中描述当创建一个用户态进程并加载了应用程序后，CPU是如何让这个应用程序最终在用户态执行起来的。即这个用户态进程被ucore选择占用CPU执行（RUNNING态） 到具体执行应用程序第一条指令的整个经过。 在经过调度器占用了CPU的资源之后，用户态进程调用了exec系统调用，从而转入到了系统调用的处理例程； 调用中断处理例程之后，最终控制权转移到了syscall.c中的syscall函数，然后根据系统调用号转移给了sys_exec函数，在该函数中调用了上文中提及的do_execve函数来完成指定应用程序的加载； 在do_execve中进行了若干设置，包括退出当前进程的页表，换用kernel的PDT之后，使用load_icode函数，完成了对整个用户线程内存空间的初始化，包括堆栈的设置以及将ELF可执行文件的加载，之后通过current-&gt;tf指针修改了当前系统调用的trapframe，使得最终中断返回的时候能够切换到用户态，并且同时可以正确地将控制权转移到应用程序的入口处； 在完成了do_exec函数之后，进行正常的中断返回的流程，由于中断处理例程的栈上面的eip已经被修改成了应用程序的入口处，而cs上的CPL是用户态，因此iret进行中断返回的时候会将堆栈切换到用户的栈，并且完成特权级的切换，并且跳转到要求的应用程序的入口处； 接下来开始具体执行应用程序的第一条指令； 本问题参考：https://www.jianshu.com/p/8c852af5b403 练习2：父进程复制自己的内存空间给子进程创建子进程的函数do_fork在执行中将拷贝当前进程（即父进程）的用户内存地址空间中的合法内容到新进程中（子进程），完成内存资源的复制。具体是通过copy_range函数（位于 kern/mm/pmm.c中）实现的，请补充copy_range的实现，确保能够正确执行。 父进程调用fork()，进入中断处理机制，最终交由syscall函数进行处理； 在syscall，根据系统调用号，交由sys_fork函数处理； 进一步调用do_fork函数，这个函数创建了子进程、并且将父进程的内存空间复制给子进程； 在do_fork函数中，调用copy_mm进行内存空间的复制，在该函数中，进一步调用了dup_mmap。dup_mmap中遍历父进程的所有合法虚拟内存空间，并且将这些空间的内容复制到子进程的内存空间中去； 在copy_range函数中，对需要复制的内存空间按照页为单位从父进程的内存空间复制到子进程的内存空间中去； 遍历父进程指定的某一段内存空间中的每一个虚拟页，如果这个虚拟页存在，为子进程对应的同一个地址（但是页目录表是不一样的，因此不是一个内存空间）也申请分配一个物理页，然后将前者中的所有内容复制到后者中去，然后为子进程的这个物理页和对应的虚拟地址（事实上是线性地址）建立映射关系；而在本练习中需要完成的内容就是内存的复制和映射的建立，具体流程如下： 找到父进程指定的某一物理页对应的内核虚拟地址； 找到需要拷贝过去的子进程的对应物理页对应的内核虚拟地址； 将前者的内容拷贝到后者中去； 为子进程当前分配这一物理页映射上对应的在子进程虚拟地址空间里的一个虚拟页； 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* copy_range - copy content of memory (start, end) of one process A to another process B * @to: the addr of process B&apos;s Page Directory * @from: the addr of process A&apos;s Page Directory * @share: flags to indicate to dup OR share. We just use dup method, so it didn&apos;t be used. * * CALL GRAPH: copy_mm--&gt;dup_mmap--&gt;copy_range */intcopy_range(pde_t *to, pde_t *from, uintptr_t start, uintptr_t end, bool share) &#123; assert(start % PGSIZE == 0 &amp;&amp; end % PGSIZE == 0); assert(USER_ACCESS(start, end)); // copy content by page unit. do &#123; //call get_pte to find process A&apos;s pte according to the addr start pte_t *ptep = get_pte(from, start, 0), *nptep; if (ptep == NULL) &#123; start = ROUNDDOWN(start + PTSIZE, PTSIZE); continue ; &#125; //call get_pte to find process B&apos;s pte according to the addr start. If pte is NULL, just alloc a PT if (*ptep &amp; PTE_P) &#123; if ((nptep = get_pte(to, start, 1)) == NULL) &#123; return -E_NO_MEM; &#125; uint32_t perm = (*ptep &amp; PTE_USER); //get page from ptep struct Page *page = pte2page(*ptep); // alloc a page for process B struct Page *npage=alloc_page(); assert(page!=NULL); assert(npage!=NULL); int ret=0; /* LAB5:EXERCISE2 YOUR CODE * replicate content of page to npage, build the map of phy addr of nage with the linear addr start * * Some Useful MACROs and DEFINEs, you can use them in below implementation. * MACROs or Functions: * page2kva(struct Page *page): return the kernel vritual addr of memory which page managed (SEE pmm.h) * page_insert: build the map of phy addr of an Page with the linear addr la * memcpy: typical memory copy function * * (1) find src_kvaddr: the kernel virtual address of page * (2) find dst_kvaddr: the kernel virtual address of npage * (3) memory copy from src_kvaddr to dst_kvaddr, size is PGSIZE * (4) build the map of phy addr of nage with the linear addr start */ char *src_kvaddr = page2kva(page); //找到父进程需要复制的物理页在内核地址空间中的虚拟地址，这是由于这个函数执行的时候使用的时内核的地址空间 char *dst_kvaddr = page2kva(npage); // 找到子进程需要被填充的物理页的内核虚拟地址 memcpy(dst_kvaddr, src_kvaddr, PGSIZE); // 将父进程的物理页的内容复制到子进程中去 page_insert(to, npage, start, perm); // 建立子进程的物理页与虚拟页的映射关系 assert(ret == 0); &#125; start += PGSIZE; &#125; while (start != 0 &amp;&amp; start &lt; end); return 0;&#125; 练习3：阅读分析源代码，理解进程执行 fork/exec/wait/exit 的实现，以及系统调用的实现（不需要编码） fork：在执行了fork系统调用之后，会执行正常的中断处理流程，到中断向量表里查系统调用入口，最终将控制权转移给syscall，之后根据系统调用号执行sys_fork函数，进一步执行了上文中的do_fork函数，新进程的进程控制块进行初始化、设置、以及调用copy_mm将父进程内存中的内容到子进程的内存的复制工作，然后调用wakeup_proc将新创建的进程放入可执行队列（runnable），之后由调度器对子进程进行调度。 exec：在执行了exec系统调用之后，会执行正常的中断处理流程，到中断向量表里查系统调用入口，最终将控制权转移给syscall，之后根据系统调用号执行sys_exec函数，进一步执行了上文中的do_execve函数。在该函数中，会对内存空间进行清空，然后调用load_icode将将要执行的程序加载到内存中，然后调用lcr3(boot_cr4)设置好中断帧，使得最终中断返回之后可以跳转到指定的应用程序的入口处，就可以正确执行了。 wait：在执行了wait系统调用之后，会执行正常的中断处理流程，到中断向量表里查系统调用入口，最终将控制权转移给syscall，之后根据系统调用号执行sys_wait函数，进一步执行了的do_wait函数，在这个函数中，找一个当前进程的处于ZOMBIE状态的子进程，如果有的话直接将其占用的资源释放掉即可；如果找不到，则将我这个进程的状态改成SLEEPING态，并且标记为等待ZOMBIE态的子进程，然后调用schedule函数将其当前线程从CPU占用中切换出去，直到有对应的子进程结束来唤醒这个进程为止。 exit：在执行了exit系统调用之后，会执行正常的中断处理流程，到中断向量表里查系统调用入口，最终将控制权转移给syscall，之后根据系统调用号执行sys_exit函数，进一步执行了的do_exit函数，首先将释放当前进程的大多数资源，然后将其标记为ZOMBIE态，然后调用wakeup_proc函数将其父进程唤醒（如果父进程执行了wait进入SLEEPING态的话），然后调用schedule函数，让出CPU资源，等待父进程进一步完成其所有资源的回收； 问题回答 请分析fork/exec/wait/exit在实现中是如何影响进程的执行状态的？ fork不会影响当前进程的执行状态，但是会将子进程的状态标记为RUNNALB，使得可以在后续的调度中运行起来；exec不会影响当前进程的执行状态，但是会修改当前进程中执行的程序；wait系统调用取决于是否存在可以释放资源（ZOMBIE）的子进程，如果有的话不会发生状态的改变，如果没有的话会将当前进程置为SLEEPING态，等待执行了exit的子进程将其唤醒；exit会将当前进程的状态修改为ZOMBIE态，并且会将父进程唤醒（修改为RUNNABLE），然后主动让出CPU使用权；]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验四]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[Lab4 内核线程管理 实验报告实验目的了解内核线程创建/执行的管理过程了解内核线程的切换和基本调度过程 实验内容当一个程序加载到内存中运行时，首先通过ucore OS的内存管理子系统分配合适的空间，然后就需要考虑如何分时使用CPU来“并发”执行多个程序，让每个运行的程序（这里用线程或进程表示）“感到”它们各自拥有“自己”的CPU。 内核线程是一种特殊的进程，内核线程与用户进程的区别有两个： 内核线程只运行在内核态 用户进程会在在用户态和内核态交替运行 所有内核线程共用ucore内核内存空间，不需为每个内核线程维护单独的内存空间 用户进程需要维护各自的用户内存空间 预备知识内核线程管理本实验实现了让ucore实现分时共享CPU，实现多条控制流能够并发执行。内核线程是一种特殊的进程，内核线程与用户进程的区别有两个： 内核线程只运行在内核态而用户进程会在在用户态和内核态交替运行； 所有内核线程直接使用共同的ucore内核内存空间，不需为每个内核线程维护单独的内存空间而用户进程需要维护各自的用户内存空间。 设计管理线程的数据结构，即进程控制块(PCB)。创建内核线程对应的进程控制块，把这些进程控制块通过链表连在一起，便于随时进行插入，删除和查找操作。通过调度器（scheduler）来让不同的内核线程在不同的时间段占用CPU执行，实现对CPU的分时共享。 kern/init/init.c中的kern_init函数中，当完成虚拟内存的初始化工作vmm_init()后，就调用了proc_init函数。123456789101112131415161718192021222324252627282930313233343536voidproc_init(void) &#123; int i; list_init(&amp;proc_list); // initialize the process double linked list for (i = 0; i &lt; HASH_LIST_SIZE; i ++) &#123; list_init(hash_list + i); &#125; if ((idleproc = alloc_proc()) == NULL) &#123; panic(&quot;cannot alloc idleproc.\n&quot;); &#125; idleproc-&gt;pid = 0; idleproc-&gt;state = PROC_RUNNABLE; idleproc-&gt;kstack = (uintptr_t)bootstack; idleproc-&gt;need_resched = 1; // 完成了idleproc内核线程创建 set_proc_name(idleproc, &quot;idle&quot;); nr_process ++; current = idleproc; int pid = kernel_thread(init_main, &quot;Hello world!!&quot;, 0); if (pid &lt;= 0) &#123; panic(&quot;create init_main failed.\n&quot;); &#125; initproc = find_proc(pid); // initproc内核线程的创建 set_proc_name(initproc, &quot;init&quot;); assert(idleproc != NULL &amp;&amp; idleproc-&gt;pid == 0); assert(initproc != NULL &amp;&amp; initproc-&gt;pid == 1);&#125; idleproc内核线程的工作就是不停地查询，看是否有其他内核线程可以执行了，如果有，马上让调度器选择那个内核线程执行（请参考cpu_idle函数的实现）。所以idleproc内核线程是在ucore操作系统没有其他内核线程可执行的情况下才会被调用。 接着就是调用kernel_thread函数来创建initproc内核线程。initproc内核线程的工作就是显示“Hello World”，表明自己存在且能正常工作了。调度器会在特定的调度点上执行调度，完成进程切换。 在lab4中，这个调度点就一处，即在cpu_idle函数中，此函数如果发现当前进程（也就是idleproc）的need_resched置为1（在初始化idleproc的进程控制块时就置为1了），则调用schedule函数，完成进程调度和进程切换。进程调度的过程其实比较简单，就是在进程控制块链表中查找到一个“合适”的内核线程，所谓“合适”就是指内核线程处于“PROC_RUNNABLE”状态。 在接下来的switch_to函数(在后续有详细分析，有一定难度，需深入了解一下)完成具体的进程切换过程。一旦切换成功，那么initproc内核线程就可以通过显示字符串来表明本次实验成功。 进程管理信息用struct proc_struct表示，在kern/process/proc.h中定义如下：12345678910111213141516struct proc_struct &#123; enum proc_state state; // Process state int pid; // Process ID int runs; // the running times of Proces uintptr_t kstack; // Process kernel stack volatile bool need_resched; // need to be rescheduled to release CPU? struct proc_struct *parent; // the parent process struct mm_struct *mm; // Process&apos;s memory management field struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for current interrupt uintptr_t cr3; // the base addr of Page Directroy Table(PDT) uint32_t flags; // Process flag char name[PROC_NAME_LEN + 1]; // Process name list_entry_t list_link; // Process link list list_entry_t hash_link; // Process hash list&#125;; mm：内存管理的信息。在lab3中有涉及，主要包括内存映射列表、页表指针等。在实际OS中，内核线程常驻内存，不需要考虑swap page问题，在用户进程中考虑进程用户内存空间的swap_page问题时mm才会发挥作用。所以在lab4中mm对于内核线程就没有用了，这样内核线程的proc_struct的成员变量mm=0是合理的。mm里有个很重要的项pgdir，记录的是该进程使用的一级页表的物理地址。由于mm=NULL，所以在proc_struct数据结构中需要有一个代替pgdir项来记录页表起始地址，这就是proc_struct数据结构中的cr3成员变量。 state：进程所处的状态。 123456enum proc_state &#123; PROC_UNINIT = 0, // uninitialized PROC_SLEEPING, // sleeping PROC_RUNNABLE, // runnable(maybe running) PROC_ZOMBIE, // almost dead, and wait parent proc to reclaim his resource&#125;; parent：用户进程的父进程（创建它的进程）。在所有进程中，只有一个进程没有父进程，就是内核创建的第一个内核线程idleproc。内核根据这个父子关系建立一个树形结构，用于维护一些特殊的操作，例如确定某个进程是否可以对另外一个进程进行某种操作等等。 context：进程的上下文，用于进程切换（参见switch.S）。在uCore中，所有的进程在内核中也是相对独立的（例如独立的内核堆栈以及上下文等等）。使用context保存寄存器的目的就在于在内核态中能够进行上下文之间的切换。实际利用context进行上下文切换的函数是在kern/process/switch.S中定义switch_to。 123456789101112// 在上下文切换时保存寄存器信息，其中有些寄存器貌似不被保存，为了省事// The 这个结构体的布局要跟switch.S中的switch_to操作对应。struct context &#123; uint32_t eip; uint32_t esp; uint32_t ebx; uint32_t ecx; uint32_t edx; uint32_t esi; uint32_t edi; uint32_t ebp;&#125;; tf：中断帧的指针，总是指向内核栈的某个位置：当进程从用户空间跳到内核空间时，中断帧记录了进程在被中断前的状态。当内核需要跳回用户空间时，需要调整中断帧以恢复让进程继续执行的各寄存器值。除此之外，uCore内核允许嵌套中断。因此为了保证嵌套中断发生时tf总是能够指向当前的trapframe，uCore在内核栈上维护了tf的链。 cr3: cr3 保存页表的物理地址，目的就是进程切换的时候方便直接使用lcr3实现页表切换，避免每次都根据 mm 来计算 cr3。mm数据结构是用来实现用户空间的虚存管理的，但是内核线程没有用户空间，它执行的只是内核中的一小段代码（通常是一小段函数），所以它没有mm结构，也就是NULL。当某个进程是一个普通用户态进程的时候，PCB中的cr3就是mm中页表（pgdir）的物理地址；而当它是内核线程的时候，cr3等于boot_cr3。而boot_cr3指向了uCore启动时建立好的内核虚拟空间的页目录表首地址。 kstack: 每个线程都有一个内核栈，并且位于内核地址空间的不同位置。对于内核线程，该栈就是运行时的程序使用的栈；而对于普通进程，该栈是发生特权级改变的时候使保存被打断的硬件信息用的栈。uCore在创建进程时分配了 2 个连续的物理页（参见memlayout.h中KSTACKSIZE的定义）作为内核栈的空间。这个栈很小，所以内核中的代码应该尽可能的紧凑，并且避免在栈上分配大的数据结构，以免栈溢出，导致系统崩溃。kstack记录了分配给该进程/线程的内核栈的位置。主要作用有以下几点。 首先，当内核准备从一个进程切换到另一个的时候，需要根据kstack 的值正确的设置好tss，以便在进程切换以后再发生中断时能够使用正确的栈。 其次，内核栈位于内核地址空间，并且是不共享的（每个线程都拥有自己的内核栈），因此不受到 mm 的管理，当进程退出的时候，内核能够根据 kstack 的值快速定位栈的位置并进行回收。uCore 的这种内核栈的设计借鉴的是 linux 的方法（但由于内存管理实现的差异，它实现的远不如 linux 的灵活），它使得每个线程的内核栈在不同的位置，这样从某种程度上方便调试，但同时也使得内核对栈溢出变得十分不敏感，因为一旦发生溢出，它极可能污染内核中其它的数据使得内核崩溃。如果能够通过页表，将所有进程的内核栈映射到固定的地址上去，能够避免这种问题，但又会使得进程切换过程中对栈的修改变得相当繁琐。 为了管理系统中所有的进程控制块，uCore维护了如下全局变量（位于kern/process/proc.c）： static struct proc *current：当前占用CPU且处于“运行”状态进程控制块指针。通常这个变量是只读的，只有在进程切换的时候才进行修改，并且整个切换和修改过程需要保证操作的原子性，目前至少需要屏蔽中断。可以参考 switch_to 的实现。 static struct proc *initproc：本实验中，指向一个内核线程。本实验以后，此指针将指向第一个用户态进程。 static list_entry_t hash_list[HASH_LIST_SIZE]：所有进程控制块的哈希表，proc_struct中的成员变量hash_link将基于pid链接入这个哈希表中。 list_entry_t proc_list：所有进程控制块的双向线性列表，proc_struct中的成员变量list_link将链接入这个链表中。 创建并执行内核线程ucore实现了一个简单的进程/线程机制，进程包含独立的地址空间，至少一个线程、内核数据、进程状态、文件等。ucore需要高效地管理所有细节。在ucore，一个线程看成一个特殊的进程（process）。 进程状态 意义 原因 PROC_UNINIT uninitialized alloc_proc PROC_SLEEPING sleeping try_free_pages, do_wait, do_sleep PROC_RUNNABLE runnable(maybe running) proc_init, wakeup_proc, PROC_ZOMBIE almost dead do_exit 进程之间的关系：parent: proc-&gt;parent (proc is children)children: proc-&gt;cptr (proc is parent)older sibling: proc-&gt;optr (proc is younger sibling)younger sibling: proc-&gt;yptr (proc is older sibling) 建立进程控制块（proc.c中的alloc_proc函数）。首先，考虑最简单的内核线程，它通常只是内核中的一小段代码或者函数，没有自己的“专属”空间。这是由于在uCore OS启动后，已经对整个内核内存空间进行了管理，通过设置页表建立了内核虚拟空间（即boot_cr3指向的二级页表描述的空间）。所以uCore OS内核中的所有线程都不需要再建立各自的页表，只需共享这个内核虚拟空间就可以访问整个物理内存了。从这个角度看，内核线程被uCore OS内核这个大“内核进程”所管理。 创建第 0 个内核线程 idleproc在init.c中的kern_init函数调用了proc.c中的proc_init函数。proc_init函数启动了创建内核线程的步骤。 首先当前的执行上下文（从kern_init启动至今）就可以看成是uCore内核（也可看做是内核进程）中的一个内核线程的上下文。为此，uCore通过给当前执行的上下文分配一个进程控制块以及对它进行相应初始化，将其打造成第0个内核线程——idleproc。具体步骤如下： 首先调用alloc_proc函数来通过kmalloc函数获得proc_struct结构的一块内存块，作为第0个进程控制块，并把proc进行初步初始化（即把proc_struct中的各个成员变量清零）。但有些成员变量设置了特殊的值，比如：1234proc-&gt;state = PROC_UNINIT; 设置进程为“初始”态proc-&gt;pid = -1; 设置进程pid的未初始化值proc-&gt;cr3 = boot_cr3; 由于该内核线程在内核中运行，故采用为uCore内核已经建立的页表， 即设置为在uCore内核页表的起始地址boot_cr3，使用内核页目录表的基址 内核线程共用一个映射内核空间的页表，这表示内核空间对所有内核线程都是“可见”的，所以更精确地说，这些内核线程都应该是从属于同一个唯一的“大内核进程”—uCore内核。 proc_init函数对idleproc内核线程进行进一步初始化：12345idleproc-&gt;pid = 0;idleproc-&gt;state = PROC_RUNNABLE;idleproc-&gt;kstack = (uintptr_t)bootstack;idleproc-&gt;need_resched = 1;set_proc_name(idleproc, &quot;idle&quot;); 第一条将pid赋值为0，表明idleproc是第0个内核线程。 第二条语句改变了idleproc的状态，使其变为“准备工作”，现在只要uCore调度便可执行。 第三条语句设置了idleproc所使用的内核栈的起始地址。需要注意以后的其他线程的内核栈都需要通过分配获得，因为uCore启动时设置的内核栈就直接分配给idleproc使用了所以这里不用分配。 第四条把idleproc-&gt;need_resched设置为“1”，在cpu_idle函数中指明如果进程的need_resched为1那么就可以调度执行其他的了，如果当前idleproc在执行，则只要此标志为1，马上就调用schedule函数要求调度器切换其他进程执行。 创建第 1 个内核线程 initproc第0个内核线程主要工作是完成内核中各个子系统的初始化。uCore接下来还需创建其他进程来完成各种工作，通过调用kernel_thread函数创建了一个内核线程init_main。12345678// init_main - the second kernel thread used to create user_main kernel threadsstatic intinit_main(void *arg) &#123; cprintf(&quot;this initproc, pid = %d, name = \&quot;%s\&quot;\n&quot;, current-&gt;pid, get_proc_name(current)); cprintf(&quot;To U: \&quot;%s\&quot;.\n&quot;, (const char *)arg); cprintf(&quot;To U: \&quot;en.., Bye, Bye. :)\&quot;\n&quot;); return 0;&#125; 下面我们来分析一下创建内核线程的函数kernel_thread。kernel_thread函数采用了局部变量tf来放置保存内核线程的临时中断帧，并把中断帧的指针传递给do_fork函数，而do_fork函数会调用copy_thread函数来在新创建的进程内核栈上专门给进程的中断帧分配一块空间。给中断帧分配完空间后，就需要构造新进程的中断帧，具体过程是：12345678910111213141516kernel_thread(int (*fn)(void *), void *arg, uint32_t clone_flags)&#123; struct trapframe tf; memset(&amp;tf, 0, sizeof(struct trapframe)); // 给tf进行清零初始化 tf.tf_cs = KERNEL_CS; tf.tf_ds = tf_struct.tf_es = tf_struct.tf_ss = KERNEL_DS; // 设置中断帧的代码段（tf.tf_cs）和数据段(tf.tf_ds/tf_es/tf_ss)为内核空间的段（KERNEL_CS/KERNEL_DS） tf.tf_regs.reg_ebx = (uint32_t)fn; // fn是函数主体 tf.tf_regs.reg_edx = (uint32_t)arg; // arg是fn函数的参数 tf.tf_eip = (uint32_t)kernel_thread_entry; // tf.tf_eip的指出了initproc内核线程从kernel_thread_entry开始执行 return do_fork(clone_flags | CLONE_VM, 0, &amp;tf);&#125; kernel_thread_entry是entry.S中实现的汇编函数，它做的事情很简单：12345kernel_thread_entry: # void kernel_thread(void)pushl %edx # push argcall *%ebx # call fnpushl %eax # save the return value of fn(arg)call do_exit # call do_exit to terminate current thread 从上可以看出，kernel_thread_entry函数主要为内核线程的主体fn函数做了一个准备开始和结束运行的“壳”： 把函数fn的参数arg（保存在edx寄存器中）压栈； 调用fn函数 把函数返回值eax寄存器内容压栈 调用do_exit函数退出线程执行。 do_fork是创建线程的主要函数。kernel_thread函数通过调用do_fork函数最终完成了内核线程的创建工作。do_fork函数主要做了以下6件事情： 分配并初始化进程控制块（alloc_proc函数）； 分配并初始化内核栈（setup_stack函数）； 根据clone_flag标志复制或共享进程内存管理结构（copy_mm函数）； 设置进程在内核（将来也包括用户态）正常运行和调度所需的中断帧和执行上下文（copy_thread函数）； 把设置好的进程控制块放入hash_list和proc_list两个全局进程链表中； 进程已经准备好执行了，把进程状态设置为“就绪”态；设置返回码为子进程的id号。 copy_thread函数代码如下：1234567891011121314151617static voidcopy_thread(struct proc_struct *proc, uintptr_t esp, struct trapframe *tf) &#123; proc-&gt;tf = (struct trapframe *)(proc-&gt;kstack + KSTACKSIZE) - 1; // 在内核堆栈的顶部设置中断帧大小的一块栈空间 *(proc-&gt;tf) = *tf; // 拷贝在kernel_thread函数建立的临时中断帧的初始值 proc-&gt;tf-&gt;tf_regs.reg_eax = 0; // 设置子进程/线程执行完do_fork后的返回值 proc-&gt;tf-&gt;tf_esp = esp; // 设置中断帧中的栈指针esp proc-&gt;tf-&gt;tf_eflags |= FL_IF; // 使能中断 // 以上两句设置中断帧中的栈指针esp和标志寄存器eflags，特别是eflags设置了FL_IF标志， // 这表示此内核线程在执行过程中，能响应中断，打断当前的执行。 proc-&gt;context.eip = (uintptr_t)forkret; proc-&gt;context.esp = (uintptr_t)(proc-&gt;tf);&#125; 对于initproc而言，它的中断帧如下所示：1234567891011//所在地址位置initproc-&gt;tf= (proc-&gt;kstack+KSTACKSIZE) – sizeof (struct trapframe);//具体内容initproc-&gt;tf.tf_cs = KERNEL_CS;initproc-&gt;tf.tf_ds = initproc-&gt;tf.tf_es = initproc-&gt;tf.tf_ss = KERNEL_DS;initproc-&gt;tf.tf_regs.reg_ebx = (uint32_t)init_main;initproc-&gt;tf.tf_regs.reg_edx = (uint32_t) ADDRESS of &quot;Helloworld!!&quot;;initproc-&gt;tf.tf_eip = (uint32_t)kernel_thread_entry;initproc-&gt;tf.tf_regs.reg_eax = 0;initproc-&gt;tf.tf_esp = esp;initproc-&gt;tf.tf_eflags |= FL_IF; 设置好中断帧后，最后就是设置initproc的进程上下文。uCore调度器选择了initproc执行，需要根据initproc-&gt;context中保存的执行现场来恢复initproc的执行。这里设置了initproc的执行现场中主要的两个信息： 上次停止执行时的下一条指令地址context.eip 上次停止执行时的堆栈地址context.esp。 可以看出，由于initproc的中断帧占用了实际给initproc分配的栈空间的顶部，所以initproc就只能把栈顶指针context.esp设置在initproc的中断帧的起始位置。根据context.eip的赋值，可以知道initproc实际开始执行的地方在forkret函数（主要完成do_fork函数返回的处理工作）处。至此，initproc内核线程已经做好准备执行了。 调度并执行内核线程 initproc在uCore执行完proc_init函数后，就创建好了两个内核线程：idleproc和initproc，这时uCore当前的执行现场就是idleproc，等到执行到init函数的最后一个函数cpu_idle之前，uCore的所有初始化工作就结束了，idleproc将通过执行cpu_idle函数让出CPU，给其它内核线程执行，具体过程如下：12345678voidcpu_idle(void) &#123; while (1) &#123; if (current-&gt;need_resched) &#123; schedule(); &#125; &#125;&#125; 首先，判断当前内核线程idleproc的need_resched是否不为0，idleproc中的need_resched本就置为1，所以会马上调用schedule函数找其他处于“就绪”态的进程执行。uCore的调度器为FIFO调度器，其核心就是schedule函数。它的执行逻辑很简单： 设置当前内核线程current-&gt;need_resched为0； 在proc_list队列中查找下一个处于“就绪”态的线程或进程； 找到这样的进程后，就调用proc_run函数，保存当前进程current的上下文，恢复新进程的执行现场，完成进程切换。 uCore通过proc_run和进一步的switch_to函数完成两个执行现场的切换，具体流程如下： 让current指向next内核线程initproc； 设置任务状态段ts中特权态0下的栈顶指针esp0为next内核线程initproc的内核栈的栈顶，即next-&gt;kstack + KSTACKSIZE； 设置CR3寄存器的值为next内核线程initproc的页目录表起始地址next-&gt;cr3，这实际上是完成进程间的页表切换； 由switch_to函数完成具体的两个线程的执行现场切换，即切换各个寄存器，当switch_to函数执行完“ret”指令后，就切换到initproc执行了。 注意，在第二步设置任务状态段ts中特权态0下的栈顶指针esp0的目的是建立好内核线程或将来用户线程在执行特权态切换（从特权态0特权态3，或从特权态3特权态0）时能够正确定位处于特权态0时进程的内核栈的栈顶，而这个栈顶其实放了一个trapframe结构的内存空间。如果是在特权态3发生了中断/异常/系统调用，则CPU会从特权态3–&gt;特权态0，且CPU从此栈顶（当前被打断进程的内核栈顶）开始压栈来保存被中断/异常/系统调用打断的用户态执行现场；如果是在特权态0发生了中断/异常/系统调用，则CPU会从从当前内核栈指针esp所指的位置开始压栈保存被中断/异常/系统调用打断的内核态执行现场。反之，当执行完对中断/异常/系统调用打断的处理后，最后会执行一个“iret”指令。在执行此指令之前，CPU的当前栈指针esp一定指向上次产生中断/异常/系统调用时CPU保存的被打断的指令地址CS和EIP，“iret”指令会根据ESP所指的保存的址CS和EIP恢复到上次被打断的地方继续执行。 第四步proc_run函数调用switch_to函数，参数是前一个进程和后一个进程的执行现场。 switch.S中的switch_to函数的执行流程：123456789101112131415161718192021222324252627282930.globl switch_toswitch_to: # switch_to(from, to)### save from&apos;s registers ###movl 4(%esp), %eax # eax points to frompopl 0(%eax)# esp--&gt; return address, so save return addr in FROM’s context保存前一个进程的执行现场，前两条汇编指令保存了进程在返回switch_to函数后的指令地址到context.eip中movl %esp, 4(%eax)……movl %ebp, 28(%eax) 7条汇编指令完成了保存前一个进程的其他7个寄存器到context中的相应成员变量中### restore to&apos;s registers ### 恢复下一个进程的执行现场，这其实就是上述保存过程的逆执行过程movl 4(%esp), %eax # not 8(%esp): popped return address already# eax now points to tomovl 28(%eax), %ebp……movl 4(%eax), %esp 从context的高地址的成员变量ebp开始，逐一把相关成员变量的值赋值给对应的寄存器pushl 0(%eax) # push TO’s context’s eip, so return addr = TO’s eip 把context中保存的下一个进程要执行的指令地址context.eip放到了堆栈顶ret after ret, eip= TO’s eip 把栈顶的内容赋值给EIP寄存器，这样就切换到下一个进程执行了，即当前进程已经是下一个进程了 uCore会执行进程切换，让initproc执行。在对initproc进行初始化时，设置了initproc-&gt;context.eip = (uintptr_t)forkret，这样，当执行switch_to函数并返回后，initproc将执行其实际上的执行入口地址forkret。而forkret会调用位于kern/trap/trapentry.S中的forkrets函数执行，具体代码如下：123456789101112131415161718.globl __trapret __trapret: # restore registers from stack popal # restore %ds and %es popl %es popl %ds # get rid of the trap number and error code addl $0x8, %esp iret .globl forkrets forkrets: # set stack to this new process trapframe movl 4(%esp), %esp 把esp指向当前进程的中断帧，esp指向了current-&gt;tf.tf_eip jmp __trapret 如果此时执行的是initproc，则current-&gt;tf.tf_eip=kernel_thread_entry，initproc-&gt;tf.tf_cs = KERNEL_CS，所以当执行完iret后，就开始在内核中执行kernel_thread_entry函数了。 而initproc-&gt;tf.tf_regs.reg_ebx = init_main，所以在kernl_thread_entry中执行“call %ebx”后，就开始执行initproc的主体了。Initprocde的主体函数很简单就是输出一段字符串，然后就返回到kernel_tread_entry函数，并进一步调用do_exit执行退出操作了。 练习1：分配并初始化一个进程控制块alloc_proc函数（位于kern/process/proc.c中）负责分配并返回一个新的struct proc_struct结 构，用于存储新建立的内核线程的管理信息。比较简单，state、pid和cr3需要考虑，其他的无脑赋0和memset一波带走就行123456789101112131415161718192021222324252627282930313233343536static struct proc_struct *alloc_proc(void) &#123; struct proc_struct *proc = kmalloc(sizeof(struct proc_struct)); if (proc != NULL) &#123; //LAB4:EXERCISE1 YOUR CODE /* * below fields in proc_struct need to be initialized * enum proc_state state; // Process state * int pid; // Process ID * int runs; // the running times of Proces * uintptr_t kstack; // Process kernel stack * volatile bool need_resched; // bool value: need to be rescheduled to release CPU? * struct proc_struct *parent; // the parent process * struct mm_struct *mm; // Process&apos;s memory management field * struct context context; // Switch here to run process * struct trapframe *tf; // Trap frame for current interrupt * uintptr_t cr3; // CR3 register: the base addr of Page Directroy Table(PDT) * uint32_t flags; // Process flag * char name[PROC_NAME_LEN + 1]; // Process name */ proc-&gt;state = PROC_UNINIT; proc-&gt;pid = -1; proc-&gt;cr3 = boot_cr3; proc-&gt;runs = 0; proc-&gt;kstack = 0; proc-&gt;need_resched = 0; proc-&gt;parent = NULL; proc-&gt;mm = NULL; memset(&amp;proc-&gt;context, 0, sizeof(struct context)); proc-&gt;tf = NULL; proc-&gt;flags = 0; memset(proc-&gt;name, 0, PROC_NAME_LEN); &#125; return proc;&#125; 1234567891011121314151617181920请说明proc_struct中struct context context和struct trapframe *tf成员变量含义和在本实验中的作用是啥？（提示通过看代码和编程调试可以判断出来）：结构体中存储了除eax之外的所有通用寄存器以及eip的数值，保存了线程运行的上下文信息；struct context &#123; uint32_t eip; uint32_t esp; uint32_t ebx; uint32_t ecx; uint32_t edx; uint32_t esi; uint32_t edi; uint32_t ebp;&#125;;context用于内核线程之间切换时，保存原先线程运行的上下文struct trapframe *tf的作用：在copy_thread函数中对tf进行了设置。在这个函数中，把context变量的esp设置成tf变量的地址，把eip设置成forkret函数指针。forkret函数调用了__trapret进行中断返回，tf变量用于构造出新线程时，正确地将控制权转交给新的线程。 练习2：为新创建的内核线程分配资源创建一个内核线程需要分配和设置好很多资源。kernel_thread函数通过调用do_fork函数完成具体内核线程的创建工作。do_fork函数会调用alloc_proc函数来分配并初始化一个进程控制块，但alloc_proc只是找到了一小块内存用以记录进程的必要信息，并没有实际分配这些资源。 ucore一般通过do_fork实际创建新的内核线程。do_fork的作用是： 创建当前内核线程的一个副本，它们的执行上下文、代码、数据都一样，但是存储位置不同。在这个过程中，需要给新内核线程分配资源，并且复制原进程的状态。为内核线程创建新的线程控制块，并且对控制块中的每个成员变量进行正确的设置，使得之后可以正确切换到对应的线程中执行。练习2完成了在kern/process/proc.c中的do_fork函数中的处理过程。它的大致执行步骤包括： 调用alloc_proc，首先获得一块用户信息块。 为进程分配一个内核栈。 复制原进程的内存管理信息到新进程（但内核线程不必做此事） 复制原进程上下文到新进程 将新进程添加到进程列表 唤醒新进程 返回新进程号 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* do_fork - parent process for a new child process * @clone_flags: used to guide how to clone the child process * @stack: the parent&apos;s user stack pointer. if stack==0, It means to fork a kernel thread. * @tf: the trapframe info, which will be copied to child process&apos;s proc-&gt;tf */intdo_fork(uint32_t clone_flags, uintptr_t stack, struct trapframe *tf) &#123; int ret = -E_NO_FREE_PROC; struct proc_struct *proc; if (nr_process &gt;= MAX_PROCESS) &#123; goto fork_out; &#125; ret = -E_NO_MEM; //LAB4:EXERCISE2 YOUR CODE /* * Some Useful MACROs, Functions and DEFINEs, you can use them in below implementation. * MACROs or Functions: * alloc_proc: create a proc struct and init fields (lab4:exercise1) * 创建进程并初始化 * setup_kstack: alloc pages with size KSTACKPAGE as process kernel stack * 创建页，大小为KSTACKPAGE，并作为进程的内核栈 * copy_mm: process &quot;proc&quot; duplicate OR share process &quot;current&quot;&apos;s mm according clone_flags * if clone_flags &amp; CLONE_VM, then &quot;share&quot; ; else &quot;duplicate&quot; * 进程复制memory manager，根据clone_flag不同决定不同操作 * copy_thread: setup the trapframe on the process&apos;s kernel stack top and * setup the kernel entry point and stack of process * 在进程内核栈顶建立trapframe * hash_proc: add proc into proc hash_list * 添加进程到hash_list中 * get_pid: alloc a unique pid for process * 为进程分配一个独特的pid * wakeup_proc: set proc-&gt;state = PROC_RUNNABLE * VARIABLES: * proc_list: the process set&apos;s list * nr_process: the number of process set */ // 1. call alloc_proc to allocate a proc_struct // 为要创建的新的线程分配线程控制块的空间 proc = alloc_proc(); if(proc == NULL) goto fork_out; // 判断是否分配到内存空间 // 2. call setup_kstack to allocate a kernel stack for child process // 为新的线程设置栈，在本实验中，每个线程的栈的大小初始均为2个Page, 即8KB int status = setup_kstack(proc); if(status != 0) goto fork_out; // 3. call copy_mm to dup OR share mm according clone_flag // 对虚拟内存空间进行拷贝，由于在本实验中，内核线程之间共享一个虚拟内存空间，因此实际上该函数不需要进行任何操作 status = copy_mm(clone_flags, proc); if(status != 0) goto fork_out; // 4. call copy_thread to setup tf &amp; context in proc_struct // 在新创建的内核线程的栈上面设置伪造好的中端帧，便于后文中利用iret命令将控制权转移给新的线程 copy_thread(proc, stack, tf); // 5. insert proc_struct into hash_list &amp;&amp; proc_list // 为新的线程创建pid proc-&gt;pid = get_pid(); hash_proc(proc); // 将线程放入使用hash组织的链表中，便于加速以后对某个指定的线程的查找 nr_process ++; // 将全局线程的数目加1 list_add(&amp;proc_list, &amp;proc-&gt;list_link); // 将线程加入到所有线程的链表中，便于进行调度 // 6. call wakeup_proc to make the new child process RUNNABLE // 唤醒该线程，即将该线程的状态设置为可以运行 wakeup_proc(proc); // 7. set ret vaule using child proc&apos;s pid // 返回新线程的pid ret = proc-&gt;pid;fork_out: 请说明ucore是否做到给每个新fork的线程一个唯一的id？请说明你的分析和理由。 可以。ucore中为fork的线程分配pid的函数为get_pid：123456789101112131415161718192021222324252627282930313233// get_pid - alloc a unique pid for processstatic int get_pid(void) &#123; static_assert(MAX_PID &gt; MAX_PROCESS); struct proc_struct *proc; list_entry_t *list = &amp;proc_list, *le; static int next_safe = MAX_PID, last_pid = MAX_PID; if (++ last_pid &gt;= MAX_PID) &#123; last_pid = 1; goto inside; &#125; if (last_pid &gt;= next_safe) &#123; inside: next_safe = MAX_PID; repeat: le = list; while ((le = list_next(le)) != list) &#123; proc = le2proc(le, list_link); if (proc-&gt;pid == last_pid) &#123; if (++ last_pid &gt;= next_safe) &#123; if (last_pid &gt;= MAX_PID) &#123; last_pid = 1; &#125; next_safe = MAX_PID; goto repeat; &#125; &#125; else if (proc-&gt;pid &gt; last_pid &amp;&amp; next_safe &gt; proc-&gt;pid) &#123; next_safe = proc-&gt;pid; &#125; &#125; &#125; return last_pid;&#125; 如果有严格的next_safe &gt; last_pid + 1，那么可以直接取last_pid + 1作为新的pid（需要last_pid没有超出MAX_PID从而变成1），如果在进入函数的时候，这两个变量之后没有合法的取值，也就是说next_safe &gt; last_pid + 1不成立，那么进入循环，在循环之中首先通过if(proc-&gt;pid == last_pid)这一分支确保了不存在任何进程的pid与last_pid重合，然后再通过if (proc-&gt;pid &gt; last_pid &amp;&amp; next_safe &gt; proc-&gt;pid)这一判断语句保证了不存在任何已经存在的pid满足：last_pid&lt; pid &lt; next_safe，这样就确保了最后能够找到这么一个满足条件的区间，获得合法的pid； 练习3：阅读代码，理解 proc_run 函数和它调用的函数如何完成进程切换的。唯一调用到这个函数是在线程调度器的schedule函数中，proc_run将proc加载到CPU12345678910111213141516171819202122// proc_run - make process &quot;proc&quot; running on cpu// NOTE: before call switch_to, should load base addr of &quot;proc&quot;&apos;s new PDTvoid proc_run(struct proc_struct *proc) &#123; // 判断需要运行的线程是否是正在运行的线程 if (proc != current) &#123; bool intr_flag; struct proc_struct *prev = current, *next = proc; //如果不是的话，获取到切换前后的两个线程 local_intr_save(intr_flag); // 关闭中断 &#123; current = proc; load_esp0(next-&gt;kstack + KSTACKSIZE); lcr3(next-&gt;cr3); // 设置了TSS和cr3，相当于是切换了页表和栈 switch_to(&amp;(prev-&gt;context), &amp;(next-&gt;context)); // switch_to恢复要运行的线程的上下文，然后由于恢复的上下文中已经将返回地址（copy_thread函数中完成）修改成了forkret函数的地址(如果这个线程是第一运行的话，否则就是切换到这个线程被切换出来的地址)，也就是会跳转到这个函数，最后进一步跳转到了__trapsret函数，调用iret最终将控制权切换到新的线程； &#125; local_intr_restore(intr_flag); // 使能中断 &#125;&#125; forkret函数：1234567// forkret -- the first kernel entry point of a new thread/process// NOTE: the addr of forkret is setted in copy_thread function// after switch_to, the current proc will execute here.static voidforkret(void) &#123; forkrets(current-&gt;tf);&#125; 在本实验的执行过程中，创建且运行了几个内核线程？ 总共创建了两个内核线程，分别为： idleproc: 最初的内核线程，在完成新的内核线程的创建以及各种初始化工作之后，进入死循环，用于调度其他线程； initproc: 被创建用于打印”Hello World”的线程； 语句 local_intr_save(intr_flag);….local_intr_restore(intr_flag);说明理由在这里有何作用? 请说明理由。 关闭中断，使得在这个语句块内的内容不会被中断打断，是一个原子操作； 在proc_run函数中，将current指向了要切换到的线程，但是此时还没有真正将控制权转移过去，如果在这个时候出现中断打断这些操作，就会出现current中保存的并不是正在运行的线程的中断控制块，从而出现错误。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验二]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[读代码在bootloader进入保护模式前进行探测物理内存分布和大小，基本方式是通过BIOS中断调用，在实模式下完成，在boot/bootasm.S中从probe_memory处到finish_probe处的代码部分完成。以下应该是检测到的物理内存信息：12345678memory management: default_pmm_managere820map: memory: 0009fc00, [00000000, 0009fbff], type = 1. memory: 00000400, [0009fc00, 0009ffff], type = 2. memory: 00010000, [000f0000, 000fffff], type = 2. memory: 07ee0000, [00100000, 07fdffff], type = 1. memory: 00020000, [07fe0000, 07ffffff], type = 2. memory: 00040000, [fffc0000, ffffffff], type = 2. 参考：type是物理内存空间的类型，1是可以使用的，2是暂时不能够使用的。12345678910111213141516171819202122232425262728293031之前是开启A20的16位地址线，实现20位地址访问。通过写键盘控制器8042的64h端口与60h端口。先转成实模式！获取的物理内存信息是用这种结构存的（内存映射地址描述符），一共20字节：struct e820map &#123; int nr_map; struct &#123; uint64_t addr; //8字节，unsigned long long，基地址？ uint64_t size; //8字节，unsigned long long，大小 uint32_t type; //4字节，unsigned long，内存类型 &#125; __attribute__((packed)) map[E820MAX];&#125;;每探测到一块内存空间，对应的内存映射描述符被写入指定表，以下是通过向INT 15h中断传入e820h参数来探测物理内存空间的信息&quot;$&quot;美元符号修饰立即数，&quot;%&quot;修饰寄存器。probe_memory: movl $0, 0x8000 #把0这个立即数写入0x8000地址， xorl %ebx, %ebx #相当于我们设置在0x8000处存放struct e820map, 并清除e820map中的nr_map置0 movw $0x8004, %di #0x8004正好就是第一个内存映射地址描述符的地址，因为nr_map是四个字节start_probe: movl $0xE820, %eax #传入0xE820作为参数， movl $20, %ecx #内存映射地址描述符的大小是20个字节 movl $SMAP, %edx #SMAP之前定义是0x534d4150，不知道何用 int $0x15 #调用INT 15H中断 jnc cont #CF=0,则跳转到cont movw $12345, 0x8000 jmp finish_probecont: addw $20, %di #设置下一个内存映射地址描述符的地址 incl 0x8000 #E820map中的nr_map加一 cmpl $0, %ebx #如果INT0x15返回的ebx为零，表示探测结束，如果还有就继续找 jnz start_probefinish_probe: Below are from CSDN 调用中断int 15h 之前，需要填充如下寄存器： eax int 15h 可以完成许多工作，主要有ax的值决定，我们想要获取内存信息，需要将ax赋值为0E820H。 ebx 放置着“后续值(continuation value)”，第一次调用时ebx必须为0. es:di 指向一个地址范围描述结构 ARDS(Address Range Descriptor Structure), BIOS将会填充此结构。 ecx es:di所指向的地址范围描述结构的大小，以字节为单位。无论es:di所指向的结构如何设置，BIOS最多将会填充ecx字节。不过，通常情况下无论ecx为多大，BIOS只填充20字节，有些BIOS忽略ecx的值，总是填充20字节。 edx 0534D4150h(‘SMAP’)——BIOS将会使用此标志，对调用者将要请求的系统映像信息进行校验，这些信息被BIOS放置到es:di所指向的结构中。 中断调用之后，结果存放于下列寄存器之中。 CF CF=0表示没有错误，否则存在错误。 eax 0534D4150h(‘SMAP’) es:di 返回的地址范围描述符结构指针，和输入值相同。 ecx BIOS填充在地址范围描述符中的字节数量，被BIOS所返回的最小值是20字节。 ebx 这里放置着为等到下一个地址描述符所需要的后续值，这个值得实际形势依赖于具体的BIOS的实现，调用者不必关心它的具体形式，自需在下一次迭代时将其原封不动地放置到ebx中，就可以通过它获取下一个地址范围描述符。如果它的值为0，并且CF没有进位，表示它是最后一个地址范围描述符。 由于一个物理页需要占用一个Page结构的空间，Page结构在设计时须尽可能小，以减少对内存的占用。1234567struct Page &#123; // 描述了一个Page int ref; // 这一页被页表的引用计数，一个页表项设置了一个虚拟页的映射 uint32_t flags; // 描述这个Page的状态，可能每个位表示不同的意思 unsigned int property; // property表示这个块中空闲页的数量，用到此成员变量的这个Page比较特殊， // 是这个连续内存空闲块地址最小的一页（即头一页， Head Page）。 list_entry_t page_link; // 链接比它地址小和大的其他连续内存空闲块。&#125;; flag用到了两个bit123#define PG_reserved 0 // 表明了是否被保留，如果被保留，则bit 0会设置位1，且不能放到空闲列表里#define PG_property 1 // bit 1表示此页是否是free的，如果设置为1，表示这页是free的，可以被分配； // 如果设置为0，表示这页已经被分配出去了，不能被再二次分配。 总结来说：一个页，里边有各种属性和双向链表的指针段 1、ref表示这个页被页表的引用记数，是映射此物理页的虚拟页个数。一旦某页表中有一个页表项设置了虚拟页到这个Page管理的物理页的映射关系，就会把Page的ref加一。反之，若是解除，那就减一。 2、 flags表示此物理页的状态标记，有两个标志位，第一个表示是否被保留，如果被保留了则设为1（比如内核代码占用的空间）。第二个表示此页是否是free的。如果设置为1，表示这页是free的，可以被分配；如果设置为0，表示这页已经被分配出去了，不能被再二次分配。 3、property用来记录某连续内存空闲块的大小，这里需要注意的是用到此成员变量的这个Page一定是连续内存块的开始地址（第一页的地址）。 4、page_link是便于把多个连续内存空闲块链接在一起的双向链表指针，连续内存空闲块利用第一个页的成员变量page_link来链接比它地址小和大的其他连续内存空闲块，用到这个成员变量的是这个块的地址最小的一页。下面简单看看mm/pmm.c中的pmm_init()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* pmm_init - initialize the physical memory management */static voidpage_init(void) &#123; struct e820map *memmap = (struct e820map *)(0x8000 + KERNBASE); uint64_t maxpa = 0; cprintf(&quot;e820map:\n&quot;); int i; for (i = 0; i &lt; memmap-&gt;nr_map; i ++) &#123; uint64_t begin = memmap-&gt;map[i].addr, end = begin + memmap-&gt;map[i].size; cprintf(&quot; memory: %08llx, [%08llx, %08llx], type = %d.\n&quot;, memmap-&gt;map[i].size, begin, end - 1, memmap-&gt;map[i].type); if (memmap-&gt;map[i].type == E820_ARM) &#123; if (maxpa &lt; end &amp;&amp; begin &lt; KMEMSIZE) &#123; maxpa = end; &#125; &#125; &#125; if (maxpa &gt; KMEMSIZE) &#123; maxpa = KMEMSIZE; &#125; extern char end[]; npage = maxpa / PGSIZE; //起始物理内存地址位0，所以需要管理的页个数为npage，需要管理的所有页的大小位sizeof(struct Page)*npage pages = (struct Page *)ROUNDUP((void *)end, PGSIZE); // pages的地址，最末尾地址按照页大小取整。 for (i = 0; i &lt; npage; i ++) &#123; SetPageReserved(pages + i); &#125; //当前的这些页设置为已占用的 uintptr_t freemem = PADDR((uintptr_t)pages + sizeof(struct Page) * npage); // 之前设置了占用的页，那空闲的页就是从（pages+sizeof(struct Page)*npage）以上开始的 for (i = 0; i &lt; memmap-&gt;nr_map; i ++) &#123; uint64_t begin = memmap-&gt;map[i].addr, end = begin + memmap-&gt;map[i].size; if (memmap-&gt;map[i].type == E820_ARM) &#123; if (begin &lt; freemem) &#123; begin = freemem; &#125; if (end &gt; KMEMSIZE) &#123; end = KMEMSIZE; &#125; if (begin &lt; end) &#123; begin = ROUNDUP(begin, PGSIZE); end = ROUNDDOWN(end, PGSIZE); if (begin &lt; end) &#123; init_memmap(pa2page(begin), (end - begin) / PGSIZE); // 通过调用本函数进行空闲的标记 &#125; &#125; &#125; &#125;&#125; SetPageReserved表示把物理地址对应的Page结构中的flags标志设置为PG_reserved ，表示这些页已经被使用了，将来不能被用于分配。而init_memmap函数把空闲物理页对应的Page结构中的flags和引用计数ref清零，并加到free_area.free_list指向的双向列表中。123456789struct pmm_manager &#123; const char *name; //物理内存页管理器的名字 void (*init)(void); //初始化内存管理器 void (*init_memmap)(struct Page *base, size_t n); //初始化管理空闲内存页的数据结构 struct Page *(*alloc_pages)(size_t n); //分配n个物理内存页 void (*free_pages)(struct Page *base, size_t n); //释放n个物理内存页 size_t (*nr_free_pages)(void); //返回当前剩余的空闲页数 void (*check)(void); //用于检测分配/释放实现是否正确&#125;; 12345free_area_t - 维护一个双向链表记录没有用到的Page。typedef struct &#123; list_entry_t free_list; // 整个双向链表的头节点 unsigned int nr_free; // 表示空闲页的数量&#125; free_area_t; 12345typedef struct list_entry list_entry_t;struct list_entry &#123; struct list_entry *prev, *next;&#125;;类似Linux里的双向链表，这只是指针部分，数据部分在其他定义里 练习1 实现first-fit连续物理内存分配算法重写函数: default_init, default_init_memmap,default_alloc_pages, default_free_pages。在实现first_fit的回收函数时，注意连续地址空间之间的合并操作。在遍历空闲页块链表时，需要按照空闲块起始地址来排序，形成一个有序的的链表。 首次适应算法（First Fit）：该算法从空闲分区链首开始查找，直至找到一个能满足其大小要求的空闲分区为止。然后再按照需求的大小，从该分区中划出一块内存分配给请求者，余下的空闲分区仍留在空闲分区链中。多使用内存中低地址部分的空闲区，在高地址部分的空闲区很少被利用，从而保留了高地址部分的空闲区。显然为以后到达的大作业分配大的内存空间创造了条件。但是低地址部分不断被划分，留下许多难以利用、很小的空闲区，每次查找又都从低地址部分开始，会增加查找的开销。 在First Fit算法中，分配器维护一个空闲块列表（free表）。一旦收到内存分配请求，它遍历列表找到第一个满足的块。如果所选块明显大于请求的块，则分开，其余的空间将被添加到列表中下一个free块中。 准备：实现First Fit我们需要使用链表管理空闲块，free_area_t被用来管理free块，首先，找到list.h中的”struct list”。结构”list”是一个简单的双向链表实现。使用”list_init”，”list_add”（”list_add_after”和”list_add_before”），”list_del”，“list_next”，”list_prev”。有一个棘手的方法是将一般的”list”结构转换为一个特殊结构（如struct”page”），使用以下宏：”le2page”（在memlayout.h中）。 “default_init”：重用例子中的”default_init”函数来初始化”free_list”并将”nr_free”设置为0。”free_list”用于记录空闲内存块，”nr_free”是可用内存块的总数。 “default_init_memmap”：调用栈为”kern_init” -&gt; “pmm_init” -&gt; “page_init” -&gt; “init_memmap” -&gt; “pmm_manager” -&gt; “init_memmap”。此函数用于初始化空闲块（使用参数”addr_base”，”page_mumber”）。为了初始化一个空闲块，首先，应该在这个空闲块中初始化每个页面（在memlayout.h中定义）。这个程序包括： 设置”p -&gt; flags”的’PG_property’位，表示该页面为有效。在函数”pmm_init”（在pmm.c中），”p-&gt; flags”的位’PG_reserved”已经设置好了。 如果此页面是free的且不是free区块的第一页，”p-&gt; property”应该设置为0。 如果此页面是free的且是free区块的第一页，”p-&gt; property”应该设置为本空闲块的总页数。 “default_alloc_pages”：在空闲列表中搜索第一个空闲块（块大小&gt;=n），返回该块的地址作为所需的地址. 空闲页管理链表的初始化：12345678static void default_init(void) &#123; list_init(&amp;free_list); nr_free = 0;&#125;static inline void list_init(list_entry_t *elm) &#123; elm-&gt;prev = elm-&gt;next = elm;&#125;把free_list的双向链表中的指针都指向自己，且计数器为0 123456789101112131415161718初始化空闲页链表，初始化每一个空闲页，然后计算空闲页的总数。static void default_init_memmap(struct Page *base, size_t n) &#123; assert(n &gt; 0); struct Page *p = base; for (; p != base + n; p ++) &#123; assert(PageReserved(p)); //这个页是否为保留页,PageReserved(p)返回true才会继续，如果返回true了，说明是保留页 //设置标志位 p-&gt;flags = 0； SetPageProperty(p); p-&gt;property = 0; //应该只有第一个页的这个参数有用 set_page_ref(p, 0);//清空引用，现在是没有虚拟内存引用它的 list_add_before(&amp;free_list, &amp;(p-&gt;page_link));//插入空闲页的链表里面 &#125; nr_free += n; //连续有n个空闲块，空闲链表的个数加n base-&gt;property=n; //连续内存空闲块的大小为n，属于物理页管理链表 //所有的页都在这个双向链表里且只有第0个页有这个块的信息&#125; default_alloc_pages从空闲页链表中查找n个空闲页，如果成功，返回第一个页表的地址。遍历空闲链表，一旦发现有大于等于n的连续空闲页块，便将这n个页从空闲页链表中取出，同时使用SetPageReserved和ClearPageProperty表示该页为使用状态，同时如果该连续页的数目大于n，则从第n+1开始截断，之后为截断的块，重新计算相应的property的值。在贴代码之前先说说几个宏。123456789101112131415161718/* 将这个le转换成一个Page */#define le2page(le, member) \ to_struct((le), struct Page, member) /* * * to_struct - get the struct from a ptr * @ptr: a struct pointer of member * @type: the type of the struct this is embedded in * @member: the name of the member within the struct * 一般用的时候传进来的type是Page类型的，ptr是这个（Page+双向链表的两个指针）块的双向链表指针的开始地址。offsetof算出了page_link在Page中的偏移值，ptr减去双向链表第一个指针的偏移量得到了这个Page的地址 */#define to_struct(ptr, type, member) \ ((type *)((char *)(ptr) - offsetof(type, member)))/* Return the offset of &apos;member&apos; relative to the beginning of a struct type */0不代表具体地址，这个offsetof代表这个member在这个type中的偏移值#define offsetof(type, member) \ ((size_t)(&amp;((type *)0)-&gt;member)) 12345678910111213141516171819202122232425262728293031323334353637static struct Page * default_alloc_pages(size_t n) &#123; assert(n &gt; 0); if (n &gt; nr_free) &#123; return NULL; &#125; // n 一定要大于0，且n要小于当前可用的空闲块数 list_entry_t *le, *len; le = &amp;free_list; struct Page *p=NULL; while((le=list_next(le)) != &amp;free_list) &#123; p = le2page(le, page_link); if(p-&gt;property&gt;=n) break; &#125; //在free_list里遍历每一页，用le2page转换成Page //如果找到了一个property大于n的就说明找到了这个符合要求的块 if(p != NULL)&#123; int i; for(i=0;i&lt;n;i++)&#123; len = list_next(le); struct Page *pp = le2page(le, page_link); SetPageReserved(pp); ClearPageProperty(pp); list_del(le); le = len; &#125; // 如果我现在找到的块是大于n的，那就拆开 if(p-&gt;property&gt;n)&#123; (le2page(le,page_link))-&gt;property = p-&gt;property - n; &#125; ClearPageProperty(p); SetPageReserved(p); nr_free -= n; return p; &#125; return NULL;&#125; default_free_pages将base为起始地址的n个页面放回到free_list中1234567891011121314151617181920212223242526272829303132333435363738394041424344static void default_free_pages(struct Page *base, size_t n) &#123; assert(n &gt; 0); list_entry_t *le = &amp;free_list; struct Page *p = base; //找到比base大的页面地址 while((le=list_next(le)) != &amp;free_list)&#123; p = le2page(le,page_link); if(p &gt; base) break; &#125; //在找到的p之前逐个插入 for(p = base; p &lt; base + n; p ++)&#123; list_add_before(le,&amp;(p-&gt;page_link)); &#125; base-&gt;flags=0; set_page_ref(base,0); ClearPageProperty(base); SetPageProperty(base); base-&gt;property = n; // 清空flag的信息，清空引用的信息，清空property信息，设置这个Page又是可以被引用的了 // 当前的base又是n个空闲块的头 p = le2page(le,page_link); if(base+n==p)&#123; base-&gt;property+=p-&gt;property; p-&gt;property=0; &#125; //看是不是可以跟后边的块恰好连在一起，如果连在一起的话就可以合并了 le=list_prev(&amp;(base-&gt;page_link)); p = le2page(le, page_link); //看是不是可以跟前边的连在一起，如果可以的话这个base就可以把property设成0了 if(le!=&amp;free_list &amp;&amp; p==base-1)&#123; while(le!=&amp;free_list)&#123; if(p-&gt;property)&#123; p-&gt;property+=base-&gt;property; base-&gt;property=0; break; &#125; le = list_prev(le); p=le2page(le,page_link); &#125; &#125; nr_free +=n; cprintf(&quot;release %d page,last %d.\n&quot;,n,nr_free);&#125; 运行中出现提示，表明本题成功：123456789101112131415release 1 page,last 1.release 1 page,last 2.release 1 page,last 3.release 1 page,last 1.release 1 page,last 32291.release 1 page,last 32292.release 1 page,last 32293.release 3 page,last 3.release 1 page,last 1.release 3 page,last 4.release 1 page,last 4.release 2 page,last 4.release 1 page,last 5.release 5 page,last 32293.check_alloc_page() succeeded! first_fit有一种改进，next_fit，第一次找到之后不暂停，第二次找到之后才真正给分配空间。修改比较简单，第一次找到之后记一个flag，下次再找到就可以分配了。 练习二系统执行中的地址映射。mooc中讲到了在段页式管理机制下运行这整个过程中，虚拟地址到物理地址的映射产生了多次变化，实现了最终的段页式映射关系： virt addr = linear addr = phy addr + 0xC0000000第一个阶段（开启保护模式，创建启动段表）是bootloader阶段，即从bootloader的start函数（在boot/bootasm.S中）到执行ucore kernel的kern_entry函数之前，其虚拟地址、线性地址以及物理地址之间的映射关系与lab1的一样，即：virt addr = linear addr = phy addr第二个阶段（创建初始页目录表，开启分页模式）从kern_entry函数开始，到pmm_init函数被执行之前。通过几条汇编指令（在kern/init/entry.S中）使能分页机制，主要做了两件事：12通过movl %eax, %cr3指令把页目录表的起始地址存入CR3寄存器中；通过movl %eax, %cr0指令把cr0中的CR0_PG标志位设置上。 在此之后，进入了分页机制，地址映射关系如下：12virt addr = linear addr = phy addr # 线性地址在0~4MB之内三者的映射关系virt addr = linear addr = phy addr + 0xC0000000 # 线性地址在0xC0000000~0xC0000000+4MB之内三者的映射关系 仅仅比第一个阶段增加了下面一行的0xC0000000偏移的映射，并且作用范围缩小到了0~4M。在下一个节点，会将作用范围继续扩充到0~KMEMSIZE。此时的内核（EIP）还在0~4M的低虚拟地址区域运行，而在之后，这个区域的虚拟内存是要给用户程序使用的。为此，需要使用一个绝对跳转来使内核跳转到高虚拟地址（代码在kern/init/entry.S中）：123456 # update eip # now, eip = 0x1..... leal next, %eax # set eip = KERNBASE + 0x1..... jmp *%eaxnext: 跳转完毕后，通过把boot_pgdir[0]对应的第一个页目录表项（0~4MB）清零来取消了临时的页映射关系：123# unmap va 0 ~ 4M, it&apos;s temporary mappingxorl %eax, %eaxmovl %eax, __boot_pgdir 最终的地址映射关系如下：1lab2 stage 2: virt addr = linear addr = phy addr + 0xC0000000 # 线性地址在0~4MB之内三者的映射关系 第三个阶段（完善段表和页表）从pmm_init函数被调用开始。pmm_init函数将页目录表项补充完成（从0~4M扩充到0~KMEMSIZE）。然后，更新了段映射机制，使用了一个新的段表。这个新段表除了包括内核态的代码段和数据段描述符，还包括用户态的代码段和数据段描述符以及TSS（段）的描述符。理论上可以在第一个阶段，即bootloader阶段就将段表设置完全，然后在此阶段继续使用，但这会导致内核的代码和bootloader的代码产生过多的耦合，于是就有了目前的设计。这时形成了我们期望的虚拟地址、线性地址以及物理地址之间的映射关系：1lab2 stage 3: virt addr = linear addr = phy addr + 0xC0000000 123456789101112131415161718192021222324252627282930请描述页目录项（Pag Director Entry）和页表（Page Table Entry）中每个组成部分的含义和以及对ucore而言的潜在用处。页目录项（Pag Director Entry）每一位的含义：前20位表示4K对齐的该PDE对应的页表起始位置（物理地址，该物理地址的高20位即PDE中的高20位，低12位为0）；第9-11位未被CPU使用，可保留给OS使用；接下来的第8位可忽略；第7位用于设置Page大小，0表示4KB；第6位恒为0；第5位用于表示该页是否被使用过；第4位设置为1则表示不对该页进行缓存；第3位设置是否使用write through缓存写策略；第2位表示该页的访问需要的特权级；第1位表示是否允许读写；第0位为该PDE的存在位；页表项（PTE）中的每项的含义：高20位与PDE相似的，用于表示该PTE指向的物理页的物理地址；9-11位保留给OS使用；7-8位恒为0；第6位表示该页是否为dirty，即是否需要在swap out的时候写回外存；第5位表示是否被访问；3-4位恒为0；0-2位分别表示存在位、是否允许读写、访问该页需要的特权级；PTE和PDE都有一些保留位供操作系统使用，ucore利用保留位来完成一些其他的内存管理相关的算法。当ucore执行过程中出现了页访问异常，硬件需要完成的事情分别如下：- 将发生错误的线性地址保存在cr2寄存器中;- 在中断栈中依次压入EFLAGS，CS, EIP，以及页访问异常码error code，如果pgfault是发生在用户态，则还需要先压入ss和esp，并且切换到内核栈；- 根据中断描述符表查询到对应page fault的处理例程地址如后，跳转到对应处执行。 建立虚拟页和物理页帧的地址映射关系整个页目录表和页表所占空间大小取决与二级页表要管理和映射的物理页数。假定当前物理内存0~16MB，每物理页（也称Page Frame）大小为4KB，则有4096个物理页，也就意味这有4个页目录项和4096个页表项需要设置。一个页目录项（Page Directory Entry，PDE）和一个页表项（Page Table Entry，PTE）占4B。即使是4个页目录项也需要一个完整的页目录表（占4KB）。而4096个页表项需要16KB（即4096*4B）的空间，也就是4个物理页，16KB的空间。所以对16MB物理页建立一一映射的16MB虚拟页，需要4+1=5个物理页，即20KB的空间来形成二级页表。 把0~KERNSIZE（明确ucore设定实际物理内存不能超过KERNSIZE值，即0x38000000字节，896MB，3670016个物理页）的物理地址一一映射到页目录项和页表项的内容，其大致流程如下： 指向页目录表的指针已存储在boot_pgdir变量中。 映射0~4MB的首个页表已经填充好。 调用boot_map_segment函数进一步建立一一映射关系，具体处理过程以页为单位进行设置，即: linear addr = phy addr + 0xC0000000 设一个32bit线性地址la有一个对应的32bit物理地址pa，如果在以la的高10位为索引值的页目录项中的存在位（PTE_P）为0，表示缺少对应的页表空间，则可通过alloc_page获得一个空闲物理页给页表，页表起始物理地址是按4096字节对齐的，这样填写页目录项的内容为： 页目录项内容 = (页表起始物理地址 &amp; ~0x0FFF) | PTE_U | PTE_W | PTE_P 进一步对于页表中以线性地址la的中10位为索引值对应页表项的内容为： 页表项内容 = (pa &amp; ~0x0FFF) | PTE_P | PTE_W 其中： PTE_U：位3，表示用户态的软件可以读取对应地址的物理内存页内容PTE_W：位2，表示物理内存页内容可写PTE_P：位1，表示物理内存页存在 ucore的内存管理经常需要查找页表：给定一个虚拟地址，找出这个虚拟地址在二级页表中对应的项。通过更改此项的值可以方便地将虚拟地址映射到另外的页上。可完成此功能的这个函数是get_pte函数。它的原型为1pte_t *get_pte(pde_t *pgdir, uintptr_t la, bool create) 这里涉及到三个类型pte_t、pde_t和uintptr_t。这三个都是unsigned int类型。pde_t：page directory entry，一级页表的表项。pte_t：page table entry，表示二级页表的表项。uintptr_t：表示为线性地址，由于段式管理只做直接映射，所以它也是逻辑地址。pgdir：给出页表起始地址。通过查找这个页表，我们需要给出二级页表中对应项的地址。可以在需要时再添加对应的二级页表。如果在查找二级页表项时，发现对应的二级页表不存在，则需要根据create参数的值来处理是否创建新的二级页表。如果create参数为0，则get_pte返回NULL；如果create参数不为0，则get_pte需要申请一个新的物理页（通过alloc_page来实现，可在mm/pmm.h中找到它的定义），再在一级页表中添加页目录项指向表示二级页表的新物理页。 注意，新申请的页必须全部设定为零，因为这个页所代表的虚拟地址都没有被映射。 当建立从一级页表到二级页表的映射时，需要注意设置控制位。这里应该设置同时设置上PTE_U、PTE_W和PTE_P（定义可在mm/mmu.h）。如果原来就有二级页表，或者新建立了页表，则只需返回对应项的地址即可。虚拟地址只有映射上了物理页才可以正常的读写。在完成映射物理页的过程中，除了要在页表的对应表项上填上相应的物理地址外，还要设置正确的控制位。 只有当一级二级页表的项都设置了用户写权限后，用户才能对对应的物理地址进行读写。由于一个物理页可能被映射到不同的虚拟地址上去（譬如一块内存在不同进程间共享），当这个页需要在一个地址上解除映射时，操作系统不能直接把这个页回收，而是要先看看它还有没有映射到别的虚拟地址上。这是通过查找管理该物理页的Page数据结构的成员变量ref（用来表示虚拟页到物理页的映射关系的个数）来实现的，如果ref为0了，表示没有虚拟页到物理页的映射关系了，就可以把这个物理页给回收了，从而这个物理页是free的了，可以再被分配。 page_insert函数将物理页映射在了页表上。可参看page_insert函数的实现来了解ucore内核是如何维护这个变量的。当不需要再访问这块虚拟地址时，可以把这块物理页回收并在将来用在其他地方。取消映射由page_remove来做，这其实是page_insert的逆操作。建立好一一映射的二级页表结构后，由于分页机制在前一节所述的前两个阶段已经开启，分页机制到此初始化完毕。当执行完毕gdt_init函数后，新的段页式映射已经建立好了。 预备知识copy完了，上练习二和练习三 练习二代码预备知识不够用了上mmu.h的代码读读1234567891011A linear address &apos;la&apos; has a three-part structure as follows:+--------10------+-------10-------+---------12----------+| Page Directory | Page Table | Offset within Page || Index | Index | |+----------------+----------------+---------------------+ \--- PDX(la) --/ \--- PTX(la) --/ \---- PGOFF(la) ----/ \----------- PPN(la) -----------/The PDX, PTX, PGOFF, and PPN macros decompose linear addresses as shown.To construct a linear address la from PDX(la), PTX(la), and PGOFF(la),use PGADDR(PDX(la), PTX(la), PGOFF(la)). 123456789101112131415161718192021222324252627282930313233343536373839//get_pte - get Page Table Entry and return the kernel virtual address of this Page Table Entry for la// - if the PT contians this Page Table Entry didn&apos;t exist, alloc a page for PT// parameter:// pgdir: the kernel virtual base address of PDT （页目录表的入口）// la: the linear address need to map （线性地址）// create: a logical value to decide if alloc a page for PT// return vaule: the kernel virtual address of this pte （返回这个页表项的虚拟地址）pte_t *get_pte(pde_t *pgdir, uintptr_t la, bool create) &#123;/* * 使用KADDR()获得物理地址 * PDX(la) = 虚拟地址la在page directory entry 的 index * KADDR(pa) : takes a physical address and returns the corresponding kernel virtual address. * set_page_ref(page,1) : means the page be referenced by one time，这一页被引用了 * page2pa(page): get the physical address of memory which this (struct Page *) page manages * 得到这个页管理的内存的物理地址 * struct Page * alloc_page() : allocation a page * memset(void *s, char c, size_t n) : sets the first n bytes of the memory area pointed by s * to the specified value c. * DEFINEs: * PTE_P 0x001 // page table/directory entry flags bit : Present * PTE_W 0x002 // page table/directory entry flags bit : Writeable * PTE_U 0x004 // page table/directory entry flags bit : User can access */ pde_t *pdep = &amp;pgdir[PDX(la)]; // (1) find page directory entry struct Page *page; if (!(*pdep &amp; PTE_P) ) &#123; // (2) check if entry is not present if (!create || (page = alloc_page()) == NULL) &#123; return NULL; &#125; // (3) check if creating is needed, then alloc page for page table // CAUTION: this page is used for page table, not for common data page set_page_ref(page, 1); // (4) set page reference uintptr_t pa = page2pa(page); // (5) get linear address of page memset(KADDR(pa),0,PGSIZE); // (6) clear page content using memset *pdep = pa | PTE_U | PTE_W | PTE_P;// (7) set page directory entry&apos;s permission &#125; return &amp;((pte_t *)KADDR(PDE_ADDR(*pdep)))[PTX(la)]; // (8) return page table entry&#125; 练习三12345678910111213141516171819202122232425262728293031323334353637383940//page_remove_pte - free an Page sturct which is related linear address la// - and clean(invalidate) pte which is related linear address la//note: PT is changed, so the TLB need to be invalidatestatic inline voidpage_remove_pte(pde_t *pgdir, uintptr_t la, pte_t *ptep) &#123; /* LAB2 EXERCISE 3: YOUR CODE * * Please check if ptep is valid, and tlb must be manually updated if mapping is updated * * Maybe you want help comment, BELOW comments can help you finish the code * * Some Useful MACROs and DEFINEs, you can use them in below implementation. * MACROs or Functions: * struct Page *page pte2page(*ptep): get the according page from the value of a ptep * free_page : free a page * page_ref_dec(page) : decrease page-&gt;ref. NOTICE: ff page-&gt;ref == 0 , then this page should be free. * tlb_invalidate(pde_t *pgdir, uintptr_t la) : Invalidate a TLB entry, but only if the page tables being * edited are the ones currently in use by the processor. * DEFINEs: * PTE_P 0x001 // page table/directory entry flags bit : Present */#if 0 if (0) &#123; //(1) check if this page table entry is present struct Page *page = NULL; //(2) find corresponding page to pte //(3) decrease page reference //(4) and free this page when page reference reachs 0 //(5) clear second page table entry //(6) flush tlb &#125;#endif if (*ptep &amp; PTE_P) &#123; // 确保传进来的二级页表时可用的 struct Page *page = pte2page(*ptep);// 获取页表项对应的物理页的Page结构 if (page_ref_dec(page) == 0) &#123; // page_ref_dec被用于page-&gt;ref自减1， // 如果返回值是0，那么就说明不存在任何虚拟页指向该物理页，释放该物理页 free_page(page); &#125; *ptep = 0; // 将PTE的映射关系清空 tlb_invalidate(pgdir, la); // 刷新TLB，确保TLB的缓存中不会有错误的映射关系 &#125;&#125; 问题：12345678数据结构Page的全局变量（其实是一个数组）的每一项与页表中的页目录项和页表项有无对应关系？如果有，其对应关系是啥？存在对应关系：由于页表项中存放着对应的物理页的物理地址，因此可以通过这个物理地址来获取到对应到的Page数组的对应项，具体做法为将物理地址除以一个页的大小，然后乘上一个Page结构的大小获得偏移量，使用偏移量加上Page数组的基地址皆可以或得到对应Page项的地址；如果希望虚拟地址与物理地址相等，则需要如何修改lab2，完成此事？ 鼓励通过编程来具体完成这个问题。由于在完全启动了ucore之后，虚拟地址和线性地址相等，都等于物理地址加上0xc0000000，如果需要虚拟地址和物理地址相等，可以考虑更新gdt，更新段映射，使得virtual address = linear address - 0xc0000000，这样的话就可以实现virtual address = physical address；reference：https://www.jianshu.com/p/abbe81dfe016]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记一]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[第五讲 物理内存管理5.1 计算机体系结构和内存层次一个进程使用内存时要满足其要求，在不用时应及时回收。寄存器是非常小的；内存的最小访问是8bit，一次读写32位的话也要注意对齐问题。高速缓存如果不命中，则到内存中查找，在内存中找不到，就读取到内存中再读取，需要操作系统的介入。内存中每一个字节有一个物理地址，硬盘中扇区512字节最小单位，我们希望将线性的物理内存空间转换成逻辑内存空间；很好的把保护（独立地址空间）和共享（访问相同内存）结合，虚拟化（实现更大的逻辑空间）。操作系统中采用的内存管理：重定位（段地址+offset）、分段（希望他能够不连续，将程序分成三个相对独立的空间，代码数据加堆栈）、分页（把内存分成最基本的单位）。MMU（内存管理单元） 5.2 地址空间和地址生成物理地址空间是硬件支持的地址空间，多少位就是有多少条地址线；逻辑地址是CPU运行时进程看到的地址，对应可执行文件中的区域，进程的逻辑地址空间需要转换成物理地址空间，最后在总线上访问相应的物理单元。逻辑地址生成：将程序转成汇编码，添加逻辑地址，再进行链接，把多个模块和函数库排成线性的序列，在程序加载要进行重定位，把链接时生成的地址进行平移。在编译时，如果已知运行时起始地址，则可以直接生成地址，如果起始地址改变则要重新编译；在加载时也可生成绝对地址，编译器生成可重定位的代码；执行时地址生成出现在使用虚拟存储的情况下，在执行指令时进行地址转换，最灵活，可以移动指令实现虚拟内存。 CPU：ALU需要逻辑地址的内存内容，MMU进行逻辑地址和内存地址的转换，CPU控制逻辑给总线发送物理地址请求，内存发送物理地址的内容给CPU，操作系统建立逻辑地址和物理地址的映射。CPU在执行指令时，如果访问数据段的数据，如果数据段基址+offset超过了数据段，则内存访问异常，执行失败，调用中断处理程序；如果正确那在段基址寄存器配合下得到相应的地址。 5.3 连续内存分配为了提高效率，采用动态分配算法。连续内存分配指给进程分配一块不小于指定大小的连续物理内存区域，会产生一些碎片，一种是两块分配单元之间的未被使用的内存，内部碎片是分配单元内部的未被使用的内存，取决于分配单元大小是否要考虑取整和对齐。动态分区分配是指程序加载时分配一个进程指定大小可变的分区，分配得到的地址是连续的。操作系统维护两个数据结构，一个是所有进程已分配的分区，另一个是空闲分区。动态分区分配策略有很多：最先匹配（从空闲分区列表里找第一个符合的，释放时检查是不是可以和邻近的空闲分区合并，在高地址有大块的空闲分区，但有很多外部碎片，分配大块时较慢）；最佳匹配（全找一遍，找最合适的，空闲分区按照从小往大排序，释放时跟邻近地址的合并，并且重排序，大部分分配的尺寸较小时比较好，避免大的空闲分区被拆分，减小外部碎片，但是增加了无用的小碎片）；最差匹配（找相差最大的，空闲分区从大到小拍，分配时找最大的，释放时检查可否与邻近的空闲分区合并，进行合并并重排序，如果中等大小的分配较多，则最好，避免出现太多小碎片，但是释放分区比较慢，容易破坏大的空闲分区）。 5.4碎片整理调整已分配的进程占用的分区位置来减少或避免分区碎片，通过移动分配给进程的内存分区，以合并外部碎片。保证所有程序可动态重定位！分区对换：通过抢占并回收处于等待状态进程的分区，以增大可用内存空间。采用对换使多个进程同时运行。 5.5 伙伴系统连续内存分配实例。整个可分配的分区约定为2^U，需要的分区大小为2^(U-1) &lt; s &lt; 2^(U)，把整个块分配给这个进程。如s&lt;2^(i-1)-1，将大小为2^i的当前分区划分成2个大小为2^(i-1)的空闲分区，重复划分过程，直到2^(i-1)-1&lt;\s&lt;2^(i)，把一个空闲分区分配给该进程。数据结构：空闲块按照大小和起始地址组织成二维数组，初始时只有一个大小为2^U的块，由小到大在空闲数组找最小的，如果空闲块过大，则进行二等分，直到得到需要的大小是空闲块的1/2还大些。总之，找比它大的最小的空闲块，看是不是比它的二倍大，如果是，就切块，不是的话就分配给它。合并：大小相同且地址相邻，起始地址较小的块的起始地址必须是2^(i+1)的倍数。两个块具有相同大小，且它们物理地址连续。 为了便于页面的维护，将多个页面组成内存块，每个内存块都有 2 的方幂个页，方幂的指数被称为阶 order。order相同的内存块被组织到一个空闲链表中。伙伴系统基于2的方幂来申请释放内存页。当申请内存页时，伙伴系统首先检查与申请大小相同的内存块链表中，检看是否有空闲页，如果有就将其分配出去，并将其从链表中删除，否则就检查上一级，即大小为申请大小的2倍的内存块空闲链表，如果该链表有空闲内存，就将其分配出去，同时将剩余的一部分（即未分配出去的一半）加入到下一级空闲链表中；如果这一级仍没有空闲内存；就检查它的上一级，依次类推，直到分配成功或者彻底失败，在成功时还要按照伙伴系统的要求，将未分配的内存块进行划分并加入到相应的空闲内存块链表在释放内存页时，会检查其伙伴是否也是空闲的，如果是就将它和它的伙伴合并为更大的空闲内存块，该检查会递归进行，直到发现伙伴正在被使用或者已经合并成了最大的内存块。 第六讲 物理内存管理: 非连续内存分配6.1 非连续内存分配的需求背景一种是段，一种是页，还有段页式。非连续分配的目的是提高内存利用效率和管理灵活性： 允许一个程序使用非连续的物理地址空间； 允许共享代码与数据； 支持动态加载和动态链接。如何实现虚拟地址和物理地址的转换？软/硬件。 6.2 段式存储管理段的地址空间是如何组织的，内存访问如何进行。进程的地址空间看成若干个段，主代码段、子模块代码段、公用库代码段、堆栈段、初始化数据段、符号表等。段式管理更精细。把逻辑地址空间转换成一个不连续的物理地址空间集。每一个段是访问方式和存储数据等属性一致的一段地址空间；对应一个连续的内存块，若干个段组成了逻辑地址空间，把逻辑地址分成一个二元组（段号，段内偏移地址），再转换成原来的地址。程序访问物理单元时，首先用段号查段表，找到段的起始地址和长度，硬件的存储管理单元（MMU）检查越界，在MMU里利用段地址和偏移找到实际地址。 6.3 页式存储管理物理内存空间分成“帧”，大小是2的n次幂，让这个转换变得方便，逻辑地址空间里也划分成相同大小的基本分配单位“页”，页面到页帧的转换涉及了“页表”、MMU/TLB。物理地址组织成二元组（帧号，帧内偏移量）。逻辑地址空间也是二元组（p，o），逻辑地址中页号是连续的，物理地址的帧号是不连续的，逻辑地址中页号是p，物理地址的帧号是f，用p到页表中找对应的f，页表中保存了每个页的页表基址，用p就可以找到。每个帧的大小是2的n次方，把f左移s位再把页内偏移加上，就可以找到物理地址。 6.4 页表概述从逻辑页号到物理页号的转换，每一个逻辑页号对应一个物理帧号，且随着程序运行变化，动态调整分配给程序的内存大小。这个表存在页表基址寄存器，告诉你这个页表放在哪。页表项中有帧号f，有几个标志位： 存在位：如果有对应的物理帧则为1；修改位：是否修改对应页面的内容；引用位：在过去一段时间里是否有过引用。 内存访问性能：访问一个内存单元需要2次内存访问，先获取页表项，再访问数据。页表大小问题：页表可能非常大。处理缓存或者间接访问（一个很长的表，多级页表等） 6.5 快表和多级页表快表：缓存近期访问的页表项，在TLB使用关联存储实现，查找对应的key，并行查找表项，具备快速访问性能。如果没有命中只能再次查找内存中的页表并把它加到快表中。多级页表：通过间接引用将页号分为k级。整个访问次数是k+1。建立页表树。先查第一段逻辑地址作为第一级页表的偏移，找到第二级页表的起始，第二段地址作为第二级页表项的偏移，找到第三级页表项的起始。就是说第一段地址是这个页在第一级页表中的偏移，第二段是这个页在第二级页表中的偏移地址。利用多级页表减少了整个页表的长度。 6.6 反置页表对于大地址空间系统，多级页表变得繁琐，让页表项和物理地址空间的大小对应，不让页表项和逻辑地址空间的大小对应。这样进程数目的增加和虚拟地址空间的增大对页表占用空间没影响。页寄存器：每个帧和一个页寄存器关联，寄存器里有：使用位表示此帧是否被使用；占用页号表明对应的页号p，保护位表明使用方式是读或者写。页寄存器中的地址转换：CPU生成的逻辑地址如何找对应的物理地址？对逻辑地址做Hash映射，并解决Hash冲突，利用快表缓存页表项，如果出现冲突，遍历所有的对应页表项，查找失败时产生异常。 6.7 段页式存储管理在段式管理的基础上，给每个段加一级页表，得到段的页表，再得到页的地址。 第七讲 实验二 物理内存管理7.1 x86保护模式的特权级x86的特权级有0，1，2，3，一般只需要0（Kernel）和3（user），有些指令只能在ring 0中执行，CPU在某些情况下也会检查特权级。段选择子位于段寄存器中，程序在代码段中执行，指令执行会访问代码段和数据段。它的DPL位于段描述符中，来进行特权控制。中断门和陷入门中也有对应的DPL。产生中断和内存访问都有对应的CPL和RPL，进行检查确保当前的操作合法。 RPL处于数据段（DS或ES中最低两位），CPL处于指令代码段中（CS最低两位）。数字越低特权级越高，数字越高特权级越低。DPL是要被访问的目标的特权级。访问门时代码段的CPL要小于门的DPL，门的特权级要比较低，执行代码段的特权级比较高，这样才允许通过门（中断陷入什么的）一般特权级的应用程序可以访问处于内核态的操作系统提供的服务；访问段的时候CPL和RPL中的最大值小于DPL，即发出请求的特权级要高于对应目标，DPL的特权级要比较小。 7.2 了解特权级切换过程通过中断切换特权级。有一个中断门，通过中断描述符表进行切换，如果产生了中断，内核态ring 0中的栈会压入一系列东西（当前执行的程序的堆栈信息SS，ESP，EFLAGS，保存了回去的地址CS，EIP等）以便恢复现场。如何回到ring3？如果是从ring0跳到ring3的，在栈中会存SS（RPL=3）和ESP，用户的ss和内核态的ss不是同一个数据段，这是特权级的转换，内核栈把数据弹出来了。通过构造一个能返回ring3的栈，再通过iret指令把相关信息弹出栈，这时候运行环境已经变成用户态。从ring3到ring0的转换，建立中断门，一旦产生中断需要保存一些信息。通过对堆栈修改，使其执行完iret后留在ring0执行，修改CS使其指向内核态的代码段。TSS是特殊段，任务状态段，在内存中，保存了不同特权级的堆栈信息。在全局描述符表中有一个专门指向这个TSS。硬件有一个专门的寄存器缓存TSS中的内容，建立TSS是在pmm.c中。 7.3 了解段/页表x86内存管理单元MMU有一系列寄存器和段描述符，寄存器里的信息最高端的十几位作为索引来找全局描述符表（GDT）里的一项，找对应的项，一项就是一个段描述符，描述了地址和基址，base address+EIP这个offset找到最终的线性地址。 如果没有页机制的话，线性地址就是物理地址。MMU放在内存中，每次访问要先查找GDT（段表），靠硬件实现把建立在GDT里的段描述符的相关信息放在一些寄存器中的隐藏部分，缓存了基址和段大小等隐藏信息，放在CPU内部的。在entry.S中建立了映射机制，lab1建立的是对等映射，而lab2中base_address是 -0xC0000000，虚地址比线性地址大0xC0000000.只是这个用到的映射关系（放在GDT中的信息）不同。 7.4 了解UCORE建立段/页表一个虚拟地址它分了三块，一个典型的二级页表是32位的地址，第一个是Offset，占了12位，中间的二级页表对应的页表项占了10位，高的页目录项也占了10位。那么高的这10位是用来作为index查找这个页目录表里面的对应的项，这叫PDE，是页目录的entry，PDE记录的是二级页表里面的起始地址。所以说根据PDE里面的信息可以找到Page Table的起始地址。同时根据第二级Table这里面的10位作为index来查这个Page Table对应的项。称之为PTE。这个PTE就是Page Table Entry。存的是这个线性地址它所对应的一个页的起始地址。这一个页大小多其实由它的Offset可以算出来，12位意味着一个页的大小是4k。base_address加上offset得到了地址。进入保护模式后段机制一定存在，为了保护。根据地址的前10位找到Page Table的物理地址，中间12位找到PDE，计算物理页的基址。利用PDE和PTE加上offset算出地址。CR3寄存器保存了页目录地址。 CR0的31位如果置1的话就打开了页机制。页的基址、页表的基址都是20位，剩下12位存下了一些信息（只读？用户态或内核态）分配一个4k的页作为页目录的Table，清理这个Page做初始化，建立页表，在页目录表和页表中填好对应信息。0xC0000000到0xF8000000这块空间会映射到物理地址的0x00000000到0x38000000这么一个地址，它的偏移值是0xC0000000，链接时用到的起始地址就是0xC0000000，把0x00000000到0x00100000映射到0x00100000的对等映射，且把CR0的31位置1，即enable了页机制，需要UPDATE GDT，使段机制的不对等映射变成对等映射，又做了取消0x00000000到0x00100000映射的操作。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验七]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%B8%83%2F</url>
    <content type="text"><![CDATA[实验七：同步互斥实验目的 理解操作系统的同步互斥的设计实现； 理解底层支撑技术：禁用中断、定时器、等待队列； 在ucore中理解信号量（semaphore）机制的具体实现； 理解管程机制，在ucore内核中增加基于管程（monitor）的条件变量（condition variable）的支持； 了解经典进程同步问题，并能使用同步机制解决进程同步问题。 实验内容lab6已经可以调度运行多个进程，如果多个进程需要协同操作或访问共享资源，则存在如何同步和有序竞争的问题。本次实验，主要是熟悉ucore的进程同步机制—信号量（semaphore）机制，以及基于信号量的哲学家就餐问题解决方案。然后掌握管程的概念和原理，并参考信号量机制，实现基于管程的条件变量机制和基于条件变量来解决哲学家就餐问题。 在本次实验中，在kern/sync/check_sync.c中提供了一个基于信号量的哲学家就餐问题解法。同时还需完成练习，即实现基于管程（主要是灵活运用条件变量和互斥信号量）的哲学家就餐问题解法。 哲学家就餐问题描述如下：有五个哲学家，他们的生活方式是交替地进行思考和进餐。哲学家们公用一张圆桌，周围放有五把椅子，每人坐一把。在圆桌上有五个碗和五根筷子，当一个哲学家思考时，他不与其他人交谈，饥饿时便试图取用其左、右最靠近他的筷子，但他可能一根都拿不到。只有在他拿到两根筷子时，方能进餐，进餐完后，放下筷子又继续思考。 同步互斥的设计与实现实验执行流程概述互斥是指某一资源同时只允许一个进程对其进行访问，具有唯一性和排它性，但互斥不用限制进程对资源的访问顺序，即访问可以是无序的。同步是指在进程间的执行必须严格按照规定的某种先后次序来运行，即访问是有序的，这种先后次序取决于要系统完成的任务需求。在进程写资源情况下，进程间要求满足互斥条件。在进程读资源情况下，可允许多个进程同时访问资源。 实验七设计实现了多种同步互斥手段，包括时钟中断管理、等待队列、信号量、管程机制（包含条件变量设计）等，并基于信号量实现了哲学家问题的执行过程。而本次实验的练习是要求用管程机制实现哲学家问题的执行过程。在实现信号量机制和管程机制时，需要让无法进入临界区的进程睡眠，为此在ucore中设计了等待队列wait_queue。当进程无法进入临界区（即无法获得信号量）时，可让进程进入等待队列，这时的进程处于等待状态（也可称为阻塞状态），从而会让实验六中的调度器选择一个处于就绪状态（即RUNNABLE_STATE）的进程，进行进程切换，让新进程有机会占用CPU执行，从而让整个系统的运行更加高效。 lab7/kern/sync/check_sync.c中的check_sync函数可以理解为是实验七的起始执行点，是实验七的总控函数。进一步分析此函数，可以看到这个函数主要分为了两个部分，第一部分是实现基于信号量的哲学家问题，第二部分是实现基于管程的哲学家问题。 对于check_sync函数的第一部分，首先实现初始化了一个互斥信号量，然后创建了对应5个哲学家行为的5个信号量，并创建5个内核线程代表5个哲学家，每个内核线程完成了基于信号量的哲学家吃饭睡觉思考行为实现。 对于check_sync函数的第二部分，首先初始化了管程，然后又创建了5个内核线程代表5个哲学家，每个内核线程要完成基于管程的哲学家吃饭、睡觉、思考的行为实现。 同步互斥的底层支撑由于调度的存在，且进程在访问某类资源暂时无法满足的情况下会进入等待状态，导致了多进程执行时序的不确定性和潜在执行结果的不确定性。为了确保执行结果的正确性，本试验需要设计更加完善的进程等待和互斥的底层支撑机制，确保能正确提供基于信号量和条件变量的同步互斥机制。 由于有定时器、屏蔽/使能中断、等待队列wait_queue支持test_and_set_bit等原子操作机器指令（在本次实验中没有用到）的存在，使得我们在实现进程等待、同步互斥上得到了极大的简化。下面将对定时器、屏蔽/使能中断和等待队列进行进一步讲解。 定时器在传统的操作系统中，定时器提供了基于时间事件的调度机制。在ucore中，两次时间中断之间的时间间隔为一个时间片，timer splice。 基于此时间单位，操作系统得以向上提供基于时间点的事件，并实现基于时间长度的睡眠等待和唤醒机制。在每个时钟中断发生时，操作系统产生对应的时间事件。 sched.h, sched.c定义了有关timer的各种相关接口来使用 timer 服务，其中主要包括: typedef struct {……} timer_t：定义了 timer_t 的基本结构，其可以用 sched.h 中的timer_init函数对其进行初始化。 void timer_init(timer t *timer, struct proc_struct *proc, int expires): 对某定时器进行初始化，让它在expires时间片之后唤醒proc进程。 void add_timer(timer t *timer)：向系统添加某个初始化过的timer_t，该定时器在指定时间后被激活，并将对应的进程唤醒至runnable（如果当前进程处在等待状态）。 void del_timer(timer_t *time)：向系统删除（或者说取消）某一个定时器。该定时器在取消后不会被系统激活并唤醒进程。 void run_timer_list(void)：更新当前系统时间点，遍历当前所有处在系统管理内的定时器，找出所有应该激活的计数器，并激活它们。该过程在且只在每次定时器中断时被调用。在ucore中，其还会调用调度器事件处理程序。 一个 timer_t 在系统中的存活周期可以被描述如下： timer_t在某个位置被创建和初始化，并通过add_timer加入系统管理列表中； 系统时间被不断累加，直到 run_timer_list 发现该 timer_t到期； run_timer_list更改对应的进程状态，并从系统管理列表中移除该timer_t； 屏蔽与使能中断之前用过，这里简单看看。 在ucore中提供的底层机制包括中断屏蔽/使能控制等。kern/sync.c有开关中断的控制函数local_intr_save(x)和local_intr_restore(x)，它们是基于kern/driver文件下的intr_enable()、intr_disable()函数实现的。具体调用关系为： 关中断：local_intr_save –&gt; __intr_save –&gt; intr_disable –&gt; cli开中断：local_intr_restore –&gt; __intr_restore –&gt; intr_enable –&gt; sti 最终的cli和sti是x86的机器指令，最终实现了关（屏蔽）中断和开（使能）中断，即设置了eflags寄存器中与中断相关的位。通过关闭中断，可以防止对当前执行的控制流被其他中断事件处理所打断。既然不能中断，那也就意味着在内核运行的当前进程无法被打断或被重新调度，即实现了对临界区的互斥操作。所以在单处理器情况下，可以通过开关中断实现对临界区的互斥保护，需要互斥的临界区代码的一般写法为：12345local_intr_save(intr_flag);&#123; 临界区代码&#125;local_intr_restore(intr_flag); 但是，在多处理器情况下，这种方法是无法实现互斥的，因为屏蔽了一个CPU的中断，只能阻止本地CPU上的进程不会被中断或调度，并不意味着其他CPU上执行的进程不能执行临界区的代码。所以，开关中断只对单处理器下的互斥操作起作用。 等待队列在课程中提到用户进程或内核线程可以转入等待状态以等待某个特定事件（比如睡眠,等待子进程结束,等待信号量等），当该事件发生时这些进程能够被再次唤醒。内核实现这一功能的一个底层支撑机制就是等待队列wait_queue，等待队列和每一个事件（睡眠结束、时钟到达、任务完成、资源可用等）联系起来。需要等待事件的进程在转入休眠状态后插入到等待队列中。当事件发生之后，内核遍历相应等待队列，唤醒休眠的用户进程或内核线程，并设置其状态为就绪状态（PROC_RUNNABLE），并将该进程从等待队列中清除。 ucore在kern/sync/{ wait.h, wait.c }中实现了等待项wait结构和等待队列wait queue结构以及相关函数），这是实现ucore中的信号量机制和条件变量机制的基础，进入wait queue的进程会被设为等待状态（PROC_SLEEPING），直到他们被唤醒。 数据结构定义123456789101112typedef struct &#123; struct proc_struct *proc; //等待进程的指针 uint32_t wakeup_flags; //进程被放入等待队列的原因标记 wait_queue_t *wait_queue; //指向此wait结构所属于的wait_queue list_entry_t wait_link; //用来组织wait_queue中wait节点的连接&#125; wait_t;typedef struct &#123; list_entry_t wait_head; //wait_queue的队头&#125; wait_queue_t;le2wait(le, member) //实现wait_t中成员的指针向wait_t 指针的转化 相关函数说明与wait和wait queue相关的函数主要分为两层，底层函数是对wait queue的初始化、插入、删除和查找操作，相关函数如下： wait_init：初始化wait结构，将放入等待队列的原因标记设置为WT_INTERRUPTED，意为可以被打断等待状态123456voidwait_init(wait_t *wait, struct proc_struct *proc) &#123; wait-&gt;proc = proc; wait-&gt;wakeup_flags = WT_INTERRUPTED; list_init(&amp;(wait-&gt;wait_link));&#125; wait_in_queue：wait是否在wait queue中1234boolwait_in_queue(wait_t *wait) &#123; return !list_empty(&amp;(wait-&gt;wait_link));&#125; wait_queue_init：初始化wait_queue结构1234voidwait_queue_init(wait_queue_t *queue) &#123; list_init(&amp;(queue-&gt;wait_head));&#125; wait_queue_add：设置当前等待项wait的等待队列，并把wait前插到wait queue中123456voidwait_queue_add(wait_queue_t *queue, wait_t *wait) &#123; assert(list_empty(&amp;(wait-&gt;wait_link)) &amp;&amp; wait-&gt;proc != NULL); wait-&gt;wait_queue = queue; list_add_before(&amp;(queue-&gt;wait_head), &amp;(wait-&gt;wait_link));&#125; wait_queue_del：从wait queue中删除wait12345voidwait_queue_del(wait_queue_t *queue, wait_t *wait) &#123; assert(!list_empty(&amp;(wait-&gt;wait_link)) &amp;&amp; wait-&gt;wait_queue == queue); list_del_init(&amp;(wait-&gt;wait_link));&#125; wait_queue_next：取得wait_queue中wait等待项的后一个链接指针123456789wait_t *wait_queue_next(wait_queue_t *queue, wait_t *wait) &#123; assert(!list_empty(&amp;(wait-&gt;wait_link)) &amp;&amp; wait-&gt;wait_queue == queue); list_entry_t *le = list_next(&amp;(wait-&gt;wait_link)); if (le != &amp;(queue-&gt;wait_head)) &#123; return le2wait(le, wait_link); &#125; return NULL;&#125; wait_queue_prev：取得wait_queue中wait等待项的前一个链接指针123456789wait_t *wait_queue_prev(wait_queue_t *queue, wait_t *wait) &#123; assert(!list_empty(&amp;(wait-&gt;wait_link)) &amp;&amp; wait-&gt;wait_queue == queue); list_entry_t *le = list_prev(&amp;(wait-&gt;wait_link)); if (le != &amp;(queue-&gt;wait_head)) &#123; return le2wait(le, wait_link); &#125; return NULL;&#125; wait_queue_first：取得wait queue的第一个wait12345678wait_t *wait_queue_first(wait_queue_t *queue) &#123; list_entry_t *le = list_next(&amp;(queue-&gt;wait_head)); if (le != &amp;(queue-&gt;wait_head)) &#123; return le2wait(le, wait_link); &#125; return NULL;&#125; wait_queue_last：取得wait queue的最后一个wait12345678wait_t *wait_queue_last(wait_queue_t *queue) &#123; list_entry_t *le = list_prev(&amp;(queue-&gt;wait_head)); if (le != &amp;(queue-&gt;wait_head)) &#123; return le2wait(le, wait_link); &#125; return NULL;&#125; bool wait_queue_empty：wait queue是否为空1234boolwait_queue_empty(wait_queue_t *queue) &#123; return list_empty(&amp;(queue-&gt;wait_head));&#125; 高层函数基于底层函数实现了让进程进入等待队列–wait_current_set，以及从等待队列中唤醒进程–wakeup_wait，相关函数如下： wait_current_set：进程进入等待队列，当前进程的状态设置成睡眠12345678voidwait_current_set(wait_queue_t *queue, wait_t *wait, uint32_t wait_state) &#123; assert(current != NULL); wait_init(wait, current); current-&gt;state = PROC_SLEEPING; current-&gt;wait_state = wait_state; wait_queue_add(queue, wait);&#125; wait_current_del：把与当前进程关联的wait从等待队列queue中删除123456#define wait_current_del(queue, wait) \ do &#123; \ if (wait_in_queue(wait)) &#123; \ wait_queue_del(queue, wait); \ &#125; \ &#125; while (0) wakeup_wait：唤醒等待队列上的wait所关联的进程12345678voidwakeup_wait(wait_queue_t *queue, wait_t *wait, uint32_t wakeup_flags, bool del) &#123; if (del) &#123; wait_queue_del(queue, wait); &#125; wait-&gt;wakeup_flags = wakeup_flags; wakeup_proc(wait-&gt;proc);&#125; void wakeup_first：唤醒等待队列上第一个的等待的进程1234567voidwakeup_first(wait_queue_t *queue, uint32_t wakeup_flags, bool del) &#123; wait_t *wait; if ((wait = wait_queue_first(queue)) != NULL) &#123; wakeup_wait(queue, wait, wakeup_flags, del); &#125;&#125; wakeup_queue：唤醒等待队列上的所有等待进程12345678910111213141516voidwakeup_queue(wait_queue_t *queue, uint32_t wakeup_flags, bool del) &#123; wait_t *wait; if ((wait = wait_queue_first(queue)) != NULL) &#123; if (del) &#123; do &#123; wakeup_wait(queue, wait, wakeup_flags, 1); &#125; while ((wait = wait_queue_first(queue)) != NULL); &#125; else &#123; do &#123; wakeup_wait(queue, wait, wakeup_flags, 0); &#125; while ((wait = wait_queue_next(queue, wait)) != NULL); &#125; &#125;&#125; 信号量信号量是一种同步互斥机制的实现，普遍存在于现在的各种操作系统内核里。相对于spinlock 的应用对象，信号量的应用对象是在临界区中运行的时间较长的进程。等待信号量的进程需要睡眠来减少占用 CPU 的开销。1234567891011121314151617181920struct semaphore &#123; int count; queueType queue;&#125;;void semWait(semaphore s)&#123; s.count--; if (s.count &lt; 0) &#123; /* place this process in s.queue */; /* block this process */; &#125;&#125;void semSignal(semaphore s)&#123; s.count++; if (s.count&lt;= 0) &#123; /* remove a process P from s.queue */; /* place process P on ready list */; &#125;&#125; 基于上诉信号量实现可以认为，当多个（&gt;1）进程可以进行互斥或同步合作时，一个进程会由于无法满足信号量设置的某条件而在某一位置停止，直到它接收到一个特定的信号（表明条件满足了）。为了发信号，需要使用一个称作信号量的特殊变量。为通过信号量s传送信号，信号量的V操作采用进程可执行原语semSignal(s)；为通过信号量s接收信号，信号量的P操作采用进程可执行原语semWait(s)；如果相应的信号仍然没有发送，则进程被阻塞或睡眠，直到发送完为止。ucore中信号量参照上述原理描述，建立在开关中断机制和wait_queue的基础上进行了具体实现。信号量的数据结构定义如下：1234typedef struct &#123; int value; //信号量的当前值 wait_queue_t wait_queue; //信号量对应的等待队列&#125; semaphore_t; semaphore_t是最基本的记录型信号量（record semaphore)结构，包含了用于计数的整数值value，和一个进程等待队列wait_queue，一个等待的进程会挂在此等待队列上。 在ucore中最重要的信号量操作是P操作函数down(semaphore_t *sem)和V操作函数up(semaphore_t *sem)。但这两个函数的具体实现是__down(semaphore_t *sem, uint32_t wait_state)函数和__up(semaphore_t *sem, uint32_t wait_state)函数，二者的具体实现描述如下： __down(semaphore_t *sem, uint32_t wait_state, timer_t *timer)：具体实现信号量的P操作，首先关掉中断，然后判断当前信号量的value是否大于0。如果是&gt;0，则表明可以获得信号量，故让value减一，并打开中断返回即可；如果不是&gt;0，则表明无法获得信号量，故需要将当前的进程加入到等待队列中，并打开中断，然后运行调度器选择另外一个进程执行。如果被V操作唤醒，则把自身关联的wait从等待队列中删除（此过程需要先关中断，完成后开中断）。 __up(semaphore_t *sem, uint32_t wait_state)：具体实现信号量的V操作，首先关中断，如果信号量对应的wait queue中没有进程在等待，直接把信号量的value加一，然后开中断返回；如果有进程在等待且进程等待的原因是semophore设置的，则调用wakeup_wait函数将waitqueue中等待的第一个wait删除，且把此wait关联的进程唤醒，最后开中断返回。 对照信号量的原理性描述和具体实现，可以发现二者在流程上基本一致，只是具体实现采用了关中断的方式保证了对共享资源的互斥访问，通过等待队列让无法获得信号量的进程睡眠等待。另外，我们可以看出信号量的计数器value具有有如下性质： value&gt;0，表示共享资源的空闲数 vlaue&lt;0，表示该信号量的等待队列里的进程数 value=0，表示等待队列为空 管程和条件变量原理回顾引入了管程是为了将对共享资源的所有访问及其所需要的同步操作集中并封装起来。Hansan为管程所下的定义：“一个管程定义了一个数据结构和能为并发进程所执行（在该数据结构上）的一组操作，这组操作能同步进程和改变管程中的数据”。有上述定义可知，管程由四部分组成： 管程内部的共享变量； 管程内部的条件变量； 管程内部并发执行的进程； 对局部于管程内部的共享数据设置初始值的语句。 局限在管程中的数据结构，只能被局限在管程的操作过程所访问，任何管程之外的操作过程都不能访问它；另一方面，局限在管程中的操作过程也主要访问管程内的数据结构。由此可见，管程相当于一个隔离区，它把共享变量和对它进行操作的若干个过程围了起来，所有进程要访问临界资源时，都必须经过管程才能进入，而管程每次只允许一个进程进入管程，从而需要确保进程之间互斥。 但在管程中仅仅有互斥操作是不够用的。进程可能需要等待某个条件Cond为真才能继续执行。如果采用忙等(busy waiting)方式：1while not( Cond ) do &#123;&#125; 在单处理器情况下，将会导致所有其它进程都无法进入临界区使得该条件Cond为真，该管程的执行将会发生死锁。为此，可引入条件变量（Condition Variables，简称CV）。一个条件变量CV可理解为一个进程的等待队列，队列中的进程正等待某个条件Cond变为真。每个条件变量关联着一个条件，如果条件Cond不为真，则进程需要等待，如果条件Cond为真，则进程可以进一步在管程中执行。需要注意当一个进程等待一个条件变量CV（即等待Cond为真），该进程需要退出管程，这样才能让其它进程可以进入该管程执行，并进行相关操作，比如设置条件Cond为真，改变条件变量的状态，并唤醒等待在此条件变量CV上的进程。因此对条件变量CV有两种主要操作： wait_cv： 被一个进程调用，以等待断言Pc被满足后该进程可恢复执行. 进程挂在该条件变量上等待时，不被认为是占用了管程。 signal_cv：被一个进程调用，以指出断言Pc现在为真，从而可以唤醒等待断言Pc被满足的进程继续执行。 “哲学家就餐”实例有了互斥和信号量支持的管程就可用用了解决各种同步互斥问题。“用管程解决哲学家就餐问题”如下：1234567891011121314151617181920212223242526272829303132monitor dp&#123; enum &#123;THINKING, HUNGRY, EATING&#125; state[5]; condition self[5]; void pickup(int i) &#123; state[i] = HUNGRY; test(i); if (state[i] != EATING) self[i].wait_cv(); &#125; void putdown(int i) &#123; state[i] = THINKING; test((i + 4) % 5); test((i + 1) % 5); &#125; void test(int i) &#123; if ((state[(i + 4) % 5] != EATING) &amp;&amp; (state[i] == HUNGRY) &amp;&amp; (state[(i + 1) % 5] != EATING)) &#123; state[i] = EATING; self[i].signal_cv(); &#125; &#125; initialization code() &#123; for (int i = 0; i &lt; 5; i++) state[i] = THINKING; &#125;&#125; 关键数据结构虽然大部分教科书上说明管程适合在语言级实现比如java等高级语言，没有提及在采用C语言的OS中如何实现。下面我们将要尝试在ucore中用C语言实现采用基于互斥和条件变量机制的管程基本原理。ucore中的管程机制是基于信号量和条件变量来实现的。ucore中的管程的数据结构monitor_t定义如下：123456789typedef struct monitor&#123; semaphore_t mutex; // the mutex lock for going into the routines in monitor, should be initialized to 1 // the next semaphore is used to // (1) procs which call cond_signal funciton should DOWN next sema after UP cv.sema // OR (2) procs which call cond_wait funciton should UP next sema before DOWN cv.sema semaphore_t next; int next_count; // the number of of sleeped procs which cond_signal funciton condvar_t *cv; // the condvars in monitor&#125; monitor_t; 管程中的成员变量mutex是一个二值信号量，是实现每次只允许一个进程进入管程的关键元素，确保了互斥访问性质。管程中的条件变量cv通过执行wait_cv，会使得等待某个条件Cond为真的进程能够离开管程并睡眠，且让其他进程进入管程继续执行；而进入管程的某进程设置条件Cond为真并执行signal_cv时，能够让等待某个条件Cond为真的睡眠进程被唤醒，从而继续进入管程中执行。 注意：管程中的成员变量信号量next和整型变量next_count是配合进程对条件变量cv的操作而设置的，这是由于发出signal_cv的进程A会唤醒由于wait_cv而睡眠的进程B，由于管程中只允许一个进程运行，所以进程B执行会导致唤醒进程B的进程A睡眠，直到进程B离开管程，进程A才能继续执行，这个同步过程是通过信号量next完成的；而next_count表示了由于发出singal_cv而睡眠的进程个数。管程中的条件变量的数据结构condvar_t定义如下：12345typedef struct condvar&#123; semaphore_t sem; // the sem semaphore is used to down the waiting proc, and the signaling proc should up the waiting proc int count; // the number of waiters on condvar monitor_t * owner; // the owner(monitor) of this condvar&#125; condvar_t; 条件变量的定义中也包含了一系列的成员变量，信号量sem用于让发出wait_cv操作的等待某个条件Cond为真的进程睡眠，而让发出signal_cv操作的进程通过这个sem来唤醒睡眠的进程。count表示等在这个条件变量上的睡眠进程的个数。owner表示此条件变量的宿主是哪个管程。 条件变量的signal和wait的设计理解了数据结构的含义后，我们就可以开始管程的设计实现了。ucore设计实现了条件变量wait_cv操作和signal_cv操作对应的具体函数，即cond_wait函数和cond_signal函数，此外还有cond_init初始化函数。 首先来看wait_cv的原理实现：1234567cv.count++;if(monitor.next_count &gt; 0) sem_signal(monitor.next);else sem_signal(monitor.mutex);sem_wait(cv.sem);cv.count -- ; 对照着可分析出cond_wait函数的具体执行过程。可以看出如果进程A执行了cond_wait函数，表示此进程等待某个条件Cond不为真，需要睡眠。因此表示等待此条件的睡眠进程个数cv.count要加一。接下来会出现两种情况。情况一：如果monitor.next_count如果大于0，表示有大于等于1个进程执行cond_signal函数且睡了，就睡在了monitor.next信号量上（假定这些进程挂在monitor.next信号量相关的等待队列Ｓ上），因此需要唤醒等待队列Ｓ中的一个进程B；然后进程A睡在cv.sem上。如果进程A醒了，则让cv.count减一，表示等待此条件变量的睡眠进程个数少了一个，可继续执行了！ 这里隐含这一个现象，即某进程A在时间顺序上先执行了cond_signal，而另一个进程B后执行了cond_wait，这会导致进程A没有起到唤醒进程B的作用。 问题: 在cond_wait有sem_signal(mutex)，但没有看到哪里有sem_wait(mutex)，这好像没有成对出现，是否是错误的？ 答案：其实在管程中的每一个函数的入口处会有wait(mutex)，这样二者就配好对了。 情况二：如果monitor.next_count如果小于等于0，表示目前没有进程执行cond_signal函数且睡着了，那需要唤醒的是由于互斥条件限制而无法进入管程的进程，所以要唤醒睡在monitor.mutex上的进程。然后进程A睡在cv.sem上，如果睡醒了，则让cv.count减一，表示等待此条件的睡眠进程个数少了一个，可继续执行了！然后来看signal_cv的原理实现：123456if( cv.count &gt; 0) &#123; monitor.next_count ++; sem_signal(cv.sem); sem_wait(monitor.next); monitor.next_count -- ;&#125; 对照着可分析出cond_signal函数的具体执行过程。首先进程B判断cv.count，如果不大于0，则表示当前没有执行cond_wait而睡眠的进程，因此就没有被唤醒的对象了，直接函数返回即可；如果大于0，这表示当前有执行cond_wait而睡眠的进程A，因此需要唤醒等待在cv.sem上睡眠的进程A。由于只允许一个进程在管程中执行，所以一旦进程B唤醒了别人（进程A），那么自己就需要睡眠。故让monitor.next_count加一，且让自己（进程B）睡在信号量monitor.next上。如果睡醒了，这让monitor.next_count减一。 管程中函数的入口出口设计为了让整个管程正常运行，还需在管程中的每个函数的入口和出口增加相关操作，即：1234567891011function_in_monitor （…）&#123; sem.wait(monitor.mutex);//----------------------------- the real body of function;//----------------------------- if(monitor.next_count &gt; 0) sem_signal(monitor.next); else sem_signal(monitor.mutex);&#125; 这样带来的作用有两个，（1）只有一个进程在执行管程中的函数。（2）避免由于执行了cond_signal函数而睡眠的进程无法被唤醒。对于第二点，如果进程A由于执行了cond_signal函数而睡眠（这会让monitor.next_count大于0，且执行sem_wait(monitor.next)），则其他进程在执行管程中的函数的出口，会判断monitor.next_count是否大于0，如果大于0，则执行sem_signal(monitor.next)，从而执行了cond_signal函数而睡眠的进程被唤醒。上诉措施将使得管程正常执行。 练习1：理解内核级信号量的实现和基于内核级信号量的哲学家就餐问题首先把trap.c中处理时钟中断的时候调用的sched_class_proc_tick函数替换为run_timer_list函数（后者中已经包括了前者），用于支持定时器机制； 在sem.c定义了内核级信号量机制的函数，先来学习这个文件。sem.h中是定义，这个semphore_t结构体就是信号量的定义了。里边有一个value和一个队列。123456789101112131415161718#ifndef __KERN_SYNC_SEM_H__#define __KERN_SYNC_SEM_H__#include &lt;defs.h&gt;#include &lt;atomic.h&gt;#include &lt;wait.h&gt;typedef struct &#123; int value; wait_queue_t wait_queue;&#125; semaphore_t;void sem_init(semaphore_t *sem, int value);void up(semaphore_t *sem);void down(semaphore_t *sem);bool try_down(semaphore_t *sem);#endif /* !__KERN_SYNC_SEM_H__ */ sem_init对信号量进行初始化，信号量包括了一个整型数值变量和一个等待队列，该函数将该变量设置为指定的初始值（有几个资源），并且将等待队列初始化即可；wait_queue_init是把这个队列初始化。12345678910voidsem_init(semaphore_t *sem, int value) &#123; sem-&gt;value = value; wait_queue_init(&amp;(sem-&gt;wait_queue));&#125;voidwait_queue_init(wait_queue_t *queue) &#123; list_init(&amp;(queue-&gt;wait_head));&#125; __up: 这个函数是释放一个该信号量对应的资源，如果它的等待队列中没有等待的请求，则直接把资源数加一，返回即可；如果在等待队列上有等在这个信号量上的进程，则调用wakeup_wait将其唤醒执行；在函数中禁用了中断，保证了操作的原子性，函数中操作的具体流程为：12345678910111213141516171819static __noinline void __up(semaphore_t *sem, uint32_t wait_state) &#123; bool intr_flag; local_intr_save(intr_flag); &#123; wait_t *wait; //查询等待队列是否为空 if ((wait = wait_queue_first(&amp;(sem-&gt;wait_queue))) == NULL) &#123; sem-&gt;value ++; //如果是空的话，没有等待的线程，给整型变量加1； &#125; else &#123; //如果等待队列非空，有等待的线程，取出其中的一个进程唤醒； assert(wait-&gt;proc-&gt;wait_state == wait_state); wakeup_wait(&amp;(sem-&gt;wait_queue), wait, wait_state, 1); //这个函数找到等待的线程并唤醒 &#125; &#125; local_intr_restore(intr_flag);&#125; __down: 是原理课中的P操作，表示请求一个该信号量对应的资源，同样禁用中断，保证原子性。首先查询整型变量看是否大于0，如果大于0则表示存在可分配的资源，整型变量减1，直接返回；如果整型变量小于等于0，表示没有可用的资源，那么当前进程的需求得不到满足，因此在wait_current_set中将其状态改为SLEEPING态，然后调用wait_queue_add将其挂到对应信号量的等待队列中，调用schedule函数进行调度，让出CPU，在资源得到满足，重新被唤醒之后，将自身从等待队列上删除掉；12345678910111213141516171819202122232425262728293031323334static __noinline uint32_t __down(semaphore_t *sem, uint32_t wait_state) &#123; bool intr_flag; local_intr_save(intr_flag); if (sem-&gt;value &gt; 0) &#123; sem-&gt;value --; local_intr_restore(intr_flag); return 0; &#125; wait_t __wait, *wait = &amp;__wait; wait_current_set(&amp;(sem-&gt;wait_queue), wait, wait_state); // 挂起这个等待线程并加入等待队列 local_intr_restore(intr_flag); schedule(); local_intr_save(intr_flag); wait_current_del(&amp;(sem-&gt;wait_queue), wait); local_intr_restore(intr_flag);// 有可能当前线程被唤醒的原因跟之前等待的原因不一致// 要把原因返回，由高层判断是否是合理状态。 if (wait-&gt;wakeup_flags != wait_state) &#123; return wait-&gt;wakeup_flags; &#125; return 0;&#125;voidwait_current_set(wait_queue_t *queue, wait_t *wait, uint32_t wait_state) &#123; assert(current != NULL); wait_init(wait, current); current-&gt;state = PROC_SLEEPING; current-&gt;wait_state = wait_state; wait_queue_add(queue, wait);&#125; try_down: 简化版的P操作，如果资源数大于0则分配，资源数小于0也不进入等待队列，即使获取资源失败也不会堵塞当前进程；123456789bool try_down(semaphore_t *sem) &#123; bool intr_flag, ret = 0; local_intr_save(intr_flag); if (sem-&gt;value &gt; 0) &#123; sem-&gt;value --, ret = 1; &#125; local_intr_restore(intr_flag); return ret;&#125; 请在实验报告中给出给用户态进程/线程提供信号量机制的设计方案，并比较说明给内核级提供信号量机制的异同。 用于保证操作原子性的禁用中断机制、以及CPU提供的Test and Set指令机制都只能在用户态下运行，为了方便起见，可以将信号量机制的实现放在OS中来提供，然后使用系统调用的方法统一提供出若干个管理信号量的系统调用，分别如下所示： 申请创建一个信号量的系统调用，可以指定初始值，返回一个信号量描述符(类似文件描述符)； 将指定信号量执行P操作； 将指定信号量执行V操作； 将指定信号量释放掉； 给内核级线程提供信号量机制和给用户态进程/线程提供信号量机制的异同点在于： 相同点：提供信号量机制的代码实现逻辑是相同的；不同点：由于实现原子操作的中断禁用、Test and Set指令等均需要在内核态下运行，因此提供给用户态进程的信号量机制是通过系统调用来实现的，而内核级线程只需要直接调用相应的函数就可以了； 练习2: 完成内核级条件变量和基于内核级条件变量的哲学家就餐问题首先掌握管程机制，然后基于信号量实现完成条件变量实现，然后用管程机制实现哲学家就餐问题的解决方案（基于条件变量）。 In [OS CONCEPT] 7.7 section, the accurate define and approximate implementation of MONITOR was introduced.INTRODUCTION:通常，管程是一种语言结构，编译器通常会强制执行互斥。 将其与信号量进行比较，信号量通常是OS构造。DEFNIE &amp; CHARACTERISTIC:管程是组合在一起的过程、变量和数据结构的集合。进程可以调用监视程序但无法访问内部数据结构。管程中一次只能有一个进程处于活动状态。条件变量允许阻塞和解除阻塞。 cv.wait() 阻塞一个进程 该过程等待条件变量cv。 cv.signal() (也视为 cv.notify) 解除一个等待条件变量cv的进程的阻塞状态。 发生这种情况时，我们仍然需要在管程中只有一个进程处于活动状态。 这可以通过以下几种方式完成： 在某些系统上，旧进程（执行信号的进程）离开管程，新进程进入 在某些系统上，信号必须是管程内执行的最后一个语句。 在某些系统上，旧进程将阻塞，直到管程再次可用。 在某些系统上，新进程（未被信号阻止的进程）将保持阻塞状态，直到管程再次可用。如果在没有人等待的情况下发出条件变量信号，则信号丢失。 将此与信号量进行比较，其中信号将允许将来执行等待的进程无阻塞。不应该将条件变量视为传统意义上的变量。它没有价值。将其视为OOP意义上的对象。它有两种方法，wait和signal来操纵调用过程。定义如下，mutex保证对操作的互斥访问，这些访问主要是对共享变量的访问，所以需要互斥；cv是条件变量。12345678monitor mt &#123; ----------------variable------------------ semaphore mutex; semaphore next; int next_count; condvar &#123;int count, sempahore sem&#125; cv[N]; other variables in mt;&#125; 实现如下：12345678910111213typedef struct condvar&#123; semaphore_t sem; // the sem semaphore is used to down the waiting proc, // and the signaling proc should up the waiting proc int count; // the number of waiters on condvar monitor_t * owner; // the owner(monitor) of this condvar&#125; condvar_t;typedef struct monitor&#123; semaphore_t mutex; // the mutex lock for going into the routines in monitor, should be initialized to 1 semaphore_t next; // the next semaphore is used to down the signaling proc itself, // and the other OR wakeuped waiting proc should wake up the sleeped signaling proc. int next_count; // the number of of sleeped signaling proc condvar_t *cv; // the condvars in monitor&#125; monitor_t; 这是一个管程里的操作，首先在操作开始和结束有wait和signal，保证对中间的访问是互斥的，条件不满足则执行wait执行等待。特殊信号量next和后边的if-else是有对应关系的。1234567891011--------routines in monitor---------------routineA_in_mt () &#123; wait(mt.mutex); ... real body of routineA ... if(next_count&gt;0) signal(mt.next); else signal(mt.mutex);&#125; 条件变量是管程的重要组成部分。cond_wait: 一个条件得不到满足，则睡眠，如果这个条件得到满足，则另一个进程调用signal唤醒这个进程。该函数的功能为将当前进程等待在指定信号量上。等待队列的计数加1，然后释放管程的锁或者唤醒一个next上的进程来释放锁（否则会造成管程被锁死无法继续访问，同时这个操作不能和前面的等待队列计数加1的操作互换顺序，要不不能保证共享变量访问的互斥性），然后把自己等在条件变量的等待队列上，直到有signal信号将其唤醒，正常退出函数；12345678910--------condvar wait/signal---------------cond_wait (cv) &#123; cv.count ++; if(mt.next_count&gt;0) signal(mt.next) else signal(mt.mutex); wait(cv.sem);//由于条件不满足，则wait，这里时cv的sem cv.count --; &#125; 实现：12345678910111213141516171819// Suspend calling thread on a condition variable waiting for condition Atomically unlocks// mutex and suspends calling thread on conditional variable after waking up locks mutex. Notice: mp is mutex semaphore for monitor&apos;s proceduresvoidcond_wait (condvar_t *cvp) &#123; //LAB7 EXERCISE1: YOUR CODE cprintf(&quot;cond_wait begin: cvp %x, cvp-&gt;count %d, cvp-&gt;owner-&gt;next_count %d\n&quot;, cvp, cvp-&gt;count, cvp-&gt;owner-&gt;next_count); cvp-&gt;count ++; if (cvp-&gt;owner-&gt;next_count &gt; 0) &#123; up(&amp;cvp-&gt;owner-&gt;next); &#125; else &#123; up(&amp;cvp-&gt;owner-&gt;mutex); &#125; down(&amp;cvp-&gt;sem); cvp-&gt;count --; cprintf(&quot;cond_wait end: cvp %x, cvp-&gt;count %d, cvp-&gt;owner-&gt;next_count %d\n&quot;, cvp, cvp-&gt;count, cvp-&gt;owner-&gt;next_count);&#125; cond_signal: 将指定条件变量上等待队列中的一个线程进行唤醒，并且将控制权转交给这个进程。判断当前的条件变量的等待队列是否大于0，即队列上是否有正在等待的进程，如果没有则不需要进行任何操作；如果有正在等待的进程，则将其中的一个唤醒，这里的等待队列是使用了一个信号量来进行实现的，由于信号量中已经包括了对等待队列的操作，因此要进行唤醒只需要对信号量执行up操作即可；接下来当前进程为了将控制权转交给被唤醒的进程，将自己等待到了这个条件变量所述的管程的next信号量上，这样的话就可以切换到被唤醒的进程。 有线程处于等待时，它的cv.count大于0，会有进一步的操作，唤醒其他进程，自身处于睡眠状态。上边的wait如果A进程中monitor.next_count大于0，那么可以唤醒monitor.next，正好与这里的wait对应。123456789如果cv.count大于0，有线程正在等待，把线程A从等待队列中移除，并唤醒线程A。在A的real_body之后的那个signal是唤醒B的实际函数。这里的next_count是发出条件变量signal的线程的个数。当B发出了条件变量signal操作，且把自身置成睡眠状态，使得被唤醒的A有机会在它自己退出的时候唤醒B。这是因为A和B都是在管程中执行的函数，都会涉及到对共享变量的访问，但是只允许一个进程对共享变量访问，保证互斥！ cond_signal(cv) &#123; if(cv.count&gt;0) &#123; mt.next_count ++; signal(cv.sem); wait(mt.next); mt.next_count--; &#125; &#125; 实现：123456789101112131415// Unlock one of threads waiting on the condition variable.voidcond_signal (condvar_t *cvp) &#123; //LAB7 EXERCISE1: YOUR CODE cprintf(&quot;cond_signal begin: cvp %x, cvp-&gt;count %d, cvp-&gt;owner-&gt;next_count %d\n&quot;, cvp, cvp-&gt;count, cvp-&gt;owner-&gt;next_count); if(cvp-&gt;count&gt;0) &#123; cvp-&gt;owner-&gt;next_count ++; up(&amp;cvp-&gt;sem); down(&amp;cvp-&gt;owner-&gt;next); cvp-&gt;owner-&gt;next_count --; &#125; cprintf(&quot;cond_signal end: cvp %x, cvp-&gt;count %d, cvp-&gt;owner-&gt;next_count %d\n&quot;, cvp, cvp-&gt;count, cvp-&gt;owner-&gt;next_count);&#125; 哲学家就餐问题：phi_take_forks_condvar表示指定的哲学家尝试获得自己所需要进餐的两把叉子，如果不能获得则阻塞。首先给管程上锁，将哲学家的状态修改为HUNGER，判断当前哲学家是否可以获得足够的资源进行就餐，即判断与之相邻的哲学家是否正在进餐；如果能够进餐，将自己的状态修改成EATING，然后释放锁，离开管程即可；如果不能进餐，等待在自己对应的条件变量上，等待相邻的哲学家释放资源的时候将自己唤醒；最终具体的代码实现如下：1234567891011121314151617181920212223void phi_take_forks_condvar(int i) &#123;//--------into routine in monitor-------------- // LAB7 EXERCISE1: YOUR CODE // I am hungry // try to get fork//--------leave routine in monitor-------------- down(&amp;(mtp-&gt;mutex)); state_condvar[i]=HUNGRY; if(state_condvar[(i+4)%5]!=EATING &amp;&amp; state_condvar[(i+1)%5]!=EATING)&#123; state_condvar[i]=EATING; &#125; else &#123; cprintf(&quot;phi_take_forks_condvar: %d didn’t get fork and will wait\n&quot;, i); cond_wait(mtp-&gt;cv + i); &#125; if(mtp-&gt;next_count&gt;0) up(&amp;(mtp-&gt;next)); else up(&amp;(mtp-&gt;mutex));&#125; phi_put_forks_condvar函数则是释放当前哲学家占用的叉子，并且唤醒相邻的因为得不到资源而进入等待的哲学家。首先获取管程的锁，将自己的状态修改成THINKING，检查相邻的哲学家是否在自己释放了叉子的占用之后满足了进餐的条件，如果满足，将其从等待中唤醒（使用cond_signal）；释放锁，离开管程；12345678910111213141516void phi_put_forks_condvar(int i) &#123;//--------into routine in monitor-------------- // LAB7 EXERCISE1: YOUR CODE // I ate over // test left and right neighbors//--------leave routine in monitor-------------- down(&amp;(mtp-&gt;mutex)); state_condvar[i] = THINKING; cprintf(&quot;phi_put_forks_condvar: %d finished eating\n&quot;, i); phi_test_condvar((i + N - 1) % N); phi_test_condvar((i + 1) % N); if(mtp-&gt;next_count&gt;0) up(&amp;(mtp-&gt;next)); else up(&amp;(mtp-&gt;mutex));&#125; phi_test_sema检查了第i个哲学家左右两边的人是不是处于EATING状态，如果都不是的话，而且第i个人又是HUNGRY的，则唤醒第i个。1234567891011#define LEFT (i-1+N)%N /* i的左邻号码 */#define RIGHT (i+1)%N /* i的右邻号码 */void phi_test_sema(i) /* i：哲学家号码从0到N-1 */&#123; if(state_sema[i]==HUNGRY&amp;&amp;state_sema[LEFT]!=EATING &amp;&amp;state_sema[RIGHT]!=EATING) &#123; state_sema[i]=EATING; up(&amp;s[i]); &#125;&#125; 请在实验报告中给出给用户态进程/线程提供条件变量机制的设计方案，并比较说明给内核级 提供条件变量机制的异同。 本实验中管程的实现中互斥访问的保证是完全基于信号量的，如果根据上文中的说明使用系统调用实现用户态的信号量的实现机制，那么就可以按照相同的逻辑在用户态实现管程机制和条件变量机制；]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验一]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%B8%80%2F</url>
    <content type="text"><![CDATA[操作系统镜像文件ucore.img是如何一步一步生成的？(需要比较详细地解释Makefile中每一条相关命令和命令参数的含义，以及说明命令导致的结果)用make “V=”看到了所有的编译命令第178行 create ucore.img，可以看到call函数，totarget = $(addprefix $(BINDIR)$(SLASH),$(1))这样就调用了addprefix，把$(BINDIR)$(SLASH)变成$(1)的前缀，在makefile里再把$(1)调用call变成要生成的文件，这里需要bootblock和kernel。bootblock需要一些.o文件，makefile里的foreach有如下格式：$(foreach &lt; var &gt;,&lt; list &gt;,&lt; text &gt;)这个函数的意思是，把参数&lt; list &gt;;中的单词逐一取出放到参数&lt; var &gt;所指定的变量中，然后再执行&lt; text&gt;;所包含的表达式。每一次&lt; text &gt;会返回一个字符串，循环过程中，&lt; text &gt;的所返回的每个字符串会以空格分隔，最后当整个循环结束时，&lt; text &gt;所返回的每个字符串所组成的整个字符串（以空格分隔）将会是foreach函数的返回值。 通过看makefile生成的编译命令，生成bootasm.o需要bootasm.S1gcc -Iboot/ -fno-builtin -Wall -ggdb -m32 -gstabs -nostdinc -fno-stack-protector -Ilibs/ -Os -nostdinc -c boot/bootasm.S -o obj/boot/bootasm.o 参考：-ggdb 生成可供gdb使用的调试信息。这样才能用qemu+gdb来调试bootloader or ucore。-m32 生成适用于32位环境的代码。我们用的模拟硬件是32bit的80386，所以ucore也要是32位。-gstabs 生成stabs格式的调试信息。这样要ucore的monitor可以显示出便于开发者阅读的函数调用-nostdinc 不使用标准库。标准库是给应用程序用的，我们是编译ucore内核，OS内核是提供服务的，所以所有的服务要自给自足。-fno-stack-protector 不生成用于检测缓冲区溢出的代码。这是for 应用程序的，我们是编译内核，ucore内核好像还用不到此功能。-Os 为减小代码大小而进行优化。根据硬件spec，主引导扇区只有512字节，我们写的简单bootloader的最终大小不能大于510字节。-I&lt; dir &gt; 添加搜索头文件的路径1ld -m elf_i386 -nostdlib -N -e start -Ttext 0x7C00 obj/boot/bootasm.o obj/boot/bootmain.o -o obj/bootblock.o 参考：-m 模拟为i386上的连接器-nostdlib 不使用标准库-N 设置代码段和数据段均可读写-e 指定入口-Ttext 制定代码段开始位置 1234567891011kernel = $(call totarget,kernel)$(kernel): tools/kernel.ld$(kernel): $(KOBJS) @echo + ld $@ $(V)$(LD) $(LDFLAGS) -T tools/kernel.ld -o $@ $(KOBJS) @$(OBJDUMP) -S $@ &gt; $(call asmfile,kernel) @$(OBJDUMP) -t $@ | $(SED) &apos;1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d&apos; &gt; $(call symfile,kernel)$(call create_target,kernel) 编译命令：1gcc -Ikern/trap/ -fno-builtin -Wall -ggdb -m32 -gstabs -nostdinc -fno-stack-protector -Ilibs/ -Ikern/debug/ -Ikern/driver/ -Ikern/trap/ -Ikern/mm/ -c kern/trap/trapentry.S -o obj/kern/（o文件） 链接器：1ld -m elf_i386 -nostdlib -T tools/kernel.ld -o bin/kernel obj/kern/init/init.o obj/kern/libs/stdio.o obj/kern/libs/readline.o obj/kern/debug/panic.o obj/kern/debug/kdebug.o obj/kern/debug/kmonitor.o obj/kern/driver/clock.o obj/kern/driver/console.o obj/kern/driver/picirq.o obj/kern/driver/intr.o obj/kern/trap/trap.o obj/kern/trap/vectors.o obj/kern/trap/trapentry.o obj/kern/mm/pmm.o obj/libs/string.o obj/libs/printfmt.o dd： dd：用指定大小的块拷贝一个文件，并在拷贝的同时进行指定的转换。 注意：指定数字的地方若以下列字符结尾，则乘以相应的数字：b=512；c=1；k=1024；w=2 参数注释： if=文件名：输入文件名，缺省为标准输入。即指定源文件。&lt; if=input file &gt; of=文件名：输出文件名，缺省为标准输出。即指定目的文件。&lt; of=output file &gt; ibs=bytes：一次读入bytes个字节，即指定一个块大小为bytes个字节。 obs=bytes：一次输出bytes个字节，即指定一个块大小为bytes个字节。 bs=bytes：同时设置读入/输出的块大小为bytes个字节。 cbs=bytes：一次转换bytes个字节，即指定转换缓冲区大小。 skip=blocks：从输入文件开头跳过blocks个块后再开始复制。 seek=blocks：从输出文件开头跳过blocks个块后再开始复制。 注意：通常只用当输出文件是磁盘或磁带时才有效，即备份到磁盘或磁带时才有效。 count=blocks：仅拷贝blocks个块，块大小等于ibs指定的字节数。 conv=conversion：用指定的参数转换文件。 ascii：转换ebcdic为ascii ebcdic：转换ascii为ebcdic ibm：转换ascii为alternate ebcdic block：把每一行转换为长度为cbs，不足部分用空格填充 unblock：使每一行的长度都为cbs，不足部分用空格填充 lcase：把大写字符转换为小写字符 ucase：把小写字符转换为大写字符 swab：交换输入的每对字节 noerror：出错时不停止 notrunc：不截短输出文件 sync：将每个输入块填充到ibs个字节，不足部分用空（NUL）字符补齐。12345678生成一个有10000个块的文件，用0填充（答案中说，每个块默认512字节，但是可能要有bs参数指定或者bs默认就是512？）dd if=/dev/zero of=bin/ucore.img count=10000把bootblock中的内容写到第一个块dd if=bin/bootblock of=bin/ucore.img conv=notrunc从第二个块开始写kernel中的内容dd if=bin/kernel of=bin/ucore.img seek=1 conv=notrunc 一个被系统认为是符合规范的硬盘主引导扇区的特征是什么？上课讲过，合法的主引导扇区最后两个字节有特定值0x55、0xAA123buf一共512个字节buf[510] = 0x55;buf[511] = 0xAA; 练习2：12345file bin/kernelset architecture i8086target remote :1234b *0x7c00continue 在gdb中输入命令，输出2条instruction1x /2i $pc 跟bootasm.S里的汇编代码一致！amazing1234567891011121314(gdb) x /2i $pc=&gt; 0x7c00: cli 0x7c01: cld (gdb) x /10i $pc=&gt; 0x7c00: cli 0x7c01: cld 0x7c02: xor %ax,%ax 0x7c04: mov %ax,%ds 0x7c06: mov %ax,%es 0x7c08: mov %ax,%ss 0x7c0a: in $0x64,%al 0x7c0c: test $0x2,%al 0x7c0e: jne 0x7c0a 0x7c10: mov $0xd1,%al 在Makefile的debug选项中加入-d in_asm -D q.log，可以生成一个q.log里边是执行的汇编命令（部分）12345678910111213141516171819202122----------------IN:0xfffffff0: ljmp $0xf000,$0xe05b----------------IN:0x000fe05b: cmpl $0x0,%cs:0x6c480x000fe062: jne 0xfd2e1----------------IN:0x000fe066: xor %dx,%dx0x000fe068: mov %dx,%ss----------------IN:0x000fe06a: mov $0x7000,%esp----------------IN:0x000fe070: mov $0xf3691,%edx0x000fe076: jmp 0xfd165 练习3分析bootloader进入保护模式的过程。（要求在报告中写出分析）BIOS将通过读取硬盘主引导扇区到内存，并转跳到对应内存中的位置执行bootloader。请分析bootloader是如何完成从实模式进入保护模式的。1lab1/boot/bootasm.S 类似之前，从0x7c00进入，首先12345678910.globl startstart: .code16 cli ;禁止中断发生 cld ;CLD与STD是用来操作方向标志位DF。CLD使DF复位，即D ;F=0，STD使DF置位，即DF=1.用于串操作指令中。 xorw %ax, %ax ;ax置0 movw %ax, %ds ;其他寄存器也清空 movw %ax, %es movw %ax, %ss .globl指示告诉汇编器，_start这个符号要被链接器用到，所以要在目标文件的符号表中标记它是一个全局符号（在第 5.1 节 “目标文件”详细解释）。_start就像C程序的main函数一样特殊，是整个程序的入口，链接器在链接时会查找目标文件中的_start符号代表的地址，把它设置为整个程序的入口地址，所以每个汇编程序都要提供一个_start符号并且用.globl声明。如果一个符号没有用.globl声明，就表示这个符号不会被链接器用到。开启A20：到了80286，系统的地址总线有原来的20根发展为24根，这样能够访问的内存可以达到2^24=16M。Intel在设计80286时提出的目标是向下兼容。所以，在实模式下，系统所表现的行为应该和8086/8088所表现的完全一样，也就是说，在实模式下，80286以及后续系列，应该和8086/8088完全兼容。但最终，80286芯片却存在一个BUG：因为有了80286有A20线，如果程序员访问100000H-10FFEFH之间的内存，系统将实际访问这块内存，而不是象8086/8088一样从0开始。为了解决上述兼容性问题，IBM使用键盘控制器上剩余的一些输出线来管理第21根地址线（从0开始数是第20根） 的有效性，被称为A20 Gate: 如果A20 Gate被打开，则当程序员给出100000H-10FFEFH之间的地址的时候，系统将真正访问这块内存区域； 如果A20 Gate被禁止，则当程序员给出100000H-10FFEFH之间的地址的时候，系统仍然使用8086/8088的方式即取模方式（8086仿真）。绝大多数IBM PC兼容机默认的A20 Gate是被禁止的。现在许多新型PC上存在直接通过BIOS功能调用来控制A20 Gate的功能。123456789101112131415seta20.1: inb $0x64, %al ;0x64里的数据放到al中，即从I/O端口读取一个字节(BYTE,;HALF-WORD) testb $0x2, %al ;检测 jnz seta20.1 ;等到这个端口不忙，没有东西传进来 movb $0xd1, %al ; 0xd1 写到 0x64 outb %al, $0x64 ;写8042输出端口seta20.2: inb $0x64, %al testb $0x2, %al jnz seta20.2 ;等不忙 movb $0xdf, %al ;打开A20 0xdf -&gt; port 0x60 outb %al, $0x60 ;0xdf = 11011111 初始化GDT表并打开保护模式12345lgdt gdtdesc ;让CPU读取gdtr_addr所指向内存内容保存到GDT内存当中movl %cr0, %eax ;cr0寄存器PE位or置1orl $CR0_PE_ON, %eax movl %eax, %cr0ljmp $PROT_MODE_CSEG, $protcseg ;长跳改cs，基于段机制的寻址 最后初始化堆栈、寄存器，调用bootmain12345678910111213protcseg: # 初始化寄存器 movw $PROT_MODE_DSEG, %ax # Our data segment selector movw %ax, %ds # -&gt; DS: Data Segment movw %ax, %es # -&gt; ES: Extra Segment movw %ax, %fs # -&gt; FS movw %ax, %gs # -&gt; GS movw %ax, %ss # -&gt; SS: Stack Segment # Set up the stack pointer and call into C. The stack region is from 0--start(0x7c00) movl $0x0, %ebp movl $start, %esp call bootmain 练习四对于bootmain.c，它唯一的工作就是从硬盘的第一个扇区启动格式为ELF的内核镜像；控制从boot.S文件开始–这个文件设置了保护模式和一个栈，这样C代码就可以运行了，然后再调用bootmain()。 对x86.h头文件有：http://www.codeforge.cn/read/234474/x86.h__html1234567891011static inline ucharinb(ushort port)&#123; uchar data; asm volatile(&quot;in %1,%0&quot; : &quot;=a&quot; (data) : &quot;d&quot; (port)); //对应 in port,data return data; &#125; 0x1F7：读 用来存放读操作后的状态readsect(void *dst, uint32_t secno)从secno扇区读取数据到dst 用汇编的方式实现读取1000号逻辑扇区开始的8个扇区IDE通道的通讯地址是0x1F0 - 0x1F7其中0x1F3 - 0x1F6 4个字节的端口是用来写入LBA地址的LBA就是 logical Block Address1000的16进制就是0x3E8向0x1F3 - 0x1F6写入 0x3E8向0x1F2这个地址写入扇区数量，也就是8向0X1F7写入要执行的操作命令码，对读操作的命令码是 0x20123456out 0x1F3 0x00out 0x1F4 0x00out 0x1F5 0x03out 0x1F6 0xE8out 0x1F2 0x08out 0x1F7 0x20 outb的定义在x86.h中，封装out命令，将data输出到port端口1234567static inline voidoutb(ushort port, uchar data)&#123; asm volatile(&quot;out %0,%1&quot; : : &quot;a&quot; (data), &quot;d&quot; (port)); &#125; 业界共同推出了 LBA48，采用 48 个比特来表示逻辑扇区号。如此一来，就可以管理131072 TB 的硬盘容量了。在这里我们采用将采用 LBA28 来访问硬盘。第1步：设置要读取的扇区数量。这个数值要写入0x1f2端口。这是个8位端口，因此每次只能读写255个扇区：123mov dx,0x1f2mov al,0x01 ;1 个扇区out dx,al 注意：如果写入的值为 0，则表示要读取 256 个扇区。每读一个扇区，这个数值就减一。因此，如果在读写过程中发生错误，该端口包含着尚未读取的扇区数。 第2步：设置起始LBA扇区号。扇区的读写是连续的，因此只需要给出第一个扇区的编号就可以了。28 位的扇区号太长，需要将其分成 4 段，分别写入端口 0x1f3、0x1f4、0x1f5 和 0x1f6 号端口。其中，0x1f3 号端口存放的是 0～7 位；0x1f4 号端口存放的是 8～15 位；0x1f5 号端口存放的是 16～23 位，最后 4 位在 0x1f6 号端口。 第3步:向端口 0x1f7 写入 0x20，请求硬盘读。 第4步:等待读写操作完成。端口0x1f7既是命令端口，又是状态端口。在通过这个端口发送读写命令之后，硬盘就忙乎开了。在它内部操作期间，它将 0x1f7 端口的第7位置“1”，表明自己很忙。一旦硬盘系统准备就绪，它再将此位清零，说明自己已经忙完了，同时将第3位置“1”，意思是准备好了，请求主机发送或者接收数据。 第5步:连续取出数据。0x1f0 是硬盘接口的数据端口，而且还是一个16位端口。一旦硬盘控制器空闲，且准备就绪，就可以连续从这个端口写入或者读取数据。 12345678outb(0x1F2, 1); // 读取第一个数据块outb(0x1F3, secno &amp; 0xFF);outb(0x1F4, (secno &gt;&gt; 8) &amp; 0xFF);outb(0x1F5, (secno &gt;&gt; 16) &amp; 0xFF);outb(0x1F6, ((secno &gt;&gt; 24) &amp; 0xF) | 0xE0);outb(0x1F7, 0x20); // cmd 0x20 - read sectorsinsl(0x1F0, dst, SECTSIZE / 4) // 第五步 readseg函数简单包装了readsect，可以从设备读取任意长度的内容。1234567891011static void readseg(uintptr_t va, uint32_t count, uint32_t offset) &#123; uintptr_t end_va = va + count; va -= offset % SECTSIZE; uint32_t secno = (offset / SECTSIZE) + 1; // 看是第几块，加1因为0扇区被引导占用,ELF文件从1扇区开始 for (; va &lt; end_va; va += SECTSIZE, secno ++) &#123; readsect((void *)va, secno);//调用之前的封装函数对每一块进行处理 &#125;&#125; 对不同的文件，执行file命令如下：1234567891011file link.o link.o: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), not stripped file libfoo.so libfoo.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=871ecaf438d2ccdcd2e54cd8158b9d09a9f971a7, not stripped file p1p1: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=37f75ef01273a9c77f4b4739bcb7b63a4545d729, not stripped file libfoo.so libfoo.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, BuildID[sha1]=871ecaf438d2ccdcd2e54cd8158b9d09a9f971a7, stripped 以下是主函数。12345678910111213141516171819202122232425262728bootmain(void) &#123; // read the 1st page off disk readseg((uintptr_t)ELFHDR, SECTSIZE * 8, 0); // 看是不是标准的elf if (ELFHDR-&gt;e_magic != ELF_MAGIC) &#123; goto bad; &#125; struct proghdr *ph, *eph; // elf头中有elf文件应该加载到什么位置，将表头地址存在ph中 ph = (struct proghdr *)((uintptr_t)ELFHDR + ELFHDR-&gt;e_phoff); eph = ph + ELFHDR-&gt;e_phnum; for (; ph &lt; eph; ph ++) &#123; readseg(ph-&gt;p_va &amp; 0xFFFFFF, ph-&gt;p_memsz, ph-&gt;p_offset); &#125; // 找到内核的入口，这个函数不返回 ((void (*)(void))(ELFHDR-&gt;e_entry &amp; 0xFFFFFF))();bad: outw(0x8A00, 0x8A00); outw(0x8A00, 0x8E00); /* do nothing */ while (1);&#125; 一般的 ELF 文件包括三个索引表：ELF header，Program header table，Section header table。ELF header：在文件的开始，保存了路线图，描述了该文件的组织情况。Program header table：告诉系统如何创建进程映像。用来构造进程映像的目标文件必须具有程序头部表，可重定位文件不需要这个表。Section header table：包含了描述文件节区的信息，每个节区在表中都有一项，每一项给出诸如节区名称、节区大小这类信息。用于链接的目标文件必须包含节区头部表，其他目标文件可以有，也可以没有这个表。1234567891011121314151617typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; ELF文件中有很多段，段表（Section Header Table）就是保存这些段的基本信息的结构，包括了段名、段长度、段在文件中的偏移位置、读写权限和其他段属性。objdump工具可以查看ELF文件基本的段结构12345678910111213typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; 练习五一个比较简单但很绕的逻辑，找到每个函数调用压栈时的指针，找到这个指针也就找到了上一个函数的部分，再找它之前的函数调用压栈的内容。主要问题是忘记了ebp!=0这个条件，忽视了要用16进制。eip是寄存器存放下一个CPU指令存放的内存地址，当CPU执行完当前的指令后，从eip寄存器中读取下一条指令的内存地址，然后继续执行；esp是寄存器存放当前线程的栈顶指针；ebp存放一个指针，该指针指向系统栈最上面一个栈帧的底部。即EBP寄存器存储的是栈底地址，而这个地址是由ESP在函数调用前传递给EBP的。等到调用结束，EBP会把其地址再次传回给ESP。所以ESP又一次指向了函数调用结束后，栈顶的地址。1234567891011121314151617181920212223242526void print_stackframe(void) &#123; /* (1) call read_ebp() to get the value of ebp. the type is (uint32_t); * (2) call read_eip() to get the value of eip. the type is (uint32_t); * (3) from 0 .. STACKFRAME_DEPTH * (3.1) printf value of ebp, eip * (3.2) (uint32_t)calling arguments [0..4] = the contents in address (uint32_t)ebp +2 [0..4] * (3.3) cprintf(&quot;\n&quot;); * (3.4) call print_debuginfo(eip-1) to print the C calling function name and line number, etc. * (3.5) popup a calling stackframe * NOTICE: the calling funciton&apos;s return addr eip = ss:[ebp+4] * the calling funciton&apos;s ebp = ss:[ebp] */ uint32_t my_ebp = read_ebp(); uint32_t my_eip = read_eip();//读取当前的ebp和eip int i,j; for(i = 0; my_ebp!=0 &amp;&amp; i&lt; STACKFRAME_DEPTH; i++)&#123; cprintf(&quot;%0x %0x\n&quot;,my_ebp,my_eip); for(j=0;j&lt;4;j++)&#123; cprintf(&quot;%0x\t&quot;,((uint32_t*)my_ebp+2)[j]); &#125; cprintf(&quot;\n&quot;); print_debuginfo(my_eip-1); my_ebp = ((uint32_t*)my_ebp)[0]; my_eip = ((uint32_t*)my_ebp)[1]; &#125;&#125; ebp（基指针）寄存器主要通过软件约定与堆栈相关联。 在进入C函数时，函数的初始代码通常将先前函数的基本指针推入堆栈来保存，然后在函数持续时间内将当前esp值复制到ebp中。 如果程序中的所有函数都遵循这个约定，那么在程序执行期间的任何给定点，都可以通过跟踪保存的ebp指针链并确切地确定嵌套的函数调用序列引起这个特定的情况来追溯堆栈。 指向要达到的函数。 例如，当某个特定函数导致断言失败时，因为错误的参数传递给它，但您不确定是谁传递了错误的参数。 堆栈回溯可找到有问题的函数。最后一行对应的是第一个使用堆栈的函数，所以在栈的最深一层，就是bootmain.c中的bootmain。 bootloader起始的堆栈从0x7c00开始，使用”call bootmain”转入bootmain函数。 call指令压栈，所以bootmain中ebp为0x7bf8。 练习六123456789101112131415一个表项的结构如下:/*lab1/kern/mm/mmu.h*//* Gate descriptors for interrupts and traps */struct gatedesc &#123; unsigned gd_off_15_0 : 16; // low 16 bits of offset in segment unsigned gd_ss : 16; // segment selector unsigned gd_args : 5; // # args, 0 for interrupt/trap gates unsigned gd_rsv1 : 3; // reserved(should be zero I guess) unsigned gd_type : 4; // type(STS_&#123;TG,IG32,TG32&#125;) unsigned gd_s : 1; // must be 0 (system) unsigned gd_dpl : 2; // descriptor(meaning new) privilege level unsigned gd_p : 1; // Present unsigned gd_off_31_16 : 16; // high bits of offset in segment&#125;; 一个表项占用8字节，其中2-3字节是段选择子，0-1字节和6-7字节拼成位移， 两者联合便是中断处理程序的入口地址。(copy from answer)pic_init：中断控制器的初始化；idt_init：建立中断描述符表，并使能中断，intr_enable()中断向量表可以认为是一个大数组，产生中断时生成一个中断号，来查这个idt表，找到中断服务例程的地址（段选择子加offset）。主要是调用SETGATE这个宏对interrupt descriptor table进行初始化，是之前看到的对每个字节进行操作。然后调用lidt进行load idt（sti：使能中断）1234567建立一个中断描述符 - istrap: 1 是一个trap, 0 代表中断 - sel: 中断处理代码段 - off: 中断处理代码段偏移 - dpl: 描述符的优先级*/#define SETGATE(gate, istrap, sel, off, dpl) 除了系统调用中断(T_SYSCALL)使用陷阱门描述符且权限为用户态权限以外，其它中断均使用特权级(DPL)为０的中断门描述符，权限为内核态权限； 中断描述符表（Interrupt Descriptor Table）中断描述符表把每个中断或异常编号和一个指向中断服务例程的描述符联系起来。同GDT一样，IDT是一个8字节的描述符数组，但IDT的第一项可以包含一个描述符。CPU把中断（异常）号乘以8做为IDT的索引。IDT可以位于内存的任意位置，CPU通过IDT寄存器（IDTR）的内容来寻址IDT的起始地址。指令LIDT和SIDT用来操作IDTR。两条指令都有一个显示的操作数：一个6字节表示的内存地址。在保护模式下，最多会存在256个Interrupt/Exception Vectors。 123456789 extern uintptr_t __vectors[]; int i; //for(i=0;i&lt;256;i++) for(i=0;i&lt; sizeof(idt) / sizeof(struct gatedesc); i++)&#123; SETGATE(idt[i],0,GD_KTEXT,__vectors[i],DPL_KERNEL); &#125;// SETGATE(idt[T_SWITCH_TOK], 0, GD_KTEXT, __vectors[T_SWITCH_TOK], DPL_USER); SETGATE(idt[T_SWITCH_TOK], 1, GD_KTEXT, __vectors[T_SWITCH_TOK], DPL_USER); lidt(&amp;idt_pd); 对idt中的每一项，调用SETGATE进行设置，第二个是0表明是一个中断，如果是1表明是一个陷阱；GD_KTEXT是SEG_KTEXT（1，全局段编号）乘8，是处理中断的代码段编号，__vectors[i]是作为在代码段中的偏移量，vectors[i]在kern/trap/vectors.S中定义，定义了255个中断服务例程的地址，这里才是入口，且都跳转到__alltraps。在trap中调用了trap_dispatch，这样就根据传进来的进行switch处理。用户态设置在特权级3，内核态设置在特权级0。 练习七这个实验实现用户态和内核态的转换，通过看代码基本明白。在init.c中的lab1_switch_to_user函数时一段汇编代码， 触发中断的话，有‘int %0’，就把第二个冒号（输入的数，T_SWITCH_TOK）替换%0， 这样中断号就是T_SWITCH_TOK。SETGATE设置中断向量表将每个中断处理例程的入口设成vector[i]的值，然后在有中断时，找到中断向量表中这个中断的处理例程，都是跳到alltraps，__alltraps把寄存器（ds es fs gs）压栈，把esp压栈，这样假装构造一个trapframe然后调用trap，trap调用了trap_dispatch在trap_dispatch中，对从堆栈弹出的段寄存器进行修改，转成User时和转成Kernel时不一样，分别赋值，同时需要修改之前的trapframe，实现中断的恢复。 12345678910111213141516171819202122 //LAB1 CHALLENGE 1 : YOUR CODE you should modify below codes.case T_SWITCH_TOU: if(tf-&gt;tf_cs != USER_CS)&#123; tf-&gt;tf_cs = USER_CS; tf-&gt;tf_ds = USER_DS; tf-&gt;tf_es = USER_DS; tf-&gt;tf_ss = USER_DS; tf-&gt;tf_eflags |= FL_IOPL_MASK; *((uint32_t*)tf - 1) = (uint32_t)tf; &#125; break;case T_SWITCH_TOK: if(tf-&gt;tf_cs != KERNEL_CS) &#123; tf-&gt;tf_cs = KERNEL_CS; tf-&gt;tf_ds = KERNEL_DS; tf-&gt;tf_es = KERNEL_DS; tf-&gt;tf_eflags &amp;= ~FL_IOPL_MASK; struct trapframe *switchu2k = (struct trapframe *)(tf-&gt;tf_esp - (sizeof(struct trapframe) - 8)); memmove(switchu2k,tf,sizeof(struct trapframe)-8); *((uint32_t *)tf-1)=(uint32_t)switchu2k; &#125; break;]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记四]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[处理机调度处理机调度概念进程切换是CPU资源的当前占用者的切换，保存当前进程在PCB中的执行上下文（CPU状态），恢复下一个进程的执行上下文。 处理机调度是从就绪队列中找一个占用CPU的进程，从多个可用CPU中挑选就绪进程可使用的CPU资源。 调度准则调度时机操作系统维护进程的状态序列。进程从运行状态切换到等待状态，这样CPU就空闲了，或者进程被终结了，CPU又空闲了。这两种情况对应着非抢占系统，当前进程主动放弃CPU。对可抢占系统，中断请求被服务例程响应完成，或当前进程因为时间片用完时会被抢占，进程从等待切换到就绪，这时更急迫的想占用CPU，也会发生抢占。 调度策略进程在CPU计算和IO操作间交替，在时间片机制下，进程可能在结束当前CPU计算之前就被迫放弃CPU。 CPU使用率：CPU处于忙状态的时间百分比。 吞吐率：单位时间内完成的进程数量 周转时间：进程从初始化到结束（包括等待）的时间 等待时间：进程在就绪队列中的时间 响应时间：从提交请求到产生相应所花费的时间 调度算法希望“更快”的服务。 响应时间目标： 减少相应时间，及时处理输入请求 减少平均响应时间的波动，提高可预测性 低延迟调度改善了交互体验 吞吐量目标： 增加吞吐量，减少开销（操作系统开销，上下文切换） 系统资源的高效利用（CPU、IO） 减少等待时间，提高响应性能和吞吐量性能 吞吐量是系统的计算带宽 公平性目标： 保证每个进程占用相同的CPU时间 公平通常会增加响应时间 先来先服务、短进程优先和最高响应比优先调度算法先来先服务按照就绪队列的先后顺序排列，进程进入等待或结束状态时，就绪队列中的下一个进程占用CPU。 周转时间：每个进程的平均总时间（等待+执行） 优点：简单，排队依据容易获得。 缺点： 平均等待时间波动大，排队位置对算法影响大，IO和CPU资源利用效率低。 短进程优先考虑进程的特征，选择就绪队列中执行时间最短进程占用CPU进入运行状态。它具有最好的平均周转时间。 但可能导致饥饿，连续的短进程会使长进程无法获得CPU资源。且需要预知未来，可以用历史执行时间预估未来的执行时间。 最高响应比优先考虑进程在就绪队列中的等待时间。选择就绪队列中响应比R最高的进程。R = (w + s) / s，w是等待时间，s是执行时间。这种算法基于短进程优先算法，不可抢占，关注了进程等待时间，以防止无限等待。 时间片轮转、多级反馈队列、公平共享调度算法和ucore调度框架时间片轮转时间片是分配处理机资源的基本时间单元，各个进程占用一个时间片，仍按照先来先服务策略，时间片结束时按照先来先服务切换到下一个就绪进程，每隔(n-1)个时间片进程执行一个时间片。 时间片太大的话，等待时间过长，退化成先来先服务；若太短，产生了大量上下文切换，影响系统吞吐量。 这时需要选择一个合适的时间片长度。 多级反馈队列就绪队列排成多个子队列，不同队列可以有不同算法，进程可以在队列之间转换。队列间的调度可以采用时间片方法。 多级反馈队列：进程在不同队列间移动的多级队列算法。时间片大小随优先级级别增加而增加，如进程在当前的时间片没有完成，则降到下一个优先级。CPU密集型的进程优先级下降很快，这样时间片会增大，IO密集型的则优先级上升。 公平共享调度算法注重资源访问的公平，一些用户比另一些用户重要，保证不重要的组无法垄断资源。未使用的资源按照比例分配，没有达到资源使用率目标的组获得更高的优先级。 uCore的调度队列run_queue123456struct run_queue&#123; list_entry_t run_list; unsigned int proc_num; int max_time_slice; list_entry_t rq_link;&#125; 实时调度和多处理器调度实时调度对时间有要求，实时操作系统的正确性以来其时间和功能两方面，其性能指标是时间约束的及时性。 周期实时任务：一系列相似任务，任务有规律的重复，周期p=任务请求时间间隔，执行时间e=最大执行时间，使用率U=e/p。 硬实时是指错过任务时限会导致灾难性或非常严重的后果，必须验证，在最坏情况下能满足时限。软实时是指尽量满足任务时限。 可调度性：一个实时操作系统能满足任务时限要求。需要确定实时任务的执行顺序。静态/动态优先级调度。 速率单调调度算法（静态）：通过周期安排优先级，周期越短优先级越高，执行周期最短的任务； 最早截止时间优先算法（动态）：截止时间越早优先级越高，执行截止时间最早的任务。 多处理器调度针对多个处理机，一条系统总线连接多个物理CPU，一个CPU可能有几个逻辑CPU，处理机之间可以负载共享。 对阵多处理机（SMP）调度：每个处理器运行自己的调度程序，调度程序对共享资源的访问需要同步。 静态进程分配：进程开始执行到结束都被分配到一个固定的处理机上，每个处理机都有自己的就绪队列，调度开销小，但各个处理机可能忙闲不均。 动态进程分配：进程在执行中可以分配到任意空闲处理机执行，所有处理机共享一个公共的就绪队列，调度开销大，各个处理机的负载是均衡的。 优先级反置操作系统中出现高优先级进程长时间等待低优先级进程所占用的资源，而导致高优先级进程长时间等待的现象。 优先级继承：占用资源的低优先级进程继承申请资源的高优先级进程的优先级。只有占有资源的低优先级进程被阻塞时才能提高占有资源进程的优先级。 优先级天花板协议：占有资源进程的优先级和所有可能申请该资源的进程的最高优先级相同，不管是否发生等待，都提升占有资源进程的优先级。优先级高于系统中所有被锁定的资源的优先级上限，任务执行临界区就不会被阻塞。 实验六 调度器16.1 总体介绍和调度过程在lab5中，完成了用户进程的管理。lab6中完成了调度的初始化和调度过程。实现一个调度类，绑定调度类（类似于多态或重载），设定调度点，触发调度时间，调整调度参数和调用调度算法，实现选择新进程和完成进程切换。 把当前进程放到就绪队列中，在就绪队列中选取一个适合的进程，出队然后完成切换。 16.2 调度算法支撑框架调度点：出发做调度相关的工作 位置 原因 proc.c:do_exit 用户线程执行结束，主动放弃CPU proc.c:do_wait 用户线程等待着子进程结束，主动放弃CPU proc.c:init_main Init_porc内核线程等待所有用户进程结束；所有用户进程结束后回收系统资源 proc.c:cpu_idle idleproc内核线程等待处于就绪态的进程或线程，如果有选择一个并切换 sync.h:lock 进程无法得到锁，则主动放弃CPU trap.c:trap 修改当前进程时间片，若时间片用完，则设置need_resched为1，让当前进程放弃CPU 进入/离开就绪队列的机制： 抽象数据结构，可以不是队列； 可根据调度算法的需求采用多种数据结构 schedule是一个总控函数，如果当前进程是 RUNNABLE会调用sched_class_enqueue，放到就绪队列中。 16.3 时间片轮转调度算法（RR调度算法）前边介绍完成一个sched_class， RR_init{ list_init; run_queue-&gt;proc_num = 0;} 在产生时钟中断时调用RR_proc_tick{ if(proc-&gt;time_slice &gt; 0) proc-&gt;time_slice –; if(proc-&gt;time_slice == 0) proc-&gt;need_resched = 1;}一旦标志位为1，则说明需要调度了 当有一个进程需要进队列，则调用list_add_before，如果要选择一个进程，则选择一个尾list_next 16.4 Stride调度算法如果有三个进程，每个进程有2个属性，stride表示现在执行到什么地方，数字大小表示执行进度；pass表示一次前进的步数。 选择当前步长最小的一个进程，执行目标是当前步长加path。 它是基于优先级的且每一步的调度策略是特定的。 可以使用priority_queue实现，又可以用Skew heap（斜堆）的优先队列实现。 stride在不停累加下如何正确判断最大最小？uint32_t！]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验六]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%85%AD%2F</url>
    <content type="text"><![CDATA[实验六: 调度器实验目的 理解操作系统的调度管理机制 熟悉 ucore 的系统调度器框架，以及缺省的Round-Robin 调度算法 基于调度器框架实现一个(Stride Scheduling)调度算法来替换缺省的调度算法 实验内容 实验五完成了用户进程的管理，可在用户态运行多个进程。 之前采用的调度策略是很简单的FIFO调度策略。 本次实验，主要是熟悉ucore的系统调度器框架，以及基于此框架的Round-Robin（RR） 调度算法。 然后参考RR调度算法的实现，完成Stride Scheduling调度算法。 调度框架和调度算法设计与实现实验六中的kern/schedule/sched.c只实现了调度器框架，而不再涉及具体的调度算法实现，调度算法在单独的文件（default_sched.[ch]）中实现。 在init.c中的kern_init函数中的proc_init之前增加了对sched_init函数的调用。sched_init函数主要完成了对实现特定调度算法的调度类（sched_class，这里是default_sched_class）的绑定，使得ucore在后续的执行中，能够通过调度框架找到实现特定调度算法的调度类并完成进程调度相关工作。 进程状态12345678910111213141516struct proc_struct &#123; enum proc_state state; // Process state int pid; // Process ID int runs; // the running times of Proces uintptr_t kstack; // Process kernel stack volatile bool need_resched; // bool value: need to be rescheduled to release CPU? struct proc_struct *parent; // the parent process struct mm_struct *mm; // Process&apos;s memory management field struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for current interrupt uintptr_t cr3; // CR3 register: the base addr of Page Directroy Table(PDT) uint32_t flags; // Process flag char name[PROC_NAME_LEN + 1]; // Process name list_entry_t list_link; // Process link list list_entry_t hash_link; // Process hash list&#125;; ucore定义的进程控制块struct proc_struct包含了成员变量state,用于描述进程的运行状态，而running和runnable共享同一个状态(state)值(PROC_RUNNABLE。不同之处在于处于running态的进程不会放在运行队列中。进程的正常生命周期如下： 进程首先在 cpu 初始化或者 sys_fork 的时候被创建，当为该进程分配了一个进程控制块之后，该进程进入 uninit态(在proc.c 中 alloc_proc)。 当进程完全完成初始化之后，该进程转为runnable态。 当到达调度点时，由调度器sched_class根据运行队列run_queue的内容来判断一个进程是否应该被运行，即把处于runnable态的进程转换成running状态，从而占用CPU执行。 running态的进程通过wait等系统调用被阻塞，进入sleeping态。 sleeping态的进程被wakeup变成runnable态的进程。 running态的进程主动 exit 变成zombie态，然后由其父进程完成对其资源的最后释放，子进程的进程控制块成为unused。 所有从runnable态变成其他状态的进程都要出运行队列，反之，被放入某个运行队列中。 进程调度实现内核抢占点对于用户进程而言，由于有中断的产生，可以随时打断用户进程的执行，转到操作系统内部，从而给了操作系统以调度控制权，让操作系统可以根据具体情况（比如用户进程时间片已经用完了）选择其他用户进程执行。这体现了用户进程的可抢占性。 ucore内核执行是不可抢占的（non-preemptive），即在执行“任意”内核代码时，CPU控制权不可被强制剥夺。这里需要注意，不是在所有情况下ucore内核执行都是不可抢占的，有以下几种“固定”情况是例外： 进行同步互斥操作，比如争抢一个信号量、锁（lab7中会详细分析）； 进行磁盘读写等耗时的异步操作，由于等待完成的耗时太长，ucore会调用shcedule让其他就绪进程执行。 以上两种是因为某个资源（也可称为事件）无法得到满足，无法继续执行下去，从而不得不主动放弃对CPU的控制权。在lab5中有几种情况是调用了schedule函数的。 编号 位置 原因 1 proc.c:do_exit 用户线程执行结束，主动放弃CPU 2 proc.c:do_wait 用户线程等待着子进程结束，主动放弃CPU 3 proc.c:init_main Init_porc内核线程等待所有用户进程结束；所有用户进程结束后回收系统资源 4 proc.c:cpu_idle idleproc内核线程等待处于就绪态的进程或线程，如果有选择一个并切换 5 sync.h:lock 进程无法得到锁，则主动放弃CPU 6 trap.c:trap 修改当前进程时间片，若时间片用完，则设置need_resched为1，让当前进程放弃CPU 第1、2、5处的执行位置体现了由于获取某种资源一时等不到满足、进程要退出、进程要睡眠等原因而不得不主动放弃CPU。第3、4处的执行位置比较特殊，initproc内核线程等待用户进程结束而执行schedule函数；idle内核线程在没有进程处于就绪态时才执行，一旦有了就绪态的进程，它将执行schedule函数完成进程调度。这里只有第6处的位置比较特殊：1234567if (!in_kernel) &#123; …… if (current-&gt;need_resched) &#123; schedule(); &#125;&#125; 只有当进程在用户态执行到“任意”某处用户代码位置时发生了中断，且当前进程控制块成员变量need_resched为1（表示需要调度了）时，才会执行shedule函数。这实际上体现了对用户进程的可抢占性。如果没有第一行的if语句，那么就可以体现对内核代码的可抢占性。但如果要把这一行if语句去掉，我们就不得不实现对ucore中的所有全局变量的互斥访问操作，以防止所谓的race-condition现象，这样ucore的实现复杂度会增加不少。 Race condition旨在描述一个系统或者进程的输出依赖于不受控制的事件出现顺序或者出现时机。此词源自于两个信号试着彼此竞争，来影响谁先输出。 举例来说，如果计算机中的两个进程同时试图修改一个共享内存的内容，在没有并发控制的情况下，最后的结果依赖于两个进程的执行顺序与时机。而且如果发生了并发访问冲突，则最后的结果是不正确的。从维基百科的定义来看，race condition不仅仅是出现在程序中。以下讨论的race conditon全是计算机中多个进程同时访问一个共享内存，共享变量的例子。 要阻止出现race condition情况的关键就是不能让多个进程同时访问那块共享内存。访问共享内存的那段代码就是critical section。所有的解决方法都是围绕这个critical section来设计的。想要成功的解决race condition问题，并且程序还可以正确运行，从理论上应该满足以下四个条件： 不会有两个及以上进程同时出现在他们的critical section。 不要做任何关于CPU速度和数量的假设。 任何进程在运行到critical section之外时都不能阻塞其他进程。 不会有进程永远等在critical section之前。 进程切换过程进程调度函数schedule选择了下一个将占用CPU执行的进程后，将调用进程切换，从而让新的进程得以执行。 两个用户进程，在二者进行进程切换的过程中，具体的步骤如下： 首先在执行某进程A的用户代码时，出现了一个trap，这个时候就会从进程A的用户态切换到内核态(过程(1))，并且保存好进程A的trapframe；当内核态处理中断时发现需要进行进程切换时，ucore要通过schedule函数选择下一个将占用CPU执行的进程（即进程B），然后会调用proc_run函数，proc_run函数进一步调用switch_to函数，切换到进程B的内核态(过程(2))，继续进程B上一次在内核态的操作，并通过iret指令，最终将执行权转交给进程B的用户空间(过程(3))。 当进程B由于某种原因发生中断之后(过程(4))，会从进程B的用户态切换到内核态，并且保存好进程B的trapframe；当内核态处理中断时发现需要进行进程切换时，即需要切换到进程A，ucore再次切换到进程A(过程(5))，会执行进程A上一次在内核调用schedule函数返回后的下一行代码，这行代码当然还是在进程A的上一次中断处理流程中。最后当进程A的中断处理完毕的时候，执行权又会反交给进程A的用户代码(过程(6))。这就是在只有两个进程的情况下，进程切换间的大体流程。 调度框架和调度算法设计思路在操作方面，如果需要选择一个就绪进程，就可以从基于某种组织方式的就绪进程集合中选择出一个进程执行。选择是在集合中挑选一个“合适”的进程，出意味着离开就绪进程集合。 另外考虑到一个处于运行态的进程还会由于某种原因（比如时间片用完了）回到就绪态而不能继续占用CPU执行，这就会重新进入到就绪进程集合中。这两种情况就形成了调度器相关的三个基本操作：在就绪进程集合中选择、进入就绪进程集合和离开就绪进程集合。这三个操作属于调度器的基本操作。 在进程的执行过程中，就绪进程的等待时间和执行进程的执行时间是影响调度选择的重要因素。这些进程状态变化的情况需要及时让进程调度器知道，便于选择更合适的进程执行。所以这种进程变化的情况就形成了调度器相关的一个变化感知操作：timer时间事件感知操作。这样在进程运行或等待的过程中，调度器可以调整进程控制块中与进程调度相关的属性值（比如消耗的时间片、进程优先级等），并可能导致对进程组织形式的调整（比如以时间片大小的顺序来重排双向链表等），并最终可能导致调选择新的进程占用CPU运行。这个操作属于调度器的进程调度属性调整操作。 数据结构 在 ucore 中，调度器引入 run-queue（简称rq,即运行队列）的概念，通过链表结构管理进程。 由于目前 ucore 设计运行在单CPU上，其内部只有一个全局的运行队列，用来管理系统内全部的进程。 运行队列通过链表的形式进行组织。链表的每一个节点是一个list_entry_t,每个list_entry_t 又对应到了struct proc_struct *，这其间的转换是通过宏le2proc来完成。 具体来说，我们知道在struct proc_struct中有一个叫run_link的list_entry_t，因此可以通过偏移量逆向找到对因某个run_list的struct proc_struct。即进程结构指针proc = le2proc(链表节点指针, run_link)。 123456789101112131415161718192021222324252627282930313233// The introduction of scheduling classes is borrrowed from Linux, and makes the// core scheduler quite extensible. These classes (the scheduler modules) encapsulate// the scheduling policies.struct sched_class &#123; // the name of sched_class const char *name; // 初始化运行队列 void (*init)(struct run_queue *rq); // put the proc into runqueue, and this function must be called with rq_lock // 进程放入运行队列 void (*enqueue)(struct run_queue *rq, struct proc_struct *proc); // get the proc out runqueue, and this function must be called with rq_lock // 从队列中取出 void (*dequeue)(struct run_queue *rq, struct proc_struct *proc); // choose the next runnable task // 选择下一个可运行的任务 struct proc_struct *(*pick_next)(struct run_queue *rq); // dealer of the time-tick // 处理tick中断 void (*proc_tick)(struct run_queue *rq, struct proc_struct *proc); /* for SMP support in the future * load_balance * void (*load_balance)(struct rq* rq); * get some proc from this rq, used in load_balance, * return value is the num of gotten proc * int (*get_proc)(struct rq* rq, struct proc* procs_moved[]); */&#125;; proc.h 中的 struct proc_struct 中也记录了一些调度相关的信息：12345678910111213141516171819202122232425262728293031323334struct proc_struct &#123; enum proc_state state; // Process state int pid; // Process ID int runs; // the running times of Proces uintptr_t kstack; // Process kernel stack volatile bool need_resched; // bool value: need to be rescheduled to release CPU? struct proc_struct *parent; // the parent process struct mm_struct *mm; // Process&apos;s memory management field struct context context; // Switch here to run process struct trapframe *tf; // Trap frame for current interrupt uintptr_t cr3; // CR3 register: the base addr of Page Directroy Table(PDT) uint32_t flags; // Process flag char name[PROC_NAME_LEN + 1]; // Process name list_entry_t list_link; // Process link list list_entry_t hash_link; // Process hash list int exit_code; // exit code (be sent to parent proc) uint32_t wait_state; // waiting state struct proc_struct *cptr, *yptr, *optr; // relations between processes struct run_queue *rq; // running queue contains Process list_entry_t run_link; // the entry linked in run queue // 该进程的调度链表结构，该结构内部的连接组成了 运行队列 列表 int time_slice; // time slice for occupying the CPU // 进程剩余的时间片 skew_heap_entry_t lab6_run_pool; // FOR LAB6 ONLY: the entry in the run pool //在优先队列中用到的 uint32_t lab6_stride; // FOR LAB6 ONLY: the current stride of the process // 步进值 uint32_t lab6_priority; // FOR LAB6 ONLY: the priority of process, set by lab6_set_priority(uint32_t) // 优先级&#125;; RR调度算法在RR_sched_class调度策略类中实现。通过数据结构 struct run_queue 来描述完整的 run_queue（运行队列）。它的主要结构如下：12345678910struct run_queue &#123; //其运行队列的哨兵结构，可以看作是队列头和尾 list_entry_t run_list; //优先队列形式的进程容器，只在 LAB6 中使用 skew_heap_entry_t *lab6_run_pool; //表示其内部的进程总数 unsigned int proc_num; //每个进程一轮占用的最多时间片 int max_time_slice;&#125;; 在 ucore 框架中，运行队列存储的是当前可以调度的进程，所以，只有状态为runnable的进程才能够进入运行队列。当前正在运行的进程并不会在运行队列中。 调度点的相关关键函数如果我们能够让wakup_proc、schedule、run_timer_list这三个调度相关函数的实现与具体调度算法无关，那么就可以认为ucore实现了一个与调度算法无关的调度框架。 wakeup_proc函数完成了把一个就绪进程放入到就绪进程队列中的工作，为此还调用了一个调度类接口函数sched_class_enqueue，这使得wakeup_proc的实现与具体调度算法无关。123456789101112131415161718void wakeup_proc(struct proc_struct *proc) &#123; assert(proc-&gt;state != PROC_ZOMBIE); bool intr_flag; local_intr_save(intr_flag); &#123; if (proc-&gt;state != PROC_RUNNABLE) &#123; proc-&gt;state = PROC_RUNNABLE; proc-&gt;wait_state = 0; if (proc != current) &#123; sched_class_enqueue(proc); &#125; &#125; else &#123; warn(&quot;wakeup runnable process.\n&quot;); &#125; &#125; local_intr_restore(intr_flag);&#125; schedule函数完成了与调度框架和调度算法相关三件事情: 把当前继续占用CPU执行的运行进程放放入到就绪进程队列中； 从就绪进程队列中选择一个“合适”就绪进程； 把这个“合适”的就绪进程从就绪进程队列中取出； 如果没有的话，说明现在没有合适的进程可以执行，就执行idle_proc； 加了一个runs，表明这个进程运行过几次了； 12345678910111213141516171819202122void schedule(void) &#123; bool intr_flag; struct proc_struct *next; local_intr_save(intr_flag); &#123; current-&gt;need_resched = 0; if (current-&gt;state == PROC_RUNNABLE) &#123; sched_class_enqueue(current); &#125; if ((next = sched_class_pick_next()) != NULL) &#123; sched_class_dequeue(next); &#125; if (next == NULL) &#123; next = idleproc; &#125; next-&gt;runs ++; if (next != current) &#123; proc_run(next); &#125; &#125; local_intr_restore(intr_flag);&#125; run_time_list在lab6中并没有涉及，是在lab7中的。 通过调用三个调度类接口函数sched_class_enqueue、sched_class_pick_next、sched_class_enqueue来使得完成这三件事情与具体的调度算法无关。run_timer_list函数在每次timer中断处理过程中被调用，从而可用来调用调度算法所需的timer时间事件感知操作，调整相关进程的进程调度相关的属性值。通过调用调度类接口函数sched_class_proc_tick使得此操作与具体调度算法无关。这里涉及了一系列调度类接口函数： sched_class_enqueue sched_class_dequeue sched_class_pick_next sched_class_proc_tick 这4个函数的实现其实就是调用某基于sched_class数据结构的特定调度算法实现的4个指针函数。采用这样的调度类框架后，如果我们需要实现一个新的调度算法，则我们需要定义一个针对此算法的调度类的实例，一个就绪进程队列的组织结构描述就行了，其他的事情都可交给调度类框架来完成。 RR调度算法RR调度算法的调度思想是让所有runnable态的进程分时轮流使用CPU时间。 RR调度器维护当前runnable进程的有序运行队列。当前进程的时间片用完之后，调度器将当前进程放置到运行队列的尾部，再从其头部取出进程进行调度。 RR调度算法的就绪队列在组织结构上也是一个双向链表，只是增加了一个成员变量，表明在此就绪进程队列中的最大执行时间片。而且在进程控制块proc_struct中增加了一个成员变量time_slice，用来记录进程当前的可运行时间片段。这是由于RR调度算法需要考虑执行进程的运行时间不能太长。在每个timer到时的时候，操作系统会递减当前执行进程的time_slice，当time_slice为0时，就意味着这个进程运行了一段时间（这个时间片段称为进程的时间片），需要把CPU让给其他进程执行，于是操作系统就需要让此进程重新回到rq的队列尾，且重置此进程的时间片为就绪队列的成员变量最大时间片max_time_slice值，然后再从rq的队列头取出一个新的进程执行。 RR_enqueue的函数实现如下表所示。即把某进程的进程控制块指针放入到rq队列末尾，且如果进程控制块的时间片为0，则需要把它重置为rq成员变量max_time_slice。这表示如果进程在当前的执行时间片已经用完，需要等到下一次有机会运行时，才能再执行一段时间。123456789static void RR_enqueue(struct run_queue *rq, struct proc_struct *proc) &#123; assert(list_empty(&amp;(proc-&gt;run_link))); list_add_before(&amp;(rq-&gt;run_list), &amp;(proc-&gt;run_link)); if (proc-&gt;time_slice == 0 || proc-&gt;time_slice &gt; rq-&gt;max_time_slice) &#123; proc-&gt;time_slice = rq-&gt;max_time_slice; &#125; proc-&gt;rq = rq; rq-&gt;proc_num ++;&#125; RR_pick_next的函数实现如下表所示。即选取就绪进程队列rq中的队头队列元素，并把队列元素转换成进程控制块指针。12345678static struct proc_struct *RR_pick_next(struct run_queue *rq) &#123; list_entry_t *le = list_next(&amp;(rq-&gt;run_list)); if (le != &amp;(rq-&gt;run_list)) &#123; return le2proc(le, run_link); &#125; return NULL;&#125; RR_dequeue的函数实现如下表所示。即把就绪进程队列rq的进程控制块指针的队列元素删除，并把表示就绪进程个数的proc_num减一。12345static void RR_dequeue(struct run_queue *rq, struct proc_struct *proc) &#123; assert(!list_empty(&amp;(proc-&gt;run_link)) &amp;&amp; proc-&gt;rq == rq); list_del_init(&amp;(proc-&gt;run_link)); rq-&gt;proc_num --;&#125; RR_proc_tick的函数实现如下表所示。每次timer到时后，trap函数将会间接调用此函数来把当前执行进程的时间片time_slice减一。如果time_slice降到零，则设置此进程成员变量need_resched标识为1，这样在下一次中断来后执行trap函数时，会由于当前进程程成员变量need_resched标识为1而执行schedule函数，从而把当前执行进程放回就绪队列末尾，而从就绪队列头取出在就绪队列上等待时间最久的那个就绪进程执行。123456789static voidRR_proc_tick(struct run_queue *rq, struct proc_struct *proc) &#123; if (proc-&gt;time_slice &gt; 0) &#123; proc-&gt;time_slice --; &#125; if (proc-&gt;time_slice == 0) &#123; proc-&gt;need_resched = 1; &#125;&#125; Stride Scheduling基本思路 为每个runnable的进程设置一个当前状态stride，表示该进程当前的调度权，也可以表示这个进程执行了多久了。另外定义其对应的pass值，表示对应进程在调度后，stride 需要进行的累加值。 每次需要调度时，从当前 runnable 态的进程中选择stride最小的进程调度。 对于获得调度的进程P，将对应的stride加上其对应的步长pass（只与进程的优先权有关系）。 在一段固定的时间之后，回到2步骤，重新调度当前stride最小的进程。 可以证明，如果令P.pass =BigStride / P.priority，其中P.priority表示进程的优先权（大于 1），而 BigStride 表示一个预先定义的大常数，则该调度方案为每个进程分配的时间将与其优先级成正比。 将该调度器应用到 ucore 的调度器框架中来，则需要将调度器接口实现如下： init: 初始化调度器类的信息（如果有的话）。 初始化当前的运行队列为一个空的容器结构。（比如和RR调度算法一样，初始化为一个有序列表） enqueue 初始化刚进入运行队列的进程 proc的stride属性。 将 proc插入放入运行队列中去（注意：这里并不要求放置在队列头部）。 dequeue 从运行队列中删除相应的元素。 pick next 扫描整个运行队列，返回其中stride值最小的对应进程。 更新对应进程的stride值，即pass = BIG_STRIDE / P-&gt;priority; P-&gt;stride += pass。 proc tick: 检测当前进程是否已用完分配的时间片。如果时间片用完，应该正确设置进程结构的相关标记来引起进程切换。 一个 process 最多可以连续运行 rq.max_time_slice个时间片。 使用优先队列实现 Stride Scheduling使用优化的优先队列数据结构实现该调度。 优先队列是这样一种数据结构：使用者可以快速的插入和删除队列中的元素，并且在预先指定的顺序下快速取得当前在队列中的最小（或者最大）值及其对应元素。可以看到，这样的数据结构非常符合 Stride 调度器的实现。 libs/skew_heap.h中是优先队列的一个实现。1234567891011121314151617static inline void skew_heap_init(skew_heap_entry_t *a) __attribute__((always_inline));// 初始化一个队列节点static inline skew_heap_entry_t *skew_heap_merge( skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp);// 合并两个优先队列static inline skew_heap_entry_t *skew_heap_insert( skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp) __attribute__((always_inline));// 将节点 b 插入至以节点 a 为队列头的队列中去，返回插入后的队列static inline skew_heap_entry_t *skew_heap_remove( skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp) __attribute__((always_inline));// 将节点 b 插入从以节点 a 为队列头的队列中去，返回删除后的队列 当使用优先队列作为Stride调度器的实现方式之后，运行队列结构也需要作相关改变，其中包括： struct run_queue中的lab6_run_pool指针，在使用优先队列的实现中表示当前优先队列的头元素，如果优先队列为空，则其指向空指针（NULL）。 struct proc_struct中的lab6_run_pool结构，表示当前进程对应的优先队列节点。本次实验已经修改了系统相关部分的代码，使得其能够很好地适应LAB6新加入的数据结构和接口。而在实验中我们需要做的是用优先队列实现一个正确和高效的Stride调度器，如果用较简略的伪代码描述，则有： init(rq): Initialize rq-&gt;run_list Set rq-&gt;lab6_run_pool to NULL Set rq-&gt;proc_num to 0 enqueue(rq, proc) Initialize proc-&gt;time_slice Insert proc-&gt;lab6_run_pool into rq-&gt;lab6_run_pool rq-&gt;proc_num ++ dequeue(rq, proc) Remove proc-&gt;lab6_run_pool from rq-&gt;lab6_run_pool rq-&gt;proc_num – pick_next(rq) If rq-&gt;lab6_run_pool == NULL, return NULL Find the proc corresponding to the pointer rq-&gt;lab6_run_pool proc-&gt;lab6_stride += BIG_STRIDE / proc-&gt;lab6_priority Return proc proc_tick(rq, proc): If proc-&gt;time_slice &gt; 0, proc-&gt;time_slice –– If proc-&gt;time_slice == 0, set the flag proc-&gt;need_resched 练习1: 使用 Round Robin 调度算法（不需要编码）与之前相比，新增了斜堆数据结构的实现；新增了调度算法Round Robin的实现，具体为调用sched.c文件中的sched_class的一系列函数，主要有enqueue、dequeue、pick_next等。之后，这些函数进一步调用调度器中的相应函数，默认该调度器为Round Robin调度器，这是在default_sched.[c|h]中定义的；新增了set_priority，get_time等函数； 首先在init.c中调用了sched_init函数，在这里把sched_class赋值为default_sched_class，也就是RR，如下：12345678910voidsched_init(void) &#123; list_init(&amp;timer_list); sched_class = &amp;default_sched_class; rq = &amp;__rq; rq-&gt;max_time_slice = MAX_TIME_SLICE; sched_class-&gt;init(rq); cprintf(&quot;sched class: %s\n&quot;, sched_class-&gt;name);&#125; RR_init函数：这个函数会被封装为sched_init函数，用于调度算法的初始化，它是在ucore的init.c里面被调用进行初始化，主要完成了计时器list、run_queue的run_list的初始化； enqueue函数：将某个进程放入调用算法中的可执行队列中，被封装成sched_class_enqueue函数，这个函数仅在wakeup_proc和schedule函数中被调用，wakeup_proc将某个不是RUNNABLE的进程改成RUNNABLE的并调用enqueue加入可执行队列，而后者是将正在执行的进程换出到可执行队列中去并取出一个可执行进程； dequeue函数：将某个在队列中的进程取出，sched_class_dequeue将其封装并在schedule中被调用，将调度算法选择的进程从等待的可执行进程队列中取出； pick_next函数：根据调度算法选择下一个要执行的进程，仅在schedule中被调用； proc_tick函数：在时钟中断时执行的操作，时间片减一，当时间片为0时，说明这个进程需要重新调度了。仅在进行时间中断的ISR中调用； 请理解并分析sched_calss中各个函数指针的用法，并接合Round Robin 调度算法描述ucore的调度执行过程： ucore中的调度主要通过schedule和wakeup_proc函数完成，schedule主要把当前执行的进程入队，调用sched_class_pick_next选择下一个执行的进程并将其出队，开始执行。scheduleha函数把当前的进程入队，挑选一个进程将其出队并开始执行。 当需要将某一个进程加入就绪进程队列中，需要调用enqueue，将其插入到使用链表组织run_queue的队尾，将这个进程的能够使用的时间片初始化为max_time_slice； 当需要将某一个进程从就绪队列中取出，需要调用dequeue，调用list_del_init将其直接删除即可； 当需要取出执行的下一个进程时，只需调用pick_next将就绪队列run_queue的队头取出即可； 在一个时钟中断中，调用proc_tick将当前执行的进程的剩余可执行时间减1，一旦减到了0，则这个进程的need_resched为1，设成可以被调度的，这样之后就会调用schedule函数将这个进程切换出去； 请在实验报告中简要说明如何设计实现”多级反馈队列调度算法“，给出概要设计，鼓励给出详细设计; 1.调度机制： 进程在进入待调度的队列等待时，首先进入优先级最高的Q1等待。 设置多个就绪队列。在系统中设置多个就绪队列，并为每个队列赋予不同的优先级，从第一个开始逐个降低。不同队列进程中所赋予的执行时间也不同，优先级越高，时间片越小。 每个队列都采用FCFS（先来先服务）算法。轮到该进程执行时，若在该时间片内完成，便撤离操作系统，否则调度程序将其转入第二队列的末尾等待调度，…….。若进程最后被调到第N队列中时，便采用RR方式运行。 按队列优先级调度。调度按照优先级最高队列中诸进程运行，仅当第一队列空闲时才调度第二队列进程执行。若低优先级队列执行中有优先级高队列进程执行，应立刻将此进程放入队列末尾，把处理机分配给新到高优先级进程。 设置N个多级反馈队列的入口，Q0，Q1，Q2，Q3，…，编号越靠前的队列优先级越低，优先级越低的队列上时间片的长度越大； 调用sched_init对调度算法初始化的时候需要同时对N个队列进行初始化； 在将进程加入到就绪进程集合的时候，观察这个进程的时间片有没有使用完，如果使用完了，就将所在队列的优先级调低，加入到优先级低一级的队列中去，如果没有使用完时间片，则加入到当前优先级的队列中去； 在同一个优先级的队列内使用时间片轮转算法； 在选择下一个执行的进程的时候，先考虑更高优先级的队列中是否存在任务，如果不存在在去找较低优先级的队列； 从就绪进程集合中删除某一个进程的话直接在对应队列中删除； 练习2：实现 Stride Scheduling 调度算法（需要编码）啊啊啊忘了在trap.c里改怪不得怎么都搞不对啊啊啊啊啊啊啊啊啊这下子总算有170了！！！ 还是先看看代码里斜堆（skew heap）的实现吧，好多地方要用到这个结构，具体可以在yuhao0102.github.io里仔细看。在libs/skew.h中定义了skew heap。 猜测这只是一个入口，类似链表那种实现，不包括数据，只有指针。123struct skew_heap_entry &#123; struct skew_heap_entry *parent, *left, *right;&#125;; proc_stride_comp_f函数是用来比较这两个进程的stride的，a比b大返回1，相等返回0，a比b小返回-1。1234567891011/* The compare function for two skew_heap_node_t&apos;s and the * corresponding procs*/static int proc_stride_comp_f(void *a, void *b)&#123; struct proc_struct *p = le2proc(a, lab6_run_pool); struct proc_struct *q = le2proc(b, lab6_run_pool); int32_t c = p-&gt;lab6_stride - q-&gt;lab6_stride; if (c &gt; 0) return 1; else if (c == 0) return 0; else return -1;&#125; 这是初始化的函数，把三个指针初始化为NULL12345static inline voidskew_heap_init(skew_heap_entry_t *a)&#123; a-&gt;left = a-&gt;right = a-&gt;parent = NULL;&#125; 这个是把两个堆merge在一起的操作，强行内联hhh，这个是递归的！12345678910111213141516171819202122232425262728293031323334static inline skew_heap_entry_t *skew_heap_merge(skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp)&#123; if (a == NULL) return b; else if (b == NULL) return a;// 如果a或b有一个为空，则返回另一个 skew_heap_entry_t *l, *r; if (comp(a, b) == -1) &#123; r = a-&gt;left; l = skew_heap_merge(a-&gt;right, b, comp); a-&gt;left = l; a-&gt;right = r; if (l) l-&gt;parent = a; return a;// 否则判断a和b的值哪个大，如果a比b小，则a的右子树和b合并，a作为堆顶 &#125; else &#123; r = b-&gt;left; l = skew_heap_merge(a, b-&gt;right, comp); b-&gt;left = l; b-&gt;right = r; if (l) l-&gt;parent = b; return b;// 另一种情况 &#125;&#125; insert就是把一个单节点的堆跟大堆合并1234567static inline skew_heap_entry_t *skew_heap_insert(skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp)&#123; skew_heap_init(b); return skew_heap_merge(a, b, comp);&#125; 删除就是把节点的左右子树进行merge，比较简单，记得删掉这个节点之后补充它的parent即可1234567891011121314151617static inline skew_heap_entry_t *skew_heap_remove(skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp)&#123; skew_heap_entry_t *p = b-&gt;parent; skew_heap_entry_t *rep = skew_heap_merge(b-&gt;left, b-&gt;right, comp); if (rep) rep-&gt;parent = p; if (p) &#123; if (p-&gt;left == b) p-&gt;left = rep; else p-&gt;right = rep; return a; &#125; else return rep;&#125; 首先把default_sched.c中设置RR调度器为默认调度器的部分注释掉，然后把default_sched_stride_c改成default_sched_stride.c，这里对默认调度器进行了重新定义。12345678struct sched_class default_sched_class = &#123; .name = &quot;stride_scheduler&quot;, .init = stride_init, .enqueue = stride_enqueue, .dequeue = stride_dequeue, .pick_next = stride_pick_next, .proc_tick = stride_proc_tick,&#125;; 针对PCB的初始化，代码如下，综合了几个实验的初始化代码，也是一个总结：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354//LAB4:EXERCISE1 YOUR CODE/* * below fields in proc_struct need to be initialized * enum proc_state state; // Process state * int pid; // Process ID * int runs; // the running times of Proces * uintptr_t kstack; // Process kernel stack * volatile bool need_resched; // bool value: need to be rescheduled to release CPU? * struct proc_struct *parent; // the parent process * struct mm_struct *mm; // Process&apos;s memory management field * struct context context; // Switch here to run process * struct trapframe *tf; // Trap frame for current interrupt * uintptr_t cr3; // CR3 register: the base addr of Page Directroy Table(PDT) * uint32_t flags; // Process flag * char name[PROC_NAME_LEN + 1]; // Process name */ proc-&gt;state = PROC_UNINIT; proc-&gt;pid = -1; proc-&gt;cr3 = boot_cr3; proc-&gt;runs = 0; proc-&gt;kstack = 0; proc-&gt;need_resched = 0; proc-&gt;parent = NULL; proc-&gt;mm = NULL; memset(&amp;proc-&gt;context, 0, sizeof(struct context)); proc-&gt;tf = NULL; proc-&gt;flags = 0; memset(proc-&gt;name, 0, PROC_NAME_LEN);//LAB5 YOUR CODE : (update LAB4 steps)/* * below fields(add in LAB5) in proc_struct need to be initialized * uint32_t wait_state; // waiting state * struct proc_struct *cptr, *yptr, *optr; // relations between processes */ proc-&gt;wait_state = 0; proc-&gt;cptr = proc-&gt;optr = proc-&gt;yptr = NULL;//LAB6 YOUR CODE : (update LAB5 steps)/* * below fields(add in LAB6) in proc_struct need to be initialized * struct run_queue *rq; // running queue contains Process * list_entry_t run_link; // the entry linked in run queue * int time_slice; // time slice for occupying the CPU * skew_heap_entry_t lab6_run_pool; // FOR LAB6 ONLY: the entry in the run pool * uint32_t lab6_stride; // FOR LAB6 ONLY: the current stride of the process * uint32_t lab6_priority; // FOR LAB6 ONLY: the priority of process, set by lab6_set_priority(uint32_t) */ proc-&gt;rq = NULL; memset(&amp;proc-&gt;run_link, 0, sizeof(list_entry_t)); proc-&gt;time_slice = 0; memset(&amp;proc-&gt;lab6_run_pool,0,sizeof(skew_heap_entry_t)); proc-&gt;lab6_stride=0; proc-&gt;lab6_priority=1; 主要就是在vim kern/schedule/default_sched_stride.c里的修改。1#define BIG_STRIDE ((uint32_t)(1&lt;&lt;31)-3) BIG_STRIDE应该设置成小于2^32-1的一个常数。 这个函数用来对run_queue进行初始化等操作12345678910111213141516171819202122/* * stride_init initializes the run-queue rq with correct assignment for * member variables, including: * * - run_list: should be a empty list after initialization. * - lab6_run_pool: NULL * - proc_num: 0 * - max_time_slice: no need here, the variable would be assigned by the caller. * * hint: see libs/list.h for routines of the list structures. */static voidstride_init(struct run_queue *rq) &#123; /* LAB6: YOUR CODE * (1) init the ready process list: rq-&gt;run_list * (2) init the run pool: rq-&gt;lab6_run_pool * (3) set number of process: rq-&gt;proc_num to 0 */ list_init(&amp;rq-&gt;run_list); rq-&gt;lab6_run_pool = NULL; rq-&gt;proc_num = 0;&#125; 1234567891011121314151617181920212223242526272829303132333435/* * stride_enqueue inserts the process ``proc&apos;&apos; into the run-queue * ``rq&apos;&apos;. The procedure should verify/initialize the relevant members * of ``proc&apos;&apos;, and then put the ``lab6_run_pool&apos;&apos; node into the * queue(since we use priority queue here). The procedure should also * update the meta date in ``rq&apos;&apos; structure. * * proc-&gt;time_slice denotes the time slices allocation for the * process, which should set to rq-&gt;max_time_slice. * * hint: see libs/skew_heap.h for routines of the priority * queue structures. */static voidstride_enqueue(struct run_queue *rq, struct proc_struct *proc) &#123; /* LAB6: YOUR CODE * (1) insert the proc into rq correctly * NOTICE: you can use skew_heap or list. Important functions * skew_heap_insert: insert a entry into skew_heap * list_add_before: insert a entry into the last of list * (2) recalculate proc-&gt;time_slice * (3) set proc-&gt;rq pointer to rq * (4) increase rq-&gt;proc_num */ rq-&gt;lab6_run_pool = skew_heap_insert(rq-&gt;lab6_run_pool, &amp;proc-&gt;lab6_run_pool, proc_stride_comp_f); // 做插入操作，把这个进程插到run_pool里。 if(proc-&gt;time_slice == 0 || proc-&gt;time_slice &gt; rq-&gt;max_time_slice) &#123; proc-&gt;time_slice = rq-&gt;max_time_slice; &#125; // 如果这个进程的时间片不符合要求，就把它初始化成最大值。 proc-&gt;rq = rq; rq-&gt;proc_num ++; //run_queue里的进程数++&#125; 做删除操作，把这个进程从run_pool里删除，并且将run_queue里的进程数减一。12345678910111213141516171819/* * stride_dequeue removes the process ``proc&apos;&apos; from the run-queue * ``rq&apos;&apos;, the operation would be finished by the skew_heap_remove * operations. Remember to update the ``rq&apos;&apos; structure. * * hint: see libs/skew_heap.h for routines of the priority * queue structures. */static voidstride_dequeue(struct run_queue *rq, struct proc_struct *proc) &#123; /* LAB6: YOUR CODE * (1) remove the proc from rq correctly * NOTICE: you can use skew_heap or list. Important functions * skew_heap_remove: remove a entry from skew_heap * list_del_init: remove a entry from the list */ rq-&gt;lab6_run_pool = skew_heap_remove(rq-&gt;lab6_run_pool, &amp;proc-&gt;lab6_run_pool, proc_stride_comp_f); rq-&gt;proc_num --;&#125; pick_next从run_queue中选择stride值最小的进程，即斜堆的根节点对应的进程，并且返回这个proc，同时更新这个proc的stride12345678910111213141516171819202122232425262728/* * stride_pick_next pick the element from the ``run-queue&apos;&apos;, with the * minimum value of stride, and returns the corresponding process * pointer. The process pointer would be calculated by macro le2proc, * see kern/process/proc.h for definition. Return NULL if * there is no process in the queue. * * When one proc structure is selected, remember to update the stride * property of the proc. (stride += BIG_STRIDE / priority) * * hint: see libs/skew_heap.h for routines of the priority * queue structures. */static struct proc_struct *stride_pick_next(struct run_queue *rq) &#123; /* LAB6: YOUR CODE * (1) get a proc_struct pointer p with the minimum value of stride (1.1) If using skew_heap, we can use le2proc get the p from rq-&gt;lab6_run_poll (1.2) If using list, we have to search list to find the p with minimum stride value * (2) update p;s stride value: p-&gt;lab6_stride * (3) return p */ if (rq-&gt;lab6_run_pool == NULL) return NULL; struct proc_struct *p = le2proc(rq-&gt;lab6_run_pool, lab6_run_pool); p-&gt;lab6_stride += BIG_STRIDE/p-&gt;lab6_priority; return p;&#125; 要在trap的时候调用！！！！如果这个proc的时间片还有的话，就减一，如果这个时间片为0了，就把它设成可调度的，参与调度。123456789101112131415161718/* * stride_proc_tick works with the tick event of current process. You * should check whether the time slices for current process is * exhausted and update the proc struct ``proc&apos;&apos;. proc-&gt;time_slice * denotes the time slices left for current * process. proc-&gt;need_resched is the flag variable for process * switching. */static voidstride_proc_tick(struct run_queue *rq, struct proc_struct *proc) &#123; /* LAB6: YOUR CODE */ if (proc-&gt;time_slice &gt; 0) &#123; proc-&gt;time_slice --; &#125; if (proc-&gt;time_slice == 0) &#123; proc-&gt;need_resched = 1; &#125;&#125;]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程笔记三]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0%E4%B8%89%2F</url>
    <content type="text"><![CDATA[第十一讲 进程和线程11.1 进程的概念进程是一个具有一定功能的程序在一个数据集合中的一次动态执行过程。源代码到可执行文件再到加载到进程地址内存空间（堆、栈、代码段）。进程浩瀚了正在运行的一个程序的所有状态的信息，进程是由： 代码 数据 状态寄存器：CPU状态CR0、指令指针IP等 通用寄存器：AX、BX、CX… 进程占用系统资源：打开文件、已分配内存 特点： 动态性：动态创建 并发性：独立调度并占用处理机运行 独立性：不同进程相互工作不影响 制约性：因访问共享数据和资源或进程间同步产生制约 进程是处于运行状态程序的抽象，程序是一个静态的可执行文件，进程是执行中的程序，是程序+执行状态；同一个程序的多次执行过程对应不同进程；进程执行需要内存和CPU。进程是动态的，程序是动态的，程序是有序代码的集合，进程是程序的俄执行，进程有核心态和用户态；进程是暂时的，程序是永久的，进程的组成包括程序、数据和进程控制块。 11.2 进程控制块（PCB）是操作系统控制进程运行的信息集合。操作系统用PCB来描述进程的基本情况和运行变化的过程。PCB是进程存在的唯一标志。 进程创建：生成该进程的PCB； 进程终止：回收PCB； 进程的组织管理：通过对PCB的组织管理实现。 进程控制块内容： 进程标识信息 处理机现场保存：从进程地址空间抽取PC、SP、其他寄存器保存 进程控制信息：调度和状态信息（调度进程和处理机使用情况）、进程间通信信息（通信相关的标识）、存储管理信息（指向进程映像存储空间数据结构）、进程所用资源（进程使用的系统资源，文件等）、有关数据结构链接信息（与PCB有关的进程队列） 进程控制块的组织： 链表：同一状态的进程其PCB组织成一个链表，多个状态对应不同链表； 索引表：同一状态的进程归入一个索引表，由索引指向PCB，多个状态对应多个不同的索引表。 11.3 进程状态操作系统为了维护进程执行中的变化来维护进程的状态。进程的生命周期分为： 进程创建：创建PCB、拷贝数据。引起进程创建主要有：系统初始化、用户请求创建进程、正在执行的进程执行了创建进程的调用； 进程就绪：放入等待队列中等待运行； 进程执行：内核选择一个就绪进程，占用处理机并执行； 进程等待：进程执行的某项条件不满足，比如请求并等待系统服务、启动某种操作无法马上完成，只有进程自身知道何时需要等待某种事件的发生； 进程抢占：高优先级的进程就绪或进程执行时间片用完； 进程唤醒：被阻塞的进程需要的资源可满足，进程只能被别的进程或操作系统唤醒； 进程结束：把进程执行占用的资源释放，有几种可能：正常、错误退出、致命错误、强制退出。 N个进程交替运行，假定进程1执行sleep()，内核里调用计时器，进程1把当前进程占用寄存器的状态保存，切换进程2，如果计时器到点了，计时器产生中断，保存进程2的状态，恢复进程1的状态。 11.4 三状态进程模型核心是： 就绪：进程获得了除了处理机之外的所有资源，得到处理机即可运行； 运行：进程正在处理机上执行； 等待：进程在等待某一事件在等待。 辅助状态两种： 创建：一个进程正在被创建，还未被转到就绪状态之前的状态； 结束：进程正在从系统中消失的状态，这是因为进程结束或其他原因所导致。 状态转换： 创建 -&gt; 就绪：进程被创建并完成初始化，变成就绪状态； 就绪 -&gt; 运行：处于就绪状态的进程被调度程序选中，分配到处理机上运行； 运行 -&gt; 结束：进程表示它已经完成或因为出错，当前运行今晨会由操作系统作结束处理； 运行 -&gt; 就绪：处于运行状态的进程在其运行过程中，由于分配给它的处理机时间片用完而让出处理机； 运行 -&gt; 等待：当进程请求某资源且必须等待时； 等待 -&gt; 就绪：进程等待的某事件到来时，它从阻塞状态变到就绪状态； 11.5 挂起进程模型处于挂起状态的进程映像在磁盘上，目的是减少进程占用内存。 等待挂起：进程在外存并等待某事件的发生； 就绪挂起：进程在外存，但是只要进入内存即可运行； 挂起：把进程从内存转到外存 增加了内存的转换： 等待 -&gt; 等待挂起：没有进程处于就绪状态或就绪状态要求更多内存资源； 就绪到就绪挂起：有高优先级等待进程（系统认为很快就绪）和低优先级就绪进程； 运行 -&gt; 就绪挂起：对抢先式分时系统，当有高优先级等待挂起进程因事件出现而进入就绪挂起； 从外存转到内存的转换：激活 就绪挂起 -&gt; 就绪：没有就绪进程或挂起就绪进程优先级高于就绪进程； 等待挂起 -&gt; 等待：进程释放了足够内存，并有高优先级的等待挂起进程； 状态队列：有操作系统维护一组队列，表示系统所有进程的当前状态。根据进程状态不同，进程PCB加入不同队列，进程状态切换时，加入不同队列。 11.6 线程的概念 为什么要引入线程在进程内部增加一类实体，满足实体之间可以并发执行且实体之间可以共享相同的地址空间。线程是进程的一部分，描述指令流执行状态，它是进程中指令执行流的最小单元，是CPU调度的单位。这种剥离为并发提供了可能，描述了在进程资源环境中的指令流执行状态；进程扮演了资源分配的角色。原来只有一个指令指针，现在有多个堆栈和指令指针。线程=进程-共享资源。但是如果一个线程有异常，会导致其所属进程的所有线程都崩。 比较 进程是资源分配单位，线程是CPU调度单位； 进程有一个完整的资源平台，线程只独享指令流执行的必要资源，如寄存器和栈； 线程具有就绪、等待和运行三种基本状态和其转移关系； 线程能减少并发执行的时间和空间开销： 线程创建时间短； 线程的终止时间比进程短； 同一进程的线程切换时间比进程短； 由于同一进程的各个线程共享内存和文件资源，可不通过内核进行直接通信。 11.7 用户线程三种实现方式： 用户线程：在用户空间实现，通过用户级的线程库函数完成线程的管理。在操作系统内核中仍然只有进程控制块来描述处理机的调度的情况，操作系统并不感知应用态有多线程的支持，多线程的支持是用户的函数库支持的。在应用程序内部通过构造相应的线程控制块来控制一个进程内部多个线程的交替执行和同步。这种方法不依赖操作系统内核，用于不支持线程的多线程的操作系统。每个进程有私有的线程控制块(TCB)，TCB由线程库函数维护；同一进程的用户线程切换速度快，无需用户态/核心态的切换，且允许每个进程有自己的线程调度算法。缺点就是不支持基于线程的处理机抢占， 除非当前运行的线程主动放弃CPU，他所在进程的其他线程无法抢占CPU。POSIX Pthreads、Math C-threads、Solaris threads 内核线程：在内核中实现，Windows、Solaris、Linux 轻量级进程：在内核中实现，支持用户进程。 11.8 内核线程内核通过系统调用完成的线程机制。由内核维护PCB和TCB，线程执行系统调用而阻塞不影响其他线程，以线程为单位的进程调度会更合理。轻权进程：内核支持的用户线程，一个进程有多个轻量级进程，每个轻权进程由一个单独的内核线程来支持。在内核支持线程，轻权进程来绑定用户线程。用户线程与内核线程的对应关系：一对一、多对一、多对多。 第十二讲 进程控制12.1 进程切换上下文切换，暂停当前运行的进程，从当前运行状态转变成其他状态，调度另一个进程从就绪状态变成运行状态，在此过程中实现进程上下文的保存和快速切换。维护进程生命周期的信息（寄存器等）。 进程控制块PCB：内核为每个进程维护了对应的PCB，将相同状态的进程的PCB放置在同一个队列中。 ucore中的进程控制块结构proc_struct： 进程ID、父进程ID，组ID； 进程状态信息、地址空间起始、页表起始、是否允许调度； 进程所占用的资源struct mm_struct* mm； 现场保护的上下文切换的context； 用于描述当前进程在哪个状态队列中的指针，等。 ucore的切换流程：开始调度 -&gt; 清除调度标志 -&gt; 查找就绪进程 -&gt; 修改进程状态 -&gt; 进程切换switch_to()。switch_to用汇编写成。。。 12.2 进程创建Windows进程创建API：CreateProcessUnix进程创建系统调用：fork/exec，fork()把一个进程复制成两个进程，exec()用新程序重写当前进程。 fork()的地址空间复制：fork调用对子进程就是在调用时间对父进程地址空间的一次复制。执行到fork时，复制一份，只有PID不同。系统调用exec()加载新程序取代当前运行的程序。加载进来后把代码换掉。 ucore中的do_fork：分配进程控制块数据结构、创建堆栈、复制内存数据结构、设置进程标识等。操作系统没有新的任务执行，则创建空闲进程，在proc_init中分配idleproc需要的资源，初始化idleproc的PCB。 fork的开销昂贵，在fork中内存复制是没用的，子进程将可能关闭打开的文件和连接，所以可以将fork和exec联系起来。产生了vfork，创建进程时不再创建一个同样的内存映像，用时再加载，一些时候称为轻量级fork。这时子进程应立即执行exec。现在使用写时复制技术。 12.3 进程加载应用程序通过exec加载可执行文件，允许进程加载一个完全不同的程序，并从main开始执行。不同系统加载可执行文件的格式不同，并且允许进程加载时指定启动参数（argc,argv），exec调用成功时，它与运行exec之前是相同的进程，但是运行了不同的程序，且代码段和堆栈重写。主要是可执行文件格式的识别，有sys_exec、do_execv、load_icode函数。 ucore中第一个用户态进程是由proc_init创建的，执行了init_main创建内核线程，创建了shell程序。 12.4 进程等待与退出父子进程的交互，完成子进程的资源回收。 子进程通过exit()向父进程返回一个值，父进程通过wait()接受并处理这个返回值。wait()父进程先等待，还是子进程先做exit()，这两种情况会导致它下面的处理有一些区别。 如果有子进程存活，也就是说父进程创建的子进程还有子进程，那这时候父进程进入等待状态，等待子进程的返回结果，父进程先执行wait，等到子进程执行的时候它执行exit()，这是exit ()是在wait之后执行的。这时候，子进程的exit()退出，唤醒父进程，父进程由等待状态回到就绪状态，父进程就处理子进程的返回的这个返回值，这是wait在前exit()在后的情况。 如果不是这样那就有一种情况，就是有僵尸子进程等待，就是子进程先执行exit()，这时它返回一个值，等待父进程的处理，exit()在前，如果子进程还一直处在这个等待的状态，在这里等待父进程的处理，父进程的wait就直接返回，如果有多个的话就从其中一个返回它的值。 进程的有序终止exit()，完成资源回收。 调用参数作为进程的结果； 关闭所有打开的文件等占用资源； 释放内存，释放进程相关的内核数据结构； 检查父进程是否存活，如存活则保留结果的值直到父进程需要他。 清理所有等待的僵尸进程。 第十三讲 实验四 内核线程管理13.1 总体介绍了解内核线程创建执行的管理过程。了解内核线程的切换和基本调度过程，对TCB充分了解。 13.2 关键数据结构struct proc_struct：TCB pid和name代表了标识符。 state、runs、need_reshed代表了状态和是否需要调度 cr3不太需要，因为共用进程的页表 kstack代表了堆栈 mm_struct不太需要，在ucore的统一管理下 context是通常说的上下文，基本都是寄存器，代表了当前线程的状态 trap_frame代表中断产生时的信息（硬件保存）、段寄存器的信息（软件保存） 一些list，父进程的信息和线程控制块的链表 基于hash的list，查找对应的线程比较快 13.3 执行流程kern_init最开始初始化，proc_init完成一系列的创建内核线程并执行。 创建第0号内核线程idleproc： alloc_proc创建TCB的内存块-init idle_proc，设置pid、stat、kstack等 创建第1个内核线程： initproc： keep trapframe调用了do_fork，copy_thread等，如何跳到入口正确执行？是用户态还是内核态？ init_proc init kernel stack，可以放到两个list中执行了 开始调度执行 找到线程队列中哪个是处于就绪的，切换switch kstack、页表、上下文，根据trapframe跳到内核线程的入口地址，开始执行函数。 13.4 实际操作关注proc_init创建第0、1号线程。switch_to完成两个内核线程的切换。 第十四讲 实验五 用户进程管理14.1 总体介绍第一个用户进程如何创建、进程管理的实现机制、系统调用的框架实现。构造出第一个用户进程：建立用户代码/数据段 —&gt; 创建内核线程 —&gt; 创建用户进程“壳” —&gt; 填写用户进程 —&gt; 执行用户进程(特权级转换) —&gt; 完成系统调用 —&gt; 结束用户进程(资源回收) 14.2 进程的内存布局内核虚拟内存布局有一部分是对实际物理空间的映射，0xC0000000到0xF8000000，映射为物理空间。一个Page Tabel，0xFAC00000到0xB0000000，一开始只是管理内核空间的映射关系，有了用户进程后，页表需要扩展。 进程虚拟内存空间：Ivalid MemoryUser Stack————0xB0000000………..User Program &amp; Heap—0x00800000Invalid MemoryUser STAB Data(optional，调试信息)Invalid Memory Invalid Memory一旦访问为非法，确保访问到这些是产生page fault，使之不能随意访问。 14.3 执行ELF格式的二进制代码-do_execve的实现do_execve建好一个壳并把程序加载进来。本实验用到一个PCB（process control block），其实是跟上一个实验的TCB一样的。 首先，把之前的内存空间清空，只留下PCB，换成自己的程序。把cr3这个页表基址指向boot_cr3内核页表；把进程内存管理区域清空，对应页表清空，导致内存没有了；load_icode加载执行程序。 14.4 执行ELF格式的二进制代码-load_icode的实现前边已经把内存管理清空了，先创建一个新内存管理空间mm_create和新页表setup_pgdir；填上我执行代码的内容，找到要加载的程序的代码段和数据段，根据代码段和数据段的虚拟地址通过mm_map完成对合法空间的建立；从程序的内存区域拷贝过来，建立物理地址和虚拟地址的映射关系；准备all_zero的内存；设置相应堆栈空间（用户态空间），使用mm_map建立；把页表的起始地址换成新建好的页表的起始地址。 完成trapframe的设置。trapframe保存了打断的中断状态保存，完成特权级转变，从kernel转换到user。 x86特权级：从ring 0 —&gt; ring 3，一个ring 0栈空间，构造一个信息使得执行iret时能回到用户态，重新设置ss和cs，从ring0到ring3。 用户进程有两个栈，用户栈和内核栈，通过系统调用转化。 14.5 进程复制父进程如何构造子进程？一个函数叫do_fork，是一个内核函数，完成用户空间的拷贝。首先，父进程创建进程控制块，初始化kernel stack，分配页空间和内核里的虚地址。copy_mm为新进程建立新虚存空间。copy_range拷贝父进程的内存到新进程。拷贝父进程的trapframe到新进程。添加新的proc_struct到proc_list并唤醒新进程。执行完do_fork后父进程得到子进程的pid，子进程得到0。 14.6 内存管理的copy-on-write机制进程A通过do_fork创建进程B，二者重用一段空间，使得空间占用量大大减少，如果是只读的话没问题。一旦某进程做了写操作，因为页表设置成只读，则产生page_fault，触发copy-on-write机制，真正为子进程复制页表。进程创建的开销大大减小，且有效减少空间。 一个物理页可能被多个虚拟页引用，这个个数很重要，因为在进程运行时可能会出现换入换出，如何进行有效换入换出，有可能那个页既在内存中也在虚存中。 dup_mmap完成内存管理的复制。]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验八]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E5%85%AB%2F</url>
    <content type="text"><![CDATA[实验八：文件系统实验目的通过完成本次实验，希望能达到以下目标： 了解基本的文件系统系统调用的实现方法； 了解一个基于索引节点组织方式的Simple FS文件系统的设计与实现； 了解文件系统抽象层-VFS的设计与实现； 实验内容本次实验涉及的是文件系统，通过分析了解ucore文件系统的总体架构设计，完善读写文件操作，从新实现基于文件系统的执行程序机制（即改写do_execve），从而可以完成执行存储在磁盘上的文件和实现文件读写等功能。 文件系统设计与实现ucore 文件系统总体介绍UNIX提出了四个文件系统抽象概念：文件(file)、目录项(dentry)、索引节点(inode)和安装点(mount point) 文件：文件中的内容可理解为是一有序字节，文件有一个方便应用程序识别的文件名称（也称文件路径名）。典型的文件操作有读、写、创建和删除等。 目录项：目录项不是目录（又称文件路径），而是目录的组成部分。在UNIX中目录被看作一种特定的文件，而目录项是文件路径中的一部分。如一个文件路径名是“/test/testfile”，则包含的目录项为： 根目录“/”， 目录“test”和文件“testfile” 这三个都是目录项。 一般而言，目录项包含目录项的名字（文件名或目录名）和目录项的索引节点位置。 索引节点：UNIX将文件的相关元数据信息（如访问控制权限、大小、拥有者、创建时间、数据内容等等信息）存储在一个单独的数据结构中，该结构被称为索引节点。 安装点：在UNIX中，文件系统被安装在一个特定的文件路径位置，这个位置就是安装点。所有的已安装文件系统都作为根文件系统树中的叶子出现在系统中。 ucore模仿了UNIX的文件系统设计，ucore的文件系统架构主要由四部分组成： 通用文件系统访问接口层：该层提供了一个从用户空间到文件系统的标准访问接口。这一层访问接口让应用程序能够通过一个简单的接口获得ucore内核的文件系统服务。 文件系统抽象层：向上提供一个一致的接口给内核其他部分（文件系统相关的系统调用实现模块和其他内核功能模块）访问。向下提供一个同样的抽象函数指针列表和数据结构屏蔽不同文件系统的实现细节。 Simple FS文件系统层：一个基于索引方式的简单文件系统实例。向上通过各种具体函数实现以对应文件系统抽象层提出的抽象函数。向下访问外设接口 外设接口层：向上提供device访问接口屏蔽不同硬件细节。向下实现访问各种具体设备驱动的接口，比如disk设备接口/串口设备接口/键盘设备接口等。 假如应用程序操作文件（打开/创建/删除/读写）： 通过文件系统的通用文件系统访问接口层为用户空间提供的访问接口进入文件系统内部； 文件系统抽象层把访问请求转发给某一具体文件系统（比如SFS文件系统）； 具体文件系统（Simple FS文件系统层）把应用程序的访问请求转化为对磁盘上的block的处理请求，并通过外设接口层交给磁盘驱动例程来完成具体的磁盘操作。 通用文件系统访问接口 文件系统相关用户库 write::usr/libs/file.c 用户态文件系统相关系统调用访问接口 sys_write/sys_call::/usr/libs/syscall.c 内核态文件系统相关系统调用实现 sys_write::/kern/syscall/syscall.c 文件系统抽象层VFS dir接口 file接口 inode接口 etc… sysfile_write::kern/fs/sysfile.c file_write::/kern/fs/file.c vop_write::/kern/fs/vfs/inode.h Simple FS文件系统实现 sfs的inode实现 sfs的外设访问接口 sfs_write::kern/fs/sfs/sfs_inode.c sfs_wbuf::/kern/fs/sfs/sfs_io.c 文件系统IO设备接口 device访问接口 stdin/stdout访问接口 etc… dop_io::/kern/fs/devs/dev.h disk0_io::/kern/fs/devs/dev_disk0.c 硬盘驱动、串口驱动 ide_write_secs::/kern/driver/ide.c ucore文件系统总体结构从ucore操作系统不同的角度来看，ucore中的文件系统架构包含四类主要的数据结构, 它们分别是： 超级块（SuperBlock），它主要从文件系统的全局角度描述特定文件系统的全局信息。它的作用范围是整个OS空间。 索引节点（inode）：它主要从文件系统的单个文件的角度描述了文件的各种属性和数据所在位置。它的作用范围是整个OS空间。 目录项（dentry）：它主要从文件系统的文件路径的角度描述了文件路径中的一个特定的目录项（注：一系列目录项形成目录/文件路径）。它的作用范围是整个OS空间。 对于SFS而言，inode(具体为struct sfs_disk_inode)对应于物理磁盘上的具体对象， dentry（具体为struct sfs_disk_entry）是一个内存实体，其中的ino成员指向对应的inode number，另外一个成员是file name(文件名). 文件（file），它主要从进程的角度描述了一个进程在访问文件时需要了解的文件标识，文件读写的位置，文件引用情况等信息。它的作用范围是某一具体进程。 通用文件系统访问接口文件和目录相关用户库函数在文件操作方面，最基本的相关函数是open、close、read、write。 在读写一个文件之前，首先要用open系统调用将其打开。 open的第一个参数指定文件的路径名，可使用绝对路径名； 第二个参数指定打开的方式，可设置为O_RDONLY、O_WRONLY、O_RDWR，分别表示只读、只写、可读可写。 在打开一个文件后，就可以使用它返回的文件描述符fd对文件进行相关操作。 在使用完一个文件后，还要用close系统调用把它关闭，其参数就是文件描述符fd。这样它的文件描述符就可以空出来，给别的文件使用。 读写文件内容的系统调用是read和write。read系统调用有三个参数： 一个指定所操作的文件描述符，一个指定读取数据的存放地址，最后一个指定读多少个字节。在C程序中调用该系统调用的方法如下：count = read(filehandle, buffer, nbytes);。 该系统调用会把实际读到的字节数返回给count变量。在正常情形下这个值与nbytes相等，但有时可能会小一些。例如，在读文件时碰上了文件结束符，从而提前结束此次读操作。 对于目录而言，最常用的操作是跳转到某个目录，这里对应的用户库函数是chdir。然后就需要读目录的内容了，即列出目录中的文件或目录名，这在处理上与读文件类似，即需要：通过opendir函数打开目录，通过readdir来获取目录中的文件信息，读完后还需通过closedir函数来关闭目录。由于在ucore中把目录看成是一个特殊的文件，所以opendir和closedir实际上就是调用与文件相关的open和close函数。只有readdir需要调用获取目录内容的特殊系统调用sys_getdirentry。而且这里没有写目录这一操作。在目录中增加内容其实就是在此目录中创建文件，需要用到创建文件的函数。 文件和目录访问相关系统调用与文件相关的open、close、read、write用户库函数对应的是sys_open、sys_close、sys_read、sys_write四个系统调用接口。与目录相关的readdir用户库函数对应的是sys_getdirentry系统调用。这些系统调用函数接口将通过syscall函数来获得ucore的内核服务。当到了ucore内核后，在调用文件系统抽象层的file接口和dir接口。 文件系统抽象层 - VFS文件系统抽象层是把不同文件系统的对外共性接口提取出来，形成一个函数指针数组，这样，通用文件系统访问接口层只需访问文件系统抽象层，而不需关心具体文件系统的实现细节和接口。 file &amp; dir接口file&amp;dir接口层定义了进程在内核中直接访问的文件相关信息，这定义在file数据结构中，具体描述如下：1234567891011struct file &#123; enum &#123; FD_NONE, FD_INIT, FD_OPENED, FD_CLOSED, &#125; status; //访问文件的执行状态 bool readable; //文件是否可读 bool writable; //文件是否可写 int fd; //文件在filemap中的索引值 off_t pos; //访问文件的当前位置 struct inode *node; //该文件对应的内存inode指针 int open_count; //打开此文件的次数&#125;; 而在kern/process/proc.h中的proc_struct结构中描述了进程访问文件的数据接口files_struct，其数据结构定义如下：123456struct files_struct &#123; struct inode *pwd; //进程当前执行目录的内存inode指针 struct file *fd_array; //进程打开文件的数组 atomic_t files_count; //访问此文件的线程个数 semaphore_t files_sem; //确保对进程控制块中fs_struct的互斥访问&#125;; 当创建一个进程后，该进程的files_struct将会被初始化或复制父进程的files_struct。当用户进程打开一个文件时，将从fd_array数组中取得一个空闲file项，然后会把此file的成员变量node指针指向一个代表此文件的inode的起始地址。 inode 接口index node是位于内存的索引节点，它是VFS结构中的重要数据结构，因为它实际负责把不同文件系统的特定索引节点信息（甚至不能算是一个索引节点）统一封装起来，避免了进程直接访问具体文件系统。其定义如下：1234567891011121314struct inode &#123; union &#123; //包含不同文件系统特定inode信息的union成员变量 struct device __device_info; //设备文件系统内存inode信息 struct sfs_inode __sfs_inode_info; //SFS文件系统内存inode信息 &#125; in_info; enum &#123; inode_type_device_info = 0x1234, inode_type_sfs_inode_info, &#125; in_type; //此inode所属文件系统类型 atomic_t ref_count; //此inode的引用计数 atomic_t open_count; //打开此inode对应文件的个数 struct fs *in_fs; //抽象的文件系统，包含访问文件系统的函数指针 const struct inode_ops *in_ops; //抽象的inode操作，包含访问inode的函数指针 &#125;; 在inode中，有一成员变量为in_ops，这是对此inode的操作函数指针列表，其数据结构定义如下：1234567891011struct inode_ops &#123; unsigned long vop_magic; int (*vop_open)(struct inode *node, uint32_t open_flags); int (*vop_close)(struct inode *node); int (*vop_read)(struct inode *node, struct iobuf *iob); int (*vop_write)(struct inode *node, struct iobuf *iob); int (*vop_getdirentry)(struct inode *node, struct iobuf *iob); int (*vop_create)(struct inode *node, const char *name, bool excl, struct inode **node_store); int (*vop_lookup)(struct inode *node, char *path, struct inode **node_store);…… &#125;; 参照上面对SFS中的索引节点操作函数的说明，可以看出inode_ops是对常规文件、目录、设备文件所有操作的一个抽象函数表示。对于某一具体的文件系统中的文件或目录，只需实现相关的函数，就可以被用户进程访问具体的文件了，且用户进程无需了解具体文件系统的实现细节。 Simple FS 文件系统ucore内核把所有文件都看作是字节流，任何内部逻辑结构都是专用的，由应用程序负责解释。但是ucore区分文件的物理结构。ucore目前支持如下几种类型的文件： 常规文件：文件中包括的内容信息是由应用程序输入。SFS文件系统在普通文件上不强加任何内部结构，把其文件内容信息看作为字节。 目录：包含一系列的entry，每个entry包含文件名和指向与之相关联的索引节点（index node）的指针。目录是按层次结构组织的。 链接文件：实际上一个链接文件是一个已经存在的文件的另一个可选择的文件名。 设备文件：不包含数据，但是提供了一个映射物理设备（如串口、键盘等）到一个文件名的机制。可通过设备文件访问外围设备。 管道：管道是进程间通讯的一个基础设施。管道缓存了其输入端所接受的数据，以便在管道输出端读的进程能一个先进先出的方式来接受数据。 SFS文件系统中目录和常规文件具有共同的属性，而这些属性保存在索引节点中。SFS通过索引节点来管理目录和常规文件，索引节点包含操作系统所需要的关于某个文件的关键信息，比如文件的属性、访问许可权以及其它控制信息都保存在索引节点中。可以有多个文件名可指向一个索引节点。 文件系统的布局文件系统通常保存在磁盘上。在本实验中，第三个磁盘（即disk0，前两个磁盘分别是ucore.img和swap.img）用于存放一个SFS文件系统（Simple Filesystem）。通常文件系统中，磁盘的使用是以扇区（Sector）为单位的，但是为了实现简便，SFS 中以 block （4K，与内存 page 大小相等）为基本单位。SFS文件系统的布局如下图所示。superblock -&gt; root-dir inode -&gt; freemap -&gt; inode/file_data/dir_data_blocks 第0个块（4K）是超级块（superblock），它包含了关于文件系统的所有关键参数，当计算机被启动或文件系统被首次接触时，超级块的内容就会被装入内存。其定义如下：123456struct sfs_super &#123; uint32_t magic; /* magic number, should be SFS_MAGIC */ uint32_t blocks; /* # of blocks in fs */ uint32_t unused_blocks; /* # of unused blocks in fs */ char info[SFS_MAX_INFO_LEN + 1]; /* infomation for sfs */&#125;; 可以看到，包含： 成员变量魔数magic，其值为0x2f8dbe2a，内核通过它来检查磁盘镜像是否是合法的 SFS img； 成员变量blocks记录了SFS中所有block的数量，即 img 的大小； 成员变量unused_block记录了SFS中还没有被使用的block的数量； 成员变量info包含了字符串”simple file system”。 第1个块放了一个root-dir的inode，用来记录根目录的相关信息。有关inode还将在后续部分介绍。通过这个root-dir的inode信息就可以定位并查找到根目录下的所有文件信息。 从第2个块开始，根据SFS中所有块的数量，用1个bit来表示一个块的占用和未被占用的情况。这个区域称为SFS的freemap区域，这将占用若干个块空间。为了更好地记录和管理freemap区域，专门提供了两个文件kern/fs/sfs/bitmap.[ch]来完成根据一个块号查找或设置对应的bit位的值。12345struct bitmap &#123; uint32_t nbits; uint32_t nwords; WORD_TYPE *map;&#125;; 最后在剩余的磁盘空间中，存放了所有其他目录和文件的inode信息和内容数据信息。需要注意的是虽然inode的大小小于一个块的大小（4096B），但为了实现简单，每个 inode 都占用一个完整的 block。在sfs_fs.c文件中的sfs_do_mount函数中，完成了加载位于硬盘上的SFS文件系统的超级块superblock和freemap的工作。这样，在内存中就有了SFS文件系统的全局信息。 在fs_init中分别调用了vfs_init()，dev_init()和sfs_init()，sfs_init()中调用了sfs_mount(&quot;disk0&quot;)，sfs_mount中调用了vfs_mount(devname, sfs_do_mount);，vfs_mount()中从设备列表中找到一个名字相同的设备，这个设备的fs应该是NULL，即它是没有被挂载到某个文件系统的。找到这个设备的inode中in_info，调用传进来的mountfunc，即sfs_do_mount123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/* * sfs_do_mount - mount sfs file system. * * @dev: the block device contains sfs file system * @fs_store: the fs struct in memroy */static intsfs_do_mount(struct device *dev, struct fs **fs_store) &#123; static_assert(SFS_BLKSIZE &gt;= sizeof(struct sfs_super)); static_assert(SFS_BLKSIZE &gt;= sizeof(struct sfs_disk_inode)); static_assert(SFS_BLKSIZE &gt;= sizeof(struct sfs_disk_entry)); if (dev-&gt;d_blocksize != SFS_BLKSIZE) &#123; return -E_NA_DEV; &#125; /* 分配一个fs的结构 */ struct fs *fs; if ((fs = alloc_fs(sfs)) == NULL) &#123; return -E_NO_MEM; &#125; /* 获取这个sfs的sfs_fs */ struct sfs_fs *sfs = fsop_info(fs, sfs); sfs-&gt;dev = dev; int ret = -E_NO_MEM; void *sfs_buffer; if ((sfs-&gt;sfs_buffer = sfs_buffer = kmalloc(SFS_BLKSIZE)) == NULL) &#123; goto failed_cleanup_fs; &#125; /* 专门用来读超级块的 */ if ((ret = sfs_init_read(dev, SFS_BLKN_SUPER, sfs_buffer)) != 0) &#123; goto failed_cleanup_sfs_buffer; &#125; ret = -E_INVAL; struct sfs_super *super = sfs_buffer; if (super-&gt;magic != SFS_MAGIC) &#123; // 开头一定要是魔数 cprintf(&quot;sfs: wrong magic in superblock. (%08x should be %08x).\n&quot;, super-&gt;magic, SFS_MAGIC); goto failed_cleanup_sfs_buffer; &#125; if (super-&gt;blocks &gt; dev-&gt;d_blocks) &#123; cprintf(&quot;sfs: fs has %u blocks, device has %u blocks.\n&quot;, super-&gt;blocks, dev-&gt;d_blocks); goto failed_cleanup_sfs_buffer; &#125; super-&gt;info[SFS_MAX_INFO_LEN] = &apos;\0&apos;; sfs-&gt;super = *super; ret = -E_NO_MEM; uint32_t i; /* alloc and initialize hash list, 用于inode */ list_entry_t *hash_list; if ((sfs-&gt;hash_list = hash_list = kmalloc(sizeof(list_entry_t) * SFS_HLIST_SIZE)) == NULL) &#123; goto failed_cleanup_sfs_buffer; &#125; for (i = 0; i &lt; SFS_HLIST_SIZE; i ++) &#123; list_init(hash_list + i); &#125; /* load and check freemap */ struct bitmap *freemap; uint32_t freemap_size_nbits = sfs_freemap_bits(super); if ((sfs-&gt;freemap = freemap = bitmap_create(freemap_size_nbits)) == NULL) &#123; goto failed_cleanup_hash_list; &#125; uint32_t freemap_size_nblks = sfs_freemap_blocks(super); if ((ret = sfs_init_freemap(dev, freemap, SFS_BLKN_FREEMAP, freemap_size_nblks, sfs_buffer)) != 0) &#123; goto failed_cleanup_freemap; &#125; uint32_t blocks = sfs-&gt;super.blocks, unused_blocks = 0; for (i = 0; i &lt; freemap_size_nbits; i ++) &#123; if (bitmap_test(freemap, i)) &#123; unused_blocks ++; &#125; &#125; assert(unused_blocks == sfs-&gt;super.unused_blocks); /* and other fields */ sfs-&gt;super_dirty = 0; sem_init(&amp;(sfs-&gt;fs_sem), 1); sem_init(&amp;(sfs-&gt;io_sem), 1); sem_init(&amp;(sfs-&gt;mutex_sem), 1); list_init(&amp;(sfs-&gt;inode_list)); cprintf(&quot;sfs: mount: &apos;%s&apos; (%d/%d/%d)\n&quot;, sfs-&gt;super.info, blocks - unused_blocks, unused_blocks, blocks); /* link addr of sync/get_root/unmount/cleanup funciton fs&apos;s function pointers*/ fs-&gt;fs_sync = sfs_sync; fs-&gt;fs_get_root = sfs_get_root; fs-&gt;fs_unmount = sfs_unmount; fs-&gt;fs_cleanup = sfs_cleanup; *fs_store = fs; return 0;failed_cleanup_freemap: bitmap_destroy(freemap);failed_cleanup_hash_list: kfree(hash_list);failed_cleanup_sfs_buffer: kfree(sfs_buffer);failed_cleanup_fs: kfree(fs); return ret;&#125; 索引节点在SFS文件系统中，需要记录文件内容的存储位置以及文件名与文件内容的对应关系。 sfs_disk_inode记录了文件或目录的内容存储的索引信息，该数据结构在硬盘里储存，需要时读入内存。 sfs_disk_entry表示一个目录中的一个文件或目录，包含该项所对应inode的位置和文件名，同样也在硬盘里储存，需要时读入内存。 磁盘索引节点SFS中的磁盘索引节点代表了一个实际位于磁盘上的文件。首先我们看看在硬盘上的索引节点的内容：12345678struct sfs_disk_inode &#123; uint32_t size; 如果inode表示常规文件，则size是文件大小 uint16_t type; inode的文件类型 uint16_t nlinks; 此inode的硬链接数 uint32_t blocks; 此inode的数据块数的个数 uint32_t direct[SFS_NDIRECT]; 此inode的直接数据块索引值（有SFS_NDIRECT个） uint32_t indirect; 此inode的一级间接数据块索引值&#125;; 通过上表可以看出，如果inode表示的是文件，则成员变量direct[]直接指向了保存文件内容数据的数据块索引值。indirect间接指向了保存文件内容数据的数据块，indirect指向的是间接数据块（indirect_block），此数据块实际存放的全部是数据块索引，这些数据块索引指向的数据块才被用来存放文件内容数据。 默认的，ucore 里 SFS_NDIRECT 是 12，即直接索引的数据页大小为 12 4k = 48k；当使用一级间接数据块索引时，ucore 支持最大的文件大小为 12 4k + 1024 * 4k = 48k + 4m。数据索引表内，0 表示一个无效的索引，inode 里 blocks 表示该文件或者目录占用的磁盘的 block 的个数。indiret 为 0 时，表示不使用一级索引块。（因为 block 0 用来保存 super block，它不可能被其他任何文件或目录使用，所以这么设计也是合理的）。 对于普通文件，索引值指向的 block 中保存的是文件中的数据。而对于目录，索引值指向的数据保存的是目录下所有的文件名以及对应的索引节点所在的索引块（磁盘块）所形成的数组。数据结构如下：12345/* file entry (on disk) */struct sfs_disk_entry &#123; uint32_t ino; 索引节点所占数据块索引值 char name[SFS_MAX_FNAME_LEN + 1]; 文件名&#125;; 操作系统中，每个文件系统下的 inode 都应该分配唯一的 inode 编号。SFS 下，为了实现的简便，每个 inode 直接用他所在的磁盘 block 的编号作为 inode 编号。比如，root block 的 inode 编号为 1；每个 sfs_disk_entry 数据结构中，name 表示目录下文件或文件夹的名称，ino 表示磁盘 block 编号，通过读取该 block 的数据，能够得到相应的文件或文件夹的 inode。ino 为0时，表示一个无效的 entry。此外，和 inode 相似，每个 sfs_dirent_entry 也占用一个 block。 内存中的索引节点1234567891011/* inode for sfs */struct sfs_inode &#123; struct sfs_disk_inode *din; /* on-disk inode */ uint32_t ino; /* inode number */ uint32_t flags; /* inode flags */ bool dirty; /* true if inode modified */ int reclaim_count; /* kill inode if it hits zero */ semaphore_t sem; /* semaphore for din */ list_entry_t inode_link; /* entry for linked-list in sfs_fs */ list_entry_t hash_link; /* entry for hash linked-list in sfs_fs */&#125;; 可以看到SFS中的内存inode包含了SFS的硬盘inode信息，而且还增加了其他一些信息，这属于是便于进行是判断否改写、互斥操作、回收和快速地定位等作用。需要注意，一个内存inode是在打开一个文件后才创建的，如果关机则相关信息都会消失。而硬盘inode的内容是保存在硬盘中的，只是在进程需要时才被读入到内存中，用于访问文件或目录的具体内容数据 为了方便实现上面提到的多级数据的访问以及目录中 entry 的操作，对 inode SFS实现了一些辅助的函数： sfs_bmap_load_nolock：将对应 sfs_inode 的第 index 个索引指向的 block 的索引值取出存到相应的指针指向的单元（ino_store）。该函数只接受 index &lt;= inode-&gt;blocks 的参数。当 index == inode-&gt;blocks 时，该函数理解为需要为 inode 增长一个 block。并标记 inode 为 dirty（所有对 inode 数据的修改都要做这样的操作，这样，当 inode 不再使用的时候，sfs 能够保证 inode 数据能够被写回到磁盘）。sfs_bmap_load_nolock 调用的 sfs_bmap_get_nolock 来完成相应的操作，阅读 sfs_bmap_get_nolock，了解他是如何工作的。（sfs_bmap_get_nolock 只由 sfs_bmap_load_nolock 调用） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/* * sfs_bmap_load_nolock - according to the DIR&apos;s inode and the logical index of block in inode, find the NO. ofdisk block. * @sfs: sfs file system * @sin: sfs inode in memory * @index: the logical index of disk block in inode * @ino_store:the NO. of disk block */static intsfs_bmap_load_nolock(struct sfs_fs *sfs, struct sfs_inode *sin, uint32_t index, uint32_t *ino_store) &#123; struct sfs_disk_inode *din = sin-&gt;din; assert(index &lt;= din-&gt;blocks); int ret; uint32_t ino; bool create = (index == din-&gt;blocks); if ((ret = sfs_bmap_get_nolock(sfs, sin, index, create, &amp;ino)) != 0) &#123; return ret; &#125; assert(sfs_block_inuse(sfs, ino)); if (create) &#123; din-&gt;blocks ++; &#125; if (ino_store != NULL) &#123; *ino_store = ino; &#125; return 0;&#125;/* * sfs_bmap_get_nolock - according sfs_inode and index of block, find the NO. of disk block * no lock protect * @sfs: sfs file system * @sin: sfs inode in memory * @index: the index of block in inode * @create: BOOL, if the block isn&apos;t allocated, if create = 1 the alloc a block, otherwise just do nothing * @ino_store: 0 OR the index of already inused block or new allocated block. */static intsfs_bmap_get_nolock(struct sfs_fs *sfs, struct sfs_inode *sin, uint32_t index, bool create, uint32_t *ino_store) &#123; struct sfs_disk_inode *din = sin-&gt;din; int ret; uint32_t ent, ino; // the index of disk block is in the fist SFS_NDIRECT direct blocks if (index &lt; SFS_NDIRECT) &#123; if ((ino = din-&gt;direct[index]) == 0 &amp;&amp; create) &#123; if ((ret = sfs_block_alloc(sfs, &amp;ino)) != 0) &#123; return ret; &#125; din-&gt;direct[index] = ino; sin-&gt;dirty = 1; &#125; goto out; &#125; // the index of disk block is in the indirect blocks. index -= SFS_NDIRECT; if (index &lt; SFS_BLK_NENTRY) &#123; ent = din-&gt;indirect; if ((ret = sfs_bmap_get_sub_nolock(sfs, &amp;ent, index, create, &amp;ino)) != 0) &#123; return ret; &#125; if (ent != din-&gt;indirect) &#123; assert(din-&gt;indirect == 0); din-&gt;indirect = ent; sin-&gt;dirty = 1; &#125; goto out; &#125; else &#123; panic (&quot;sfs_bmap_get_nolock - index out of range&quot;); &#125;out: assert(ino == 0 || sfs_block_inuse(sfs, ino)); *ino_store = ino; return 0;&#125; sfs_bmap_truncate_nolock：将多级数据索引表的最后一个 entry 释放掉。他可以认为是 sfs_bmap_load_nolock 中，index == inode-&gt;blocks 的逆操作。当一个文件或目录被删除时，sfs 会循环调用该函数直到 inode-&gt;blocks 减为 0，释放所有的数据页。函数通过 sfs_bmap_free_nolock 来实现，他应该是 sfs_bmap_get_nolock 的逆操作。和 sfs_bmap_get_nolock 一样，调用 sfs_bmap_free_nolock 也要格外小心。 sfs_dirent_read_nolock：将目录的第 slot 个 entry 读取到指定的内存空间。他通过上面提到的函数来完成。 sfs_dirent_search_nolock：是常用的查找函数。他在目录下查找 name，并且返回相应的搜索结果（文件或文件夹）的 inode 的编号（也是磁盘编号），和相应的 entry 在该目录的 index 编号以及目录下的数据页是否有空闲的 entry。（SFS 实现里文件的数据页是连续的，不存在任何空洞；而对于目录，数据页不是连续的，当某个 entry 删除的时候，SFS 通过设置 entry-&gt;ino 为0将该 entry 所在的 block 标记为 free，在需要添加新 entry 的时候，SFS 优先使用这些 free 的 entry，其次才会去在数据页尾追加新的 entry。 注意，这些后缀为 nolock 的函数，只能在已经获得相应 inode 的semaphore才能调用。 inode的文件操作函数12345678static const struct inode_ops sfs_node_fileops = &#123; .vop_magic = VOP_MAGIC, .vop_open = sfs_openfile, .vop_close = sfs_close, .vop_read = sfs_read, .vop_write = sfs_write, ……&#125;; 上述sfs_openfile、sfs_close、sfs_read和sfs_write分别对应用户进程发出的open、close、read、write操作。其中sfs_openfile不用做什么事；sfs_close需要把对文件的修改内容写回到硬盘上，这样确保硬盘上的文件内容数据是最新的；sfs_read和sfs_write函数都调用了一个函数sfs_io，并最终通过访问硬盘驱动来完成对文件内容数据的读写。 inode的目录操作函数12345678static const struct inode_ops sfs_node_dirops = &#123; .vop_magic = VOP_MAGIC, .vop_open = sfs_opendir, .vop_close = sfs_close, .vop_getdirentry = sfs_getdirentry, .vop_lookup = sfs_lookup, ……&#125;; 对于目录操作而言，由于目录也是一种文件，所以sfs_opendir、sys_close对应户进程发出的open、close函数。相对于sfs_open，sfs_opendir只是完成一些open函数传递的参数判断，没做其他更多的事情。目录的close操作与文件的close操作完全一致。由于目录的内容数据与文件的内容数据不同，所以读出目录的内容数据的函数是sfs_getdirentry，其主要工作是获取目录下的文件inode信息。 设备层文件 IO 层在本实验中，为了统一地访问设备，我们可以把一个设备看成一个文件，通过访问文件的接口来访问设备。目前实现了stdin设备文件文件、stdout设备文件、disk0设备。stdin设备就是键盘，stdout设备就是CONSOLE（串口、并口和文本显示器），而disk0设备是承载SFS文件系统的磁盘设备。下面我们逐一分析ucore是如何让用户把设备看成文件来访问。 关键数据结构为了表示一个设备，需要有对应的数据结构，ucore为此定义了struct device，其描述如下：12345678struct device &#123; size_t d_blocks; //设备占用的数据块个数 size_t d_blocksize; //数据块的大小 int (*d_open)(struct device *dev, uint32_t open_flags); //打开设备的函数指针 int (*d_close)(struct device *dev); //关闭设备的函数指针 int (*d_io)(struct device *dev, struct iobuf *iob, bool write); //读写设备的函数指针 int (*d_ioctl)(struct device *dev, int op, void *data); //用ioctl方式控制设备的函数指针&#125;; 这个数据结构能够支持对块设备（比如磁盘）、字符设备（比如键盘、串口）的表示，完成对设备的基本操作。ucore虚拟文件系统为了把这些设备链接在一起，还定义了一个设备链表，即双向链表vdev_list，这样通过访问此链表，可以找到ucore能够访问的所有设备文件。 但这个设备描述没有与文件系统以及表示一个文件的inode数据结构建立关系，为此，还需要另外一个数据结构把device和inode联通起来，这就是vfs_dev_t数据结构：12345678// device info entry in vdev_list typedef struct &#123; const char *devname; struct inode *devnode; struct fs *fs; bool mountable; list_entry_t vdev_link;&#125; vfs_dev_t; 利用vfs_dev_t数据结构，就可以让文件系统通过一个链接vfs_dev_t结构的双向链表找到device对应的inode数据结构，一个inode节点的成员变量in_type的值是0x1234，则此 inode的成员变量in_info将成为一个device结构。这样inode就和一个设备建立了联系，这个inode就是一个设备文件。 stdout设备文件初始化既然stdout设备是设备文件系统的文件，自然有自己的inode结构。在系统初始化时，即只需如下处理过程1234567kern_init ——&gt; fs_init ——&gt; dev_init ——&gt; dev_init_stdout ——&gt; dev_create_inode ——&gt; stdout_device_init ——&gt; vfs_add_dev 在dev_init_stdout中完成了对stdout设备文件的初始化。即首先创建了一个inode，然后通过stdout_device_init完成对inode中的成员变量inode-&gt;__device_info进行初始：这里的stdout设备文件实际上就是指的console外设（它其实是串口、并口和CGA的组合型外设）。这个设备文件是一个只写设备，如果读这个设备，就会出错。接下来我们看看stdout设备的相关处理过程。 初始化stdout设备文件的初始化过程主要由stdout_device_init完成，其具体实现如下：123456789static voidstdout_device_init(struct device *dev) &#123; dev-&gt;d_blocks = 0; dev-&gt;d_blocksize = 1; dev-&gt;d_open = stdout_open; dev-&gt;d_close = stdout_close; dev-&gt;d_io = stdout_io; dev-&gt;d_ioctl = stdout_ioctl;&#125; 可以看到，stdout_open函数完成设备文件打开工作，如果发现用户进程调用open函数的参数flags不是只写（O_WRONLY），则会报错。1234567static intstdout_open(struct device *dev, uint32_t open_flags) &#123; if (open_flags != O_WRONLY) &#123; return -E_INVAL; &#125; return 0;&#125; 访问操作实现stdout_io函数完成设备的写操作工作，具体实现如下：1234567891011static intstdout_io(struct device *dev, struct iobuf *iob, bool write) &#123; if (write) &#123; char *data = iob-&gt;io_base; for (; iob-&gt;io_resid != 0; iob-&gt;io_resid --) &#123; cputchar(*data ++); &#125; return 0; &#125; return -E_INVAL;&#125; 可以看到，要写的数据放在iob-&gt;io_base所指的内存区域，一直写到iob-&gt;io_resid的值为0为止。每次写操作都是通过cputchar来完成的，此函数最终将通过console外设驱动来完成把数据输出到串口、并口和CGA显示器上过程。另外，也可以注意到，如果用户想执行读操作，则stdout_io函数直接返回错误值-E_INVAL。 stdin 设备文件这里的stdin设备文件实际上就是指的键盘。这个设备文件是一个只读设备，如果写这个设备，就会出错。接下来我们看看stdin设备的相关处理过程。 初始化stdin设备文件的初始化过程主要由stdin_device_init完成了主要的初始化工作，具体实现如下：123456789101112static voidstdin_device_init(struct device *dev) &#123; dev-&gt;d_blocks = 0; dev-&gt;d_blocksize = 1; dev-&gt;d_open = stdin_open; dev-&gt;d_close = stdin_close; dev-&gt;d_io = stdin_io; dev-&gt;d_ioctl = stdin_ioctl; p_rpos = p_wpos = 0; wait_queue_init(wait_queue);&#125; 相对于stdout的初始化过程，stdin的初始化相对复杂一些，多了一个stdin_buffer缓冲区，描述缓冲区读写位置的变量p_rpos、p_wpos以及用于等待缓冲区的等待队列wait_queue。在stdin_device_init函数的初始化中，也完成了对p_rpos、p_wpos和wait_queue的初始化。 访问操作实现stdin_io函数负责完成设备的读操作工作，具体实现如下：1234567891011static intstdin_io(struct device *dev, struct iobuf *iob, bool write) &#123; if (!write) &#123; int ret; if ((ret = dev_stdin_read(iob-&gt;io_base, iob-&gt;io_resid)) &gt; 0) &#123; iob-&gt;io_resid -= ret; &#125; return ret; &#125; return -E_INVAL;&#125; 可以看到，如果是写操作，则stdin_io函数直接报错返回。所以这也进一步说明了此设备文件是只读文件。如果此读操作，则此函数进一步调用dev_stdin_read函数完成对键盘设备的读入操作。dev_stdin_read函数的实现相对复杂一些，主要的流程如下：123456789101112131415161718192021222324252627282930static intdev_stdin_read(char *buf, size_t len) &#123; int ret = 0; bool intr_flag; local_intr_save(intr_flag); &#123; for (; ret &lt; len; ret ++, p_rpos ++) &#123; try_again: if (p_rpos &lt; p_wpos) &#123; *buf ++ = stdin_buffer[p_rpos % stdin_BUFSIZE]; &#125; else &#123; wait_t __wait, *wait = &amp;__wait; wait_current_set(wait_queue, wait, WT_KBD); local_intr_restore(intr_flag); schedule(); local_intr_save(intr_flag); wait_current_del(wait_queue, wait); if (wait-&gt;wakeup_flags == WT_KBD) &#123; goto try_again; &#125; break; &#125; &#125; &#125; local_intr_restore(intr_flag); return ret;&#125; 在上述函数中可以看出，如果p_rpos &lt; p_wpos，则表示有键盘输入的新字符在stdin_buffer中，于是就从stdin_buffer中取出新字符放到iobuf指向的缓冲区中；如果p_rpos &gt;=p_wpos，则表明没有新字符，这样调用read用户态库函数的用户进程就需要采用等待队列的睡眠操作进入睡眠状态，等待键盘输入字符的产生。 当识别出中断是键盘中断（中断号为IRQ_OFFSET + IRQ_KBD）时，会调用dev_stdin_write函数，来把字符写入到stdin_buffer中，且会通过等待队列的唤醒操作唤醒正在等待键盘输入的用户进程。 实验执行流程概述kern_init函数增加了对fs_init函数的调用。fs_init函数就是文件系统初始化的总控函数，它进一步调用了虚拟文件系统初始化函数vfs_init，与文件相关的设备初始化函数dev_init和Simple FS文件系统的初始化函数sfs_init。这三个初始化函数联合在一起，协同完成了整个虚拟文件系统、SFS文件系统和文件系统对应的设备（键盘、串口、磁盘）的初始化工作。其函数调用关系图如下所示： vfs_init如下所示：123456// vfs_init - vfs initializevoidvfs_init(void) &#123; sem_init(&amp;bootfs_sem, 1); vfs_devlist_init();&#125; sem_init函数主要是初始化了信号量和等待队列：12345voidsem_init(semaphore_t *sem, int value) &#123; sem-&gt;value = value; wait_queue_init(&amp;(sem-&gt;wait_queue));&#125; vfs_devlist_init主要是初始化设备列表，建立了一个device list双向链表vdev_list，为后续具体设备（键盘、串口、磁盘）以文件的形式呈现建立查找访问通道12345voidvfs_devlist_init(void) &#123; list_init(&amp;vdev_list); sem_init(&amp;vdev_list_sem, 1);&#125; dev_init函数通过进一步调用disk0/stdin/stdout_device_init完成对具体设备的初始化，把它们抽象成一个设备文件，并建立对应的inode数据结构，最后把它们链入到vdev_list中。这样通过虚拟文件系统就可以方便地以文件的形式访问这些设备了。1234567891011121314#define init_device(x) \ do &#123; \ extern void dev_init_##x(void); \ dev_init_##x(); \ &#125; while (0)/* dev_init - Initialization functions for builtin vfs-level devices. */voiddev_init(void) &#123; // init_device(null); init_device(stdin); init_device(stdout); init_device(disk0);&#125; 12345678910111213voiddev_init_disk0(void) &#123; struct inode *node; if ((node = dev_create_inode()) == NULL) &#123; panic(&quot;disk0: dev_create_node.\n&quot;); &#125; disk0_device_init(vop_info(node, device)); int ret; if ((ret = vfs_add_dev(&quot;disk0&quot;, node, 1)) != 0) &#123; panic(&quot;disk0: vfs_add_dev: %e.\n&quot;, ret); &#125;&#125; 123456789101112dev_init_stdin(void) &#123; struct inode *node; if ((node = dev_create_inode()) == NULL) &#123; panic(&quot;stdin: dev_create_node.\n&quot;); &#125; stdin_device_init(vop_info(node, device)); int ret; if ((ret = vfs_add_dev(&quot;stdin&quot;, node, 0)) != 0) &#123; panic(&quot;stdin: vfs_add_dev: %e.\n&quot;, ret); &#125;&#125; 12345678910111213voiddev_init_stdout(void) &#123; struct inode *node; if ((node = dev_create_inode()) == NULL) &#123; panic(&quot;stdout: dev_create_node.\n&quot;); &#125; stdout_device_init(vop_info(node, device)); int ret; if ((ret = vfs_add_dev(&quot;stdout&quot;, node, 0)) != 0) &#123; panic(&quot;stdout: vfs_add_dev: %e.\n&quot;, ret); &#125;&#125; sfs_init是完成对Simple FS的初始化工作，并把此实例文件系统挂在虚拟文件系统中，从而让ucore的其他部分能够通过访问虚拟文件系统的接口来进一步访问到SFS实例文件系统。12345678910111213/* * sfs_init - mount sfs on disk0 * * CALL GRAPH: * kern_init--&gt;fs_init--&gt;sfs_init */voidsfs_init(void) &#123; int ret; if ((ret = sfs_mount(&quot;disk0&quot;)) != 0) &#123; panic(&quot;failed: sfs: sfs_mount: %e.\n&quot;, ret); &#125;&#125; 在sfs_init中调用了sfs_mount –&gt; vfs_mount 进行挂载：1234intsfs_mount(const char *devname) &#123; return vfs_mount(devname, sfs_do_mount);&#125; vfs_mount把一个文件系统挂载到系统上12345678910111213141516171819202122232425262728293031323334/* * vfs_mount - Mount a filesystem. Once we&apos;ve found the device, call MOUNTFUNC to * set up the filesystem and hand back a struct fs. * * The DATA argument is passed through unchanged to MOUNTFUNC. */intvfs_mount(const char *devname, int (*mountfunc)(struct device *dev, struct fs **fs_store)) &#123; int ret; lock_vdev_list(); // 信号量操作 vfs_dev_t *vdev; if ((ret = find_mount(devname, &amp;vdev)) != 0) &#123; // 找一个同名设备 goto out; &#125; if (vdev-&gt;fs != NULL) &#123; ret = -E_BUSY; // 如果这个设备已经被挂载到一个文件系统上了，就不能被再挂载 goto out; &#125; assert(vdev-&gt;devname != NULL &amp;&amp; vdev-&gt;mountable); struct device *dev = vop_info(vdev-&gt;devnode, device); if ((ret = mountfunc(dev, &amp;(vdev-&gt;fs))) == 0) &#123; assert(vdev-&gt;fs != NULL); cprintf(&quot;vfs: mount %s.\n&quot;, vdev-&gt;devname); &#125;out: unlock_vdev_list(); // 解锁 return ret;&#125; 对于vop_info：12345678#define __vop_info(node, type) \ (&#123; \ struct inode *__node = (node); \ assert(__node != NULL &amp;&amp; check_inode_type(__node, type)); \ &amp;(__node-&gt;in_info.__##type##_info); \ &#125;)#define vop_info(node, type) __vop_info(node, type) __##type##_info是一个struct device或struct sfs_inode的结构体，一般调用vop_info的时候都是给一个变量赋值为一个设备的结构体。 mountfunc竟然是一个参数，流批流批。。。溯源的话有sfs_do_mount作为参数，下文介绍sfs_do_mount，太多了。。。 文件操作实现打开文件有了上述分析后，我们可以看看如果一个用户进程打开文件会做哪些事情？首先假定用户进程需要打开的文件已经存在在硬盘上。以user/sfs_filetest1.c为例，首先用户进程会调用在main函数中的如下语句：1int fd1 = safe_open(&quot;sfs\_filetest1&quot;, O_RDONLY); 如果ucore能够正常查找到这个文件，就会返回一个代表文件的文件描述符fd1，这样在接下来的读写文件过程中，就直接用这样fd1来代表就可以了。 safe_open实现如下，在open中调用了sys_open，接着调用了syscall，执行系统调用：1234567static int safe_open(const char *path, int open_flags)&#123; int fd = open(path, open_flags); printf(&quot;fd is %d\n&quot;,fd); assert(fd &gt;= 0); return fd;&#125; 通用文件访问接口层的处理流程进一步调用如下用户态函数： open-&gt;sys_open-&gt;syscall，从而引起系统调用进入到内核态。到了内核态后，通过中断处理例程，会调用到sys_open内核函数，并进一步调用sysfile_open内核函数。到了这里，需要把位于用户空间的字符串”sfs_filetest1”拷贝到内核空间中的字符串path中，这里copy_path完成了本功能，这里不再列出。进入到文件系统抽象层的处理流程完成进一步的打开文件操作中。12345678910111213141516171819static intsys_open(uint32_t arg[]) &#123; const char *path = (const char *)arg[0]; uint32_t open_flags = (uint32_t)arg[1]; return sysfile_open(path, open_flags);&#125;/* sysfile_open - open file */intsysfile_open(const char *__path, uint32_t open_flags) &#123; int ret; char *path; if ((ret = copy_path(&amp;path, __path)) != 0) &#123; return ret; &#125; ret = file_open(path, open_flags); kfree(path); return ret;&#125; 文件系统抽象层的处理流程 分配一个空闲的file数据结构变量file。 在文件系统抽象层的处理中，首先调用的是file_open函数，它要给这个即将打开的文件分配一个file数据结构的变量，这个变量其实是当前进程的打开文件数组current-&gt;fs_struct-&gt;filemap[]中的一个空闲元素（即还没用于一个打开的文件），而这个元素的索引值就是最终要返回到用户进程并赋值给变量fd1。到了这一步还仅仅是给当前用户进程分配了一个file数据结构的变量，还没有找到对应的文件索引节点。 调用vfs_open函数来找到path指出的文件所对应的基于inode数据结构的VFS索引节点node。 vfs_open函数需要完成： 确定读写权限； 通过vfs_lookup找到path对应文件的inode；首先是调用get_device，先对路径字符串进行判断，看是不是声明了设备（有：）或者是绝对路径（有/）。如果是相对路径，调用vfs_get_curdir获得当前的路径。如果有设备名，则根据路径中的设备名在设备list中找到这个设备，返回一个inode。如果是绝对路径，则返回根目录。如果开头有个‘:’，说明是在当前文件系统中，返回的是当前目录。 找到文件设备的根目录“/”的索引节点需要注意，这里的vfs_lookup函数是一个针对目录的操作函数，它会调用vop_lookup函数来找到SFS文件系统中的“/”目录下的“sfs_filetest1”文件。为此，vfs_lookup函数首先调用get_device函数，并进一步调用vfs_get_bootfs函数来找到根目录“/”对应的inode。这个inode就是位于vfs.c中的inode变量bootfs_node。这个变量在init_main函数（位于kern/process/proc.c）执行时获得了赋值。 通过调用vop_lookup函数来查找到根目录“/”下对应文件sfs_filetest1的索引节点，如果找到就返回此索引节点。 调用vop_open函数打开文件。 调用了vop_truncate（应该是这个sfs_truncfile），调整文件大小到适当的大小（按照块个数计算） 调用了vfs_fsync，如果发生了什么使得这个块变成dirty了，就调用d_io把它写进去。 把file和node建立联系，设置file的读写权限，如果是append模式的话还要把file的pos设置到末尾。完成后，将返回到file_open函数中，通过执行语句“file-&gt;node=node;”，就把当前进程的current-&gt;fs_struct-&gt;filemap[fd]（即file所指变量）的成员变量node指针指向了代表sfs_filetest1文件的索引节点inode。 这时返回fd。经过重重回退，通过系统调用返回，用户态的syscall-&gt;sys_open-&gt;open-&gt;safe_open等用户函数的层层函数返回，最终把fd赋值给fd1。自此完成了打开文件操作。12345678910111213141516171819202122232425262728293031323334353637383940414243444546// open fileintfile_open(char *path, uint32_t open_flags) &#123; bool readable = 0, writable = 0; switch (open_flags &amp; O_ACCMODE) &#123; case O_RDONLY: readable = 1; break; case O_WRONLY: writable = 1; break; case O_RDWR: readable = writable = 1; break; default: return -E_INVAL; &#125; int ret; struct file *file; if ((ret = fd_array_alloc(NO_FD, &amp;file)) != 0) &#123; return ret; &#125;//分配一个file数据结构的变量 struct inode *node; if ((ret = vfs_open(path, open_flags, &amp;node)) != 0) &#123; fd_array_free(file); return ret; &#125;//找到path指出的文件所对应的基于inode数据结构的VFS索引节点node file-&gt;pos = 0; if (open_flags &amp; O_APPEND) &#123; struct stat __stat, *stat = &amp;__stat; if ((ret = vop_fstat(node, stat)) != 0) &#123; vfs_close(node); fd_array_free(file); return ret; &#125; file-&gt;pos = stat-&gt;st_size; &#125;// 根据open_flags找当前指针应该指在文件的什么位置 file-&gt;node = node; file-&gt;readable = readable; file-&gt;writable = writable; fd_array_open(file); return file-&gt;fd;&#125; SFS文件系统层的处理流程在sfs_inode.c中的sfs_node_dirops变量定义了“.vop_lookup = sfs_lookup”，所以我们重点分析sfs_lookup的实现。 sfs_lookup有三个参数：node，path，node_store。其中node是根目录“/”所对应的inode节点；path是文件sfs_filetest1的绝对路径/sfs_filetest1，而node_store是经过查找获得的sfs_filetest1所对应的inode节点。sfs_lookup函数以“/”为分割符，从左至右逐一分解path获得各个子目录和最终文件对应的inode节点。在本例中是调用sfs_lookup_once查找以根目录下的文件sfs_filetest1所对应的inode节点。当无法分解path后，就意味着找到了sfs_filetest1对应的inode节点，就可顺利返回了。1234567891011121314151617181920212223242526/* * sfs_lookup - Parse path relative to the passed directory * DIR, and hand back the inode for the file it * refers to. */static intsfs_lookup(struct inode *node, char *path, struct inode **node_store) &#123; struct sfs_fs *sfs = fsop_info(vop_fs(node), sfs); assert(*path != &apos;\0&apos; &amp;&amp; *path != &apos;/&apos;); vop_ref_inc(node); struct sfs_inode *sin = vop_info(node, sfs_inode); // 找到sfs_inode __sfs_inode_info。 if (sin-&gt;din-&gt;type != SFS_TYPE_DIR) &#123; vop_ref_dec(node); return -E_NOTDIR; &#125; struct inode *subnode; int ret = sfs_lookup_once(sfs, sin, path, &amp;subnode, NULL); // 找到与路径相符的inode并加载到subnode里。 vop_ref_dec(node); if (ret != 0) &#123; return ret; &#125; *node_store = subnode; return 0;&#125; 读文件用户进程有如下语句：1read(fd, data, len); 即读取fd对应文件，读取长度为len，存入data中。下面来分析一下读文件的实现。 通用文件访问接口层的处理流程进一步调用如下用户态函数：read-&gt;sys_read-&gt;syscall，从而引起系统调用进入到内核态。到了内核态以后，通过中断处理例程，会调用到sys_read内核函数，并进一步调用sysfile_read内核函数，进入到文件系统抽象层处理流程完成进一步读文件的操作。1234567static intsys_read(uint32_t arg[]) &#123; int fd = (int)arg[0]; void *base = (void *)arg[1]; size_t len = (size_t)arg[2]; return sysfile_read(fd, base, len);&#125; 文件系统抽象层的处理流程 检查错误，即检查读取长度是否为0和文件是否可读。 分配buffer空间，即调用kmalloc函数分配4096字节的buffer空间。 读文件过程 实际读文件。 循环读取文件，每次读取buffer大小。 每次循环中，先检查剩余部分大小，若其小于4096字节，则只读取剩余部分的大小。 调用file_read函数（详细分析见后）将文件内容读取到buffer中，alen为实际大小。 调用copy_to_user函数将读到的内容拷贝到用户的内存空间中。 调整各变量以进行下一次循环读取，直至指定长度读取完成。 最后函数调用层层返回至用户程序，用户程序收到了读到的文件内容。 file_read函数 这个函数是读文件的核心函数。函数有4个参数， fd是文件描述符， base是缓存的基地址， len是要读取的长度， copied_store存放实际读取的长度。 函数首先调用fd2file函数找到对应的file结构，并检查是否可读。 调用filemap_acquire函数使打开这个文件的计数加1。 调用vop_read函数将文件内容读到iob中（详细分析见后）。 调整文件指针偏移量pos的值，使其向后移动实际读到的字节数iobuf_used(iob)。 调用filemap_release函数使打开这个文件的计数减1，若打开计数为0，则释放file。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/* sysfile_read - read file */intsysfile_read(int fd, void *base, size_t len) &#123; struct mm_struct *mm = current-&gt;mm; if (len == 0) &#123; return 0; &#125; if (!file_testfd(fd, 1, 0)) &#123; return -E_INVAL; &#125;// 检查读取长度是否为0和文件是否可读 void *buffer; if ((buffer = kmalloc(IOBUF_SIZE)) == NULL) &#123; return -E_NO_MEM; &#125;// 调用kmalloc函数分配4096字节的buffer空间 int ret = 0; size_t copied = 0, alen; while (len != 0) &#123; if ((alen = IOBUF_SIZE) &gt; len) &#123; alen = len; &#125; ret = file_read(fd, buffer, alen, &amp;alen); // 将文件内容读取到buffer中，alen为实际大小 if (alen != 0) &#123; lock_mm(mm); &#123; if (copy_to_user(mm, base, buffer, alen)) &#123; // copy_to_user在vmm.c中，检查权限后memcpy assert(len &gt;= alen); base += alen, len -= alen, copied += alen; &#125; // 调用copy_to_user函数将读到的内容拷贝到用户的内存空间中 // 调整各变量以进行下一次循环读取，直至指定长度读取完成 else if (ret == 0) &#123; ret = -E_INVAL; &#125; &#125; unlock_mm(mm); &#125; if (ret != 0 || alen == 0) &#123; goto out; &#125; &#125;out: kfree(buffer); if (copied != 0) &#123; return copied; &#125; return ret;&#125; 123456789101112131415161718192021222324252627282930// read fileintfile_read(int fd, void *base, size_t len, size_t *copied_store) &#123; int ret; struct file *file; *copied_store = 0; if ((ret = fd2file(fd, &amp;file)) != 0) &#123; return ret; &#125; // 找到对应的file结构 if (!file-&gt;readable) &#123; return -E_INVAL; &#125; fd_array_acquire(file); // 打开这个文件的计数加1 struct iobuf __iob, *iob = iobuf_init(&amp;__iob, base, len, file-&gt;pos); ret = vop_read(file-&gt;node, iob); // 文件内容读到iob中，通过sfs_read --&gt; sfs_io，获取到inode，执行sfs_io_nolock。 size_t copied = iobuf_used(iob); if (file-&gt;status == FD_OPENED) &#123; file-&gt;pos += copied; &#125; *copied_store = copied; fd_array_release(file); return ret;&#125; SFS文件系统层的处理流程vop_read函数实际上是对sfs_read的包装。在sfs_inode.c中sfs_node_fileops变量定义了.vop_read = sfs_read，所以下面来分析sfs_read函数的实现。 sfs_read函数调用sfs_io函数。 它有三个参数，node是对应文件的inode，iob是缓存，write表示是读还是写的布尔值（0表示读，1表示写），这里是0。 函数先找到inode对应sfs和sin， 然后调用sfs_io_nolock函数进行读取文件操作， 最后调用iobuf_skip函数调整iobuf的指针。1234567891011121314151617181920212223242526272829/* * sfs_io - Rd/Wr file. the wrapper of sfs_io_nolock with lock protect */static inline intsfs_io(struct inode *node, struct iobuf *iob, bool write) &#123; struct sfs_fs *sfs = fsop_info(vop_fs(node), sfs); struct sfs_inode *sin = vop_info(node, sfs_inode); int ret; lock_sin(sin); &#123; size_t alen = iob-&gt;io_resid; ret = sfs_io_nolock(sfs, sin, iob-&gt;io_base, iob-&gt;io_offset, &amp;alen, write); if (alen != 0) &#123; iobuf_skip(iob, alen); &#125; &#125; unlock_sin(sin); return ret;&#125;/* * iobuf_skip - change the current position of io buffer */voidiobuf_skip(struct iobuf *iob, size_t n) &#123; assert(iob-&gt;io_resid &gt;= n); iob-&gt;io_base += n, iob-&gt;io_offset += n, iob-&gt;io_resid -= n;&#125; 练习1: 完成读文件操作的实现首先完成proc.c中process控制块的初始化，在static struct proc_struct *alloc_proc(void)中添加：1proc-&gt;filesp = NULL; 如果调用了read系统调用，继续调用sys_read函数，和sysfile_read函数，在这个函数中，创建了缓冲区，进一步复制到用户空间的指定位置去；从文件读取数据的函数是file_read。 在file_read函数中，通过文件描述符找到相应文件对应的内存中的inode信息，调用vop_read进行读取处理，vop_read继续调用sfs_read函数，然后调用sfs_io函数和sfs_io_nolock函数。 在sfs_io_nolock函数中， 先计算一些辅助变量，并处理一些特殊情况（比如越界）， 然后有sfs_buf_op = sfs_rbuf，sfs_block_op = sfs_rblock，设置读取的函数操作。 先处理起始的没有对齐到块的部分，再以块为单位循环处理中间的部分，最后处理末尾剩余的部分。 每部分中都调用sfs_bmap_load_nolock函数得到blkno对应的inode编号， 并调用sfs_rbuf或sfs_rblock函数读取数据（中间部分调用sfs_rblock，起始和末尾部分调用sfs_rbuf），调整相关变量。 完成后如果offset + alen &gt; din-&gt;fileinfo.size（写文件时会出现这种情况，读文件时不会出现这种情况，alen为实际读写的长度），则调整文件大小为offset + alen并设置dirty变量。 sfs_bmap_load_nolock函数将对应sfs_inode的第index个索引指向的block的索引值取出存到相应的指针指向的单元（ino_store）。 调用sfs_bmap_get_nolock来完成相应的操作。 sfs_rbuf和sfs_rblock函数最终都调用sfs_rwblock_nolock函数完成操作， 而sfs_rwblock_nolock函数调用dop_io-&gt;disk0_io-&gt;disk0_read_blks_nolock-&gt;ide_read_secs完成对磁盘的操作。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106/* * sfs_io_nolock - Rd/Wr a file contentfrom offset position to offset+ length disk blocks&lt;--&gt;buffer (in memroy) * * @sfs: sfs file system * @sin: sfs inode in memory * @buf: the buffer Rd/Wr * @offset: the offset of file * @alenp: the length need to read (is a pointer). and will RETURN the really Rd/Wr lenght * @write: BOOL, 0 read, 1 write */static intsfs_io_nolock(struct sfs_fs *sfs, struct sfs_inode *sin, void *buf, off_t offset, size_t *alenp, bool write) &#123; struct sfs_disk_inode *din = sin-&gt;din; assert(din-&gt;type != SFS_TYPE_DIR); off_t endpos = offset + *alenp, blkoff; *alenp = 0; // 计算出读写的长度，从初始偏移量走到文件的哪个位置 if (offset &lt; 0 || offset &gt;= SFS_MAX_FILE_SIZE || offset &gt; endpos) &#123; return -E_INVAL; &#125; if (offset == endpos) &#123; return 0; &#125; if (endpos &gt; SFS_MAX_FILE_SIZE) &#123; endpos = SFS_MAX_FILE_SIZE; &#125; // 文件过大，到了最大支持的文件长度了 if (!write) &#123; if (offset &gt;= din-&gt;size) &#123; return 0; &#125; if (endpos &gt; din-&gt;size) &#123; endpos = din-&gt;size; &#125; &#125; // 如果end position超过了文件大小，就把它移动到这个文件的末尾 int (*sfs_buf_op)(struct sfs_fs *sfs, void *buf, size_t len, uint32_t blkno, off_t offset); int (*sfs_block_op)(struct sfs_fs *sfs, void *buf, uint32_t blkno, uint32_t nblks); if (write) &#123; sfs_buf_op = sfs_wbuf, sfs_block_op = sfs_wblock; &#125; else &#123; sfs_buf_op = sfs_rbuf, sfs_block_op = sfs_rblock; &#125; // 设置读取/写入的函数操作 int ret = 0; size_t size, alen = 0; uint32_t ino; uint32_t blkno = offset / SFS_BLKSIZE; // 起始的block序号 uint32_t nblks = endpos / SFS_BLKSIZE - blkno; // 一共要读写多少个block？//LAB8:EXERCISE1 YOUR CODE //HINT: call sfs_bmap_load_nolock, sfs_rbuf, sfs_rblock,etc. // read different kind of blocks in file /* * (1) If offset isn&apos;t aligned with the first block, Rd/Wr some content from offset to the end of the first block * NOTICE: useful function: sfs_bmap_load_nolock, sfs_buf_op * Rd/Wr size = (nblks != 0) ? (SFS_BLKSIZE - blkoff) : (endpos - offset) * (2) Rd/Wr aligned blocks * NOTICE: useful function: sfs_bmap_load_nolock, sfs_block_op * (3) If end position isn&apos;t aligned with the last block, Rd/Wr some content from begin to the (endpos % SFS_BLKSIZE) of the last block * NOTICE: useful function: sfs_bmap_load_nolock, sfs_buf_op */ if (offset % SFS_BLKSIZE != 0 || endpos / SFS_BLKSIZE == offset / SFS_BLKSIZE)&#123; blkoff = offset % SFS_BLKSIZE; size = (nblks != 0) ? (SFS_BLKSIZE - blkoff) : (endpos - offset); if ((ret = sfs_bmap_load_nolock(sfs, sin, blkno, &amp;ino)) != 0) goto out; if ((ret = sfs_buf_op(sfs, buf, size, ino, blkoff)) != 0) goto out; alen += size; buf += size; &#125; // 处理如果不是从块的开头开始写的情况，如果偏移量%块大小不是0则是从块内部开始写的。如果nblks是0的话说明只有一个块里的一部分需要写。先把这个写了。 uint32_t my_nblks = nblks; if (offset % SFS_BLKSIZE != 0 &amp;&amp; my_nblks &gt; 0) my_nblks --; // 如果是从一个块的一部分开始写的，那在总的块数上需要减一。 if (my_nblks &gt; 0) &#123; int temp_blkno = (offset % SFS_BLKSIZE == 0) ? blkno: blkno + 1 if ((ret = sfs_bmap_load_nolock(sfs, sin, temp_blkno, &amp;ino)) != 0) goto out; if ((ret = sfs_block_op(sfs, buf, ino, my_nblks)) != 0) // 这里的sfs_block_op是一个循环，把mu_nblks个块进行读写，跟开头和结尾的那个sfs_buf_op不一样 goto out; size = SFS_BLKSIZE * my_nblks; alen += size; buf += size; &#125; //下边就是处理如果最后一部分是最后一块的一部分的了，ino存储了disk上的inode的编号，然后在下边的sfs_buf_op中，处理最后一小块 if (endpos % SFS_BLKSIZE != 0 &amp;&amp; endpos / SFS_BLKSIZE != offset / SFS_BLKSIZE) &#123; size = endpos % SFS_BLKSIZE; if ((ret = sfs_bmap_load_nolock(sfs, sin, endpos / SFS_BLKSIZE, &amp;ino) == 0) != 0) goto out; if ((ret = sfs_buf_op(sfs, buf, size, ino, 0)) != 0) goto out; alen += size; buf += size; &#125;out: *alenp = alen; if (offset + alen &gt; sin-&gt;din-&gt;size) &#123; sin-&gt;din-&gt;size = offset + alen; sin-&gt;dirty = 1; &#125; return ret;&#125; 请在实验报告中给出设计实现”UNIX的PIPE机制“的概要设方案，鼓励给出详细设计方案。 PIPE机制可以看成是一个缓冲区，可以在磁盘上（或内存中？）保留一部分空间作为pipe机制的缓冲区。当两个进程之间要求建立pipe时，在两个进程的进程控制块上修改某些属性表明这个进程是管道数据的发送方还是接受方，这样就可以将stdin或stdout重定向到生成的临时文件里，在两个进程中打开这个临时文件。 当进程A使用stdout写时，查询PCB中的相关变量，把这些stdout数据输出到临时文件中； 当进程B使用stdin的时候，查询PCB中的信息，从临时文件中读取数据； 练习2: 完成基于文件系统的执行程序机制的实现改写proc.c中的load_icode函数和其他相关函数，实现基于文件系统的执行程序机制。首先是在do_execve中进行文件名和命令行参数的复制，执行sysfie_open打开相关文件，fd是已经打开的这个文件。执行： make qemu。如果能看看到sh用户程序的执行界面，则基本成功了。如果在sh用户界面上可 以执行”ls”,”hello”等其他放置在sfs文件系统中的其他执行程序，则可以认为本实验基本成功。 给要执行的用户进程创建一个新的内存管理结构mm， 创建用户内存空间的新的页目录表； 将磁盘上的ELF文件的TEXT/DATA/BSS段正确地加载到用户空间中； 从磁盘中读取elf文件的header； 根据elfheader中的信息，获取到磁盘上的program header； 对于每一个program header: 为TEXT/DATA段在用户内存空间上的保存分配物理内存页，同时建立物理页和虚拟页的映射关系； 从磁盘上读取TEXT/DATA段，并且复制到用户内存空间上去； 根据program header得知是否需要创建BBS段，如果是，则分配相应的内存空间，并且全部初始化成0，并且建立物理页和虚拟页的映射关系； 将用户栈的虚拟空间设置为合法，并且为栈顶部分先分配4个物理页，建立好映射关系； 切换到用户地址空间； 设置好用户栈上的信息，即需要传递给执行程序的参数； 设置好中断帧； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203static intload_icode(int fd, int argc, char **kargv) &#123; /* LAB8:EXERCISE2 YOUR CODE HINT:how to load the file with handler fd in to process&apos;s memory? how to setup argc/argv? * MACROs or Functions: * mm_create - create a mm * setup_pgdir - setup pgdir in mm * load_icode_read - read raw data content of program file * mm_map - build new vma * pgdir_alloc_page - allocate new memory for TEXT/DATA/BSS/stack parts * lcr3 - update Page Directory Addr Register -- CR3 * * (1) create a new mm for current process * (2) create a new PDT, and mm-&gt;pgdir= kernel virtual addr of PDT * (3) copy TEXT/DATA/BSS parts in binary to memory space of process * (3.1) read raw data content in file and resolve elfhdr * (3.2) read raw data content in file and resolve proghdr based on info in elfhdr * (3.3) call mm_map to build vma related to TEXT/DATA * (3.4) callpgdir_alloc_page to allocate page for TEXT/DATA, read contents in file * and copy them into the new allocated pages * (3.5) callpgdir_alloc_page to allocate pages for BSS, memset zero in these pages * (4) call mm_map to setup user stack, and put parameters into user stack * (5) setup current process&apos;s mm, cr3, reset pgidr (using lcr3 MARCO) * (6) setup uargc and uargv in user stacks * (7) setup trapframe for user environment * (8) if up steps failed, you should cleanup the env. */ if (current-&gt;mm != NULL) &#123; panic(&quot;load_icode: current-&gt;mm must be empty.\n&quot;); &#125; int ret = -E_NO_MEM; struct mm_struct *mm; //(1) create a new mm for current process if ((mm = mm_create()) == NULL) &#123; goto bad_mm; &#125; //(2) create a new PDT, and mm-&gt;pgdir= kernel virtual addr of PDT if (setup_pgdir(mm) != 0) &#123; goto bad_pgdir_cleanup_mm; &#125; //(3) copy TEXT/DATA section, build BSS parts in binary to memory space of process struct Page *page; //(3.1) get the file header of the bianry program (ELF format) struct elfhdr elf; off_t offset = 0; if((ret = load_icode_read(fd, (void*)&amp;elf, sizeof(struct elfhdr), 0)) != 0) &#123; // elf header读取到elf中，这里的参数比较复杂需要先取地址再类型转换 goto bad_elf_cleanup_pgdir; &#125; if (elf.e_magic != ELF_MAGIC) &#123; //检查是不是魔数，如果是的话才是对的elf文件 ret = -E_INVAL_ELF; goto bad_elf_cleanup_pgdir; &#125; offset += sizeof(struct elfhdr); // 这个文件已经读取到elf header 之后了 uint32_t vm_flags, perm; struct proghdr ph; for (int i=0; i &lt; elf.e_phnum; i ++) &#123; // e_phnum is number of entries in program header. //(3.4) find every program section headers // 第二三个参数分别是读取的长度和在文件中的偏移量。 off_t phoff = elf.e_phoff + sizeof(struct proghdr) * i; load_icode_read(fd, (void*)&amp;ph, sizeof(struct proghdr), phoff); if (ph.p_type != ELF_PT_LOAD) &#123; continue ; &#125; if (ph.p_filesz &gt; ph.p_memsz) &#123; ret = -E_INVAL_ELF; goto bad_cleanup_mmap; &#125; if (ph.p_filesz == 0) &#123; continue ; &#125; // call mm_map fun to setup the new vma ( ph-&gt;p_va, ph-&gt;p_memsz) vm_flags = 0, perm = PTE_U; if (ph.p_flags &amp; ELF_PF_X) vm_flags |= VM_EXEC; if (ph.p_flags &amp; ELF_PF_W) vm_flags |= VM_WRITE; if (ph.p_flags &amp; ELF_PF_R) vm_flags |= VM_READ; if (vm_flags &amp; VM_WRITE) perm |= PTE_W; if ((ret = mm_map(mm, ph.p_va, ph.p_memsz, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; &#125; // 虚拟内存管理的权限控制，并设置映射 offset = ph.p_offset; size_t off, size; uintptr_t start = ph.p_va, end=ph.p_va+ph.p_filesz, la = ROUNDDOWN(start, PGSIZE); // start 和 end 是vma中的segment的起始和结尾 ret = -E_NO_MEM; while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; ret = -E_NO_MEM; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; load_icode_read(fd, page2kva(page)+off, size, offset); //memcpy(page2kva(page) + off, from, size); start += size, offset += size; &#125; // build BSS section of binary program end = ph.p_va + ph.p_memsz; if (start &lt; la) &#123; /* ph-&gt;p_memsz == ph-&gt;p_filesz */ if (start == end) &#123; continue ; &#125; off = start + PGSIZE - la, size = PGSIZE - off; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page) + off, 0, size); start += size; assert((end &lt; la &amp;&amp; start == end) || (end &gt;= la &amp;&amp; start == la)); &#125; while (start &lt; end) &#123; if ((page = pgdir_alloc_page(mm-&gt;pgdir, la, perm)) == NULL) &#123; ret = -E_NO_MEM; goto bad_cleanup_mmap; &#125; off = start - la, size = PGSIZE - off, la += PGSIZE; if (end &lt; la) &#123; size -= la - end; &#125; memset(page2kva(page), 0, size); start += size; &#125; &#125; sysfile_close(fd); //(4) build user stack memory vm_flags = VM_READ | VM_WRITE | VM_STACK; if ((ret = mm_map(mm, USTACKTOP - USTACKSIZE, USTACKSIZE, vm_flags, NULL)) != 0) &#123; goto bad_cleanup_mmap; &#125; uint32_t stacktop = USTACKTOP; uint32_t argsize = 0; for(int j = 0; j&lt; argc ; j++) argsize += (1 + strlen(kargv[j])); // 计算传进来的参数的大小和长度，并进行取整 argsize = (argsize / sizeof(long)+1)*sizeof(long); argsize += (2+argc)*sizeof(long); stacktop = USTACKTOP - argsize; uint32_t pagen = argsize / PGSIZE + 4; for (int j = 1; j &lt;= 4; ++ j) &#123; assert(pgdir_alloc_page(mm-&gt;pgdir, USTACKTOP-PGSIZE*j , PTE_USER) != NULL); &#125; //(5) set current process&apos;s mm, sr3, and set CR3 reg = physical addr of Page Directory mm_count_inc(mm); current-&gt;mm = mm; current-&gt;cr3 = PADDR(mm-&gt;pgdir); lcr3(PADDR(mm-&gt;pgdir)); //(6) setup trapframe for user environment uint32_t now_pos = stacktop, argvp; *((uint32_t*)now_pos) = argc; now_pos += 4; *((uint32_t *) now_pos) = argvp = now_pos + 4; now_pos += 4; now_pos += argc*4; //压栈 for (int j = 0; j &lt; argc; ++ j) &#123; argsize = strlen(kargv[j]) + 1; memcpy((void *) now_pos, kargv[j], argsize); *((uint32_t *) (argvp + j * 4)) = now_pos; now_pos += argsize; &#125; /* LAB5:EXERCISE1 YOUR CODE * should set tf_cs,tf_ds,tf_es,tf_ss,tf_esp,tf_eip,tf_eflags * NOTICE: If we set trapframe correctly, then the user level process can return to USER MODE from kernel. So * tf_cs should be USER_CS segment (see memlayout.h) * tf_ds=tf_es=tf_ss should be USER_DS segment * tf_esp should be the top addr of user stack (USTACKTOP) * tf_eip should be the entry point of this binary program (elf-&gt;e_entry) * tf_eflags should be set to enable computer to produce Interrupt */ struct trapframe *tf = current-&gt;tf; memset(tf, 0, sizeof(struct trapframe)); tf-&gt;tf_cs = USER_CS; tf-&gt;tf_ds = tf-&gt;tf_es = tf-&gt;tf_ss = USER_DS; tf-&gt;tf_esp = stacktop; tf-&gt;tf_eip = elf.e_entry; tf-&gt;tf_eflags = 0x2 | FL_IF; // to enable interrupt ret = 0;out: return ret;bad_cleanup_mmap: exit_mmap(mm);bad_elf_cleanup_pgdir: put_pgdir(mm);bad_pgdir_cleanup_mm: mm_destroy(mm);bad_mm: goto out;&#125; UNIX的硬链接和软链接机制： 硬链接： 文件有相同的 inode 及 data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 不能对目录进行创建，只可对文件创建； 删除一个硬链接文件并不影响其他有相同 inode 号的文件。 软链接： 软链接有自己的文件属性及权限等； 可对不存在的文件或目录创建软链接； 软链接可交叉文件系统； 软链接可对文件或目录创建； 创建软链接时，链接计数 i_nlink 不会增加； 删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接 硬链接： 与普通文件没什么不同，inode 都指向同一个文件在硬盘中的区块软链接： 保存了其代表的文件的绝对路径，是另外一种文件，在硬盘上有独立的区块，访问时替换自身路径。 sfs_disk_inode结构体中有一个nlinks变量，如果要创建一个文件的软链接，这个软链接也要创建inode，只是它的类型是链接，找一个域设置它所指向的文件inode，如果文件是一个链接，就可以通过保存的inode位置进行操作；当删除一个软链接时，直接删掉inode即可； 硬链接与文件是共享inode的，如果创建一个硬链接，需要将源文件中的被链接的计数加1；当删除一个硬链接的时候，除了需要删掉inode之外，还需要将硬链接指向的文件的被链接计数减1，如果减到了0，则需要将A删除掉；]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华大学操作系统课程实验三]]></title>
    <url>%2F2019%2F06%2F29%2F%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AF%BE%E7%A8%8B%E5%AE%9E%E9%AA%8C%E4%B8%89%2F</url>
    <content type="text"><![CDATA[实验三实验内容在实验二的基础上，借助页表机制和实验一中涉及的中断异常处理机制，完成Pgfault异常处理和FIFO页替换算法的实现，结合磁盘提供的缓存空间，从而能够支持虚存管理，提供一个比实际物理内存空间“更大”的虚拟内存空间给系统使用。这个实验与实际操作系统中的实现比较起来要简单，不过需要了解实验一和实验二的具体实现。实际操作系统系统中的虚拟内存管理设计与实现是相当复杂的，涉及到与进程管理系统、文件系统等的交叉访问。 简单原理 copy from gitbook通过内存地址虚拟化，可以使得软件在没有访问某虚拟内存地址时不分配具体的物理内存，而只有在实际访问某虚拟内存地址时，操作系统再动态地分配物理内存，建立虚拟内存到物理内存的页映射关系，这种技术称为按需分页（demand paging）。 把不经常访问的数据所占的内存空间临时写到硬盘上，这样可以腾出更多的空闲内存空间给经常访问的数据；当CPU访问到不经常访问的数据时，再把这些数据从硬盘读入到内存中，这种技术称为页换入换出（page swap in/out）。这种内存管理技术给了程序员更大的内存“空间”，从而可以让更多的程序在内存中并发运行。 参考ucore总控函数kern_init的代码，在调用完成虚拟内存初始化的vmm_init函数之前，需要首先调用pmm_init函数完成物理内存的管理，调用pic_init函数完成中断控制器的初始化，调用idt_init函数完成中断描述符表的初始化。在调用完idt_init函数之后，将进一步调用新函数vmm_init、ide_init、swap_init。do_pgfault函数会申请一个空闲物理页，并建立好虚实映射关系，从而使得这样的“合法”虚拟页有实际的物理页帧对应。ide_init就是完成对用于页换入换出的硬盘（简称swap硬盘）的初始化工作。完成ide_init函数后，ucore就可以对这个swap硬盘进行读写操作了。 vmm设计包括两部分：mm_struct（mm）和vma_struct（vma）。mm是具有相同PDT的连续虚拟内存区域集的内存管理器。 vma是一个连续的虚拟内存区域。 vma中存在线性链接列表，mm的vma的redblack链接列表。（redblack是啥？）建立mm_struct和vma_struct数据结构。当访问内存产生pagefault异常时，可获得访问的内存的方式（读或写）以及具体的虚拟内存地址，这样ucore就可以查询此地址，看是否属于vma_struct数据结构中描述的合法地址范围中，如果在，则可根据具体情况进行请求调页/页换入换出处理；如果不在，则报错。两种数据结构：123456789101112131415161718192021222324struct mm_struct &#123; // 链接所有属于同一页目录表的虚拟内存空间 list_entry_t mmap_list; // 指向当前正在使用的虚拟内存空间，直接使用这个指针就能找到下一次要用到的虚拟空间 struct vma_struct *mmap_cache; pde_t *pgdir; // 第一级页表的起始地址，即页目录表项PDT。通过访问pgdir可以查找某虚拟地址对应的页表项是否存在以及页表项的属性等 int map_count; // 记录了链接了的vma_struct个数，共享了几次 void *sm_priv; // 指向记录页访问情况的链表头。&#125;;struct vma_struct &#123; // 描述应用程序对虚拟内存“需求” struct mm_struct *vm_mm; // 指向更高抽象层次的数据结构 // the set of vma using the same PDT uintptr_t vm_start; // 连续地址虚拟内存空间的起始位置 uintptr_t vm_end; // 连续地址虚拟内存空间的结束位置 uint32_t vm_flags; // 标志属性（读/写/执行） //link将一系列虚拟内存空间连接起来 list_entry_t list_link;&#125;;vm_flags：#define VM_READ 0x00000001 //只读#define VM_WRITE 0x00000002 //可读写#define VM_EXEC 0x00000004 //可执行 具体函数：12345678910111213141516171819202122232425// mm_create - alloc a mm_struct &amp; initialize it.struct mm_struct * mm_create(void) &#123; struct mm_struct *mm = kmalloc(sizeof(struct mm_struct)); if (mm != NULL) &#123; list_init(&amp;(mm-&gt;mmap_list)); mm-&gt;mmap_cache = NULL; mm-&gt;pgdir = NULL; mm-&gt;map_count = 0; if (swap_init_ok) swap_init_mm(mm); else mm-&gt;sm_priv = NULL; &#125; return mm;&#125;// mm_destroy - free mm and mm internal fieldsvoid mm_destroy(struct mm_struct *mm) &#123; list_entry_t *list = &amp;(mm-&gt;mmap_list), *le; while ((le = list_next(list)) != list) &#123; list_del(le); kfree(le2vma(le, list_link),sizeof(struct vma_struct)); //kfree vma &#125; kfree(mm, sizeof(struct mm_struct)); //kfree mm mm=NULL;&#125; 设备驱动程序或者内核模块中动态开辟内存，不是用malloc，而是kmalloc ,vmalloc，释放内存用的是kfree,vfree，kmalloc函数返回的是虚拟地址(线性地址)。 kmalloc特殊之处在于它分配的内存是物理上连续的,这对于要进行DMA的设备十分重要。而用vmalloc分配的内存只是线性地址连续,物理地址不一定连续,不能直接用于DMA。vmalloc函数的工作方式类似于kmalloc，只不过前者分配的内存虚拟地址是连续的，而物理地址则无需连续。 通过vmalloc获得的页必须一个一个地进行映射，效率不高， 因此，只在不得已(一般是为了获得大块内存)时使用。vmalloc函数返回一个指针，指向逻辑上连续的一块内存区，其大小至少为size。在发生错误 时，函数返回NULL。1234567891011// vma_create - 新建一个vma_struct并且初始化(地址范围： vm_start~vm_end)struct vma_struct * vma_create(uintptr_t vm_start, uintptr_t vm_end, uint32_t vm_flags) &#123; struct vma_struct *vma = kmalloc(sizeof(struct vma_struct)); if (vma != NULL) &#123; vma-&gt;vm_start = vm_start; vma-&gt;vm_end = vm_end; vma-&gt;vm_flags = vm_flags; &#125; return vma;&#125; Page Fault异常处理处理该异常主要用do_pgfault函数，当启动分页机制以后，如果一条指令或数据的虚拟地址所对应的物理页框不在内存中或者访问的类型有错误（比如写一个只读页或用户态程序访问内核态的数据等），就会发生页访问异常。产生页访问异常的原因主要有： 目标页帧不存在（页表项全为0，即该线性地址与物理地址尚未建立映射或者已经撤销)；相应的物理页帧不在内存中（页表项非空，但Present标志位=0，比如在swap分区或磁盘文件上)；不满足访问权限（此时页表项P标志=1，但低权限的程序试图访问高权限的地址空间，或者有程序试图写只读页面）。 当出现上面情况之一，那么就会产生页面page fault（#PF）异常。CPU会把产生异常的线性地址存储在CR2中，并且把表示页访问异常类型的值（简称页访问异常错误码，errorCode）保存在中断栈中。CR2是页故障线性地址寄存器，保存最后一次出现页故障的全32位线性地址。CR2用于发生页异常时报告出错信息。产生页访问异常后，CPU把引起页访问异常的线性地址装到寄存器CR2中，并给出了出错码errorCode，说明了页访问异常的类型。操作系统中对应的中断服务例程可以检查CR2的内容，从而查出线性地址空间中的哪个页引起本次异常。 CPU在当前内核栈保存当前被打断的程序现场，即依次压入当前被打断程序使用的EFLAGS，CS，EIP，errorCode；由于页访问异常的中断号是0xE，CPU把异常中断号0xE对应的中断服务例程的地址（vectors.S中的标号vector14处）加载到CS和EIP寄存器中，开始执行中断服务例程。 这时ucore开始处理异常中断，首先需要保存硬件没有保存的寄存器。在vectors.S中的标号vector14处先把中断号压入内核栈，然后再在trapentry.S中的标号__alltraps处把DS、ES和其他通用寄存器都压栈。自此，被打断的程序执行现场（context）被保存在内核栈中。接下来，在trap.c的trap函数开始了中断服务例程的处理流程，大致调用关系为： trap –&gt; trap_dispatch –&gt; pgfault_handler –&gt; do_pgfault ucore中do_pgfault函数是完成页访问异常处理的主要函数，它根据从CPU的控制寄存器CR2中获取的页访问异常的物理地址以及根据errorCode的错误类型来查找此地址是否在某个VMA的地址范围内以及是否满足正确的读写权限，如果在此范围内并且权限也正确，这认为这是一次合法访问，但没有建立虚实对应关系。所以需要分配一个空闲的内存页，并修改页表完成虚地址到物理地址的映射，刷新TLB，然后调用iret产生软中断，返回到产生页访问异常的指令处重新执行此指令。如果该虚地址不在某VMA范围内，则认为是一次非法访问。 页面置换机制的实现当缺页中断发生时，操作系统把应用程序当前需要的数据或代码放到内存中来，然后重新执行应用程序产生异常的访存指令。如果在把硬盘中对应的数据或代码调入内存前，操作系统发现物理内存已经没有空闲空间了，这时操作系统必须把它认为“不常用”的页换出到磁盘上去，以腾出内存空闲空间给应用程序所需的数据或代码。 先进先出：选择在内存中驻留时间最久的页予以淘汰。将调入内存的页按照调入的先后顺序链接成一个队列，队列头指向内存中驻留时间最久的页，队列尾指向最近被调入内存的页。因为那些常被访问的页，往往在内存中也停留得最久，结果它们因变“老”而不得不被置换出去。FIFO算法的另一个缺点是，它有一种异常现象（Belady现象），即在增加放置页的页帧的情况下，反而使页访问异常次数增多。 时钟替换算法：是LRU算法的一种近似实现。时钟页替换算法把各个页面组织成环形链表的形式，类似于一个钟的表面。然后把一个指针（简称当前指针）指向最老的那个页面，即最先进来的那个页面。另外，时钟算法需要在页表项（PTE）中设置了一位访问位来表示此页表项对应的页当前是否被访问过。当该页被访问时，CPU中的MMU硬件将把访问位置“1”。当操作系统需要淘汰页时，对当前指针指向的页所对应的页表项进行查询，如果访问位为“0”，则淘汰该页，如果该页被写过，则还要把它换出到硬盘上；如果访问位为“1”，则将该页表项的此位置“0”，继续访问下一个页。该算法近似地体现了LRU的思想，且易于实现，开销少，需要硬件支持来设置访问位。时钟页替换算法在本质上与FIFO算法是类似的，不同之处是在时钟页替换算法中跳过了访问位为1的页。 改进时钟页替换算法：在时钟置换算法中，淘汰一个页面时只考虑了页面是否被访问过，但在实际情况中，还应考虑被淘汰的页面是否被修改过。因为淘汰修改过的页面还需要写回硬盘，使得其置换代价大于未修改过的页面，所以优先淘汰没有修改的页，减少磁盘操作次数。改进的时钟置换算法除了考虑页面的访问情况，还需考虑页面的修改情况。即该算法不但希望淘汰的页面是最近未使用的页，而且还希望被淘汰的页是在主存驻留期间其页面内容未被修改过的。这需要为每一页的对应页表项内容中增加一位引用位和一位修改位。当该页被访问时，CPU中的MMU硬件将把访问位置“1”。当该页被“写”时，CPU中的MMU硬件将把修改位置“1”。这样这两位就存在四种可能的组合情况：（0，0）表示最近未被引用也未被修改，首先选择此页淘汰；（0，1）最近未被使用，但被修改，其次选择；（1，0）最近使用而未修改，再次选择；（1，1）最近使用且修改，最后选择。该算法与时钟算法相比，可进一步减少磁盘的I/O操作次数。 页面置换机制可以被换出的页只有映射到用户空间且被用户程序直接访问的页面才能被交换，被内核直接使用的内核空间的页面不能被换出！！！操作系统是执行的关键代码，需要保证运行的高效性和实时性，如果在操作系统执行过程中，发生了缺页现象，则操作系统不得不等很长时间（硬盘的访问速度比内存的访问速度慢2到3个数量级），这将导致整个系统运行低效。 当一个Page Table Entry用来描述一般意义上的物理页时，它维护各种权限和映射关系，以及应该有PTE_P标记；但当它用来描述一个被置换出去的物理页时，它被用来维护该物理页与swap磁盘上扇区的映射关系，并且该PTE不应该由MMU将它解释成物理页映射(即没有 PTE_P 标记)。 与此同时对应的权限则交由mm_struct来维护，当对位于该页的内存地址进行访问的时候，必然导致 page fault，然后ucore能够根据 PTE 描述的swap项将相应的物理页重新建立起来，并根据虚存所描述的权限重新设置好 PTE 使得内存访问能够继续正常进行。 虚存中的页与硬盘上的扇区之间的映射关系一个页被换出到硬盘，则PTE最低位present位应该是0，表示虚实地址映射关系不存在，接下来7位为保留位，表示页帧号的24位地址用来表示在硬盘上的地址。-—————————-| offset | reserved | 0 |-—————————-24 bits &nbsp;&nbsp; 7 bits &nbsp;&nbsp; 1 bit 执行换入换出的时机当ucore或应用程序访问地址所在的页不在内存时，就会产生page fault异常，引起调用do_pgfault函数，此函数会判断产生访问异常的地址属于check_mm_struct某个vma表示的合法虚拟地址空间，且保存在硬盘swap文件中。 ucore目前大致有两种策略来实现换出操作，即积极换出策略和消极换出策略。积极换出策略是指操作系统周期性地（或在系统不忙的时候）主动把某些认为“不常用”的页换出到硬盘上，从而确保系统中总有一定数量的空闲页存在，这样当需要空闲页时，基本上能够及时满足需求；消极换出策略是指，只是当试图得到空闲页时，发现当前没有空闲的物理页可供分配，这时才开始查找“不常用”页面，并把一个或多个这样的页换出到硬盘上。 页替换算法的数据结构设计12345struct Page &#123; …… list_entry_t pra_page_link; uintptr_t pra_vaddr; &#125;; pra_page_link构造了按页的第一次访问时间进行排序的一个链表，这个链表的开始表示第一次访问时间最近的页，链表结尾表示第一次访问时间最远的页。当然链表头可以就可设置为pra_list_head（定义在swap_fifo.c中），构造的时机是在page fault发生后，进行do_pgfault函数时。pra_vaddr可以用来记录此物理页对应的虚拟页起始地址。 当一个物理页（struct Page）需要被swap出去的时候，首先需要确保它已经分配了一个位于磁盘上的swap page（由连续的8个扇区组成）。这里为了简化设计，在swap_check函数中建立了每个虚拟页唯一对应的swap page，其对应关系设定为：虚拟页对应的PTE的索引值 = swap page的扇区起始位置*8。 123456789101112131415161718struct swap_manager &#123; const char *name; /* swap manager 全局初始化 */ int (*init) (void); /* 对mm_struct中的数据进行初始化 */ int (*init_mm) (struct mm_struct *mm); /* 时钟中断处理 */ int (*tick_event) (struct mm_struct *mm); /* Called when map a swappable page into the mm_struct */ int (*map_swappable) (struct mm_struct *mm, uintptr_t addr, struct Page *page, int swap_in); /* When a page is marked as shared, this routine is called to delete the addr entry from the swap manager */ int (*set_unswappable) (struct mm_struct *mm, uintptr_t addr); /* Try to swap out a page, return then victim */ int (*swap_out_victim) (struct mm_struct *mm, struct Page *ptr_page, int in_tick); /* check the page relpacement algorithm */ int (*check_swap)(void); &#125;; map_swappable函数用于记录页访问情况相关属性，swap_out_vistim函数用于挑选需要换出的页。显然第二个函数依赖于第一个函数记录的页访问情况。tick_event函数指针也很重要，结合定时产生的中断，可以实现一种积极的换页策略。 准备：为了实现FIFO置换算法，我们应该管理所有可交换的页面，因此我们可以根据时间顺序将这些页面链接到pra_list_head。 使用list.h中的struct list。 struct list是一个简单的双向链表实现，具体函数包括：list_init，list_add（list_add_after），list_add_before，list_del，list_next，list_prev。 将通用列表结构转换为特殊结构（例如结构页面）。可以找到一些宏：le2page（在memlayout.h中），le2vma（在vmm.h中），le2proc（在proc.h中）等； _fifo_init_mm：初始化pra_list_head并让mm -&gt; sm_priv指向pra_list_head的addr。 现在，从内存控制struct mm_struct，我们可以调用FIFO算法； _fifo_map_swappable：将最近访问的页放到 pra_list_head 队列最后； _fifo_swap_out_victim：最早访问的页面从pra_list_head队列中剔除，然后*ptr_page赋值为这一页。 读代码1234567/*与虚拟地址范围[VPT，VPT + PTSIZE]对应的页面目录条目(page directory entry,PDE)指向页面目录本身。 因此，页面目录被视为页面表和页面目录。将页面目录视为页表的一个结果是可以通过虚拟地址VPT处的“虚拟页表(virtual page table,VPT)”访问所有PTE。 数字n的PTE存储在vpt[n]中。第二个结果是当前页面目录的内容将始终在虚拟地址PGADDR（PDX（VPT），PDX（VPT），0）处可用，vpd设置如下。*/pte_t * const vpt = (pte_t *)VPT;pde_t * const vpd = (pde_t *)PGADDR(PDX(VPT), PDX(VPT), 0); 练习1：给未被映射的地址映射上物理页完成do_pgfault（mm/vmm.c）函数，给未被映射的地址映射上物理页。设置访问权限的时候 需要参考页面所在VMA的权限，同时需要注意映射物理页时需要操作内存控制结构所指定的页表，而不是内核的页表。 引入虚拟内存后，可能会出现某一些虚拟内存空间是合法的（在vma中），但是还没有为其分配具体的内存页，这样的话，在访问这些虚拟页的时候就会产生pagefault异常，从而使得OS可以在异常处理时完成对这些虚拟页的物理页分配，在中端返回之后就可以正常进行内存的访问了。将出现了异常的线性地址保存在cr2寄存器中；再到trap_dispatch函数，在该函数中会根据中断号，将page fault的处理交给pgfault_handler函数，进一步交给do_pgfault函数进行处理。产生页面异常的原因主要有: 目标页面不存在（页表项全为0，即该线性地址与物理地址尚未建立映射或者已经撤销）； 相应的物理页面不在内存中（页表项非空，但Present标志位=0，比如在swap分区或磁盘文件上）； 访问权限不符合（此时页表项P标志=1，比如企图写只读页面）。1234do_pgfault - 处理缺页中断的中断处理例程 interrupt handler to process the page fault execption@mm : the control struct for a set of vma using the same PDT@error_code : the error code recorded in trapframe-&gt;tf_err which is setted by x86 hardware@addr : the addr which causes a memory access exception, (the contents of the CR2 register) 调用栈： trap–&gt; trap_dispatch–&gt;pgfault_handler–&gt;do_pgfault处理器为ucore的do_pgfault函数提供了两项信息，以帮助诊断异常并从中恢复。(1) CR2寄存器的内容。 处理器使用产生异常的32位线性地址加载CR2寄存器。 do_pgfault可以使用此地址来查找相应的页面目录和页表条目。(2) 在内核栈中的错误码。缺页错误码与其他异常的错误码不同，错误码可以通知中断处理例程以下信息: P flag(bit 0) 表明异常是否是因为一个不存在的页(0)或违反访问权限或使用保留位(1)； W/R flag(bit 1) 表明引起异常的访存操作是读(0)还是写(1)； U/S flag (bit 2) 表明引起异常时处理器是在用户态(1)还是内核态(0) do_pgfault(struct mm_struct *mm, uint32_t error_code, uintptr_t addr)第一个是一个mm_struct变量，其中保存了所使用的PDT，合法的虚拟地址空间（使用链表组织），以及与后文的swap机制相关的数据；而第二个参数是产生pagefault的时候硬件产生的error code，可以用于帮助判断发生page fault的原因，而最后一个参数则是出现page fault的线性地址（保存在cr2寄存器中的线性地址）。 查询mm_struct中的虚拟地址链表（线性地址对等映射，因此线性地址等于虚拟地址），确定出现page_fault的线性地址是否合法； 使用error code（包含了这次内存访问为读/写，对应物理页是否存在）判断是否出现权限问题，如果出现问题则直接返回； 根据合法虚拟地址（mm_struct中保存的合法虚拟地址链表中）生成对应产生的物理页的权限； 使用get_pte获取出错的线性地址所对应的虚拟页起始地址对应到的页表项，同时使用页表项保存物理地址（P为1）和被换出的物理页在swap中的位置（P为0），并规定swap中第0个页空出来不用于交换。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118int do_pgfault(struct mm_struct *mm, uint32_t error_code, uintptr_t addr) &#123; int ret = -E_INVAL; //根据传进的mm和地址addr，找一个vma，这个vma是在mm的mmap_cache中的，find_vma主要是先找mm中的mmap_cache，如果还不存在，就在mm的mmap_list中找，这个vma用le2vma宏进行转换，直到找到一个地址空间合适的vma，把这个vma赋值给mmap_cache。 struct vma_struct *vma = find_vma(mm, addr); pgfault_num++; //检查找到的vma是否为空或符合地址范围 if (vma == NULL || vma-&gt;vm_start &gt; addr) &#123; cprintf(&quot;not valid addr %x, and can not find it in vma\n&quot;, addr); goto failed; &#125; //如果present位是0，代表没有映射关系，不存在物理页和虚拟页帧的对应关系 //error_code在cr2寄存器中的后几位，对这个errorcode进行判断，确定读写权限和p位是否为1 switch (error_code &amp; 3) &#123; default: /* error code flag : default is 3 ( W/R=1, P=1): write, present */ case 2: /* error code flag : (W/R=1, P=0): write, not present */ if (!(vma-&gt;vm_flags &amp; VM_WRITE)) &#123; cprintf(&quot;do_pgfault failed: error code flag = write AND not present, but the addr&apos;s vma cannot write\n&quot;); goto failed; &#125; break; case 1: /* error code flag : (W/R=0, P=1): read, present */ cprintf(&quot;do_pgfault failed: error code flag = read AND present\n&quot;); goto failed; case 0: /* error code flag : (W/R=0, P=0): read, not present */ if (!(vma-&gt;vm_flags &amp; (VM_READ | VM_EXEC))) &#123; cprintf(&quot;do_pgfault failed: error code flag = read AND not present, but the addr&apos;s vma cannot read or exec\n&quot;); goto failed; &#125; &#125; /* IF (write an existed addr ) OR * (write an non_existed addr &amp;&amp; addr is writable) OR * (read an non_existed addr &amp;&amp; addr is readable) * THEN * continue process * 写一个存在的地址、写一个不存在的地址但是地址是可写的、读一个不存在的地址但是地址是可读的 */ uint32_t perm = PTE_U; if (vma-&gt;vm_flags &amp; VM_WRITE) &#123; perm |= PTE_W; &#125; // 生成一个权限控制 addr = ROUNDDOWN(addr, PGSIZE); // 向下舍入到n的最接近的倍数 ret = -E_NO_MEM; pte_t *ptep=NULL; /*LAB3 EXERCISE 1: YOUR CODE * 本次实验用到的宏和定义： * get_pte : 获得pte，返回pte的线性地址、虚拟地址 * if the PT contians this pte didn&apos;t exist, alloc a page for PT (notice the 3th parameter &apos;1&apos;) * pgdir_alloc_page : 调用alloc_page 和 page_insert 分配一个页大小的内存空间，设置物理地址和线性地址的映射关系 * DEFINES: * VM_WRITE : If vma-&gt;vm_flags &amp; VM_WRITE == 1/0, then the vma is writable/non writable * PTE_W 0x002 // page table/directory entry flags bit : Writeable * PTE_U 0x004 // page table/directory entry flags bit : User can access * VARIABLES: * mm-&gt;pgdir : the PDT of these vma * */ /*LAB3 EXERCISE 1: YOUR CODE*/ ptep = get_pte(mm-&gt;pgdir, addr, 1); // 第三个参数create代表是否在查找page_directory的过程中没找到的话要不要创建，在这里要创建 if (ptep == NULL) &#123; cprintf(&quot;get_pte return a NULL.\n&quot;); goto failed; &#125; //(1) 找到一个pte，如果需要的物理页是没有分配而不是被换出到外存中 //如果物理地址不存在，则分配一个页面并使用逻辑地址映射物理地址，pgdir_alloc_page一个函数就能分配页和设置映射关系 if (*ptep == 0) &#123; struct Page* page = pgdir_alloc_page(mm-&gt;pgdir, addr, perm); if(page == NULL) &#123; cprintf(&quot;pgdir_alloc_page return a NULL.\n&quot;); goto failed; &#125; &#125; else &#123; /*LAB3 EXERCISE 2: YOUR CODE * 现在我们认为这个pte是一个swap的，我们应该将数据从disk加载到带有物理地址的页面，并将物理地址映射到逻辑地址，触发交换管理器来记录该页面的访问情况。 * * MACROs or Functions: * swap_in(mm, addr, &amp;page) : 分配一个内存页，根据PTE中的swap地址找到磁盘页的地址，读进内存页中 * page_insert ： 创建页的物理地址和线性地址的映射关系 * swap_map_swappable ： 设置这一个页是可交换的 */ if(swap_init_ok) &#123; // 判断是否当前交换机制正确被初始化 struct Page *page=NULL; ret = swap_in(mm, addr, &amp;page); // 将物理页换入到内存中 if (ret != 0) &#123; cprintf(&quot;swap_in failed.\n&quot;); goto failed; &#125; page_insert(mm-&gt;pgdir, page, addr, perm); //(2) According to the mm, addr AND page, setup the map of phy addr &lt;---&gt; logical addr // 将物理页与虚拟页建立映射关系 swap_map_swappable(mm, addr, page, 1); //(3) make the page swappable。设置当前的物理页为可交换的 page-&gt;pra_vaddr = addr; //同时在物理页中维护其对应到的虚拟页的信息； //网上有人说这个语句最好应当放置在page_insert函数中， //在该建立映射关系的函数外对物理page对应的虚拟地址进行维护显得有些不太合适（感觉好有道理） &#125; else &#123; cprintf(&quot;no swap_init_ok but ptep is %x, failed\n&quot;,*ptep); goto failed; &#125; &#125; ret = 0;failed: return ret;&#125; 问题： 请描述页目录项（Page Director Entry）和页表（Page Table Entry）中组成部分对ucore实现页替换算法的潜在用处。 首先不妨先分析PDE以及PTE中各个组成部分以及其含义； 接下来先描述页目录项的每个组成部分，PDE（页目录项）的具体组成如下图所示；描述每一个组成部分的含义如下： 前20位表示4K对齐的该PDE对应的页表起始位置（物理地址，该物理地址的高20位即PDE中的高20位，低12位为0）； 第9-11位未被CPU使用，可保留给OS使用； 接下来的第8位可忽略； 第7位用于设置Page大小，0表示4KB； 第6位恒为0； 第5位用于表示该页是否被使用过； 第4位设置为1则表示不对该页进行缓存； 第3位设置是否使用write through缓存写策略； 第2位表示该页的访问需要的特权级； 第1位表示是否允许读写； 第0位为该PDE的存在位； 接下来描述页表项（PTE）中的每个组成部分的含义，具体组成如下图所示： 高20位与PDE相似的，用于表示该PTE指向的物理页的物理地址； 9-11位保留给OS使用； 7-8位恒为0； 第6位表示该页是否为dirty，即是否需要在swap out的时候写回外存； 第5位表示是否被访问； 3-4位恒为0； 0-2位分别表示存在位、是否允许读写、访问该页需要的特权级； 可以发现无论是PTE还是TDE，都具有着一些保留的位供操作系统使用，也就是说ucore可以利用这些位来完成一些其他的内存管理相关的算法，比如可以在这些位里保存最近一段时间内该页的被访问的次数（仅能表示0-7次），用于辅助近似地实现虚拟内存管理中的换出策略的LRU之类的算法；也就是说这些保留位有利于OS进行功能的拓展； 作者：AmadeusChan链接：https://www.jianshu.com/p/8d6ce61ac678来源：简书 如果ucore的缺页服务例程在执行过程中访问内存，出现了页访问异常，请问硬件要做哪些事情？ 考虑到ucore的缺页服务例程如果在访问内容中出现了缺页异常，则会有可能导致ucore最终无法完成缺页的处理，因此一般不应该将缺页的ISR以及OS中的其他一些关键代码或者数据换出到外存中，以确保操作系统的正常运行；如果缺页ISR在执行过程中遇到页访问异常，则最终硬件需要完成的处理与正常出现页访问异常的处理相一致，均为： 将发生错误的线性地址保存在cr2寄存器中; 在中断栈中依次压入EFLAGS，CS, EIP，以及页访问异常码errorcode，由于ISR一定是运行在内核态下的，因此不需要压入ss和esp以及进行栈的切换； 根据中断描述符表查询到对应页访问异常的ISR，跳转到对应的ISR处执行，接下来将由软件进行处理； 练习2：补充完成基于FIFO的页面替换算法维基百科：最简单的页面替换算法（Page Replace Algorithm）是FIFO算法。先进先出页面替换算法是一种低开销算法。这个想法从名称中可以明显看出 - 操作系统跟踪队列中内存中的所有页面，最近到达的放在后面，最早到达的放在前面。当需要更换页面时，会选择队列最前面的页面（最旧的页面）。虽然FIFO开销小且直观，但在实际应用中表现不佳。因此，它很少以未修改的形式使用。该算法存在Belady异常。 FIFO的详细信息 准备：为了实现FIFO，我们应该管理所有可交换的页面，这样我们就可以按照时间顺序将这些页面链接到pra_list_head。将通用list换为特殊结构（例如Page）； _fifo_init_mm：初始化pra_list_head并让mm-&gt; sm_priv指向pra_list_head的addr。 现在，从内存控制struct mm_struct，我们可以访问FIFO； _fifo_map_swappable: 最近到达的页需要放到pra_list_head队列的最末尾； _fifo_swap_out_victim: 最早到达的页面在pra_list_head队列最前边，我们应该将它踢出去。 123456789101112131415将当前的物理页面插入到FIFO算法中维护的可被交换出去的物理页面链表中的末尾，从而保证该链表中越接近链表头的物理页面在内存中的驻留时间越长；static int _fifo_map_swappable(struct mm_struct *mm, uintptr_t addr, struct Page *page, int swap_in)&#123; list_entry_t *head=(list_entry_t*) mm-&gt;sm_priv; // 找到链表入口 list_entry_t *entry=&amp;(page-&gt;pra_page_link); // 找到当前物理页用于组织成链表的list_entry_t assert(entry != NULL &amp;&amp; head != NULL); /*LAB3 EXERCISE 2: YOUR CODE*/ // link the most recent arrival page at the back of the pra_list_head qeueue // 将当前指定的物理页插入到链表的末尾 list_add(head, entry); return 0;&#125; 123456789101112131415161718192021222324static int_fifo_swap_out_victim(struct mm_struct *mm, struct Page ** ptr_page, int in_tick)&#123; list_entry_t *head=(list_entry_t*) mm-&gt;sm_priv; // 找到链表的入口 assert(head != NULL); assert(in_tick==0); /* Select the victim */ /*LAB3 EXERCISE 2: YOUR CODE*/ // unlink the earliest arrival page in front of pra_list_head qeueue //list_entry_t *le = head-&gt;prev; the given answer list_entry_t *le = list_next(head); // 取出链表头，即最早进入的物理页面 assert(le != NULL); // 确保链表非空 struct Page *p = le2page(le,pra_page_link); // 找到对应的物理页面的Page结构 list_del(le); // 从链表上删除取出的即将被换出的物理页面 assert(p != NULL); *ptr_page = p; // assign the value of *ptr_page to the addr of this page return 0;&#125; 如果在_fifo_map_swappable函数中使用的是list_add_before的话，在_fifo_swap_out_victim中应该使用list_next(head)取得要被删除的页；如果在_fifo_map_swappable函数中使用的是list_add的话，在_fifo_swap_out_victim中应该使用head-&gt;prev取得要被删除的页；这个链表是双向循环链表！ 如果要在ucore上实现”extended clock页替换算法”请给你的设计方案，现有的swap_manager框架是否足以支持在ucore中实现此算法？如果是，请给你的设计方案。如果不是，请给出你的新的扩展和基此扩展的设计方案。并需要回答如下问题 在现有框架基础上可以支持Extended clock算法。 根据上文中提及到的PTE的组成部分可知，PTE中包含了dirty位和访问位，因此可以确定某一个虚拟页是否被访问过以及写过，但是，考虑到在替换算法的时候是将物理页面进行换出，而可能存在着多个虚拟页面映射到同一个物理页面这种情况，也就是说某一个物理页面是否dirty和是否被访问过是有这些所有的虚拟页面共同决定的，而在原先的实验框架中，物理页的描述信息Page结构中默认只包括了一个对应的虚拟页的地址，应当采用链表的方式，在Page中扩充一个成员，把物理页对应的所有虚拟页都给保存下来；而物理页的dirty位和访问位均为只需要某一个对应的虚拟页对应位被置成1即可置成1；完成了上述对物理页描述信息的拓展之后，考虑对FIFO算法的框架进行修改得到拓展时钟算法的框架，由于这两种算法都是将所有可以换出的物理页面均按照进入内存的顺序连成一个环形链表，因此初始化，将某个页面置为可以/不可以换出这些函数均不需要进行大的修改(小的修改包括在初始化当前指针等)，唯一需要进行重写的函数是选择换出物理页的函数swap_out_victim，对该函数的修改如下： 从当前指针开始，对环形链表进行扫描，根据指针指向的物理页的状态（表示为(access, dirty)）来确定应当进行何种修改：如果状态是(0, 0)，则将该物理页面从链表上去下，该物理页面记为换出页面，但是由于这个时候这个页面不是dirty的，因此事实上不需要将其写入swap分区；如果状态是(0,1)，则将该物理页对应的虚拟页的PTE中的dirty位都改成0，并且将该物理页写入到外存中，然后指针跳转到下一个物理页；如果状态是(1, 0), 将该物理页对应的虚拟页的PTE中的访问位都置成0，然后指针跳转到下一个物理页面；如果状态是(1, 1)，则该物理页的所有对应虚拟页的PTE中的访问为置成0，然后指针跳转到下一个物理页面； 需要被换出的页的特征是什么？ 该物理页在当前指针上一次扫过之前没有被访问过；该物理页的内容与其在外存中保存的数据是一致的, 即没有被修改过; 在ucore中如何判断具有这样特征的页？ 在ucore中判断具有这种特征的页的方式已经在上文设计方案中提及过了，具体为： 假如某物理页对应的所有虚拟页中存在一个dirty的页，则认为这个物理页为dirty，否则不这么认为；假如某物理页对应的所有虚拟页中存在一个被访问过的页，则认为这个物理页为被访问过的，否则不这么认为； 何时进行换入和换出操作？ 在产生page fault的时候进行换入操作；换出操作源于在算法中将物理页的dirty从1修改成0的时候，因此这个时候如果不进行写出到外存，就会造成数据的不一致，具体写出内存的时机是比较细节的问题, 可以在修改dirty的时候写入外存，或者是在这个物理页面上打一个需要写出的标记，到了最终删除这个物理页面的时候，如果发现了这个写出的标记，则在这个时候再写入外存；后者使用一个写延迟标记，有利于多个写操作的合并，从而降低缺页的代价；]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[golang学习]]></title>
    <url>%2F2019%2F06%2F27%2Fgolang%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[开始学学golang这门伟大的语言。 结构Go的基础组成有以下几个部分： 包声明 引入包 函数 变量 语句 &amp; 表达式 注释 123456789package main/* 包的名字是main，每个程序都有一个main的包 */import &quot;fmt&quot;/* 需要fmt这个包 */func main() &#123; /* 这是我的第一个简单的程序 */ fmt.Println(&quot;Hello, World!&quot;)&#125; （太奇葩了，竟然是以大小写作为权限控制的。）当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）；标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 protected ）。 运行的话：1go run hello.go 最奇葩的是 { 不能单独放在一行 基础行分隔符在 Go 程序中，一行代表一个语句结束。每个语句不需要像C一样以分号结尾，因为这些工作都将由 Go 编译器自动完成。 标识符用来命名变量、类型等程序实体。一个标识符实际上就是一个或是多个字母、数字、下划线组成的序列，但是第一个字符必须是字母或下划线而不能是数字。 Go 语言的字符串可以通过 + 实现：12345package mainimport &quot;fmt&quot;func main() &#123; fmt.Println(&quot;Google&quot; + &quot;Runoob&quot;)&#125; 数据类型在 Go 编程语言中，数据类型用于声明函数和变量。 数据类型的出现是为了把数据分成所需内存大小不同的数据，编程的时候需要用大数据的时候才需要申请大内存，就可以充分利用内存。 Go 语言按类别有以下几种数据类型： 布尔型：布尔型的值只可以是常量 true 或者 false。一个简单的例子：var b bool = true。 数字类型：整型 int 和浮点型 float32、float64，Go 语言支持整型和浮点型数字，并且支持复数，其中位的运算采用补码。 字符串类型：字符串就是一串固定长度的字符连接起来的字符序列。Go 的字符串是由单个字节连接起来的。Go 语言的字符串的字节使用 UTF-8 编码标识 Unicode 文本。 派生类型: (a) 指针类型（Pointer） (b) 数组类型 (c) 结构化类型(struct) (d) Channel 类型 (e) 函数类型 (f) 切片类型 (g) 接口类型（interface） (h) Map 类型 数字类型Go 也有基于架构的类型，例如：int、uint 和 uintptr。 uint8：无符号 8 位整型 (0 到 255) uint16：无符号 16 位整型 (0 到 65535) uint32：无符号 32 位整型 (0 到 4294967295) uint64：无符号 64 位整型 (0 到 18446744073709551615) int8：有符号 8 位整型 (-128 到 127) int16：有符号 16 位整型 (-32768 到 32767) int32：有符号 32 位整型 (-2147483648 到 2147483647) int64：有符号 64 位整型 (-9223372036854775808 到 9223372036854775807) 浮点型 float32：IEEE-754 32位浮点型数 float64：IEEE-754 64位浮点型数 complex64：32 位实数和虚数 complex128：64 位实数和虚数 其他数字类型 byte：类似 uint8 rune：类似 int32 uint：32 或 64 位 int：与 uint 一样大小 uintptr：无符号整型，用于存放一个指针 变量Go 语言变量名由字母、数字、下划线组成，其中首个字符不能为数字。 声明变量的一般形式是使用 var 关键字：1var identifier type 可以一次声明多个变量：1var identifier1, identifier2 type 实例123456789package mainimport &quot;fmt&quot;func main() &#123; var a string = &quot;Runoob&quot; fmt.Println(a) var b, c int = 1, 2 fmt.Println(b, c)&#125; 变量声明第一种，指定变量类型，如果没有初始化，则变量默认为零值。12var v_name v_typev_name = value 未初始化的时候： 数值类型（包括complex64/128）为 0 布尔类型为 false 字符串为 “”（空字符串） 以下几种类型为 nil： var a *int var a []int var a map[string] int var a chan int var a func(string) int var a error // error 是接口 第二种，根据值自行判定变量类型。1var v_name = value 实例123456package mainimport &quot;fmt&quot;func main() &#123; var d = true fmt.Println(d)&#125; 第三种，省略 var, 注意 := 左侧如果没有声明新的变量，就产生编译错误，格式：1v_name := value 例如：123var intVal int intVal :=1 // 这时候会产生编译错误intVal,intVal1 := 1,2 // 此时不会产生编译错误，因为有声明新的变量，因为 := 是一个声明语句 可以将 var f string = &quot;Runoob&quot; 简写为 f := &quot;Runoob&quot; 实例1234567package mainimport &quot;fmt&quot;func main() &#123; f := &quot;Runoob&quot; // var f string = &quot;Runoob&quot; fmt.Println(f)&#125; 多变量声明//类型相同多个变量, 非全局变量1234var vname1, vname2, vname3 typevname1, vname2, vname3 = v1, v2, v3var vname1, vname2, vname3 = v1, v2, v3 // 和 python 很像,不需要显示声明类型，自动推断vname1, vname2, vname3 := v1, v2, v3 // 出现在 := 左侧的变量不应该是已经被声明过的，否则会导致编译错误 这种因式分解关键字的写法一般用于声明全局变量1234var ( vname1 v_type1 vname2 v_type2) 可以在变量的初始化时省略变量的类型而由系统自动推断，声明语句写上 var 关键字其实是显得有些多余了，因此我们可以将它们简写为 a := 50 或 b := false。 a 和 b 的类型（int 和 bool）将由编译器自动推断。 这是使用变量的首选形式，但是它只能被用在函数体内，而不可以用于全局变量的声明与赋值。使用操作符 := 可以高效地创建一个新的变量，称之为初始化声明。 如果在相同的代码块中，我们不可以再次对于相同名称的变量使用初始化声明，例如：a := 20 就是不被允许的，编译器会提示错误 no new variables on left side of :=，但是 a = 20 是可以的，因为这是给相同的变量赋予一个新的值。 如果你在定义变量 a 之前使用它，则会得到编译错误 undefined: a。 如果你声明了一个局部变量却没有在相同的代码块中使用它，同样会得到编译错误 常量常量是一个简单值的标识符，在程序运行时，不会被修改的量。 常量中的数据类型只可以是布尔型、数字型（整数型、浮点型和复数）和字符串型。 常量的定义格式：1const identifier [type] = value 你可以省略类型说明符 [type]，因为编译器可以根据变量的值来推断其类型。 显式类型定义： const b string = “abc”隐式类型定义： const b = “abc”多个相同类型的声明可以简写为：1const c_name1, c_name2 = value1, value2 常量还可以用作枚举：12345const ( Unknown = 0 Female = 1 Male = 2) 数字 0、1 和 2 分别代表未知性别、女性和男性。 常量可以用len(), cap(), unsafe.Sizeof()函数计算表达式的值。常量表达式中，函数必须是内置函数，否则编译不过 iotaiota，特殊常量，可以认为是一个可以被编译器修改的常量。 iota 在 const 关键字出现时将被重置为 0(const 内部的第一行之前)，const 中每新增一行常量声明将使 iota 计数一次(iota 可理解为 const 语句块中的行索引)。 iota 可以被用作枚举值：12345const ( a = iota b = iota c = iota) 第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1；所以 a=0, b=1, c=2 可以简写为如下形式：12345const ( a = iota b c) iota 用法 实例123456789101112131415161718package mainimport &quot;fmt&quot;func main() &#123; const ( a = iota //0 b //1 c //2 d = &quot;ha&quot; //独立值，iota += 1 e //&quot;ha&quot; iota += 1 f = 100 //iota +=1 g //100 iota +=1 h = iota //7,恢复计数 i //8 ) fmt.Println(a,b,c,d,e,f,g,h,i)&#125; 以上实例运行结果为：10 1 2 ha ha 100 100 7 8 再看个有趣的的 iota 实例： 实例12345678910111213141516package mainimport &quot;fmt&quot;const ( i=1&lt;&lt;iota j=3&lt;&lt;iota k l)func main() &#123; fmt.Println(&quot;i=&quot;,i) fmt.Println(&quot;j=&quot;,j) fmt.Println(&quot;k=&quot;,k) fmt.Println(&quot;l=&quot;,l)&#125; 以上实例运行结果为：1234i= 1j= 6k= 12l= 24 iota 表示从 0 开始自动加 1，所以 i=1&lt;&lt;0, j=3&lt;&lt;1（&lt;&lt; 表示左移的意思），即：i=1, j=6，这没问题，关键在 k 和 l，从输出结果看 k=3&lt;&lt;2，l=3&lt;&lt;3。 简单表述:1234i=1：左移 0 位,不变仍为 1;j=3：左移 1 位,变为二进制 110, 即 6;k=3：左移 2 位,变为二进制 1100, 即 12;l=3：左移 3 位,变为二进制 11000,即 24。 部分运算符假定 A 为60，B 为13： 运算符 描述 实例 &amp; 按位与运算符”&amp;”是双目运算符。 其功能是参与运算的两数各对应的二进位相与。 (A &amp; B) 结果为 12, 二进制为 0000 1100 竖线或 按位或运算符是双目运算符。 其功能是参与运算的两数各对应的二进位相或。 (A 或 B) 结果为 61, 二进制为 0011 1101 ^ 按位异或运算符”^”是双目运算符。 其功能是参与运算的两数各对应的二进位相异或，当两对应的二进位相异时，结果为1。 (A ^ B) 结果为 49, 二进制为 0011 0001 &lt;&lt; 左移运算符”&lt;&lt;”是双目运算符。左移n位就是乘以2的n次方。 其功能把”&lt;&lt;”左边的运算数的各二进位全部左移若干位，由”&lt;&lt;”右边的数指定移动的位数，高位丢弃，低位补0。 A &lt;&lt; 2 结果为 240 ，二进制为 1111 0000 &gt;&gt; 右移运算符&gt;&gt;是双目运算符。右移n位就是除以2的n次方。 其功能是把&gt;&gt;左边的运算数的各二进位全部右移若干位，&gt;&gt;右边的数指定移动的位数。 A &gt;&gt; 2 结果为 15 ，二进制为 0000 1111 运算符 描述 实例 &amp; 返回变量存储地址 &a; 将给出变量的实际地址。 * 指针变量。 *a; 是一个指针变量 条件语句if 语句的语法如下：123if 布尔表达式 &#123; /* 在布尔表达式为 true 时执行 */&#125; If 在布尔表达式为 true 时，其后紧跟的语句块执行，如果为 false 则不执行。 Go 编程语言中 if…else 语句的语法如下：12345if 布尔表达式 &#123; /* 在布尔表达式为 true 时执行 */&#125; else &#123; /* 在布尔表达式为 false 时执行 */&#125; If 在布尔表达式为 true 时，其后紧跟的语句块执行，如果为 false 则执行 else 语句块。 Go 编程语言中 if…else 语句的语法如下：123456if 布尔表达式 1 &#123; /* 在布尔表达式 1 为 true 时执行 */ if 布尔表达式 2 &#123; /* 在布尔表达式 2 为 true 时执行 */ &#125;&#125; switchswitch 语句用于基于不同条件执行不同动作，每一个 case 分支都是唯一的，从上至下逐一测试，直到匹配为止。 switch 语句执行的过程从上至下，直到找到匹配项，匹配项后面也不需要再加 break。 switch 默认情况下 case 最后自带 break 语句，匹配成功后就不会执行其他 case，如果我们需要执行后面的 case，可以使用 fallthrough 。 语法Go 编程语言中 switch 语句的语法如下：12345678switch var1 &#123; case val1: ... case val2: ... default: ...&#125; 变量 var1 可以是任何类型，而 val1 和 val2 则可以是同类型的任意值。类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。 您可以同时测试多个可能符合条件的值，使用逗号分割它们，例如：case val1, val2, val3。 switch 语句还可以被用于 type-switch 来判断某个 interface 变量中实际存储的变量类型。 Type Switch 语法格式如下：123456789switch x.(type)&#123; case type: statement(s); case type: statement(s); /* 你可以定义任意个数的case */ default: /* 可选 */ statement(s);&#125; fallthrough使用 fallthrough 会强制执行后面的 case 语句，fallthrough 不会判断下一条 case 的表达式结果是否为 true。 selectselect 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。 select 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。 语法Go 编程语言中 select 语句的语法如下：123456789select &#123; case communication clause : statement(s); case communication clause : statement(s); /* 你可以定义任意数量的 case */ default : /* 可选 */ statement(s);&#125; 以下描述了 select 语句的语法： 每个 case 都必须是一个通信 所有 channel 表达式都会被求值 所有被发送的表达式都会被求值 如果任意某个通信可以进行，它就执行，其他被忽略。 如果有多个 case 都可以运行，Select 会随机公平地选出一个执行。其他不会执行。 否则： 如果有 default 子句，则执行该语句。 如果没有 default 子句，select 将阻塞，直到某个通信可以运行；Go 不会重新对 channel 或值进行求值。 循环Go语言的For循环有3中形式，只有其中的一种使用分号。 和 C 语言的 for 一样：1for init; condition; post &#123; &#125; 和 C 的 while 一样：1for condition &#123; &#125; 和 C 的 for(;;) 一样：1for &#123; &#125; init： 一般为赋值表达式，给控制变量赋初值； condition： 关系表达式或逻辑表达式，循环控制条件； post： 一般为赋值表达式，给控制变量增量或减量。 for语句执行过程如下： 先对表达式1赋初值； 判别赋值表达式 init 是否满足给定条件，若其值为真，满足循环条件，则执行循环体内语句，然后执行 post，进入第二次循环，再判别 condition； 否则判断 condition 的值为假，不满足条件，就终止for循环，执行循环体外语句。 for 循环的 range 格式可以对 slice、map、数组、字符串等进行迭代循环。格式如下：123for key, value := range oldMap &#123; newMap[key] = value&#125; break 语句Go 语言循环语句 Go语言循环语句 Go 语言中 break 语句用于以下两方面： 用于循环语句中跳出循环，并开始执行循环之后的语句。 break 在 switch（开关语句）中在执行一条case后跳出语句的作用。 Go 语言的 continue 语句 有点像 break 语句。但是 continue 不是跳出循环，而是跳过当前循环执行下一次循环语句。 for 循环中，执行 continue 语句会触发for增量语句的执行。 函数函数是基本的代码块，用于执行一个任务。 Go 语言最少有个 main() 函数。 你可以通过函数来划分不同功能，逻辑上每个函数执行的是指定的任务。函数声明告诉了编译器函数的名称，返回类型，和参数。 Go 语言标准库提供了多种可动用的内置的函数。例如，len() 函数可以接受不同类型参数并返回该类型的长度。如果我们传入的是字符串则返回字符串的长度，如果传入的是数组，则返回数组中包含的元素个数。 Go 语言函数定义格式如下：123func function_name( [parameter list] ) [return_types] &#123; 函数体&#125; func：函数由 func 开始声明 function_name：函数名称，函数名和参数列表一起构成了函数签名。 parameter list：参数列表，参数就像一个占位符，当函数被调用时，你可以将值传递给参数，这个值被称为实际参数。参数列表指定的是参数类型、顺序、及参数个数。参数是可选的，也就是说函数也可以不包含参数。 return_types：返回类型，函数返回一列值。return_types 是该列值的数据类型。有些功能不需要返回值，这种情况下 return_types 不是必须的。 函数体：函数定义的代码集合。 函数返回多个值Go 函数可以返回多个值，例如： 实例1234567891011package mainimport &quot;fmt&quot;func swap(x, y string) (string, string) &#123; return y, x&#125;func main() &#123; a, b := swap(&quot;Google&quot;, &quot;Runoob&quot;) fmt.Println(a, b)&#125; 值传递传递是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。默认情况下，Go 语言使用的是值传递，即在调用过程中不会影响到实际参数。 引用传递引用传递是指在调用函数时将实际参数的地址传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 引用传递指针参数传递到函数内，以下是交换函数 swap() 使用了引用传递：1234567/* 定义交换值函数*/func swap(x *int, y *int) &#123; var temp int temp = *x /* 保持 x 地址上的值 */ *x = *y /* 将 y 值赋给 x */ *y = temp /* 将 temp 值赋给 y */&#125; 函数作为实参Go 语言可以很灵活的创建函数，并作为另外一个函数的实参。以下实例中我们在定义的函数中初始化一个变量，该函数仅仅是为了使用内置函数 math.sqrt()，实例为：1234567891011121314151617package mainimport ( &quot;fmt&quot; &quot;math&quot;)func main()&#123; /* 声明函数变量 */ getSquareRoot := func(x float64) float64 &#123; return math.Sqrt(x) &#125; /* 使用函数 */ fmt.Println(getSquareRoot(9))&#125; 函数闭包go支持匿名函数，可作为闭包。匿名函数是一个”内联”语句或表达式。匿名函数的优越性在于可以直接使用函数内的变量，不必申明。 以下实例中，我们创建了函数 getSequence() ，返回另外一个函数。该函数的目的是在闭包中递增 i 变量，代码如下：12345678910111213141516171819202122232425package mainimport &quot;fmt&quot;func getSequence() func() int &#123; i:=0 return func() int &#123; i+=1 return i &#125;&#125;func main()&#123; /* nextNumber 为一个函数，函数 i 为 0 */ nextNumber := getSequence() /* 调用 nextNumber 函数，i 变量自增 1 并返回 */ fmt.Println(nextNumber()) fmt.Println(nextNumber()) fmt.Println(nextNumber()) /* 创建新的函数 nextNumber1，并查看结果 */ nextNumber1 := getSequence() fmt.Println(nextNumber1()) fmt.Println(nextNumber1())&#125; 方法Go 语言中同时有函数和方法。一个方法就是一个包含了接受者的函数，接受者可以是命名类型或者结构体类型的一个值或者是一个指针。所有给定类型的方法属于该类型的方法集。语法格式如下：123func (variable_name variable_data_type) function_name() [return_type]&#123; /* 函数体*/&#125; 下面定义一个结构体类型和该类型的一个方法：12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; )/* 定义结构体 */type Circle struct &#123; radius float64&#125;func main() &#123; var c1 Circle c1.radius = 10.00 fmt.Println(&quot;圆的面积 = &quot;, c1.getArea())&#125;//该 method 属于 Circle 类型对象中的方法func (c Circle) getArea() float64 &#123; //c.radius 即为 Circle 类型对象中的属性 return 3.14 * c.radius * c.radius&#125; 变量作用域作用域为已声明标识符所表示的常量、类型、变量、函数或包在源代码中的作用范围。 Go 语言中变量可以在三个地方声明： 函数内定义的变量称为局部变量 函数外定义的变量称为全局变量 函数定义中的变量称为形式参数 接下来让我们具体了解局部变量、全局变量和形式参数。 局部变量在函数体内声明的变量称之为局部变量，它们的作用域只在函数体内，参数和返回值变量也是局部变量。 全局变量在函数体外声明的变量称之为全局变量，全局变量可以在整个包甚至外部包（被导出后）使用。 Go 语言程序中全局变量与局部变量名称可以相同，但是函数内的局部变量会被优先考虑。 形式参数形式参数会作为函数的局部变量来使用。 数组Go 语言提供了数组类型的数据结构。 数组是具有相同唯一类型的一组已编号且长度固定的数据项序列，这种类型可以是任意的原始类型例如整形、字符串或者自定义类型。 相对于去声明 number0, number1, …, number99 的变量，使用数组形式 numbers[0], numbers[1] …, numbers[99] 更加方便且易于扩展。 数组元素可以通过索引（位置）来读取（或者修改），索引从 0 开始，第一个元素索引为 0，第二个索引为 1，以此类推。 多维数组Go 语言支持多维数组，以下为常用的多维数组声明方式：1var variable_name [SIZE1][SIZE2]...[SIZEN] variable_type 以下实例声明了三维的整型数组：1var threedim [5][10][4]int 二维数组是最简单的多维数组，二维数组本质上是由一维数组组成的。二维数组定义方式如下：1var arrayName [ x ][ y ] variable_type 指针Go 语言的取地址符是&amp;，放到一个变量前使用就会返回相应变量的内存地址。123456789package mainimport &quot;fmt&quot;func main() &#123; var a int = 10 fmt.Printf(&quot;变量的地址: %x\n&quot;, &amp;a )&#125; 指针使用流程： 定义指针变量。 为指针变量赋值。 访问指针变量中指向地址的值。 在指针类型前面加上 * 号（前缀）来获取指针所指向的内容。 空指针当一个指针被定义后没有分配到任何变量时，它的值为 nil。nil 指针也称为空指针。nil在概念上和其它语言的null、None、nil、NULL一样，都指代零值或空值。 一个指针变量通常缩写为 ptr。 结构体Go 语言中数组可以存储同一类型的数据，但在结构体中我们可以为不同项定义不同的数据类型。 结构体是由一系列具有相同类型或不同类型的数据构成的数据集合。 定义结构体结构体定义需要使用 type 和 struct 语句。struct 语句定义一个新的数据类型，结构体有中有一个或多个成员。type 语句设定了结构体的名称。结构体的格式如下：123456type struct_variable_type struct &#123; member definition; member definition; ... member definition;&#125; 一旦定义了结构体类型，它就能用于变量的声明，语法格式如下：1variable_name := structure_variable_type &#123;value1, value2...valuen&#125; 或1variable_name := structure_variable_type &#123; key1: value1, key2: value2..., keyn: valuen&#125; 你可以像其他数据类型一样将结构体类型作为参数传递给函数。123456func printBook( book Books ) &#123; fmt.Printf( &quot;Book title : %s\n&quot;, book.title); fmt.Printf( &quot;Book author : %s\n&quot;, book.author); fmt.Printf( &quot;Book subject : %s\n&quot;, book.subject); fmt.Printf( &quot;Book book_id : %d\n&quot;, book.book_id);&#125; 切片Go 语言切片是对数组的抽象。 Go 数组的长度不可改变，因此提供了一种灵活，功能强悍的内置类型切片(“动态数组”),与数组相比切片的长度是不固定的，可以追加元素，在追加时可能使切片的容量增大。 定义切片你可以声明一个未指定大小的数组来定义切片：1var identifier []type 切片不需要说明长度。 或使用make()函数来创建切片:1var slice1 []type = make([]type, len) 也可以简写为1slice1 := make([]type, len) 也可以指定容量，其中capacity为可选参数。1make([]T, length, capacity) 这里 len 是数组的长度并且也是切片的初始长度。 切片初始化1s :=[] int &#123;1,2,3 &#125; 直接初始化切片，[]表示是切片类型，{1,2,3}初始化值依次是1,2,3.其cap=len=31s := arr[:] 初始化切片s,是数组arr的引用1s := arr[startIndex:endIndex] 将arr中从下标startIndex到endIndex-1 下的元素创建为一个新的切片1s := arr[startIndex:] 缺省endIndex时将表示一直到arr的最后一个元素1s := arr[:endIndex] 缺省startIndex时将表示从arr的第一个元素开始1s1 := s[startIndex:endIndex] 通过切片s初始化切片s11s :=make([]int,len,cap) 通过内置函数make()初始化切片s,[]int 标识为其元素类型为int的切片 len() 和 cap() 函数切片是可索引的，并且可以由 len() 方法获取长度。 切片提供了计算容量的方法 cap() 可以测量切片最长可以达到多少。 空(nil)切片一个切片在未初始化之前默认为 nil，长度为 0. 范围（range） range 关键字用于 for 循环中迭代数组(array)、切片(slice)、通道(channel)或集合(map)的元素。在数组和切片中它返回元素的索引和索引对应的值，在集合中返回 key-value 对的 key 值。1234kvs := map[string]string&#123;&quot;a&quot;: &quot;apple&quot;, &quot;b&quot;: &quot;banana&quot;&#125; for k, v := range kvs &#123; fmt.Printf(&quot;%s -&gt; %s\n&quot;, k, v) &#125; Map(集合)Map 是一种无序的键值对的集合。Map 最重要的一点是通过 key 来快速检索数据，key 类似于索引，指向数据的值。 Map 是一种集合，所以我们可以像迭代数组和切片那样迭代它。不过，Map 是无序的，我们无法决定它的返回顺序，这是因为 Map 是使用 hash 表来实现的。 定义 Map可以使用内建函数 make 也可以使用 map 关键字来定义 Map:12345/* 声明变量，默认 map 是 nil */var map_variable map[key_data_type]value_data_type/* 使用 make 函数 */map_variable := make(map[key_data_type]value_data_type) 12345678var countryCapitalMap map[string]string /*创建集合 */ countryCapitalMap = make(map[string]string) /* map插入key - value对,各个国家对应的首都 */ countryCapitalMap [ &quot;France&quot; ] = &quot;巴黎&quot; countryCapitalMap [ &quot;Italy&quot; ] = &quot;罗马&quot; countryCapitalMap [ &quot;Japan&quot; ] = &quot;东京&quot; countryCapitalMap [ &quot;India &quot; ] = &quot;新德里&quot; 递归Go 语言支持递归。但我们在使用递归时，开发者需要设置退出条件，否则递归将陷入无限循环中。 类型转换类型转换用于将一种数据类型的变量转换为另外一种类型的变量。Go 语言类型转换基本格式如下：1type_name(expression) type_name 为类型，expression 为表达式。 接口Go 语言提供了另外一种数据类型即接口，它把所有的具有共性的方法定义在一起，任何其他类型只要实现了这些方法就是实现了这个接口。123456789101112131415161718192021type interface_name interface &#123; method_name1 [return_type] method_name2 [return_type] method_name3 [return_type] ... method_namen [return_type]&#125;/* 定义结构体 */type struct_name struct &#123; /* variables */&#125;/* 实现接口方法 */func (struct_name_variable struct_name) method_name1() [return_type] &#123; /* 方法实现 */&#125;...func (struct_name_variable struct_name) method_namen() [return_type] &#123; /* 方法实现*/&#125; 错误处理Go 语言通过内置的错误接口提供了非常简单的错误处理机制。 error类型是一个接口类型，这是它的定义：123type error interface &#123; Error() string&#125; 我们可以在编码中通过实现 error 接口类型来生成错误信息。 函数通常在最后的返回值中返回错误信息。使用errors.New 可返回一个错误信息：123456func Sqrt(f float64) (float64, error) &#123; if f &lt; 0 &#123; return 0, errors.New(&quot;math: square root of negative number&quot;) &#125; // 实现&#125; 在下面的例子中，我们在调用Sqrt的时候传递的一个负数，然后就得到了non-nil的error对象，将此对象与nil比较，结果为true，所以fmt.Println(fmt包在处理error时会调用Error方法)被调用，以输出错误，请看下面调用的示例代码：12345result, err:= Sqrt(-1)if err != nil &#123; fmt.Println(err)&#125; 并发Go 语言支持并发，我们只需要通过 go 关键字来开启 goroutine 即可。 goroutine 是轻量级线程，goroutine 的调度是由 Golang 运行时进行管理的。 goroutine 语法格式：1go 函数名( 参数列表 ) 例如：1go f(x, y, z) 开启一个新的 goroutine:1f(x, y, z) Go 允许使用 go 语句开启一个新的运行期线程， 即 goroutine，以一个不同的、新创建的 goroutine 来执行一个函数。 同一个程序中的所有 goroutine 共享同一个地址空间。 通道通道（channel）是用来传递数据的一个数据结构。 通道可用于两个 goroutine 之间通过传递一个指定类型的值来同步运行和通讯。操作符 &lt;- 用于指定通道的方向，发送或接收。如果未指定方向，则为双向通道。123ch &lt;- v // 把 v 发送到通道 chv := &lt;-ch // 从 ch 接收数据 // 并把值赋给 v 声明一个通道很简单，我们使用chan关键字即可，通道在使用前必须先创建：1ch := make(chan int) 注意：默认情况下，通道是不带缓冲区的。发送端发送数据，同时必须又接收端相应的接收数据。 以下实例通过两个 goroutine 来计算数字之和，在 goroutine 完成计算后，它会计算两个结果的和： 通道缓冲区通道可以设置缓冲区，通过 make 的第二个参数指定缓冲区大小：1ch := make(chan int, 100) 带缓冲区的通道允许发送端的数据发送和接收端的数据获取处于异步状态，就是说发送端发送的数据可以放在缓冲区里面，可以等待接收端去获取数据，而不是立刻需要接收端去获取数据。 不过由于缓冲区的大小是有限的，所以还是必须有接收端来接收数据的，否则缓冲区一满，数据发送端就无法再发送数据了。 注意：如果通道不带缓冲，发送方会阻塞直到接收方从通道中接收了值。如果通道带缓冲，发送方则会阻塞直到发送的值被拷贝到缓冲区内；如果缓冲区已满，则意味着需要等待直到某个接收方获取到一个值。接收方在有值可以接收之前会一直阻塞。 遍历通道与关闭通道Go 通过 range 关键字来实现遍历读取到的数据，类似于与数组或切片。格式如下：1v, ok := &lt;-ch 如果通道接收不到数据后 ok 就为 false，这时通道就可以使用 close() 函数来关闭。]]></content>
      <tags>
        <tag>golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode5. Longest Palindromic Substring]]></title>
    <url>%2F2019%2F06%2F05%2FLeetcode5%2F</url>
    <content type="text"><![CDATA[Given a string s, find the longest palindromic substring in s. You may assume that the maximum length of s is 1000. Example 1: Input: “babad”Output: “bab”Note: “aba” is also a valid answer.Example 2: Input: “cbbd”Output: “bb” dp[i][i]=1;//单个字符是回文串dp[i][i+1]=1 if s[i]=s[i+1];//连续两个相同字符是回文串 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: string longestPalindrome(string s) &#123; int len = s.size(); if(len==0 || len==1) return s; int start = 0; int max = 1; int dp[len][len]; memset(dp,0,sizeof(dp)); for(int i=0;i&lt;len;i++)&#123; dp[i][i]=1; if(i&lt;len-1 &amp;&amp; s[i]==s[i+1])&#123; dp[i][i+1]=1; max=2; start=i; &#125; &#125; //l表示检索的子串长度，等于3表示先检索长度为3的子串 for(int l=3;l&lt;=len;l++) for(int i=0;i+l-1&lt;len;i++)&#123; int j=l+i-1; //终止字符位置 if(s[i]==s[j] &amp;&amp; dp[i+1][j-1]==1)&#123; //状态转移 dp[i][j]=1; start = i; max = l; &#125; &#125; return s.substr(start,max); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高速缓存以及TLB与虚拟内存]]></title>
    <url>%2F2019%2F06%2F03%2F%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%BB%A5%E5%8F%8ATLB%E4%B8%8E%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[内存管理单元MMU这里假设大家了解虚拟内存的由来。参考《深入理解计算机系统》讲虚拟内存的章节 实际上我们写的程序，都是面向虚拟内存的。我们在程序中写的变量的地址，实际上是虚拟内存中的地址，当CPU想要访问该地址的时候，内存管理单元MMU会将该虚拟地址翻译成真实的物理地址，然后CPU就去真实的物理地址处取得数据。 这里说的虚拟地址，是指虚拟地址空间中地址。这里我们说的虚拟地址空间，实际上是在磁盘上的一块空间（常见的是4G的进程虚拟地址空间）。具体这4G的虚拟地址空间的来龙去脉，参考《深入理解计算机系统》第九章。 MMU：内存管理单元。它是一个硬件，不是软件。它用于将虚拟地址翻译成实际的物理内存地址。同时它还可以将特定的内存块设置成不同的读写属性，进而实现内存保护。注意，MMU是硬件管理，不是软件实现内存管理。 总结来说，MMU能实现以下功能： 虚拟内存。有了虚拟内存，可以在处理器上运行比实际物理内存大的应用程序。为了使用虚拟内存，操作系统通常要设置一个交换区（通常在硬盘上），通过将内存中不活跃的数据与指令放到交换区，以腾出物理内存来为其他程序服务。内存保护。通过这一功能，可以将特定的内存块设置为读、写或者可执行的属性。比如将不可变的数据或者代码设为只读的，这样可以防止被恶意串改。 虚拟内存进程的概念大家都知道。 每一个进程都独立的运行在自己的虚拟地址空间。为了理解这一个概念。我们可以看一个而简单的例子： 看一下下面的代码：main.c1234567891011#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;int g_int = 1;int main() &#123; printf(&quot;g_int = %d\n&quot;,g_int); printf(&quot;&amp;g_int = %d\n&quot;,&amp;g_int); system(&quot;pause&quot;);//此处程序会停止执行，不会执行到return 0 return 0;&#125; 如果我同时运行该程序两次。打印结果会是一样么？答案是结果肯定一样，运行结果都为： 当然，这是在我的计算机上，在你的计算机上g_int地址可能不一样，但是同时运行该程序两次，结果肯定是一样的。其实这个答案很多人都知道是一样的，初学者都知道。但是初学者说不清楚是为什么。 这个进程运行两份实例的时候。在物理内存中，实际上是以下分布情况： 进程1和进程2 位于不同的地址。但是我们程序打印的g_int全局变量的地址值，是一样的。 这里就引入了虚拟内存的概念。我们写程序，面向的是虚拟地址空间。写的程序的内容，都可以看成是在虚拟地址空间中运行（实际上最终是将虚拟地址空间映射到了物理地址空间）。如下图： 我们可以看到。main.o可执行程序，运行两份实例时，相当于两个进程。这两个进程都有自己独立的虚拟地址空间。然后将虚拟地址空间里的代码数据映射到内存中，从而被CPU执行与处理。在物理内存中，g_int这个全局变量的物理地址确实不同。但是在虚拟内存中，由于进程1与进程2的虚拟地址空间完全一样（同一个可执行程序代码），那么g_int地址，实际上就是一样的。 CPU在执行指令与数据时，获得的是虚拟内存的地址。但是CPU只能去物理内存寻址。此时，MMU就派上用场了。MMU负责，将虚拟地址，翻译成，真正运行时的物理地址。 MMU是如何将虚拟地址翻译成物理地址的，这个后面讲。现在先要了解一下交换区的概念。 交换区： 实际上就是一块磁盘空间（硬盘空间）。虚拟内存与物理内存映射的时候，是将虚拟内存的代码放到交换区中，以后在CPU想要执行相关的指令或者数据时，如果内存中没有，先去交换区将需要的指令与数据映射到物理内存，然后CPU再执行。虚拟内存与交换取的这种概念，实现了大内存需求量的（多个）进程，能够（同时）运行在较小的物理内存中。如下图所示： 上图中，说的是进程的局部代码在物理内存中运行。是因为程序具有局部性原则，所以在某一段很小的时间段内，只有很少一部分代码会被CPU执行。具体可以参考下一篇文章。 到这里，我们应该大致明白了虚拟内存的作用与简单机制。还剩下MMU如何翻译虚拟地址为物理地址的，这放到最后讲解。现在先总结一下虚拟内存机制： 虚拟内存需要重新映射到物理内存虚拟地址映射到物理地址中的实际地址每次只有进程的少部分代码会在物理内存中运行大部分代码依然位于磁盘中（存储器硬盘） 页式内存管理上一节笼统的介绍了虚拟内存的概念。接下来学习内存管理中的一种方式：页式内存管理。 页的概念由1.1的内容，我们知道了交换区。我们知道交换区里面存放的是大部分的可执行代码与数据。而物理内存中，执行的是少部分的可执行代码与数据。那么当物理内存中的代码与数据执行完需要执行接下来的代码，而刚好接下来的代码还在交换区中没有映射到物理内存（这称为缺页，后面会讲），那么此时就需要从交换区获取程序的代码，将它拿到物理内存执行。那么一次拿多少代码过来呢？这是一个问题！ 为了CPU的高效执行以及方便的内存管理（详细原因见以后的文章），每次需要拿一个页的代码。这个页，指的是一段连续的存储空间（常见的是4Kb），也叫作块。假设页的大小为P。在虚拟内存中，叫做虚拟页（VP）。从虚拟内存拿了一个页的代码要放到物理内存，那么自然物理内存也得有一个刚好一般大小的页才能存放虚拟页的代码。物理内存中的页叫做物理页（PP） 在任何时刻，虚拟页都是以下三种状态中的一种： 未分配的：VM系统还未分配的页（或者未创建）。未分配的页还没有任何数据与代码与他们相关联，因此也就不占用任何磁盘。 缓存的： 当前已缓存在物理内存中的已分配页 未缓存的：未缓存在物理内存中的已分配页 下图展示了一个8个虚拟页的小虚拟内存。其中：虚拟页0和3还没有被分配，因此在磁盘上还不存在。虚拟页1、4、 6被缓存在物理内存中。虚拟页2、 5、 7已经被分配，但是还没有缓存到物理内存中去执行。 页表的概念1.21节用到了缓存这个词。这里假设大家都理解缓存的概念。 虚拟内存中的一些虚拟页是缓存在物理内存中被执行的。理所应当，应该有一种机制，来判断虚拟页，是否被缓存在了物理内存中的某个物理页上。如果不命中（需要一个页的代码，但是这个页未缓存在物理内存中），系统还必须知道这个虚拟页存放在磁盘上的哪个位置，从而在物理内存中选择一个空闲页或者替换一个牺牲页，并将需要的虚拟页从磁盘复制到物理内存中。 这些功能，是由软硬件结合完成的。 包括操作系统软件，MMU中的地址翻译硬件，和一个存放在物理内存中的页表的数据结构。 上一节说将虚拟页映射到物理页，实际上就是MMU地址翻译硬件将一个虚拟地址翻译成物理地址时，都会去读取页表的内容。操作系统负责维护页表的内容，以及在磁盘与物理内存之间来回传送页。 下图是一个页表的基本组织结构（实际上不止那些内容）： 页表实际上就是一个数组。这个数组存放的是一个称为页表条目（PTE）的结构。虚拟地址空间的每一个页在页表中，都有一个对应的页表条目（PTE）。虚拟页地址（首地址）翻译的时候就是查询的各个虚拟页在页表中的PTE，从而进行地址翻译的。 现在假设每一个PTE都有一个有效位和一个n位字段的地址。其中 有效位：表示对应的虚拟页是否缓存在了物理内存中。0表示未缓存。1表示已缓存。n位地址字段：如果未缓存（有效字段为0），n位地址字段不为空的话，这个n位地址字段就表示该虚拟页在磁盘上的起始的位置。如果这个n位字段为空，那么就说明该虚拟页未分配。如果已缓存（有效字段为1），n位地址字段肯定不为空，它表示该虚拟页在物理内存中的起始地址。综上分析，就得知，上图中：四个虚拟页VP1 , VP2, VP4 , VP7 是被缓存在物理内存中。 两个虚拟页VP0, VP5还未被分配。但是剩下的虚拟页VP3 ,VP6已经被分配了，但是还没有缓存到物理内存中去执行。 注意：任意的物理页，都可以缓存任意的虚拟页。（因为物理内存是全相联的） 页命中考虑下图的情形： 假设现在CPU想读取VP2页面中的某一个字节的内容。会发生什么呢？ 当CPU得到一个地址vaddr想要访问它（这个addr就是上面想要访问的某一个字节的地址），通过后面会学习的MMU地址翻译硬件，将虚拟地址addr作为索引定位到页表的PTE条目中的PTE2（这里假设是PTE2），从内存中去读到PTE2的有效位为1，说明该虚拟页面已经被缓存了，所以CPU使用该PTE2条目中的物理内存地址（这个物理内存地址是PP1中的起始地址）构造出vaddr的物理地址paddr（这个地址是PP1页面起始地址或后面的某一个地址）。然后CPU就会去paddr这个物理内存地址去取数据。这种情况，就是也命中。 实际上，上面的VP2的起始地址与paddr地址，很类似于内存的分段机制（X86以前就是分段机制），CPU访问内存的地址是“段地址：偏移地址”或者叫做“CS:IP”。而我们现在学习的是分页机制，他们都是一种内存管理机制。 缺页什么是缺页？ 考虑以下图示情形：当CPU想访问VP3页面中的某一个字节。会发生什么情况？ 由1.23小节的分析知，当地址翻译硬件MMU找到了PTE3后，发现有效位为0，则说明VP3并未缓存在物理内存中，并且触发一个缺页异常。缺页异常调用内核中的缺页异常处理程序，该程序会在物理内存中查询是否有空闲页面。如果物理内存中有空闲页面，则将VP3页面的内容从磁盘中复制到（映射）物理内存中的空闲页面。如果物理内存中没有空闲页面，则缺页异常处理程序就选择一个牺牲页，在此例中就是存放在PP3中的VP4。如果VP4已经被修改了，那么内核就会将它复制回磁盘。 然后此时因为VP3已经在物理内存中被缓存了，就需要将页表更新，也就是更新PTE3。 随后缺页异常处理程序返回。它会重新启动导致缺页的指令，该指令会重新将刚刚导致缺页的虚拟地址发送到MMU硬件翻译，但是此时，因为VP3已经被缓存，所以会页命中。 下图是在经过了缺页后，我们的示例页表的状态： 以上有一个过程是替换页面的过程，其中包含一个页面调度算法。这个以后会学习。1.25 分配页面当你在程序中调用malloc或者new分配内存时，发生了什么？调用malloc后，会在虚拟内存中分配页面。（注意malloc分配的内存时虚拟内存，当CPU访问的时候，首先肯定会发生缺页，然后再将该页缓存到物理内存中） 如下图所示：本身没有VP5这个虚拟页面，现在malloc后，新分配了一个虚拟页面VP5。 分配好VP5这个虚拟页面后，还需要更新PTE条目，使得PTE5指向VP5。 程序的局部性原则虚拟内存这种机制会有什么问题？经常缺页会不会导致程序的执行效率低下？ 实际上，虽然会产生不命中现象，但是虚拟内存机制工作的很好。这主要与程序局部性原则有关！！！什么是程序的局部性？ 尽管在程序整个运行的生命周期，引用的不同的页面总数可能会超过物理内存的大小，但是局部性原则保证了在任意时刻：程序将趋向于在一个较小的活动页面集合上工作。 这个集合成为工作集或者常驻集合。在最开始，也就是将工作集页面调度到物理内存中之后，接下来对这个工作集的引用将导致页命中，而不会产生额外的磁盘流量。 上面看似很完美，但是也有可能会出现这样一种情况：工作集的大小超过了物理内存的大小！！ 此时，页面会不停的换入换出。这种状态叫做抖动！！！ 当然，现在的计算机的物理内存的大小都非常大，一般不会出现抖动的现象！！！ 虚拟内存作为内存管理工具虚拟内存为什么说是一种内存管理工具？ 虚拟内存大大地简化了内存管理，并提供了一种自然的保护内存的方法。 到目前为止，我们都假设有一个单独的页表，将一个虚拟地址空间映射到物理地址空间。实际上，操作系统为每一个进程提供了一个独立的页表，因而也就是一个独立的虚拟地址空间。如下图： 注意：多个虚拟页面，可以映射到同一个共享物理页面上。 按需页面调度和独立的虚拟地址空间的结合，对系统中内存的使用和管理产生了深远的影响！！！如下： 简化链接。 简化加载 简化共享 简化内存分配具体参考CSAPP：9.4节内容。 虚拟内存作为内存保护工具上一节学习了虚拟内存作为内存管理工具。 其实虚拟内存还可以作为内存保护工具。如何做到？ 想一想，CPU在访问一个虚拟内存页面时，需要读取页表条目中的PTE条目。如果在PTE条目中加一些额外的许可位来控制对虚拟内存的访问，当CPU读到相应的许可位，就可以知道该虚拟内存是否可读或者可写，或者可执行？ 这样看来我们的页表就要变化一下，就如下图所示： 上图中： SUP表示进程是否必须运行在内核模式（超级用户）下才能访问该页。 READ表示是否可读 WRITE表示是否可写 如果一条指令违反了这些许可条件，那么CPU就会触发一个一般保护故障，将控制传递给一个内核中的异常处理程序。Linux shell 一般将这种异常报告为“段错误（segmentation fault）” 地址翻译上面一直在说MMU通过读取页表的PTE将虚拟地址翻译成物理地址。到底是如何翻译的？ 如下图，展示了MMU是如何翻译地址的： 看到这么复杂的图，不要害怕！！！ 下面讲解很容易懂！ CPU中有一个控制寄存器，页表基址寄存器（PTBR）指向当前页表。n位的虚拟地址，包含两个部分：虚拟页面偏移VPO（p位）与虚拟页号VPN（n-p位）MMU利用虚拟内存的高n-p位VPN作为索引找到页表的对应的PTE条目，然后获取PTE条目对应的物理页号PPN然后将PPN与VPO串联连接起来，就得到了实际的物理地址。（实际上就是PPN左移p位然后加上VPO，VPO=PPO）到这里实际上我们已经更加的将这种地址串联与X86处理器中的分段机制很像。X86-16位的分段机制 也是将段地址CS左移4位然后与偏移地址IP相加，得到最终的物理地址。这是不是与上面的分页机制的地址翻译过程很像？ 实际上它们一个是实模式，一个是保护模式而已！ MMU的地址翻译过程是不是很简单？如果不理解，就反复看，就理解了！！！ 总结下面来总结一下，分页机制中，CPU获得一个虚拟地址后，有哪些步骤需要做： 当页命中时，CPU硬件执行的步骤 注释：VA：虚拟地址 PTEA：页表条目地址 PTE：页表条目 PA物理内存地址 如上图，CPU的执行步骤如下： 处理器生成一个虚拟地址，并把它传送给MMU MMU生成PTE地址，并从高速缓存/物理内存请求得到它 高速缓存/物理内存向MMU返回PTE MMU根据得到的PTE索引页表，从而构造物理地址，并把物理地址传送给高速缓存/物理内存 高速缓存/物理内存返回请求的数据或者指令给CPU 当缺页时，CPU的硬件执行过程 注释：VA：虚拟地址 PTEA：页表条目地址 PTE：页表条目 如上图，CPU的执行步骤如下： 处理器生成一个虚拟地址，并把它传送给MMU MMU生成PTE地址，并从高速缓存/物理内存请求得到它 高速缓存/物理内存向MMU返回PTE PTE中的有效位是0，所以MMU触发了一次异常，传递CPU中的控制到操作系统内核中的缺页异常处理程序 缺页异常处理程序确定出物理内存中的牺牲页，如果这个页面被修改了，就将它换出道磁盘 缺页异常处理程序将需要的页面调入到高速缓存/物理内存，并更新内存中的PTE 缺页异常处理程序返回到原来的进程，再次执行导致缺页的指令。CPU将引起缺页的地址再次发送给MMU。因为虚拟页面现在缓存在物理内存中了，所以此次就会命中，物理内存就会将所请求的数据或者指令返回给CPU 可以看到，页命中与缺页的前三步，都是一样的。我们还可以总结出一个重要的结论：页命中完全是由硬件来处理的，而缺页，却是由硬件和操作系统内核共同完成的。 高速缓存（Cache）的引入看看上面分析页命中与缺页的过程中，出现了高速缓存，如果只有物理内存很好理解，现在出现高速缓存是啥意思？ 学习过上一篇文章，我们应该可以理解页命中，缺页这些简单的概念以及虚拟地址的寻址过程（如果不明白，建议先学习上一篇文章）。 我们知道，CPU寻址时，从内存中获取指令与数据的时间还是相当大的（CPU的速度远远大于内存的速度）。所以高速缓存（Cache）就出现了。 Cache是一种小容量高速存储器 Cache的存取速度与CPU的运算速度几乎同量级 Cache在现代计算机系统中直接内置于处理器芯片中 在处理器和内存之间设置cache（精确来讲是将Cache放在MMU与物理内存之间） 把内存中被频繁访问的数据和指令复制到cache中 页表也在内存中，将被频繁访问的PTE，复制到Cache中 大多数情况下，CPU可以直接从cache中取指令与数据 如下图，我们先来看一个高速缓存与虚拟内存结合的例子，看看此时CPU的访问过程： 这个图，其实很好理解！！！当MMU要查询PTEA以及PA时，都先去高速缓存中先查一下，看看有没有，如果高速缓存中有PTEA与PA，直接从高速缓存中获取数相应的PTE与数据。 如果高速缓存中没有相应的PTEA或者PA时，就去物理内存中获取，然后从物理内存中获取之后，将获取到的PTE或者数据再缓存到高速缓存中，然后高速缓存将获取到的数据返回给CPU执行。 注意：因为Cache是放在MMU与物理内存之间的，所以高速缓存无需处理保护问题，因为访问权限的检查是MMU地址翻译过程的一部分。 利用TLB加速地址翻译学到了这里，我们应该很清楚地址翻译的过程了。如果不清楚，就需要看上一篇文章或者深入理解计算机系统第九章。 在地址翻译的过程中，CPU每产生一个虚拟地址（VP），MMU都要去别的地方查询一个PTE。这个别的地方指：高速缓存或者物理内存。在最坏的情况下（缺页），需要访问两次物理内存。这种开销是极其昂贵的。在最好的情况下，MMU也需要去高速缓存中获取PTE对应的值。虽然高速缓存已经很快了，但是相对于CPU内部来说，还是有点慢。那么能不能MMU不去别的地方获取PTE？能不能在MMU内部也搞一个类似于高速缓存的东西，来存储一部分经常被访问的PTE？答案是可以的！！！在MMU中，有一个小的缓存，称为翻译后备缓冲器（TLB） 如下图示来看看带有TLB的 MMU，且TLB命中时，是如何执行的 CPU产生一个虚拟地址 第二部和第三部是MMU从TLB中取出相应的PTE MMU将这个虚拟地址翻译成一个物理地址，并将它发送到高速缓存/物理内存。 高速缓存/物理内存将所请求的数据字返回给CPU 我们可以看到，TLB是虚拟寻址的缓存。 下面再来看看TLB不命中时，是如何执行的 当TLB不命中时，关键点在于，MMU必须从L1高速缓存中获取到相应的PTE，新取出的PTE再放到TLB中，此时可能会覆盖一个已经存在的条目。那么当TLB中有了相应的PTE,MMU再去TLB中查找… Cache与物理内存是如何映射的这里我们只学习一下直接映射法： 直接映射法： 将cache和物理内存分成固定大小的块（如512byte/块） 物理内存中的每一块在cache中都有固定的映射位置 对应的映射公式为： Pos（cache） = 内存块号 % cache总块数 如图： 注意：任意一个物理内存块都可以映射到唯一固定的cache块（物理内存不同的块，可以映射到同一个cache块）。 直接映射原理比如我们想要访问某一个物理地址，我们如何知道这个地址是否在cache中？或者如何知道它在cache中的位置？ 首先，现在只有一个物理地址，需要根据这个物理地址进行判断。 看下面，对物理地址有一个划分： 以上的物理地址分为3部分，都是什么意思呢？ 我们利用以下规则来判断; 根据物理地址的中间的c位，找到cache中对应的块 比较物理地址的高t位，让它与cache中的flag比较，看是否相同 如果相同：说明数据在高速缓存中有缓存，那么此时根据物理内存的b位找到cache对应的块中的偏移 如果不同：说明数据在缓存中没有缓存，此时就将物理内存中对应的数据复制到cache中 比如下面这个例子： 直接映射法的特点我们已经知道，直接映射法，很有可能不同的物理内存块映射到相同的cache块。所以直接映射法这样会导致缓存失效。但是直接映射法过程简单，所需耗时短！！ 总结下面笼统的用流程图概括一下处理器的数据访问过程：]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中手动获取调用堆栈]]></title>
    <url>%2F2019%2F05%2F31%2Fcpp%E4%B8%AD%E6%89%8B%E5%8A%A8%E8%8E%B7%E5%8F%96%E8%B0%83%E7%94%A8%E5%A0%86%E6%A0%88%2F</url>
    <content type="text"><![CDATA[原文链接；https://blog.csdn.net/kevinlynx/article/details/39269507 要了解调用栈，首先需要了解函数的调用过程，下面用一段代码作为例子：1234567891011121314#include &lt;stdio.h&gt;int add(int a, int b) &#123; int result = 0; result = a + b; return result;&#125;int main(int argc, char *argv[]) &#123; int result = 0; result = add(1, 2); printf(&quot;result = %d \r\n&quot;, result); return 0;&#125; 使用gcc编译，然后gdb反汇编main函数，看看它是如何调用add函数的：12345678910111213141516171819(gdb) disassemble main Dump of assembler code for function main: 0x08048439 &lt;+0&gt;: push %ebp 0x0804843a &lt;+1&gt;: mov %esp,%ebp 0x0804843c &lt;+3&gt;: and $0xfffffff0,%esp 0x0804843f &lt;+6&gt;: sub $0x20,%esp 0x08048442 &lt;+9&gt;: movl $0x0,0x1c(%esp) # 给result变量赋0值 0x0804844a &lt;+17&gt;: movl $0x2,0x4(%esp) # 将第2个参数压栈(该参数偏移为esp+0x04) 0x08048452 &lt;+25&gt;: movl $0x1,(%esp) # 将第1个参数压栈(该参数偏移为esp+0x00) 0x08048459 &lt;+32&gt;: call 0x804841c &lt;add&gt; # 调用add函数 0x0804845e &lt;+37&gt;: mov %eax,0x1c(%esp) # 将add函数的返回值赋给result变量 0x08048462 &lt;+41&gt;: mov 0x1c(%esp),%eax 0x08048466 &lt;+45&gt;: mov %eax,0x4(%esp) 0x0804846a &lt;+49&gt;: movl $0x8048510,(%esp) 0x08048471 &lt;+56&gt;: call 0x80482f0 &lt;printf@plt&gt; 0x08048476 &lt;+61&gt;: mov $0x0,%eax 0x0804847b &lt;+66&gt;: leave 0x0804847c &lt;+67&gt;: ret End of assembler dump. 可以看到，参数是在add函数调用前压栈，换句话说，参数压栈由调用者进行，参数存储在调用者的栈空间中，下面再看一下进入add函数后都做了什么：1234567891011121314(gdb) disassemble addDump of assembler code for function add: 0x0804841c &lt;+0&gt;: push %ebp # 将ebp压栈(保存函数调用者的栈基址) 0x0804841d &lt;+1&gt;: mov %esp,%ebp # 将ebp指向栈顶esp(设置当前函数的栈基址) 0x0804841f &lt;+3&gt;: sub $0x10,%esp # 分配栈空间(栈向低地址方向生长) 0x08048422 &lt;+6&gt;: movl $0x0,-0x4(%ebp) # 给result变量赋0值(该变量偏移为ebp-0x04) 0x08048429 &lt;+13&gt;: mov 0xc(%ebp),%eax # 将第2个参数的值赋给eax(准备运算) 0x0804842c &lt;+16&gt;: mov 0x8(%ebp),%edx # 将第1个参数的值赋给edx(准备运算) 0x0804842f &lt;+19&gt;: add %edx,%eax # 加法运算(edx+eax)，结果保存在eax中 0x08048431 &lt;+21&gt;: mov %eax,-0x4(%ebp) # 将运算结果eax赋给result变量 0x08048434 &lt;+24&gt;: mov -0x4(%ebp),%eax # 将result变量的值赋给eax(eax将作为函数返回值) 0x08048437 &lt;+27&gt;: leave # 恢复函数调用者的栈基址(pop %ebp) 0x08048438 &lt;+28&gt;: ret # 返回(准备执行下条指令)End of assembler dump. 进入add函数后，首先进行的操作是将当前的栈基址ebp压栈(此栈基址是调用者main函数的)，然后将ebp指向栈顶esp，接下来再进行函数内的处理流程。函数结束前，会将函数调用者的栈基址恢复，然后返回准备执行下一指令。这个过程中，栈上的空间会是下面的样子： 可以发现，每调用一次函数，都会对调用者的栈基址(ebp)进行压栈操作，并且由于栈基址是由当时栈顶指针(esp)而来，会发现，各层函数的栈基址很巧妙的构成了一个链，即当前的栈基址指向下一层函数栈基址所在的位置，如下图所示： 了解了函数的调用过程，想要回溯调用栈也就很简单了，首先获取当前函数的栈基址(寄存器ebp)的值，然后获取该地址所指向的栈的值，该值也就是下层函数的栈基址，找到下层函数的栈基址后，重复刚才的动作，即可以将每一层函数的栈基址都找出来，这也就是我们所需要的调用栈了。 下面是根据原理实现的一段获取函数调用栈的代码，供参考。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &lt;stdio.h&gt;/* 打印调用栈的最大深度 */#define DUMP_STACK_DEPTH_MAX 16/* 获取寄存器ebp的值 */void get_ebp(unsigned long *ebp) &#123; __asm__ __volatile__ ( &quot;mov %%ebp, %0&quot; :&quot;=m&quot;(*ebp) ::&quot;memory&quot;);&#125;/* 获取调用栈 */int dump_stack(void **stack, int size) &#123; unsigned long ebp = 0; int depth = 0; /* 1.得到首层函数的栈基址 */ get_ebp(&amp;ebp); /* 2.逐层回溯栈基址 */ for (depth = 0; (depth &lt; size) &amp;&amp; (0 != ebp) &amp;&amp; (0 != *(unsigned long *)ebp) &amp;&amp; (ebp != *(unsigned long *)ebp); ++depth) &#123; stack[depth] = (void *)(*(unsigned long *)(ebp + sizeof(unsigned long))); ebp = *(unsigned long *)ebp; &#125; return depth;&#125;/* 测试函数 2 */void test_meloner() &#123; void *stack[DUMP_STACK_DEPTH_MAX] = &#123;0&#125;; int stack_depth = 0; int i = 0; /* 获取调用栈 */ stack_depth = dump_stack(stack, DUMP_STACK_DEPTH_MAX); /* 打印调用栈 */ printf(&quot; Stack Track: \r\n&quot;); for (i = 0; i &lt; stack_depth; ++i) &#123; printf(&quot; [%d] %p \r\n&quot;, i, stack[i]); &#125; return;&#125;/* 测试函数 1 */void test_hutaow() &#123; test_meloner(); return;&#125;/* 主函数 */int main(int argc, char *argv[]) &#123; test_hutaow(); return 0;&#125; 需要知道的信息： 函数调用对应的call指令本质上是先压入下一条指令的地址到堆栈，然后跳转到目标函数地址 函数返回指令ret则是从堆栈取出一个地址，然后跳转到该地址 EBP寄存器始终指向当前执行函数相关信息（局部变量）所在栈中的位置，ESP则始终指向栈顶 每一个函数入口都会保存调用者的EBP值，在出口处都会重设EBP值，从而实现函数调用的现场保存及现场恢复 64位机器增加了不少寄存器，从而使得函数调用的参数大部分时候可以通过寄存器传递；同时寄存器名字发生改变，例如EBP变为RBP 在函数调用中堆栈的情况可用下图说明： 将代码对应起来：123456789101112131415161718void g() &#123; int *p = 0; long a = 0x1234; printf(&quot;%p %x\n&quot;, &amp;a, a); printf(&quot;%p %x\n&quot;, &amp;p, p); f(); *p = 1;&#125; void b(int argc, char **argv) &#123; printf(&quot;%p %p\n&quot;, &amp;argc, &amp;argv); g();&#125; int main(int argc, char **argv) &#123; b(argc, argv); return 0;&#125; 在函数g()中断点，看看堆栈中的内容(64位机器)：1234567891011(gdb) p $rbp$2 = (void *) 0x7fffffffe370(gdb) p &amp;p$3 = (int **) 0x7fffffffe368(gdb) p $rsp$4 = (void *) 0x7fffffffe360(gdb) x/8ag $rbp-160x7fffffffe360: 0x1234 0x00x7fffffffe370: 0x7fffffffe390 0x400631 &lt;b(int, char**)+43&gt;0x7fffffffe380: 0x7fffffffe498 0x1a561cbc00x7fffffffe390: 0x7fffffffe3b0 0x40064f &lt;main(int, char**)+27&gt; 对应的堆栈图：可以看看例子中0x400631 &lt;b(int, char**)+43&gt;和0x40064f &lt;main(int, char**)+27&gt;中的代码：123456789101112131415(gdb) disassemble 0x400631...0x0000000000400627 &lt;b(int, char**)+33&gt;: callq 0x400468 &lt;printf@plt&gt;0x000000000040062c &lt;b(int, char**)+38&gt;: callq 0x4005ae &lt;g()&gt;0x0000000000400631 &lt;b(int, char**)+43&gt;: leaveq # call的下一条指令...(gdb) disassemble 0x40064f... 0x000000000040063f &lt;main(int, char**)+11&gt;: mov %rsi,-0x10(%rbp)0x0000000000400643 &lt;main(int, char**)+15&gt;: mov -0x10(%rbp),%rsi0x0000000000400647 &lt;main(int, char**)+19&gt;: mov -0x4(%rbp),%edi0x000000000040064a &lt;main(int, char**)+22&gt;: callq 0x400606 &lt;b(int, char**)&gt;0x000000000040064f &lt;main(int, char**)+27&gt;: mov $0x0,%eax # call的下一条指令... 顺带一提，每个函数入口和出口，对应的设置RBP代码为：12345678(gdb) disassemble g...0x00000000004005ae &lt;g()+0&gt;: push %rbp # 保存调用者的RBP到堆栈0x00000000004005af &lt;g()+1&gt;: mov %rsp,%rbp # 设置自己的RBP...0x0000000000400603 &lt;g()+85&gt;: leaveq # 等同于：movq %rbp, %rsp # popq %rbp0x0000000000400604 &lt;g()+86&gt;: retq 由以上可见，通过当前的RSP或RBP就可以找到调用堆栈中所有函数的RBP；找到了RBP就可以找到函数地址。因为，任何时候的RBP指向的堆栈位置就是上一个函数的RBP；而任何时候RBP所在堆栈中的前一个位置就是函数返回地址。 由此我们可以自己构建一个导致gdb无法取得调用堆栈的例子：123456789101112131415161718192021222324void f() &#123; long *p = 0; p = (long*) (&amp;p + 1); // 取得g()的RBP *p = 0; // 破坏g()的RBP&#125; void g() &#123; int *p = 0; long a = 0x1234; printf(&quot;%p %x\n&quot;, &amp;a, a); printf(&quot;%p %x\n&quot;, &amp;p, p); f(); *p = 1; // 写0地址导致一次core&#125; void b(int argc, char **argv) &#123; printf(&quot;%p %p\n&quot;, &amp;argc, &amp;argv); g();&#125; int main(int argc, char **argv) &#123; b(argc, argv); return 0;&#125; 使用gdb运行该程序：1234567Program received signal SIGSEGV, Segmentation fault.g () at ebp.c:3737 *p = 1;(gdb) btCannot access memory at address 0x8(gdb) p $rbp$1 = (void *) 0x0 bt无法获取堆栈，在函数g()中RBP被改写为0，gdb从0偏移一个地址长度即0x8，尝试从0x8内存位置获取函数地址，然后提示Cannot access memory at address 0x8。 RBP出现了问题，我们就可以通过RSP来手动获取调用堆栈。因为RSP是不会被破坏的，要通过RSP获取调用堆栈则需要偏移一些局部变量所占的空间：1234567(gdb) p $rsp$2 = (void *) 0x7fffffffe360(gdb) x/8ag $rsp+16 # g()中局部变量占16字节0x7fffffffe370: 0x7fffffffe390 0x400631 &lt;b(int, char**)+43&gt;0x7fffffffe380: 0x7fffffffe498 0x1a561cbc00x7fffffffe390: 0x7fffffffe3b0 0x40064f &lt;main(int, char**)+27&gt;0x7fffffffe3a0: 0x7fffffffe498 0x100000000 基于以上就可以手工找到调用堆栈：123g()0x400631 &lt;b(int, char**)+43&gt;0x40064f &lt;main(int, char**)+27&gt; 上面的例子本质上也是破坏堆栈，并且仅仅破坏了保存了的RBP。在实际情况中，堆栈可能会被破坏得更多，则可能导致手动定位也较困难。 堆栈被破坏还可能导致更多的问题，例如覆盖了函数返回地址，则会导致RIP错误；例如堆栈的不平衡。导致堆栈被破坏的原因也有很多，例如局部数组越界；delete/free栈上对象等。 omit-frame-pointer使用RBP获取调用堆栈相对比较容易。但现在编译器都可以设置不使用RBP(gcc使用-fomit-frame-pointer，msvc使用/Oy)，对于函数而言不设置其RBP意味着可以节省若干条指令。在函数内部则完全使用RSP的偏移来定位局部变量，包括嵌套作用域里的局部变量，即使程序实际运行时不会进入这个作用域。 例如：1234567void f2() &#123; int a = 0x1234; if (a &gt; 0) &#123; int b = 0xff; b = a; &#125;&#125; gcc中使用-fomit-frame-pointer生成的代码为：123456789(gdb) disassemble f2Dump of assembler code for function f2:0x00000000004004a5 &lt;f2+0&gt;: movl $0x1234,-0x8(%rsp) # int a = 0x12340x00000000004004ad &lt;f2+8&gt;: cmpl $0x0,-0x8(%rsp) 0x00000000004004b2 &lt;f2+13&gt;: jle 0x4004c4 &lt;f2+31&gt; 0x00000000004004b4 &lt;f2+15&gt;: movl $0xff,-0x4(%rsp) # int b = 0xff0x00000000004004bc &lt;f2+23&gt;: mov -0x8(%rsp),%eax0x00000000004004c0 &lt;f2+27&gt;: mov %eax,-0x4(%rsp)0x00000000004004c4 &lt;f2+31&gt;: retq]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++模板元编程2]]></title>
    <url>%2F2019%2F05%2F29%2Fcpp%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B2%2F</url>
    <content type="text"><![CDATA[概述模板元编程（Template Metaprogramming，TMP）是编写生成或操纵程序的程序，也是一种复杂且功能强大的编程范式（Programming Paradigm）。C++模板给C++提供了元编程的能力，但大部分用户对 C++ 模板的使用并不是很频繁，大致限于泛型编程，在一些系统级的代码，尤其是对通用性、性能要求极高的基础库（如 STL、Boost）几乎不可避免在大量地使用 C++ 模板以及模板元编程。 模版元编程完全不同于普通的运行期程序，因为模版元程序的执行完全是在编译期，并且模版元程序操纵的数据不能是运行时变量，只能是编译期常量，不可修改。另外它用到的语法元素也是相当有限，不能使用运行期的一些语法，比如if-else、for和while等语句都不能用。因此，模版元编程需要很多技巧，常常需要类型重定义、枚举常量、继承、模板偏特化等方法来配合，因此模版元编程比较复杂也比较困难。 模板元编程的作用C++ 模板最初是为实现泛型编程设计的，但人们发现模板的能力远远不止于那些设计的功能。一个重要的理论结论就是：C++ 模板是图灵完备的（Turing-complete），就是用 C++ 模板可以模拟图灵机。理论上说 C++ 模板可以执行任何计算任务，但实际上因为模板是编译期计算，其能力受到具体编译器实现的限制（如递归嵌套深度，C++11 要求至少 1024，C++98 要求至少 17）。C++ 模板元编程是“意外”功能，而不是设计的功能，这也是 C++ 模板元编程语法丑陋的根源。 C++ 模板是图灵完备的，这使得 C++代码存在两层次，其中，执行编译计算的代码称为静态代码（static code），执行运行期计算的代码称为动态代码（dynamic code），C++的静态代码由模板实现，编写C++的静态代码，就是进行C++的模板元编程。 具体来说 C++ 模板可以做以下事情：编译期数值计算、类型计算、代码计算（如循环展开），其中数值计算实际意义不大，而类型计算和代码计算可以使得代码更加通用，更加易用，性能更好（也更难阅读，更难调试，有时也会有代码膨胀问题）。编译期计算在编译过程中的位置请见下图。 使用模板元编程的基本原则就是：将负载由运行时转移到编译时，同时保持原有的抽象层次。其中负载可以分为两类，一类就是程序运行本身的开销，一类则是程序员需要编写的代码。前者可以理解为编译时优化，后者则是为提高代码复用度，从而提高程序员的编程效率。 模板元编程的组成要素从编程范式上来说，C++模板元编程是函数式编程，用递归形式实现循环结构的功能，用C++ 模板的特例化提供了条件判断能力，这两点使得其具有和普通语言一样通用的能力（图灵完备性）。 模版元程序由元数据和元函数组成，元数据就是元编程可以操作的数据，即C++编译器在编译期可以操作的数据。元数据不是运行期变量，只能是编译期常量，不能修改，常见的元数据有enum枚举常量、静态常量、基本类型和自定义类型等。 元函数是模板元编程中用于操作处理元数据的“构件”，可以在编译期被“调用”，因为它的功能和形式和运行时的函数类似，而被称为元函数，它是元编程中最重要的构件。元函数实际上表现为C++的一个类、模板类或模板函数，它的通常形式如下：12345template&lt;int N, int M&gt;struct meta_func&#123; static const int value = N+M;&#125; 调用元函数获取value值：cout&lt;&lt;meta_func&lt;1, 2&gt;::value&lt;&lt;endl; meta_func的执行过程是在编译期完成的，实际执行程序时，是没有计算动作而是直接使用编译期的计算结果。元函数只处理元数据，元数据是编译期常量和类型，所以下面的代码是编译不过的：12int i = 1, j = 2;meta_func&lt;i, j&gt;::value; //错误，元函数无法处理运行时普通数据 模板元编程产生的源程序是在编译期执行的程序，因此它首先要遵循C++和模板的语法，但是它操作的对象不是运行时普通的变量，因此不能使用运行时的C++关键字（如if、else、for），可用的语法元素相当有限，最常用的是：12345enum、static const //用来定义编译期的整数常量；typedef/using //用于定义元数据；T/Args... //声明元数据类型；Template //主要用于定义元函数；:: //域运算符，用于解析类型作用域获取计算结果（元数据）。 实际上，模板元中的if-else可以通过type_traits来实现，它不仅仅可以在编译期做判断，还可以做计算、查询、转换和选择。模板元中的for等逻辑可以通过递归、重载、和模板特化（偏特化）等方法实现。 模板元编程的控制逻辑第一个 C++ 模板元程序由Erwin Unruh 在 1994 年编写，这个程序计算小于给定数 N 的全部素数（又叫质数），程序并不运行（都不能通过编译），而是让编译器在错误信息中显示结果（直观展现了是编译期计算结果，C++ 模板元编程不是设计的功能，更像是在戏弄编译器。从此，C++模板元编程的能力开始被人们认识到。 在模版元程序的具体实现时，由于其执行完全是在编译期，所以不能使用运行期的一些语法，比如if-else、for和while等语句都不能用。这些控制逻辑需要通过特殊的方法来实现。 if判断模板元编程中实现条件if判断，参考如下代码：1234567891011121314151617181920212223#include &lt;iostream&gt;template&lt;bool c, typename Then, typename Else&gt; class IF_ &#123;&#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;true, Then, Else&gt; &#123; public: typedef Then reType; &#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;false,Then, Else&gt; &#123; public: typedef Else reType; &#125;;int main()&#123; const int len = 4; // 定义一个指定字节数的类型 typedef IF_&lt;sizeof(short)==len, short, IF_&lt;sizeof(int)==len, int, IF_&lt;sizeof(long)==len, long, IF_&lt;sizeof(long long)==len, long long, void&gt;::reType&gt;::reType&gt;::reType&gt;::reType int_my; std::cout &lt;&lt; sizeof(int_my) &lt;&lt; &apos;\n&apos;;&#125; 程序输出结果：4。 实际上，从C++11开始，可以通过type_traits来实现。因为type_traits提供了编译期选择特性：std::conditional，它在编译期根据一个判断式选择两个类型中的一个，和条件表达式的语义类似，类似于一个三元表达式。它的原型是：12template&lt; bool B, class T, class F &gt;struct conditional; 所以上面的代码可以改写为如下代码：12345678910111213141516#include &lt;iostream&gt;#include &lt;type_traits&gt;int main()&#123; const int len = 4; // 定义一个指定字节数的类型 typedef std::conditional&lt;sizeof(short)==len, short, std::conditional&lt;sizeof(int)==len, int, std::conditional&lt;sizeof(long)==len, long, std::conditional&lt;sizeof(long long)==len, long long, void&gt;::type&gt;::type&gt;::type&gt;::type int_my; std::cout &lt;&lt; sizeof(int_my) &lt;&lt; &apos;\n&apos;;&#125; 程序同样编译输出4。 循环展开编译期的循环展开（ Loop Unrolling）可以通过模板特化来结束递归展开，达到运行期的for和while语句的功能。下面看一个编译期数值计算的例子。1234567891011121314151617#include &lt;iostream&gt;template&lt;int N&gt; class sum&#123;public: static const int ret = sum&lt;N-1&gt;::ret + N;&#125;;template&lt;&gt; class sum&lt;0&gt;&#123;public: static const int ret = 0;&#125;;int main()&#123;std::cout &lt;&lt; sum&lt;5&gt;::ret &lt;&lt;std::endl; return 0;&#125; 程序输出：15。 当编译器遇到sumt时，试图实例化之，sumt 引用了sumt即sumt，试图实例化sumt，以此类推，直到sumt，sumt匹配模板特例，sumt::ret为 0，sumt::ret为sumt::ret+1为1，以此类推，sumt::ret为15。值得一提的是，虽然对用户来说程序只是输出了一个编译期常量sumt::ret，但在背后，编译器其实至少处理了sumt到sumt共6个类型。 从这个例子我们也可以窥探 C++ 模板元编程的函数式编程范型，对比结构化求和程序：for(i=0,sum=0; i&lt;=N; ++i) sum+=i;用逐步改变存储（即变量 sum）的方式来对计算过程进行编程，模板元程序没有可变的存储（都是编译期常量，是不可变的变量），要表达求和过程就要用很多个常量：sumt::ret，sumt::ret，…，sumt::ret。函数式编程看上去似乎效率低下（因为它和数学接近，而不是和硬件工作方式接近），但有自己的优势：描述问题更加简洁清晰，没有可变的变量就没有数据依赖，方便进行并行化。 switch/case分支同样可以通过模板特化来模拟实现编译期的switch/case分支功能。参考如下代码：12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;template&lt;int v&gt; class Case&#123;public: static inline void Run() &#123; cout &lt;&lt; &quot;default case&quot; &lt;&lt; endl; &#125;&#125;;template&lt;&gt; class Case&lt;1&gt;&#123;public:static inline void Run()&#123; cout &lt;&lt; &quot;case 1&quot; &lt;&lt; endl; &#125;&#125;;template&lt;&gt; class Case&lt;2&gt;&#123;public: static inline void Run() &#123; cout &lt;&lt; &quot;case 2&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; Case&lt;2&gt;::Run();&#125; 程序输出结果： case 2 特性、策略与标签利用迭代器，我们可以实现很多通用算法，迭代器在容器与算法之间搭建了一座桥梁。求和函数模板如下：12345678910111213141516171819#include &lt;iostream&gt; #include &lt;vector&gt;template&lt;typename iter&gt;typename iter::value_type mysum(iter begin, iter end)&#123; typename iter::value_type sum(0);for(iter i=begin; i!=end; ++i) sum += *i; return sum;&#125;int main() &#123; std::vector&lt;int&gt; v; for(int i = 0; i&lt;100; ++i) v.push_back(i);v.push_back(i); std::cout &lt;&lt; mysum(v.begin(), v.end()) &lt;&lt; &apos;\n&apos;;&#125; 程序编译输出：4950。 我们想让 mysum() 对指针参数也能工作，毕竟迭代器就是模拟指针，但指针没有嵌套类型 value_type，可以定义 mysum() 对指针类型的特例，但更好的办法是在函数参数和 value_type 之间多加一层特性（traits）。1234567891011121314151617181920212223242526template&lt;typename iter&gt;class mytraits&#123; public: typedef typename iter::value_type value_type;&#125;;template&lt;typename T&gt;class mytraits&lt;T*&gt;&#123; public: typedef T value_type;&#125;;template&lt;typename iter&gt;typename mytraits&lt;iter&gt;::value_type mysum(iter begin, iter end) &#123; typename mytraits&lt;iter&gt;::value_type sum(0); for(iter i=begin; i!=end; ++i) sum += *i;sum += *i; return sum;&#125;int main() &#123; int v[4] = &#123;1,2,3,4&#125;; std::cout &lt;&lt; mysum(v, v+4) &lt;&lt; &apos;\n&apos;; return 0;&#125; 程序输出：10。 其实，C++ 标准定义了类似的 traits：std::iterator_trait（另一个经典例子是 std::numeric_limits） 。特性对类型的信息（如 value_type、 reference）进行包装，使得上层代码可以以统一的接口访问这些信息。C++ 模板元编程会涉及大量的类型计算，很多时候要提取类型的信息（typedef、 常量值等），如果这些类型信息的访问方式不一致（如上面的迭代器和指针），我们将不得不定义特例，这会导致大量重复代码的出现（另一种代码膨胀），而通过加一层特性可以很好的解决这一问题。另外，特性不仅可以对类型的信息进行包装，还可以提供更多信息，当然，因为加了一层，也带来复杂性。特性是一种提供元信息的手段。 策略（policy）一般是一个类模板，典型的策略是 STL 容器（如std::vector&lt;&gt;，完整声明是template&lt;class T, class Alloc=allocator&lt;T&gt;&gt; class vector;）的分配器（这个参数有默认参数，即默认存储策略），策略类将模板的经常变化的那一部分子功能块集中起来作为模板参数，这样模板便可以更为通用，这和特性的思想是类似的。 标签（tag）一般是一个空类，其作用是作为一个独一无二的类型名字用于标记一些东西，典型的例子是 STL 迭代器的五种类型的名字。12345input_iterator_tagoutput_iterator_tagforward_iterator_tagbidirectional_iterator_tagrandom_access_iterator_tag 实际上，std::vector&lt;int&gt;::iterator::iterator_category就是random_access_iterator_tag可以使用type_traits的特性is_same来判断类型是否相同。123456789#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;type_traits&gt;int main()&#123; std::cout &lt;&lt; is_same&lt;std::vector&lt;int&gt;::iterator::iterator_category, std::random_access_iterator_tag &gt;::value &lt;&lt; std::endl; return 0;&#125; 程序输出：1。 有了这样的判断，还可以根据判断结果做更复杂的元编程逻辑（如一个算法以迭代器为参数，根据迭代器标签进行特例化以对某种迭代器特殊处理）。标签还可以用来分辨函数重载。 小结C++模板元编程是图灵完备的且是函数式编程，主要特点是代码在编译期执行，可用于编译期数值计算，能够获得更有效率的运行码。模板的使用，也提高了代码泛化。与此同时，模板元编程也存一定缺点，主要有： （1）模板元编程产生的代码较为复杂，难易阅读，可读性较差； （2）大量模板的使用，编译时容易导致代码膨胀，提高了编译时间； （3）对于C++来说，由于各编译器的差异，大量依赖模板元编程（特别是最新形式的）的代码可能会有移植性的问题。 所以，对于模板元编程，我们需要扬其长避其短，合理使用模板元编程。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++模板元编程]]></title>
    <url>%2F2019%2F05%2F28%2Fcpp%E6%A8%A1%E6%9D%BF%E5%85%83%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文：http://blog.jobbole.com/83461/ 所谓元编程就是编写直接生成或操纵程序的程序，C++ 模板给 C++ 语言提供了元编程的能力，模板使 C++ 编程变得异常灵活，能实现很多高级动态语言才有的特性（语法上可能比较丑陋，一些历史原因见下文）。普通用户对 C++ 模板的使用可能不是很频繁，大致限于泛型编程，但一些系统级的代码，尤其是对通用性、性能要求极高的基础库（如 STL、Boost）几乎不可避免的都大量地使用 C++ 模板，一个稍有规模的大量使用模板的程序，不可避免的要涉及元编程（如类型计算）。本文就是要剖析 C++ 模板元编程的机制。 C++模板的语法函数模板（function template）和类模板（class template）的简单示例如下：12345678910111213141516171819202122232425262728#include &lt;iostream&gt; // 函数模板template&lt;typename T&gt;bool equivalent(const T&amp; a, const T&amp; b)&#123; return !(a &lt; b) &amp;&amp; !(b &lt; a);&#125;// 类模板template&lt;typename T=int&gt; // 默认参数class bignumber&#123; T _v;public: bignumber(T a) : _v(a) &#123; &#125; inline bool operator&lt;(const bignumber&amp; b) const; // 等价于 (const bignumber&lt;T&gt; b)&#125;;// 在类模板外实现成员函数template&lt;typename T&gt;bool bignumber&lt;T&gt;::operator&lt;(const bignumber&amp; b) const&#123; return _v &lt; b._v;&#125; int main()&#123; bignumber&lt;&gt; a(1), b(1); // 使用默认参数，&quot;&lt;&gt;&quot;不能省略 std::cout &lt;&lt; equivalent(a, b) &lt;&lt; &apos;\n&apos;; // 函数模板参数自动推导 std::cout &lt;&lt; equivalent&lt;double&gt;(1, 2) &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 程序输出如下：1210 关于模板（函数模板、类模板）的模板参数（详见文献[1]第3章）： 类型参数（type template parameter），用 typename 或 class 标记；非类型参数（non-type template parameter）可以是：整数及枚举类型、对象或函数的指针、对象或函数的引用、对象的成员指针，非类型参数是模板实例的常量；模板型参数（template template parameter），如template&lt;typename T, template&lt;typename&gt; class A&gt; someclass {};；模板参数可以有默认值（函数模板参数默认是从 C++11 开始支持）；函数模板的和函数参数类型有关的模板参数可以自动推导，类模板参数不存在推导机制；C++11 引入变长模板参数，请见下文。模板特例化（template specialization，又称特例、特化）的简单示例如下：12345678910111213141516171819202122232425262728293031// 实现一个向量类template&lt;typename T, int N&gt;class Vec&#123; T _v[N]; // ... // 模板通例（primary template），具体实现&#125;;template&lt;&gt;class Vec&lt;float, 4&gt;&#123; float _v[4]; // ... // 对 Vec&lt;float, 4&gt; 进行专门实现，如利用向量指令进行加速&#125;;template&lt;int N&gt;class Vec&lt;bool, N&gt;&#123; char _v[(N+sizeof(char)-1)/sizeof(char)]; // ... // 对 Vec&lt;bool, N&gt; 进行专门实现，如用一个比特位表示一个bool&#125;;template&lt;typename T, int N&gt;class Vec&#123; T _v[N]; // ... // 模板通例（primary template），具体实现&#125;;template&lt;&gt;class Vec&lt;float, 4&gt;&#123; float _v[4]; // ... // 对 Vec&lt;float, 4&gt; 进行专门实现，如利用向量指令进行加速&#125;;template&lt;int N&gt;class Vec&lt;bool, N&gt;&#123; char _v[(N+sizeof(char)-1)/sizeof(char)]; // ... // 对 Vec&lt;bool, N&gt; 进行专门实现，如用一个比特位表示一个bool&#125;; 所谓模板特例化即对于通例中的某种或某些情况做单独专门实现，最简单的情况是对每个模板参数指定一个具体值，这成为完全特例化（full specialization），另外，可以限制模板参数在一个范围取值或满足一定关系等，这称为部分特例化（partial specialization），用数学上集合的概念，通例模板参数所有可取的值组合构成全集U，完全特例化对U中某个元素进行专门定义，部分特例化对U的某个真子集进行专门定义。 更多模板特例化的例子如下（参考了文献[1]第44页）：12345678910111213141516template&lt;typename T, int i&gt; class cp00; // 用于模板型模板参数// 通例template&lt;typename T1, typename T2, int i, template&lt;typename, int&gt; class CP&gt;class TMP;// 完全特例化template&lt;&gt;class TMP&lt;int, float, 2, cp00&gt;;// 第一个参数有const修饰template&lt;typename T1, typename T2, int i, template&lt;typename, int&gt; class CP&gt;class TMP&lt;const T1, T2, i, CP&gt;;// 第一二个参数为cp00的实例且满足一定关系，第四个参数为cp00template&lt;typename T, int i&gt;class TMP&lt;cp00&lt;T, i&gt;, cp00&lt;T, i+10&gt;, i, cp00&gt;;// 编译错误!，第四个参数类型和通例类型不一致//template&lt;template&lt;int i&gt; CP&gt;//class TMP&lt;int, float, 10, CP&gt;; 关于模板特例化（详见文献[1]第4章）： 在定义模板特例之前必须已经有模板通例（primary template）的声明；模板特例并不要求一定与通例有相同的接口，但为了方便使用（体会特例的语义）一般都相同；匹配规则，在模板实例化时如果有模板通例、特例加起来多个模板版本可以匹配，则依据如下规则：对版本AB，如果 A 的模板参数取值集合是B的真子集，则优先匹配 A，如果 AB 的模板参数取值集合是“交叉”关系（AB 交集不为空，且不为包含关系），则发生编译错误，对于函数模板，用函数重载分辨（overload resolution）规则和上述规则结合并优先匹配非模板函数。对模板的多个实例，类型等价（type equivalence）判断规则（详见文献[2] 13.2.4）：同一个模板（模板名及其参数类型列表构成的模板签名（template signature）相同，函数模板可以重载，类模板不存在重载）且指定的模板实参等价（类型参数是等价类型，非类型参数值相同）。如下例子：123456789101112131415161718#include &lt;iostream&gt;// 识别两个类型是否相同，提前进入模板元编程^_^template&lt;typename T1, typename T2&gt; // 通例，返回 falseclass theSameType &#123; public: enum &#123; ret = false &#125;; &#125;;template&lt;typename T&gt; // 特例，两类型相同时返回 trueclass theSameType&lt;T, T&gt; &#123; public: enum &#123; ret = true &#125;; &#125;; template&lt;typename T, int i&gt; class aTMP &#123; &#125;; int main()&#123; typedef unsigned int uint; // typedef 定义类型别名而不是引入新类型 typedef uint uint2; std::cout &lt;&lt; theSameType&lt;unsigned, uint2&gt;::ret &lt;&lt; &apos;\n&apos;; // 感谢 C++11，连续角括号“&gt;&gt;”不会被当做流输入符号而编译错误 std::cout &lt;&lt; theSameType&lt;aTMP&lt;unsigned, 2&gt;, aTMP&lt;uint2, 2&gt;&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; theSameType&lt;aTMP&lt;int, 2&gt;, aTMP&lt;int, 3&gt;&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 123110 关于模板实例化（template instantiation）（详见文献[4]模板）： 指在编译或链接时生成函数模板或类模板的具体实例源代码，即用使用模板时的实参类型替换模板类型参数（还有非类型参数和模板型参数）；隐式实例化（implicit instantiation）：当使用实例化的模板时自动地在当前代码单元之前插入模板的实例化代码，模板的成员函数一直到引用时才被实例化；显式实例化（explicit instantiation）：直接声明模板实例化，模板所有成员立即都被实例化；实例化也是一种特例化，被称为实例化的特例（instantiated (or generated) specialization）。隐式实例化时，成员只有被引用到才会进行实例化，这被称为推迟实例化（lazy instantiation），由此可能带来的问题如下面的例子（文献[6]，文献[7]）：123456789101112131415#include &lt;iostream&gt; template&lt;typename T&gt;class aTMP &#123;public: void f1() &#123; std::cout &lt;&lt; &quot;f1()\n&quot;; &#125; void f2() &#123; std::ccccout &lt;&lt; &quot;f2()\n&quot;; &#125; // 敲错键盘了，语义错误：没有 std::ccccout&#125;; int main()&#123; aTMP&lt;int&gt; a; a.f1(); // a.f2(); // 这句代码被注释时，aTMP&lt;int&gt;::f2() 不被实例化，从而上面的错误被掩盖! std::cin.get(); return 0;&#125; 所以模板代码写完后最好写个诸如显示实例化的测试代码，更深入一些，可以插入一些模板调用代码使得编译器及时发现错误，而不至于报出无限长的错误信息。另一个例子如下（GCC 4.8 下编译的输出信息，VS2013 编译输出了 500 多行错误信息）：12345678910111213#include &lt;iostream&gt; // 计算 N 的阶乘 N!template&lt;int N&gt;class aTMP&#123;public: enum &#123; ret = N==0 ? 1 : N * aTMP&lt;N-1&gt;::ret &#125;; // Lazy Instantiation，将产生无限递归!&#125;; int main()&#123; std::cout &lt;&lt; aTMP&lt;10&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 123456789sh-4.2# g++ -std=c++11 -o main *.cppmain.cpp:7:28: error: template instantiation depth exceeds maximum of 900 (use -ftemplate-depth= to increase the maximum) instantiating &apos;class aTMP&lt;-890&gt;&apos; enum &#123; ret = N==0 ? 1 : N * aTMP&lt;N-1&gt;::ret &#125;; ^main.cpp:7:28: recursively required from &apos;class aTMP&lt;9&gt;&apos;main.cpp:7:28: required from &apos;class aTMP&lt;10&gt;&apos;main.cpp:11:23: required from here main.cpp:7:28: error: incomplete type &apos;aTMP&lt;-890&gt;&apos; used in nested name specifier 上面的错误是因为，当编译 aTMP 时，并不判断 N==0，而仅仅知道其依赖 aTMP（lazy instantiation），从而产生无限递归，纠正方法是使用模板特例化，如下：123456789101112131415161718#include &lt;iostream&gt; // 计算 N 的阶乘 N!template&lt;int N&gt;class aTMP&#123;public: enum &#123; ret = N * aTMP&lt;N-1&gt;::ret &#125;;&#125;;template&lt;&gt;class aTMP&lt;0&gt;&#123;public: enum &#123; ret = 1 &#125;;&#125;; int main()&#123; std::cout &lt;&lt; aTMP&lt;10&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 13228800 关于模板的编译和链接（详见文献[1] 1.3、文献[4]模板）： 包含模板编译模式：编译器生成每个编译单元中遇到的所有的模板实例，并存放在相应的目标文件中；链接器合并等价的模板实例，生成可执行文件，要求实例化时模板定义可见，不能使用系统链接器；分离模板编译模式（使用 export 关键字）：不重复生成模板实例，编译器设计要求高，可以使用系统链接器；包含编译模式是主流，C++11 已经弃用 export 关键字（对模板引入 extern 新用法），一般将模板的全部实现代码放在同一个头文件中并在用到模板的地方用 #include 包含头文件，以防止出现实例不一致（如下面紧接着例子）；实例化，编译链接的简单例子如下（参考了文献[1]第10页）：123456789101112131415161718192021// file: a.cpp#include &lt;iostream&gt;template&lt;typename T&gt;class MyClass &#123; &#125;;template MyClass&lt;double&gt;::MyClass(); // 显示实例化构造函数 MyClass&lt;double&gt;::MyClass()template class MyClass&lt;long&gt;; // 显示实例化整个类 MyClass&lt;long&gt; template&lt;typename T&gt;void print(T const&amp; m) &#123; std::cout &lt;&lt; &quot;a.cpp: &quot; &lt;&lt; m &lt;&lt; &apos;\n&apos;; &#125; void fa() &#123; print(1); // print&lt;int&gt;，隐式实例化 print(0.1); // print&lt;double&gt;&#125;void fb(); // fb() 在 b.cpp 中定义，此处声明 int main()&#123; fa(); fb(); std::cin.get(); return 0;&#125; 123456789// file: b.cpp#include &lt;iostream&gt;template&lt;typename T&gt;void print(T const&amp; m) &#123; std::cout &lt;&lt; &quot;b.cpp: &quot; &lt;&lt; m &lt;&lt; &apos;\n&apos;; &#125;void fb() &#123; print(&apos;2&apos;); // print&lt;char&gt; print(0.1); // print&lt;double&gt;&#125; 1234a.cpp: 1a.cpp: 0.1b.cpp: 2a.cpp: 0.1 上例中，由于 a.cpp 和 b.cpp 中的 print 实例等价（模板实例的二进制代码在编译生成的对象文件 a.obj、b.obj 中），故链接时消除了一个（消除哪个没有规定，上面消除了 b.cpp 中的）。关于 template、typename、this 关键字的使用（文献[4]模板，文献[5]）： 依赖于模板参数（template parameter，形式参数，实参英文为 argument）的名字被称为依赖名字（dependent name），C++标准规定，如果解析器在一个模板中遇到一个嵌套依赖名字，它假定那个名字不是一个类型，除非显式用 typename 关键字前置修饰该名字；和上一条 typename 用法类似，template 用于指明嵌套类型或函数为模板；this 用于指定查找基类中的成员（当基类是依赖模板参数的类模板实例时，由于实例化总是推迟，这时不依赖模板参数的名字不在基类中查找，文献[1]第 166 页）。一个例子如下（需要 GCC 编译，GCC 对 C++11 几乎全面支持，VS2013 此处总是在基类中查找名字，且函数模板前不需要 template）：1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt; template&lt;typename T&gt;class aTMP&#123;public: typedef const T reType;&#125;; void f() &#123; std::cout &lt;&lt; &quot;global f()\n&quot;; &#125; template&lt;typename T&gt;class Base &#123;public: template &lt;int N = 99&gt; void f() &#123; std::cout &lt;&lt; &quot;member f(): &quot; &lt;&lt; N &lt;&lt; &apos;\n&apos;; &#125;&#125;; template&lt;typename T&gt;class Derived : public Base&lt;T&gt; &#123;public: typename T::reType m; // typename 不能省略 Derived(typename T::reType a) : m(a) &#123; &#125; void df1() &#123; f(); &#125; // 调用全局 f()，而非想象中的基类 f() void df2() &#123; this-&gt;template f(); &#125; // 基类 f&lt;99&gt;() void df3() &#123; Base&lt;T&gt;::template f&lt;22&gt;(); &#125; // 强制基类 f&lt;22&gt;() void df4() &#123; ::f(); &#125; // 强制全局 f()&#125;; int main()&#123; Derived&lt;aTMP&lt;int&gt;&gt; a(10); a.df1(); a.df2(); a.df3(); a.df4(); std::cin.get(); return 0;&#125; 1234global f()member f(): 99member f(): 22global f() C++11 关于模板的新特性（详见文献[1]第15章，文献[4]C++11）： “&gt;&gt;” 根据上下文自动识别正确语义；函数模板参数默认值；变长模板参数（扩展 sizeof…() 获取参数个数）；模板别名（扩展 using 关键字）；外部模板实例（拓展 extern 关键字），弃用 export template。在本文中，如无特别声明将不使用 C++11 的特性（除了 “&gt;&gt;”）。 模板元编程概述如果对 C++ 模板不熟悉（光熟悉语法还不算熟悉），可以先跳过本节，往下看完例子再回来。 C++ 模板最初是为实现泛型编程设计的，但人们发现模板的能力远远不止于那些设计的功能。一个重要的理论结论就是：C++ 模板是图灵完备的（Turing-complete），其证明过程请见文献[8]（就是用 C++ 模板模拟图灵机），理论上说 C++ 模板可以执行任何计算任务，但实际上因为模板是编译期计算，其能力受到具体编译器实现的限制（如递归嵌套深度，C++11 要求至少 1024，C++98 要求至少 17）。C++ 模板元编程是“意外”功能，而不是设计的功能，这也是 C++ 模板元编程语法丑陋的根源。 C++ 模板是图灵完备的，这使得 C++ 成为两层次语言（two-level languages，中文暂且这么翻译，文献[9]），其中，执行编译计算的代码称为静态代码（static code），执行运行期计算的代码称为动态代码（dynamic code），C++ 的静态代码由模板实现（预处理的宏也算是能进行部分静态计算吧，也就是能进行部分元编程，称为宏元编程，见 Boost 元编程库即 BCCL，文献[16]和文献[1] 10.4）。 具体来说 C++ 模板可以做以下事情：编译期数值计算、类型计算、代码计算（如循环展开），其中数值计算实际不太有意义，而类型计算和代码计算可以使得代码更加通用，更加易用，性能更好（也更难阅读，更难调试，有时也会有代码膨胀问题）。编译期计算在编译过程中的位置请见下图（取自文献[10]），可以看到关键是模板的机制在编译具体代码（模板实例）前执行： C++ 模板元编程 从编程范型（programming paradigm）上来说，C++ 模板是函数式编程（functional programming），它的主要特点是：函数调用不产生任何副作用（没有可变的存储），用递归形式实现循环结构的功能。C++ 模板的特例化提供了条件判断能力，而模板递归嵌套提供了循环的能力，这两点使得其具有和普通语言一样通用的能力（图灵完备性）。 从编程形式来看，模板的“&lt;&gt;”中的模板参数相当于函数调用的输入参数，模板中的 typedef 或 static const 或 enum 定义函数返回值（类型或数值，数值仅支持整型，如果需要可以通过编码计算浮点数），代码计算是通过类型计算进而选择类型的函数实现的（C++ 属于静态类型语言，编译器对类型的操控能力很强）。代码示意如下：1234567891011121314151617181920212223242526272829#include &lt;iostream&gt; template&lt;typename T, int i=1&gt;class someComputing &#123;public: typedef volatile T* retType; // 类型计算 enum &#123; retValume = i + someComputing&lt;T, i-1&gt;::retValume &#125;; // 数值计算，递归 static void f() &#123; std::cout &lt;&lt; &quot;someComputing: i=&quot; &lt;&lt; i &lt;&lt; &apos;\n&apos;; &#125;&#125;;template&lt;typename T&gt; // 模板特例，递归终止条件class someComputing&lt;T, 0&gt; &#123;public: enum &#123; retValume = 0 &#125;;&#125;; template&lt;typename T&gt;class codeComputing &#123;public: static void f() &#123; T::f(); &#125; // 根据类型调用函数，代码计算&#125;; int main()&#123; someComputing&lt;int&gt;::retType a=0; std::cout &lt;&lt; sizeof(a) &lt;&lt; &apos;\n&apos;; // 64-bit 程序指针 // VS2013 默认最大递归深度500，GCC4.8 默认最大递归深度900（-ftemplate-depth=n） std::cout &lt;&lt; someComputing&lt;int, 500&gt;::retValume &lt;&lt; &apos;\n&apos;; // 1+2+...+500 codeComputing&lt;someComputing&lt;int, 99&gt;&gt;::f(); std::cin.get(); return 0;&#125; 1238125250someComputing: i=99 编译期数值计算第一个 C++ 模板元程序是 Erwin Unruh 在 1994 年写的（文献[14]），这个程序计算小于给定数 N 的全部素数（又叫质数），程序并不运行（都不能通过编译），而是让编译器在错误信息中显示结果（直观展现了是编译期计算结果，C++ 模板元编程不是设计的功能，更像是在戏弄编译器，当然 C++11 有所改变），由于年代久远，原来的程序用现在的编译器已经不能编译了，下面的代码在原来程序基础上稍作了修改（GCC 4.8 下使用 -fpermissvie，只显示警告信息）：123456789101112131415161718192021222324252627// Prime number computation by Erwin Unruhtemplate&lt;int i&gt; struct D &#123; D(void*); operator int(); &#125;; // 构造函数参数为 void* 指针 template&lt;int p, int i&gt; struct is_prime &#123; // 判断 p 是否为素数，即 p 不能整除 2...p-1 enum &#123; prim = (p%i) &amp;&amp; is_prime&lt;(i&gt;2?p:0), i-1&gt;::prim &#125;;&#125;;template&lt;&gt; struct is_prime&lt;0, 0&gt; &#123; enum &#123; prim = 1 &#125;; &#125;;template&lt;&gt; struct is_prime&lt;0, 1&gt; &#123; enum &#123; prim = 1 &#125;; &#125;; template&lt;int i&gt; struct Prime_print &#123; Prime_print&lt;i-1&gt; a; enum &#123; prim = is_prime&lt;i, i-1&gt;::prim &#125;; // prim 为真时， prim?1:0 为 1，int 到 D&lt;i&gt; 转换报错；假时， 0 为 NULL 指针不报错 void f() &#123; D&lt;i&gt; d = prim?1:0; a.f(); &#125; // 调用 a.f() 实例化 Prime_print&lt;i-1&gt;::f()&#125;;template&lt;&gt; struct Prime_print&lt;2&gt; &#123; // 特例，递归终止 enum &#123; prim = 1 &#125;; void f() &#123; D&lt;2&gt; d = prim?1:0; &#125;&#125;; #ifndef LAST#define LAST 10#endif int main() &#123; Prime_print&lt;LAST&gt; a; a.f(); // 必须调用 a.f() 以实例化 Prime_print&lt;LAST&gt;::f()&#125; 12345678910111213141516171819202122232425262728293031323334353637sh-4.2# g++ -std=c++11 -fpermissive -o main *.cppmain.cpp: In member function &apos;void Prime_print&lt;2&gt;::f()&apos;:main.cpp:17:33: warning: invalid conversion from &apos;int&apos; to &apos;void*&apos; [-fpermissive] void f() &#123; D&lt;2&gt; d = prim ? 1 : 0; &#125; ^main.cpp:2:28: warning: initializing argument 1 of &apos;D&lt;i&gt;::D(void*) [with int i = 2]&apos; [-fpermissive] template&lt;int i&gt; struct D &#123; D(void*); operator int(); &#125;; ^main.cpp: In instantiation of &apos;void Prime_print&lt;i&gt;::f() [with int i = 7]&apos;:main.cpp:13:36: recursively required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 9]&apos;main.cpp:13:36: required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 10]&apos;main.cpp:25:27: required from heremain.cpp:13:33: warning: invalid conversion from &apos;int&apos; to &apos;void*&apos; [-fpermissive] void f() &#123; D&lt;i&gt; d = prim ? 1 : 0; a.f(); &#125; ^main.cpp:2:28: warning: initializing argument 1 of &apos;D&lt;i&gt;::D(void*) [with int i = 7]&apos; [-fpermissive] template&lt;int i&gt; struct D &#123; D(void*); operator int(); &#125;; ^main.cpp: In instantiation of &apos;void Prime_print&lt;i&gt;::f() [with int i = 5]&apos;:main.cpp:13:36: recursively required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 9]&apos;main.cpp:13:36: required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 10]&apos;main.cpp:25:27: required from heremain.cpp:13:33: warning: invalid conversion from &apos;int&apos; to &apos;void*&apos; [-fpermissive] void f() &#123; D&lt;i&gt; d = prim ? 1 : 0; a.f(); &#125; ^main.cpp:2:28: warning: initializing argument 1 of &apos;D&lt;i&gt;::D(void*) [with int i = 5]&apos; [-fpermissive] template&lt;int i&gt; struct D &#123; D(void*); operator int(); &#125;; ^main.cpp: In instantiation of &apos;void Prime_print&lt;i&gt;::f() [with int i = 3]&apos;:main.cpp:13:36: recursively required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 9]&apos;main.cpp:13:36: required from &apos;void Prime_print&lt;i&gt;::f() [with int i = 10]&apos;main.cpp:25:27: required from heremain.cpp:13:33: warning: invalid conversion from &apos;int&apos; to &apos;void*&apos; [-fpermissive] void f() &#123; D&lt;i&gt; d = prim ? 1 : 0; a.f(); &#125; ^main.cpp:2:28: warning: initializing argument 1 of &apos;D&lt;i&gt;::D(void*) [with int i = 3]&apos; [-fpermissive] template&lt;int i&gt; struct D &#123; D(void*); operator int(); &#125;; 上面的编译输出信息只给出了前一部分，虽然信息很杂，但还是可以看到其中有 10 以内全部素数：2、3、5、7（已经加粗显示关键行）。 到目前为止，虽然已经看到了阶乘、求和等递归数值计算，但都没涉及原理，下面以求和为例讲解 C++ 模板编译期数值计算的原理：1234567891011121314 template&lt;int N&gt;class sumt&#123;public: static const int ret = sumt&lt;N-1&gt;::ret + N;&#125;;template&lt;&gt;class sumt&lt;0&gt;&#123;public: static const int ret = 0;&#125;; int main() &#123; std::cout &lt;&lt; sumt&lt;5&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 115 当编译器遇到 sumt 时，试图实例化之，sumt 引用了 sumt 即 sumt，试图实例化 sumt，以此类推，直到 sumt，sumt 匹配模板特例，sumt::ret 为 0，sumt::ret 为 sumt::ret+1 为 1，以此类推，sumt::ret 为 15。值得一提的是，虽然对用户来说程序只是输出了一个编译期常量 sumt::ret，但在背后，编译器其实至少处理了 sumt 到 sumt 共 6 个类型。 从这个例子我们也可以窥探 C++ 模板元编程的函数式编程范型，对比结构化求和程序：for(i=0,sum=0; i&lt;=N; ++i) sum+=i; 用逐步改变存储（即变量 sum）的方式来对计算过程进行编程，模板元程序没有可变的存储（都是编译期常量，是不可变的变量），要表达求和过程就要用很多个常量：sumt::ret，sumt::ret，…，sumt::ret 。函数式编程看上去似乎效率低下（因为它和数学接近，而不是和硬件工作方式接近），但有自己的优势：描述问题更加简洁清晰（前提是熟悉这种方式），没有可变的变量就没有数据依赖，方便进行并行化。 模板下的控制结构模板实现的条件 if 和 while 语句如下（文献[9]）：123456789101112131415161718// 通例为空，若不匹配特例将报错，很好的调试手段（这里是 bool 就无所谓了）template&lt;bool c, typename Then, typename Else&gt; class IF_ &#123; &#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;true, Then, Else&gt; &#123; public: typedef Then reType; &#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;false,Then, Else&gt; &#123; public: typedef Else reType; &#125;; // 隐含要求： Condition 返回值 ret，Statement 有类型 Nexttemplate&lt;template&lt;typename&gt; class Condition, typename Statement&gt;class WHILE_ &#123; template&lt;typename Statement&gt; class STOP &#123; public: typedef Statement reType; &#125;;public: typedef typename IF_&lt;Condition&lt;Statement&gt;::ret, WHILE_&lt;Condition, typename Statement::Next&gt;, STOP&lt;Statement&gt;&gt;::reType::reType reType;&#125;; IF_&lt;&gt; 的使用示例见下面：123456789const int len = 4;typedef IF_&lt;sizeof(short)==len, short, IF_&lt;sizeof(int)==len, int, IF_&lt;sizeof(long)==len, long, IF_&lt;sizeof(long long)==len, long long, void&gt;::reType&gt;::reType&gt;::reType&gt;::reTypeint_my; // 定义一个指定字节数的类型std::cout &lt;&lt; sizeof(int_my) &lt;&lt; &apos;\n&apos;; 14 WHILE_&lt;&gt; 的使用示例见下面：1234567891011121314151617181920// 计算 1^e+2^e+...+n^etemplate&lt;int n, int e&gt;class sum_pow &#123; template&lt;int i, int e&gt; class pow_e&#123; public: enum&#123; ret=i*pow_e&lt;i,e-1&gt;::ret &#125;; &#125;; template&lt;int i&gt; class pow_e&lt;i,0&gt;&#123; public: enum&#123; ret=1 &#125;; &#125;; // 计算 i^e，嵌套类使得能够定义嵌套模板元函数，private 访问控制隐藏实现细节 template&lt;int i&gt; class pow&#123; public: enum&#123; ret=pow_e&lt;i,e&gt;::ret &#125;; &#125;; template&lt;typename stat&gt; class cond &#123; public: enum&#123; ret=(stat::ri&lt;=n) &#125;; &#125;; template&lt;int i, int sum&gt; class stat &#123; public: typedef stat&lt;i+1, sum+pow&lt;i&gt;::ret&gt; Next; enum&#123; ri=i, ret=sum &#125;; &#125;;public: enum&#123; ret = WHILE_&lt;cond, stat&lt;1,0&gt;&gt;::reType::ret &#125;;&#125;;int main() &#123; std::cout &lt;&lt; sum_pow&lt;10, 2&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 1385 为了展现编译期数值计算的强大能力，下面是一个更复杂的计算：最大公约数（Greatest Common Divisor，GCD）和最小公倍数（Lowest Common Multiple，LCM），经典的辗转相除算法：12345678910111213141516171819202122232425262728293031323334353637// 最小公倍数，普通函数int lcm(int a, int b)&#123; int r, lcm=a*b; while(r=a%b) &#123; a = b; b = r; &#125; // 因为用可变的存储，不能写成 a=b; b=a%b; return lcm/b;&#125;// 递归函数版本int gcd_r(int a, int b) &#123; return b==0 ? a : gcd_r(b, a%b); &#125; // 简洁int lcm_r(int a, int b) &#123; return a * b / gcd_r(a,b); &#125; // 模板版本template&lt;int a, int b&gt;class lcm_T&#123; template&lt;typename stat&gt; class cond &#123; public: enum&#123; ret=(stat::div!=0) &#125;; &#125;; template&lt;int a, int b&gt; class stat &#123; public: typedef stat&lt;b, a%b&gt; Next; enum&#123; div=a%b, ret=b &#125;; &#125;; static const int gcd = WHILE_&lt;cond, stat&lt;a,b&gt;&gt;::reType::ret;public: static const int ret = a * b / gcd;&#125;;// 递归模板版本template&lt;int a, int b&gt;class lcm_T_r&#123; template&lt;int a, int b&gt; class gcd &#123; public: enum&#123; ret = gcd&lt;b,a%b&gt;::ret &#125;; &#125;; template&lt;int a&gt; class gcd&lt;a, 0&gt; &#123; public: enum&#123; ret = a &#125;; &#125;;public: static const int ret = a * b / gcd&lt;a,b&gt;::ret;&#125;; int main() &#123; std::cout &lt;&lt; lcm(100, 36) &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; lcm_r(100, 36) &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; lcm_T&lt;100, 36&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; lcm_T_r&lt;100, 36&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 1234900900900900 上面例子中，定义一个类的整型常量，可以用 enum，也可以用 static const int，需要注意的是 enum 定义的常量的字节数不会超过 sizeof(int) （文献[2]）。 循环展开文献[11]展示了一个循环展开（loop unrolling）的例子 — 冒泡排序：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;utility&gt; // std::swap // dynamic code, 普通函数版本void bubbleSort(int* data, int n)&#123; for(int i=n-1; i&gt;0; --i) &#123; for(int j=0; j&lt;i; ++j) if (data[j]&gt;data[j+1]) std::swap(data[j], data[j+1]); &#125;&#125;// 数据长度为 4 时，手动循环展开inline void bubbleSort4(int* data)&#123;#define COMP_SWAP(i, j) if(data[i]&gt;data[j]) std::swap(data[i], data[j]) COMP_SWAP(0, 1); COMP_SWAP(1, 2); COMP_SWAP(2, 3); COMP_SWAP(0, 1); COMP_SWAP(1, 2); COMP_SWAP(0, 1);&#125; // 递归函数版本，指导模板思路，最后一个参数是哑参数（dummy parameter），仅为分辨重载函数class recursion &#123; &#125;;void bubbleSort(int* data, int n, recursion)&#123; if(n&lt;=1) return; for(int j=0; j&lt;n-1; ++j) if(data[j]&gt;data[j+1]) std::swap(data[j], data[j+1]); bubbleSort(data, n-1, recursion());&#125; // static code, 模板元编程版本template&lt;int i, int j&gt;inline void IntSwap(int* data) &#123; // 比较和交换两个相邻元素 if(data[i]&gt;data[j]) std::swap(data[i], data[j]);&#125; template&lt;int i, int j&gt;inline void IntBubbleSortLoop(int* data) &#123; // 一次冒泡，将前 i 个元素中最大的置换到最后 IntSwap&lt;j, j+1&gt;(data); IntBubbleSortLoop&lt;j&lt;i-1?i:0, j&lt;i-1?(j+1):0&gt;(data);&#125;template&lt;&gt;inline void IntBubbleSortLoop&lt;0, 0&gt;(int*) &#123; &#125; template&lt;int n&gt;inline void IntBubbleSort(int* data) &#123; // 模板冒泡排序循环展开 IntBubbleSortLoop&lt;n-1, 0&gt;(data); IntBubbleSort&lt;n-1&gt;(data);&#125;template&lt;&gt;inline void IntBubbleSort&lt;1&gt;(int* data) &#123; &#125; 对循环次数固定且比较小的循环语句，对其进行展开并内联可以避免函数调用以及执行循环语句中的分支，从而可以提高性能，对上述代码做如下测试，代码在 VS2013 的 Release 下编译运行：12345678910111213141516171819#include &lt;iostream&gt;#include &lt;omp.h&gt;#include &lt;string.h&gt; // memcpy int main() &#123; double t1, t2, t3; const int num=100000000; int data[4]; int inidata[4]=&#123;3,4,2,1&#125;; t1 = omp_get_wtime(); for(int i=0; i&lt;num; ++i) &#123; memcpy(data, inidata, 4); bubbleSort(data, 4); &#125; t1 = omp_get_wtime()-t1; t2 = omp_get_wtime(); for(int i=0; i&lt;num; ++i) &#123; memcpy(data, inidata, 4); bubbleSort4(data); &#125; t2 = omp_get_wtime()-t2; t3 = omp_get_wtime(); for(int i=0; i&lt;num; ++i) &#123; memcpy(data, inidata, 4); IntBubbleSort&lt;4&gt;(data); &#125; t3 = omp_get_wtime()-t3; std::cout &lt;&lt; t1/t3 &lt;&lt; &apos;\t&apos; &lt;&lt; t2/t3 &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 12.38643 0.926521 上述结果表明，模板元编程实现的循环展开能够达到和手动循环展开相近的性能（90% 以上），并且性能是循环版本的 2 倍多（如果扣除 memcpy 函数占据的部分加速比将更高，根据 Amdahl 定律）。这里可能有人会想，既然循环次数固定，为什么不直接手动循环展开呢，难道就为了使用模板吗？当然不是，有时候循环次数确实是编译期固定值，但对用户并不是固定的，比如要实现数学上向量计算的类，因为可能是 2、3、4 维，所以写成模板，把维度作为 int 型模板参数，这时因为不知道具体是几维的也就不得不用循环，不过因为维度信息在模板实例化时是编译期常量且较小，所以编译器很可能在代码优化时进行循环展开，但我们想让这一切发生的更可控一些。 上面用三个函数模板 IntSwap&lt;&gt;()、 IntBubbleSortLoop&lt;&gt;()、 IntBubbleSort&lt;&gt;() 来实现一个排序功能，不但显得分散（和封装原理不符），还暴露了实现细节，我们可以仿照上一节的代码，将 IntBubbleSortLoop&lt;&gt;()、 IntBubbleSort&lt;&gt;() 嵌入其他模板内部，因为函数不允许嵌套，我们只能用类模板：12345678910111213141516171819202122232425262728293031// 整合成一个类模板实现，看着好，但引入了 代码膨胀template&lt;int n&gt;class IntBubbleSortC &#123; template&lt;int i, int j&gt; static inline void IntSwap(int* data) &#123; // 比较和交换两个相邻元素 if(data[i]&gt;data[j]) std::swap(data[i], data[j]); &#125; template&lt;int i, int j&gt; static inline void IntBubbleSortLoop(int* data) &#123; // 一次冒泡 IntSwap&lt;j, j+1&gt;(data); IntBubbleSortLoop&lt;j&lt;i-1?i:0, j&lt;i-1?(j+1):0&gt;(data); &#125; template&lt;&gt; static inline void IntBubbleSortLoop&lt;0, 0&gt;(int*) &#123; &#125;public: static inline void sort(int* data) &#123; IntBubbleSortLoop&lt;n-1, 0&gt;(data); IntBubbleSortC&lt;n-1&gt;::sort(data); &#125;&#125;;template&lt;&gt;class IntBubbleSortC&lt;0&gt; &#123;public: static inline void sort(int* data) &#123; &#125;&#125;; int main() &#123; int data[4] = &#123;3,4,2,1&#125;; IntBubbleSortC&lt;4&gt;::sort(data); // 如此调用 std::cin.get(); return 0;&#125; 上面代码看似很好，不仅整合了代码，借助类成员的访问控制，还隐藏了实现细节。不过它存在着很大问题，如果实例化 IntBubbleSortC、 IntBubbleSortC、 IntBubbleSortC，将实例化成员函数 IntBubbleSortC::IntSwap&lt;0, 1&gt;()、 IntBubbleSortC::IntSwap&lt;1, 2&gt;()、 IntBubbleSortC::IntSwap&lt;2, 3&gt;()、 IntBubbleSortC::IntSwap&lt;0, 1&gt;()、 IntBubbleSortC::IntSwap&lt;1, 2&gt;()、 IntBubbleSortC::IntSwap&lt;0, 1&gt;()，而在原来的看着分散的代码中 IntSwap&lt;0, 1&gt;() 只有一个。这将导致代码膨胀（code bloat），即生成的可执行文件体积变大（代码膨胀另一含义是源代码增大，见文献[1]第11章）。不过这里使用了内联（inline），如果编译器确实内联展开代码则不会导致代码膨胀（除了循环展开本身会带来的代码膨胀），但因为重复编译原本可以复用的模板实例，会增加编译时间。在上一节的例子中，因为只涉及编译期常量计算，并不涉及函数（函数模板，或类模板的成员函数，函数被编译成具体的机器二进制代码），并不会出现代码膨胀。 为了清晰证明上面的论述，我们去掉所有 inline 并将函数实现放到类外面（类里面实现的成员函数都是内联的，因为函数实现可能被包含多次，见文献[2] 10.2.9，不过现在的编译器优化能力很强，很多时候加不加 inline 并不影响编译器自己对内联的选择…），分别编译分散版本和类模板封装版本的冒泡排序代码编译生成的目标文件（VS2013 下是 .obj 文件）的大小，代码均在 VS2013 Debug 模式下编译（防止编译器优化），比较 main.obj （源文件是 main.cpp）大小。 类模板封装版本代码如下，注意将成员函数在外面定义的写法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;utility&gt; // std::swap // 整合成一个类模板实现，看着好，但引入了 代码膨胀template&lt;int n&gt;class IntBubbleSortC &#123; template&lt;int i, int j&gt; static void IntSwap(int* data); template&lt;int i, int j&gt; static void IntBubbleSortLoop(int* data); template&lt;&gt; static void IntBubbleSortLoop&lt;0, 0&gt;(int*) &#123; &#125;public: static void sort(int* data);&#125;;template&lt;&gt;class IntBubbleSortC&lt;0&gt; &#123;public: static void sort(int* data) &#123; &#125;&#125;; template&lt;int n&gt; template&lt;int i, int j&gt;void IntBubbleSortC&lt;n&gt;::IntSwap(int* data) &#123; if(data[i]&gt;data[j]) std::swap(data[i], data[j]);&#125;template&lt;int n&gt; template&lt;int i, int j&gt;void IntBubbleSortC&lt;n&gt;::IntBubbleSortLoop(int* data) &#123; IntSwap&lt;j, j+1&gt;(data); IntBubbleSortLoop&lt;j&lt;i-1?i:0, j&lt;i-1?(j+1):0&gt;(data);&#125;template&lt;int n&gt;void IntBubbleSortC&lt;n&gt;::sort(int* data) &#123; IntBubbleSortLoop&lt;n-1, 0&gt;(data); IntBubbleSortC&lt;n-1&gt;::sort(data);&#125; int main() &#123; int data[40] = &#123;3,4,2,1&#125;; IntBubbleSortC&lt;2&gt;::sort(data); IntBubbleSortC&lt;3&gt;::sort(data); IntBubbleSortC&lt;4&gt;::sort(data); IntBubbleSortC&lt;5&gt;::sort(data); IntBubbleSortC&lt;6&gt;::sort(data); IntBubbleSortC&lt;7&gt;::sort(data); IntBubbleSortC&lt;8&gt;::sort(data); IntBubbleSortC&lt;9&gt;::sort(data); IntBubbleSortC&lt;10&gt;::sort(data); IntBubbleSortC&lt;11&gt;::sort(data);#if 0 IntBubbleSortC&lt;12&gt;::sort(data); IntBubbleSortC&lt;13&gt;::sort(data); IntBubbleSortC&lt;14&gt;::sort(data); IntBubbleSortC&lt;15&gt;::sort(data); IntBubbleSortC&lt;16&gt;::sort(data); IntBubbleSortC&lt;17&gt;::sort(data); IntBubbleSortC&lt;18&gt;::sort(data); IntBubbleSortC&lt;19&gt;::sort(data); IntBubbleSortC&lt;20&gt;::sort(data); IntBubbleSortC&lt;21&gt;::sort(data); IntBubbleSortC&lt;22&gt;::sort(data); IntBubbleSortC&lt;23&gt;::sort(data); IntBubbleSortC&lt;24&gt;::sort(data); IntBubbleSortC&lt;25&gt;::sort(data); IntBubbleSortC&lt;26&gt;::sort(data); IntBubbleSortC&lt;27&gt;::sort(data); IntBubbleSortC&lt;28&gt;::sort(data); IntBubbleSortC&lt;29&gt;::sort(data); IntBubbleSortC&lt;30&gt;::sort(data); IntBubbleSortC&lt;31&gt;::sort(data);#endif std::cin.get(); return 0;&#125; 分散定义函数模板版本代码如下，为了更具可比性，也将函数放在类里面作为成员函数： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;iostream&gt;#include &lt;utility&gt; // std::swap // static code, 模板元编程版本template&lt;int i, int j&gt;class IntSwap &#123;public: static void swap(int* data);&#125;; template&lt;int i, int j&gt;class IntBubbleSortLoop &#123;public: static void loop(int* data);&#125;;template&lt;&gt;class IntBubbleSortLoop&lt;0, 0&gt; &#123;public: static void loop(int* data) &#123; &#125;&#125;; template&lt;int n&gt;class IntBubbleSort &#123;public: static void sort(int* data);&#125;;template&lt;&gt;class IntBubbleSort&lt;0&gt; &#123;public: static void sort(int* data) &#123; &#125;&#125;; template&lt;int i, int j&gt;void IntSwap&lt;i, j&gt;::swap(int* data) &#123; if(data[i]&gt;data[j]) std::swap(data[i], data[j]);&#125;template&lt;int i, int j&gt;void IntBubbleSortLoop&lt;i, j&gt;::loop(int* data) &#123; IntSwap&lt;j, j+1&gt;::swap(data); IntBubbleSortLoop&lt;j&lt;i-1?i:0, j&lt;i-1?(j+1):0&gt;::loop(data);&#125;template&lt;int n&gt;void IntBubbleSort&lt;n&gt;::sort(int* data) &#123; IntBubbleSortLoop&lt;n-1, 0&gt;::loop(data); IntBubbleSort&lt;n-1&gt;::sort(data);&#125; int main() &#123; int data[40] = &#123;3,4,2,1&#125;; IntBubbleSort&lt;2&gt;::sort(data); IntBubbleSort&lt;3&gt;::sort(data); IntBubbleSort&lt;4&gt;::sort(data); IntBubbleSort&lt;5&gt;::sort(data); IntBubbleSort&lt;6&gt;::sort(data); IntBubbleSort&lt;7&gt;::sort(data); IntBubbleSort&lt;8&gt;::sort(data); IntBubbleSort&lt;9&gt;::sort(data); IntBubbleSort&lt;10&gt;::sort(data); IntBubbleSort&lt;11&gt;::sort(data);#if 0 IntBubbleSort&lt;12&gt;::sort(data); IntBubbleSort&lt;13&gt;::sort(data); IntBubbleSort&lt;14&gt;::sort(data); IntBubbleSort&lt;15&gt;::sort(data); IntBubbleSort&lt;16&gt;::sort(data); IntBubbleSort&lt;17&gt;::sort(data); IntBubbleSort&lt;18&gt;::sort(data); IntBubbleSort&lt;19&gt;::sort(data); IntBubbleSort&lt;20&gt;::sort(data); IntBubbleSort&lt;21&gt;::sort(data); IntBubbleSort&lt;22&gt;::sort(data); IntBubbleSort&lt;23&gt;::sort(data); IntBubbleSort&lt;24&gt;::sort(data); IntBubbleSort&lt;25&gt;::sort(data); IntBubbleSort&lt;26&gt;::sort(data); IntBubbleSort&lt;27&gt;::sort(data); IntBubbleSort&lt;28&gt;::sort(data); IntBubbleSort&lt;29&gt;::sort(data); IntBubbleSort&lt;30&gt;::sort(data); IntBubbleSort&lt;31&gt;::sort(data);#endif std::cin.get(); return 0;&#125; 程序中条件编译都未打开时（#if 0），main.obj 大小分别为 264 KB 和 211 KB，条件编译打开时（#if 1），main.obj 大小分别为 1073 KB 和 620 KB。可以看到，类模板封装版的对象文件不但绝对大小更大，而且增长更快，这和之前分析是一致的。 表达式模板，向量运算文献[12]展示了一个表达式模板（Expression Templates）的例子：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#include &lt;iostream&gt; // std::cout#include &lt;cmath&gt; // std::sqrt() // 表达式类型class DExprLiteral &#123; // 文字量 double a_;public: DExprLiteral(double a) : a_(a) &#123; &#125; double operator()(double x) const &#123; return a_; &#125;&#125;;class DExprIdentity &#123; // 自变量public: double operator()(double x) const &#123; return x; &#125;&#125;;template&lt;class A, class B, class Op&gt; // 双目操作class DBinExprOp &#123; A a_; B b_;public: DBinExprOp(const A&amp; a, const B&amp; b) : a_(a), b_(b) &#123; &#125; double operator()(double x) const &#123; return Op::apply(a_(x), b_(x)); &#125;&#125;;template&lt;class A, class Op&gt; // 单目操作class DUnaryExprOp &#123; A a_;public: DUnaryExprOp(const A&amp; a) : a_(a) &#123; &#125; double operator()(double x) const &#123; return Op::apply(a_(x)); &#125;&#125;;// 表达式template&lt;class A&gt;class DExpr &#123; A a_;public: DExpr() &#123; &#125; DExpr(const A&amp; a) : a_(a) &#123; &#125; double operator()(double x) const &#123; return a_(x); &#125;&#125;; // 运算符，模板参数 A、B 为参与运算的表达式类型// operator /, divisionclass DApDiv &#123; public: static double apply(double a, double b) &#123; return a / b; &#125; &#125;;template&lt;class A, class B&gt; DExpr&lt;DBinExprOp&lt;DExpr&lt;A&gt;, DExpr&lt;B&gt;, DApDiv&gt; &gt;operator/(const DExpr&lt;A&gt;&amp; a, const DExpr&lt;B&gt;&amp; b) &#123; typedef DBinExprOp&lt;DExpr&lt;A&gt;, DExpr&lt;B&gt;, DApDiv&gt; ExprT; return DExpr&lt;ExprT&gt;(ExprT(a, b));&#125;// operator +, additionclass DApAdd &#123; public: static double apply(double a, double b) &#123; return a + b; &#125; &#125;;template&lt;class A, class B&gt; DExpr&lt;DBinExprOp&lt;DExpr&lt;A&gt;, DExpr&lt;B&gt;, DApAdd&gt; &gt;operator+(const DExpr&lt;A&gt;&amp; a, const DExpr&lt;B&gt;&amp; b) &#123; typedef DBinExprOp&lt;DExpr&lt;A&gt;, DExpr&lt;B&gt;, DApAdd&gt; ExprT; return DExpr&lt;ExprT&gt;(ExprT(a, b));&#125;// sqrt(), square rootingclass DApSqrt &#123; public: static double apply(double a) &#123; return std::sqrt(a); &#125; &#125;;template&lt;class A&gt; DExpr&lt;DUnaryExprOp&lt;DExpr&lt;A&gt;, DApSqrt&gt; &gt;sqrt(const DExpr&lt;A&gt;&amp; a) &#123; typedef DUnaryExprOp&lt;DExpr&lt;A&gt;, DApSqrt&gt; ExprT; return DExpr&lt;ExprT&gt;(ExprT(a));&#125;// operator-, negative signclass DApNeg &#123; public: static double apply(double a) &#123; return -a; &#125; &#125;;template&lt;class A&gt; DExpr&lt;DUnaryExprOp&lt;DExpr&lt;A&gt;, DApNeg&gt; &gt;operator-(const DExpr&lt;A&gt;&amp; a) &#123; typedef DUnaryExprOp&lt;DExpr&lt;A&gt;, DApNeg&gt; ExprT; return DExpr&lt;ExprT&gt;(ExprT(a));&#125; // evaluate()template&lt;class Expr&gt;void evaluate(const DExpr&lt;Expr&gt;&amp; expr, double start, double end, double step) &#123; for(double i=start; i&lt;end; i+=step) std::cout &lt;&lt; expr(i) &lt;&lt; &apos; &apos;;&#125; int main() &#123; DExpr&lt;DExprIdentity&gt; x; evaluate( -x / sqrt( DExpr&lt;DExprLiteral&gt;(1.0) + x ) , 0.0, 10.0, 1.0); std::cin.get(); return 0;&#125; 1-0 -0.707107 -1.1547 -1.5 -1.78885 -2.04124 -2.26779 -2.47487 -2.66667 -2.84605 代码有点长（我已经尽量压缩行数），请先看最下面的 main() 函数，表达式模板允许我们以 “-x / sqrt( 1.0 + x )” 这种类似数学表达式的方式传参数，在 evaluate() 内部，将 0-10 的数依次赋给自变量 x 对表达式进行求值，这是通过在 template&lt;&gt; DExpr 类模板内部重载 operator() 实现的。我们来看看这一切是如何发生的。 在 main() 中调用 evaluate() 时，编译器根据全局重载的加号、sqrt、除号、负号推断“-x / sqrt( 1.0 + x )” 的类型是 Dexpr&lt;DBinExprOp&lt;Dexpr&lt;DUnaryExprOp&lt;Dexpr, DApNeg&gt;&gt;, Dexpr&lt;DUnaryExprOp&lt;Dexpr&lt;DBinExprOp&lt;Dexpr, Dexpr, DApAdd&gt;&gt;, DApSqrt&gt;&gt;, DApDiv&gt;&gt;（即将每个表达式编码到一种类型，设这个类型为 ultimateExprType），并用此类型实例化函数模板 evaluate()，类型的推导见下图。在 evaluate() 中，对表达式进行求值 expr(i)，调用 ultimateExprType 的 operator()，这引起一系列的 operator() 和 Op::apply() 的调用，最终遇到基础类型 “表达式类型” DExprLiteral 和 DExprIdentity，这个过程见下图。总结就是，请看下图，从下到上类型推断，从上到下 operator() 表达式求值。 表达式模板，Expression Templates 上面代码函数实现写在类的内部，即内联，如果编译器对内联支持的好的话，上面代码几乎等价于如下代码：12345678910111213#include &lt;iostream&gt; // std::cout#include &lt;cmath&gt; // std::sqrt()void evaluate(double start, double end, double step) &#123; double _temp = 1.0; for(double i=start; i&lt;end; i+=step) std::cout &lt;&lt; -i / std::sqrt(_temp + i) &lt;&lt; &apos; &apos;;&#125;int main() &#123; evaluate(0.0, 10.0, 1.0); std::cin.get(); return 0;&#125; 1-0 -0.707107 -1.1547 -1.5 -1.78885 -2.04124 -2.26779 -2.47487 -2.66667 -2.84605 和表达式模板类似的技术还可以用到向量计算中，以避免产生临时向量变量，见文献[4] Expression templates 和文献[12]的后面。传统向量计算如下：123456789class DoubleVec; // DoubleVec 重载了 + - * / 等向量元素之间的计算DoubleVec y(1000), a(1000), b(1000), c(1000), d(1000); // 向量长度 1000// 向量计算y = (a + b) / (c - d);// 等价于DoubleVec __t1 = a + b;DoubleVec __t2 = c - d;DoubleVec __t3 = __t1 / __t2;y = __t3; 模板代码实现向量计算如下：12345678910111213template&lt;class A&gt; DVExpr;class DVec&#123; // ... template&lt;class A&gt; DVec&amp; operator=(const DVExpr&lt;A&gt;&amp;); // 由 = 引起向量逐个元素的表达式值计算并赋值&#125;;DVec y(1000), a(1000), b(1000), c(1000), d(1000); // 向量长度 1000// 向量计算y = (a + b) / (c - d);// 等价于for(int i=0; i&lt;1000; ++i) &#123; y[i] = (a[i] + b[i]) / (c[i] + d[i]);&#125; 不过值得一提的是，传统代码可以用 C++11 的右值引用提升性能，C++11 新特性我们以后再详细讨论。 我们这里看下文献[4] Expression templates 实现的版本，它用到了编译期多态，编译期多态示意代码如下（关于这种代码形式有个名字叫 curiously recurring template pattern， CRTP，见文献[4]）：12345678910111213141516171819// 模板基类，定义接口，具体实现由模板参数，即子类实现template &lt;typename D&gt;class base &#123;public: void f1() &#123; static_cast&lt;E&amp;&gt;(*this).f1(); &#125; // 直接调用子类实现 int f2() const &#123; static_cast&lt;const E&amp;&gt;(*this).f1(); &#125;&#125;;// 子类class dirived1 : public base&lt;dirived1&gt; &#123;public: void f1() &#123; /* ... */ &#125; int f2() const &#123; /* ... */ &#125;&#125;;template&lt;typename T&gt;class dirived2 : public base&lt;dirived2&lt;T&gt;&gt; &#123;public: void f1() &#123; /* ... */ &#125; int f2() const &#123; /* ... */ &#125;&#125;; 简化后（向量长度固定为1000，元素类型为 double）的向量计算代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt; // std::cout // A CRTP base class for Vecs with a size and indexing:template &lt;typename E&gt;class VecExpr &#123;public: double operator[](int i) const &#123; return static_cast&lt;E const&amp;&gt;(*this)[i]; &#125; operator E const&amp;() const &#123; return static_cast&lt;const E&amp;&gt;(*this); &#125; // 向下类型转换&#125;;// The actual Vec class:class Vec : public VecExpr&lt;Vec&gt; &#123; double _data[1000];public: double&amp; operator[](int i) &#123; return _data[i]; &#125; double operator[](int i) const &#123; return _data[i]; &#125; template &lt;typename E&gt; Vec const&amp; operator=(VecExpr&lt;E&gt; const&amp; vec) &#123; E const&amp; v = vec; for (int i = 0; i&lt;1000; ++i) _data[i] = v[i]; return *this; &#125; // Constructors Vec() &#123; &#125; Vec(double v) &#123; for(int i=0; i&lt;1000; ++i) _data[i] = v; &#125;&#125;; template &lt;typename E1, typename E2&gt;class VecDifference : public VecExpr&lt;VecDifference&lt;E1, E2&gt; &gt; &#123; E1 const&amp; _u; E2 const&amp; _v;public: VecDifference(VecExpr&lt;E1&gt; const&amp; u, VecExpr&lt;E2&gt; const&amp; v) : _u(u), _v(v) &#123; &#125; double operator[](int i) const &#123; return _u[i] - _v[i]; &#125;&#125;;template &lt;typename E&gt;class VecScaled : public VecExpr&lt;VecScaled&lt;E&gt; &gt; &#123; double _alpha; E const&amp; _v;public: VecScaled(double alpha, VecExpr&lt;E&gt; const&amp; v) : _alpha(alpha), _v(v) &#123; &#125; double operator[](int i) const &#123; return _alpha * _v[i]; &#125;&#125;; // Now we can overload operators:template &lt;typename E1, typename E2&gt; VecDifference&lt;E1, E2&gt; constoperator-(VecExpr&lt;E1&gt; const&amp; u, VecExpr&lt;E2&gt; const&amp; v) &#123; return VecDifference&lt;E1, E2&gt;(u, v);&#125;template &lt;typename E&gt; VecScaled&lt;E&gt; constoperator*(double alpha, VecExpr&lt;E&gt; const&amp; v) &#123; return VecScaled&lt;E&gt;(alpha, v);&#125; int main() &#123; Vec u(3), v(1); double alpha=9; Vec y; y = alpha*(u - v); std::cout &lt;&lt; y[999] &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 118 这里可以看到基类的作用：提供统一的接口，让 operator- 和 operator* 可以写成统一的模板形式。 特性，策略，标签利用迭代器，我们可以实现很多通用算法，迭代器在容器与算法之间搭建了一座桥梁。求和函数模板如下：12345678910111213141516#include &lt;iostream&gt; // std::cout#include &lt;vector&gt; template&lt;typename iter&gt;typename iter::value_type mysum(iter begin, iter end) &#123; typename iter::value_type sum(0); for(iter i=begin; i!=end; ++i) sum += *i; return sum;&#125; int main() &#123; std::vector&lt;int&gt; v; for(int i = 0; i&lt;100; ++i) v.push_back(i); std::cout &lt;&lt; mysum(v.begin(), v.end()) &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 14950 我们想让 mysum() 对指针参数也能工作，毕竟迭代器就是模拟指针，但指针没有嵌套类型 value_type，可以定义 mysum() 对指针类型的特例，但更好的办法是在函数参数和 value_type 之间多加一层 — 特性（traits）（参考了文献[1]第72页，特性详见文献[1] 12.1）：12345678910111213141516171819202122// 特性，traitstemplate&lt;typename iter&gt;class mytraits&#123;public: typedef typename iter::value_type value_type;&#125;;template&lt;typename T&gt;class mytraits&lt;T*&gt;&#123;public: typedef T value_type;&#125;; template&lt;typename iter&gt;typename mytraits&lt;iter&gt;::value_type mysum(iter begin, iter end) &#123; typename mytraits&lt;iter&gt;::value_type sum(0); for(iter i=begin; i!=end; ++i) sum += *i; return sum;&#125; int main() &#123; int v[4] = &#123;1,2,3,4&#125;; std::cout &lt;&lt; mysum(v, v+4) &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 110 其实，C++ 标准定义了类似的 traits：std::iterator_trait（另一个经典例子是 std::numeric_limits） 。特性对类型的信息（如 value_type、 reference）进行包装，使得上层代码可以以统一的接口访问这些信息。C++ 模板元编程会涉及大量的类型计算，很多时候要提取类型的信息（typedef、 常量值等），如果这些类型的信息的访问方式不一致（如上面的迭代器和指针），我们将不得不定义特例，这会导致大量重复代码的出现（另一种代码膨胀），而通过加一层特性可以很好的解决这一问题。另外，特性不仅可以对类型的信息进行包装，还可以提供更多信息，当然，因为加了一层，也带来复杂性。特性是一种提供元信息的手段。 策略（policy）一般是一个类模板，典型的策略是 STL 容器（如 std::vector&lt;&gt;，完整声明是template&lt;class T, class Alloc=allocator&gt; class vector;）的分配器（这个参数有默认参数，即默认存储策略），策略类将模板的经常变化的那一部分子功能块集中起来作为模板参数，这样模板便可以更为通用，这和特性的思想是类似的（详见文献[1] 12.3）。 标签（tag）一般是一个空类，其作用是作为一个独一无二的类型名字用于标记一些东西，典型的例子是 STL 迭代器的五种类型的名字（input_iterator_tag, output_iterator_tag, forward_iterator_tag, bidirectional_iterator_tag, random_access_iterator_tag），std::vector::iterator::iterator_category 就是 random_access_iterator_tag，可以用第1节判断类型是否等价的模板检测这一点：12345678910111213#include &lt;iostream&gt;#include &lt;vector&gt; template&lt;typename T1, typename T2&gt; // 通例，返回 falseclass theSameType &#123; public: enum &#123; ret = false &#125;; &#125;;template&lt;typename T&gt; // 特例，两类型相同时返回 trueclass theSameType&lt;T, T&gt; &#123; public: enum &#123; ret = true &#125;; &#125;; int main()&#123; std::cout &lt;&lt; theSameType&lt; std::vector&lt;int&gt;::iterator::iterator_category, std::random_access_iterator_tag &gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 11 有了这样的判断，还可以根据判断结果做更复杂的元编程逻辑（如一个算法以迭代器为参数，根据迭代器标签进行特例化以对某种迭代器特殊处理）。标签还可以用来分辨函数重载，第5节中就用到了这样的标签（recursion）（标签详见文献[1] 12.1）。 更多类型计算在第1节我们讲类型等价的时候，已经见到了一个可以判断两个类型是否等价的模板，这一节我们给出更多例子，下面是判断一个类型是否可以隐式转换到另一个类型的模板（参考了文献[6] Static interface checking）：1234567891011121314151617181920#include &lt;iostream&gt; // std::cout // whether T could be converted to Utemplate&lt;class T, class U&gt;class ConversionTo &#123; typedef char Type1[1]; // 两种 sizeof 不同的类型 typedef char Type2[2]; static Type1&amp; Test( U ); // 较下面的函数，因为参数取值范围小，优先匹配 static Type2&amp; Test(...); // 变长参数函数，可以匹配任何数量任何类型参数 static T MakeT(); // 返回类型 T，用这个函数而不用 T() 因为 T 可能没有默认构造函数public: enum &#123; ret = sizeof(Test(MakeT()))==sizeof(Type1) &#125;; // 可以转换时调用返回 Type1 的 Test()&#125;; int main() &#123; std::cout &lt;&lt; ConversionTo&lt;int, double&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; ConversionTo&lt;float, int*&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; ConversionTo&lt;const int&amp;, int&amp;&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 123100 下面这个例子检查某个类型是否含有某个嵌套类型定义（参考了文献[4] Substitution failure is not an erro (SFINAE)），这个例子是个内省（反射的一种）：123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;vector&gt; // thanks to Substitution failure is not an erro (SFINAE)template&lt;typename T&gt;struct has_typedef_value_type &#123; typedef char Type1[1]; typedef char Type2[2]; template&lt;typename C&gt; static Type1&amp; test(typename C::value_type*); template&lt;typename&gt; static Type2&amp; test(...);public: static const bool ret = sizeof(test&lt;T&gt;(0)) == sizeof(Type1); // 0 == NULL&#125;; struct foo &#123; typedef float lalala; &#125;; int main() &#123; std::cout &lt;&lt; has_typedef_value_type&lt;std::vector&lt;int&gt;&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; has_typedef_value_type&lt;foo&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 1210 这个例子是有缺陷的，因为不存在引用的指针，所以不用用来检测引用类型定义。可以看到，因为只涉及类型推断，都是编译期的计算，不涉及任何可执行代码，所以类的成员函数根本不需要具体实现。 元容器文献[1]第 13 章讲了元容器，所谓元容器，就是类似于 std::vector&lt;&gt; 那样的容器，不过它存储的是元数据 — 类型，有了元容器，我们就可以判断某个类型是否属于某个元容器之类的操作。 在讲元容器之前，我们先来看看伪变长参数模板（文献[1] 12.4），一个可以存储小于某个数（例子中为 4 个）的任意个数，任意类型数据的元组（tuple）的例子如下（参考了文献[1] 第 225~227 页）：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include &lt;iostream&gt; class null_type &#123;&#125;; // 标签类，标记参数列表末尾template&lt;typename T0, typename T1, typename T2, typename T3&gt;class type_shift_node &#123;public: typedef T0 data_type; typedef type_shift_node&lt;T1, T2, T3, null_type&gt; next_type; // 参数移位了 static const int num = next_type::num + 1; // 非 null_type 模板参数个数 data_type data; // 本节点数据 next_type next; // 后续所有节点数据 type_shift_node() :data(), next() &#123; &#125; // 构造函数 type_shift_node(T0 const&amp; d0, T1 const&amp; d1, T2 const&amp; d2, T3 const&amp; d3) :data(d0), next(d1, d2, d3, null_type()) &#123; &#125; // next 参数也移位了&#125;;template&lt;typename T0&gt; // 特例，递归终止class type_shift_node&lt;T0, null_type, null_type, null_type&gt; &#123;public: typedef T0 data_type; static const int num = 1; data_type data; // 本节点数据 type_shift_node() :data(), next() &#123; &#125; // 构造函数 type_shift_node(T0 const&amp; d0, null_type, null_type, null_type) : data(d0) &#123; &#125;&#125;;// 元组类模板，默认参数 + 嵌套递归template&lt;typename T0, typename T1=null_type, typename T2=null_type, typename T3=null_type&gt;class my_tuple &#123;public: typedef type_shift_node&lt;T0, T1, T2, T3&gt; tuple_type; static const int num = tuple_type::num; tuple_type t; my_tuple(T0 const&amp; d0=T0(),T1 const&amp; d1=T1(),T2 const&amp; d2=T2(),T3 const&amp; d3=T3()) : t(d0, d1, d2, d3) &#123; &#125; // 构造函数，默认参数&#125;; // 为方便访问元组数据，定义 get&lt;unsigned&gt;(tuple) 函数模板template&lt;unsigned i, typename T0, typename T1, typename T2, typename T3&gt;class type_shift_node_traits &#123;public: typedef typename type_shift_node_traits&lt;i-1,T0,T1,T2,T3&gt;::node_type::next_type node_type; typedef typename node_type::data_type data_type; static node_type&amp; get_node(type_shift_node&lt;T0,T1,T2,T3&gt;&amp; node) &#123; return type_shift_node_traits&lt;i-1,T0,T1,T2,T3&gt;::get_node(node).next; &#125;&#125;;template&lt;typename T0, typename T1, typename T2, typename T3&gt;class type_shift_node_traits&lt;0, T0, T1, T2, T3&gt; &#123;public: typedef typename type_shift_node&lt;T0,T1,T2,T3&gt; node_type; typedef typename node_type::data_type data_type; static node_type&amp; get_node(type_shift_node&lt;T0,T1,T2,T3&gt;&amp; node) &#123; return node; &#125;&#125;;template&lt;unsigned i, typename T0, typename T1, typename T2, typename T3&gt;typename type_shift_node_traits&lt;i,T0,T1,T2,T3&gt;::data_typeget(my_tuple&lt;T0,T1,T2,T3&gt;&amp; tup) &#123; return type_shift_node_traits&lt;i,T0,T1,T2,T3&gt;::get_node(tup.t).data;&#125; int main()&#123; typedef my_tuple&lt;int, char, float&gt; tuple3; tuple3 t3(10, &apos;m&apos;, 1.2f); std::cout &lt;&lt; t3.t.data &lt;&lt; &apos; &apos; &lt;&lt; t3.t.next.data &lt;&lt; &apos; &apos; &lt;&lt; t3.t.next.next.data &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; tuple3::num &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; get&lt;2&gt;(t3) &lt;&lt; &apos;\n&apos;; // 从 0 开始，不要出现 3，否则将出现不可理解的编译错误 std::cin.get(); return 0;&#125; 12310 m 1.231.2 C++11 引入了变长模板参数，其背后的原理也是模板递归（文献[1]第 230 页）。 利用和上面例子类似的模板参数移位递归的原理，我们可以构造一个存储“类型”的元组，即元容器，其代码如下（和文献[1]第 237 页的例子不同）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;iostream&gt; // 元容器template&lt;typename T0=void, typename T1=void, typename T2=void, typename T3=void&gt;class meta_container &#123;public: typedef T0 type; typedef meta_container&lt;T1, T2, T3, void&gt; next_node; // 参数移位了 static const int size = next_node::size + 1; // 非 null_type 模板参数个数&#125;;template&lt;&gt; // 特例，递归终止class meta_container&lt;void, void, void, void&gt; &#123;public: typedef void type; static const int size = 0;&#125;; // 访问元容器中的数据template&lt;typename C, unsigned i&gt;class get &#123;public: static_assert(i&lt;C::size, &quot;get&lt;C,i&gt;: index exceed num&quot;); // C++11 引入静态断言 typedef typename get&lt;C,i-1&gt;::c_type::next_node c_type; typedef typename c_type::type ret_type;&#125;;template&lt;typename C&gt;class get&lt;C, 0&gt; &#123;public: static_assert(0&lt;C::size, &quot;get&lt;C,i&gt;: index exceed num&quot;); // C++11 引入静态断言 typedef C c_type; typedef typename c_type::type ret_type;&#125;; // 在元容器中查找某个类型，找到返回索引，找不到返回 -1template&lt;typename T1, typename T2&gt; class same_type &#123; public: enum &#123; ret = false &#125;; &#125;;template&lt;typename T&gt; class same_type&lt;T, T&gt; &#123; public: enum &#123; ret = true &#125;; &#125;; template&lt;bool c, typename Then, typename Else&gt; class IF_ &#123; &#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;true, Then, Else&gt; &#123; public: typedef Then reType; &#125;;template&lt;typename Then, typename Else&gt;class IF_&lt;false, Then, Else&gt; &#123; public: typedef Else reType; &#125;; template&lt;typename C, typename T&gt;class find &#123; template&lt;int i&gt; class number &#123; public: static const int ret = i; &#125;; template&lt;typename C, typename T, int i&gt; class find_i &#123; public: static const int ret = IF_&lt; same_type&lt;get&lt;C,i&gt;::ret_type, T&gt;::ret, number&lt;i&gt;, find_i&lt;C,T,i-1&gt; &gt;::reType::ret; &#125;; template&lt;typename C, typename T&gt; class find_i&lt;C, T, -1&gt; &#123; public: static const int ret = -1; &#125;;public: static const int ret = find_i&lt;C, T, C::size-1&gt;::ret;&#125;; int main()&#123; typedef meta_container&lt;int, int&amp;, const int&gt; mc; int a = 9999; get&lt;mc, 1&gt;::ret_type aref = a; std::cout &lt;&lt; mc::size &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; aref &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; find&lt;mc, const int&gt;::ret &lt;&lt; &apos;\n&apos;; std::cout &lt;&lt; find&lt;mc, float&gt;::ret &lt;&lt; &apos;\n&apos;; std::cin.get(); return 0;&#125; 1234399992-1 上面例子已经实现了存储类型的元容器，和元容器上的查找算法，但还有一个小问题，就是它不能处理模板，编译器对模板的操纵能力远不如对类型的操纵能力强（提示：类模板实例是类型），我们可以一种间接方式实现存储“模板元素”，即用模板的一个代表实例（如全用 int 为参数的实例）来代表这个模板，这样对任意模板实例，只需判断其模板的代表实例是否在容器中即可，这需要进行类型过滤：对任意模板的实例将其替换为指定模板参数的代表实例，类型过滤实例代码如下（参考了文献[1]第 241 页）：1234567891011121314151617181920212223/ 类型过滤，meta_filter 使用时只用一个参数，设置四个模板参数是因为，模板通例的参数列表// 必须能够包含特例参数列表，后面三个参数设置默认值为 void 或标签模板template&lt;typename T&gt; class dummy_template_1 &#123;&#125;;template&lt;typename T0, typename T1&gt; class dummy_template_2 &#123;&#125;;template&lt;typename T0, typename T1 = void, template&lt;typename&gt; class tmp_1 = dummy_template_1, template&lt;typename, typename&gt; class tmp_2 = dummy_template_2&gt;class meta_filter &#123; // 通例，不改变类型public: typedef T0 ret_type;&#125;; // 匹配任何带有一个类型参数模板的实例，将模板实例替换为代表实例template&lt;template&lt;typename&gt; class tmp_1, typename T&gt;class meta_filter&lt;tmp_1&lt;T&gt;, void, dummy_template_1, dummy_template_2&gt; &#123;public: typedef tmp_1&lt;int&gt; ret_type;&#125;; // 匹配任何带有两个类型参数模板的实例，将模板实例替换为代表实例template&lt;template&lt;typename, typename&gt; class tmp_2, typename T0, typename T1&gt;class meta_filter&lt;tmp_2&lt;T0, T1&gt;, void, dummy_template_1, dummy_template_2&gt; &#123;public: typedef tmp_2&lt;int, int&gt; ret_type;&#125;; 现在，只需将上面元容器和元容器查找函数修改为：对模板实例将其换为代表实例，即修改 meta_container&lt;&gt; 通例中“typedef T0 type;”语句为“typedef typename meta_filter::ret_type type;”，修改 find&lt;&gt; 的最后一行中“T”为“typename meta_filter::ret_type”。修改后，下面代码的执行结果是： 123456template&lt;typename, typename&gt; class my_tmp_2; // 自动将 my_tmp_2&lt;float, int&gt; 过滤为 my_tmp_2&lt;int, int&gt;typedef meta_container&lt;int, float, my_tmp_2&lt;float, int&gt;&gt; mc2;// 自动将 my_tmp_2&lt;char, double&gt; 过滤为 my_tmp_2&lt;int, int&gt;std::cout &lt;&lt; find&lt;mc2, my_tmp_2&lt;char, double&gt;&gt;::ret &lt;&lt; &apos;\n&apos;; // 输出 2 12 总结博文比较长，总结一下所涉及的东西： C++ 模板包括函数模板和类模板，模板参数形式有：类型、模板型、非类型（整型、指针）；模板的特例化分完全特例化和部分特例化，实例将匹配参数集合最小的特例；用实例参数替换模板形式参数称为实例化，实例化的结果是产生具体类型（类模板）或函数（函数模板），同一模板实参完全等价将产生等价的实例类型或函数；模板一般在头文件中定义，可能被包含多次，编译和链接时会消除等价模板实例；template、typename、this 关键字用来消除歧义，避免编译错误或产生不符预期的结果；C++11 对模板引入了新特性：“&gt;&gt;”、函数模板也可以有默认参数、变长模板参数、外部模板实例（extern），并弃用 export template；C++ 模板是图灵完备的，模板编程是函数编程风格，特点是：没有可变的存储、递归，以“&lt;&gt;”为输入，typedef 或静态常量为输出；编译期数值计算虽然实际意义不大，但可以很好证明 C++ 模板的能力，可以用模板实现类似普通程序中的 if 和 while 语句；一个实际应用是循环展开，虽然编译器可以自动循环展开，但我们可以让这一切更可控；C++ 模板编程的两个问题是：难调试，会产生冗长且难以阅读的编译错误信息、代码膨胀（源代码膨胀、二进制对象文件膨胀），改进的方法是：增加一些检查代码，让编译器及时报错，使用特性、策略等让模板更通用，可能的话合并一些模板实例（如将代码提出去做成单独模板）；表达式模板和向量计算是另一个可加速程序的例子，它们将计算表达式编码到类型，这是通过模板嵌套参数实现的；特性，策略，标签是模板编程常用技巧，它们可以是模板变得更加通用；模板甚至可以获得类型的内部信息（是否有某个 typedef），这是反射中的内省，C++ 在语言层面对反射支持很少（typeid），这不利于模板元编程；可以用递归实现伪变长参数模板，C++11 变长参数模板背后的原理也是模板递归；元容器存储元信息（如类型）、类型过滤过滤某些类型，它们是元编程的高级特性。 进一步学习C++ 确实比较复杂，这可能是因为，虽然 C++ 语言层次比较低，但它却同时可以实现很多高级特性。进一步学习 C++ 模板元编程的途径很多： C++ 标准库的 STL 可能是最好的学习案例，尤其是其容器、迭代器、通用算法、函数类模板等部件，实现机制很巧妙；另外一个 C++ 库也值得一看，那就是 Boost 库，Boost 的元编程库参考文献[16]；很推荐《深入实践C++模板编程》这本书，这篇博文大量参考了这本书；wikibooks.org 上有个介绍 C++ 各种编程技巧书：More C++ Idioms，文献[15]；文献[17]列了 C++ 模板的参考书，共四本；好多东西，书上讲的比较浅显，而且不全面，有时候直接看 C++ 标准（最新 C++11）可能更为高效，C++ 标准并不是想象中那样难读，C++ 标准委员会网站的 Papers 也很值得看，文献[3]。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode922. Sort Array By Parity II]]></title>
    <url>%2F2019%2F05%2F27%2FLeetcode922%2F</url>
    <content type="text"><![CDATA[Given an array A of non-negative integers, half of the integers in A are odd, and half of the integers are even. Sort the array so that whenever A[i] is odd, i is odd; and whenever A[i] is even, i is even. You may return any answer array that satisfies this condition. Example 1:12Input: [4,2,5,7]Output: [4,5,2,7] Explanation: [4,7,2,5], [2,5,4,7], [2,7,4,5] would also have been accepted. Note: 2 &lt;= A.length &lt;= 20000A.length % 2 == 00 &lt;= A[i] &lt;= 1000 首先，将所有偶数元素放在正确的位置就足够了，因为所有奇数元素也都在正确的位置。 所以我们只关注A [0]，A [2]，A [4]，…… 理想情况下，我们希望有一些分区，左边的所有内容都已经正确，右边的所有内容都是未定的。实际上，如果我们把它分成两个切片，即偶数= A [0]，A [2]，A [4]，……和奇数= A [1]，A [3]，A [5]，这个想法是有效的， ….我们的不变量将是偶数切片中的所有小于i的位置都是正确的，并且奇数切片中小于j的所有位置都是正确的。 对于每个偶数，让我们使A[i]也为偶数。 为此，我们将从奇数切片中提取一个元素。 我们将j传递到奇数切片，直到找到偶数元素，然后交换。 我们的不变量得以维持，因此算法是正确的。 就是说对每一个偶数位置的奇数，在奇数位置找一个偶数，然后交换。 12345678910111213141516class Solution &#123;public: vector&lt;int&gt; sortArrayByParityII(vector&lt;int&gt;&amp; A) &#123; int j=1; for(int i=0;i&lt;A.size();i+=2)&#123; if(A[i]%2==1)&#123; while(A[j]%2==1) j+=2; int temp=A[i]; A[i]=A[j]; A[j]=temp; &#125; &#125; return A; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode509. Fibonacci Number]]></title>
    <url>%2F2019%2F05%2F27%2FLeetcode509%2F</url>
    <content type="text"><![CDATA[The Fibonacci numbers, commonly denoted F(n) form a sequence, called the Fibonacci sequence, such that each number is the sum of the two preceding ones, starting from 0 and 1. That is, F(0) = 0, F(1) = 1F(N) = F(N - 1) + F(N - 2), for N &gt; 1.Given N, calculate F(N). Example 1: Input: 2Output: 1Explanation: F(2) = F(1) + F(0) = 1 + 0 = 1.Example 2: Input: 3Output: 2Explanation: F(3) = F(2) + F(1) = 1 + 1 = 2.Example 3: Input: 4Output: 3Explanation: F(4) = F(3) + F(2) = 2 + 1 = 3. Note: 0 ≤ N ≤ 30. 斐波那契，不解释。12345678910class Solution &#123;public: int fib(int N) &#123; if(N==0) return 0; if(N==1) return 1; return fib(N-1)+fib(N-2); &#125;&#125;; 另外的解法：Solution 2 - 动态规划使用数组存储以前计算的斐波纳契值。Time Complexity - O(N)Space Complexity - O(N)12345678910int fib(int N) &#123; if(N &lt; 2) return N; int memo[N+1]; memo[0] = 0; memo[1] = 1; for(int i=2; i&lt;=N; i++) memo[i] = memo[i-1] + memo[i-2]; return memo[N];&#125; Solution 3使用Imperative方法，我们通过循环并通过在两个变量中仅存储两个先前的斐波那契值来优化空间。Time Complexity - O(N)Space Complexity - O(1)123456789101112int fib(int N) &#123; if(N &lt; 2) return N; int a = 0, b = 1, c = 0; for(int i = 1; i &lt; N; i++) &#123; c = a + b; a = b; b = c; &#125; return c;&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1051. Height Checker]]></title>
    <url>%2F2019%2F05%2F27%2FLeetcode1051%2F</url>
    <content type="text"><![CDATA[Students are asked to stand in non-decreasing order of heights for an annual photo. Return the minimum number of students not standing in the right positions. (This is the number of students that must move in order for all students to be standing in non-decreasing order of height.) Example 1:12Input: [1,1,4,2,1,3]Output: 3 Explanation:Students with heights 4, 3 and the last 1 are not standing in the right positions. Note: 1 &lt;= heights.length &lt;= 1001 &lt;= heights[i] &lt;= 100 看上去比较简单的题，找到没有按照顺序排列的数，但是有一个样例过不去， 所以copy了别人的代码。123456789101112131415161718class Solution &#123;public: /*int heightChecker(vector&lt;int&gt;&amp; heights) &#123; int res=0; for(int i=1;i&lt;heights.size()-1;i++)&#123; if(!(heights[i]&gt;=heights[i-1] &amp;&amp; heights[i]&lt;=heights[i+1])) res++; &#125; return res; &#125;*/ int heightChecker(vector&lt;int&gt;&amp; h, int res = 0) &#123; vector&lt;int&gt; s = h; sort(begin(s), end(s)); for (auto i = 0; i &lt; h.size(); ++i) res += h[i] != s[i]; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Merkle Tree学习]]></title>
    <url>%2F2019%2F05%2F25%2FMerkle_Tree%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Merkle Tree概念 Merkle Tree，通常也被称作Hash Tree，顾名思义，就是存储hash值的一棵树。Merkle树的叶子是数据块(例如，文件或者文件的集合)的hash值。非叶节点是其对应子节点串联字符串的hash。[1] HashHash是一个把任意长度的数据映射成固定长度数据的函数[2]。例如，对于数据完整性校验，最简单的方法是对整个数据做Hash运算得到固定长度的Hash值，然后把得到的Hash值公布在网上，这样用户下载到数据之后，对数据再次进行Hash运算，比较运算结果和网上公布的Hash值进行比较，如果两个Hash值相等，说明下载的数据没有损坏。可以这样做是因为输入数据的稍微改变就会引起Hash运算结果的面目全非，而且根据Hash值反推原始输入数据的特征是困难的。 如果从一个稳定的服务器进行下载，采用单一Hash是可取的。但如果数据源不稳定，一旦数据损坏，就需要重新下载，这种下载的效率是很低的。 Hash List在点对点网络中作数据传输的时候，会同时从多个机器上下载数据，而且很多机器可以认为是不稳定或者不可信的。为了校验数据的完整性，更好的办法是把大的文件分割成小的数据块（例如，把分割成2K为单位的数据块）。这样的好处是，如果小块数据在传输过程中损坏了，那么只要重新下载这一快数据就行了，不用重新下载整个文件。 怎么确定小的数据块没有损坏哪？只需要为每个数据块做Hash。BT下载的时候，在下载到真正数据之前，我们会先下载一个Hash列表。那么问题又来了，怎么确定这个Hash列表本事是正确的哪？答案是把每个小块数据的Hash值拼到一起，然后对这个长字符串在作一次Hash运算，这样就得到Hash列表的根Hash(Top Hash or Root Hash)。下载数据的时候，首先从可信的数据源得到正确的根Hash，就可以用它来校验Hash列表了，然后通过校验后的Hash列表校验数据块。 Merkle TreeMerkle Tree可以看做Hash List的泛化（Hash List可以看作一种特殊的Merkle Tree，即树高为2的多叉Merkle Tree）。 在最底层，和哈希列表一样，我们把数据分成小的数据块，有相应地哈希和它对应。但是往上走，并不是直接去运算根哈希，而是把相邻的两个哈希合并成一个字符串，然后运算这个字符串的哈希，这样每两个哈希就结婚生子，得到了一个”子哈希“。如果最底层的哈希总数是单数，那到最后必然出现一个单身哈希，这种情况就直接对它进行哈希运算，所以也能得到它的子哈希。于是往上推，依然是一样的方式，可以得到数目更少的新一级哈希，最终必然形成一棵倒挂的树，到了树根的这个位置，这一代就剩下一个根哈希了，我们把它叫做 Merkle Root[3]。 在p2p网络下载网络之前，先从可信的源获得文件的Merkle Tree树根。一旦获得了树根，就可以从其他从不可信的源获取Merkle tree。通过可信的树根来检查接受到的Merkle Tree。如果Merkle Tree是损坏的或者虚假的，就从其他源获得另一个Merkle Tree，直到获得一个与可信树根匹配的Merkle Tree。 Merkle Tree和Hash List的主要区别是，可以直接下载并立即验证Merkle Tree的一个分支。因为可以将文件切分成小的数据块，这样如果有一块数据损坏，仅仅重新下载这个数据块就行了。如果文件非常大，那么Merkle tree和Hash list都很到，但是Merkle tree可以一次下载一个分支，然后立即验证这个分支，如果分支验证通过，就可以下载数据了。而Hash list只有下载整个hash list才能验证。 Merkle Tree的特点MT是一种树，大多数是二叉树，也可以多叉树，无论是几叉树，它都具有树结构的所有特点；Merkle Tree的叶子节点的value是数据集合的单元数据或者单元数据HASH。非叶子节点的value是根据它下面所有的叶子节点值，然后按照Hash算法计算而得出的。[4][5] 通常，加密的hash方法像SHA-2和MD5用来做hash。但如果仅仅防止数据不是蓄意的损坏或篡改，可以改用一些安全性低但效率高的校验和算法，如CRC。 Second Preimage Attack: Merkle tree的树根并不表示树的深度，这可能会导致second-preimage attack，即攻击者创建一个具有相同Merkle树根的虚假文档。一个简单的解决方法在Certificate Transparency中定义：当计算叶节点的hash时，在hash数据前加0x00。当计算内部节点是，在前面加0x01。另外一些实现限制hash tree的根，通过在hash值前面加深度前缀。因此，前缀每一步会减少，只有当到达叶子时前缀依然为正，提取的hash链才被定义为有效。 Merkle Tree的操作创建Merckle Tree加入最底层有9个数据块。 step1：（红色线）对数据块做hash运算，Node0i = hash(Data0i), i=1,2,…,9 step2: （橙色线）相邻两个hash块串联，然后做hash运算，Node1((i+1)/2) = hash(Node0i+Node0(i+1)), i=1,3,5,7;对于i=9, Node1((i+1)/2) = hash(Node0i) step3: （黄色线）重复step2 step4：（绿色线）重复step2 step5：（蓝色线）重复step2，生成Merkle Tree Root 易得，创建Merkle Tree是O(n)复杂度(这里指O(n)次hash运算)，n是数据块的大小。得到Merkle Tree的树高是log(n)+1。 检索数据块为了更好理解，我们假设有A和B两台机器，A需要与B相同目录下有8个文件，文件分别是f1 f2 f3 ….f8。这个时候我们就可以通过Merkle Tree来进行快速比较。假设我们在文件创建的时候每个机器都构建了一个Merkle Tree。具体如下图: 从上图可得知，叶子节点node7的value = hash(f1),是f1文件的HASH;而其父亲节点node3的value = hash(v7, v8)，也就是其子节点node7 node8的值得HASH。就是这样表示一个层级运算关系。root节点的value其实是所有叶子节点的value的唯一特征。 假如A上的文件5与B上的不一样。我们怎么通过两个机器的merkle treee信息找到不相同的文件? 这个比较检索过程如下: Step1. 首先比较v0是否相同,如果不同，检索其孩子node1和node2. Step2. v1 相同，v2不同。检索node2的孩子node5 node6; Step3. v5不同，v6相同，检索比较node5的孩子node 11 和node 12 Step4. v11不同，v12相同。node 11为叶子节点，获取其目录信息。 Step5. 检索比较完毕。 以上过程的理论复杂度是Log(N)。过程描述图如下: 从上图可以得知真个过程可以很快的找到对应的不相同的文件。 更新，插入和删除虽然网上有很多关于Merkle Tree的资料，但大部分没有涉及Merkle Tree的更新、插入和删除操作，讨论Merkle Tree的检索和遍历的比较多。我也是非常困惑，一种树结构的操作肯定不仅包括查找，也包括更新、插入和删除的啊。后来查到stackexchange上的一个问题，才稍微有点明白，原文见[6]。 对于Merkle Tree数据块的更新操作其实是很简单的，更新完数据块，然后接着更新其到树根路径上的Hash值就可以了，这样不会改变Merkle Tree的结构。但是，插入和删除操作肯定会改变Merkle Tree的结构，如下图，一种插入操作是这样的： 插入数据块0后(考虑数据块的位置)，Merkle Tree的结构是这样的： 而[6]中的同学在考虑一种插入的算法，满足下面条件： re-hashing操作的次数控制在log(n)以内数据块的校验在log(n)+1以内除非原始树的n是偶数，插入数据后的树没有孤儿，并且如果有孤儿，那么孤儿是最后一个数据块数据块的顺序保持一致插入后的Merkle Tree保持平衡然后上面的插入结果就会变成这样： 根据[6]中回答者所说，Merkle Tree的插入和删除操作其实是一个工程上的问题，不同问题会有不同的插入方法。如果要确保树是平衡的或者是树高是log(n)的，可以用任何的标准的平衡二叉树的模式，如AVL树，红黑树，伸展树，2-3树等。这些平衡二叉树的更新模式可以在O(lgn)时间内完成插入操作，并且能保证树高是O(lgn)的。那么很容易可以看出更新所有的Merkle Hash可以在O((lgn)2)时间内完成（对于每个节点如要更新从它到树根O(lgn)个节点，而为了满足树高的要求需要更新O(lgn)个节点）。如果仔细分析的话，更新所有的hash实际上可以在O(lgn)时间内完成，因为要改变的所有节点都是相关联的，即他们要不是都在从某个叶节点到树根的一条路径上，或者这种情况相近。 [6]的回答者说实际上Merkle Tree的结构(是否平衡，树高限制多少)在大多数应用中并不重要，而且保持数据块的顺序也在大多数应用中也不需要。因此，可以根据具体应用的情况，设计自己的插入和删除操作。一个通用的Merkle Tree插入删除操作是没有意义的。 Merkle Tree的应用数字签名最初Merkle Tree目的是高效的处理Lamport one-time signatures。 每一个Lamport key只能被用来签名一个消息，但是与Merkle tree结合可以来签名多条Merkle。这种方法成为了一种高效的数字签名框架，即Merkle Signature Scheme。 P2P网络在P2P网络中，Merkle Tree用来确保从其他节点接受的数据块没有损坏且没有被替换，甚至检查其他节点不会欺骗或者发布虚假的块。大家所熟悉的BT下载就是采用了P2P技术来让客户端之间进行数据传输，一来可以加快数据下载速度，二来减轻下载服务器的负担。BT即BitTorrent，是一种中心索引式的P2P文件分分析通信协议[7]。 要进下载必须从中心索引服务器获取一个扩展名为torrent的索引文件（即大家所说的种子），torrent文件包含了要共享文件的信息，包括文件名，大小，文件的Hash信息和一个指向Tracker的URL[8]。Torrent文件中的Hash信息是每一块要下载的文件内容的加密摘要，这些摘要也可运行在下载的时候进行验证。大的torrent文件是Web服务器的瓶颈，而且也不能直接被包含在RSS或gossiped around(用流言传播协议进行传播)。一个相关的问题是大数据块的使用，因为为了保持torrent文件的非常小，那么数据块Hash的数量也得很小，这就意味着每个数据块相对较大。大数据块影响节点之间进行交易的效率，因为只有当大数据块全部下载下来并校验通过后，才能与其他节点进行交易。 就解决上面两个问题是用一个简单的Merkle Tree代替Hash List。设计一个层数足够多的满二叉树，叶节点是数据块的Hash，不足的叶节点用0来代替。上层的节点是其对应孩子节点串联的hash。Hash算法和普通torrent一样采用SHA1。其数据传输过程和第一节中描述的类似。 Trusted Computing可信计算是可信计算组为分布式计算环境中参与节点的计算平台提供端点可信性而提出的。可信计算技术在计算平台的硬件层引入可信平台模块(Trusted Platform，TPM)，实际上为计算平台提供了基于硬件的可信根(Root of trust，RoT)。从可信根出发，使用信任链传递机制，可信计算技术可对本地平台的硬件及软件实施逐层的完整性度量，并将度量结果可靠地保存再TPM的平台配置寄存器(Platform configuration register，PCR)中，此后远程计算平台可通过远程验证机制(Remote Attestation)比对本地PCR中度量结果，从而验证本地计算平台的可信性。可信计算技术让分布式应用的参与节点摆脱了对中心服务器的依赖，而直接通过用户机器上的TPM芯片来建立信任，使得创建扩展性更好、可靠性更高、可用性更强的安全分布式应用成为可能[10]。可信计算技术的核心机制是远程验证(remote attestation),分布式应用的参与结点正是通过远程验证机制来建立互信,从而保障应用的安全。 文献[10]提出了一种基于Merkle Tree的远程验证机制，其核心是完整性度量值哈希树。 首先,RAMT 在内核中维护的不再是一张完整性度量值列表(ML),而是一棵完整性度量值哈希树(integrity measurement hash tree,简称IMHT).其中,IMHT的叶子结点存储的数据对象是待验证计算平台上被度量的各种程序的完整性哈希值,而其内部结点则依据Merkle 哈希树的构建规则由子结点的连接的哈希值动态生成。 其次,为了维护IMHT 叶子结点的完整性,RAMT 需要使用TPM 中的一段存储器来保存IMHT 可信根哈希的值。 再次,RAMT 的完整性验证过程基于认证路径(authentication path)实施.认证路径是指IMHT 上从待验证叶子结点到根哈希的路径。 IPFSIPFS(InterPlanetary File System)是很多NB的互联网技术的综合体，如DHT( Distributed HashTable，分布式哈希表)，Git版本控制系统，Bittorrent等。它创建了一个P2P的集群，这个集群允许IPFS对象的交换。全部的IPFS对象形成了一个被称作Merkle DAG的加密认证数据结构。 IPFS对象是一个含有两个域的数据结构: Data – 非结构的二进制数据，大小小于256kBLinks – 一个Link数据结构的数组。IPFS对象通过他们链接到其他对象 Link数据结构包含三个域： Name – Link的名字Hash – Link链接到对象的HashSize – Link链接到对象的累积大小，包括它的Links 通过Name和Links，IPFS的集合组成了一个Merkle DAG（有向无环图）。 对于小文件（&lt;256kB），是一个没有Links的IPFS对象。 对于大文件，被表示为一个文件块(&lt;256kB)的集合。只有拥有最小的Data的对象来代表这个大文件。这个对象的Links的名字都为空字符串。 目录结构：目录是没有数据的IPFS对象，它的链接指向其包含的文件和目录。 IPFS可以表示Git使用的数据结构，Git commit object。Commit Object主要的特点是他有一个或多个名为’parent0’和‘parent1’等的链接（这些链接指向前一个版本），以及一个名为object的对象(在Git中成为tree)指向引用这个commit的文件系统结构。 BitCoin和EthereumMerkle Proof最早的应用是Bitcoin，它是由中本聪在2009年描述并创建的。Bitcoin的Blockchain利用Merkle proofs来存储每个区块的交易。 而这样做的好处，也就是中本聪描述到的“简化支付验证”（Simplified Payment Verification，SPV）的概念:一个“轻客户端”（light client）可以仅下载链的区块头即每个区块中的80byte的数据块，仅包含五个元素，而不是下载每一笔交易以及每一个区块： 上一区块头的哈希值时间戳挖矿难度值工作量证明随机数（nonce）包含该区块交易的Merkle Tree的根哈希 如果客户端想要确认一个交易的状态，它只需简单的发起一个Merkle proof请求，这个请求显示出这个特定的交易在Merkle trees的一个之中，而且这个Merkle Tree的树根在主链的一个区块头中。 但是Bitcoin的轻客户端有它的局限。一个局限是，尽管它可以证明包含的交易，但是它不能进行涉及当前状态的证明（如数字资产的持有，名称注册，金融合约的状态等）。 Bitcoin如何查询你当前有多少币？一个比特币轻客户端，可以使用一种协议，它涉及查询多个节点，并相信其中至少会有一个节点会通知你，关于你的地址中任何特定的交易支出，而这可以让你实现更多的应用。但对于其他更为复杂的应用而言，这些远远是不够的。一笔交易影响的确切性质（precise nature），可以取决于此前的几笔交易，而这些交易本身则依赖于更为前面的交易，所以最终你可以验证整个链上的每一笔交易。为了解决这个问题，Ethereum的Merkle Tree的概念，会更进一步。 Ethereum的Merkle Proof每个以太坊区块头不是包括一个Merkle树，而是为三种对象设计的三棵树： 交易Transaction收据Receipts(本质上是显示每个交易影响的多块数据)状态State 这使得一个非常先进的轻客户端协议成为了可能，它允许轻客户端轻松地进行并核实以下类型的查询答案： 这笔交易被包含在特定的区块中了么？告诉我这个地址在过去30天中，发出X类型事件的所有实例（例如，一个众筹合约完成了它的目标）目前我的账户余额是多少？这个账户是否存在？假如在这个合约中运行这笔交易，它的输出会是什么？ 第一种是由交易树（transaction tree）来处理的；第三和第四种则是由状态树（state tree）负责处理，第二种则由收据树（receipt tree）处理。计算前四个查询任务是相当简单的。服务器简单地找到对象，获取Merkle分支，并通过分支来回复轻客户端。 第五种查询任务同样也是由状态树处理，但它的计算方式会比较复杂。这里，我们需要构建一个Merkle状态转变证明（Merkle state transition proof）。从本质上来讲，这样的证明也就是在说“如果你在根S的状态树上运行交易T，其结果状态树将是根为S’，log为L，输出为O” （“输出”作为存在于以太坊的一种概念，因为每一笔交易都是一个函数调用；它在理论上并不是必要的）。 为了推断这个证明，服务器在本地创建了一个假的区块，将状态设为 S，并在请求这笔交易时假装是一个轻客户端。也就是说，如果请求这笔交易的过程，需要客户端确定一个账户的余额，这个轻客户端(由服务器模拟的)会发出一个余额查询请求。如果需要轻客户端在特点某个合约的存储中查询特定的条目，这个轻客户端就会发出这样的请求。也就是说服务器(通过模拟一个轻客户端)正确回应所有自己的请求，但服务器也会跟踪它所有发回的数据。 然后，服务器从上述的这些请求中把数据合并并把数据以一个证明的方式发送给客户端。 然后，客户端会进行相同的步骤，但会将服务器提供的证明作为一个数据库来使用。如果客户端进行步骤的结果和服务器提供的是一样的话，客户端就接受这个证明。 MPT(Merkle Patricia Trees)前面我们提到，最为简单的一种Merkle Tree大多数情况下都是一棵二叉树。然而，Ethereum所使用的Merkle Tree则更为复杂，我们称之为“梅克尔.帕特里夏树”（Merkle Patricia tree）。 对于验证属于list格式（本质上来讲，它就是一系列前后相连的数据块）的信息而言，二叉Merkle Tree是非常好的数据结构。对于交易树来说，它们也同样是不错的，因为一旦树已经建立，花多少时间来编辑这棵树并不重要，树一旦建立了，它就会永远存在并且不会改变。 但是，对于状态树，情况会更复杂些。以太坊中的状态树基本上包含了一个键值映射，其中的键是地址，而值包括账户的声明、余额、随机数nounce、代码以及每一个账户的存储（其中存储本身就是一颗树）。例如，摩登测试网络（the Morden testnet ）的创始状态如下所示： 然而，不同于交易历史记录，状态树需要经常地进行更新：账户余额和账户的随机数nonce经常会更变，更重要的是，新的账户会频繁地插入，存储的键（ key）也会经常被插入以及删除。我们需要这样的数据结构，它能在一次插入、更新、删除操作后快速计算到树根，而不需要重新计算整个树的Hash。这种数据结构同样得包括两个非常好的第二特征： 树的深度是有限制的，即使考虑攻击者会故意地制造一些交易，使得这颗树尽可能地深。不然，攻击者可以通过操纵树的深度，执行拒绝服务攻击（DOS attack），使得更新变得极其缓慢。树的根只取决于数据，和其中的更新顺序无关。换个顺序进行更新，甚至重新从头计算树，并不会改变根。 MPT是最接近同时满足上面的性质的的数据结构。MPT的工作原理的最简单的解释是，值通过键来存储，键被编码到搜索树必须要经过的路径中。每个节点有16个孩子，因此路径又16进制的编码决定：例如，键‘dog’的16进制编码是6 4 6 15 6 7，所以从root开始到第六个分支，然后到第四个，再到第六个，再到第十五个，这样依次进行到达树的叶子。 在实践中，当树稀少时也会有一些额外的优化，我们会使过程更为有效，但这是基本的原则。 参考：[1] https://en.wikipedia.org/wiki/Merkle_tree [2] https://en.wikipedia.org/wiki/Hash_function#Hash_function_algorithms [3] http://www.jianshu.com/p/458e5890662f [4] http://blog.csdn.net/xtu_xiaoxin/article/details/8148237 [5] http://blog.csdn.net/yuanrxdu/article/details/22474697?utm_source=tuicool&amp;utm_medium=referral [6] http://crypto.stackexchange.com/questions/22669/merkle-hash-tree-updates [7] https://en.wikipedia.org/wiki/BitTorrent]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言宏定义#define的理解与资料整理]]></title>
    <url>%2F2019%2F05%2F25%2FC%E8%AF%AD%E8%A8%80%E5%AE%8F%E5%AE%9A%E4%B9%89define%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E8%B5%84%E6%96%99%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[利用define来定义 数值宏常量#define宏定义是个演技非常高超的替身演员，但也会经常耍大牌的，所以我们用它要慎之又慎。它可以出现在代码的任何地方，从本行宏定义开始，以后的代码就就都认识这个宏了；也可以把任何东西定义成宏。因为编译器会在预编译的时候用真身替换替身，而在我们的代码里面却又用常常用替身来帮忙。 看例子：1#define PI 3.141592654 在此后的代码中你尽可以使用PI 来代替3.141592654，而且你最好就这么做。不然的话，如果我要把PI 的精度再提高一些，你是否愿意一个一个的去修改这串数呢？你能保证不漏不出错？而使用PI 的话，我们却只需要修改一次（这是十分高效的）。 这种情况还不是最要命的，我们再看一个例子：1#define ERROR_POWEROFF -1 如果你在代码里不用ERROR_POWEROFF 这个宏而用-1，尤其在函数返回错误代码的时候（往往一个开发一个系统需要定义很多错误代码）。肯怕上帝都无法知道-1 表示的是什么意思吧。这个-1，我们一般称为“魔鬼数”，上帝遇到它也会发狂的。所以，我奉劝你代码里一定不要出现“魔鬼数”。(这里是从代码可读性的角度进行考虑！) 但是我们利用define来定义数值类型的数据，一般只是用来定义 常量 ，如果 要定义一些变量，则可以使用c语言中const这个关键字。 我们已经讨论了const 这个关键字，我们知道const 修饰的数据是有类型的，而define 宏定义的数据没有类型。为了安全，我建议你以后在定义一些宏常数的时候用const代替，编译器会给const 修饰的只读变量做类型校验，减少错误的可能。 但一定要注意const修饰的不是常量而是readonly 的变量，const 修饰的只读变量不能用来作为定义数组的维数，也不能放在case 关键字后面。 利用define来定义 字符串宏常量除了定义宏常数之外，经常还用来定义字符串，尤其是路径：12A),#define ENG_PATH_1 E:\English\listen_to_this\listen_to_this_3B),#define ENG_PATH_2 “E:\English\listen_to_this\listen_to_this_3” 噢，到底哪一个正确呢？如果路径太长，一行写下来比较别扭怎么办？用反斜杠接续符 ‘\’ 啊：1C), #define ENG_PATH_3 E:\English\listen_to_this\listen\_to_this_3 还没发现问题？这里用了4 个反斜杠，到底哪个是接续符？回去看看接续符反斜杠。 反斜杠作为接续符时，在本行其后面不能再有任何字符，空格都不行。所以，只有最后一个反斜杠才是接续符。至于A)和B)，那要看你怎么用了，既然define 宏只是简单的替换，那给ENG_PATH_1 加上双引号不就成了：“ENG_PATH_1”。 但是请注意：有的系统里规定路径的要用双反斜杠“\”,比如（这是正确的版本）：1#define ENG_PATH_4 E:\\English\\listen_to_this\\listen_to_this_3 用define 宏定义 注释符号上面对define 的使用都很简单，再看看下面的例子：12345#define BSC //#define BMC /*#define EMC */D),BSC my single-line commentE),BMC my multi-line comment EMC D)和E)都错误，为什么呢？因为注释先于预处理指令被处理,当这两行被展开成//…或/…/时,注释已处理完毕,此时再出现//…或/…/自然错误.（这一条需要对编译预处理有所理解，才能体会。看来我还得再写一篇这方面的文章。） 因此,试图用宏开始或结束一段注释是不行的。 用define 宏定义表达式这些都好理解，下面来点有“技术含量”的，定义一年有多少秒：1#define SEC_A_YEAR 60*60*24*365 这个定义没错吧？很遗憾，很有可能错了，至少不可靠。你有没有考虑在16 位系统下把这样一个数赋给整型变量的时候可能会发生溢出？一年有多少秒也不可能是负数吧。 改一下：1#define SEC_A_YEAR （60*60*24*365）UL 又出现一个问题，这里的括号到底需不需要呢？继续看一个例子，定义一个宏函数，求x 的平方：1#define SQR (x) x * x 对不对？试试：假设x 的值为10，SQR (x)被替换后变成10*10。没有问题。 再试试：假设x 的值是个表达式10+1，SQR (x)被替换后变成10+1*10+1。问题来了，这并不是我想要得到的。怎么办？括号括起来不就完了？1#define SQR (x) （（x）*（x）） 最外层的括号最好也别省了，看例子，求两个数的和：1#define SUM (x) （x）+（x） 如果x 的值是个表达式5*3,而代码又写成这样：SUM (x)* SUM (x)。替换后变成：（5*3）+（5*3）*（5*3）+（5*3）。又错了！所以最外层的括号最好也别省了。我说过define是个演技高超的替身演员，但也经常耍大牌。要搞定它其实很简单，别吝啬括号就行了。 注意这一点：宏函数被调用时是以实参代换形参。而不是“值传送”。 宏定义中的空格另外还有一个问题需要引起注意，看下面例子：1#define SUM （x） （x）+（x） 这还是定义的宏函数SUM（x）吗？显然不是。编译器认为这是定义了一个宏：SUM，其代表的是（x） （x）+（x）。 为什么会这样呢？其关键问题还是在于SUM 后面的这个空格。所以在定义宏的时候一定要注意什么时候该用空格，什么时候不该用空格。这个空格仅仅在定义的时候有效，在使用这个宏函数的时候，空格会被编译器忽略掉。也就是说，上一节定义好的宏函数SUM（x）在使用的时候在SUM 和（x）之间留有空格是没问题的。比如：SUM（3）和SUM （3）的意思是一样的。 #undef#undef是用来撤销宏定义的，用法如下：12345#define PI 3.141592654…// code#undef PI//下面的代码就不能用PI 了，它已经被撤销了宏定义。 写好C语言，漂亮的宏定义很重要，使用宏定义可以防止出错，提高可移植性，可读性，方便性 等等。下面列举一些成熟软件中常用得宏定义： 防止一个头文件被重复包含1234567#ifndef COMDEF_H #define COMDEF_H //头文件内容 #endif 重新定义一些类型防止由于各种平台和编译器的不同，而产生的类型字节数差异，方便移植。这里已经不是#define的范畴了。1234567891011121314151617181920typedef unsigned char boolean; /* Boolean value type. */typedef unsigned long int uint32; /* Unsigned 32 bit value */typedef unsigned short uint16; /* Unsigned 16 bit value */typedef unsigned char uint8; /* Unsigned 8 bit value */typedef signed long int int32; /* Signed 32 bit value */typedef signed short int16; /* Signed 16 bit value */typedef signed char int8; /* Signed 8 bit value *///下面的不建议使用typedef unsigned char byte; /* Unsigned 8 bit value type. */typedef unsigned short word; /* Unsinged 16 bit value type. */typedef unsigned long dword; /* Unsigned 32 bit value type. */typedef unsigned char uint1; /* Unsigned 8 bit value type. */typedef unsigned short uint2; /* Unsigned 16 bit value type. */typedef unsigned long uint4; /* Unsigned 32 bit value type. */typedef signed char int1; /* Signed 8 bit value type. */typedef signed short int2; /* Signed 16 bit value type. */typedef long int int4; /* Signed 32 bit value type. */typedef signed long sint31; /* Signed 32 bit value */typedef signed short sint15; /* Signed 16 bit value */typedef signed char sint7; /* Signed 8 bit value */ 得到指定地址上的一个字节或字12#define MEM_B( x ) ( *( (byte *) (x) ) )#define MEM_W( x ) ( *( (word *) (x) ) ) 求最大值和最小值12#define MAX( x, y ) ( ((x) &gt; (y)) ? (x) : (y) )#define MIN( x, y ) ( ((x) &lt; (y)) ? (x) : (y) ) 得到一个field在结构体(struct)中的偏移量12#define FPOS( type, field ) \/*lint -e545 */ ( (dword) &amp;(( type *) 0)-&gt; field ) /*lint +e545 */ 得到一个结构体中field所占用的字节数1#define FSIZ( type, field ) sizeof( ((type *) 0)-&gt;field ) 按照LSB格式把两个字节转化为一个Word1#define FLIPW( ray ) ( (((word) (ray)[0]) * 256) + (ray)[1] ) 按照LSB格式把一个Word转化为两个字节123#define FLOPW( ray, val ) \(ray)[0] = ((val) / 256); \(ray)[1] = ((val) &amp; 0xFF) 得到一个变量的地址（word宽度）12#define B_PTR( var ) ( (byte *) (void *) &amp;(var) )#define W_PTR( var ) ( (word *) (void *) &amp;(var) ) 得到一个字的高位和低位字节123#define WORD_LO(xxx) ((byte) ((word)(xxx) &amp; 255))#define WORD_HI(xxx) ((byte) ((word)(xxx) &gt;&gt; 8)) 返回一个比X大的最接近的8的倍数1#define RND8( x ) ((((x) + 7) / 8 ) * 8 ) 将一个字母转换为大写1#define UPCASE( c ) ( ((c) &gt;= &apos;a&apos; &amp;&amp; (c) &lt;= &apos;z&apos;) ? ((c) - 0x20) : (c) ) 判断字符是不是10进值的数字1#define DECCHK( c ) ((c) &gt;= &apos;0&apos; &amp;&amp; (c) &lt;= &apos;9&apos;) 判断字符是不是16进值的数字123#define HEXCHK( c ) ( ((c) &gt;= &apos;0&apos; &amp;&amp; (c) &lt;= &apos;9&apos;) ||\((c) &gt;= &apos;A&apos; &amp;&amp; (c) &lt;= &apos;F&apos;) ||\((c) &gt;= &apos;a&apos; &amp;&amp; (c) &lt;= &apos;f&apos;) ) 防止溢出的一个方法1#define INC_SAT( val ) (val = ((val)+1 &gt; (val)) ? (val)+1 : (val)) 返回数组元素的个数1#define ARR_SIZE( a ) ( sizeof( (a) ) / sizeof( (a[0]) ) ) 返回一个无符号数n尾的值MOD_BY_POWER_OF_TWO(X,n)=X%(2^n)12#define MOD_BY_POWER_OF_TWO( val, mod_by ) \( (dword)(val) &amp; (dword)((mod_by)-1) ) 对于IO空间映射在存储空间的结构，输入输出处理123456#define inp(port) (*((volatile byte *) (port)))#define inpw(port) (*((volatile word *) (port)))#define inpdw(port) (*((volatile dword *)(port)))#define outp(port, val) (*((volatile byte *) (port)) = ((byte) (val)))#define outpw(port, val) (*((volatile word *) (port)) = ((word) (val)))#define outpdw(port, val) (*((volatile dword *) (port)) = ((dword) (val))) 使用一些宏跟踪调试ANSI标准说明了五个预定义的宏名。它们是：12345__LINE____FILE____DATE____TIME____STDC__ 可以定义宏，例如: 当定义了_DEBUG，输出数据信息和所在文件所在行12345#ifdef _DEBUG#define DEBUGMSG(msg,date) printf(msg);printf(“%d%d%d”,date,_LINE_,_FILE_)#else#define DEBUGMSG(msg,date)#endif 宏定义防止使用错误用小括号包含。例如：1#define ADD(a,b) （a+b） 用do{}while(0)语句包含多语句防止错误 例如：12#define DO(a,b) a+b;\a++; 应用时：123if(….)DO(a,b); //产生错误else 解决方法: 代码就只会执行一次。和直接加花括号有什么区别呢。哦对，不能随便在程序中，任意加｛｝，组成代码块的。12#define DO(a,b) do&#123;a+b;\a++;&#125;while(0)]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言函数指针的理解与使用]]></title>
    <url>%2F2019%2F05%2F25%2FC%E8%AF%AD%E8%A8%80%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[函数指针的定义顾名思义，函数指针就是函数的指针。它是一个指针，指向一个函数。看例子：123A) char * (*fun1)(char * p1,char * p2);B) char * *fun2(char * p1,char * p2);C) char * fun3(char * p1,char * p2); 看看上面三个表达式分别是什么意思？ C）这很容易，fun3是函数名，p1，p2是参数，其类型为char 型，函数的返回值为char 类型。 B) 也很简单，与C）表达式相比，唯一不同的就是函数的返回值类型为char**，是个二级指针。 A) fun1是函数名吗？回忆一下前面讲解数组指针时的情形。我们说数组指针这么定义或许更清晰：1int (*)[10] p; 再看看A）表达式与这里何其相似！明白了吧。这里fun1不是什么函数名，而是一个指针变量，它指向一个函数。这个函数有两个指针类型的参数，函数的返回值也是一个指针。同样，我们把这个表达式改写一下：1char * (*)(char * p1,char * p2) fun1; 这样子是不是好看一些呢？只可惜编译器不这么想。^_^。 函数指针使用的例子上面我们定义了一个函数指针，但如何来使用它呢？先看如下例子：12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;string.h&gt;char * fun(char * p1,char * p2)&#123; int i = 0; i = strcmp(p1,p2); if (0 == i) &#123; return p1; &#125; else &#123; return p2; &#125;&#125;int main()&#123; char * (*pf)(char * p1,char * p2); pf = &amp;fun; (*pf) (&quot;aa&quot;,&quot;bb&quot;); return 0;&#125; 我们使用指针的时候，需要通过钥匙（“*”）来取其指向的内存里面的值，函数指针使用也如此。通过用(*pf)取出存在这个地址上的函数，然后调用它。 这里需要注意到是，在Visual C++6.0里，给函数指针赋值时，可以用&amp;fun或直接用函数名fun。这是因为函数名被编译之后其实就是一个地址，所以这里两种用法没有本质的差别。这个例子很简单，就不再详细讨论了。 (int)&amp;p —-这是什么？也许上面的例子过于简单，我们看看下面的例子：1234567891011void Function()&#123; printf(&quot;Call Function!\n&quot;);&#125;int main()&#123; void (*p)(); *(int*)&amp;p=(int)Function; (*p)(); return 0;&#125; 这是在干什么？*(int*)&amp;p=(int)Function;表示什么意思？别急，先看这行代码：1void (*p)(); 这行代码定义了一个指针变量p，p指向一个函数，这个函数的参数和返回值都是void。&amp;p是求指针变量p本身的地址，这是一个32位的二进制常数（32位系统）。 (int*)&amp;p表示将地址强制转换成指向int类型数据的指针。(int)Function表示将函数的入口地址强制转换成int类型的数据。分析到这里，相信你已经明白*(int*)&amp;p=(int)Function;表示将函数的入口地址赋值给指针变量p。 那么(*p) ();就是表示对函数的调用。 讲解到这里，相信你已经明白了。其实函数指针与普通指针没什么差别，只是指向的内容不同而已。使用函数指针的好处在于，可以将实现同一功能的多个模块统一起来标识，这样一来更容易后期的维护，系统结构更加清晰。或者归纳为：便于分层设计、利于系统抽象、降低耦合度以及使接口与实现分开。 (*(void(*) ())0)()——这是什么？是不是感觉上面的例子太简单，不够刺激？好，那就来点刺激的，看下面这个例子：1(*(void(*) ())0)(); 这是《C Traps and Pitfalls》这本经典的书中的一个例子。没有发狂吧？下面我们就来分析分析： 第一步：void(*) ()，可以明白这是一个函数指针类型。这个函数没有参数，没有返回值。 第二步：(void(*) ())0，这是将0强制转换为函数指针类型，0是一个地址，也就是说一个函数存在首地址为0的一段区域内。 第三步：(*(void(*) ())0)，这是取0地址开始的一段内存里面的内容，其内容就是保存在首地址为0的一段区域内的函数。 第四步：(*(void(*) ())0)()，这是函数调用。 好像还是很简单是吧，上面的例子再改写改写：1(*(char**(*) (char **,char **))0) ( char **,char **); 如果没有上面的分析，肯怕不容易把这个表达式看明白吧。不过现在应该是很简单的一件事了。读者以为呢？ 函数指针数组现在我们清楚表达式1char * (*pf)(char * p); 定义的是一个函数指针pf。既然pf是一个指针，那就可以储存在一个数组里。把上式修改一下：1char * (*pf[3])(char * p); 这是定义一个函数指针数组。 它是一个数组，数组名为pf，数组内存储了3个指向函数的指针。这些指针指向一些返回值类型为指向字符的指针、参数为一个指向字符的指针的函数。 这念起来似乎有点拗口。不过不要紧，关键是你明白这是一个指针数组，是数组。函数指针数组怎么使用呢？这里也给出一个非常简单的例子，只要真正掌握了使用方法，再复杂的问题都可以应对。 如下：12345678910111213141516171819202122232425262728#include &lt;stdio.h&gt;#include &lt;string.h&gt;char * fun1(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125; char * fun2(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125;char * fun3(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125;&lt;br&gt;int main()&#123; char * (*pf[3])(char * p); pf[0] = fun1; //可以直接用函数名 pf[1] = &amp;fun2; //可以用函数名加上取地址符 pf[2] = &amp;fun3;&lt;br&gt; pf[0](&quot;fun1&quot;); pf[0](&quot;fun2&quot;); pf[0](&quot;fun3&quot;); return 0;&#125; 函数指针数组的指针看着这个标题没发狂吧？函数指针就够一般初学者折腾了，函数指针数组就更加麻烦，现在的函数指针数组指针就更难理解了。其实，没这么复杂。前面详细讨论过数组指针的问题，这里的函数指针数组指针不就是一个指针嘛。只不过这个指针指向一个数组，这个数组里面存的都是指向函数的指针。仅此而已。 下面就定义一个简单的函数指针数组指针：1char * (*(*pf)[3])(char * p); 注意，这里的pf和上一节的pf就完全是两码事了。上一节的pf并非指针，而是一个数组名；这里的pf确实是实实在在的指针。这个指针指向一个包含了3个元素的数组；这个数字里面存的是指向函数的指针；这些指针指向一些返回值类型为指向字符的指针、参数为一个指向字符的指针的函数。 这比上一节的函数指针数组更拗口。其实你不用管这么多，明白这是一个指针就ok了。其用法与前面讲的数组指针没有差别。下面列一个简单的例子：123456789101112131415161718192021222324252627282930313233343536#include &lt;stdio.h&gt;#include &lt;string.h&gt; char * fun1(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125; char * fun2(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125; char * fun3(char * p)&#123; printf(&quot;%s\n&quot;,p); return p;&#125; int main()&#123; char * (*a[3])(char * p); char * (*(*pf)[3])(char * p); pf = &amp;a; a[0] = fun1; a[1] = &amp;fun2; a[2] = &amp;fun3; pf[0][0](&quot;fun1&quot;); pf[0][1](&quot;fun2&quot;); pf[0][2](&quot;fun3&quot;); return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言编译预处理和条件编译执行过程的理解]]></title>
    <url>%2F2019%2F05%2F25%2FC%E8%AF%AD%E8%A8%80%E7%BC%96%E8%AF%91%E9%A2%84%E5%A4%84%E7%90%86%E5%92%8C%E6%9D%A1%E4%BB%B6%E7%BC%96%E8%AF%91%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[在C语言的程序中可包括各种以符号#开头的编译指令，这些指令称为预处理命令。预处理命令属于C语言编译器，而不是C语言的组成部分。通过预处理命令可扩展C语言程序设计的环境。 预处理的工作方式预处理的功能在集成开发环境中，编译，链接是同时完成的。其实，C语言编译器在对源代码编译之前，还需要进一步的处理：预编译。所以，完整的步骤是：预编译 -&gt; 编译 -&gt; 链接预编译的主要作用如下： 将源文件中以”include”格式包含的文件复制到编译的源文件中。 用实际值替换用“#define”定义的字符串。 根据“#if”后面的条件决定需要编译的代码。 预处理的工作方式预处理的行为是由指令控制的。这些指令是由#字符开头的一些命令。 #define指令定义了一个宏—用来代表其他东西的一个命令，通常是某一个类型的常量。预处理会通过将宏的名字和它的定义存储在一起来响应#define指令。当这个宏在后面的程序中使用到时，预处理器”扩展”了宏，将宏替换为它所定义的值。例如：下面这行命令：1#define PI 3.141592654 #include指令告诉预处理器打开一个特定的文件，将它的内容作为正在编译的文件的一部分“包含”进来。例如：下面这行命令：1#include&lt;stdio.h&gt; 指示预处理器打开一个名字为stdio.h的文件，并将它的内容加到当前的程序中。 预处理器的输入是一个C语言程序，程序可能包含指令。预处理器会执行这些指令，并在处理过程中删除这些指令。预处理器的输出是另外一个程序：原程序的一个编辑后的版本，不再包含指令。预处理器的输出被直接交给编译器，编译器检查程序是否有错误，并经程序翻译为目标代码。 预处理指令预处理指令大多数预处理器指令属于下面3种类型： 宏定义：#define 指令定义一个宏，#undef指令删除一个宏定义。 文件包含：#include指令导致一个指定文件的内容被包含到程序中。 条件编译：#if,#ifdef,#ifndef,#elif,#else和#endif指令可以根据编译器可以测试的条件来将一段文本包含到程序中或排除在程序之外。 剩下的#error,#line和#pragma指令更特殊的指令，较少用到。 指令规则指令都是以#开始。#符号不需要在一行的行首，只要她之前有空白字符就行。在#后是指令名，接着是指令所需要的其他信息。在指令的符号之间可以插入任意数量的空格或横向制表符。指令总是第一个换行符处结束，除非明确地指明要继续。指令可以出现在程序中任何地方。我们通常将#define和#include指令放在文件的开始，其他指令则放在后面，甚至在函数定义的中间。注释可以与指令放在同一行。 宏定义命令—-#define使用#define命令并不是真正的定义符号常量，而是定义一个可以替换的宏。被定义为宏的标示符称为“宏名”。在编译预处理过程时，对程序中所有出现的“宏名”，都用宏定义中的字符串去代换，这称为“宏代换”或“宏展开”。 在C语言中，宏分为有参数和无参数两种。 无参数的宏其定义格式如下：1#define 宏名 字符串 在以上宏定义语句中，各部分的含义如下： #：表示这是一条预处理命令(凡是以“#”开始的均为预处理命令)。 define:关键字“define”为宏定义命令。 宏名：是一个标示符，必须符合C语言标示符的规定，一般以大写字母标示宏名。 字符串：可以是常数，表达式，格式串等。在前面使用的符号常量的定义就是一个无参数宏定义。 Notice:预处理命令语句后面一般不会添加分号，如果在#define最后有分号，在宏替换时分号也将替换到源代码中去。在宏名和字符串之间可以有任意个空格。1#define PI 3.14 在使用宏定义时，还需要注意以下几点： 宏定义是宏名来表示一个字符串，在宏展开时又以该字符串取代宏名。这只是一种简单的代换，字符串中可以含任何字符，可以是常数，也可以是表达式，预处理程序对它不作任何检查。如有错误，只能在编译已被宏展开后的源程序时发现。 宏定义必须写在函数之外，其作用域为宏定义命令起到源程序结束。 宏名在源程序中若用引号括起来，则预处理程序不对其作宏替换。 宏定义允许嵌套，在宏定义的字符串中可以使用已经定义的宏名。在宏展开时由预处理程序层层替换。 习惯上宏名可用大写字母表示，以方便与变量区别。但也允许用小写字母。 带参数的宏#define命令定义宏时，还可以为宏设置参数。与函数中的参数类似，在宏定于中的参数为形式参数，在宏调用中的参数称为实际参数。对带参数的宏，在调用中，不仅要宏展开，还要用实参去代换形参。带参宏定义的一般形式为：1#define 宏名(形参表) 字符串 在定义带参数的宏时，宏名和形参表之间不能有空格出现，否则，就将宏定义成为无参数形式，而导致程序出错。1#define ABS(x) (x)&lt;0?-(x):(x) 以上的宏定义中，如果x的值小于0，则使用一元运算符(-)对其取负，得到正数。 带参的宏和带参的函数相似，但其本质是不同的。使用带参宏时，在预处理时将程序源代码替换到相应的位置，编译时得到完整的目标代码，而不进行函数调用，因此程序执行效率要高些。而函数调用只需要编译一次函数，代码量较少，一般情况下，对于简单的功能，可使用宏替换的形式来使用。 预处理操作符#和操作符在使用#define定义宏时，可使用操作符#在字符串中输出实参。Eg:1#define AREA(x,y) printf(“长为“#x”,宽为“#y”的长方形的面积：%d\n”,(x)*(y)); 操作符与操作符#类似，操作符##也可用在带参宏中替换部分内容。该操作符将宏中的两个部分连接成一个内容。例如，定义如下宏：1#define VAR(n) v##n 当使用一下方式引用宏：VAR(1)预处理时，将得到以下形式：v1 如果使用以下宏定义：1#define FUNC(n) oper##n 当实参为1时，预处理后得到一下形式：1oper1 文件包含——include当一个C语言程序由多个文件模块组成时，主模块中一般包含main函数和一些当前程序专用的函数。程序从main函数开始执行，在执行过程中，可调用当前文件中的函数，也可调用其他文件模块中的函数。 如果在模块中要调用其他文件模块中的函数，首先必须在主模块中声明该函数原型。一般都是采用文件包含的方法，包含其他文件模块的头文件。 文件包含中指定的文件名即可以用引号括起来，也可以用尖括号括起来，格式如下：1#include&lt; 文件名&gt; 或1#include“文件名” 如果使用尖括号&lt;&gt;括起文件名，则编译程序将到C语言开发环境中设置好的 include文件中去找指定的文件。 因为C语言的标准头文件都存放在include文件夹中，所以一般对标准头文件采用尖括号；对编程自己编写的文件，则使用双引号。 如果自己编写的文件不是存放在当前工作文件夹，可以在#include命令后面加在路径。 #include命令的作用是把指定的文件模块内容插入到#include所在的位置，当程序编译链接时，系统会把所有#include指定的文件链接生成可执行代码。文件包含必须以#开头，表示这是编译预处理命令，行尾不能用分号结束。 #include所包含的文件，其扩展名可以是“.c”,表示包含普通C语言源程序。也可以是 “.h”,表示C语言程序的头文件。C语言系统中大量的定义与声明是以头文件形式提供的。 “.h”是接口文件，如果想理解C语言接口的写法，有必要琢磨一下 “.h”。 通过#define包含进来的文件模块中还可以再包含其他文件，这种用法称为嵌套包含。嵌套的层数与具体C语言系统有关，但是一般可以嵌套8层以上。 条件编译预处理器还提供了条件编译功能。在预处理时，按照不同的条件去编译程序的不同部分，从而得到不同的目标代码。 使用条件编译，可方便地处理程序的调试版本和正式版本，也可使用条件编译使程序的移植更方便。 使用#if与C语言的条件分支语句类似，在预处理时，也可以使用分支，根据不同的情况编译不同的源代码段。 #if的使用格式如下：12345#if 常量表达式 程序段#else 程序段#endif 该条件编译命令的执行过程为：若常量表达式的值为真(非0),则对程序段1进行编译，否则对程序段2进行编译。因此可以使程序在不同条件下完成不同的功能。 举个例子：123456789101112131415161718#define DEBUG 1int main()&#123; int i,j; char ch[26]; for(i=&apos;a&apos;;j=0;i&lt;=&apos;z&apos;;i++,j++) &#123; ch[j]=i; #if DEBUG printf(&quot;ch[%d]=%c\n&quot;,j,ch[j]); #endif &#125; for(j=0;j&lt;26;j++) &#123; printf(&quot;%c&quot;,ch[j]); &#125; return 0;&#125; #if预编译命令还可使用多分支语句格式，具体格式如下：12345678910111213141516171819#if 常量表达式 1 程序段 1 #elif 常量表达式 2 程序段 2 … … #elif 常量表达式 n 程序段 n #else 程序段 m #endif 关键字#elif与多分支if语句中的else if类似。举个例子123456789101112131415#define os win #if os=win #include&quot;win.h&quot; #elif os=linux #include&quot;linux.h&quot; #elif os=mac #include&quot;mac.h&quot; #endif #if和#elif还可以进行嵌套，C89标准中，嵌套深度可以到达8层，而C99允许嵌套达到63层。在嵌套时，每个#endif，#else或#elif与最近的#if或#elif配对。Eg:1234567891011121314151617181920212223242526272829303132333435363738394041#define MAX 100#define OLD -1 int main()&#123;int i;#if MAX&gt;50&#123; #if OLD&gt;3 &#123; i=1; &#123; #elif OLD&gt;0 &#123; i=2; &#125; #else &#123; i=3; &#125; #endif&#125;#else&#123; #if OLD&gt;3 &#123; i=4; &#125; #elif OLD&gt;4 &#123; i=5; &#125; #else &#123; i=6; &#125; #endif&#125;#endifreturn 0;&#125; 使用#ifdef和#ifndef在上面的#if条件编译命令中，需要判断符号常量定义的具体值。在很多情况下，其实不需要判断符号常量的值，只需要判断是否定义了该符号常量。这时，可不使用#if命令，而使用另外一个预编译命令———#ifdef.123456789#ifdef命令的使用格式如下：#ifdef 标识符程序段 1 #else 程序段 2 #endif 其意义是，如果#ifdef后面的标识符已被定义过，则对“程序段1”进行编译；如果没有定义标识符，则编译“程序段2”。一般不使用#else及后面的“程序2”。 而#ifndef的意义与#ifdef相反，其格式如下：12345678#ifndef 标识符 程序段 1 #else 程序段 2 #endif 其意义是：如果未定义标识符，则编译“程序段1”；否则编译“程序段2”。 使用#defined和#undef与#ifdef类似的，可以在#if命令中使用define来判断是否已定义指定的标识符。例如：1234#if defined 标识符程序段 1 #endif 与下面的标示方式意义相同。1234#ifdef 标识符 程序段 1 #endif 也可使用逻辑运算符，对defined取反。例如：1234#if ! define 标识符 程序段 1 #endif 与下面的标示方式意义相同。1234#ifndef 标识符 程序段 1 #endif 在#ifdef和#ifndef命令后面的标识符是使用#define进行定义的。在程序中，还可以使用#undef取消对标识符的定义，其形式为：1#undef 标识符 举个例子：123#define MAX 100 ……#undef MAX 在以上代码中，首先使用#define定义标识符MAX,经过一段程序代码后，又可以使用#undef取消已定义的标识符。使用#undef命令后，再使用#ifdef max，将不会编译后的源代码，因为此时标识符MAX已经被取消定义了。 其他预处理命令预定义的宏名ANSI C标准预定义了五个宏名，每个宏名的前后均有两个下画线，避免与程序员定义相同的宏名(一般都不会定义前后有两个下划线的宏)。这5个宏名如下： __DATE__:当前源程序的创建日期。 __FILE__:当前源程序的文件名称(包括盘符和路径)。 __LINE__:当前被编译代码的行号。 __STDC__:返回编译器是否位标准C,若其值为1表示符合标准C，否则不是标准C. __TIME__:当前源程序的创建时间。 举个例子：1234567891011#include&lt;stdio.h&gt;int main()&#123; int j; printf(&quot;日期：%s\n&quot;,__DATE__); printf(&quot;时间：%s\n&quot;,__TIME__&#125;; printf(&quot;文件名：%s\n&quot;,__FILE__); printf(&quot;这是第%d行代码\n&quot;,__LINE__); printf(&quot;本编译器%s标准C\n&quot;,(__STD__)?&quot;符合&quot;:&quot;不符合&quot;)； return 0;&#125; 重置行号和文件名命令————#line使用__LINE__预定义宏名赈灾编译的程序行号。使用#line命令可改变预定义宏__LINE__与__FILE__的内容，该命令的基本形如下：1#line number[“filename”] 其中的数字为一个正整数，可选的文件名为有效文件标识符。行号为源代码中当前行号，文件名为源文件的名字。命令为#line主要用于调试以及其他特殊应用。举个例子：123456789#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#line 1000int main()&#123; printf(&quot;当前行号：%d\n&quot;,__LINE__); return 0;&#125; 在以上程序中，在第4行中使用#line定义的行号为从1000开始(不包括#line这行)。所以第5行的编号将为1000，第6行为1001，第7行为1002，第8行为1003. 修改编译器设置命令 ————#pragma#pragma命令的作用是设定编译器的状态，或者指示编译器完全一些特定的动作。#pragma命令对每个编译器给出了一个方法，在保持与C语言完全兼容的情况下，给出主机或者操作系统专有的特征。其格式一般为：1#pragma Para 其中，Para为参数，可使用的参数很多，下面列出常用的参数： Message参数，该参数能够在编译信息输出窗口中输出对应的信息，这对于源代码信息的控制是非常重要的，其使用方法是：1#pragma message(消息文本) 当编译器遇到这条指令时，就在编译输出窗口中将消息文本显示出来。 另外一个使用比较多得pragma参数是code_seg.格式如：1#pragma code_seg([“section_name”[,section_class]]) 它能够设置程序中函数代码存放的代码段，在开发驱动程序的时候就会使用到它。 参数once，可保证头文件被编译一次，其格式为：1#pragma once 只要在头文件的最开始加入这条指令就能够保证头文件被编译一次。 产生错误信息命令 ————#error#error命令强制编译器停止编译，并输出一个错误信息，主要用于程序调试。其使用如下：1#error 信息错误 注意，错误信息不用双括号括起来。当遇到#error命令时，错误信息将显示出来。 例如，以下编译预处理器命令判断预定义宏__STDC__,如果其值不为1，则显示一个错误信息，提示程序员该编译器不支持ANSI C标准。1234#if __STDC__!=1 #error NOT ANSI C#endif 内联函数在使用#define定义带参数宏时，在调用函数时，一般需要增加系统的开销，如参数传递，跳转控制，返回结果等额外操作需要系统内存和执行时间。而使用带参数宏时，通过宏替换可再编译前将函数代码展开导源代码中，使编译后的目标文件含有多段重复的代码。这样做，会增加程序的代码量，都可以减少执行时间。 在C99标准钟，还提供另外一种解决方法：使用内联函数。 在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来进行替代。显然，这种做法不会产生转去转回得问题。都是由于在编译时将函数体中的代码被替代到程序中，因此会增加目标代码量，进而增加空间的开销，而在时间开销上不像函数调用时那么大，可见它是以增加目标代码为代码来换取时间的节省。定义内联函数的方法很简单，只要在定义函数头的前面加上关键字inline即可。内联函数的定义与一般函数一样。例如，定于一个两个整数相加的函数：123456789101112131415161718#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;inline int add(int x,int y); inline int add(int x,int y)&#123; return x+y;&#125; int main()&#123; int i,j,k; printf(&quot;请输入两个整数的值：\n&quot;); scanf(&quot;%d %d&quot;,&amp;i,&amp;j); k=add(i,j); printf(&quot;k=%d\n&quot;,k); return 0;&#125; 在程序中，调用函数add时，该函数在编译时会将以上代码复制过来，而不是像一般函数那样是运行时被调用。 内联函数具有一般函数的特性，它与一般函数所不同之处在于函数调用的处理。一般函数进行调用时，要讲程序执行权转导被调函数中，然后再返回到调用到它的函数中；而内联函数在调用时，是将调用表达式用内联函数体来替换。在使用内联函数时，应该注意如下几点： 在内联函数内部允许用循环语句和开关语句。但是，程序在经过编译之后，这个函数是不会作为内联函数进行调用的。内联函数的定义必须出现在内联函数第一次被调用之前。 其实，在程序中声明一个函数为内联时，编译以后这个函数不一定是内联的， 即程序只是建议编译器使用内联函数，但是编译器会根据函数情况决定是否使用内联，所以如果编写的内联函数中出现循环或者开关语句，程序也不会提示出错，但那个函数已经不是内联函数了。 一般都是将一个小型函数作为内联函数。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode965. Univalued Binary Tree]]></title>
    <url>%2F2019%2F05%2F24%2FLeetcode956%2F</url>
    <content type="text"><![CDATA[A binary tree is univalued if every node in the tree has the same value. Return true if and only if the given tree is univalued. Example 1:Input: [1,1,1,1,1,null,1]Output: true Example 2:Input: [2,2,2,5,2]Output: false Note: The number of nodes in the given tree will be in the range [1, 100].Each node’s value will be an integer in the range [0, 99].1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool des(TreeNode* root,int val)&#123; if(root==NULL) return true; if(root-&gt;val != val) return false; return des(root-&gt;left,val)&amp;&amp;des(root-&gt;right,val); &#125; bool isUnivalTree(TreeNode* root) &#123; if(root==NULL) return true; return des(root,root-&gt;val); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode589 N-ary Tree Preorder Traversal]]></title>
    <url>%2F2019%2F05%2F23%2FLeetcode589%2F</url>
    <content type="text"><![CDATA[Given an n-ary tree, return the preorder traversal of its nodes’ values. For example, given a 3-ary tree: Return its preorder traversal as: [1,3,5,6,2,4]. Note: Recursive solution is trivial, could you do it iteratively? 1234567891011121314151617181920212223242526272829303132/*// Definition for a Node.class Node &#123;public: int val; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125;&#125;;*/class Solution &#123;public: vector&lt;int&gt; res; void des(Node* root)&#123; if(root==NULL) return ; res.push_back(root-&gt;val); for(int i=0;i&lt;root-&gt;children.size();i++) des(root-&gt;children[i]); return; &#125; vector&lt;int&gt; preorder(Node* root) &#123; des(root); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode590 N-ary Tree Postorder Traversal]]></title>
    <url>%2F2019%2F05%2F22%2FLeetcode590%2F</url>
    <content type="text"><![CDATA[Given an n-ary tree, return the postorder traversal of its nodes’ values. For example, given a 3-ary tree: Return its postorder traversal as: [5,6,3,2,4,1]. Note: Recursive solution is trivial, could you do it iteratively? 遍历一棵n叉树。 1234567891011121314151617181920212223242526272829303132333435363738/*// Definition for a Node.class Node &#123;public: int val; vector&lt;Node*&gt; children; Node() &#123;&#125; Node(int _val, vector&lt;Node*&gt; _children) &#123; val = _val; children = _children; &#125;&#125;;*/class Solution &#123;public: vector&lt;int&gt; res; void des(Node* root)&#123; if(root==NULL) return ; if(root-&gt;children.size()==0)&#123; res.push_back(root-&gt;val); return ; &#125; for(int i=0;i&lt;root-&gt;children.size();i++)&#123; des(root-&gt;children[i]); &#125; res.push_back(root-&gt;val); return ; &#125; vector&lt;int&gt; postorder(Node* root) &#123; des(root); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode700. Search in a Binary Search Tree]]></title>
    <url>%2F2019%2F05%2F22%2FLeetcode700%2F</url>
    <content type="text"><![CDATA[Given the root node of a binary search tree (BST) and a value. You need to find the node in the BST that the node’s value equals the given value. Return the subtree rooted with that node. If such node doesn’t exist, you should return NULL. For example, Given the tree:12345 4 / \ 2 7 / \1 3 And the value to search: 2You should return this subtree:123 2 / \ 1 3 In the example above, if we want to search the value 5, since there is no node with value 5, we should return NULL. Note that an empty tree is represented by NULL, therefore you would see the expected output (serialized tree format) as [], not null. 给一棵树，查找对应value的子树。 1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* des(TreeNode* root,int val)&#123; if(root==NULL) return NULL; if(root-&gt;val == val) return root; if(root-&gt;val &gt; val) return des(root-&gt;left,val); else return des(root-&gt;right,val); &#125; TreeNode* searchBST(TreeNode* root, int val) &#123; if(root == NULL) return NULL; return des(root,val); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode944. Delete Columns to Make Sorted]]></title>
    <url>%2F2019%2F05%2F22%2FLeetcode944%2F</url>
    <content type="text"><![CDATA[We are given an array A of N lowercase letter strings, all of the same length. Now, we may choose any set of deletion indices, and for each string, we delete all the characters in those indices. For example, if we have an array A = [“abcdef”,”uvwxyz”] and deletion indices {0, 2, 3}, then the final array after deletions is [“bef”, “vyz”], and the remaining columns of A are [“b”,”v”], [“e”,”y”], and [“f”,”z”]. (Formally, the c-th column is [A[0][c], A[1][c], …, A[A.length-1][c]].) Suppose we chose a set of deletion indices D such that after deletions, each remaining column in A is in non-decreasing sorted order. Return the minimum possible value of D.length. Example 1:12Input: [&quot;cba&quot;,&quot;daf&quot;,&quot;ghi&quot;]Output: 1 Explanation:After choosing D = {1}, each column [“c”,”d”,”g”] and [“a”,”f”,”i”] are in non-decreasing sorted order.If we chose D = {}, then a column [“b”,”a”,”h”] would not be in non-decreasing sorted order.Example 2:12Input: [&quot;a&quot;,&quot;b&quot;]Output: 0 Explanation: D = {}Example 3:12Input: [&quot;zyx&quot;,&quot;wvu&quot;,&quot;tsr&quot;]Output: 3 Explanation: D = {0, 1, 2} Note: 1 &lt;= A.length &lt;= 1001 &lt;= A[i].length &lt;= 1000 字符串数组 A 中的每个字符串元素的长度相同，统计index个数，这个index 的要求是 A[i].charAt(index)，i=0,1,2,3,4 组成的 字符序列 不是严格递增。 1234567891011121314151617class Solution &#123;public: int minDeletionSize(vector&lt;string&gt;&amp; A) &#123; int isize=A.size(); int jsize=A[0].size(); int ans=0; for(int j=0;j&lt;jsize;j++)&#123; for(int i=0;i&lt;isize-1;i++)&#123; if(A[i][j]&gt;A[i+1][j])&#123; ans++; break; &#125; &#125; &#125; return ans; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库设计三大范式与BCNF]]></title>
    <url>%2F2019%2F05%2F21%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F%E4%B8%8EBCNF%2F</url>
    <content type="text"><![CDATA[概念 实体（entity）：就是实际应用中要用数据描述的事物，一般是名词。 字段（fields）：就是一项数据，也就是我们平常所说的“列”。 记录（record）：一个实体的一个实例所特有的相关数据项的集合，也就是我们平常所说的“行”。 键（key）：可唯一标识一条记录的一个字段或字段集，有时翻译为“码”。 主键（primary key）：用于唯一标识一个表中的一条记录的键。每个主键应该具有下列特征： 唯一的。 最小 的（尽量选择最少键的组合）。 非空。 不可更新的（不能随时更改） 外键（foreign keys）：对连接父表和子表的相关记录的主键字段的复制。 依赖表（dependent table）：也称为弱实体（weak entity）是需要用父表标识的子表。 关联表（associative table）：是多对多关系中两个父表的子表。 实体完整性：每个表必须有一个有效的主 键。 参照完整性：没有不相匹配的外键值。 名词解释函数依赖：通俗描述：描述一个学生的关系，可以有学号(SNO),姓名(SNAME),系名(SDEPT)等几个属性。由于一个学号只对应一个学生，一个学生只在一个系学习。因此当学号确定之后，姓名和该学生所在系的值也就唯一被确定了，就像自变量x确定之后，相应的函数值f(x)也就唯一地被确定了一样，称SNO函数决定SNAME和SDEPT，或者说SNAME，SDEPT函数依赖于SNO，记为：SNO -&gt; SNAME， SNO -&gt; SDEPT. 严格定义：设R(U)是属性集U上的关系模式。X，Y是U的子集。若对于R(U)的任意一个可能的关系r,r中不可能存在两个元组在X上的属性值相等，而在Y上的属性值不相等，则称X函数确定Y或者Y函数依赖于X。记为X-&gt;Y。 （如果不知道“关系”、“属性集”等定义，自己看大学教材去。这里的定义摘自萨师煊&amp;王珊《数据库系统概论》第三版） 完全函数依赖：在R(U)中，如果Y函数依赖于X,并且对于X的任何一个真子集X’，都有Y不函数依赖于X’， 则称Y对X完全函数依赖。否则称Y对X部分函数依赖。 举个例子就明白了。假设一个学生有几个属性 SNO 学号SNAME 姓名SDEPT 系SAGE 年龄CNO 班级号G 成绩 对于(SNO,SNAME,SDEPT,SAGE,CNO,G)来说，G完全依赖于(SNO, CNO), 因为(SNO,CNO)可以决定G，而SNO和CNO都不能单独决定G。 而SAGE部分函数依赖于(SNO,CNO),因为(SNO,CNO)可以决定SAGE，而单独的SNO也可以决定SAGE。 传递函数依赖：在R(U)中，如果X-&gt;Y, Y-&gt;Z, 则称Z对X传递函数依赖。 候选键：(又称候选码，候选关键字,码 ，candidate key)： 设K是一个R(U)中的属性或属性集合(注意可以是属性集合，也即多个属性的组合)，若K完全函数确定U，则K为R的候选键(Candidate key); 通俗地说就是，能够确定全部属性的某个属性或某组属性，称为候选键。若候选键多于一个，则选定其中一个作为主键。 主属性：包含在任何一个候选键中的属性，叫做主属性(Prime attribute),不包含在任何候选键中的属性称为非主属性或非键属性或非关键字段。 例子：在(SNO, CNO, G)中，SNO和CNO这俩合起来就是一个候选键，因为每个元组只要确定了SNO和CNO，则其它所有属性都可以根据SNO和CNO来确定。而SNO和CNO就都是“主属性”，G是“非主属性”。由于此例中只有一个候选键，于是只能选择(SNO, CNO)作为主键。 在(SNO,SDEPT, SNAME)中，SNO是一个候选键，因为只要SNO确定了，其它所有属性也都确定了，如果保证没有重名的话，则SNAME也是一个候选键，于是可以选SNO或者SNAME之一作为候选键。如果不能保证没有重名，就不能把SNAME当成候选键，于是就只有SNO能够做主键。 范式：第一范式：指数据库表的每一列都是不可分割的基本数据项在任何一个关系数据库中，第一范式（1NF）是对关系模式的基本要求，不满足第一范式（1NF）的数据库就不是关系数据库。 第二范式：数据库表中不存在非关键字段对任一候选键的部分函数依赖，也即所有非关键字 段都完全依赖于任意一组候选关键字。 2NF的违例只会出现在候选键由超过一个字段构成的表中，因为对单关键字字段不存在部分依赖问题。 例子：(学号, 姓名, 年龄, 课程名称, 成绩, 学分) 候选键只有一个，就是(姓名，课程名称)，则主键就是(姓名，课程名称) 存在如下决定关系： 1：(学号, 课程名称) → (姓名, 年龄, 成绩, 学分)2：(课程名称) → (学分)3：(学号) → (姓名, 年龄) 其中，姓名、年龄、学分是部分依赖于主键的，而成绩是完全依赖于主键的，存在部分依赖关系，所以不满足第二范式。 这会造成如下问题 数据冗余：同一门课程由n个学生选修，”学分”就重复n-1次；同一个学生选修了m门课程，姓名和年龄就重复了m-1次。 更新异常：若调整了某门课程的学分，数据表中所有行的”学分”值都要更新，否则会出现同一门课程学分不同的情况。 插入异常：假设要开设一门新的课程，暂时还没有人选修。这样，由于还没有”学号”关键字，课程名称和学分也无法记录入数据 库。 删除异常：假设一批学生已经完成课程的选修，这些选修记录就应该从数据库表中删除。但是，与此同 时，课程名称和学分信息也被删除了。很显然，这也会导致插入异常。 问题就在于存在非主属性对主键的部分依赖 解决办法：把原表(学号, 姓名, 年龄, 课程名称, 成绩, 学分)分成三个表： 学生：Student(学号, 姓名, 年龄)； 课程：Course(课程名称, 学分)； 选课关 系：SelectCourse(学号, 课程名称, 成绩)。 第三范式:在第二范式的基础上，数据表中如果不存在非关键字段对任一候选关键字段的传递函数依赖则符合第三范式 出现传递依赖A-&gt;B-&gt;C，即主键A可以确定出某一非关键字段B，而B又可以确定出C，这意味着C依赖于一个非关键字段B。因此第三范式又可描述为：表中不存在可以确定其他非关键字的非键字段 例子：表：(学号, 姓名, 年龄, 所在学院, 学院地点, 学院电话) 该表中候选字段只有“学号”，于是“学号”做主键。由于主键是单一属性，所以不存在非主属性对主键的部分函数依赖的问题，所以必然满足第二范式。但是存在如下传递依赖 (学号) → (所在学院) → (学院地点, 学院电话) 学院地点和学院电话传递依赖于学号，而学院地点和学院电话都是非关键字段，即表中出现了“某一非关键字段可以确定出其它非关键字段”的情况，于是违反了第三范式。 解决办法： 把原表分成两个表： 学生：(学号, 姓名, 年龄, 所在学院)； 学院：(学院, 地点, 电话)。 BCNF：BCNF意味着在关系模式中每一个决定因素都包含候选键，也就是说，只要属性或属性组A能够决定任何一个属性B，则A的子集中必须有候选键。BCNF范式排除了任何属性(不光是非主属性，2NF和3NF所限制的都是非主属性)对候选键的传递依赖与部分依赖。 例子： 例子二： 假设仓库管理关系表为StorehouseManage(仓库ID, 存储物品ID, 管理员ID, 数量)，且有一个管理员只在一个仓库工作；一个仓库可以存储多种物品。这个数据库表中存在如下决定关系： (仓库ID, 存储物品ID) →(管理员ID, 数量) (管理员ID, 存储物品ID) → (仓库ID, 数量) 所以，(仓库ID, 存储物品ID)和(管理员ID, 存储物品ID)都是StorehouseManage的候选关键字，表中的唯一非关键字段为数量，它是符合第三范式的。但是，由于存在如下决定关系： (仓库ID) → (管理员ID) (管理员ID) → (仓库ID) 仓库I是决定因素，但仓库ID不包含候选键(candidate key,也就是候选码，简称码)。 同样的，管理员ID也是决定因素，但不包含候选键。 所以该表不满足BCNF。 3NF和BCNF是在函数依赖的条件下对模式分解所能达到的最大程度。一个模式中的关系模式如果都属于BCNF，那么在函数依赖范围内，它已经实现了彻底的分离，已消除了插入和删除的异常。3NF的“不彻底”性表现在可能存在主属性对键的部分依赖和传递依赖。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++智能指针]]></title>
    <url>%2F2019%2F05%2F21%2Fcpp%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[智能指针背后的设计思想无智能指针造成内存泄漏的例子12345678910void remodel(std::string &amp; str)&#123; std::string * ps = new std::string(str);//堆内存 ... if (weird_thing()) throw exception(); str = *ps; delete ps; return;&#125; 当出现异常时（weird_thing()返回true），delete将不被执行，因此将导致内存泄露 。 常规解决方案：在throw exception()之前添加delete ps;不要忘了最后一个delete ps;出现问题：在一个大型的工程中，并不能保证所有的开发人员都能在合适的地方添加delete语句。 智能指针的设计思想仿照本地变量能够自动从栈内存中删除的思想，对指针设计一个析构函数，该析构函数将在指针过期时自动释放它指向的内存，总结来说就是：将基本类型指针封装为类对象指针（这个类肯定是个模板，以适应不同基本类型的需求），并在析构函数中编写delete语句以用来删除指针指向的内存空间。 转换remodel()函数的步骤： 包含头义件memory（智能指针所在的头文件）；将指向string的指针替换为指向string的智能指针对象；删除delete语句。使用auto_ptr修改该函数的结果：1234567891011#include &lt;memory&gt;void remodel (std::string &amp; str)&#123; std::auto_ptr&lt;std::string&gt; ps (new std::string(str))； ... if (weird_thing ()) throw exception()； str = *ps； // delete ps； NO LONGER NEEDED return;&#125; C++智能指针简单介绍STL一共给我们提供了四种智能指针：auto_ptr、unique_ptr、shared_ptr和weak_ptr。 其中：auto_ptr在C++11中已将其摒弃。 使用注意点： 所有的智能指针类都有一个explicit构造函数，以指针作为参数。比如auto_ptr的类模板原型为：12345templet&lt;class T&gt;class auto_ptr &#123; explicit auto_ptr(X* p = 0) ; ...&#125;; 因此不能自动将指针转换为智能指针对象，必须显示调用：123456shared_ptr&lt;double&gt; pd;double *p_reg = new double;pd = p_reg;//NOT ALLOWED(implicit conversion)pd = shared_ptr&lt;double&gt;(p_reg);// ALLOWED (explicit conversion)shared_ptr&lt;double&gt; pshared = p_reg;//NOT ALLOWED (implicit conversion)shared_ptr&lt;double&gt; pshared(p_reg);//ALLOWED (explicit conversion) 对全部三种智能指针都应避免的一点：12string vacation(&quot;I wandered lonely as a child.&quot;); //heap paramshared_ptr&lt;string&gt; pvac(&amp;vacation);//NO!! pvac过期时，程序将把delete运算符用于非堆(栈)内存，这是错误的！ 使用实例1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;memory&gt;class report&#123;private: std::string str;public: report(const std::string s) : str(s)&#123; std::cout&lt;&lt;&quot;Object created.\n&quot;; &#125; ~report()&#123; std::cout&lt;&lt;&quot;Object deleted.\n&quot;; &#125; void comment() const &#123; std::cout&lt;&lt;str&lt;&lt;&quot;\n&quot;; &#125;&#125;;int main()&#123; &#123; std::auto_ptr&lt;report&gt; ps(new report(&quot;using auto ptr&quot;)); ps-&gt;comment(); &#125;//auto_ptr 作用域结束 &#123; std::shared_ptr&lt;report&gt; ps(new report(&quot;using shared_ptr&quot;)); ps-&gt;comment(); &#125;//shared_ptr 作用域结束 &#123; std::unique_ptr&lt;report&gt; ps(new report(&quot;using unique ptr&quot;)); ps-&gt;comment(); &#125;//unique_ptr 作用域结束 return 0;&#125; 为什么摒弃auto_ptr?问题来源：123auto_ptr&lt;string&gt; ps (new string(&quot;I reigned lonely as a cloud.&quot;));auto_ptr&lt;string&gt; vocation;vocation = ps; 如果ps和vocation是常规指针，则两个指针指向同一个string对象，当指针过期时，则程序会试图删除同一个对象，要避免这种问题，解决办法： 定义赋值运算符，使之执行深复制。这样两个指针将指向不同的对象，其中的一个对象是另一个对象的副本，缺点是浪费空间，所以智能指针都未采取此方案。建立所有权(ownership)概念。对于特定的对象，智能有一个智能对象可拥有，这样只能拥有对象的智能指针的析构函数会删除该对象。然后让赋值操作转让所有权。这就是用于auto_ptr和unique_ptr的策略，但unique_ptr的策略更严格。创建智能更高的指针，跟踪引用特定对象的智能指针数。这称为引用计数。例如，赋值时，计数将加1，而指针过期时，计数将减1，当减为0时才调用delete。这是shared_ptr采用的策略。同样的策略也适用于复制构造函数。 摒弃auto_ptr的例子：12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;memory&gt;using namespace std;int main()&#123; auto_ptr&lt;string&gt; films[5] = &#123; auto_ptr&lt;string&gt; (new string(&quot;Fowl Balls&quot;)), auto_ptr&lt;string&gt; (new string(&quot;Duck Walks&quot;)), auto_ptr&lt;string&gt; (new string(&quot;Chicken Runs&quot;)), auto_ptr&lt;string&gt; (new string(&quot;Turkey Errors&quot;)), auto_ptr&lt;string&gt; (new string(&quot;Goose Eggs&quot;)) &#125;; auto_ptr&lt;string&gt; pwin; pwin = films[2];//films[2] loses owership,将所有权从films[2]转让给pwin,此时films[2]不再引用该字符串从而变成空指针 cout&lt;&lt;&quot;The nominees for best avian baseball film are\n&quot;; for(int i = 0;i &lt; 5;++i) &#123; cout&lt;&lt; *films[i]&lt;&lt;endl; &#125; cout&lt;&lt;&quot;The winner is &quot;&lt;&lt;*pwin&lt;&lt;endl; cin.get(); return 0;&#125; 运行下发现程序崩溃了，原因是films[2]已经是空指针了，输出空指针就会崩溃。如果把auto_ptr换成shared_ptr或unique_ptr后，程序就不会崩溃，原因如下： 适用shared_ptr时运行正常，因为shared_ptr采用引用计数，pwin和films[2]都指向同一块内存，在释放空间时因为事先要判断引用计数值的大小，因此不会出现多次删除一个对象的错误。 适用unique_ptr时编译出错，与auto_ptr一样，unique_ptr也采用所有权模型，但在适用unique_ptr时，程序不会等到运行阶段崩溃，在编译阶段下属代码就会出现错误：12unique_ptr&lt;string&gt; pwin;pwin = films[2];//films[2] loses ownership 这就是为何摒弃auto_ptr的原因：避免潜在的内存泄漏问题。 unique_ptr为何优于auto_ptr？使用规则更严格123auto_ptr&lt;string&gt; p1(new string(&quot;auto&quot;)); //#1 auto_ptr&lt;string&gt; p2; //#2 p2 = p1; //#3 在语句#3中，p2接管string对象的所有权后，p1的所有权将被剥夺。–&gt;可防止p1和p2的析构函数试图删除同一个对象。但如果随后试图使用p1，则会出现错误。123unique_ptr&lt;string&gt; p3(new string(&quot;auto&quot;));//#4unique_ptr&lt;string&gt; p4;//#5p4=p3;//#6 编译器会认为#6语句为非法，可以避免上述问题。 对悬挂指针的操作更智能总体来说：允许临时悬挂指针的赋值，禁止其他情况的出现。 示例：函数定义如下：1234unique_ptr&lt;string&gt; demo(const char *s)&#123; unique_ptr&lt;string&gt; temp (new string(a)); return temp;&#125; 在程序中调用函数：12unique_ptr&lt;string&gt; ps;ps = demo(&quot;unique special&quot;); 编译器允许此种赋值方式。总之：当程序试图将一个unique_ptr赋值给另一个时，如果源unique_ptr是个临时右值，编译器允许这么做；如果源unique_ptr将存在一段时间，编译器将禁止这么做。12345unique_ptr&lt;string&gt; pu1(new string(&quot;hello world&quot;));unique_ptr&lt;string&gt; pu2;pu2 = pu1;//#1 not allowedunique_ptr&lt;string&gt; pu3;pu3 = unique_ptr&lt;string&gt;(new string(&quot;you&quot;));//#2 allowed 如果确实想执行类似#1的操作，仅当以非智能的方式使用摒弃的智能指针时（如解除引用时），这种赋值才不安全。要安全的重用这种指针，可给它赋新值。C++有一个标准库函数std::move()，可以将原来的指针转让所有权变成空指针，可以对其重新赋值。12345unque_ptr&lt;string&gt; ps1,ps2;ps1 = demo(&quot;hello&quot;);ps2 = move(ps1);ps1 = demo(&quot;alexia&quot;);cout&lt;&lt;*ps2&lt;&lt;*ps1&lt;&lt;endl; 如何选择智能指针使用指南： 如果程序要使用多个指向同一个对象的指针，应选用shared_ptr。这样的情况包括： 有一个指针数组，并使用一些辅助指针来标示特定的元素，如最大的元素和最小的元素； 连个对象包含指向第三个对象的指针； STL容器包含指针。很多STL算法都支持复制和赋值操作，这些操作可用于shared_ptr，但不能用于unique_ptr（编译器发出warning）和auto_ptr（行为不确定）。如果你的编译器没有提供shared_ptr，可使用Boost库提供的shared_ptr。 如果程序不需要多个指向同一个对象的指针，则可使用unique_ptr。如果函数使用new分配内存，并返还指向该内存的指针，将其返回类型声明为unique_ptr是不错的选择。这样，所有权转让给接受返回值的unique_ptr，而该智能指针将负责调用delete。可将unique_ptr储存到STL容器中，只要不调用将unique_ptr复制或赋值给另一个算法（如sort())。例如，可在程序中使用类似于下面的代码段： 123456789101112131415unique_ptr&lt;int&gt; make_int(int n)&#123; return unique_ptr&lt;int&gt;(new int(n));&#125;void show(unique_ptr&lt;int&gt; &amp;p1)&#123; cout&lt;&lt;*a&lt;&lt;&apos; &apos;;&#125;int main()&#123; ... vector&lt;unique_ptr&lt;int&gt;&gt; vp(size); for(int i=0; i&lt;vp.size();i++)&#123; vp[i] = make_int(rand() %1000);//copy temporary unique_ptr &#125; vp.push_back(make_int(rand()%1000));// ok because arg is temporary for_each(vp.begin(),vp.end(),show); //use for_each();&#125; 其中push_back调用没有问题，因为它返回一个临时unique_ptr，该unique_ptr被赋值给vp中的一个unique_ptr。另外，如果按值而不是按引用给show()传递对象，for_each()将非法，因为这将导致使用一个来自vp的非临时unique_ptr初始化p1，而这是不允许的。前面说过，编译器将发现错误使用unique_ptr的企图。 在unique_ptr为右值时，可将其赋给shared_ptr，这与将一个unique_ptr赋给一个需要满足的条件相同。与前面一样，在下面的代码中,make_int()的返回类型为unique_ptr：123unique_ptr&lt;int&gt; pup(make_int(rand() % 1000)); // okshared_ptr&lt;int&gt; spp(pup); // not allowed, pup as lvalueshared_ptr&lt;int&gt; spr(make_int(rand() % 1000)); // ok 模板shared_ptr包含一个显式构造函数，可用于将右值unique_ptr转换为shared_ptr。shared_ptr将接管原来归unique_ptr所有的对象。 在满足unique_ptr要求的条件时，也可使用auto_ptr，但unique_ptr是更好的选择。如果你的编译器没有unique_ptr，可考虑使用Boost库提供的scoped_ptr，它与unique_ptr类似。 弱引用智能指针 weak_ptr设计weak_ptr的原因：解决使用shared_ptr因循环引用而不能释放资源的问题。 空悬指针问题 有两个指针p1和p2，指向堆上的同一个对象Object，p1和p2位于不同的线程中。假设线程A通过p1指针将对象销毁了（尽管把p1置为NULL），那p2就成了空悬指针。这是一种典型的C/C++内存错误。 使用weak_ptr能够帮助我们轻松解决上述的空悬指针问题（直接使用shared_ptr也是可以的）。 weak_ptr不控制对象的生命期，但是它知道对象是否还活着，如果对象还活着，那么它可以提升为有效的shared_ptr（提升操作通过lock()函数获取所管理对象的强引用指针）；如果对象已经死了，提升会失败，返回一个空的shared_ptr。 举个栗子 ：12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;memory&gt;int main()&#123; // OLD, problem with dangling pointer // PROBLEM: ref will point to undefined data! int* ptr = new int(10); int* ref = ptr; delete ptr; // NEW // SOLUTION: check expired() or lock() to determine if pointer is valid // empty definition std::shared_ptr&lt;int&gt; sptr; // takes ownership of pointer sptr.reset(new int); *sptr = 10; // get pointer to data without taking ownership std::weak_ptr&lt;int&gt; weak1 = sptr; // deletes managed object, acquires new pointer sptr.reset(new int); *sptr = 5; // get pointer to new data without taking ownership std::weak_ptr&lt;int&gt; weak2 = sptr; // weak1 is expired! if(auto tmp = weak1.lock()) std::cout &lt;&lt; *tmp &lt;&lt; &apos;\n&apos;; else std::cout &lt;&lt; &quot;weak1 is expired\n&quot;; // weak2 points to new data (5) if(auto tmp = weak2.lock()) std::cout &lt;&lt; *tmp &lt;&lt; &apos;\n&apos;; else std::cout &lt;&lt; &quot;weak2 is expired\n&quot;;&#125; 循环引用问题栗子 大法：12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;boost/smart_ptr.hpp&gt;using namespace std;using namespace boost;class BB;class AA&#123;public: AA() &#123; cout &lt;&lt; &quot;AA::AA() called&quot; &lt;&lt; endl; &#125; ~AA() &#123; cout &lt;&lt; &quot;AA::~AA() called&quot; &lt;&lt; endl; &#125; shared_ptr&lt;BB&gt; m_bb_ptr; //!&#125;;class BB&#123;public: BB() &#123; cout &lt;&lt; &quot;BB::BB() called&quot; &lt;&lt; endl; &#125; ~BB() &#123; cout &lt;&lt; &quot;BB::~BB() called&quot; &lt;&lt; endl; &#125; shared_ptr&lt;AA&gt; m_aa_ptr; //!&#125;;int main()&#123; shared_ptr&lt;AA&gt; ptr_a (new AA); shared_ptr&lt;BB&gt; ptr_b ( new BB); cout &lt;&lt; &quot;ptr_a use_count: &quot; &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;ptr_b use_count: &quot; &lt;&lt; ptr_b.use_count() &lt;&lt; endl; //下面两句导致了AA与BB的循环引用，结果就是AA和BB对象都不会析构 ptr_a-&gt;m_bb_ptr = ptr_b; ptr_b-&gt;m_aa_ptr = ptr_a; cout &lt;&lt; &quot;ptr_a use_count: &quot; &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;ptr_b use_count: &quot; &lt;&lt; ptr_b.use_count() &lt;&lt; endl;&#125; 运行结果： 可以看到由于AA和BB内部的shared_ptr各自保存了对方的一次引用，所以导致了ptr_a和ptr_b销毁的时候都认为内部保存的指针计数没有变成0，所以AA和BB的析构函数不会被调用。解决方法就是把一个shared_ptr替换成weak_ptr。 可以看到由于AA和BB内部的shared_ptr各自保存了对方的一次引用，所以导致了ptr_a和ptr_b销毁的时候都认为内部保存的指针计数没有变成0，所以AA和BB的析构函数不会被调用。解决方法就是把一个shared_ptr替换成weak_ptr。12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;boost/smart_ptr.hpp&gt;using namespace std;using namespace boost;class BB;class AA&#123;public: AA() &#123; cout &lt;&lt; &quot;AA::AA() called&quot; &lt;&lt; endl; &#125; ~AA() &#123; cout &lt;&lt; &quot;AA::~AA() called&quot; &lt;&lt; endl; &#125; weak_ptr&lt;BB&gt; m_bb_ptr; //!&#125;;class BB&#123;public: BB() &#123; cout &lt;&lt; &quot;BB::BB() called&quot; &lt;&lt; endl; &#125; ~BB() &#123; cout &lt;&lt; &quot;BB::~BB() called&quot; &lt;&lt; endl; &#125; shared_ptr&lt;AA&gt; m_aa_ptr; //!&#125;;int main()&#123; shared_ptr&lt;AA&gt; ptr_a (new AA); shared_ptr&lt;BB&gt; ptr_b ( new BB); cout &lt;&lt; &quot;ptr_a use_count: &quot; &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;ptr_b use_count: &quot; &lt;&lt; ptr_b.use_count() &lt;&lt; endl; //下面两句导致了AA与BB的循环引用，结果就是AA和BB对象都不会析构 ptr_a-&gt;m_bb_ptr = ptr_b; ptr_b-&gt;m_aa_ptr = ptr_a; cout &lt;&lt; &quot;ptr_a use_count: &quot; &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;ptr_b use_count: &quot; &lt;&lt; ptr_b.use_count() &lt;&lt; endl;&#125; 运行结果： 最后值得一提的是，虽然通过弱引用指针可以有效的解除循环引用，但这种方式必须在能预见会出现循环引用的情况下才能使用，即这个仅仅是一种编译期的解决方案，如果程序在运行过程中出现了循环引用，还是会造成内存泄漏的。因此，不要认为只要使用了智能指针便能杜绝内存泄漏。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 伙伴算法简介]]></title>
    <url>%2F2019%2F05%2F21%2FLinux%E4%BC%99%E4%BC%B4%E7%AE%97%E6%B3%95%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[算法作用它要解决的问题是频繁地请求和释放不同大小的一组连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页面，由此带来的问题是，即使有足够的空闲页框可以满足请求，但要分配一个大块的连续页框可能无法满足请求。 伙伴算法（Buddy system）把所有的空闲页框分为11个块链表，每块链表中分布包含特定的连续页框地址空间，比如第0个块链表包含大小为2^0个连续的页框，第1个块链表中，每个链表元素包含2个页框大小的连续地址空间，….，第10个块链表中，每个链表元素代表4M的连续地址空间。每个链表中元素的个数在系统初始化时决定，在执行过程中，动态变化。 伙伴算法每次只能分配2的幂次页的空间，比如一次分配1页，2页，4页，8页，…，1024页(2^10)等等，每页大小一般为4K，因此，伙伴算法最多一次能够分配4M的内存空间。 核心概念和数据结构两个内存块，大小相同，地址连续，同属于一个大块区域。（第0块和第1块是伙伴，第2块和第3块是伙伴，但第1块和第2块不是伙伴） 伙伴位图：用一位描述伙伴块的状态位码，称之为伙伴位码。比如，bit0为第0块和第1块的伙伴位码，如果bit0为1，表示这两块至少有一块已经分配出去，如果bit0为0，说明两块都空闲，还没分配。 Linux2.6为每个管理区使用不同的伙伴系统，内核空间分为三种区，DMA，NORMAL，HIGHMEM，对于每一种区，都有对于的伙伴算法， free_area数组：12345struct zone&#123; .... struct free_area free_area[MAX_ORDER]; ....&#125; struct free_area free_area[MAX_ORDER] #MAX_ORDER 默认值为11 zone_mem_map数组 free_area数组中，第K个元素，它标识所有大小为2^k的空闲块，所有空闲快由free_list指向的双向循环链表组织起来。其中的nr_free，它指定了对应空间剩余块的个数。 整个分配图示，大概如下： 申请和回收过程比如，我要分配4(2^2)页（16k）的内存空间，算法会先从free_area[2]中查看nr_free是否为空，如果有空闲块，则从中分配，如果没有空闲块，就从它的上一级free_area[3]（每块32K）中分配出16K，并将多余的内存（16K）加入到free_area[2]中去。如果free_area[3]也没有空闲，则从更上一级申请空间，依次递推，直到free_area[max_order]，如果顶级都没有空间，那么就报告分配失败。 释放是申请的逆过程，当释放一个内存块时，先在其对于的free_area链表中查找是否有伙伴存在，如果没有伙伴块，直接将释放的块插入链表头。如果有或板块的存在，则将其从链表摘下，合并成一个大块，然后继续查找合并后的块在更大一级链表中是否有伙伴的存在，直至不能合并或者已经合并至最大块2^10为止。 内核试图将大小为b的一对空闲块（一个是现有空闲链表上的，一个是待回收的），合并为一个大小为2B的单独块，如果它成功合并所释放的块，它会试图合并2b大小的块， 内核使用_rmqueue()函数来在管理区中找到一个空闲块，成功返回第一个被分配页框的页描述符，失败返回NULL。 内核使用_free_pages_bulk()函数按照伙伴系统的策略释放页框。它使用3个基本输入参数：page：被释放块中所包含的第一个页框描述符的地址。zone：管理区描述符的地址。order：块大小的对数。 伙伴算法的优缺点优点：较好的解决外部碎片问题 当需要分配若干个内存页面时，用于DMA的内存页面必须连续，伙伴算法很好的满足了这个要求 只要请求的块不超过512个页面(2K)，内核就尽量分配连续的页面。 针对大内存分配设计。 缺点： 合并的要求太过严格，只能是满足伙伴关系的块才能合并，比如第1块和第2块就不能合并。 碎片问题：一个连续的内存中仅仅一个页面被占用，导致整块内存区都不具备合并的条件 浪费问题：伙伴算法只能分配2的幂次方内存区，当需要8K（2页）时，好说，当需要9K时，那就需要分配16K（4页）的内存空间，但是实际只用到9K空间，多余的7K空间就被浪费掉。 算法的效率问题： 伙伴算法涉及了比较多的计算还有链表和位图的操作，开销还是比较大的，如果每次2^n大小的伙伴块就会合并到2^(n+1)的链表队列中，那么2^n大小链表中的块就会因为合并操作而减少，但系统随后立即有可能又有对该大小块的需求，为此必须再从2^(n+1)大小的链表中拆分，这样的合并又立即拆分的过程是无效率的。 Linux针对大内存的物理地址分配，采用伙伴算法，如果是针对小于一个page的内存，频繁的分配和释放，有更加适宜的解决方案，如slab和kmem_cache等，这不在本文的讨论范围内。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中的银行家算法]]></title>
    <url>%2F2019%2F05%2F21%2FLinux%E4%B8%AD%E7%9A%84%E9%93%B6%E8%A1%8C%E5%AE%B6%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[银行家算法学习笔记死锁避免——银行家算法的应用背景要想说银行家，首先得说死锁问题，因为银行家算法就是为了死锁避免提出的。那么，什么是死锁？简单的举个例子：俩人吃饺子，一个人手里拿着酱油，一个人手里拿着醋，拿酱油的对拿着醋的人说：“你把醋给我，我就把酱油给你”；拿醋的对拿着酱油的人说：“不，你把酱油给我，我把醋给你。” 于是，俩人这两份调料是永远吃不上了。这就是死锁。 那么，为啥这个算法叫银行家算法？因为这个算法同样可以用于银行的贷款业务。让我们考虑下面的情况。 一个银行家共有20亿财产第一个开发商：已贷款15亿，资金紧张还需3亿。第二个开发商：已贷款5亿，运转良好能收回。第三个开发商：欲贷款18亿 在这种情况下，如果你是银行家，你怎么处理这种情况？一个常规的想法就是先等着第二个开发商把钱收回来，然后手里有了5个亿，再把3个亿贷款给第一个开发商，等第一个开发商收回来18个亿，然后再把钱贷款给第三个开发商。这里面什么值得学习呢？最重要的就是眼光放长一点，不要只看着手里有多少钱，同时要注意到别人欠自己的钱怎么能收回来。 那么正经点说这个问题，第一个例子中：醋和酱油是资源，这俩吃饺子的是进程；第二个例子中：银行家是资源，开发商是进程。在操作系统中，有内存，硬盘等等资源被众多进程渴求着，那么这些资源怎么分配给他们才能避免“银行家破产”的风险？ 银行家算法安全序列安全序列是指对当前申请资源的进程排出一个序列，保证按照这个序列分配资源完成进程，不会发生“酱油和醋”的尴尬问题。 我们假设有进程P1,P2,…..Pn则安全序列要求满足：Pi(1&lt;=i&lt;=n)需要资源&lt;=剩余资源 + 分配给Pj(1 &lt;= j &lt; i)资源为什么等号右边还有已经被分配出去的资源？想想银行家那个问题，分配出去的资源就好比第二个开发商，人家能还回来钱，咱得把这个考虑在内。 我们定义下面的数据结构123456int n,m; //系统中进程总数n和资源种类总数mint Available[1..m]; //资源当前可用总量int Allocation[1..n,1..m]; //当前给分配给每个进程的各种资源数量int Need[1..n,1..m];//当前每个进程还需分配的各种资源数量int Work[1..m]; //当前可分配的资源bool Finish[1..n]; //进程是否结束 安全判定算法1.初始化Work = Available（动态记录当前剩余资源）Finish[i] = false（设定所有进程均未完成） 2.查找可执行进程Pi（未完成但目前剩余资源可满足其需要，这样的进程是能够完成的）Finish[i] = falseNeed[i] &lt;= Work如果没有这样的进程Pi，则跳转到第4步 3.（若有则）Pi一定能完成，并归还其占用的资源，即：Finish[i] = trueWork = Work +Allocation[i]GOTO 第2步，继续查找 4.如果所有进程Pi都是能完成的，即Finish[i]=ture则系统处于安全状态，否则系统处于不安全状态 伪代码: Boolean Found;Work = Available; Finish[1..n] = false;while(true){ //不断的找可执行进程 Found = false; for(i=1; i&lt;=n; i++){ if(Finish[i]==false &amp;&amp; Need[i]&lt;=Work){ Work = Work + Allocation[i];//把放出去的贷款也当做自己的资产 Finish[i] = true; Found = true; } } if(Found==false)break; }for(i=1;i&lt;=n;i++) if(Finish[i]==false)return “deadlock”; //如果有进程是完不成的，那么就是有死锁 示例举个实际例子，假设下面的初始状态： 首先，进入算法第一步，初始化。那么Work = Available = [3 3 2] 首先看P0：P0的Need为[7 4 3]，Available不能满足，于是跳过去 P1的Need为[1 2 2]可以满足，我们令Work = Allocation[P1] + Work此时Work = [5 3 2] 再看P2，P2的Need为[6 0 0]，那么现有资源不满足。跳过去。 看P3，那么看P3，Work可以满足。那么令Work = Allocation[P3] + Work，此时Work = [7 4 3] 再看P4，Work可以满足。令Work = Allocation[P4] + Work ，此时Work = [7 4 5] 到此第一轮循环完毕，由于找到了可用进程，那么进入第二轮循环。 看P0，Work此时可以满足。令Work = Allocation[P0] + Work ，此时Work = [7 5 5] 再看P2，此时Work可以满足P2。令Work = Allocation[P2] + Work ， 此时Work = [10 5 7] 至此，算法运行完毕。找到安全序列 &lt; P1,P3,P4,P0,P2 &gt; ，证明此时没有死锁危险。(安全序列未必唯一) 资源请求算法之前说完了怎么判定当前情况是否安全，下面就是说当有进程新申请资源的时候如何处理。我们将第i个进程请求的资源数记为Requests[i] 算法流程： 1.如果Requests[i]&lt;=Need[i]，则转到第二步。否则，返回异常。这一步是控制进程申请的资源不得大于需要的资源 2.如果Requests[i]&lt;=Available，则转到第三步，否则Pi等待资源。 3.如果满足前两步，那么做如下操作： Available = Available -Requests[i]Allocation = Allocation[i]+Requests[i]Need[i]=Need[i]-Requests[i]调用安全判定算法，检查是否安全if(安全){ 申请成功，资源分配}else{ 申请失败，资源撤回。第三步前几个操作进行逆操作}]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中的slab机制]]></title>
    <url>%2F2019%2F05%2F21%2FLinux%E7%9A%84slab%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[内部碎片和外部碎片外部碎片什么是外部碎片呢？我们通过一个图来解释： 假设这是一段连续的页框，阴影部分表示已经被使用的页框，现在需要申请一个连续的5个页框。这个时候，在这段内存上不能找到连续的5个空闲的页框，就会去另一段内存上去寻找5个连续的页框，这样子，久而久之就形成了页框的浪费。称为外部碎片。内核中使用伙伴算法的迁移机制很好的解决了这种外部碎片。 内部碎片当我们申请几十个字节的时候，内核也是给我们分配一个页，这样在每个页中就形成了很大的浪费。称之为内部碎片。内核中引入了slab机制去尽力的减少这种内部碎片。 slab分配机制slab分配器是基于对象进行管理的，所谓的对象就是内核中的数据结构（例如：task_struct,file_struct 等）。相同类型的对象归为一类，每当要申请这样一个对象时，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免内部碎片。slab分配器并不丢弃已经分配的对象，而是释放并把它们保存在内存中。slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高。 内核中slab的主要数据结构 简要分析下这个图：kmem_cache是一个cache_chain的链表，描述了一个高速缓存，每个高速缓存包含了一个slabs的列表，这通常是一段连续的内存块。存在3种slab：slabs_full(完全分配的slab),slabs_partial(部分分配的slab),slabs_empty(空slab,或者没有对象被分配)。slab是slab分配器的最小单位，在实现上一个slab有一个货多个连续的物理页组成（通常只有一页）。单个slab可以在slab链表之间移动，例如如果一个半满slab被分配了对象后变满了，就要从slabs_partial中被删除，同时插入到slabs_full中去。举例说明：如果有一个名叫inode_cachep的struct kmem_cache节点，它存放了一些inode对象。当内核请求分配一个新的inode对象时，slab分配器就开始工作了： 首先要查看inode_cachep的slabs_partial链表，如果slabs_partial非空，就从中选中一个slab，返回一个指向已分配但未使用的inode结构的指针。完事之后，如果这个slab满了，就把它从slabs_partial中删除，插入到slabs_full中去，结束；如果slabs_partial为空，也就是没有半满的slab，就会到slabs_empty中寻找。如果slabs_empty非空，就选中一个slab，返回一个指向已分配但未使用的inode结构的指针，然后将这个slab从slabs_empty中删除，插入到slabs_partial（或者slab_full）中去，结束；如果slabs_empty也为空，那么没办法，cache内存已经不足，只能新创建一个slab了。接下来我们来分析下slab在内核中数据结构的组织，首先要从kmem_cache这个结构体说起了123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263struct kmem_cache &#123; struct array_cache *array[NR_CPUS];//per_cpu数据，记录了本地高速缓存的信息，也是用于跟踪最近释放的对象，每次分配和释放都要直接访问它。 unsigned int batchcount;//本地高速缓存转入和转出的大批数据数量 unsigned int limit;//本地高速缓存中空闲对象的最大数目 unsigned int shared; unsigned int buffer_size;/*buffer的大小，就是对象的大小*/ u32 reciprocal_buffer_size; unsigned int flags; /* constant flags */ unsigned int num; /* # of objs per slab *//*slab中有多少个对象*/ /* order of pgs per slab (2^n) */ unsigned int gfporder;/*每个slab中有多少个页*/ gfp_t gfpflags; /*与伙伴系统交互时所提供的分配标识*/ size_t colour; /* cache colouring range *//*slab中的着色*/ unsigned int colour_off; /* colour offset */着色的偏移量 struct kmem_cache *slabp_cache; unsigned int slab_size; //slab管理区的大小 unsigned int dflags; /* dynamic flags */ /* constructor func */ void (*ctor)(void *obj); /*构造函数*//* 5) cache creation/removal */ const char *name;/*slab上的名字*/ struct list_head next; //用于将高速缓存连入cache chain/* 6) statistics */ //一些用于调试用的变量#ifdef CONFIG_DEBUG_SLAB unsigned long num_active; unsigned long num_allocations; unsigned long high_mark; unsigned long grown; unsigned long reaped; unsigned long errors; unsigned long max_freeable; unsigned long node_allocs; unsigned long node_frees; unsigned long node_overflow; atomic_t allochit; atomic_t allocmiss; atomic_t freehit; atomic_t freemiss; int obj_offset; int obj_size;#endif /* CONFIG_DEBUG_SLAB */ //用于组织该高速缓存中的slab struct kmem_list3 *nodelists[MAX_NUMNODES];/*最大的内存节点*/&#125;;/* Size description struct for general caches. */struct cache_sizes &#123; size_t cs_size; struct kmem_cache *cs_cachep;#ifdef CONFIG_ZONE_DMA struct kmem_cache *cs_dmacachep;#endif&#125;; 由上面的总图可知，一个核心的数据结构就是kmem_list3，它描述了slab描述符的状态。123456789101112131415struct kmem_list3 &#123;/*三个链表中存的是一个高速缓存slab*//*在这三个链表中存放的是cache*/ struct list_head slabs_partial; //包含空闲对象和已经分配对象的slab描述符 struct list_head slabs_full;//只包含非空闲的slab描述符 struct list_head slabs_free;//只包含空闲的slab描述符 unsigned long free_objects; /*高速缓存中空闲对象的个数*/ unsigned int free_limit; //空闲对象的上限 unsigned int colour_next; /* Per-node cache coloring *//*即将要着色的下一个*/ spinlock_t list_lock; struct array_cache *shared; /* shared per node */ struct array_cache **alien; /* on other nodes */ unsigned long next_reap; /* updated without locking *//**/ int free_touched; /* updated without locking */&#125;; 接下来介绍描述单个slab的结构struct slab12345678struct slab &#123; struct list_head list; //用于将slab连入keme_list3的链表 unsigned long colouroff; //该slab的着色偏移 void *s_mem; /* 指向slab中的第一个对象*/ unsigned int inuse; /* num of objs active in slab */已经分配出去的对象 kmem_bufctl_t free; //下一个空闲对象的下标 unsigned short nodeid; //节点标识符&#125;; 在kmem_cache中还有一个重要的数据结构struct array_cache.这是一个指针数组，数组的元素是系统的cpu的个数。该结构用来描述每个cpu的高速缓存，它的主要作用是减少smp系统中对于自旋锁的竞争。 实际上，每次分配内存都是直接与本地cpu高速缓存进行交互，只有当其空闲内存不足时，才会从keme_list中的slab中引入一部分对象到本地高速缓存中，而keme_list中的空闲对象也不足时，那么就要从伙伴系统中引入新的页来建立新的slab了。123456789101112struct array_cache &#123; unsigned int avail;/*当前cpu上有多少个可用的对象*/ unsigned int limit;/*per_cpu里面最大的对象的个数，当超过这个值时，将对象返回给伙伴系统*/ unsigned int batchcount;/*一次转入和转出的对象数量*/ unsigned int touched;/*标示本地cpu最近是否被使用*/ spinlock_t lock;/*自旋锁*/ void *entry[]; /* * Must have this definition in here for the proper * alignment of array_cache. Also simplifies accessing * the entries. */&#125;; 对上面提到的各个数据结构做一个总结，用下图来描述： 关于slab分配器的API下面看一下slab分配器的接口——看看slab缓存是如何创建、撤销以及如何从缓存中分配一个对象的。一个新的kmem_cache通过kmem_cache_create()函数来创建：123struct kmem_cache *kmem_cache_create( const char *name, size_t size, size_t align, unsigned long flags， void (*ctor)(void*)); *name是一个字符串，存放kmem_cache缓存的名字；size是缓存所存放的对象的大小；align是slab内第一个对象的偏移；flag是可选的配置项，用来控制缓存的行为。最后一个参数ctor是对象的构造函数，一般是不需要的，以NULL来代替。kmem_cache_create()成功执行之后会返回一个指向所创建的缓存的指针，否则返回NULL。kmem_cache_create()可能会引起阻塞（睡眠），因此不能在中断上下文中使用。 撤销一个kmem_cache则是通过kmem_cache_destroy()函数：1int kmem_cache_destroy( struct kmem_cache *cachep); 该函数成功则返回0，失败返回非零值。调用kmem_cache_destroy()之前应该满足下面几个条件：首先，cachep所指向的缓存中所有slab都为空闲，否则的话是不可以撤销的；其次在调用kmem_cache_destroy()过程中以及调用之后，调用者需要确保不会再访问这个缓存；最后，该函数也可能会引起阻塞，因此不能在中断上下文中使用。可以通过下面函数来从kmem_cache中分配一个对象： void kmem_cache_alloc(struct kmem_cache cachep, gfp_t flags);这个函数从cachep指定的缓存中返回一个指向对象的指针。如果缓存中所有slab都是满的，那么slab分配器会通过调用kmem_getpages()创建一个新的slab。 释放一个对象的函数如下：1void kmem_cache_free(struct kmem_cache* cachep, void* objp); 这个函数是将被释放的对象返还给先前的slab，其实就是将cachep中的对象objp标记为空闲而已 使用以上的API写内核模块，生成自己的slab高速缓存。其实到了这里，应该去分析以上函数的源码，但是几次奋起分析，都被打趴在地。所以就写个内核模块，鼓励下自己吧。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;linux/autoconf.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/slab.h&gt;MODULE_AUTHOR(&quot;wangzhangjun&quot;);MODULE_DESCRIPTION(&quot;slab test module&quot;);static struct kmem_cache *test_cachep = NULL;struct slab_test&#123; int val;&#125;;void fun_ctor(struct slab_test *object , struct kmem_cache *cachep , unsigned long flags )&#123; printk(KERN_INFO &quot;ctor fuction ...\n&quot;); object-&gt;val = 1;&#125;static int __init slab_init(void)&#123; struct slab_test *object = NULL;//slab的一个对象 printk(KERN_INFO &quot;slab_init\n&quot;); test_cachep = kmem_cache_create(&quot;test_cachep&quot;,sizeof(struct slab_test)*3,0,SLAB_HWCACHE_ALIGN,fun_ctor); if(NULL == test_cachep) return -ENOMEM ; printk(KERN_INFO &quot;Cache name is %s\n&quot;,kmem_cache_name(test_cachep));//获取高速缓存的名称 printk(KERN_INFO &quot;Cache object size is %d\n&quot;,kmem_cache_size(test_cachep));//获取高速缓存的大小 object = kmem_cache_alloc(test_cachep,GFP_KERNEL);//从高速缓存中分配一个对象 if(object) &#123; printk(KERN_INFO &quot;alloc one val = %d\n&quot;,object-&gt;val); kmem_cache_free( test_cachep, object );//归还对象到高速缓存 //这句话的意思是虽然对象归还到了高速缓存中，但是高速缓存中的值没有做修改 //只是修改了一些它的状态。 printk(KERN_INFO &quot;alloc three val = %d\n&quot;,object-&gt;val); object = NULL; &#125;else return -ENOMEM; return 0;&#125;static void __exit slab_clean(void)&#123; printk(KERN_INFO &quot;slab_clean\n&quot;); if(test_cachep) kmem_cache_destroy(test_cachep);//调用这个函数时test_cachep所指向的缓存中所有的slab都要为空&#125;module_init(slab_init);module_exit(slab_clean);MODULE_LICENSE(&quot;GPL&quot;); 我们结合结果来分析下这个内核模块：这是dmesg的结果，可以发现我们自己创建的高速缓存的名字test_cachep,还有每个对象的大小。 还有构造函数修改了对象里面的值，至于为什么构造函数会出现这么多次，可能是因为，这个函数被注册了之后，系统的其他地方也会调用这个函数。在这里可以分析源码，当调用keme_cache_create()的时候是没有调用对象的构造函数的，调用kmem_cache_create()并没有分配slab,而是在创建对象的时候发现没有空闲对象，在分配对象的时候，会调用构造函数初始化对象。另外结合上面的代码可以发现，alloc three val是在kmem_cache_free之后打印的，但是它的值依然可以被打印出来，这充分说明了，slab这种机制是在将某个对象使用完之后，就其缓存起来，它还是切切实实的存在于内存中。再结合/proc/slabinfo的信息看我们自己创建的slab高速缓存 可以发现名字为test_cachep的高速缓存，每个对象的大小（objsize）是16,和上面dmesg看到的值相同，objperslab（每个slab中的对象时202），pagesperslab（每个slab中包含的页数），可以知道objsize * objperslab &lt; pagesperslab。 总结目前只是对slab机制的原理有了一个感性的认识，对于这部分相关的源码涉及到着色以及内存对齐等细节。看的不是很清楚，后面还需要仔细研究。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中new操作符]]></title>
    <url>%2F2019%2F05%2F21%2Fcpp%E4%B8%ADnew%E6%93%8D%E4%BD%9C%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[new 操作符（new operator）人们有时好像喜欢有益使C++语言的术语难以理解。比方说new操作符（new operator）和operator new的差别。 当你写这种代码：string *ps = new string(“Memory Management”);你使用的new是new操作符。这个操作符就象sizeof一样是语言内置的。你不能改变它的含义，它的功能总是一样的。它要完毕的功能分成两部分。第一部分是分配足够的内存以便容纳所需类型的对象。 第二部分是它调用构造函数初始化内存中的对象。new操作符总是做这两件事情，你不能以不论什么方式改变它的行为。（总结就是，new操作符做两件事，分配内存+调用构造函数初始化。 你不能改变它的行为。） operator new你所能改变的是怎样为对象分配内存。 new操作符调用一个函数来完毕必需的内存分配，你可以重写或重载这个函数来改变它的行为。new操作符为分配内存所调用函数的名字是operator new。函数operator new 通常这样声明：void operator new(size_t size);返回值类型是void，由于这个函数返回一个未经处理（raw）的指针。未初始化的内存。（假设你喜欢。你能写一种operator new函数，在返回一个指针之前可以初始化内存以存储一些数值，可是一般不这么做。）參数size_t确定分配多少内存。 你能添加额外的參数重载函数operator new，可是第一个參数类型必须是size_t。 （有关operator new很多其它的信息參见Effective C++ 条款8至条款10。） 你一般不会直接调用operator new，可是一旦这么做。你能够象调用其他函数一样调用它：void *rawMemory = operator new(sizeof(string));操作符operator new将返回一个指针，指向一块足够容纳一个string类型对象的内存。就象malloc一样，operator new的职责仅仅是分配内存。 它对构造函数一无所知。operator new所了解的是内存分配。把operator new 返回的未经处理的指针传递给一个对象是new操作符的工作。当你的编译器遇见这种语句：1string *ps = new string(&quot;Memory Management&quot;); 它生成的代码或多或少与以下的代码相似（很多其它的细节见Effective C++条款8和条款10。还有我的文章Counting object里的凝视。）：1234void *memory = operator new(sizeof(string)); // 得到未经处理的内存，为String对象call string::string(&quot;Memory Management&quot;) on *memory; // 内存中的对象string *ps = static_cast&lt;string*&gt;(memory); // 使ps指针指向新的对象 注意第二步包括了构造函数的调用，你做为一个程序猿被禁止这样去做。你的编译器则没有这个约束，它能够做它想做的一切。因此假设你想建立一个堆对象就必须用new操作符。不能直接调用构造函数来初始化对象。（总结：operator new是用来分配内存的函数，为new操作符调用。能够被重载（有限制）） placement new有时你确实想直接调用构造函数。在一个已存在的对象上调用构造函数是没有意义的，由于构造函数用来初始化对象。而一个对象只能在给它初值时被初始化一次。 可是有时你有一些已经被分配可是尚未处理的的(raw)内存，你须要在这些内存中构造一个对象。你能够使用一个特殊的operator new ，它被称为placement new。 以下的样例是placement new怎样使用，考虑一下：12345678910class Widget &#123; public: Widget(int widgetSize); ...&#125;;Widget * constructWidgetInBuffer(void *buffer,int widgetSize)&#123; return new (buffer) Widget(widgetSize);&#125; 这个函数返回一个指针。指向一个Widget对象，对象在转递给函数的buffer里分配。当程序使用共享内存或memory-mapped I/O时这个函数可能实用，由于在这样程序里对象必须被放置在一个确定地址上或一块被例程分配的内存里。（參见条款4,一个怎样使用placement new的一个不同样例。） 在constructWidgetInBuffer里面。返回的表达式是： new (buffer) Widget(widgetSize) 这初看上去有些陌生，可是它是new操作符的一个使用方法，须要使用一个额外的变量（buffer）。当new操作符隐含调用operator new函数时。把这个变量传递给它。被调用的operator new函数除了带有强制的參数size_t外，还必须接受void*指针參数。指向构造对象占用的内存空间。这个operator new就是placement new，它看上去象这样：1234void * operator new(size_t, void *location)&#123; return location;&#125; 这可能比你期望的要简单，可是这就是placement new须要做的事情。毕竟operator new的目的是为对象分配内存然后返回指向该内存的指针。在使用placement new的情况下，调用者已经获得了指向内存的指针。由于调用者知道对象应该放在哪里。placement new必须做的就是返回转递给它的指针。（没实用的（可是强制的）參数size_t没有名字，以防止编译器发出警告说它没有被使用。见条款6。） placement new是标准C++库的一部分。为了使用placement new。你必须使用语句#include （或者假设你的编译器还不支持这新风格的头文件名称）。 （总结：placement new是一种特殊的operator new，作用于一块已分配但未处理或未初始化的raw内存） 小结让我们从placement new回来片刻，看看new操作符（new operator）与operator new的关系，（new操作符调用operator new）你想在堆上建立一个对象，应该用new操作符。它既分配内存又为对象调用构造函数。假设你只想分配内存，就应该调用operator new函数；它不会调用构造函数。假设你想定制自己的在堆对象被建立时的内存分配过程，你应该写你自己的operator new函数。然后使用new操作符，new操作符会调用你定制的operator new。假设你想在一块已经获得指针的内存里建立一个对象。应该用placement new。 Deletion and Memory Deallocation为了避免内存泄漏，每一个动态内存分配必须与一个等同相反的deallocation相应。 函数operator delete与delete操作符的关系与operator new与new操作符的关系一样。当你看到这些代码：123string *ps;...delete ps; // 使用delete 操作符 你的编译器会生成代码来析构对象并释放对象占有的内存。 Operator delete用来释放内存。它被这样声明：void operator delete(void *memoryToBeDeallocated);因此， delete ps; 导致编译器生成类似于这种代码：12ps-&gt;~string(); // call the object&apos;s dtoroperator delete(ps); // deallocate the memory the object occupied 这有一个隐含的意思是假设你仅仅想处理未被初始化的内存，你应该绕过new和delete操作符，而调用operator new 获得内存和operator delete释放内存给系统：12345void *buffer = operator new(50*sizeof(char)); // 分配足够的内存以容纳50个char//没有调用构造函数...operator delete(buffer); // 释放内存// 没有调用析构函数 这与在C中调用malloc和free等同。 2.placement new建立的对象怎样释放？假设你用placement new在内存中建立对象，你应该避免在该内存中用delete操作符。 由于delete操作符调用operator delete来释放内存，可是包括对象的内存最初不是被operator new分配的。placement new仅仅是返回转递给它的指针。谁知道这个指针来自何方？而你应该显式调用对象的析构函数来解除构造函数的影响：12345678910111213141516// 在共享内存中分配和释放内存的函数 void * mallocShared(size_t size);void freeShared(void *memory);void *sharedMemory = mallocShared(sizeof(Widget));Widget *pw = // 如上所看到的,constructWidgetInBuffer(sharedMemory, 10); // 使用// placement new ...delete pw; // 结果不确定! 共享内存来自// mallocShared, 而不是operator newpw-&gt;~Widget(); // 正确。 析构 pw指向的Widget，// 可是没有释放//包括Widget的内存freeShared(pw); // 正确。 释放pw指向的共享内存// 可是没有调用析构函数 如上例所看到的，假设传递给placement new的raw内存是自己动态分配的（通过一些不经常使用的方法），假设你希望避免内存泄漏，你必须释放它。（參见我的文章Counting objects里面关于placement delete的凝视。） 数组到眼下为止一切顺利。可是还得接着走。 到眼下为止我们所測试的都是一次建立一个对象。 如何分配数组？会发生什么？string *ps = new string[10]; // allocate an array of objects被使用的new仍然是new操作符，可是建立数组时new操作符的行为与单个对象建立有少许不同。第一是内存不再用operator new分配，取代以等同的数组分配函数，叫做operator new[]（常常被称为array new）。 它与operator new一样能被重载。 这就同意你控制数组的内存分配。就象你能控制单个对象内存分配一样（可是有一些限制性说明，參见Effective C++ 条款8）。 （operator new[]对于C++来说是一个比較新的东西。所以你的编译器可能不支持它。假设它不支持。不管在数组中的对象类型是什么。全局operator new将被用来给每一个数组分配内存。 在这种编译器下定制数组内存分配是困难的。由于它须要重写全局operator new。这可不是一个能轻易接受的任务。 缺省情况下，全局operator new处理程序中全部的动态内存分配，所以它行为的不论什么改变都将有深入和普遍的影响。并且全局operator new有一个正常的签名（normal signature）(也就单一的參数size_t。參见Effective C++条款9)。所以假设你 决定用自己的方法声明它，你立马使你的程序与其他库不兼容基于这些考虑，在缺乏operator new[]支持的编译器里为数组定制内存管理不是一个合理的设计。） 第二个不同是new操作符调用构造函数的数量。对于数组，在数组里的每个对象的构造函数都必须被调用：string *ps = new string[10]; // 调用operator new[]为10个string对象分配内存, // 然后对每一个数组元素调用string对象的缺省构造函数。相同当delete操作符用于数组时，它为每一个数组元素调用析构函数，然后调用operator delete来释放内存。（buxizhizhou530注：这里应该是operator delete[]吧）就象你能替换或重载operator delete一样，你也替换或重载operator delete[]。 在它们重载的方法上有一些限制。 请參考优秀的C++教材。 （总结：数组时，两个不同点，一时调用operator new[]函数，二是new操作符调用构造函数的数量不同。） 总结new和delete操作符是内置的，其行为不受你的控制。凡是它们调用的内存分配和释放函数则能够控制。当你想定制new和delete操作符的行为时，请记住你不能真的做到这一点。你仅仅能改变它们为完毕它们的功能所採取的方法，而它们所完毕的功能则被语言固定下来。不能改变。（You can modify how they do what they do, but what they do is fixed by the language）]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核中cache的实现]]></title>
    <url>%2F2019%2F05%2F20%2FLinux%E5%86%85%E6%A0%B8%E4%B8%ADcache%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言自从诞生以来，Linux 就被不断完善和普及，目前它已经成为主流通用操作系统之一，使用得非常广泛，它与 Windows、UNIX 一起占据了操作系统领域几乎所有的市场份额。特别是在高性能计算领域，Linux 已经成为一个占主导地位的操作系统，在2005年6月全球TOP500 计算机中，有 301 台部署的是 Linux 操作系统。因此，研究和使用 Linux 已经成为开发者的不可回避的问题了。 下面我们介绍一下 Linux 内核中文件 Cache 管理的机制。本文以 2.6 系列内核为基准，主要讲述工作原理、数据结构和算法，不涉及具体代码。 操作系统和文件 Cache 管理操作系统是计算机上最重要的系统软件，它负责管理各种物理资源，并向应用程序提供各种抽象接口以便其使用这些物理资源。从应用程序的角度看，操作系统提供了一个统一的虚拟机，在该虚拟机中没有各种机器的具体细节，只有进程、文件、地址空间以及进程间通信等逻辑概念。这种抽象虚拟机使得应用程序的开发变得相对容易：开发者只需与虚拟机中的各种逻辑对象交互，而不需要了解各种机器的具体细节。此外，这些抽象的逻辑对象使得操作系统能够很容易隔离并保护各个应用程序。 对于存储设备上的数据，操作系统向应用程序提供的逻辑概念就是”文件”。应用程序要存储或访问数据时，只需读或者写”文件”的一维地址空间即可，而这个地址空间与存储设备上存储块之间的对应关系则由操作系统维护。 在 Linux 操作系统中，当应用程序需要读取文件中的数据时，操作系统先分配一些内存，将数据从存储设备读入到这些内存中，然后再将数据分发给应用程序；当需要往文件中写数据时，操作系统先分配内存接收用户数据，然后再将数据从内存写到磁盘上。文件 Cache 管理指的就是对这些由操作系统分配，并用来存储文件数据的内存的管理。 Cache 管理的优劣通过两个指标衡量：一是 Cache 命中率，Cache 命中时数据可以直接从内存中获取，不再需要访问低速外设，因而可以显著提高性能；二是有效 Cache 的比率，有效 Cache 是指真正会被访问到的 Cache 项，如果有效 Cache 的比率偏低，则相当部分磁盘带宽会被浪费到读取无用 Cache 上，而且无用 Cache 会间接导致系统内存紧张，最后可能会严重影响性能。 下面分别介绍文件 Cache 管理在 Linux 操作系统中的地位和作用、Linux 中文件 Cache相关的数据结构、Linux 中文件 Cache 的预读和替换、Linux 中文件 Cache 相关 API 及其实现。 文件 Cache 的地位和作用文件 Cache 是文件数据在内存中的副本，因此文件 Cache 管理与内存管理系统和文件系统都相关：一方面文件 Cache 作为物理内存的一部分，需要参与物理内存的分配回收过程，另一方面文件 Cache 中的数据来源于存储设备上的文件，需要通过文件系统与存储设备进行读写交互。从操作系统的角度考虑，文件 Cache 可以看做是内存管理系统与文件系统之间的联系纽带。因此，文件 Cache 管理是操作系统的一个重要组成部分，它的性能直接影响着文件系统和内存管理系统的性能。 图1描述了 Linux 操作系统中文件 Cache 管理与内存管理以及文件系统的关系示意图。从图中可以看到，在 Linux 中，具体文件系统，如 ext2/ext3、jfs、ntfs 等，负责在文件 Cache和存储设备之间交换数据，位于具体文件系统之上的虚拟文件系统VFS负责在应用程序和文件 Cache 之间通过 read/write 等接口交换数据，而内存管理系统负责文件 Cache 的分配和回收，同时虚拟内存管理系统(VMM)则允许应用程序和文件 Cache 之间通过 memory map的方式交换数据。可见，在 Linux 系统中，文件 Cache 是内存管理系统、文件系统以及应用程序之间的一个联系枢纽。 文件 Cache 相关数据结构在 Linux 的实现中，文件 Cache 分为两个层面，一是 Page Cache，另一个 Buffer Cache，每一个 Page Cache 包含若干 Buffer Cache。内存管理系统和 VFS 只与 Page Cache 交互，内存管理系统负责维护每项 Page Cache 的分配和回收，同时在使用 memory map 方式访问时负责建立映射；VFS 负责 Page Cache 与用户空间的数据交换。而具体文件系统则一般只与 Buffer Cache 交互，它们负责在外围存储设备和 Buffer Cache 之间交换数据。Page Cache、Buffer Cache、文件以及磁盘之间的关系如图 2 所示，Page 结构和 buffer_head 数据结构的关系如图 3 所示。在上述两个图中，假定了 Page 的大小是 4K，磁盘块的大小是 1K。本文所讲述的，主要是指对 Page Cache 的管理。 在 Linux 内核中，文件的每个数据块最多只能对应一个 Page Cache 项，它通过两个数据结构来管理这些 Cache 项，一个是 radix tree，另一个是双向链表。Radix tree 是一种搜索树，Linux 内核利用这个数据结构来通过文件内偏移快速定位 Cache 项，图 4 是 radix tree的一个示意图，该 radix tree 的分叉为4(22)，树高为4，用来快速定位8位文件内偏移。Linux(2.6.7) 内核中的分叉为 64(26)，树高为 6(64位系统)或者 11(32位系统)，用来快速定位 32 位或者 64 位偏移，radix tree 中的每一个叶子节点指向文件内相应偏移所对应的Cache项。 另一个数据结构是双向链表，Linux内核为每一片物理内存区域(zone)维护active_list和inactive_list两个双向链表，这两个list主要用来实现物理内存的回收。这两个链表上除了文件Cache之外，还包括其它匿名(Anonymous)内存，如进程堆栈等。 文件Cache的预读和替换Linux内核中文件预读算法的具体过程是这样的：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面(不少于一个页面，通常是三个页面)，这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的group中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读group扩大一倍，并让底层文件系统读入group中剩下尚不在Cache中的文件数据块，这时的预读称为异步预读。无论第二次读请求是否命中，系统都要更新当前预读group的大小。此外，系统中定义了一个window，它包括前一次预读的group和本次预读的group。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读window中，这时继续进行异步预读并更新相应的window和group；第二种情况是所请求的页面处于预读window之外，这时系统就要进行同步预读并重置相应的window和group。图5是Linux内核预读机制的一个示意图，其中a是某次读操作之前的情况，b是读操作所请求页面不在window中的情况，而c是读操作所请求页面在window中的情况。 Linux内核中文件Cache替换的具体过程是这样的：刚刚分配的Cache项链入到inactive_list头部，并将其状态设置为active，当内存不够需要回收Cache时，系统首先从尾部开始反向扫描active_list并将状态不是referenced的项链入到inactive_list的头部，然后系统反向扫描inactive_list，如果所扫描的项的处于合适的状态就回收该项，直到回收了足够数目的Cache项。Cache替换算法如图6的算法描述伪码所示。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Mark_Accessed(b) &#123; if b.state==(UNACTIVE &amp;&amp; UNREFERENCE) b.state = REFERENCE else if b.state == (UNACTIVE &amp;&amp; REFERENCE) &#123; b.state = (ACTIVE &amp;&amp; UNREFERENCE) Add X to tail of active_list &#125; else if b.state == (ACTIVE &amp;&amp; UNREFERENCE) b.state = (ACTIVE &amp;&amp; REFERENCE)&#125;Reclaim() &#123; if active_list not empty and scan_num&lt;MAX_SCAN1 &#123; X = head of active_list if (X.state &amp; REFERENCE) == 0 Add X to tail of inactive_list else &#123; X.state &amp;= ~REFERENCEMove X to tail of active_list &#125; scan_num++ &#125; scan_num = 0 if inactive_list not emptry and scan_num &lt; MAX_SCAN2 &#123; X = head of inactive_list if (X.state &amp; REFERENCE) == 0 return X else &#123; X.state = ACTIVE | UNREFERENCEMove X to tail of active_list &#125; scan_num++ &#125; return NULL&#125;Access(b)&#123; if b is not in cache &#123; if slot X free put b into X else &#123; X=Reclaim() put b into X &#125; Add X to tail of inactive_list &#125; Mark_Accessed(X)&#125; 文件Cache相关API及其实现Linux内核中与文件Cache操作相关的API有很多，按其使用方式可以分成两类：一类是以拷贝方式操作的相关接口， 如read/write/sendfile等，其中sendfile在2.6系列的内核中已经不再支持；另一类是以地址映射方式操作的相关接口，如mmap等。 第一种类型的API在不同文件的Cache之间或者Cache与应用程序所提供的用户空间buffer之间拷贝数据，其实现原理如图7所示。 第二种类型的API将Cache项映射到用户空间，使得应用程序可以像使用内存指针一样访问文件，Memory map访问Cache的方式在内核中是采用请求页面机制实现的，其工作过程如图8所示。 首先，应用程序调用mmap（图中1），陷入到内核中后调用do_mmap_pgoff（图中2）。该函数从应用程序的地址空间中分配一段区域作为映射的内存地址，并使用一个VMA（vm_area_struct）结构代表该区域，之后就返回到应用程序（图中3）。当应用程序访问mmap所返回的地址指针时（图中4），由于虚实映射尚未建立，会触发缺页中断（图中5）。之后系统会调用缺页中断处理函数（图中6），在缺页中断处理函数中，内核通过相应区域的VMA结构判断出该区域属于文件映射，于是调用具体文件系统的接口读入相应的Page Cache项（图中7、8、9），并填写相应的虚实映射表。经过这些步骤之后，应用程序就可以正常访问相应的内存区域了。 小结文件Cache管理是Linux操作系统的一个重要组成部分，同时也是研究领域一个很热门的研究方向。目前，Linux内核在这个方面的工作集中在开发更有效的Cache替换算法上，如LIRS(其变种ClockPro)、ARC等。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux session 浅谈]]></title>
    <url>%2F2019%2F05%2F20%2FLinux_session%E6%B5%85%E8%B0%88%2F</url>
    <content type="text"><![CDATA[session的概念：在web中的session概念，维系是基于凭证，在web中一般用session保存的是登录的信息，当客户端每次进行请求的时候，都会在请求的数据后面加上session ，这样 服务端就可以知道该用户是什么用户，以及他所具有的权限。当用户退出，或长时间没有交互，则session无效（该凭证已经失效），需要重新登录。 linux中的session跟这个有点类似，也是在一个用户登录到主机，那么就建立了一个session，但是它的维系是基于连接的，那么该对于这个会话存在两种的维持方法 本地连接：就是说用户是在主机本机上进行的登录，直接通过键盘和屏幕和主机进行交互。 远程连接：用户通过互联网进行连接，比如基于ssh，连接都是经过加密的。 session是一个或多个进程组的集合。 session的创建:创建有两种方法： 用户登录就是一个会话的开始，登录之后，用户会得到一个与终端相关联的进程，该进程就是该会话的leader，会话的id就是该进程的id。 是在程序中调用pid_t setsid（void），如果调用此函数的进程不是一个进程组的组长，则此函数就会创建一个新的会话，它将做以下三件事：a. 该进程是新会话的首进程（session leader），也是该会话中唯一的进程； b. 该进程成为一个新进程组的组长进程，新进程组id是该进程id；c. 该进程是没有控制终端的。如果该进程原来是有一个控制中断的，但是这种联系也会被打断。因此呢，我们在新建一个session的时候就要记得对输入输出进程重定向哦。 在调用setsid（）的时候呢，要注意如果caller process是进程组组长，那么函数将会返回出错哦，所以一般偶是先fork一个进程后，在调用该函数，保证了caller process不是进程组组长哦。session的退出:对于session的退出会进行很多的操作，且听我慢慢说来：当session 中leader进程退出，将导致它所连接终端被hangup，这就意味着该会话结束。如果是像ssh这种远程连接，可以通过断开网络连接来使（伪）终端hangup，这将使得leader进程收到SIGHUP信号而退出。如果是pty，其本身就是随着会话建立而创建的，会话结束，那么该终端也会被销毁的。而如果是tty则不会，因为该设备是在系统初始化的时候创建的（请看前一篇博客），并不是依赖该会话建立的，所以当该会话退出，tty仍然是存在的。只是init进程在会话结束后，就会重启getty来监听该tty。 但是对于会话的结束，并不会意味着该会话的所以进程都结束。 对于daemon进程，在会话中创建，但是不依赖于会话，是常驻在后台的进程。 具体来说当终端hangup时候，内核会有如下两个动作： 想对应会话的leader进程发送SIGHUP信号，一般来说leader是一个shell，它收到SIGHUP信号后并不是马上退出，而hi想他启动的子进程都各自发送一个SIGHUP,将他们都杀死后，自己才退出，但是如果当该leader进程主动退出，而导致的终端hangup那么就不会发送SIGHUP信号给子进程了。 因为session都将消亡了，那么它将控制终端修改为不可读不可写的文件。所以呢，会话退出后没有消亡的进程是不能控制终端的。 如果又想要某个进程称为常驻后台进程，不随session退出而退出，有下面几个方法： 避免shell发送SIGHUP信号: a. 主动调用exit，而不是直接断开终端；b. 两次fork，因为shell只给子进程发送SIGHUP信号，不给孙进程发送。 忽略SIGHUP信号：进程捕捉到该信号将该信号忽略就行了。 通过上面说到的setsid()系统调用，那么该调用进程将会退出该session而建立一个新的session。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解计算机系统之虚拟存储器]]></title>
    <url>%2F2019%2F05%2F20%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E4%B9%8B%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%99%A8%2F</url>
    <content type="text"><![CDATA[进程提供给应用程序的关键抽象： 一个独立的逻辑控制流，它提供一个假象，好像我们的程序独占地使用处理器。一个私有的地址空间，它提供一个假象，好像我们的程序独占地使用存储器系统. 虚拟存储器虚拟存储器是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。通过一个很清晰的机制，虚拟存储器提供了三个重要的能力： (1)它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据，通过这种方式，它高效地使用了主存。 (2)它为每个进程提供了一致的地址空间，从而简化了存储器管理。 (3)它保护了每个进程的地址空间不被其他进程破坏。 物理和虚拟寻址物理寻址计算机系统的主存被组织成一个由M个连续的字节大小的单元组成的数组。每字节都有一个唯一的物理地址(Physical Address，PA)。第一个字节的地址为0，接下来的字节的地址为1，再下一个为2，依此类推。给定这种简单的结构，CPU访问存储器的最自然的方式就是使用物理地址，我们把这种方式称为物理寻址。 虚拟寻址使用虚拟寻址时，CPU通过生成一个虚拟地址(Virtual Address，VA)来访问主存，这个虚拟地址在被送到存储器之前先转换成适当的物理地址。将一个虚拟地址转换为物理地址的任务叫做地址翻译(address translation)。就像异常处理一样，地址翻译需要CPU硬件和操作系统之间的紧密合作。CPU芯片上叫做存储器管理单元(Memory Management Unit，MMU)的专用硬件，利用存放在主存中的查询表来动态翻译虚拟地址，该表的内容是由操作系统管理。 地址空间地址空间(adress space)是一个非整数地址的有序集合：{0,1,2,…} 如果地址空间中的整数是连续的，那么我们说它是一个线性地址空间(linear address space)。在一个带虚拟存储器的系统中，CPU从一个有N = 2 ^ n个地址空间中生成虚拟地址，这个地址空间称为虚拟地址空间(virtual address space)：{0,1,2,3,…,N-1} 一个地址空间的大小是由表示最大地址所需要的倍数来描述的。例如，一个包含N=2^n个地址的虚拟地址空间叫做一个n位地址空间。现在系统典型地支持32位或者64位虚拟地址空间是。 一个系统还有一个物理地址空间(physical addresss space)，它与系统中物理存储器的M字节相对应：{0,1,2,…M-1} M不要求是2的幂，但是为了简化讨论，我们假设M = 2 ^ m。 地址空间的概念是很重要的，因为它清楚地区分了数据对象(字节)和它们的属性(地址)。一旦认识到了这种区别，那么我们就可以将其推广，允许每个数据对象有多个独立的地址，其中每个地址都选自一个不同的地址空间(不连续的意思吗？)。这就是虚拟存储器的基本思想。主存中每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。(这段没怎么看懂~~) 虚拟存储器作为缓存的工具概念上而言，虚拟存储器(VM)被组织为一个由存放在磁盘上N个连续的字节大小的单元组成的数组。每个字节都有一个唯一的虚拟地址，这个唯一的虚拟地址是作为到数组的索引的。磁盘上的数组的内容被缓存在主存中。和存储器层次结构中其他缓存一样，磁盘(较低层)上的数据被分割成块，这些块作为磁盘和主存(较高层)之间的传输单元。VM系统通过将虚拟存储器分割称为虚拟页(Vitual Page，VP)的大小固定的块来处理这个问题。每个虚拟页的大小为P = 2 ^ n字节。类似地，物理存储器被分割为物理页(Physical Page，PP)，大小也为P字节(物理页也称为页帧(page frame))。 在任意时刻，虚拟页面的集合都分为三个不相交的子集： 未分配的：VM系统还未分配(或者创建)的页。未分配的块没有任何数据和它们相关联，因此也就不占用任何磁盘空间。(没有调用malloc或者mmap的)缓存的：当前缓存在物理存储中的已分配页。(已经调用malloc和mmap的，在程序中正在引用的)未缓存的：没有缓存在物理存储器中的已分配页。(已经调用malloc和mmap的，在程序中还没有被引用的) 页表同任何缓存一样，虚拟存储器系统必须有某种方法来判定一个虚拟页是否存放在DRAM中的某个地方。如果是，系统还必须确定这个虚拟页存放在哪个物理页中。如果不命中，系统必须判断这个虚拟页存放在磁盘的哪个位置，在物理存储器中选择一个牺牲页，并将虚拟页从磁盘拷贝到DRAM中，替换这个牺牲页。 这些功能是由许多软硬件联合提供的，包括操作系统软件，MMU(存储器管理单元)中地址翻译硬件和一个存放在物理存储器中叫做页表(page table)的数据结构，页表将虚拟页映射到物理页。页表就是一个页表条目(Page Table Entry，PTE)的数组。 Linux虚拟存储器系统Linux为每个进程维持了一个单独的虚拟地址空间。 内核虚拟存储器包含内核中的代码和数据结构。内核虚拟存储器的某些区域被映射到所有进程共享的物理页面。例如，每个进程共享内核的代码和全局数据结构。 Linux虚拟存储器区域(Windows下也有区域的概念)Linux将虚拟存储器组织成一些区域(也叫做段)的集合。一个区域(area)就是已经存在着的(已分配的)虚拟存储器的连续片(chunk)，这些页是以某种方式相关联的。例如，代码段、数据段、堆、共享库段，以及用户栈都不同的区域。每个存在的虚拟页面保存在某个区域中，而不属于某个区域的虚拟页是不存在的，并且不能被进程引用。区域的概念很重要，因为它允许虚拟地址空间有间隙。内核不用记录那些不存在的虚拟页，而这样的页也不占用存储器。磁盘或者内核本身的任何额外资源。 内核为系统中的每个进程维护一个单独的任务结构(源代码中的task_struct)。任务结构中的元素包含或者指向内核运行该进程所需要的所有信息(例如，PID，指向用户栈的指针、可执行的目标文件的名字以及程序计数器)。 task_struct中的一个条目指向mm_struct，它描述了虚拟存储器中的当前状态。其中pgd指向第一级页表(页全局目录)的基址，而mmap指向一个vm_area_struct(区域结构)的链表，其中每个vm_area_structs都描述了当前虚拟地址空间的一个区域(area)。当内核运行这个进程时，它就将pgd存放在CR3控制寄存器中。 一个具体区域结构包含下面的字段： vm_start：指向这个区域的起始处。vm_end：指向这个区域的结束处。vm_prot：描述这个区域的内包含的所有页的读写许可权限。vm_flags：描述这个区域内页面是与其他进程共享的，还是这个进程私有的(还描述了其他一些信息)。vm_next：指向链表中下一个区域结构。 存储器映射(Windows下也有类似的机制，名叫内存映射)Linux(以及其他一些形式的Unix)通过将一个虚拟存储器区域与一个磁盘上的对象(object)关联起来，以初始化这个虚拟存储器区域的内容，这个过程称为存储器映射(memory mapping)。虚拟存储器区域可以映射到两种类型的对象的一种：(1)Unix文件上的普通文件：一个区域可以映射到一个普通磁盘文件的连续部分，例如一个可执行目标文件。文件区(section)被分成页大小的片，每一片包含一个虚拟页面的初始化内容。因为按需进行页面高度，所以这些虚拟页面没有实际进行物理存储器，直到CPU第一次引用到页面(即发射一个虚拟地址，落在地址空间这个页面的范围之内)。如果区域文件区要大，那么就用零来填充这个区域的余下部分。 (2)匿名文件：一个区域也可以映射到一个匿名文件，匿名文件是由内核创建的，包含的全是二进制零。CPU第一次引用这样一个区域内的虚拟页面时，内核就在物理存储器中找到一个合适的牺牲页面，如果该页面被修改过，就将这个页面换出来，用二进制零覆盖牺牲页面并更新页表，将这个页面标记为是驻留在存储器中的。注意在磁盘和存储器之间没有实际的数据传送。因为这个原因，映射到匿名文件的区域中的页面有时也叫做请求二进制零的页(demand-zero page)。无论在哪种情况下，一旦一个虚拟页面被初始化了， 它就在一个由内核维护的专门的交换文件(swap file)之间换来换去。交换文件也叫做交换空间(swap space)或者交换区域(swap area)。需要意识到的很重要的一点，在任何时刻，交换空间都限制着当前运行着的进程能够分配的虚拟页面的总数。 再看共享对象一个对象可以被映射到虚拟存储的一个区域，要么作为共享对象，要么作为私有对象。如果一个进程将一个共享对象映射到它的虚拟地址空间的一个区域内，那么这个进程对这个区域的任何写操作，对于那些也把这个共享对象映射到它们虚拟存储器的其他进程而言也是可见的。而且，这此变化也会反映在磁盘上的原始对象中。(IPC的一种方式)另一方面，对一个映射到私有对象的区域做的改变，对于其他进程来说是不可见的，并且进程对这个区域所做的任何写操作都不会反映在磁盘上的对象中。一个映射到共享对象的虚拟存储器区域叫做共享区域。类似地，也有私有区域。 共享对象的关键点在于即使对象被映射到了多个共享区域，物理存储器也只需要存放共享对象的一个拷贝。 一个共享对象(注意，物理页面不一定是连续的。)私有对象是使用一种叫做写时拷贝(copy-on-write)的巧妙技术被映射到虚拟存储器中的。对于每个映射私有对象的进程，相应私有区域的页表条目都被标记为只读，并且区域结构被标记为私有的写时拷贝。 再看fork函数当fork函数被当前进程调用时，内核为新进程创建各种数据结构，并分配给它一个唯一的PID。为了给这个新进程创建虚拟存储器，它创建了当前进程的mm_struct、区域结构和页表的原样拷贝。它将两个进程中的每个页面都为标记只读，并将两个进程中的每个区域结构都标记为私有的写时拷贝。 当fork在新进程中返回时，新进程现在的虚拟存储器刚好和调用fork时存在的虚拟存储器相同。当这两个进程中的任一个后来进行写操作时，写时拷贝机制就会创建新页面，因此，也就为每个进程保持了私有地址空间的抽象概念。 再看execve函数假设运行在当前进程中的程序执行了如下的调用： execve(“a.out”,NULL,NULL) ; execve函数在当前进程中加载并运行包含在可执行目标文件a.out中的程序，用a.out程序有效地替代了当前程序。加载并运行a.out需要以下几个步骤： 删除已存在的用户区域。删除当前进程虚拟地址用户部分中的已存在的区域结构。映射私有区域。为新程序的文本、数据、bss和栈区域创建新的区域结构。所有这些新的区域都是私有的、写时拷贝的。文本和数据区域被映射为a.out文件中的文本和数据区。bss区域是请求二进制零的，映射到匿名文件，其大小包含在a.out中。栈和堆区域也是请求二进制零的。映射共享区域。如果a.out程序与共享对象(或目标)链接，比如标准C库libc.so，那么这些对象都是动态链接到这个程序的，然后再映射到用户虚拟地址空间中的共享区域内。设置程序计数器(PC)。execve做的最后一件事情就是设置当前进程上下文中的程序计数器，使之指向文本区域的入口点。下一次调度这个进程时，它将从这个入口点开始执行。Linux将根据需要换入代码和数据页面。 使用mmap函数的用户级存储器映射12345#include&lt;unistd.h&gt; #include&lt;sys/mman.h&gt; void *mmap(void *start,size_t length,int prot,int flags,int fd,off_t offset) ; //返回：若成功时则为指向映射区域的指针，若出错则为MAP_FAILED(-1) mmap函数要求内核创建一个新的虚拟存储器区域是，最好是从地址start开始的一个区域，并将文件描述符fd指定的对象的一个连续的片(chunk)映射到这个新区域。连续的对象片大小为length字节，从距文件开始处偏移量为offset字节的地方开始。start地址仅仅是一个暗示，通常被定义为NULL。1234567munmap函数删除虚拟存储器的区域： #include&lt;unistd.h&gt; #include&lt;sys/mman.h&gt; int munmap(void *start,size_t length); //返回：若成功则为0，若出错则为-1 1、需要额外的虚拟存储器时，使用一种动态存储器分配器（dynamic memory allocator）。一个动态存储器分配器维护着一个进程的虚拟存储器区域，称为堆（heap）。在大多数的unix系统中，堆是一个请求二进制0的区域；对于每个进程，内核维护着一个变量brk，它指向堆的顶部。 2、分配器将堆视为一组不同大小的块（block）的集合来维护。每个块就是一个连续的虚拟存储器组块（chunk），要么是已分配的，要么是未分配的。 1）显式分配器（explicit allocator）：如通过malloc,free或C++中通过new,delete来分配和释放一个块。 2）隐式分配器（implicit allocator）：也叫做垃圾收集器（garbage collector）。自动释放未使用的已分配的块的过程叫做垃圾回收（garbage collection）。 3、malloc不初始化它返回的存储器，calloc是一个基于malloc的包装（wrapper）函数，它将分配的存储器初始化为0。想要改变一个以前已分配的块的大小，可以使用realloc函数。 4、分配器必须对齐块，使得它们可以保存任何类型的数据对象。在大多数系统中，以8字节边界对齐。 不修改已分配的块：分配器只能操作或者改变空闲块。一旦被分配，就不允许修改或者移动它。 5、碎片（fragmentation） 有内部碎片（internal）和外部碎片（external）。 外部碎片：在一个已分配块比有效载荷在时发生的。（如对齐要求，分配最小值限制等） 外部碎片：当空闲存储器合计起来足够满足一个分配请求，但是没有一个单独的空闲块足够大可以来处理这个请求时发生的。 6、隐式空间链表 放置分配的块的策略有：首次适配（first fit），下一次适配（next fit），和最佳适配（best fit）。 如果空闲块已经最大程度的合并，而仍然不能生成一个足够大的块，来满足要求的话，分配器就会向内核请求额外的堆存储器，要么是通过调用nmap，要么是通过调用sbrk函数；分配器都会将额外的（增加的）存储器转化成一个大的空闲块，将这个块插入到空闲链表中，然后将被请求的块放置在这个新的空闲块中。 7、书中对分配器的设计举了一个小例子，10.9.12节。 8、一种流行的减少分配时间的方法，称为分离存储（segregated storage），维护多个空闲链表，其中每个链表中的块有大致相等的大小。 垃圾回收1、垃圾收集器将存储器视为一张有向可达图（reachability graph）。 2、Mark%Sweep垃圾收集器由标记（mark）阶段和清除（sweep）阶段组成。标记阶段标记出根节点的所有可达的和已分配的后继，而后面的清除阶段释放每个被标记的已分配块。典型地，块头部中空闲的低位中的一位来表示这个块是否被标记了.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++类中函数的重载、隐藏和覆盖]]></title>
    <url>%2F2019%2F05%2F20%2Fcpp%E7%B1%BB%E4%B8%AD%E5%87%BD%E6%95%B0%E7%9A%84%E9%87%8D%E8%BD%BD%E3%80%81%E9%9A%90%E8%97%8F%E5%92%8C%E8%A6%86%E7%9B%96%2F</url>
    <content type="text"><![CDATA[函数重载只会发生在同一个类中，函数名相同，只能通过参数类型，参数个数或者有无const来区分。不能通过返回值类型区分，而且virtual也是可有可无的，即虚函数和普通函数在同一类中也可以构成函数重载。 基类和派生类中只能是隐藏或者覆盖。 隐藏是指派生类中有函数与基类中函数同名，但是没有构成虚函数覆盖，就是隐藏。隐藏的表现：若基类中函数func()被派生类中函数func()隐藏，那么无法通过派生类对象访问基类中的func() 函数，派生类对象只能访问到派生类中的func()函数。不过基类中的func()确实继承到了派生类中。 虚函数也只是在基类和派生类中发挥多态的作用，而在同一类中虚函数也可以重载。 虚函数实现多态的条件： 基类中将这些成员声明为virtual。 基类和派生类中的这些函数必须同名且参数类型，参数个数，返回值类型必须相同。 将派生类的对象赋给基类指针或者引用，实现多态。 缺少任何一条，只会是基类和派生类之间的隐藏，而不是覆盖 如何判断基类和派生类中函数是否是隐藏？当基类和派生类存在同名函数，不论参数类型，参数个数是否相同，派生类中的同名函数都会将基类中的同名函数隐藏掉。 基类和派生类都是虚函数，并且同名，但是形参类型或者形参个数不同，多态不满足，但是构成了隐藏，只是没有虚特性。 基类中不是虚函数，派生类中定义为虚函数，不构成多态，只是隐藏关系。 基类和派生类的两个函数同名，都是虚函数，形参的个数和类型也都相同，但是返回值类型不同，这时编译会报错，因为两个虚函数在隐藏时，返回值类型发生了冲突，因此隐藏发生错误。注意，如果这两个函数不是虚函数，这不会报错，隐藏会成功；同时，如果派生类中是虚函数，基类中不是虚函数，也不过报错，隐藏也是成功的。但是如果基类中为虚函数，派生类中不是，也会报错。这些说明，虚化并隐藏时，返回值类型一定要保持相同。 虚函数要求返回值类型也一样，但是有一种情况允许虚函数返回值时本类对象的引用或者指针，也可以构成覆盖。这个是“协变”规则，具体协变看例子：12345678910111213141516171819202122232425class A:&#123;public: virtual A* func() &#123; cout&lt;&lt;&quot;A&quot;&lt;&lt;endl; return this; &#125; &#125;;class B:public A&#123;public: virtual B* func() &#123; cout&lt;&lt;&quot;B&quot;&lt;&lt;endl; return this; &#125;&#125;;int main()&#123; A *pa=new B; B* pb=pa-&gt;func();//编译无法通过，因为pa是A*类型指针，编译时，对于pa-&gt;func()翻译成调用的是A类的函数，返回值为 A*类型。而A*类型无法赋值给派生类指针 B* pb=(B*)pa-&gt;func();//正确 B* pb=(B*)(pa-&gt;func());//正确&#125; A *pa=new B;对于虚函数将基类指针指向派生类对象，调用派生类的虚函数。该基类指针能解引用的内存空间是继承到派生类中的基类的内存空间。基类指针调用派生类的虚函数，在虚函数中，this指针指向的是派生类本身，也就是在虚函数中将基类指针强制转换成了派生类指针。其实基类指针pa和派生类中的this指针值相同，都是派生类对象的地址。 协变的存在是为了解决返回值的强制类型转换，真正用途是，通过派生类对象调用虚函数，直接返回派生类指针。若无协变，则会返回基类指针，需要再将基类指针强制转换成派生类指针。具体的意思看例子：12345678910111213141516若没有协变，那么上述的代码中派生类中虚函数需要改成以下形式：class B :public A&#123;public: virtual A* func() &#123; cout&lt;&lt;&quot;B&quot;&lt;&lt;endl; return this;//返回值this为B*类型指针，但是因为没有协变，返回的时候将B*类型赋值给了A*类型，然后以A*类型返回到main函数中 &#125;&#125;;int main()&#123; B b; A *pa=b.func(); B *pb=dynamic&lt;B*&gt; (pa);//将返回的A*类型强制转换成B*类型&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的任务调度机制]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Linux进程调度的目标 高效性：高效意味着在相同的时间下要完成更多的任务。调度程序会被频繁的执行，所以调度程序要尽可能的高效； 加强交互性能:在系统相当的负载下，也要保证系统的响应时间； 保证公平和避免饥渴； SMP调度：调度程序必须支持多处理系统； 软实时调度：系统必须有效的调用实时进程，但不保证一定满足其要求； Linux进程优先级进程提供了两种优先级，一种是普通的进程优先级，第二个是实时优先级。前者适用SCHED_NORMAL调度策略，后者可选SCHED_FIFO或SCHED_RR调度策略。任何时候，实时进程的优先级都高于普通进程，实时进程只会被更高级的实时进程抢占，同级实时进程之间是按照FIFO（一次机会做完）或者RR（多次轮转）规则调度的。 首先，说下实时进程的调度 实时进程，只有静态优先级，因为内核不会再根据休眠等因素对其静态优先级做调整，其范围在0~MAX_RT_PRIO-1间。默认MAX_RT_PRIO配置为100，也即，默认的实时优先级范围是0~99。而nice值，影响的是优先级在MAX_RT_PRIO~MAX_RT_PRIO+40范围内的进程。 不同与普通进程，系统调度时，实时优先级高的进程总是先于优先级低的进程执行。知道实时优先级高的实时进程无法执行。实时进程总是被认为处于活动状态。如果有数个 优先级相同的实时进程，那么系统就会按照进程出现在队列上的顺序选择进程。假设当前CPU运行的实时进程A的优先级为a，而此时有个优先级为b的实时进程B进入可运行状态，那么只要b &lt; a，系统将中断A的执行，而优先执行B，直到B无法执行（无论A，B为何种实时进程）。 不同调度策略的实时进程只有在相同优先级时才有可比性： 对于FIFO的进程，意味着只有当前进程执行完毕才会轮到其他进程执行。由此可见相当霸道。 对于RR的进程。一旦时间片消耗完毕，则会将该进程置于队列的末尾，然后运行其他相同优先级的进程，如果没有其他相同优先级的进程，则该进程会继续执行。 总而言之，对于实时进程，高优先级的进程就是大爷。它执行到没法执行了，才轮到低优先级的进程执行。等级制度相当森严啊。 非实时进程调度Linux对普通的进程，根据动态优先级进行调度。而动态优先级是由静态优先级（static_prio）调整而来。Linux下，静态优先级是用户不可见的，隐藏在内核中。而内核提供给用户一个可以影响静态优先级的接口，那就是nice值，两者关系如下：1static_prio=MAX_RT_PRIO +nice+ 20 nice值的范围是-20~19，因而静态优先级范围在100~139之间。nice数值越大就使得static_prio越大，最终进程优先级就越低。 ps -el 命令执行结果：NI列显示的每个进程的nice值，PRI是进程的优先级（如果是实时进程就是静态优先级，如果是非实时进程，就是动态优先级） 而进程的时间片就是完全依赖 static_prio 定制的，见下图，摘自《深入理解linux内核》， 我们前面也说了，系统调度时，还会考虑其他因素，因而会计算出一个叫进程动态优先级的东西，根据此来实施调度。因为，不仅要考虑静态优先级，也要考虑进程的属性。例如如果进程属于交互式进程，那么可以适当的调高它的优先级，使得界面反应地更加迅速，从而使用户得到更好的体验。Linux2.6 在这方面有了较大的提高。Linux2.6认为，交互式进程可以从平均睡眠时间这样一个measurement进行判断。进程过去的睡眠时间越多，则越有可能属于交互式进程。则系统调度时，会给该进程更多的奖励（bonus），以便该进程有更多的机会能够执行。奖励（bonus）从0到10不等。 系统会严格按照动态优先级高低的顺序安排进程执行。动态优先级高的进程进入非运行状态，或者时间片消耗完毕才会轮到动态优先级较低的进程执行。动态优先级的计算主要考虑两个因素：静态优先级，进程的平均睡眠时间也即bonus。计算公式如下，1dynamic_prio = max (100, min (static_prio - bonus + 5, 139)) 在调度时，Linux2.6 使用了一个小小的trick，就是算法中经典的空间换时间的思想[还没对照源码确认]，使得计算最优进程能够在O(1)的时间内完成。 为什么根据睡眠和运行时间确定奖惩分数是合理的 睡眠和CPU耗时反应了进程IO密集和CPU密集两大瞬时特点，不同时期，一个进程可能即是CPU密集型也是IO密集型进程。对于表现为IO密集的进程，应该经常运行，但每次时间片不要太长。对于表现为CPU密集的进程，CPU不应该让其经常运行，但每次运行时间片要长。交互进程为例，假如之前其其大部分时间在于等待CPU，这时为了调高相应速度，就需要增加奖励分。另一方面，如果此进程总是耗尽每次分配给它的时间片，为了对其他进程公平，就要增加这个进程的惩罚分数。可以参考CFS的virtutime机制. 现代方法CFS不再单纯依靠进程优先级绝对值，而是参考其绝对值，综合考虑所有进程的时间，给出当前调度时间单位内其应有的权重，也就是，每个进程的权重X单位时间=应获cpu时间，但是这个应得的cpu时间不应太小（假设阈值为1ms），否则会因为切换得不偿失。但是，当进程足够多时候，肯定有很多不同权重的进程获得相同的时间——最低阈值1ms，所以，CFS只是近似完全公平。 Linux进程状态机 进程是通过fork系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过kernel_thread函数创建内核进程。这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。）那么既然调用进程处于TASK_RUNNING状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于TASK_RUNNING状态。另外，在系统调用clone和内核函数kernel_thread也接受CLONE_STOPPED选项，从而将子进程的初始状态置为 TASK_STOPPED。 进程创建后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从TASK_RUNNING状态变为非TASK_RUNNING状态、或者从非TASK_RUNNING状态变为TASK_RUNNING状态。总之，TASK_RUNNING是必经之路，不可能两个非RUN状态直接转换。 也就是说，如果给一个TASK_INTERRUPTIBLE状态的进程发送SIGKILL信号，这个进程将先被唤醒（进入TASK_RUNNING状态），然后再响应SIGKILL信号而退出（变为TASK_DEAD状态）。并不会从TASK_INTERRUPTIBLE状态直接退出。 进程从非TASK_RUNNING状态变为TASK_RUNNING状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。执行唤醒的进程设置被唤醒进程的状态为TASK_RUNNING，然后将其task_struct结构加入到某个CPU的可执行队列中。于是被唤醒的进程将有机会被调度执行。 而进程从TASK_RUNNING状态变为非TASK_RUNNING状态，则有两种途径： 响应信号而进入TASK_STOPED状态、或TASK_DEAD状态； 执行系统调用主动进入TASK_INTERRUPTIBLE状态（如nanosleep系统调用）、或TASK_DEAD状态（如exit系统调用）；或由于执行系统调用需要的资源得不到满 足，而进入TASK_INTERRUPTIBLE状态或TASK_UNINTERRUPTIBLE状态（如select系统调用）。 显然，这两种情况都只能发生在进程正在CPU上执行的情况下。 通过ps命令我们能够查看到系统中存在的进程，以及它们的状态： R(TASK_RUNNING)，可执行状态。 只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。只要可执行队列不为空，其对应的CPU就不能偷懒，就要执行其中某个进程。一般称此时的CPU“忙碌”。对应的，CPU“空闲”就是指其对应的可执行队列为空，以致于CPU无事可做。有人问，为什么死循环程序会导致CPU占用高呢？因为死循环程序基本上总是处于TASK_RUNNING状态（进程处于可执行队列中）。除非一些非常极端情况（比如系统内存严重紧缺，导致进程的某些需要使用的页面被换出，并且在页面需要换入时又无法分配到内存……），否则这个进程不会睡眠。所以CPU的可执行队列总是不为空（至少有这么个进程存在），CPU也就不会“空闲”。 很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。 S(TASK_INTERRUPTIBLE)，可中断的睡眠状态。 处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。 通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。 D(TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。 与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号。绝大多数情况下，进程处在睡眠状态时，总是应该能够响应异步信号的。否则你将惊奇的发现，kill -9竟然杀不死一个正在睡眠的进程了！于是我们也很好理解，为什么ps命令看到的进程几乎不会出现TASK_UNINTERRUPTIBLE状态，而总是TASK_INTERRUPTIBLE状态。 而TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了（参见《linux异步信号handle浅析》）。在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。（比如read系统调用触发了一次磁盘到用户空间的内存的DMA，如果DMA进行过程中，进程由于响应信号而退出了，那么DMA正在访问的内存可能就要被释放了。）这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到。 linux系统中也存在容易捕捉的TASK_UNINTERRUPTIBLE状态。执行vfork系统调用后，父进程将进入TASK_UNINTERRUPTIBLE状态，直到子进程调用exit或exec。通过下面的代码就能得到处于TASK_UNINTERRUPTIBLE状态的进程：1234#include &lt;unistd.h&gt;void main() &#123;if (!vfork()) sleep(100);&#125; 编译运行，然后ps一下：1234kouu@kouu-one:~/test$ ps -ax | grep a\.out4371 pts/0 D+ 0:00 ./a.out4372 pts/0 S+ 0:00 ./a.out4374 pts/1 S+ 0:00 grep a.out 然后我们可以试验一下TASK_UNINTERRUPTIBLE状态的威力。不管kill还是kill -9，这个TASK_UNINTERRUPTIBLE状态的父进程依然屹立不倒。 T(TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。 向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 Z(TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。 进程在退出的过程中，处于TASK_DEAD状态。 在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。 父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。 通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程：12345#include &lt;unistd.h&gt;void main() &#123;if (fork())while(1) sleep(100);&#125; 编译运行，然后ps一下：1234kouu@kouu-one:~/test$ ps -ax | grep a\.out10410 pts/0 S+ 0:00 ./a.out10411 pts/0 Z+ 0:00 [a.out] &lt;defunct&gt;10413 pts/1 S+ 0:00 grep a.out 只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。 1号进程，pid为1的进程，又称init进程。linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命： 执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）； 在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作； init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。 X(TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。 而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。 一些重要的杂项调度程序的效率“优先级”明确了哪个进程应该被调度执行，而调度程序还必须要关心效率问题。调度程序跟内核中的很多过程一样会频繁被执行，如果效率不济就会浪费很多CPU时间，导致系统性能下降。在linux 2.4时，可执行状态的进程被挂在一个链表中。每次调度，调度程序需要扫描整个链表，以找出最优的那个进程来运行。复杂度为O(n)；在linux 2.6早期，可执行状态的进程被挂在N(N=140)个链表中，每一个链表代表一个优先级，系统中支持多少个优先级就有多少个链表。每次调度，调度程序只需要从第一个不为空的链表中取出位于链表头的进程即可。这样就大大提高了调度程序的效率，复杂度为O(1)；在linux 2.6近期的版本中，可执行状态的进程按照优先级顺序被挂在一个红黑树（可以想象成平衡二叉树）中。每次调度，调度程序需要从树中找出优先级最高的进程。复杂度为O(logN)。 那么，为什么从linux 2.6早期到近期linux 2.6版本，调度程序选择进程时的复杂度反而增加了呢？这是因为，与此同时，调度程序对公平性的实现从上面提到的第一种思路改变为第二种思路（通过动态调整优先级实现）。而O(1)的算法是基于一组数目不大的链表来实现的，按我的理解，这使得优先级的取值范围很小（区分度很低），不能满足公平性的需求。而使用红黑树则对优先级的取值没有限制（可以用32位、64位、或更多位来表示优先级的值），并且O(logN)的复杂度也还是很高效的。 调度触发的时机调度的触发主要有如下几种情况：1、当前进程（正在CPU上运行的进程）状态变为非可执行状态。进程执行系统调用主动变为非可执行状态。比如执行nanosleep进入睡眠、执行exit退出、等等；进程请求的资源得不到满足而被迫进入睡眠状态。比如执行read系统调用时，磁盘高速缓存里没有所需要的数据，从而睡眠等待磁盘IO；进程响应信号而变为非可执行状态。比如响应SIGSTOP进入暂停状态、响应SIGKILL退出、等等； 2、抢占。进程运行时，非预期地被剥夺CPU的使用权。这又分两种情况：进程用完了时间片、或出现了优先级更高的进程。优先级更高的进程受正在CPU上运行的进程的影响而被唤醒。如发送信号主动唤醒，或因为释放互斥对象（如释放锁）而被唤醒；内核在响应时钟中断的过程中，发现当前进程的时间片用完；内核在响应中断的过程中，发现优先级更高的进程所等待的外部资源的变为可用，从而将其唤醒。比如CPU收到网卡中断，内核处理该中断，发现某个socket可读，于是唤醒正在等待读这个socket的进程；再比如内核在处理时钟中断的过程中，触发了定时器，从而唤醒对应的正在nanosleep系统调用中睡眠的进程； 内核抢占理想情况下，只要满足“出现了优先级更高的进程”这个条件，当前进程就应该被立刻抢占。但是，就像多线程程序需要用锁来保护临界区资源一样，内核中也存在很多这样的临界区，不大可能随时随地都能接收抢占。linux 2.4时的设计就非常简单，内核不支持抢占。进程运行在内核态时（比如正在执行系统调用、正处于异常处理函数中），是不允许抢占的。必须等到返回用户态时才会触发调度（确切的说，是在返回用户态之前，内核会专门检查一下是否需要调度）；linux 2.6则实现了内核抢占，但是在很多地方还是为了保护临界区资源而需要临时性的禁用内核抢占。 也有一些地方是出于效率考虑而禁用抢占，比较典型的是spin_lock。spin_lock是这样一种锁，如果请求加锁得不到满足（锁已被别的进程占有），则当前进程在一个死循环中不断检测锁的状态，直到锁被释放。为什么要这样忙等待呢？因为临界区很小，比如只保护“i+=j++;”这么一句。如果因为加锁失败而形成“睡眠-唤醒”这么个过程，就有些得不偿失了。那么既然当前进程忙等待（不睡眠），谁又来释放锁呢？其实已得到锁的进程是运行在另一个CPU上的，并且是禁用了内核抢占的。这个进程不会被其他进程抢占，所以等待锁的进程只有可能运行在别的CPU上。（如果只有一个CPU呢？那么就不可能存在等待锁的进程了。）而如果不禁用内核抢占呢？那么得到锁的进程将可能被抢占，于是可能很久都不会释放锁。于是，等待锁的进程可能就不知何年何月得偿所望了。 对于一些实时性要求更高的系统，则不能容忍spin_lock这样的东西。宁可改用更费劲的“睡眠-唤醒”过程，也不能因为禁用抢占而让更高优先级的进程等待。比如，嵌入式实时linux montavista就是这么干的。由此可见，实时并不代表高效。很多时候为了实现“实时”，还是需要对性能做一定让步的。 多处理器下的负载均衡前面我们并没有专门讨论多处理器对调度程序的影响，其实也没有什么特别的，就是在同一时刻能有多个进程并行地运行而已。那么，为什么会有“多处理器负载均衡”这个事情呢？如果系统中只有一个可执行队列，哪个CPU空闲了就去队列中找一个最合适的进程来执行。这样不是很好很均衡吗？的确如此，但是多处理器共用一个可执行队列会有一些问题。显然，每个CPU在执行调度程序时都需要把队列锁起来，这会使得调度程序难以并行，可能导致系统性能下降。而如果每个CPU对应一个可执行队列则不存在这样的问题。另外，多个可执行队列还有一个好处。这使得一个进程在一段时间内总是在同一个CPU上执行，那么很可能这个CPU的各级cache中都缓存着这个进程的数据，很有利于系统性能的提升。所以，在linux下，每个CPU都有着对应的可执行队列，而一个可执行状态的进程在同一时刻只能处于一个可执行队列中。 于是，“多处理器负载均衡”这个麻烦事情就来了。内核需要关注各个CPU可执行队列中的进程数目，在数目不均衡时做出适当调整。什么时候需要调整，以多大力度进程调整，这些都是内核需要关心的。当然，尽量不要调整最好，毕竟调整起来又要耗CPU、又要锁可执行队列，代价还是不小的。另外，内核还得关心各个CPU的关系。两个CPU之间，可能是相互独立的、可能是共享cache的、甚至可能是由同一个物理CPU通过超线程技术虚拟出来的……CPU之间的关系也是实现负载均衡的重要依据。关系越紧密，进程在它们之间迁移的代价就越小。参见《linux内核SMP负载均衡浅析》。 优先级继承由于互斥，一个进程（设为A）可能因为等待进入临界区而睡眠。直到正在占有相应资源的进程（设为B）退出临界区，进程A才被唤醒。可能存在这样的情况：A的优先级非常高，B的优先级非常低。B进入了临界区，但是却被其他优先级较高的进程（设为C）抢占了，而得不到运行，也就无法退出临界区。于是A也就无法被唤醒。A有着很高的优先级，但是现在却沦落到跟B一起，被优先级并不太高的C抢占，导致执行被推迟。这种现象就叫做优先级反转。 出现这种现象是很不合理的。较好的应对措施是：当A开始等待B退出临界区时，B临时得到A的优先级（还是假设A的优先级高于B），以便顺利完成处理过程，退出临界区。之后B的优先级恢复。这就是优先级继承的方法。 中断处理线程化在linux下，中断处理程序运行于一个不可调度的上下文中。从CPU响应硬件中断自动跳转到内核设定的中断处理程序去执行，到中断处理程序退出，整个过程是不能被抢占的。一个进程如果被抢占了，可以通过保存在它的进程控制块（task_struct）中的信息，在之后的某个时间恢复它的运行。而中断上下文则没有task_struct，被抢占了就没法恢复了。中断处理程序不能被抢占，也就意味着中断处理程序的“优先级”比任何进程都高（必须等中断处理程序完成了，进程才能被执行）。但是在实际的应用场景中，可能某些实时进程应该得到比中断处理程序更高的优先级。于是，一些实时性要求更高的系统就给中断处理程序赋予了task_struct以及优先级，使得它们在必要的时候能够被高优先级的进程抢占。但是显然，做这些工作是会给系统造成一定开销的，这也是为了实现“实时”而对性能做出的一种让步。 通用Linux系统通用Linux系统支持实时和非实时两种进程，实时进程相对于普通进程具有绝对的优先级。对应地，实时进程采用SCHED_FIFO或者SCHED_RR调度策略，普通的进程采用SCHED_OTHER调度策略。 在调度算法的实现上，Linux中的每个任务有四个与调度相关的参数，它们是rt_priority、policy、priority（nice）、counter。调度程序根据这四个参数进行进程调度。 在SCHED_OTHER调度策略中，调度器总是选择那个priority+counter值最大的进程来调度执行。从逻辑上分析SCHED_OTHER调度策略存在着调度周期（epoch），在每一个调度周期中，一个进程的priority和counter值的大小影响了当前时刻应该调度哪一个进程来执行，其中priority是一个固定不变的值，在进程创建时就已经确定，它代表了该进程的优先级，也代表这该进程在每一个调度周期中能够得到的时间片的多少；counter是一个动态变化的值，它反映了一个进程在当前的调度周期中还剩下的时间片。在每一个调度周期的开始，priority的值被赋给counter，然后每次该进程被调度执行时，counter值都减少。当counter值为零时，该进程用完自己在本调度周期中的时间片，不再参与本调度周期的进程调度。当所有进程的时间片都用完时，一个调度周期结束，然后周而复始。另外可以看出Linux系统中的调度周期不是静态的，它是一个动态变化的量，比如处于可运行状态的进程的多少和它们priority值都可以影响一个epoch的长短。值得注意的一点是，在2.4以上的内核中，priority被nice所取代，但二者作用类似。 可见SCHED_OTHER调度策略本质上是一种比例共享的调度策略，它的这种设计方法能够保证进程调度时的公平性–一个低优先级的进程在每一个 epoch中也会得到自己应得的那些CPU执行时间，另外它也提供了不同进程的优先级区分，具有高priority值的进程能够获得更多的执行时间。对于实时进程来说，它们使用的是基于实时优先级rt_priority的优先级调度策略，但根据不同的调度策略，同一实时优先级的进程之间的调度方法有所不同： SCHED_FIFO：不同的进程根据静态优先级进行排队，然后在同一优先级的队列中，谁先准备好运行就先调度谁，并且正在运行的进程不会被终止直到以下情况发生：（1）.被有更高优先级的进程所强占CPU；（2）.自己因为资源请求而阻塞；（3）.自己主动放弃CPU（调用sched_yield）。 SCHED_RR：这种调度策略跟上面的SCHED_FIFO一模一样，除了它给每个进程分配一个时间片，时间片到了正在执行的进程就放弃执行；时间片的长度可以通过sched_rr_get_interval调用得到。 由于Linux系统本身是一个面向桌面的系统，所以将它应用于实时应用中时存在如下的一些问题： Linux系统中的调度单位为10ms，所以它不能够提供精确的定时； 当一个进程调用系统调用进入内核态运行时，它是不可被抢占的； Linux内核实现中使用了大量的锁中断操作会造成中断的丢失； 由于使用虚拟内存技术，当发生页出错时，需要从硬盘中读取交换数据，但硬盘读写由于存储位置的随机性会导致随机的读写时间，这在某些情况下会影响一些实时任务的截止期限； 虽然Linux进程调度也支持实时优先级，但缺乏有效的实时任务的调度机制和调度算法；它的网络子系统的协议处理和其它设备的中断处理都没有与它对应的进程的调度关联起来，并且它们自身也没有明确的调度机制； 实时Linux研究瘦内核（微内核）- Thin-Kernel瘦内核（或微内核）方法使用了第二个内核作为硬件与Linux内核间的抽象接口。非实时Linux内核在后台运行，作为瘦内核的一项低优先级任务托管全部非实时任务。实时任务直接在瘦内核上运行。瘦内核主要用于（除了托管实时任务外）中断管理。瘦内核截取中断以确保非实时内核无法抢占瘦内核的运行。这允许瘦内核提供硬实时支持。 虽然瘦内核方法有自己的优势（硬实时支持与标准Linux内核共存），但这种方法也有缺点。实时任务和非实时任务是独立的，这造成了调试困难。而且，非实时任务并未得到Linux平台的完全支持（瘦内核之所以称为瘦的一个原因）。使用这种方法的例子有RTLinux（现在由Wind River Systems专有），实时应用程序接口（RTAI）和Xenomai。 超微内核这里瘦内核方法依赖于包含任务管理的最小内核，而超微内核法对内核进行更进一步的缩减。通过这种方式，它不像是一个内核而更像是一个硬件抽象层（HAL）。超微内核为运行于更高级别的多个操作系统提供了硬件资源共享。因为超微内核对硬件进行了抽象，因此它可为更高级别的操作系统提供优先权，从而支持实时性。 注意，这种方法和运行多个操作系统的虚拟化方法有一些相似之处。使用这种方法的情况下，超微内核在实时和非实时内核中对硬件进行抽象。这与 hypervisor 从客户（guest）操作系统对裸机进行抽象的方式很相似。 关于超微内核的示例是操作系统的Adaptive Domain Environment for Operating Systems（ADEOS）。ADEOS支持多个并发操作系统同步运行。当发生硬件事件后，ADEOS对链中的每个操作系统进行查询以确定使用哪一个系统处理事件。 资源内核（Resource-kernel）另一个实时架构是资源内核法。这种方法为内核增加一个模块，为各种资源提供预留（reservation）。这种机制保证了对时分复用（time- multiplexed）系统资源的访问（CPU、网络或磁盘带宽）。这些资源拥有多个预留参数，如循环周期、需要的处理时间（也就是完成处理所需的时间），以及截止时间。 资源内核提供了一组应用程序编程接口（API），允许任务请求这些预留资源。然后资源内核可以合并这些请求，使用任务定义的约束定义一个调度，从而提供确定的访问（如果无法提供确定性则返回错误）。通过调度算法，如Earliest-Deadline-First（EDF），内核可以处理动态的调度负载。 资源内核法实现的一个示例是CMU公司的Linux/RK，它把可移植的资源内核集成到Linux中作为一个可加载模块。这种实现演化成商用的 TimeSys Linux/RT 产品。 标准的Linux内核最新版本2.6中加入了实时功能目前探讨的这些方法在架构上都很有趣，但是它们都在内核的外围运行。然而，如果对标准Linux内核进行必要的修改使其支持实时性，结果会怎么样呢？ 今天，在2.6内核中，通过对内核进行简单配置使其完全可抢占，您就可以得到软实时功能。在标准2.6 Linux内核中，当用户空间的进程执行内核调用时（通过系统调用），它便不能被抢占。这意味着如果低优先级进程进行了系统调用后，高优先级进程必须等到调用结束后才能访问CPU。 新的配置选项CONFIG_PREEMPT改变了这一内核行为，在高优先级任务可用的情况下（即使此进程正在进行系统调用），它允许进程被抢占。 但这种配置选项也是一种折衷。虽然此选项实现了软实时性能并且即使在负载条件下也可使操作系统顺利地运行，但这样做也付出了代价。代价就是略微减低了吞吐量以及内核性能，原因是CONFIG_PREEMPT选项增加了开销。这种选项对桌面和嵌入式系统而言是有用的，但并不是在任何场景下都有用（例如，服务器）。 在2.6内核中另一项有用的配置选项是高精度定时器。这个新选项允许定时器以1μs的精度运行（如果底层硬件支持的话），并通过红黑树实现对定时器的高效管理。通过红黑树，可以使用大量的定时器而不会对定时器子系统（O（log n））的性能造成影响。 只需要一点额外的工作，就可以通过PREEMPT_RT补丁实现硬实时。PREEMPT_RT补丁提供了多项修改，可实现硬实时支持。其中一些修改包括重新实现一些内核锁定原语，从而实现完全可抢占，实现内核互斥的优先级继承，并把中断处理程序转换为内核线程以实现线程可抢占。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程组、会话、守护进程]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E8%BF%9B%E7%A8%8B%E7%BB%84-%E4%BC%9A%E8%AF%9D-%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[进程组 一个或多个进程的集合 进程组ID: 正整数 两个函数 getpgid(0)=getpgrp() eg：显示子进程与父进程的进程组id1234567891011121314151617181920212223#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main() &#123; pid_t pid; if ((pid=fork())&lt;0) &#123; printf(&quot;fork error!&quot;); &#125;else if (pid==0) &#123; printf(&quot;The child process PID is %d.\n&quot;,getpid()); printf(&quot;The Group ID is %d.\n&quot;,getpgrp()); printf(&quot;The Group ID is %d.\n&quot;,getpgid(0)); printf(&quot;The Group ID is %d.\n&quot;,getpgid(getpid())); exit(0); &#125; sleep(3); printf(&quot;The parent process PID is %d.\n&quot;,getpid()); printf(&quot;The Group ID is %d.\n&quot;,getpgrp()); return 0;&#125; 进程组id = 父进程id，即父进程为组长进程 组长进程 组长进程标识: 其进程组ID==其进程ID 组长进程可以创建一个进程组，创建该进程组中的进程，然后终止 只要进程组中有一个进程存在，进程组就存在，与组长进程是否终止无关 进程组生存期: 进程组创建到最后一个进程离开(终止或转移到另一个进程组) 一个进程可以为自己或子进程设置进程组ID setpgid()加入一个现有的进程组或创建一个新进程组 123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main() &#123; pid_t pid; if ((pid=fork())&lt;0) &#123; printf(&quot;fork error!&quot;); exit(1); &#125;else if (pid==0) &#123; printf(&quot;The child process PID is %d.\n&quot;,getpid()); printf(&quot;The Group ID of child is %d.\n&quot;,getpgid(0)); // 返回组id sleep(5); printf(&quot;The Group ID of child is changed to %d.\n&quot;,getpgid(0)); exit(0); &#125; sleep(1); setpgid(pid,pid); // 改变子进程的组id为子进程本身 sleep(5); printf(&quot;The parent process PID is %d.\n&quot;,getpid()); printf(&quot;The parent of parent process PID is %d.\n&quot;,getppid()); printf(&quot;The Group ID of parent is %d.\n&quot;,getpgid(0)); setpgid(getpid(),getppid()); // 改变父进程的组id为父进程的父进程 printf(&quot;The Group ID of parent is changed to %d.\n&quot;,getpgid(0)); return 0;&#125; 会话一个或多个进程组的集合 开始于用户登录 终止与用户退出 此期间所有进程都属于这个会话期 建立新会话：setsid()函数 该调用进程是组长进程，则出错返回 先调用fork, 父进程终止，子进程调用 该调用进程不是组长进程，则创建一个新会话 •该进程变成新会话首进程(session header) •该进程成为一个新进程组的组长进程。 •该进程没有控制终端，如果之前有，则会被中断组长进程不能成为新会话首进程，新会话首进程必定会成为组长进程… 会话ID:会话首进程的进程组ID获取会话ID: getsid()函数 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main() &#123; pid_t pid; if ((pid=fork())&lt;0) &#123; printf(&quot;fork error!&quot;); exit(1); &#125;else if (pid==0) &#123; printf(&quot;The child process PID is %d.\n&quot;,getpid()); printf(&quot;The Group ID of child is %d.\n&quot;,getpgid(0)); printf(&quot;The Session ID of child is %d.\n&quot;,getsid(0)); sleep(10); setsid(); // 子进程非组长进程，故其成为新会话首进程，且成为组长进程。该进程组id即为会话进程 printf(&quot;Changed:\n&quot;); printf(&quot;The child process PID is %d.\n&quot;,getpid()); printf(&quot;The Group ID of child is %d.\n&quot;,getpgid(0)); printf(&quot;The Session ID of child is %d.\n&quot;,getsid(0)); sleep(20); exit(0); &#125; return 0;&#125; 在子进程中调用setsid()后，子进程成为新会话首进程，且成为一个组长进程，其进程组id等于会话id 守护进程 Linux大多数服务都是通过守护进程实现的，完成许多系统任务 0: 调度进程，称为交换进程(swapper),内核一部分，系统进程 1: init进程, 内核调用，负责内核启动后启动Linux系统 没有终端限制 让某个进程不因为用户、终端或者其他的变化而受到影响，那么就必须把这个进程变成一个守护进程 守护进程编程步骤 1. 创建子进程，父进程退出 •所有工作在子进程中进行 •形式上脱离了控制终端 2. 在子进程中创建新会话 •setsid()函数 •使子进程完全独立出来，脱离控制 3. 改变当前目录为根目录 •chdir()函数 •防止占用可卸载的文件系统 •也可以换成其它路径 4. 重设文件权限掩码 •umask()函数 •防止继承的文件创建屏蔽字拒绝某些权限 •增加守护进程灵活性 5. 关闭文件描述符 •继承的打开文件不会用到，浪费系统资源，无法卸载 •getdtablesize() •返回所在进程的文件描述符表的项数，即该进程打开的文件数目 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/types.h&gt;#include &lt;fcntl.h&gt;int main() &#123; pid_t pid; int i,fd; char *buf=&quot;This is a daemon program.\n&quot;; if ((pid=fork())&lt;0) &#123; printf(&quot;fork error!&quot;); exit(1); &#125;else if (pid&gt;0) // fork且退出父进程 exit(0); setsid(); // 在子进程中创建新会话。 chdir(&quot;/&quot;); // 设置工作目录为根 umask(0); // 设置权限掩码 for(i=0;i&lt;getdtablesize();i++) //getdtablesize返回子进程文件描述符表的项数 close(i); // 关闭这些不将用到的文件描述符 while(1) &#123;// 死循环表征它将一直运行// 以读写方式打开&quot;/tmp/daemon.log&quot;，返回的文件描述符赋给fd if ((fd=open(&quot;/tmp/daemon.log&quot;,O_CREAT|O_WRONLY|O_APPEND,0600))&lt;0) &#123; printf(&quot;Open file error!\n&quot;); exit(1); &#125; // 将buf写到fd中 write(fd,buf,strlen(buf)+1); close(fd); sleep(10); printf(&quot;Never output!\n&quot;); &#125; return 0;&#125; 因为stdout被关掉了，所以“Never ouput!”不会输出。查看/tmp/daemon.log，说明该程序一直在运行]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux虚拟地址空间布局]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[在多任务操作系统中，每个进程都运行在属于自己的内存沙盘中。这个沙盘就是虚拟地址空间(Virtual Address Space)，在32位模式下它是一个4GB的内存地址块。在Linux系统中, 内核进程和用户进程所占的虚拟内存比例是1:3，而Windows系统为2:2(通过设置Large-Address-Aware Executables标志也可为1:3)。这并不意味着内核使用那么多物理内存，仅表示它可支配这部分地址空间，根据需要将其映射到物理内存。 虚拟地址通过页表(Page Table)映射到物理内存，页表由操作系统维护并被处理器引用。内核空间在页表中拥有较高特权级，因此用户态程序试图访问这些页时会导致一个页错误(page fault)。在Linux中，内核空间是持续存在的，并且在所有进程中都映射到同样的物理内存。内核代码和数据总是可寻址，随时准备处理中断和系统调用。与此相反，用户模式地址空间的映射随进程切换的发生而不断变化。 Linux进程在虚拟内存中的标准内存段布局如下图所示： 其中，用户地址空间中的蓝色条带对应于映射到物理内存的不同内存段，灰白区域表示未映射的部分。这些段只是简单的内存地址范围，与Intel处理器的段没有关系。 上图中Random stack offset和Random mmap offset等随机值意在防止恶意程序。Linux通过对栈、内存映射段、堆的起始地址加上随机偏移量来打乱布局，以免恶意程序通过计算访问栈、库函数等地址。execve(2)负责为进程代码段和数据段建立映射，真正将代码段和数据段的内容读入内存是由系统的缺页异常处理程序按需完成的。另外，execve(2)还会将BSS段清零。 用户进程部分分段存储内容如下表所示(按地址递减顺序)： 名称 存储内容 栈 局部变量、函数参数、返回地址等 堆 动态分配的内存 BSS段 未初始化或初值为0的全局变量和静态局部变量 数据段 已初始化且初值非0的全局变量和静态局部变量 代码段 可执行代码、字符串字面值、只读变量 在将应用程序加载到内存空间执行时，操作系统负责代码段、数据段和BSS段的加载，并在内存中为这些段分配空间。栈也由操作系统分配和管理；堆由程序员自己管理，即显式地申请和释放空间。 BSS段、数据段和代码段是可执行程序编译时的分段，运行时还需要栈和堆。 以下详细介绍各个分段的含义。 内核空间内核总是驻留在内存中，是操作系统的一部分。内核空间为内核保留，不允许应用程序读写该区域的内容或直接调用内核代码定义的函数。 栈(stack)栈又称堆栈，由编译器自动分配释放，行为类似数据结构中的栈(先进后出)。堆栈主要有三个用途： 为函数内部声明的非静态局部变量(C语言中称“自动变量”)提供存储空间。 记录函数调用过程相关的维护性信息，称为栈帧(Stack Frame)或过程活动记录(Procedure Activation Record)。它包括函数返回地址，不适合装入寄存器的函数参数及一些寄存器值的保存。除递归调用外，堆栈并非必需。因为编译时可获知局部变量，参数和返回地址所需空间，并将其分配于BSS段。 临时存储区，用于暂存长算术表达式部分计算结果或alloca()函数分配的栈内内存。 持续地重用栈空间有助于使活跃的栈内存保持在CPU缓存中，从而加速访问。进程中的每个线程都有属于自己的栈。向栈中不断压入数据时，若超出其容量就会耗尽栈对应的内存区域，从而触发一个页错误。此时若栈的大小低于堆栈最大值RLIMIT_STACK(通常是8M)，则栈会动态增长，程序继续运行。映射的栈区扩展到所需大小后，不再收缩。 Linux中ulimit -s命令可查看和设置堆栈最大值，当程序使用的堆栈超过该值时, 发生栈溢出(Stack Overflow)，程序收到一个段错误(Segmentation Fault)。注意，调高堆栈容量可能会增加内存开销和启动时间。 堆栈既可向下增长(向内存低地址)也可向上增长, 这依赖于具体的实现。本文所述堆栈向下增长。 堆栈的大小在运行时由内核动态调整。 内存映射段(mmap)此处，内核将硬盘文件的内容直接映射到内存, 任何应用程序都可通过Linux的mmap()系统调用或Windows的CreateFileMapping()/MapViewOfFile()请求这种映射。内存映射是一种方便高效的文件I/O方式， 因而被用于装载动态共享库。用户也可创建匿名内存映射，该映射没有对应的文件, 可用于存放程序数据。在 Linux中，若通过malloc()请求一大块内存，C运行库将创建一个匿名内存映射，而不使用堆内存。”大块” 意味着比阈值 MMAP_THRESHOLD还大，缺省为128KB，可通过mallopt()调整。 该区域用于映射可执行文件用到的动态链接库。在Linux 2.4版本中，若可执行文件依赖共享库，则系统会为这些动态库在从0x40000000开始的地址分配相应空间，并在程序装载时将其载入到该空间。在Linux 2.6内核中，共享库的起始地址被往上移动至更靠近栈区的位置。 从进程地址空间的布局可以看到，在有共享库的情况下，留给堆的可用空间还有两处：一处是从.bss段到0x40000000，约不到1GB的空间；另一处是从共享库到栈之间的空间，约不到2GB。这两块空间大小取决于栈、共享库的大小和数量。这样来看，是否应用程序可申请的最大堆空间只有2GB？事实上，这与Linux内核版本有关。在上面给出的进程地址空间经典布局图中，共享库的装载地址为0x40000000，这实际上是Linux kernel 2.6版本之前的情况了，在2.6版本里，共享库的装载地址已经被挪到靠近栈的位置，即位于0xBFxxxxxx附近，因此，此时的堆范围就不会被共享库分割成2个“碎片”，故kernel 2.6的32位Linux系统中，malloc申请的最大内存理论值在2.9GB左右。 堆(heap)堆用于存放进程运行时动态分配的内存段，可动态扩张或缩减。堆中内容是匿名的，不能按名字直接访问，只能通过指针间接访问。当进程调用malloc(C)/new(C++)等函数分配内存时，新分配的内存动态添加到堆上(扩张)；当调用free(C)/delete(C++)等函数释放内存时，被释放的内存从堆中剔除(缩减) 。 分配的堆内存是经过字节对齐的空间，以适合原子操作。堆管理器通过链表管理每个申请的内存，由于堆申请和释放是无序的，最终会产生内存碎片。堆内存一般由应用程序分配释放，回收的内存可供重新使用。若程序员不释放，程序结束时操作系统可能会自动回收。 堆的末端由break指针标识，当堆管理器需要更多内存时，可通过系统调用brk()和sbrk()来移动break指针以扩张堆，一般由系统自动调用。 使用堆时经常出现两种问题：1) 释放或改写仍在使用的内存(“内存破坏”)；2)未释放不再使用的内存(“内存泄漏”)。当释放次数少于申请次数时，可能已造成内存泄漏。泄漏的内存往往比忘记释放的数据结构更大，因为所分配的内存通常会圆整为下个大于申请数量的2的幂次(如申请212B，会圆整为256B)。 堆不同于数据结构中的”堆”，其行为类似链表。 【扩展阅读】栈和堆的区别 ①管理方式：栈由编译器自动管理；堆由程序员控制，使用方便，但易产生内存泄露。 ②生长方向：栈向低地址扩展(即”向下生长”)，是连续的内存区域；堆向高地址扩展(即”向上生长”)，是不连续的内存区域。这是由于系统用链表来存储空闲内存地址，自然不连续，而链表从低地址向高地址遍历。 ③空间大小：栈顶地址和栈的最大容量由系统预先规定(通常默认2M或10M)；堆的大小则受限于计算机系统中有效的虚拟内存，32位Linux系统中堆内存可达2.9G空间。 ④存储内容：栈在函数调用时，首先压入主调函数中下条指令(函数调用语句的下条可执行语句)的地址，然后是函数实参，然后是被调函数的局部变量。本次调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的指令地址，程序由该点继续运行下条可执行语句。堆通常在头部用一个字节存放其大小，堆用于存储生存期与函数调用无关的数据，具体内容由程序员安排。 ⑤分配方式：栈可静态分配或动态分配。静态分配由编译器完成，如局部变量的分配。动态分配由alloca函数在栈上申请空间，用完后自动释放。堆只能动态分配且手工释放。 ⑥分配效率：栈由计算机底层提供支持：分配专门的寄存器存放栈地址，压栈出栈由专门的指令执行，因此效率较高。堆由函数库提供，机制复杂，效率比栈低得多。Windows系统中VirtualAlloc可直接在进程地址空间中分配一块内存，快速且灵活。 ⑦分配后系统响应：只要栈剩余空间大于所申请空间，系统将为程序提供内存，否则报告异常提示栈溢出。 操作系统为堆维护一个记录空闲内存地址的链表。当系统收到程序的内存分配申请时，会遍历该链表寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点空间分配给程序。若无足够大小的空间(可能由于内存碎片太多)，有可能调用系统功能去增加程序数据段的内存空间，以便有机会分到足够大小的内存，然后进行返回。，大多数系统会在该内存空间首地址处记录本次分配的内存大小，供后续的释放函数(如free/delete)正确释放本内存空间。 此外，由于找到的堆结点大小不一定正好等于申请的大小，系统会自动将多余的部分重新放入空闲链表中。 ⑧碎片问题：栈不会存在碎片问题，因为栈是先进后出的队列，内存块弹出栈之前，在其上面的后进的栈内容已弹出。而频繁申请释放操作会造成堆内存空间的不连续，从而造成大量碎片，使程序效率降低。 可见，堆容易造成内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和内核态切换，内存申请的代价更为昂贵。所以栈在程序中应用最广泛，函数调用也利用栈来完成，调用过程中的参数、返回地址、栈基指针和局部变量等都采用栈的方式存放。所以，建议尽量使用栈，仅在分配大量或大块内存空间时使用堆。 使用栈和堆时应避免越界发生，否则可能程序崩溃或破坏程序堆、栈结构，产生意想不到的后果。 BSS段BSS(Block Started by Symbol)段中通常存放程序中以下符号： 未初始化的全局变量和静态局部变量 初始值为0的全局变量和静态局部变量(依赖于编译器实现) 未定义且初值不为0的符号(该初值即common block的大小) C语言中，未显式初始化的静态分配变量被初始化为0(算术类型)或空指针(指针类型)。由于程序加载时，BSS会被操作系统清零，所以未赋初值或初值为0的全局变量都在BSS中。BSS段仅为未初始化的静态分配变量预留位置，在目标文件中并不占据空间，这样可减少目标文件体积。但程序运行时需为变量分配内存空间，故目标文件必须记录所有未初始化的静态分配变量大小总和(通过start_bss和end_bss地址写入机器代码)。当加载器(loader)加载程序时，将为BSS段分配的内存初始化为0。在嵌入式软件中，进入main()函数之前BSS段被C运行时系统映射到初始化为全零的内存(效率较高)。 注意，尽管均放置于BSS段，但初值为0的全局变量是强符号，而未初始化的全局变量是弱符号。若其他地方已定义同名的强符号(初值可能非0)，则弱符号与之链接时不会引起重定义错误，但运行时的初值可能并非期望值(会被强符号覆盖)。因此，定义全局变量时，若只有本文件使用，则尽量使用static关键字修饰；否则需要为全局变量定义赋初值(哪怕0值)，保证该变量为强符号，以便链接时发现变量名冲突，而不是被未知值覆盖。 某些编译器将未初始化的全局变量保存在common段，链接时再将其放入BSS段。在编译阶段可通过-fno-common选项来禁止将未初始化的全局变量放入common段。 此外，由于目标文件不含BSS段，故程序烧入存储器(Flash)后BSS段地址空间内容未知。U-Boot启动过程中，将U-Boot的Stage2代码(通常位于lib_xxxx/board.c文件)搬迁(拷贝)到SDRAM空间后必须人为添加清零BSS段的代码，而不可依赖于Stage2代码中变量定义时赋0值。 【扩展阅读】BSS历史 BSS(Block Started by Symbol，以符号开始的块)一词最初是UA-SAP汇编器(United Aircraft Symbolic Assembly Program)中的伪指令，用于为符号预留一块内存空间。该汇编器由美国联合航空公司于20世纪50年代中期为IBM 704大型机所开发。 后来该词被作为关键字引入到了IBM 709和7090/94机型上的标准汇编器FAP(Fortran Assembly Program)，用于定义符号并且为该符号预留指定字数的未初始化空间块。 在采用段式内存管理的架构中(如Intel 80x86系统)，BSS段通常指用来存放程序中未初始化全局变量的一块内存区域，该段变量只有名称和大小却没有值。程序开始时由系统初始化清零。 BSS段不包含数据，仅维护开始和结束地址，以便内存能在运行时被有效地清零。BSS所需的运行时空间由目标文件记录，但BSS并不占用目标文件内的实际空间，即BSS节段应用程序的二进制映象文件中并不存在。 数据段(Data)数据段通常用于存放程序中已初始化且初值不为0的全局变量和静态局部变量。数据段属于静态内存分配(静态存储区)，可读可写。 数据段保存在目标文件中(在嵌入式系统里一般固化在镜像文件中)，其内容由程序初始化。例如，对于全局变量int gVar = 10，必须在目标文件数据段中保存10这个数据，然后在程序加载时复制到相应的内存。 数据段与BSS段的区别如下： BSS段不占用物理文件尺寸，但占用内存空间；数据段占用物理文件，也占用内存空间。对于大型数组如int ar0[10000] = {1, 2, 3, …}和int ar1[10000]，ar1放在BSS段，只记录共有10000*4个字节需要初始化为0，而不是像ar0那样记录每个数据1、2、3…，此时BSS为目标文件所节省的磁盘空间相当可观。 当程序读取数据段的数据时，系统会出发缺页故障，从而分配相应的物理内存；当程序读取BSS段的数据时，内核会将其转到一个全零页面，不会发生缺页故障，也不会为其分配相应的物理内存。 运行时数据段和BSS段的整个区段通常称为数据区。某些资料中“数据段”指代数据段 + BSS段 + 堆。 代码段(text)代码段也称正文段或文本段，通常用于存放程序执行代码(即CPU执行的机器指令)。一般C语言执行语句都编译成机器代码保存在代码段。通常代码段是可共享的，因此频繁执行的程序只需要在内存中拥有一份拷贝即可。代码段通常属于只读，以防止其他程序意外地修改其指令(对该段的写操作将导致段错误)。某些架构也允许代码段为可写，即允许修改程序。 代码段指令根据程序设计流程依次执行，对于顺序指令，只会执行一次(每个进程)；若有反复，则需使用跳转指令；若进行递归，则需要借助栈来实现。 代码段指令中包括操作码和操作对象(或对象地址引用)。若操作对象是立即数(具体数值)，将直接包含在代码中；若是局部数据，将在栈区分配空间，然后引用该数据地址；若位于BSS段和数据段，同样引用该数据地址。 代码段最容易受优化措施影响。 保留区位于虚拟地址空间的最低部分，未赋予物理地址。任何对它的引用都是非法的，用于捕捉使用空指针和小整型值指针引用内存的异常情况。 它并不是一个单一的内存区域，而是对地址空间中受到操作系统保护而禁止用户进程访问的地址区域的总称。大多数操作系统中，极小的地址通常都是不允许访问的，如NULL。C语言将无效指针赋值为0也是出于这种考虑，因为0地址上正常情况下不会存放有效的可访问数据。 在32位X86架构的Linux系统中，用户进程可执行程序一般从虚拟地址空间0x08048000开始加载。该加载地址由ELF文件头决定，可通过自定义链接器脚本覆盖链接器默认配置，进而修改加载地址。0x08048000以下的地址空间通常由C动态链接库、动态加载器ld.so和内核VDSO(内核提供的虚拟共享库)等占用。通过使用mmap系统调用，可访问0x08048000以下的地址空间。 通过cat /proc/self/maps命令查看加载表如下： 【扩展阅读】分段的好处 进程运行过程中，代码指令根据流程依次执行，只需访问一次(当然跳转和递归可能使代码执行多次)；而数据(数据段和BSS段)通常需要访问多次，因此单独开辟空间以方便访问和节约空间。具体解释如下： 当程序被装载后，数据和指令分别映射到两个虚存区域。数据区对于进程而言可读写，而指令区对于进程只读。两区的权限可分别设置为可读写和只读。以防止程序指令被有意或无意地改写。 现代CPU具有极为强大的缓存(Cache)体系，程序必须尽量提高缓存命中率。指令区和数据区的分离有利于提高程序的局部性。现代CPU一般数据缓存和指令缓存分离，故程序的指令和数据分开存放有利于提高CPU缓存命中率。 当系统中运行多个该程序的副本时，其指令相同，故内存中只须保存一份该程序的指令部分。若系统中运行数百进程，通过共享指令将节省大量空间(尤其对于有动态链接的系统)。其他只读数据如程序里的图标、图片、文本等资源也可共享。而每个副本进程的数据区域不同，它们是进程私有的。 此外，临时数据及需要再次使用的代码在运行时放入栈区中，生命周期短。全局数据和静态数据可能在整个程序执行过程中都需要访问，因此单独存储管理。堆区由用户自由分配，以便管理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux系统编程之文件与IO]]></title>
    <url>%2F2019%2F05%2F19%2FLinux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%E4%B9%8B%E6%96%87%E4%BB%B6%E4%B8%8EIO%2F</url>
    <content type="text"><![CDATA[文件描述符、open，close什么是IO？输入/输出是主存和外部设备之间拷贝数据的过程设备-&gt;内存（输入操作）内存-&gt;设备（输出操作） 高级I/O：ANSI C提供的标准I/O库称为高级I/O，通常也称为带缓冲的I/O低级I/O：通常也称为不带缓冲的I/O 文件描述符：fd对于Linux而言，所有对设备或文件的操作都是通过文件描述符进行的。当打开或者创建一个文件的时候，内核向进程返回一个文件描述符（非负整数）。后续对文件的操作只需通过该文件描述符，内核记录有关这个打开文件的信息。一个进程启动时，默认打开了3个文件，标准输入、标准输出、标准错误，对应文件描述符是0（STDIN_FILENO）、1（STDOUT_FILENO）、2（STDERR_FILENO）,这些常量定义在unistd.h头文件中。C库函数中与之对应的是：stdin,stdout,stderr,不过这三个是FILE指针类型。 文件描述符与文件指针相互转换可以通过以下两个函数实现： fileno：将文件指针转换为文件描述符12#include &lt;stdio.h&gt;int fileno(FILE *stream) 测试程序：12345678910#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;int main(void)&#123; printf(&quot;fileno(stdin) = %d\n&quot;, fileno(stdin)); printf(&quot;fileno(stdout) = %d\n&quot;, fileno(stdout)); printf(&quot;fileno(stderr) = %d\n&quot;, fileno(stderr)); return 0;&#125; fdopen：将文件描述符转换为文件指针12#include &lt;stdio.h&gt;FILE *fdopen(int fd, const char *mode) //mode :r,w,r+,w+,a,a+ 文件系统调用open系统调用有几种方法可以获得允许访问文件的文件描述符。最常用的是使用open（）（打开）系统调用 函数原型123456#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;fcntl.h&gt;int open(const char *pathname, int flags); int open(const char *pathname, int flags, mode_t mode); 参数 path ：文件的名称，可以包含（绝对和相对）路径 flags：文件打开模式 mode：用来规定对该文件的所有者，文件的用户组及系 统中其他用户的访问权限 返回值打开成功，返回文件描述符；打开失败，返回－1 文件打开方式：O_EXCL表示：当O_EXCL|O_CREAT时，若文件存在，则打开失败，不存在，则打开成功 访问权限： open系统调用的几点说明：可以利用按位逻辑加(bitwise-OR)(|)对打开方式的标志值进行组合。如打开一个新文件：1#define NEWFILE (O_WRONLY|O_CREAT|O_TRUNC) 对访问权限位进行访问所用到的标识符，均可以通过12#include &lt;sys/stat.h&gt; 访问到,同样可以通过|运算来对访问权限进行组合也可以直接给出数字表示如0655#define MODE755 (S_IRWXU|S_IRGRP|S_IXGRP|S_IROTH|S_IXOTH) 注：文件的访问权限是根据：umask&amp;~mode得出来的，例如umask=0022,mode = 0655 则访问权限为：644 测试程序：12345678910111213141516171819202122232425262728#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)int main(void)&#123; umask(0); int fd; fd = open(&quot;test.txt&quot;, O_WRONLY | O_CREAT, 0666); if (fd == -1) ERR_EXIT(&quot;open error&quot;); printf(&quot;open succ\n&quot;); return 0;&#125; 测试结果一：采用默认的umask值 测试结果二：重新设置umask值 close系统调用为了重新利用文件描述符，用close()系统调用释放打开的文件描述符 函数原型：12#include &lt;unistd.h&gt;int close(int fd); 函数参数：-fd ：要关闭的文件的文件描述符 返回值如果出现错误，返回-1调用成功返回0 注：若没有显示调用close()，当程序退出时也会关闭文件 creat系统调用为了维持与早期的UNIX系统的向后兼容性，Linux也提供可选的创建文件的系统调用，它称为creat()。现代的linux内核很少采用creat创建文件，因为open可以完成创建功能 函数原型：1int creat(const char *path, mode_t mode)； 参数12path ：文件的名称，可以包含（绝对和相对）路径mode: 用来规定对该文件的所有者，文件的用户组及系 统中其他用户的访问权限 返回值打开成功，返回文件描述符；打开失败，返回－1 在UNIX的早期版本中，open()系统调用仅仅存在两个参数的形式。如文件不存在，它就不能打开这些文件。文件的创建则由单独的系统调用creat()完成。在Linux及所有UNIX的近代版本中，creat()系统调用是多余的。 creat()调用1fd = creat(file, mode)； 完全等价于近代的open()调用1fd = open(file, O_WRONLY | O_CREAT | O_TRUNC, mode)； 系统调用read和writeread系统调用一旦有了与一个打开文件描述相连的文件描述符，只要该文件是用O_RDONLY或O_RDWR标志打开的，就可以用read()系统调用从该文件中读取字节 函数原型：12#include &lt;unistd.h&gt;ssize_t read(int fd, void *buf, size_t count); 参数fd ：想要读的文件的文件描述符buf ： 指向内存块的指针，从文件中读取来的字节放到这个内存块中count ： 从该文件复制到buf中的字节个数 返回值如果出现错误，返回-1读文件结束，返回0否则返回从该文件复制到规定的缓冲区中的字节数 write系统调用用write()系统调用将数据写到一个文件中 函数原型：12#include &lt;unistd.h&gt;ssize_t write(int fd, const void *buf, size_t count); 函数参数： fd：要写入的文件的文件描述符 buf：指向内存块的指针，从这个内存块中读取数据写入 到文件中 count：要写入文件的字节个数 返回值如果出现错误，返回-1 注:write并非真正写入磁盘,而是先写入内存缓冲区,待缓冲区满或进行刷新操作后才真正写入磁盘,若想实时写入磁盘可调用int fsync(int fd);或在open时flags加上O_SYNC 利用read和write进行文件拷贝 程序代码:12345678910111213141516171819202122232425262728293031#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#define EXIT_ERR(m) \do&#123;\ perror(m);\ exit(EXIT_FAILURE);\&#125;while(0)int main(int argc, char **argv)&#123; int infd; int outfd; if(argc != 3)&#123; fprintf(stderr,&quot;usage:%s src des\n&quot;,argv[0]); exit(EXIT_FAILURE); &#125; if((infd = open(argv[1],O_RDONLY)) == -1) EXIT_ERR(&quot;open error&quot;); if((outfd = open(argv[2],O_WRONLY|O_CREAT|O_TRUNC,0644)) == -1) EXIT_ERR(&quot;OPEN ERROR&quot;); char buf[1024]; int n; while((n = read(infd, buf, 1024)) &gt; 0 )&#123; write(outfd, buf, n); &#125; close(infd); close(outfd); return 0;&#125; 结果： 利用lseek()创建空洞文件lseek（）系统调用功能说明：通过指定相对于开始位置、当前位置或末尾位置的字节数来重定位 curp，这取决于 lseek() 函数中指定的位置 函数原型：1234#include &lt;sys/types.h&gt; #include &lt;unistd.h&gt;off_t lseek(int fd, off_t offset, int whence); 参数说明： fd：文件描述符 offset：偏移量，该值可正可负，负值为向前移 whence：搜索的起始位置，有三个选项： SEEK_SET: 当前位置为文件的开头，新位置为偏移量大小 SEEK_CUR: 当前位置为文件指针位置，新位置为当前位置加上偏移量大小 SEEK_END: 当前位置为文件结尾，新位置为偏移量大小 返回值：文件新的偏移值 利用lseek（）产生空洞文件（hole）说明：seek()函数允许将文件偏移量设置为超出文件末尾（但这不会改变文件的大小）。 如果此时稍后写入数据，则后续读取间隙中的数据（“空洞”）将返回空字节（’\0’），直到数据实际写入间隙。 程序代码：123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)int main(void)&#123; int fd; int ret; fd = open(&quot;hole.txt&quot;,O_WRONLY|O_CREAT|O_TRUNC,0644); if(fd == -1) ERR_EXIT(&quot;open error&quot;); write(fd,&quot;hello&quot;,5); ret = lseek(fd,1024*1024*1024,SEEK_CUR); if(ret == -1) ERR_EXIT(&quot;lseek error&quot;); write(fd,&quot;world&quot;,5); close(fd); return 0;&#125; 测试结果：程序创建一个hole文件，然后写入”hello”字符，在利用lseek系统调用从当前位置偏移到102410241024之后再写入”world”字符，ls显示文件大小为1.1G，实际上它并没有占用这么多的磁盘空间，du表明hole文件只有8k，系统只是存储一些信息，用它来表示有多少个\0，当我们用cat查看文件内容时只看到hello，由于文件太大最后的world太后以致看不到，但当我们用od命令查看时，可以发现有好多个\0。 目录访问相关系统调用目录操作相关的系统调用mkdir和rmdir系统调用12345678filename: mk_rm_dir.c #include &lt;sys/stat.h&gt; int mkdir(const char *path, mode_t mode); return: S 0 F -1 note: mode权限至少要有执行权限。 1234567#include &lt;unistd.h&gt; int rmdir(const char *pathname); return: S 0 F -1 note: pathname目录必须是空目录。 实例12345678910111213141516#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;stdio.h&gt;#include &lt;assert.h&gt;#define MODE (S_IRUSR | S_IWUSR | S_IXUSR | S_IXGRP | S_IXOTH)int main(int argc, char *argv[])&#123; char *pname; assert(argc == 2); pname = argv[1]; assert(mkdir(pname, MODE) == 0); printf(&quot;create %s successful!\n&quot;, pname); assert(rmdir(pname) == 0); printf(&quot;rm %s\n&quot;, pname); return 0;&#125; 测试：1[qtlldr@qtldr editing]./mkrmdirtestdircreatetestdirsuccessful!rmtestdir[qtlldr@qtldrediting] chdir, getcwd系统调用12345#include &lt;unistd.h&gt; int chdir(const char *pathname); return: S 0 F -1 12345#include &lt;unistd.h&gt; char *getpwd(char *buf, size_t size); return: S buf F NULL buf是缓冲地址，size是buf的长度。该缓冲必须有足够的长度以容纳绝对路径名加上一个null终止符。 实例123456789101112131415#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;assert.h&gt;#define BUFSIZE (50)int main(void)&#123; char buf[BUFSIZE]; memset((void *)buf, &apos;\0&apos;, sizeof buf); assert(chdir(&quot;/tmp&quot;) == 0); printf(&quot;chdir to /tmp successful\n&quot;); assert(getcwd(buf, BUFSIZE) != NULL); printf(&quot;now the directory is %s\n&quot;, buf); return 0;&#125; 测试：1[qtlldr@qtldr editing]./chgetdirchdirto/tmpsuccessfulnowthedirectoryis/tmp[qtlldr@qtldrediting] opendir, closedir, readdir,12345678#include &lt;sys/type.s&gt; #include &lt;dirent.h&gt; DIR *opendir(const char *dirname); return: S DIR指针 F NULL note: DIR是一种目录结构，类似FILE。 12345678910#include &lt;sys/types.h&gt; #include &lt;dirent.h&gt; struct dirent *readir(DIR *dirp); return: S 一个指向保存目录流下一个目录项的dirent指针 F NULL note: struct dirent &#123; char d_name[NAME + 1]; /* \0结尾的文件名 */ &#125; 到达目录尾或出错返回NULL，但是到达目录尾不会设置errno，出错则设置。如果在readir的同时有其他进程在目录中创建或者删除文件爱你，readdir不保证能列处该目录中所有文件。123456#include &lt;sys/types.h&gt; #include &lt;dirent.h&gt; int closedir(DIR *dirp); return: S 0 F -1 printdir 输出目录文件或者统计目录中的文件数目语法： printdir [option] &lt;files…&gt;选项： -l 输出目录下的文件名 -c 统计目录下的文件 -d n 指定最大层次，最大为30默认行为： 如果没有指定选项，那么只输出该目录下的文件名123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102#include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;#define INDENT_DEPTH (4) /* 列举文件时的缩进数 */#define DEPTH_MAX (30) /* 递归便利的最大层次 */#define HELPFILE (&quot;help.txt&quot;)typedef int count_t;struct nfiletype &#123; count_t ndir; count_t nreg; count_t nchr; count_t nfifo; count_t nsock; count_t nchar; count_t nblock; count_t nlink; count_t ntotol; count_t nunknow;&#125;;/*记录各个类型文件的数目*/int DEPTH = 20; /* 递归层级限制 */int idepth_count = 1;int idepth_print = 1;static struct nfiletype *count_files(const char *pathname, struct nfiletype *nfile);static void printdir(const char *pathname, int indent);int main(int argc, char **argv)&#123; int opt; int depth_opt; int count_flag = 0; int print_flag = 0; char *parg = NULL; struct nfiletype nfiles = &#123;0&#125;; int fd_help; char buf_help[BUFSIZ]; int nread_help; char *filename_help = HELPFILE; while ((opt = getopt(argc, argv, &quot;lhd:c&quot;)) != -1) &#123; switch (opt) &#123; case &apos;l&apos;: print_flag = 1; break; case &apos;c&apos;: count_flag = 1; break; case &apos;d&apos;: depth_opt = strtol(optarg, NULL, 10); DEPTH = depth_opt &lt;= DEPTH_MAX ? depth_opt: DEPTH; break; case &apos;:&apos;: printf(&quot;option needs a value\n&quot;); break; case &apos;?&apos;: printf(&quot;unknown option :%c\n&quot;, optopt); break; case &apos;h&apos;: fd_help = open(filename_help, O_RDONLY); if (fd_help != -1) &#123; while ((nread_help = read(fd_help, buf_help, BUFSIZ)) &gt; 0) &#123; write(1, buf_help, nread_help); &#125; close(fd_help); &#125; else &#123; fprintf(stderr, &quot;open %s failed!\n&quot;, filename_help); &#125; return 0; &#125; &#125; /* 如果没有选项，那么默认是打印目录 */ if (!print_flag &amp;&amp; !count_flag) print_flag = 1; for( ; optind &lt; argc; optind++) &#123; parg = argv[optind]; if (print_flag) &#123; //printf(&quot;DEBUG-- printdir --%s\n&quot;, parg); printdir(parg, 4); &#125; if (count_flag) &#123; memset((void *)&amp;nfiles, &apos;\0&apos;, sizeof nfiles); //printf(&quot;DEBUG-- count_files--%s\n&quot;, parg); count_files(parg, &amp;nfiles); printf(&quot;In the %s there are :\n&quot;, parg); printf(&quot; directory %d\n&quot;, nfiles.ndir); printf(&quot; regular file %d\n&quot;, nfiles.nreg); printf(&quot; specal character file %d\n&quot;, nfiles.nchr); printf(&quot; special block file %d\n&quot;, nfiles.nblock); printf(&quot; fifo file %d\n&quot;, nfiles.nfifo); printf(&quot; sock file %d\n&quot;, nfiles.nsock); printf(&quot; link file %d\n&quot;, nfiles.nlink); printf(&quot; unknown file %d\n&quot;, nfiles.nunknow); printf(&quot;Total %d\n&quot;, nfiles.ntotol); &#125; &#125; return 0;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* *function: 对该目录下的文件类型进行统计 * input arg: * pathname:目录名指针 * nfile:记录文件类型数目的结构体指针 * return： * 记录文件类型数目的结构体指针 */static struct nfiletype *count_files(const char *pathname, struct nfiletype *nfile)&#123; DIR *dp; struct dirent *entry; struct stat statbuf; //printf(&quot;DEBUG-- in count_files -- %s\n&quot;, pathname); /* 层次控制 */ if (idepth_count &gt; DEPTH) return NULL; idepth_count++; if ((dp = opendir(pathname)) == NULL) &#123; fprintf(stderr, &quot;can not open %s\n&quot;, pathname); return NULL; &#125; chdir(pathname); while ((entry = readdir(dp)) != NULL) &#123; /* 跳过 . 和 .. */ if (strcmp(entry-&gt;d_name, &quot;.&quot;) == 0 || strcmp(entry-&gt;d_name, &quot;..&quot;) == 0) continue; /* 取得文件信息 */ if (lstat(entry-&gt;d_name, &amp;statbuf) == -1) &#123; fprintf(stderr, &quot;can not test the %s&apos;s type\n&quot;, entry-&gt;d_name); return NULL; &#125; /* 统计文件数目 */ if (S_ISDIR(statbuf.st_mode)) &#123; /* 是目录就递归吧 */ //printf(&quot;DEBUG -- directory %s\n&quot;, entry-&gt;d_name); count_files(entry-&gt;d_name, nfile); nfile-&gt;ndir++; &#125; else if (S_ISREG(statbuf.st_mode)) &#123; //printf(&quot;DEBUG -- regular file %s\n&quot;, entry-&gt;d_name); nfile-&gt;nreg++; &#125; else if (S_ISCHR(statbuf.st_mode)) nfile-&gt;nchr++; else if (S_ISBLK(statbuf.st_mode)) nfile-&gt;nblock++; else if (S_ISLNK(statbuf.st_mode)) nfile-&gt;nlink++; else if (S_ISFIFO(statbuf.st_mode)) nfile-&gt;nfifo++; else if (S_ISSOCK(statbuf.st_mode)) nfile-&gt;nsock++; else nfile-&gt;nunknow++; nfile-&gt;ntotol++; &#125; chdir(&quot;..&quot;); closedir(dp); return nfile; &#125; 1234567891011121314151617181920212223242526272829303132333435363738394041 /*nblock; *function:列出目录中的文件nlink; *input arg:ntotol; * pathname: 目录名 *return: * void */static void printdir(const char *pathname, int indent)&#123; DIR *dp; struct dirent *entry; struct stat statbuf; /* 层次控制 */ if (idepth_print &gt; DEPTH) return ; idepth_print++; if ((dp = opendir(pathname)) == NULL) &#123; fprintf(stderr, &quot;can not open %s\n&quot;, pathname); return ; &#125; chdir(pathname); while ((entry = readdir(dp)) != NULL) &#123; /* 跳过 . 和 .. */ if (strcmp(entry-&gt;d_name, &quot;.&quot;) == 0 || strcmp(entry-&gt;d_name, &quot;..&quot;) == 0) continue; if (lstat(entry-&gt;d_name, &amp;statbuf) == -1) &#123; fprintf(stderr, &quot;can not test the %s&apos;s type\n&quot;, entry-&gt;d_name); return ; &#125; if (S_ISDIR(statbuf.st_mode)) &#123; /* 是目录就递归吧 */ printf(&quot;%*s%s/\n&quot;, indent,&quot; &quot;, entry-&gt;d_name); printdir(entry-&gt;d_name, indent + INDENT_DEPTH); &#125; else &#123; printf(&quot;%*s%s\n&quot;, indent,&quot; &quot;, entry-&gt;d_name); &#125; &#125; chdir(&quot;..&quot;); closedir(dp);&#125; stat（）系统调用获取文件信息stat()获取文件元数据stat系统调用原型：12345#include &lt;sys/stat.h&gt;int stat(const char *path, struct stat *buf); int fstat(int fd, struct stat *buf); int lstat(const char *path, struct stat *buf); 123456789101112131415struct stat &#123; dev_t st_dev; /* ID of device containing file ：该文件所属设备的设备号，设备号包括主设备和和次设备号，dev_t是16位整数，高8位表示主设备号，低8位表示次设备号*/ ino_t st_ino; /* inode number */ mode_t st_mode; /* protection ：包含文件访问权限信息及文件类型*/ nlink_t st_nlink; /* number of hard links */ uid_t st_uid; /* user ID of owner */ gid_t st_gid; /* group ID of owner */ dev_t st_rdev; /* device ID (if special file)：如果该文件是特殊文件即设备文件，则表示设备号 */ off_t st_size; /* total size, in bytes */ blksize_t st_blksize; /* blocksize for file system I/O */ blkcnt_t st_blocks; /* number of 512B blocks allocated ：分配的块数量*/ time_t st_atime; /* time of last access */ time_t st_mtime; /* time of last modification */ time_t st_ctime; /* time of last status change：如修改文件的权限 */ &#125;; 文件类型有两种方式获得： 1.通过以下的一些宏进行验证：m为struct stat中得st_mode字段1234567S_ISREG(m) is it a regular file?S_ISDIR(m) directory?S_ISCHR(m) character device?S_ISBLK(m) block device?S_ISFIFO(m) FIFO (named pipe)?S_ISLNK(m) symbolic link? (Not in POSIX.1-1996.)S_ISSOCK(m) socket? (Not in POSIX.1-1996.) 2.利用struct stat中得st_mode字段与S_IFMT进行与运算：mode&amp;S_IFMT，然后将得到的结果与下列的常量比较，相等就是The following flags are defined for the st_mode field:12345678S_IFMT 0170000 bit mask for the file type bit fields S_IFSOCK 0140000 socket S_IFLNK 0120000 symbolic link S_IFREG 0100000 regular file S_IFBLK 0060000 block device S_IFDIR 0040000 directory S_IFCHR 0020000 character device S_IFIFO 0010000 FIFO 文件访问权限获得：利用struct stat中得st_mode字段与S_IFMT进行与运算：mode&amp;S_IFMT，然后将得到的结果与下列的常量比较，相等就是12345678910111213141516S_IFMT 0170000 bit mask for the file type bit fields S_ISUID 0004000 set UID bit S_ISGID 0002000 set-group-ID bit (see below) S_ISVTX 0001000 sticky bit (see below) S_IRWXU 00700 mask for file owner permissions S_IRUSR 00400 owner has read permission S_IWUSR 00200 owner has write permission S_IXUSR 00100 owner has execute permission S_IRWXG 00070 mask for group permissions S_IRGRP 00040 group has read permission S_IWGRP 00020 group has write permission S_IXGRP 00010 group has execute permission S_IRWXO 00007 mask for permissions for others (not in group) S_IROTH 00004 others have read permission S_IWOTH 00002 others have write permission S_IXOTH 00001 others have execute permission 示例程序：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143#include &lt;unistd.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#define ERR_EXIT(m) \ do \ &#123; \ perror(m); \ exit(EXIT_FAILURE); \ &#125; while(0)#define MAJOR(a) (int)((unsigned short)a &gt;&gt; 8) //高8位：主设备号#define MINOR(a) (int)((unsigned short)a &amp; 0xFF)//低8位：次设备号int filetype(struct stat *buf);void fileperm(struct stat *buf, char *perm);int main(int argc, char *argv[])&#123; if (argc != 2) &#123; fprintf(stderr, &quot;Usage %s file\n&quot;, argv[0]); exit(EXIT_FAILURE); &#125; struct stat sbuf; printf(&quot;Filename:%s\n&quot;, argv[1]); if (lstat(argv[1], &amp;sbuf) == -1) ERR_EXIT(&quot;stat error&quot;); printf(&quot;File number:major %d,minor %d inode %d\n&quot;, MAJOR(sbuf.st_dev), MINOR(sbuf.st_dev), (int)sbuf.st_ino); if (filetype(&amp;sbuf)) &#123; printf(&quot;Device number:major %d,minor %d\n&quot;, MAJOR(sbuf.st_rdev), MINOR(sbuf.st_rdev)); &#125; char perm[11] = &#123;0&#125;; fileperm(&amp;sbuf, perm); printf(&quot;File permission bits=%o %s\n&quot;, sbuf.st_mode &amp; 07777, perm); return 0;&#125;int filetype(struct stat *buf)&#123; int flag = 0; printf(&quot;Filetype:&quot;); mode_t mode; mode = buf-&gt;st_mode; switch (mode &amp; S_IFMT) &#123; case S_IFSOCK: printf(&quot;socket\n&quot;); break; case S_IFLNK: printf(&quot;symbolic link\n&quot;); break; case S_IFREG: printf(&quot;regular file\n&quot;); break; case S_IFBLK: printf(&quot;block device\n&quot;); flag = 1; //该文件为设备文件 break; case S_IFDIR: printf(&quot;directory\n&quot;); break; case S_IFCHR: printf(&quot;character device\n&quot;); flag = 1; break; case S_IFIFO: printf(&quot;FIFO\n&quot;); break; default: printf(&quot;unknown file type\n&quot;); break; &#125; return flag;&#125;void fileperm(struct stat *buf, char *perm)&#123; strcpy(perm, &quot;----------&quot;); perm[0] = &apos;?&apos;; mode_t mode; mode = buf-&gt;st_mode; switch (mode &amp; S_IFMT) &#123; case S_IFSOCK: perm[0] = &apos;s&apos;; break; case S_IFLNK: perm[0] = &apos;l&apos;; break; case S_IFREG: perm[0] = &apos;-&apos;; break; case S_IFBLK: perm[0] = &apos;b&apos;; break; case S_IFDIR: perm[0] = &apos;d&apos;; break; case S_IFCHR: perm[0] = &apos;c&apos;; break; case S_IFIFO: perm[0] = &apos;p&apos;; break; &#125; if (mode &amp; S_IRUSR) perm[1] = &apos;r&apos;; if (mode &amp; S_IWUSR) perm[2] = &apos;w&apos;; if (mode &amp; S_IXUSR) perm[3] = &apos;x&apos;; if (mode &amp; S_IRGRP) perm[4] = &apos;r&apos;; if (mode &amp; S_IWGRP) perm[5] = &apos;w&apos;; if (mode &amp; S_IXGRP) perm[6] = &apos;x&apos;; if (mode &amp; S_IROTH) perm[7] = &apos;r&apos;; if (mode &amp; S_IWOTH) perm[8] = &apos;w&apos;; if (mode &amp; S_IXOTH) perm[9] = &apos;x&apos;; perm[10] = &apos;\0&apos;;&#125; 运行结果：]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程同步之POSIX信号量]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5%E4%B9%8BPOSIX%E4%BF%A1%E5%8F%B7%E9%87%8F%2F</url>
    <content type="text"><![CDATA[POSIX信号量是属于POSIX标准系统接口定义的实时扩展部分。在SUS（Single UNIX Specification）单一规范中，定义的XSI IPC中也同样定义了人们通常称为System V信号量的系统接口。信号量作为进程间同步的工具是很常用的一种同步IPC类型。 在《UNIX网络编程 卷2：进程间通信》的前言第二页与第1版的区别中作者提到“POSIX IPC函数时大势所趋，因为他们比System V中的相应部分更具有优势”，这里所说的优势我还得慢慢领会呀。。。&lt;T_T&gt; 信号量是一种用于不同进程间进行同步的工具，当然对于进程安全的对于线程也肯定是安全的，所以信号量也理所当然可以用于同一进程内的不同线程的同步。 有了互斥量和条件变量还提供信号量的原因是：信号量的主要目的是提供一种进程间同步的方式。这种同步的进程可以共享也可以不共享内存区。虽然信号量的意图在于进程间的同步，互斥量和条件变量的意图在于线程间同步，但信号量也可用于线程间同步，互斥量和条件变量也可通过共享内存区进行进程间同步。但应该根据具体应用考虑到效率和易用性进行具体的选择。 POSIX信号量的操作POSIX信号量有两种：有名信号量和无名信号量，无名信号量也被称作基于内存的信号量。有名信号量通过IPC名字进行进程间的同步，而无名信号量如果不是放在进程间的共享内存区中，是不能用来进行进程间同步的，只能用来进行线程同步。 POSIX信号量有三种操作： （1）创建一个信号量。创建的过程还要求初始化信号量的值。 根据信号量取值（代表可用资源的数目）的不同，POSIX信号量还可以分为： 二值信号量：信号量的值只有0和1，这和互斥量很类型，若资源被锁住，信号量的值为0，若资源可用，则信号量的值为1；计数信号量：信号量的值在0到一个大于1的限制值（POSIX指出系统的最大限制值至少要为32767）。该计数表示可用的资源的个数。（2）等待一个信号量（wait）。该操作会检查信号量的值，如果其值小于或等于0，那就阻塞，直到该值变成大于0，然后等待进程将信号量的值减1，进程获得共享资源的访问权限。这整个操作必须是一个原子操作。该操作还经常被称为P操作（荷兰语Proberen，意为：尝试）。 （3）挂出一个信号量（post）。该操作将信号量的值加1，如果有进程阻塞着等待该信号量，那么其中一个进程将被唤醒。该操作也必须是一个原子操作。该操作还经常被称为V操作（荷兰语Verhogen，意为：增加） 下面演示经典的生产者消费者问题，单个生产者和消费者共享一个缓冲区； 下面是生产者和消费者同步的伪代码： 12345678910//信号量的初始化get = 0;//表示可读资源的数目put = 1;//表示可写资源的数目 //生产者进程 //消费者进程for(; ;)&#123; for(; ;)&#123;Sem_wait(put); Sem_wait(get);写共享缓冲区； 读共享缓冲区；Sem_post(get); Sem_post(put);&#125; &#125; 上面的代码大致流程如下：当生产者和消费者开始都运行时，生产者获取put信号量，此时put为1表示有资源可用，生产者进入共享缓冲区，进行修改。而消费者获取get信号量，而此时get为0，表示没有资源可读，于是消费者进入等待序列，直到生产者生产出一个数据，然后生产者通过挂出get信号量来通知等待的消费者，有数据可以读。很多时候信号量和互斥量，条件变量三者都可以在某种应用中使用，那这三者的差异有哪些呢，下面列出了这三者之间的差异： 互斥量必须由给它上锁的线程解锁。而信号量不需要由等待它的线程进行挂出，可以在其他进程进行挂出操作。互斥量要么被锁住，要么是解开状态，只有这两种状态。而信号量的值可以支持多个进程成功进行wait操作。信号量的挂出操作总是被记住，因为信号量有一个计数值，挂出操作总会将该计数值加1，然而当向条件变量发送一个信号时，如果没有线程等待在条件变量，那么该信号会丢失。 POSIX信号量函数接口POSIX信号量的函数接口如下图所示： 有名信号量的创建和删除123456#include &lt;semaphore.h&gt; sem_t *sem_open(const char *name, int oflag);sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value); //成功返回信号量指针，失败返回SEM_FAILED sem_open用于创建或打开一个信号量，信号量是通过name参数即信号量的名字来进行标识的。关于POSX IPC的名字可以参考《UNIX网络编程 卷2：进程间通信》P14。 oflag参数可以为：0，O_CREAT，O_EXCL。如果为0表示打开一个已存在的信号量，如果为O_CREAT，表示如果信号量不存在就创建一个信号量，如果存在则打开被返回。此时mode和value需要指定。如果为O_CREAT | O_EXCL，表示如果信号量已存在会返回错误。 mode参数用于创建信号量时，表示信号量的权限位，和open函数一样包括：S_IRUSR，S_IWUSR，S_IRGRP，S_IWGRP，S_IROTH，S_IWOTH。 value表示创建信号量时，信号量的初始值。12345#include &lt;semaphore.h&gt; int sem_close(sem_t *sem);int sem_unlink(const char *name); //成功返回0，失败返回-1 sem_close用于关闭打开的信号量。当一个进程终止时，内核对其上仍然打开的所有有名信号量自动执行这个操作。调用sem_close关闭信号量并没有把它从系统中删除它，POSIX有名信号量是随内核持续的。即使当前没有进程打开某个信号量它的值依然保持。直到内核重新自举或调用sem_unlink()删除该信号量。 sem_unlink用于将有名信号量立刻从系统中删除，但信号量的销毁是在所有进程都关闭信号量的时候。 信号量的P操作12345678910#include &lt;semaphore.h&gt; int sem_wait (sem_t *sem); #ifdef __USE_XOPEN2Kint sem_timedwait(sem_t *sem, const struct timespec *abs_timeout);#endif int sem_trywait (sem_t * sem); //成功返回0，失败返回-1 sem_wait()用于获取信号量，首先会测试指定信号量的值，如果大于0，就会将它减1并立即返回，如果等于0，那么调用线程会进入睡眠，指定信号量的值大于0.sem_trywait和sem_wait的差别是，当信号量的值等于0的，调用线程不会阻塞，直接返回，并标识EAGAIN错误。 sem_timedwait和sem_wait的差别是当信号量的值等于0时，调用线程会限时等待。当等待时间到后，信号量的值还是0，那么就会返回错误。其中struct timespec *abs_timeout是一个绝对时间，具体可以参考条件变量关于等待时间的使用 信号量的V操作1234#include &lt;semaphore.h&gt; int sem_post(sem_t *sem); //成功返回0，失败返回-1 当一个线程使用完某个信号量后，调用sem_post，使该信号量的值加1，如果有等待的线程，那么会唤醒等待的一个线程。 获取当前信号量的值1234#include &lt;semaphore.h&gt; int sem_getvalue(sem_t *sem, int *sval); //成功返回0，失败返回-1 该函数返回当前信号量的值，通过sval输出参数返回，如果当前信号量已经上锁（即同步对象不可用），那么返回值为0，或为负数，其绝对值就是等待该信号量解锁的线程数。 下面测试在Linux下的信号量是否会出现负值：123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt; #include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt; using namespace std; #define SEM_NAME &quot;/sem_name&quot; sem_t *pSem; void * testThread (void *ptr)&#123; sem_wait(pSem); sleep(10); sem_close(pSem);&#125; int main()&#123; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); pthread_t pid; int semVal; for (int i = 0; i &lt; 7; ++i) &#123; pthread_create(&amp;pid, NULL, testThread, NULL); sleep(1); sem_getvalue(pSem, &amp;semVal); cout&lt;&lt;&quot;semaphore value:&quot;&lt;&lt;semVal&lt;&lt;endl; &#125; sem_close(pSem); sem_unlink(SEM_NAME);&#125; 执行结果如下：1234567semaphore value:4semaphore value:3semaphore value:2semaphore value:1semaphore value:0semaphore value:0semaphore value:0 这说明在Linux 2.6.18中POSIX信号量是不会出现负值的。 无名信号量的创建和销毁123456#include &lt;semaphore.h&gt; int sem_init(sem_t *sem, int pshared, unsigned int value); //若出错则返回-1int sem_destroy(sem_t *sem); //成功返回0，失败返回-1 sem_init()用于无名信号量的初始化。无名信号量在初始化前一定要在内存中分配一个sem_t信号量类型的对象，这就是无名信号量又称为基于内存的信号量的原因。 sem_init()第一个参数是指向一个已经分配的sem_t变量。第二个参数pshared表示该信号量是否由于进程间通步，当pshared = 0，那么表示该信号量只能用于进程内部的线程间的同步。当pshared != 0，表示该信号量存放在共享内存区中，使使用它的进程能够访问该共享内存区进行进程同步。第三个参数value表示信号量的初始值。 这里需要注意的是，无名信号量不使用任何类似O_CREAT的标志，这表示sem_init()总是会初始化信号量的值，所以对于特定的一个信号量，我们必须保证只调用sem_init()进行初始化一次，对于一个已初始化过的信号量调用sem_init()的行为是未定义的。如果信号量还没有被某个线程调用还好，否则基本上会出现问题。 使用完一个无名信号量后，调用sem_destroy摧毁它。这里要注意的是：摧毁一个有线程阻塞在其上的信号量的行为是未定义的。 有名和无名信号量的持续性有名信号量是随内核持续的。当有名信号量创建后，即使当前没有进程打开某个信号量它的值依然保持。直到内核重新自举或调用sem_unlink()删除该信号量。 无名信号量的持续性要根据信号量在内存中的位置： 如果无名信号量是在单个进程内部的数据空间中，即信号量只能在进程内部的各个线程间共享，那么信号量是随进程的持续性，当进程终止时它也就消失了。如果无名信号量位于不同进程的共享内存区，因此只要该共享内存区仍然存在，该信号量就会一直存在。所以此时无名信号量是随内核的持续性。 信号量的继承和销毁继承对于有名信号量在父进程中打开的任何有名信号量在子进程中仍是打开的。即下面代码是正确的：123456789sem_t *pSem;pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); if(fork() == 0)&#123; //... sem_wait(pSem); //...&#125; 对于无名信号量的继承要根据信号量在内存中的位置： 如果无名信号量是在单个进程内部的数据空间中，那么信号量就是进程数据段或者是堆栈上，当fork产生子进程后，该信号量只是原来的一个拷贝，和之前的信号量是独立的。下面是测试代码：123456789101112131415161718192021222324252627282930int main()&#123; sem_t mSem; sem_init(&amp;mSem, 0, 3); int val; sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_wait(&amp;mSem); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; if(fork() == 0) &#123; sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_wait(&amp;mSem); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; exit(0); &#125; sleep(1); sem_getvalue(&amp;mSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl;&#125; 测试结果如下：12345parent:semaphore value:3parent:semaphore value:2child:semaphore value:2child:semaphore value:1parent:semaphore value:2 如果无名信号量位于不同进程的共享内存区，那么fork产生的子进程中的信号量仍然会存在该共享内存区，所以该信号量仍然保持着之前的状态。 销毁对于有名信号量，当某个持有该信号量的进程没有解锁该信号量就终止了，内核并不会将该信号量解锁。这跟记录锁不一样。 对于无名信号量，如果信号量位于进程内部的内存空间中，当进程终止后，信号量也就不存在了，无所谓解锁了。如果信号量位于进程间的共享内存区中，当进程终止后，内核也不会将该信号量解锁。 下面是测试代码：123456789101112131415161718192021222324int main()&#123; sem_t *pSem; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 5); int val; sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; if(fork() == 0) &#123; sem_wait(pSem); sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;child:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; exit(0); &#125; sleep(1); sem_getvalue(pSem, &amp;val); cout&lt;&lt;&quot;parent:semaphore value:&quot;&lt;&lt;val&lt;&lt;endl; sem_unlink(SEM_NAME);&#125; 下面是测试结果：123parent:semaphore value:5child:semaphore value:4parent:semaphore value:4 信号量代码测试对于有名信号量在父进程中打开的任何有名信号量在子进程中仍是打开的。即下面代码是正确的： 对于信号量用于进程间同步的代码的测试，我没有采用经典的生产者和消费者问题，原因是这里会涉及到共享内存的操作。我只是简单的用一个同步文件操作的例子进行描述。 在下面的测试代码中，POSIX有名信号量初始值为2，允许两个进程获得文件的操作权限。代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;fstream&gt;#include &lt;cstdlib&gt; #include &lt;unistd.h&gt;#include &lt;semaphore.h&gt;#include &lt;fcntl.h&gt; using namespace std; #define SEM_NAME &quot;/sem_name&quot; void semTest(int flag)&#123; sem_t *pSem; pSem = sem_open(SEM_NAME, O_CREAT, 0666, 2); sem_wait(pSem); ofstream fileStream(&quot;./test.txt&quot;, ios_base::app); for (int i = 0; i &lt; 5; ++i) &#123; sleep(1); fileStream&lt;&lt;flag; fileStream&lt;&lt;&apos; &apos;&lt;&lt;flush; &#125; sem_post(pSem); sem_close(pSem);&#125; int main()&#123; for (int i = 1; i &lt;= 3; ++i) &#123; if (fork() == 0) &#123; semTest(i); sleep(1); exit(0); &#125; &#125;&#125; 程序的运行结果，“./test.txt”文件的内容如下：12//./test.txt1 2 1 2 1 2 1 2 1 2 3 3 3 3 3]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IPC通信:Posix消息队列]]></title>
    <url>%2F2019%2F05%2F18%2FLinux_IPC%E9%80%9A%E4%BF%A1_Posix%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[消息队列可以认为是一个链表。进程（线程）可以往里写消息，也可以从里面取出消息。一个进程可以往某个消息队列里写消息，然后终止，另一个进程随时可以从消息队列里取走这些消息。这里也说明了，消息队列具有随内核的持续性，也就是系统不重启，消息队列永久存在。 创建（并打开）、关闭、删除一个消息队列12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; //头文件#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; /* 函数说明：函数创建或打开一个消息队列 返回值：成功返回消息队列描述符，失败返回-1，错误原因存于errno中 */ posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; /* 函数说明：关闭一个打开的消息队列，表示本进程不再对该消息队列读写 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; /* 函数说明：删除一个消息队列，好比删除一个文件，其他进程再也无法访问 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译并执行：123456root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c/tmp/ccZ9cTxo.o: In function `main&apos;:crtmq.c:(.text+0x31): undefined reference to `mq_open&apos;crtmq.c:(.text+0x60): undefined reference to `mq_close&apos;crtmq.c:(.text+0x8f): undefined reference to `mq_unlink&apos;collect2: ld returned 1 exit status 因为mq_XXX()函数不是标准库函数，链接时需要指定；库-lrt；12root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./crtmq 最后程序并没有删除消息队列（消息队列有随内核持续性），如再次执行该程序则会给出错误信息：12root@linux:/mnt/hgfs/C_libary# ./crtmq 创建MQ失败: File exit(0) 编译这个程序需要注意几点： 消息队列的名字最好使用“/”打头，并且只有一个“/”的名字。否则可能出现移植性问题；（还需保证在根目录有写权限,为了方便我在root权限下测试） 创建成功的消息队列不一定能看到，使用一些方法也可以看到，本文不做介绍； 消息队列的名字有如此规定，引用《UNIX网络编程 卷2》的相关描述： mq_open,sem_open,shm_open这三个函数的第一个参数是一个IPC名字，它可能是某个文件系统中的一个真正存在的路径名，也可能不是。Posix.1是这样描述Posix IPC名字的。1)它必须符合已有的路径名规则（最多由PATH_MAX个字节构成，包括结尾的空字节）2)如果它以斜杠开头，那么对这些函数的不同调用将访问同一个队列，否则效果取决于实现（也就是效果没有标准化）3)名字中的额外的斜杠符的解释由实现定义（同样是没有标准化） 因此，为便于移植起见，Posix IPC名字必须以一个斜杠打头，并且不能再包含任何其他斜杠符。 IPC通信:Posix消息队列读,写创建消息队列的程序:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; //头文件#include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; /* 函数说明：函数创建或打开一个消息队列 返回值：成功返回消息队列描述符，失败返回-1，错误原因存于errno中 */ posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; /* 函数说明：关闭一个打开的消息队列，表示本进程不再对该消息队列读写 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; #if 0 /* 函数说明：删除一个消息队列，好比删除一个文件，其他进程再也无法访问 返回值：成功返回0，失败返回-1，错误原因存于errno中 */ rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0;#endif &#125; 编译并执行：12root@linux:/mnt/hgfs/C_libary# gcc -o crtmq crtmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./crtmq 程序并没有删除消息队列（消息队列有随内核持续性），如再次执行该程序则会给出错误信息：12root@linux:/mnt/hgfs/C_libary# ./crtmq 创建MQ失败: File exit(0) 向消息队列写消息的程序： 消息队列的读写主要使用下面两个函数：12345678910111213141516/*头文件*/#include &lt;mqueue.h&gt; /*返回：若成功则为消息中字节数，若出错则为-1 */ int mq_send(mqd_t mqdes, const char *msg_ptr, size_t msg_len, unsigned msg_prio); /*返回：若成功则为0， 若出错则为-1*/ ssize_t mq_receive(mqd_t mqdes, char *msg_ptr, size_t msg_len, unsigned *msg_prio); /*消息队列属性结构体*/struct mq_attr &#123; long mq_flags; /* Flags: 0 or O_NONBLOCK */ long mq_maxmsg; /* Max. # of messages on queue */ long mq_msgsize; /* Max. message size (bytes) */ long mq_curmsgs; /* # of messages currently in queue */ &#125;; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; /*向消息队列发送消息，消息队列名及发送的信息通过参数传递*/ int main(int argc, char *argv[]) &#123; mqd_t mqd; char *ptr; size_t len; unsigned int prio; int rc; if(argc != 4) &#123; printf(&quot;Usage: sendmq &lt;name&gt; &lt;bytes&gt; &lt;priority&gt;\n&quot;); exit(1); &#125; len = atoi(argv[2]); prio = atoi(argv[3]); //只写模式找开消息队列 mqd = mq_open(argv[1], O_WRONLY); if(-1 == mqd) &#123; perror(&quot;打开消息队列失败&quot;); exit(1); &#125; // 动态申请一块内存 ptr = (char *) calloc(len, sizeof(char)); if(NULL == ptr) &#123; perror(&quot;申请内存失败&quot;); mq_close(mqd); exit(1); &#125; /*向消息队列写入消息，如消息队列满则阻塞，直到消息队列有空闲时再写入*/ rc = mq_send(mqd, ptr, len, prio); if(rc &lt; 0) &#123; perror(&quot;写入消息队列失败&quot;); mq_close(mqd); exit(1); &#125; // 释放内存 free(ptr); return 0; &#125; 编译并执行：12345root@linux:/mnt/hgfs/C_libary# gcc -o sendmq sendmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 15root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 16root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 17root@linux:/mnt/hgfs/C_libary# ./sendmq /tmp 30 18 上面先后向消息队列“/tmp”写入了四条消息，因为先前创建的消息队列只允许存放3条消息，本次第四次写入时程序会阻塞。直到有另外进程从消息队列取走消息后本次写入才成功返回。 读消息队列：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; /*读取某消息队列,消息队列名通过参数传递*/ int main(int argc, char *argv[]) &#123; mqd_t mqd; struct mq_attr attr; char *ptr; unsigned int prio; size_t n; int rc; if(argc != 2) &#123; printf(&quot;Usage: readmq &lt;name&gt;\n&quot;); exit(1); &#125; /*只读模式打开消息队列*/ mqd = mq_open(argv[1], O_RDONLY); if(mqd &lt; 0) &#123; perror(&quot;打开消息队列失败&quot;); exit(1); &#125; // 取得消息队列属性，根据mq_msgsize动态申请内存 rc = mq_getattr(mqd, &amp;attr); if(rc &lt; 0) &#123; perror(&quot;取得消息队列属性失败&quot;); exit(1); &#125; /*动态申请保证能存放单条消息的内存*/ ptr = calloc(attr.mq_msgsize, sizeof(char)); if(NULL == ptr) &#123; printf(&quot;动态申请内存失败\n&quot;); mq_close(mqd); exit(1); &#125; /*接收一条消息*/ n = mq_receive(mqd, ptr, attr.mq_msgsize, &amp;prio); if(n &lt; 0) &#123; perror(&quot;读取失败&quot;); mq_close(mqd); free(ptr); exit(1); &#125; printf(&quot;读取 %ld 字节\n 优先级为 %u\n&quot;, (long)n, prio); return 0; &#125; 编译并执行：12345678910111213141516root@linux:/mnt/hgfs/C_libary# vi readmq.croot@linux:/mnt/hgfs/C_libary# vi readmq.croot@linux:/mnt/hgfs/C_libary# gcc -o readmq readmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 18root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 17root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 16root@linux:/mnt/hgfs/C_libary# ./readmq /tmp读取 30 字节 优先级为 15root@linux:/mnt/hgfs/C_libary# ./readmq /tmp 程序执行五次，第一次执行完，先前阻塞在写处的程序成功返回。第五次执行，因为消息队列已经为空，程序阻塞。直到另外的进程向消息队列写入一条消息。另外，还可以看出Posix消息队列每次读出的都是消息队列中优先级最高的消息。 IPC通信:Posix消息队列的属性设置 Posix消息队列的属性使用如下结构存放：1234567struct mq_attr &#123; long mq_flags; /*阻塞标志位，0为非阻塞(O_NONBLOCK)*/ long mq_maxmsg; /*队列所允许的最大消息条数*/ long mq_msgsize; /*每条消息的最大字节数*/ long mq_curmsgs; /*队列当前的消息条数*/ &#125;; 队列可以在创建时由mq_open()函数的第四个参数指定mq_maxmsg，mq_msgsize。 如创建时没有指定则使用默认值，一旦创建，则不可再改变。队列可以在创建后由mq_setattr()函数设置mq_flags123456789#include &lt;mqueue.h&gt; /*取得消息队列属性，放到mqstat地fh*/ int mq_getattr(mqd_t mqdes, struct mq_attr *mqstat); /*设置消息队列属性，设置值由mqstat提供，原先值写入omqstat*/ int mq_setattr(mqd_t mqdes, const struct mq_attr *mqstat, struct mq_attr *omqstat); 均返回：若成功则为0，若出错为-1 程序获取和设置消息队列的默认属性：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; struct mq_attr mqattr; // 创建默认属性的消息队列 posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; // 获取消息队列的默认属性 rc = mq_getattr(posixmq, &amp;mqattr); if(-1 == rc) &#123; perror(&quot;获取消息队列属性失败&quot;); exit(1); &#125; printf(&quot;队列阻塞标志位：%ld\n&quot;, mqattr.mq_flags); printf(&quot;队列允许最大消息数：%ld\n&quot;, mqattr.mq_maxmsg); printf(&quot;队列消息最大字节数：%ld\n&quot;, mqattr.mq_msgsize); printf(&quot;队列当前消息条数：%ld\n&quot;, mqattr.mq_curmsgs); rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译并执行：1234567root@linux:/mnt/hgfs/C_libary# gcc -o attrmq attrmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./attrmq队列阻塞标志位：0队列允许最大消息数：10队列消息最大字节数：8192队列当前消息条数：0root@linux:/mnt/hgfs/C_libary# 设置消息队列的属性：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;mqueue.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; #include &lt;errno.h&gt; #define MQ_NAME (&quot;/tmp&quot;) #define MQ_FLAG (O_RDWR | O_CREAT | O_EXCL) // 创建MQ的flag #define FILE_MODE (S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH) // 设定创建MQ的权限 int main() &#123; mqd_t posixmq; int rc = 0; struct mq_attr mqattr; // 创建默认属性的消息队列 mqattr.mq_maxmsg = 5; // 注意不能超过系统最大限制 mqattr.mq_msgsize = 8192; //posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, NULL); posixmq = mq_open(MQ_NAME, MQ_FLAG, FILE_MODE, &amp;mqattr); if(-1 == posixmq) &#123; perror(&quot;创建MQ失败&quot;); exit(1); &#125; mqattr.mq_flags = 0; mq_setattr(posixmq, &amp;mqattr, NULL);// mq_setattr()只关注mq_flags，adw // 获取消息队列的属性 rc = mq_getattr(posixmq, &amp;mqattr); if(-1 == rc) &#123; perror(&quot;获取消息队列属性失败&quot;); exit(1); &#125; printf(&quot;队列阻塞标志位：%ld\n&quot;, mqattr.mq_flags); printf(&quot;队列允许最大消息数：%ld\n&quot;, mqattr.mq_maxmsg); printf(&quot;队列消息最大字节数：%ld\n&quot;, mqattr.mq_msgsize); printf(&quot;队列当前消息条数：%ld\n&quot;, mqattr.mq_curmsgs); rc = mq_close(posixmq); if(0 != rc) &#123; perror(&quot;关闭失败&quot;); exit(1); &#125; rc = mq_unlink(MQ_NAME); if(0 != rc) &#123; perror(&quot;删除失败&quot;); exit(1); &#125; return 0; &#125; 编译运行：123456root@linux:/mnt/hgfs/C_libary# gcc -o setattrmq setattrmq.c -lrtroot@linux:/mnt/hgfs/C_libary# ./setattrmq队列阻塞标志位：0队列允许最大消息数：5队列消息最大字节数：8192队列当前消息条数：0]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程间通信—使用共享内存]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A-%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[什么是共享内存顾名思义，共享内存就是允许两个不相关的进程访问同一个逻辑内存。共享内存是在两个正在运行的进程之间共享和传递数据的一种非常有效的方式。不同进程之间共享的内存通常安排为同一段物理内存。进程可以将同一段共享内存连接到它们自己的地址空间中，所有进程都可以访问共享内存中的地址，就好像它们是由用C语言函数malloc分配的内存一样。而如果某个进程向共享内存写入数据，所做的改动将立即影响到可以访问同一段共享内存的任何其他进程。 特别提醒：共享内存并未提供同步机制，也就是说，在第一个进程结束对共享内存的写操作之前，并无自动机制可以阻止第二个进程开始对它进行读取。所以我们通常需要用其他的机制来同步对共享内存的访问，例如前面说到的信号量。有关信号量的更多内容，可以查阅我的另一篇文章：Linux进程间通信——使用信号量 共享内存的使得与信号量一样，在Linux中也提供了一组函数接口用于使用共享内存，而且使用共享共存的接口还与信号量的非常相似，而且比使用信号量的接口来得简单。它们声明在头文件 sys/shm.h中。 shmget函数该函数用来创建共享内存，它的原型为：1int shmget(key_t key, size_t size, int shmflg); 第一个参数，与信号量的semget函数一样，程序需要提供一个参数key（非0整数），它有效地为共享内存段命名，shmget函数成功时返回一个与key相关的共享内存标识符（非负整数），用于后续的共享内存函数。调用失败返回-1. 不相关的进程可以通过该函数的返回值访问同一共享内存，它代表程序可能要使用的某个资源，程序对所有共享内存的访问都是间接的，程序先通过调用shmget函数并提供一个键，再由系统生成一个相应的共享内存标识符（shmget函数的返回值），只有shmget函数才直接使用信号量键，所有其他的信号量函数使用由semget函数返回的信号量标识符。 第二个参数，size以字节为单位指定需要共享的内存容量 第三个参数，shmflg是权限标志，它的作用与open函数的mode参数一样，如果要想在key标识的共享内存不存在时，创建它的话，可以与IPC_CREAT做或操作。共享内存的权限标志与文件的读写权限一样，举例来说，0644,它表示允许一个进程创建的共享内存被内存创建者所拥有的进程向共享内存读取和写入数据，同时其他用户创建的进程只能读取共享内存。 shmat函数第一次创建完共享内存时，它还不能被任何进程访问，shmat函数的作用就是用来启动对该共享内存的访问，并把共享内存连接到当前进程的地址空间。它的原型如下：1void *shmat(int shm_id, const void *shm_addr, int shmflg); 第一个参数，shm_id是由shmget函数返回的共享内存标识。第二个参数，shm_addr指定共享内存连接到当前进程中的地址位置，通常为空，表示让系统来选择共享内存的地址。第三个参数，shm_flg是一组标志位，通常为0。 调用成功时返回一个指向共享内存第一个字节的指针，如果调用失败返回-1. shmdt函数该函数用于将共享内存从当前进程中分离。注意，将共享内存分离并不是删除它，只是使该共享内存对当前进程不再可用。它的原型如下：int shmdt(const void *shmaddr);参数shmaddr是shmat函数返回的地址指针，调用成功时返回0，失败时返回-1. shmctl函数与信号量的semctl函数一样，用来控制共享内存，它的原型如下：int shmctl(int shm_id, int command, struct shmid_ds *buf);第一个参数，shm_id是shmget函数返回的共享内存标识符。 第二个参数，command是要采取的操作，它可以取下面的三个值 ： IPC_STAT：把shmid_ds结构中的数据设置为共享内存的当前关联值，即用共享内存的当前关联值覆盖shmid_ds的值。 IPC_SET：如果进程有足够的权限，就把共享内存的当前关联值设置为shmid_ds结构中给出的值 IPC_RMID：删除共享内存段 第三个参数，buf是一个结构指针，它指向共享内存模式和访问权限的结构。shmid_ds结构至少包括以下成员：123456struct shmid_ds&#123; uid_t shm_perm.uid; uid_t shm_perm.gid; mode_t shm_perm.mode;&#125;; 使用共享内存进行进程间通信说了这么多，又到了实战的时候了。下面就以两个不相关的进程来说明进程间如何通过共享内存来进行通信。其中一个文件shmread.c创建共享内存，并读取其中的信息，另一个文件shmwrite.c向共享内存中写入数据。为了方便操作和数据结构的统一，为这两个文件定义了相同的数据结构，定义在文件shmdata.c中。结构shared_use_st中的written作为一个可读或可写的标志，非0：表示可读，0表示可写，text则是内存中的文件。 shmdata.h的源代码如下：123456789101112#ifndef _SHMDATA_H_HEADER#define _SHMDATA_H_HEADER #define TEXT_SZ 2048 struct shared_use_st&#123; int written;//作为一个标志，非0：表示可读，0表示可写 char text[TEXT_SZ];//记录写入和读取的文本&#125;; #endif 源文件shmread.c的源代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/shm.h&gt;#include &quot;shmdata.h&quot; int main()&#123; int running = 1;//程序是否继续运行的标志 void *shm = NULL;//分配的共享内存的原始首地址 struct shared_use_st *shared;//指向shm int shmid;//共享内存标识符 //创建共享内存 shmid = shmget((key_t)1234, sizeof(struct shared_use_st), 0666|IPC_CREAT); if(shmid == -1) &#123; fprintf(stderr, &quot;shmget failed\n&quot;); exit(EXIT_FAILURE); &#125; //将共享内存连接到当前进程的地址空间 shm = shmat(shmid, 0, 0); if(shm == (void*)-1) &#123; fprintf(stderr, &quot;shmat failed\n&quot;); exit(EXIT_FAILURE); &#125; printf(&quot;\nMemory attached at %X\n&quot;, (int)shm); //设置共享内存 shared = (struct shared_use_st*)shm; shared-&gt;written = 0; while(running)//读取共享内存中的数据 &#123; //没有进程向共享内存定数据有数据可读取 if(shared-&gt;written != 0) &#123; printf(&quot;You wrote: %s&quot;, shared-&gt;text); sleep(rand() % 3); //读取完数据，设置written使共享内存段可写 shared-&gt;written = 0; //输入了end，退出循环（程序） if(strncmp(shared-&gt;text, &quot;end&quot;, 3) == 0) running = 0; &#125; else//有其他进程在写数据，不能读取数据 sleep(1); &#125; //把共享内存从当前进程中分离 if(shmdt(shm) == -1) &#123; fprintf(stderr, &quot;shmdt failed\n&quot;); exit(EXIT_FAILURE); &#125; //删除共享内存 if(shmctl(shmid, IPC_RMID, 0) == -1) &#123; fprintf(stderr, &quot;shmctl(IPC_RMID) failed\n&quot;); exit(EXIT_FAILURE); &#125; exit(EXIT_SUCCESS);&#125; 源文件shmwrite.c的源代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;sys/shm.h&gt;#include &quot;shmdata.h&quot; int main()&#123; int running = 1; void *shm = NULL; struct shared_use_st *shared = NULL; char buffer[BUFSIZ + 1];//用于保存输入的文本 int shmid; //创建共享内存 shmid = shmget((key_t)1234, sizeof(struct shared_use_st), 0666|IPC_CREAT); if(shmid == -1) &#123; fprintf(stderr, &quot;shmget failed\n&quot;); exit(EXIT_FAILURE); &#125; //将共享内存连接到当前进程的地址空间 shm = shmat(shmid, (void*)0, 0); if(shm == (void*)-1) &#123; fprintf(stderr, &quot;shmat failed\n&quot;); exit(EXIT_FAILURE); &#125; printf(&quot;Memory attached at %X\n&quot;, (int)shm); //设置共享内存 shared = (struct shared_use_st*)shm; while(running)//向共享内存中写数据 &#123; //数据还没有被读取，则等待数据被读取,不能向共享内存中写入文本 while(shared-&gt;written == 1) &#123; sleep(1); printf(&quot;Waiting...\n&quot;); &#125; //向共享内存中写入数据 printf(&quot;Enter some text: &quot;); fgets(buffer, BUFSIZ, stdin); strncpy(shared-&gt;text, buffer, TEXT_SZ); //写完数据，设置written使共享内存段可读 shared-&gt;written = 1; //输入了end，退出循环（程序） if(strncmp(buffer, &quot;end&quot;, 3) == 0) running = 0; &#125; //把共享内存从当前进程中分离 if(shmdt(shm) == -1) &#123; fprintf(stderr, &quot;shmdt failed\n&quot;); exit(EXIT_FAILURE); &#125; sleep(2); exit(EXIT_SUCCESS);&#125; 再来看看运行的结果： 分析： 程序shmread创建共享内存，然后将它连接到自己的地址空间。在共享内存的开始处使用了一个结构struct_use_st。该结构中有个标志written，当共享内存中有其他进程向它写入数据时，共享内存中的written被设置为0，程序等待。当它不为0时，表示没有进程对共享内存写入数据，程序就从共享内存中读取数据并输出，然后重置设置共享内存中的written为0，即让其可被shmwrite进程写入数据。 程序shmwrite取得共享内存并连接到自己的地址空间中。检查共享内存中的written，是否为0，若不是，表示共享内存中的数据还没有被完，则等待其他进程读取完成，并提示用户等待。若共享内存的written为0，表示没有其他进程对共享内存进行读取，则提示用户输入文本，并再次设置共享内存中的written为1，表示写完成，其他进程可对共享内存进行读操作。 关于前面的例子的安全性讨论这个程序是不安全的，当有多个程序同时向共享内存中读写数据时，问题就会出现。可能你会认为，可以改变一下written的使用方式，例如，只有当written为0时进程才可以向共享内存写入数据，而当一个进程只有在written不为0时才能对其进行读取，同时把written进行加1操作，读取完后进行减1操作。这就有点像文件锁中的读写锁的功能。咋看之下，它似乎能行得通。但是这都不是原子操作，所以这种做法是行不能的。试想当written为0时，如果有两个进程同时访问共享内存，它们就会发现written为0，于是两个进程都对其进行写操作，显然不行。当written为1时，有两个进程同时对共享内存进行读操作时也是如些，当这两个进程都读取完是，written就变成了-1. 要想让程序安全地执行，就要有一种进程同步的进制，保证在进入临界区的操作是原子操作。例如，可以使用前面所讲的信号量来进行进程的同步。因为信号量的操作都是原子性的。 使用共享内存的优缺点 优点：我们可以看到使用共享内存进行进程间的通信真的是非常方便，而且函数的接口也简单，数据的共享还使进程间的数据不用传送，而是直接访问内存，也加快了程序的效率。同时，它也不像匿名管道那样要求通信的进程有一定的父子关系。 缺点：共享内存没有提供同步的机制，这使得我们在使用共享内存进行进程间通信时，往往要借助其他的手段来进行进程间的同步工作。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程通信之POSIX共享内存]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1%E4%B9%8BPOSIX%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/anonymalias/article/details/9938865 Linux下个各种进程间的通信方式：管道，FIFO，消息队列，他们的共同特点就是通过内核来进行通信（假设POSIX消息队列也是在内核中实现的，因为POSIX标准并没有限定它的实现方式）。向管道，FIFO，消息队列写入数据需要把数据从进程复制到内核，从这些IPC读取数据的时候又需要把数据从内核复制到进程。所以这种IPC方式往往需要2次在进程和内核之间进行数据的复制，即进程间的通信必须借助内核来传递。如下图所示： 共享内存也是一种IPC，它是目前可用IPC中最快的，它是使用方式是将同一个内存区映射到共享它的不同进程的地址空间中，这样这些进程间的通信就不再需要通过内核，只需对该共享的内存区域进程操作就可以了，和其他IPC不同的是，共享内存的使用需要用户自己进行同步操作。下图是共享内存区IPC的通信， mmap系列函数简介mmap函数主要的功能就是将文件或设备映射到调用进程的地址空间中，当使用mmap映射文件到进程后,就可以直接操作这段虚拟地址进行文件的读写等操作,不必再调用read，write等系统调用。在很大程度上提高了系统的效率和代码的简洁性。 使用mmap函数的主要目的是： 对普通文件提供内存映射I/O，可以提供无亲缘进程间的通信； 提供匿名内存映射，以供亲缘进程间进行通信。 对shm_open创建的POSIX共享内存区对象进程内存映射，以供无亲缘进程间进行通信。 下面是mmap函数的接口以及说明：123#include &lt;sys/mman.h&gt;void *mmap(void *start, size_t len, int prot, int flags, int fd, off_t offset); //成功返回映射到进程地址空间的起始地址，失败返回MAP_FAILED start：指定描述符fd应被映射到的进程地址空间内的起始地址，它通常被设置为空指针NULL，这告诉内核自动选择起始地址，该函数的返回值即为fd映射到内存区的起始地址。 len：映射到进程地址空间的字节数，它从被映射文件开头的第offset个字节处开始，offset通常被设置为0。如下图是内存映射文件的一个例子： prot：内存映射区的保护由该参数来设定，通常由以下几个值组合而成： PROT_READ：数据可读； ROT_WRITE：数据可写； ROT_EXEC：数据可执行； PROT_NONE：数据不可访问； flags：设置内存映射区的类型标志，POSIX标志定义了以下三个标志： MAP_SHARED：该标志表示，调用进程对被映射内存区的数据所做的修改对于共享该内存区的所有进程都可见，而且确实改变其底层的支撑对象（一个文件对象或是一个共享内存区对象）。 AP_PRIVATE：调用进程对被映射内存区的数据所做的修改只对该进程可见，而不改变其底层支撑对象。 AP_FIXED：该标志表示准确的解释start参数，一般不建议使用该标志，对于可移植的代码，应该把start参数置为NULL，且不指定MAP_FIXED标志。 上面三个标志是在POSIX.1-2001标准中定义的，其中MAP_SHARED和MAP_PRIVATE必须选择一个。在Linux中也定义了一些非标准的标志，例如MAP_ANONYMOUS（MAP_ANON），MAP_LOCKED等，具体参考Linux手册。 fd：有效的文件描述符。如果设定了MAP_ANONYMOUS（MAP_ANON）标志，在Linux下面会忽略fd参数，而有的系统实现如BSD需要置fd为-1； offset：相对文件的起始偏移。 mmap成功后，可以关闭fd，一般也是这么做的，这对该内存映射没有任何影响。从进程的地址空间中删除一个映射关系，需要用到下面的函数：123#include &lt;sys/mman.h&gt;int munmap(void *start, size_t len); //成功返回0，出错返回-1 start：被映射到的进程地址空间的内存区的起始地址，即mmap返回的地址。len：映射区的大小。 对于一个MAP_SHARED的内存映射区，内核的虚拟内存算法会保持内存映射文件和内存映射区的同步，也就是说，对于内存映射文件所对应内存映射区的修改，内核会在稍后的某个时刻更新该内存映射文件。如果我们希望硬盘上的文件内容和内存映射区中的内容实时一致，那么我们就可以调用msync开执行这种同步：123#include &lt;sys/mman.h&gt;int msync(void *start, size_t len, int flags); //成功返回0，出错返回-1 start：被映射到的进程地址空间的内存区的起始地址，即mmap返回的地址。len：映射区的大小。flags：同步标志，有一下三个标志： MS_ASYNC：异步写，一旦写操作由内核排入队列，就立刻返回； MS_SYNC：同步写，要等到写操作完成后才返回。 MS_INVALIDATE：使该文件的其他内存映射的副本全部失效。 mmap内存映射区的大小Linux下的内存是采用页式管理机制。通过mmap进行内存映射，内核生成的映射区的大小都是以页面大小PAGESIZE为单位，即为PAGESIZE的整数倍。如果mmap映射的长度不是页面大小的整数倍，那么多余空间也会被闲置浪费。 下面可以查看Linux的页面大小12345678#include &lt;iostream&gt;#include &lt;unistd.h&gt; int main()&#123; std::cout&lt;&lt;&quot;page size:&quot;&lt;&lt;sysconf(_SC_PAGE_SIZE)&lt;&lt;std::endl; return 0;&#125; 输出结果是：1page size:4096 那么下面对映射文件的大小和映射长度的不同情况进行讨论。 (1)映射文件的大小和映射长度相同123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cerrno&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main(int argc, char **argv)&#123; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; if (ftruncate(fd, 5000) &lt; 0) &#123; cout&lt;&lt;&quot;change file size failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; close(fd); return -1; &#125; char *memPtr; memPtr = (char *)mmap(NULL, 5000, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; cout&lt;&lt;&quot;[0]:&quot;&lt;&lt;(int)memPtr[0]&lt;&lt;endl; cout&lt;&lt;&quot;[4999]:&quot;&lt;&lt;(int)memPtr[4999]&lt;&lt;endl; cout&lt;&lt;&quot;[5000]:&quot;&lt;&lt;(int)memPtr[5000]&lt;&lt;endl; cout&lt;&lt;&quot;[8191]:&quot;&lt;&lt;(int)memPtr[8191]&lt;&lt;endl; cout&lt;&lt;&quot;[8192]:&quot;&lt;&lt;(int)memPtr[8192]&lt;&lt;endl; cout&lt;&lt;&quot;[4096 * 3 - 1]:&quot;&lt;&lt;(int)memPtr[4096 * 3 - 1]&lt;&lt;endl; cout&lt;&lt;&quot;[4096 * 3]:&quot;&lt;&lt;(int)memPtr[4096 * 3]&lt;&lt;endl; return 0;&#125; 执行结果如下：1234567[0]:0[4999]:0[5000]:0[8191]:0[8192]:91[4096 * 3 - 1]:0Segmentation fault 用下图来分析执行结果： 由执行结果可以看到，能够完整的访问到前三页，在访问第四页的时候会产生SIGSEGV信号，发生Segmentation fault段越界访问错误。按照《UNIX 网络编程 卷2：进程间通信》中P257的讲解，内核会为该内存映射两个页面，访问前两个页面不会有问题，但访问第三个页面会产生SIGSEGV错误信号。这个差异具体应该是底层实现有关，留待以后研究。 (2)映射文件的大小小于映射长度 在上面代码的基础上，修改mmap内存映射还是部分的第二个参数，如下：1memPtr = (char *)mmap(NULL, 4096 * 3, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); 执行结果如下：12345[0]:0[4999]:0[5000]:0[8191]:0Bus error 再修改访问代码，访问偏移4096*3以后的内存映射去，结果的情况是123[4096 * 3]:91[4096 * 4 - 1]:0Segmentation fault // memPtr[4096*4] 用下图来分析执行结果： 该执行结果和之前的映射文件大小和映射长度相同的情况有比较大的区别，在访问内存映射区内部但超出底层支撑对象的大小的区域部分会产生SIGBUS错误信息，产生生BUS error错误，但访问第四页不会出问题，访问第四页以后的内存区就会产生 SIGSEGV错误信息。按照《UNIX 网络编程 卷2：进程间通信》中P258的讲解，访问第三个页面以后的内存会产生SIGSEGV错误信号。这个差异具体应该是底层实现有关，留待以后研究。 mmap实现进程间通信下面将介绍mmap本身提供的进程间通信的两种方式，分别用于无亲缘和亲缘进程间的通信。 （1）通过匿名内存映射提供亲缘进程间的通信 我们可以通过在父进程fork之前指定MAP_SHARED调用mmap，通过映射一个文件来实现父子进程间的通信，POSIX保证了父进程的内存映射关系保留到子进程中，父子进程对内存映射区的修改双方都可以看到。 在Linux 2.4以后，mmap提供匿名内存映射机制，即将mmap的flags参数指定为：MAP_SHARED | MAP_ANON。这样就彻底避免了内存映射文件的创建和打开，简化了对文件的操作。匿名内存映射机制的目的就是为了提供一个穿越父子进程间的内存映射区，很方便的提供了亲缘进程间的通信，下面是测试代码：123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;cerrno&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; int main(int argc, char **argv)&#123; int *memPtr; memPtr = (int *) mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANON, 0, 0); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; *memPtr = 0; if (fork() == 0) &#123; *memPtr = 1; cout&lt;&lt;&quot;child:set memory &quot;&lt;&lt;*memPtr&lt;&lt;endl; exit(0); &#125; sleep(1); cout&lt;&lt;&quot;parent:memory value &quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; 执行结果如下：12child:set memory 1parent:memory value 1 （2）通过内存映射文件提供无亲缘进程间的通信 通过在不同进程间对同一内存映射文件进行映射，来进行无亲缘进程间的通信，如下测试代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182//process 1#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main()&#123; int *memPtr; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; ftruncate(fd, sizeof(int)); memPtr = (int *)mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; *memPtr = 111; cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; send:&quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; //process 2#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define PATH_NAME &quot;/tmp/memmap&quot; int main()&#123; int *memPtr; int fd; fd = open(PATH_NAME, O_RDWR | O_CREAT, 0666); if (fd &lt; 0) &#123; cout&lt;&lt;&quot;open file &quot;&lt;&lt;PATH_NAME&lt;&lt;&quot; failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; memPtr = (int *)mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); if (memPtr == MAP_FAILED) &#123; cout&lt;&lt;&quot;mmap failed...&quot;&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; receive:&quot;&lt;&lt;*memPtr&lt;&lt;endl; return 0;&#125; 执行结果如下：1234# ./send process:12711 send:111# ./recv process:12712 receive:111 上面的代码都没进行同步操作，在实际的使用过程要考虑到进程间的同步，通常会用信号量来进行共享内存的同步。 基于mmap的POSIX共享内存上面介绍了通过内存映射文件进行进程间的通信的方式，现在要介绍的是通过POSIX共享内存区对象进行进程间的通信。POSIX共享内存使用方法有以下两个步骤： 通过shm_open创建或打开一个POSIX共享内存对象；然后调用mmap将它映射到当前进程的地址空间；和通过内存映射文件进行通信的使用上差别在于mmap描述符参数获取方式不一样：通过open或shm_open。如下图所示： POSIX共享内存区对象的特殊操作函数就只有创建（打开）和删除两个函数，其他对共享内存区对象的操作都是通过已有的函数进行的。12345#include &lt;sys/mman.h&gt;int shm_open(const char *name, int oflag, mode_t mode); //成功返回非负的描述符，失败返回-1int shm_unlink(const char *name); //成功返回0，失败返回-1 shm_open用于创建一个新的共享内存区对象或打开一个已经存在的共享内存区对象。 name：POSIX IPC的名字，前面关于POSIX进程间通信都已讲过关于POSIX IPC的规则，这里不再赘述。 oflag：操作标志，包含：O_RDONLY，O_RDWR，O_CREAT，O_EXCL，O_TRUNC。其中O_RDONLY和O_RDWR标志必须且仅能存在一项。 mode：用于设置创建的共享内存区对象的权限属性。和open以及其他POSIX IPC的xxx_open函数不同的是，该参数必须一直存在，如果oflag参数中没有O_CREAT标志，该位可以置0； shm_unlink用于删除一个共享内存区对象，跟其他文件的unlink以及其他POSIX IPC的删除操作一样，对象的析构会到对该对象的所有引用全部关闭才会发生。 POSIX共享内存和POSIX消息队列，有名信号量一样都是具有随内核持续性的特点。 下面是通过POSIX共享内存进行通信的测试代码，代码中通过POSIX信号量来进行进程间的同步操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394//process 1#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;semaphore.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define SHM_NAME &quot;/memmap&quot;#define SHM_NAME_SEM &quot;/memmap_sem&quot; char sharedMem[10]; int main()&#123; int fd; sem_t *sem; fd = shm_open(SHM_NAME, O_RDWR | O_CREAT, 0666); sem = sem_open(SHM_NAME_SEM, O_CREAT, 0666, 0); if (fd &lt; 0 || sem == SEM_FAILED) &#123; cout&lt;&lt;&quot;shm_open or sem_open failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; ftruncate(fd, sizeof(sharedMem)); char *memPtr; memPtr = (char *)mmap(NULL, sizeof(sharedMem), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); char msg[] = &quot;yuki...&quot;; memmove(memPtr, msg, sizeof(msg)); cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; send:&quot;&lt;&lt;memPtr&lt;&lt;endl; sem_post(sem); sem_close(sem); return 0;&#125; //process 2#include &lt;iostream&gt;#include &lt;cstring&gt;#include &lt;errno.h&gt; #include &lt;unistd.h&gt;#include &lt;fcntl.h&gt;#include &lt;semaphore.h&gt;#include &lt;sys/mman.h&gt; using namespace std; #define SHM_NAME &quot;/memmap&quot;#define SHM_NAME_SEM &quot;/memmap_sem&quot; int main()&#123; int fd; sem_t *sem; fd = shm_open(SHM_NAME, O_RDWR, 0); sem = sem_open(SHM_NAME_SEM, 0); if (fd &lt; 0 || sem == SEM_FAILED) &#123; cout&lt;&lt;&quot;shm_open or sem_open failed...&quot;; cout&lt;&lt;strerror(errno)&lt;&lt;endl; return -1; &#125; struct stat fileStat; fstat(fd, &amp;fileStat); char *memPtr; memPtr = (char *)mmap(NULL, fileStat.st_size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0); close(fd); sem_wait(sem); cout&lt;&lt;&quot;process:&quot;&lt;&lt;getpid()&lt;&lt;&quot; recv:&quot;&lt;&lt;memPtr&lt;&lt;endl; sem_close(sem); return 0;&#125; 程序的执行结果如下：1234# ./send process:13719 send:yuki...# ./recv process:13720 recv:yuki... 在Linux 2.6.18中，对于POSIX信号量和共享内存的名字会在/dev/shm下建立对应的路径名，例如上面的测试代码，会生成如下的路径名：1234# ll /dev/shm/total 8-rw-r--r-- 1 root root 10 Aug 13 00:28 memmap-rw-r--r-- 1 root root 32 Aug 13 00:28 sem.memmap_sem]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux线程的信号量同步]]></title>
    <url>%2F2019%2F05%2F18%2FLinux%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%BF%A1%E5%8F%B7%E9%87%8F%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[信号量和互斥锁(mutex)的区别：互斥锁只允许一个线程进入临界区，而信号量允许多个线程同时进入临界区。 不多做解释，要使用信号量同步，需要包含头文件semaphore.h。 主要用到的函数： int sem_init(sem_t *sem, int pshared, unsigned int value);，其中sem是要初始化的信号量，pshared表示此信号量是在进程间共享还是线程间共享，value是信号量的初始值。 int sem_destroy(sem_t *sem);,其中sem是要销毁的信号量。只有用sem_init初始化的信号量才能用sem_destroy销毁。 int sem_wait(sem_t *sem);：等待信号量，如果信号量的值大于0,将信号量的值减1,立即返回。如果信号量的值为0,则线程阻塞。相当于P操作。成功返回0,失败返回-1。 int sem_post(sem_t *sem);：释放信号量，让信号量的值加1。相当于V操作。 下列的代码演示了如何用信号量同步，模拟一个窗口服务系统。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/* @purpose: 基于信号量的多线程同步，操作系统原理中的P,V操作 * @author: jollywing@foxmail.com * @create: 2015-03-20 Fri * */#include &lt;pthread.h&gt;#include &lt;semaphore.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;/* @Scene: 某行业营业厅同时只能服务两个顾客。 * 有多个顾客到来，每个顾客如果发现服务窗口已满，就等待， * 如果有可用的服务窗口，就接受服务。 *//* 将信号量定义为全局变量，方便多个线程共享 */sem_t sem;/* 每个线程要运行的例程 */void * get_service(void *thread_id)&#123; /* 注意：立即保存thread_id的值，因为thread_id是对主线程中循环变量i的引用，它可能马上被修改 */ int customer_id = *((int *)thread_id); if(sem_wait(&amp;sem) == 0) &#123; usleep(100); /* service time: 100ms */ printf(&quot;customer %d receive service ...\n&quot;, customer_id); sem_post(&amp;sem); &#125;&#125;#define CUSTOMER_NUM 10int main(int argc, char *argv[])&#123; /* 初始化信号量，初始值为2，表示有两个顾客可以同时接收服务 */ /* @prototype: int sem_init(sem_t *sem, int pshared, unsigned int value); */ /* pshared: if pshared == 0, the semaphore is shared among threads of a process * otherwise the semaphore is shared between processes. */ sem_init(&amp;sem, 0, 2); /* 为每个顾客定义一个线程id, pthread_t 其实是unsigned long int */ pthread_t customers[CUSTOMER_NUM]; int i, ret; /* 为每个顾客生成一个线程 */ for(i = 0; i &lt; CUSTOMER_NUM; i++)&#123; int customer_id = i; ret = pthread_create(&amp;customers[i], NULL, get_service, &amp;customer_id); if(ret != 0)&#123; perror(&quot;pthread_create&quot;); exit(1); &#125; else &#123; printf(&quot;Customer %d arrived.\n&quot;, i); &#125; usleep(10); &#125; /* 等待所有顾客的线程结束 */ /* 注意：这地方不能再用i做循环变量，因为可能线程中正在访问i的值 */ int j; for(j = 0; j &lt; CUSTOMER_NUM; j++) &#123; pthread_join(customers[j], NULL); &#125; /* Only a semaphore that has been initialized by sem_init(3) * should be destroyed using sem_destroy().*/ sem_destroy(&amp;sem); return 0;&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基数排序]]></title>
    <url>%2F2019%2F05%2F18%2F%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/lemon_tree12138/article/details/51695211 数据背景在基数排序中，我们不能再只用一位数的序列来列举示例了。一位数的序列对基数排序来说就是一个计数排序。这里我们列举无序序列 T = [ 2314, 5428, 373, 2222, 17 ] 排序原理上面说到基数排序不需要进行元素的比较与交换。如果你有一些算法的功底，或者丰富的项目经验，我想你可能已经想到了这可能类似于一些“打表”或是哈希的做法。而计数排序则是打表或是哈希思想最简单的实现。 计数排序计数排序的核心思想是，构建一个足够大的数组 hashArray[]，数组大小需要保证能够把所有元素都包含在这个数组上 。假设我们有无序序列 T = [ 2314, 5428, 373, 2222, 17 ]首先初始化数组 hashArray[] 为一个全零数组。当然，在 Java 里，这一步就不需要了，因为默认就是零了。在对序列 T 进行排序时，只要依次读取序列 T 中的元素，并修改数组 hashArray[] 中把元素值对应位置上的值即可。这一句有一些绕口。打个比方，我们要把 T[0] 映射到 hashArray[] 中，就是 hashArray[T[0]] = 1. 也就是 hashArray[2314] = 1. 如果序列 T 中有两个相同元素，那么在 hashArray 的相应位置上的值就是 2。下图是计数排序的原理图：（假设有无序序列：[ 5, 8, 9, 1, 4, 2, 9, 3, 7, 1, 8, 6, 2, 3, 4, 0, 8 ]） 基数排序原理图上面的计数排序只是一个引导，好让你可以循序渐进地了解基数排序。 上面这幅图，或许你已经在其他的博客里见到过。这是一个很好的引导跟说明。在基数排序里，我们需要一个很大的二维数组，二维数组的大小是 （10 * n）。10 代表的是我们每个元素的每一位都有 10 种可能，也就是 10 进制数。在上图中，我们是以每个数的个位来代表这个数，于是，5428 就被填充到了第 8 个桶中了。下次再进行填充的时候，就是以十位进行填充，比如 5428 在此时，就会选择以 2 来代表它。 算法优化在算法的原理中，我们是以一张二维数组的表来存储这些无序的元素。使用二维数组有一个很明显的不足就是二维数组太过稀疏。数组的利用率为 10%。在寻求优化的路上，我们想到一种可以压缩空间的方法，且时间复杂度并没有偏离得太厉害。那就是设计了两个辅助数组，一个是 count[]，一个是 bucket[]。count 用于记录在某个桶中的最后一个元素的下标，然后再把原数组中的元素计算一下它应该属于哪个“桶”，并修改相应位置的 count 值。直到最大数的最高位也被添加到桶中，或者说，当所有的元素都被被在第 0 个桶中，基数排序就结束了。优化后的原理图如下： 算法实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import org.algorithm.array.sort.interf.Sortable;/** * &lt;p&gt; * 基数排序/桶排序 * &lt;/p&gt; * 2016年1月19日 * * @author &lt;a href=&quot;http://weibo.com/u/5131020927&quot;&gt;Q-WHai&lt;/a&gt; * @see &lt;a href=&quot;http://blog.csdn.net/lemon_tree12138&quot;&gt;http://blog.csdn.net/lemon_tree12138&lt;/a&gt; * @version 0.1.1 */public class RadixSort implements Sortable &#123; @Override public int[] sort(int[] array) &#123; if (array == null) &#123; return null; &#125; int maxLength = maxLength(array); return sortCore(array, 0, maxLength); &#125; private int[] sortCore(int[] array, int digit, int maxLength) &#123; if (digit &gt;= maxLength) &#123; return array; &#125; final int radix = 10; // 基数 int arrayLength = array.length; int[] count = new int[radix]; int[] bucket = new int[arrayLength]; // 统计将数组中的数字分配到桶中后，各个桶中的数字个数 for (int i = 0; i &lt; arrayLength; i++) &#123; count[getDigit(array[i], digit)]++; &#125; // 将各个桶中的数字个数，转化成各个桶中最后一个数字的下标索引 for (int i = 1; i &lt; radix; i++) &#123; count[i] = count[i] + count[i - 1]; &#125; // 将原数组中的数字分配给辅助数组 bucket for (int i = arrayLength - 1; i &gt;= 0; i--) &#123; int number = array[i]; int d = getDigit(number, digit); bucket[count[d] - 1] = number; count[d]--; &#125; return sortCore(bucket, digit + 1, maxLength); &#125; /* * 一个数组中最大数字的位数 * * @param array * @return */ private int maxLength(int[] array) &#123; int maxLength = 0; int arrayLength = array.length; for (int i = 0; i &lt; arrayLength; i++) &#123; int currentLength = length(array[i]); if (maxLength &lt; currentLength) &#123; maxLength = currentLength; &#125; &#125; return maxLength; &#125; /* * 计算一个数字共有多少位 * * @param number * @return */ private int length(int number) &#123; return String.valueOf(number).length(); &#125; /* * 获取 x 这个数的 d 位数上的数字 * 比如获取 123 的 0 位数,结果返回 3 * * @param x * @param d * @return */ private int getDigit(int x, int d) &#123; int a[] = &#123; 1, 10, 100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000 &#125;; return ((x / a[d]) % 10); &#125;&#125; 基数排序过程图如果我们的无序是 T = [ 2314, 5428, 373, 2222, 17 ]，那么其排序的过程就如下两幅所示。基数排序过程图-1基数排序过程图-2]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁的三种实现方式]]></title>
    <url>%2F2019%2F05%2F18%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E4%B8%89%E7%A7%8D%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[分布式锁的三种实现方式 zookeeper实现原理：基于zookeeper瞬时有序节点实现的分布式锁，其主要逻辑如下（该图来自于IBM网站）。大致思想即为：每个客户端对某个功能加锁时，在zookeeper上的与该功能对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁无法释放，而产生的死锁问题。 优点锁安全性高，zk可持久化 缺点性能开销比较高。因为其需要动态产生、销毁瞬时节点来实现锁功能。 实现可以直接采用zookeeper第三方库curator即可方便地实现分布式锁。以下为基于curator实现的zk分布式锁核心代码：123456789101112131415161718192021@Override public boolean tryLock(LockInfo info) &#123; InterProcessMutex mutex = getMutex(info); int tryTimes = info.getTryTimes(); long tryInterval = info.getTryInterval(); boolean flag = true;// 代表是否需要重试 while (flag &amp;&amp; --tryTimes &gt;= 0) &#123; try &#123; if (mutex.acquire(info.getWaitLockTime(), TimeUnit.MILLISECONDS)) &#123; LOGGER.info(LogConstant.DST_LOCK + &quot;acquire lock successfully!&quot;); flag = false; break; &#125; &#125; catch (Exception e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;acquire lock error!&quot;, e); &#125; finally &#123; checkAndRetry(flag, tryInterval, tryTimes); &#125; &#125; return !flag;// 最后还需要重试，说明没拿到锁 &#125; 1234567891011121314151617181920@Override public boolean releaseLock(LockInfo info) &#123; InterProcessMutex mutex = getMutex(info); int tryTimes = info.getTryTimes(); long tryInterval = info.getTryInterval(); boolean flag = true;// 代表是否需要重试 while (flag &amp;&amp; --tryTimes &gt;= 0) &#123; try &#123; mutex.release(); LOGGER.info(LogConstant.DST_LOCK + &quot;release lock successfully!&quot;); flag = false; break; &#125; catch (Exception e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;release lock error!&quot;, e); &#125; finally &#123; checkAndRetry(flag, tryInterval, tryTimes); &#125; &#125; return !flag;// 最后还需要重试，说明没拿到锁 &#125; 1234567891011121314151617181920212223242526/** * 获取锁。此处需要加同步，concurrentHashmap无法避免此处的同步问题 * @param info 锁信息 * @return 锁实例 */ private synchronized InterProcessMutex getMutex(LockInfo info) &#123; InterProcessReadWriteLock lock = null; if (locksCache.get(info.getLock()) != null) &#123; lock = locksCache.get(info.getLock()); &#125; else &#123; lock = new InterProcessReadWriteLock(client, BASE_DIR + info.getLock()); locksCache.put(info.getLock(), lock); &#125; InterProcessMutex mutex = null; switch (info.getIsolate()) &#123; case READ: mutex = lock.readLock(); break; case WRITE: mutex = lock.writeLock(); break; default: throw new IllegalArgumentException(); &#125; return mutex; &#125; 12345678910111213141516/** * 判断是否需要重试 * @param flag 是否需要重试标志 * @param tryInterval 重试间隔 * @param tryTimes 重试次数 */ private void checkAndRetry(boolean flag, long tryInterval, int tryTimes) &#123; try &#123; if (flag) &#123; Thread.sleep(tryInterval); LOGGER.info(LogConstant.DST_LOCK + &quot;retry getting lock! now retry time left: &quot; + tryTimes); &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error(LogConstant.DST_LOCK + &quot;retry interval thread interruptted!&quot;, e); &#125; &#125; memcached分布式锁实现原理：memcached带有add函数，利用add函数的特性即可实现分布式锁。add和set的区别在于：如果多线程并发set，则每个set都会成功，但最后存储的值以最后的set的线程为准。而add的话则相反，add会添加第一个到达的值，并返回true，后续的添加则都会返回false。利用该点即可很轻松地实现分布式锁。 优点并发高效。 缺点 memcached采用列入LRU置换策略，所以如果内存不够，可能导致缓存中的锁信息丢失。 memcached无法持久化，一旦重启，将导致信息丢失。 redis分布式锁redis分布式锁即可以结合zk分布式锁锁高度安全和memcached并发场景下效率很好的优点，可以利用jedis客户端实现。参考http://blog.csdn.net/java2000_wl/article/details/8740911]]></content>
      <tags>
        <tag>分布式系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十三）：内存管理之进程地址空间]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%B8%89%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E8%BF%9B%E7%A8%8B%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 进程地址空间由进程可寻址的虚拟内存组成，Linux 的虚拟地址空间为0~4G字节（注：本节讲述均以32为为例）。Linux内核将这 4G 字节的空间分为两部分。将最高的 1G 字节(从虚拟地址0xC0000000到0xFFFFFFFF)，供内核使用，称为“内核空间”。而将较低的 3G 字节(从虚拟地址 0x00000000 到 0xBFFFFFFF)，供各个进程使用，称为“用户空间” 。因为每个进程可以通过系统调用进入内核。因此，Linux 内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4G 字节的虚拟空间。 尽管一个进程可以寻址4G的虚拟内存，但就不代表它就有权限访问所有的地址空间，虚拟内存空间必须映射到某个物理存储空间(内存或磁盘空间)，才真正地可以被使用。进程只能访问合法的地址空间，如果一个进程访问了不合法的地址空间，内核就会终止该进程，并返回“段错误”。虚拟内存的合法地址空间在哪而呢？我们先来看看进程虚拟地址空间的划分： 其中堆栈安排在虚拟地址空间顶部，数据段和代码段分布在虚拟地址空间底部，空洞部分就是进程运行时可以动态分布的空间，包括映射内核地址空间内容、动态申请地址空间、共享库的代码或数据等。在虚拟地址空间中，只有那些映射到物理存储空间的地址才是合法的地址空间。每一片合法的地址空间片段都对应一个独立的虚拟内存区域（VMA，virtual memory areas ），而进程的进程地址空间就是由这些内存区域组成。Linux 采用了复杂的数据结构来跟踪进程的虚拟地址，进程地址空间使用内存描述符结构体来表示，内存描述符由mm_struct结构体表示，该结构体表示在&lt;include/linux/mm_types.h&gt;文件中：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889struct mm_struct &#123; struct vm_area_struct * mmap; /* list of VMAs */ struct rb_root mm_rb; struct vm_area_struct * mmap_cache; /* last find_vma result */ unsigned long (*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); void (*unmap_area) (struct mm_struct *mm, unsigned long addr); unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ unsigned long cached_hole_size; /* if non-zero, the largest hole below free_area_cache */ unsigned long free_area_cache; /* first hole of size cached_hole_size or larger */ pgd_t * pgd; atomic_t mm_users; /* How many users with user space? */ atomic_t mm_count; /* How many references to &quot;struct mm_struct&quot; (users count as 1) */ int map_count; /* number of VMAs */ struct rw_semaphore mmap_sem; spinlock_t page_table_lock; /* Protects page tables and some counters */ struct list_head mmlist; /* List of maybe swapped mm&apos;s. These are globally strung * together off init_mm.mmlist, and are protected * by mmlist_lock */ /* Special counters, in some configurations protected by the * page_table_lock, in other configurations by being atomic. */ mm_counter_t _file_rss; mm_counter_t _anon_rss; unsigned long hiwater_rss; /* High-watermark of RSS usage */ unsigned long hiwater_vm; /* High-water virtual memory usage */ unsigned long total_vm, locked_vm, shared_vm, exec_vm; unsigned long stack_vm, reserved_vm, def_flags, nr_ptes; unsigned long start_code, end_code, start_data, end_data; unsigned long start_brk, brk, start_stack; unsigned long arg_start, arg_end, env_start, env_end; unsigned long saved_auxv[AT_VECTOR_SIZE]; /* for /proc/PID/auxv */ struct linux_binfmt *binfmt; cpumask_t cpu_vm_mask; /* Architecture-specific MM context */ mm_context_t context; /* Swap token stuff */ /* * Last value of global fault stamp as seen by this process. * In other words, this value gives an indication of how long * it has been since this task got the token. * Look at mm/thrash.c */ unsigned int faultstamp; unsigned int token_priority; unsigned int last_interval; unsigned long flags; /* Must use atomic bitops to access the bits */ struct core_state *core_state; /* coredumping support */#ifdef CONFIG_AIO spinlock_t ioctx_lock; struct hlist_head ioctx_list;#endif#ifdef CONFIG_MM_OWNER /* * &quot;owner&quot; points to a task that is regarded as the canonical * user/owner of this mm. All of the following must be true in * order for it to be changed: * * current == mm-&gt;owner * current-&gt;mm != mm * new_owner-&gt;mm == mm * new_owner-&gt;alloc_lock is held */ struct task_struct *owner;#endif #ifdef CONFIG_PROC_FS /* store ref to file /proc/&lt;pid&gt;/exe symlink points to */ struct file *exe_file; unsigned long num_exe_file_vmas;#endif#ifdef CONFIG_MMU_NOTIFIER struct mmu_notifier_mm *mmu_notifier_mm;#endif&#125;; 该结构体中第一行成员mmap就是内存区域，用结构体struct vm_area_struct来表示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/* * This struct defines a memory VMM memory area. There is one of these * per VM-area/task. A VM area is any part of the process virtual memory * space that has a special rule for the page-fault handlers (ie a shared * library, the executable area etc). */struct vm_area_struct &#123; struct mm_struct * vm_mm; /* The address space we belong to. */ unsigned long vm_start; /* Our start address within vm_mm. */ unsigned long vm_end; /* The first byte after our end address within vm_mm. */ /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next; pgprot_t vm_page_prot; /* Access permissions of this VMA. */ unsigned long vm_flags; /* Flags, see mm.h. */ struct rb_node vm_rb; /* * For areas with an address space and backing store, * linkage into the address_space-&gt;i_mmap prio tree, or * linkage to the list of like vmas hanging off its node, or * linkage of vma in the address_space-&gt;i_mmap_nonlinear list. */ union &#123; struct &#123; struct list_head list; void *parent; /* aligns with prio_tree_node parent */ struct vm_area_struct *head; &#125; vm_set; struct raw_prio_tree_node prio_tree_node; &#125; shared; /* * A file&apos;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma * list, after a COW of one of the file pages. A MAP_SHARED vma * can only be in the i_mmap tree. An anonymous MAP_PRIVATE, stack * or brk vma (with NULL file) can only be in an anon_vma list. */ struct list_head anon_vma_node; /* Serialized by anon_vma-&gt;lock */ struct anon_vma *anon_vma; /* Serialized by page_table_lock */ /* Function pointers to deal with this struct. */ const struct vm_operations_struct *vm_ops; /* Information about our backing store: */ unsigned long vm_pgoff; /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */ struct file * vm_file; /* File we map to (can be NULL). */ void * vm_private_data; /* was vm_pte (shared mem) */ unsigned long vm_truncate_count;/* truncate_count or restart_addr */ #ifndef CONFIG_MMU struct vm_region *vm_region; /* NOMMU mapping region */#endif#ifdef CONFIG_NUMA struct mempolicy *vm_policy; /* NUMA policy for the VMA */#endif&#125;; vm_area_struct结构体描述了进程地址空间内连续区间上的一个独立内存范围，每一个内存区域都使用该结构体表示，每一个结构体以双向链表的形式连接起来。除链表结构外,Linux 还利用红黑树mm_rb来组织 vm_area_struct。通过这种树结构，Linux 可以快速定位某个虚拟内存地址。 该结构体中成员vm_start和vm_end表示内存区间的首地址和尾地址，两个值相减就是内存区间的长度。 成员vm_mm则指向其属于的进程地址空间结构体。所以两个不同的进程将同一个文件映射到自己的地址空间中，他们分别都会有一个vm_area_struct结构体来标识自己的内存区域。两个共享地址空间的线程则只有一个vm_area_struct结构体来标识，因为他们使用的是同一个进程地址空间。 vm_flags标识内存区域所包含的页面的行为和信息，反映内核处理页面所需要遵守的行为准则。 可以使用cat /proc/PID/maps命令和pmap命令查看给定进程空间和其中所含的内存区域。以笔者系统上进程号为17192的进程为例。12345678910111213141516# cat /proc/17192/maps //显示该进程地址空间中全部内存区域001e3000-00201000 r-xp 00000000 fd:00 789547 /lib/ld-2.12.so00201000-00202000 r--p 0001d000 fd:00 789547 /lib/ld-2.12.so00202000-00203000 rw-p 0001e000 fd:00 789547 /lib/ld-2.12.so00209000-00399000 r-xp 00000000 fd:00 789548 /lib/libc-2.12.so00399000-0039a000 ---p 00190000 fd:00 789548 /lib/libc-2.12.so0039a000-0039c000 r--p 00190000 fd:00 789548 /lib/libc-2.12.so0039c000-0039d000 rw-p 00192000 fd:00 789548 /lib/libc-2.12.so0039d000-003a0000 rw-p 00000000 00:00 008048000-08049000 r-xp 00000000 fd:00 1191771 /home/allen/Myprojects/blog/conn_user_kernel/test/a.out08049000-0804a000 rw-p 00000000 fd:00 1191771 /home/allen/Myprojects/blog/conn_user_kernel/test/a.outb7755000-b7756000 rw-p 00000000 00:00 0b776d000-b776e000 rw-p 00000000 00:00 0b776e000-b776f000 r-xp 00000000 00:00 0 [vdso]bfc9f000-bfcb4000 rw-p 00000000 00:00 0 [stack]# 1234567891011121314151617# pmap 1719217192: ./a.out001e3000 120K r-x-- /lib/ld-2.12.so //本行和下面两行为动态链接程序ld.so的代码段、数据段、bss段00201000 4K r---- /lib/ld-2.12.so00202000 4K rw--- /lib/ld-2.12.so00209000 1600K r-x-- /lib/libc-2.12.so //本行和下面为C库中libc.so的代码段、数据段和bss段00399000 4K ----- /lib/libc-2.12.so0039a000 8K r---- /lib/libc-2.12.so0039c000 4K rw--- /lib/libc-2.12.so0039d000 12K rw--- [ anon ]08048000 4K r-x-- /home/allen/Myprojects/blog/conn_user_kernel/test/a.out //可执行对象的代码段08049000 4K rw--- /home/allen/Myprojects/blog/conn_user_kernel/test/a.out //可执行对象的数据段b7755000 4K rw--- [ anon ]b776d000 4K rw--- [ anon ]b776e000 4K r-x-- [ anon ]bfc9f000 84K rw--- [ stack ] //堆栈段 total 1860K 结构体中vm_ops域指定内存区域相关操作函数表，内核使用表中方法操作VMA，操作函数表由vm_operations_struct结构体表示，定义在&lt;include/linux/mm.h&gt;文件中：1234567891011121314151617181920212223/* * These are the virtual MM functions - opening of an area, closing and * unmapping it (needed to keep files on disk up-to-date etc), pointer * to the functions called when a no-page or a wp-page exception occurs. */struct vm_operations_struct &#123; void (*open)(struct vm_area_struct * area); //指定内存区域被加载到一个地址空间时函数被调用 void (*close)(struct vm_area_struct * area); //指定内存区域从地址空间删除时函数被调用 int (*fault)(struct vm_area_struct *vma, struct vm_fault *vmf); //没有出现在物理内存中的页面被访问时，页面故障处理调用该函数 /* notification that a previously read-only page is about to become * writable, if an error is returned it will cause a SIGBUS */ int (*page_mkwrite)(struct vm_area_struct *vma, struct vm_fault *vmf); /* called by access_process_vm when get_user_pages() fails, typically * for use by special VMAs that can switch between memory and hardware */ int (*access)(struct vm_area_struct *vma, unsigned long addr, void *buf, int len, int write);#ifdef CONFIG_NUMA ......#endif&#125;; 在内核中，给定一个属于某个进程的虚拟地址，要求找到其所属的区间以及vma_area_struct结构，这通过find_vma()来实现，这种搜索通过红-黑树进行。该函数定义于&lt;mm/mmap.c&gt;中：123456789101112131415161718192021222324252627282930313233343536/* Look up the first VMA which satisfies addr &lt; vm_end, NULL if none. */struct vm_area_struct *find_vma(struct mm_struct *mm, unsigned long addr)&#123; struct vm_area_struct *vma = NULL; if (mm) &#123; /* 首先检查最近使用的内存区域，看缓存的VMA是否包含所需地址 */ /* (命中录接近35%.) */ vma = mm-&gt;mmap_cache; //如果缓存中不包含未包含希望的VMA，该函数搜索红-黑树。 if (!(vma &amp;&amp; vma-&gt;vm_end &gt; addr &amp;&amp; vma-&gt;vm_start &lt;= addr)) &#123; struct rb_node * rb_node; rb_node = mm-&gt;mm_rb.rb_node; vma = NULL; while (rb_node) &#123; struct vm_area_struct * vma_tmp; vma_tmp = rb_entry(rb_node, struct vm_area_struct, vm_rb); if (vma_tmp-&gt;vm_end &gt; addr) &#123; vma = vma_tmp; if (vma_tmp-&gt;vm_start &lt;= addr) break; rb_node = rb_node-&gt;rb_left; &#125; else rb_node = rb_node-&gt;rb_right; &#125; if (vma) mm-&gt;mmap_cache = vma; &#125; &#125; return vma;&#125; 当某个程序的映像开始执行时,可执行映像必须装入到进程的虚拟地址空间。如果该进程用到了任何一个共享库,则共享库也必须装入到进程的虚拟地址空间。由此可看出，Linux并不将映像装入到物理内存，相反，可执行文件只是被连接到进程的虚拟地址空间中。随着程序的运行，被引用的程序部分会由操作系统装入到物理内存，这种将映像链接到进程地址空间的方法被称为“内存映射”。 当可执行映像映射到进程的虚拟地址空间时，将产生一组 vm_area_struct 结构来描述虚拟内存区间的起始点和终止点，每个 vm_area_struct 结构代表可执行映像的一部分，可能是可执行代码，也可能是初始化的变量或未初始化的数据，这些都是在函数 do_mmap()中来实现的。随着 vm_area_struct 结构的生成，这些结构所描述的虚拟内存区间上的标准操作函数也由 Linux 初始化。123456789101112static inline unsigned long do_mmap(struct file *file, unsigned long addr, unsigned long len, unsigned long prot, unsigned long flag, unsigned long offset)&#123; unsigned long ret = -EINVAL; if ((offset + PAGE_ALIGN(len)) &lt; offset) goto out; if (!(offset &amp; ~PAGE_MASK)) ret = do_mmap_pgoff(file, addr, len, prot, flag, offset &gt;&gt; PAGE_SHIFT);out: return ret;&#125; 该函数会将一个新的地址区间加入到进程的地址空间中。定义于&lt;include/linux/mm.h&gt;。函数中参数的含义： file:表示要映射的文件。 offset\:文件内的偏移量，因为我们并不是一下子全部映射一个文件,可能只是映射文件的一部分,off 就表示那部分的起始位置。 len:要映射的文件部分的长度。 addr:虚拟空间中的一个地址,表示从这个地址开始查找一个空闲的虚拟区。 prot: 这个参数指定对这个虚拟区所包含页的存取权限。可能的标志有 PROT_READ、PROT_WRITE、PROT_EXEC 和 PROT_NONE。前 3 个标志与标志 VM_READ、VM_WRITE 及 VM_EXEC的意义一样。PROT_NONE 表示进程没有以上 3 个存取权限中的任意一个。 flag:这个参数指定虚拟区的其他标志。 该函数调用 do_mmap_pgoff()函数，该函数做内存映射的主要工作，该函数比较长，详细实现可查看&lt;mm/mmap.c&gt;文件。由于文件到虚存的映射仅仅是建立了一种映射关系，虚存页面到物理页面之间的映射还没有建立。当某个可执行映象映射到进程虚拟内存中并开始执行时，因为只有很少一部分虚拟内存区间装入到了物理内存，很可能会遇到所访问的数据不在物理内存。这时，处理器将向 Linux 报告一个页故障及其对应的故障原因，内核必须从磁盘映像或交换文件(此页被换出)中将其装入物理内存，这就是请页机制。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十二）：内存管理之slab分配器]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8Bslab%E5%88%86%E9%85%8D%E5%99%A8%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 上一节最后说到对于小内存区的请求，如果采用伙伴系统来进行分配，则会在页内产生很多空闲空间无法使用，因此产生slab分配器来处理对小内存区（几十或几百字节）的请求。Linux中引入Slab的主要目的是为了减少对伙伴算法的调用次数。 内核经常反复使用某一内存区。例如，只要内核创建一个新的进程，就要为该进程相关的数据结构（task_struct、打开文件对象等）分配内存区。当进程结束时，收回这些内存区。因为进程的创建和撤销非常频繁，linux把那些频繁使用的页面保存在高速缓存中并重新使用。 slab分配器基于对象进行管理，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就分配一个空闲对象出去，而当要释放时，将其重新保存在slab分配器中，而不是直接返回给伙伴系统。对于频繁请求的对象，创建适当大小的专用对象来处理。对于不频繁的对象，用一系列几何分布大小的对象来处理（详见通用对象）。 slab分配模式把对象分组放进缓冲区，为缓冲区的组织和管理与硬件高速缓存的命中率密切相关，因此，Slab缓冲区并非由各个对象直接构成，而是由一连串的“大块（Slab）”构成，而每个大块中则包含了若干个同种类型的对象，这些对象或已被分配，或空闲。实际上，缓冲区就是主存中的一片区域，把这片区域划分为多个块，每块就是一个Slab，每个Slab由一个或多个页面组成，每个Slab中存放的就是对象。 slab相关数据结构： 缓冲区数据结构使用kmem_cache结构来表示。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374struct kmem_cache &#123;/* 1) per-cpu data, touched during every alloc/free */ struct array_cache *array[NR_CPUS];/* 2) Cache tunables. Protected by cache_chain_mutex */ unsigned int batchcount; unsigned int limit; unsigned int shared; unsigned int buffer_size; u32 reciprocal_buffer_size;/* 3) touched by every alloc &amp; free from the backend */ unsigned int flags; /* constant flags */ unsigned int num; /* # of objs per slab */ /* 4) cache_grow/shrink */ /* order of pgs per slab (2^n) */ unsigned int gfporder; /* force GFP flags, e.g. GFP_DMA */ gfp_t gfpflags; size_t colour; /* cache colouring range */ unsigned int colour_off; /* colour offset */ struct kmem_cache *slabp_cache; unsigned int slab_size; unsigned int dflags; /* dynamic flags */ /* constructor func */ void (*ctor)(void *obj); /* 5) cache creation/removal */ const char *name; struct list_head next; /* 6) statistics */#ifdef CONFIG_DEBUG_SLAB unsigned long num_active; unsigned long num_allocations; unsigned long high_mark; unsigned long grown; unsigned long reaped; unsigned long errors; unsigned long max_freeable; unsigned long node_allocs; unsigned long node_frees; unsigned long node_overflow; atomic_t allochit; atomic_t allocmiss; atomic_t freehit; atomic_t freemiss; /* * If debugging is enabled, then the allocator can add additional * fields and/or padding to every object. buffer_size contains the total * object size including these internal fields, the following two * variables contain the offset to the user object and its size. */ int obj_offset; int obj_size;#endif /* CONFIG_DEBUG_SLAB */ /* * We put nodelists[] at the end of kmem_cache, because we want to size * this array to nr_node_ids slots instead of MAX_NUMNODES * (see kmem_cache_init()) * We still use [MAX_NUMNODES] and not [1] or [0] because cache_cache * is statically defined, so we reserve the max number of nodes. */ struct kmem_list3 *nodelists[MAX_NUMNODES]; /* * Do not add fields after nodelists[] */&#125;; 其中struct kmem_list3结构体链接slab，共享高速缓存，其定义如下:12345678910111213141516/* * The slab lists for all objects. */struct kmem_list3 &#123; struct list_head slabs_partial; /* partial list first, better asm code */ struct list_head slabs_full; struct list_head slabs_free; unsigned long free_objects; unsigned int free_limit; unsigned int colour_next; /* Per-node cache coloring */ spinlock_t list_lock; struct array_cache *shared; /* shared per node */ struct array_cache **alien; /* on other nodes */ unsigned long next_reap; /* updated without locking */ int free_touched; /* updated without locking */&#125;; 该结构包含三个链表：slabs_partial、slabs_full、slabs_free，这些链表包含缓冲区所有slab，slab描述符struct slab用于描述每个slab：123456789101112131415/* * struct slab * * Manages the objs in a slab. Placed either at the beginning of mem allocated * for a slab, or allocated from an general cache. * Slabs are chained into three list: fully used, partial, fully free slabs. */struct slab &#123; struct list_head list; unsigned long colouroff; void *s_mem; /* including colour offset */ unsigned int inuse; /* num of objs active in slab */ kmem_bufctl_t free; unsigned short nodeid;&#125;; 一个新的缓冲区使用如下函数创建：1struct kmem_cache *kmem_cache_create (const char *name, size_t size, size_t align, unsigned long flags, void (*ctor)(void *)); 函数创建成功会返回一个指向所创建缓冲区的指针；撤销一个缓冲区调用如下函数：1void kmem_cache_destroy(struct kmem_cache *cachep)； 上面两个函数都不能在中断上下文中使用，因为它可能睡眠。在创建来缓冲区之后，可以通过下列函数获取对象：1234567891011121314151617/** * kmem_cache_alloc - Allocate an object * @cachep: The cache to allocate from. * @flags: See kmalloc(). * * Allocate an object from this cache. The flags are only relevant * if the cache has no available objects. */void *kmem_cache_alloc(struct kmem_cache *cachep, gfp_t flags)&#123; void *ret = __cache_alloc(cachep, flags, __builtin_return_address(0)); trace_kmem_cache_alloc(_RET_IP_, ret, obj_size(cachep), cachep-&gt;buffer_size, flags); return ret;&#125; 该函数从给点缓冲区cachep中返回一个指向对象的指针。如果缓冲区的所有slab中都没有空闲对象，那么slab层必须通过kmem_getpages()获取新的页，参数flags传递给_get_free_pages()。1static void *kmem_getpages(struct kmem_cache *cachep, gfp_t flags, int nodeid)； 释放对象使用如下函数：123456789101112131415161718192021/** * kmem_cache_free - Deallocate an object * @cachep: The cache the allocation was from. * @objp: The previously allocated object. * * Free an object which was previously allocated from this * cache. */void kmem_cache_free(struct kmem_cache *cachep, void *objp)&#123; unsigned long flags; local_irq_save(flags); debug_check_no_locks_freed(objp, obj_size(cachep)); if (!(cachep-&gt;flags &amp; SLAB_DEBUG_OBJECTS)) debug_check_no_obj_freed(objp, obj_size(cachep)); __cache_free(cachep, objp); local_irq_restore(flags); trace_kmem_cache_free(_RET_IP_, objp);&#125; 如果你要频繁的创建很多相同类型的对象，就要当考虑使用slab高速缓存区。 实际上上一节所讲kmalloc()函数也是使用slab分配器分配的。123456789101112131415161718192021222324252627282930313233343536static __always_inline void *kmalloc(size_t size, gfp_t flags)&#123; struct kmem_cache *cachep; void *ret; if (__builtin_constant_p(size)) &#123; int i = 0; if (!size) return ZERO_SIZE_PTR; #define CACHE(x) \ if (size &lt;= x) \ goto found; \ else \ i++;#include &lt;linux/kmalloc_sizes.h&gt;#undef CACHE return NULL;found:#ifdef CONFIG_ZONE_DMA if (flags &amp; GFP_DMA) cachep = malloc_sizes[i].cs_dmacachep; else#endif cachep = malloc_sizes[i].cs_cachep; ret = kmem_cache_alloc_notrace(cachep, flags); trace_kmalloc(_THIS_IP_, ret, size, slab_buffer_size(cachep), flags); return ret; &#125; return __kmalloc(size, flags);&#125; kfree函数实现如下：1234567891011121314151617181920212223242526/** * kfree - free previously allocated memory * @objp: pointer returned by kmalloc. * * If @objp is NULL, no operation is performed. * * Don&apos;t free memory not originally allocated by kmalloc() * or you will run into trouble. */void kfree(const void *objp)&#123; struct kmem_cache *c; unsigned long flags; trace_kfree(_RET_IP_, objp); if (unlikely(ZERO_OR_NULL_PTR(objp))) return; local_irq_save(flags); kfree_debugcheck(objp); c = virt_to_cache(objp); debug_check_no_locks_freed(objp, obj_size(c)); debug_check_no_obj_freed(objp, obj_size(c)); __cache_free(c, (void *)objp); local_irq_restore(flags);&#125; 最后，结合上一节，看看分配函数的选择：如果需要连续的物理页，就可以使用某个低级页分配器或kmalloc()。如果想从高端内存进行分配，使用alloc_pages()。如果不需要物理上连续的页，而仅仅是虚拟地址上连续的页，那么就是用vmalloc。如果要创建和销毁很多大的数据结构，那么考虑建立slab高速缓存。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十一）：内存管理之页的分配与回收]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%E4%B8%80%EF%BC%89%EF%BC%9A%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8B%E9%A1%B5%E7%9A%84%E5%88%86%E9%85%8D%E4%B8%8E%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 内存管理单元（MMU）负责将管理内存，在把虚拟地址转换为物理地址的硬件的时候是按页为单位进行处理，从虚拟内存的角度来看，页就是内存管理中的最小单位。页的大小与体系结构有关，在 x86 结构中一般是4KB（32位）或者8KB（64位）。通过 getconf 命令可以查看系统的page的大小：12345# getconf -a | grep PAGEPAGESIZE 4096PAGE_SIZE 4096_AVPHYS_PAGES 230873_PHYS_PAGES 744957 内核中的每个物理页用struct page结构表示，结构定义于文件&lt;include/linux/mm_types.h&gt;：123456789101112131415161718192021222324252627282930313233343536373839struct page &#123; unsigned long flags; /*页的状态*/ atomic_t _count; /* 页引用计数 */ union &#123; atomic_t _mapcount; /* 已经映射到mms的pte的个数*/ struct &#123; /* */ u16 inuse; u16 objects; &#125;; &#125;; union &#123; struct &#123; unsigned long private; struct address_space *mapping; &#125;;#if USE_SPLIT_PTLOCKS spinlock_t ptl;#endif struct kmem_cache *slab; /* 指向slab层 */ struct page *first_page; /* Compound tail pages */ &#125;; union &#123; pgoff_t index; /* Our offset within mapping. */ void *freelist; /* SLUB: freelist req. slab lock */ &#125;; struct list_head lru; /* 将页关联起来的链表项 */ #if defined(WANT_PAGE_VIRTUAL) void *virtual; /* Kernel virtual address (NULL if not kmapped, ie. highmem) */#endif /* WANT_PAGE_VIRTUAL */#ifdef CONFIG_WANT_PAGE_DEBUG_FLAGS unsigned long debug_flags; /* Use atomic bitops on this */#endif #ifdef CONFIG_KMEMCHECK void *shadow;#endif&#125;; 内核使用这一结构来管理系统中所有的页，因为内核需要知道一个该页是否被分配，是被谁拥有的等信息。 由于ISA总线的DMA处理器有严格的限制，只能对物理内存前16M寻址，内核线性地址空间只有1G,CPU不能直接访问所有的物理内存。这样就导致有一些内存不能永久地映射在内核空间上。所以在linux中，把页分为不同的区，使用区来对具有相似特性的页进行分组。分组如下（以x86-32为例）： 区域 用途 ZONE_DMA 小于16M内存页框，这个区包含的页用来执行DMA操作。 ZONE_NORMAL 16M~896M内存页框，个区包含的都是能正常映射的页。 ZONE_HIGHMEM 大于896M内存页框，这个区包”高端内存”，其中的页能不永久地映射到内核地址空间。 linux 把系统的页划分区，形成不同的内存池，这样就可以根据用途进行分配了。 每个区都用struct zone表示，定义于&lt;include/linux/mmzone.h&gt;中。该结构体较大，详细结构体信息可以查看源码文件。 linux提供了几个以页为单位分配释放内存的接口，定义于&lt;include/linux/gfp.h&gt;中。分配内存主要有以下方法： —|—alloc_page(gfp_mask)|只分配一页，返回指向页结构的指针alloc_pages(gfp_mask, order)|分配 2^order 个页，返回指向第一页页结构的指针get_free_page(gfp_mask)|只分配一页，返回指向其逻辑地址的指针 get_free_pages(gfp_mask, order)|分配 2^order 个页，返回指向第一页逻辑地址的指针get_zeroed_page(gfp_mask)|只分配一页，让其内容填充为0，返回指向其逻辑地址的指针 alloc_函数返回的是内存的物理地址，get_ 函数返回内存物理地址映射后的逻辑地址。如果无须直接操作物理页结构体的话，一般使用 get_*函数。 释放页的函数有：123externvoid__free_pages( struct page *page, unsignedintorder); externvoidfree_pages(unsigned longaddr, unsigned intorder); externvoidfree_hot_page( struct page *page); 当需要以页为单位的连续物理页时，可以使用上面这些分配页的函数，对于常用以字节为单位的分配来说，内核提供来kmalloc()函数。 kmalloc()函数和用户空间一族函数类似，它可以以字节为单位分配内存，对于大多数内核分配来说，kmalloc函数用得更多。1void *kmalloc(size_t size, gfp_t gfp_mask)； 参数中有个 gfp_mask 标志，这个标志是控制分配内存时必须遵守的一些规则。gfp_mask 标志有3类： 行为标志 ：控制分配内存时，分配器的一些行为，如何分配所需内存。 区标志 ：控制内存分配在那个区(ZONE_DMA, ZONE_NORMAL, ZONE_HIGHMEM 之类)。 类型标志 ：由上面2种标志组合而成的一些常用的场景。 行为标志主要有以下几种： 行为标志 描述 __GFP_WAIT 分配器可以睡眠 __GFP_HIGH 分配器可以访问紧急事件缓冲池 __GFP_IO 分配器可以启动磁盘I/O __GFP_FS 分配器可以启动文件系统I/O __GFP_COLD 分配器应该使用高速缓存中快要淘汰出去的页 __GFP_NOWARN 分配器将不打印失败警告 __GFP_REPEAT 分配器在分配失败时重复进行分配，但是这次分配还存在失败的可能 __GFP_NOFALL 分配器将无限的重复进行分配。分配不能失败 __GFP_NORETRY 分配器在分配失败时不会重新分配 __GFP_NO_GROW 由slab层内部使用 __GFP_COMP 添加混合页元数据，在 hugetlb 的代码内部使用 标志主要有以下3种： 区标志 描述 __GFP_DMA 从 ZONE_DMA 分配 __GFP_DMA32 只在 ZONE_DMA32 分配 ，和 ZONE_DMA 类似，该区包含的页也可以进行DMA操作 __GFP_HIGHMEM 从 ZONE_HIGHMEM 或者 ZONE_NORMAL 分配，优先从 ZONE_HIGHMEM 分配，如果 ZONE_HIGHMEM 没有多余的页则从 ZONE_NORMAL 分配 类型标志是编程中最常用的，在使用标志时，应首先看看类型标志中是否有合适的，如果没有，再去自己组合 行为标志和区标志。 类型标志 描述 实际标志 GFP_ATOMIC 这个标志用在中断处理程序，下半部，持有自旋锁以及其他不能睡眠的地方 __GFP_HIGH GFP_NOWAIT 与 GFP_ATOMIC 类似，不同之处在于，调用不会退给紧急内存池。这就增加了内存分配失败的可能性 0 GFP_NOIO 这种分配可以阻塞，但不会启动磁盘I/O。这个标志在不能引发更多磁盘I/O时能阻塞I/O代码，可能会导致递归 __GFP_WAIT GFP_NOFS 这种分配在必要时可能阻塞，也可能启动磁盘I/O，但不会启动文件系统操作。这个标志在你不能再启动另一个文件系统的操作时，用在文件系统部分的代码中 (__GFP_WAIT｜ __GFP_IO) GFP_KERNEL 这是常规的分配方式，可能会阻塞。这个标志在睡眠安全时用在进程上下文代码中。为了获得调用者所需的内存，内核会尽力而为。这个标志应当为首选标志 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ) GFP_USER 这是常规的分配方式，可能会阻塞。用于为用户空间进程分配内存时 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ) GFP_HIGHUSER 从 ZONE_HIGHMEM 进行分配，可能会阻塞。用于为用户空间进程分配内存 (__GFP_WAIT｜ __GFP_IO ｜ __GFP_FS ｜__GFP_HIGHMEM) GFP_DMA 从 ZONE_DMA 进行分配。需要获取能供DMA使用的内存的设备驱动程序使用这个标志。通常与以上的某个标志组合在一起使用。 __GFP_DMA 以上各种类型标志的使用场景总结： 场景 相应标志 进程上下文，可以睡眠 使用 GFP_KERNEL 进程上下文，不可以睡眠 使用 GFP_ATOMIC，在睡眠之前或之后以 GFP_KERNEL 执行内存分配 中断处理程序 使用 GFP_ATOMIC 软中断 使用 GFP_ATOMIC tasklet 使用 GFP_ATOMIC 需要用于DMA的内存，可以睡眠 使用 (GFP_DMA｜GFP_KERNEL) 需要用于DMA的内存，不可以睡眠 使用 (GFP_DMA｜GFP_ATOMIC)，或者在睡眠之前执行内存分配 kmalloc 所对应的释放内存的方法为：1void kfree(const void *)； vmalloc()也可以按字节来分配内存。1void *vmalloc(unsigned long size) 和kmalloc是一样的作用，不同在于前者分配的内存虚拟地址是连续的，而物理地址则无需连续。kmalloc()可以保证在物理地址上都是连续的，虚拟地址当然也是连续的。vmalloc()函数只确保页在虚拟机地址空间内是连续的。它通过分配非联系的物理内存块，再“修正”页表，把内存映射到逻辑地址空间的连续区域中，就能做到这点。但很显然这样会降低处理性能，因为内核不得不做“拼接”的工作。所以这也是为什么不得已才使用 vmalloc()的原因 。 vmalloc()可能睡眠，不能从中断上下文中进行调用，也不能从其他不允许阻塞的情况下进行调用。释放时必须使用vfree()。1void vfree(const void *)； 对于内存页面的管理，通常是先在虚存空间中分配一个虚存区间，然后才根据需要为此区间分配相应的物理页面并建立起映射，也就是说，虚存区间的分配在前，而物理页面的分配在后。但由于频繁的请求和释放不同大小的连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页框，由此产生的问题是：即使有足够的空闲页框可以满足请求，但当要分配一个大块的连续页框时，无法满足请求。这就是著名的内存管理问题：外碎片问题。Linux采用著名的伙伴（Buddy）系统算法来解决外碎片问题。 把所有的空闲页框分组为11个块链表。每个块链表包含大小为1,2,4,8,16,32,64,128,256,512，1024个的页框。伙伴系统算法原理为： 假设请求一个256个页框的块，先在256个页框的链表内检查是否有一个空闲的块。如果没有这样的块，算法会查找下一个更大的块，在512个页框的链表中找一个空闲块。如果存在这样的块，内核就把512的页框分成两半，一半用作满足请求，另一半插入256个页框的链表中。如果512个页框的块链表也没有空闲块，就继续找更大的块，1024个页框的块。如果这样的块存在，内核把1024个页框的256个页框用作请求，然后从剩余的768个中拿出512个插入512个页框的链表中，把最后256个插入256个页框的链表中。 页框块的释放过程如下： 如果两个块具有相同的大小：a，并且他们的物理地址连续那么这两个块成为伙伴，内核就会试图把大小为a的一对空闲伙伴块合并为一个大小为2a的单独块。该算法还是迭代的，如果合并成功的话，它还会试图合并2a的块。 管理分区数据结构struct zone_struct中，涉及到空闲区数据结构。123456struct free_area free_area[MAX_ORDER]; struct free_area &#123; struct list_head free_list[MIGRATE_TYPES]; unsigned long nr_free; &#125;; 采用伙伴算法分配内存时，每次至少分配一个页面。但当请求分配的内存大小为几十个字节或几百个字节时应该如何处理？如何在一个页面中分配小的内存区，小内存区的分配所产生的内碎片又如何解决？slab的分配模式可以解决该问题，下一节我们将开始分析slab分配器。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（十）：内核同步]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%8D%81%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E5%90%8C%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 如同linux应用一样，内核的共享资源也要防止并发，因为如果多个执行线程同时访问和操作数据有可能发生各个线程之间相互覆盖共享数据的情况。 在linux只是单一处理器的时候，只有在中断发生或内核请求重新调度执行另一个任务时，数据才可能会并发访问。但自从内核开始支持对称多处理器之后，内核代码可以同时运行在多个处理器上，如果此时不加保护，运行在多个处理器上的代码完全可能在同一时刻并发访问共享数据。 一般把访问和操作共享数据的代码段称作临界区，为了避免在临界区中发生并发访问，程序员必须保证临界区代码原子执行，也就是要么全部执行，要么不执行。如果两个执行线程在同一个临界区同时执行，就发生了竞态（race conditions），避免并发防止竞态就是所谓的同步。 在linux内核中造成并发的原因主要有如下:中断 – 中断几乎可以在任何时刻异步发生，也就可能随时打断当前正在执行的代码。软中断和tasklet – 内核能在任何时刻唤醒或调度软中断和tasklet，打断当前正在执行的代码。内核抢占 – 因为内核具有抢占性，所以内核中的任务可能会被另一任务抢占。睡眠及与用户空间的同步 – 在内核执行的进程可能会睡眠，这就会唤醒调度程序，从而导致调度一个新的用户进程执行。对称多处理 – 两个或多个处理器可以同时执行代码。（真并发） 通过锁可以防止并发执行，并且保护临界区不受竞态影响。任何执行线程要访问临界区代码时首先先获得锁，这样当后面另外的执行线程要访问临界区时就不能再获得该锁，这样临界区就禁止后来执行线程访问。linux自身实现了多种不同的锁机制，各种锁各有差别，区别主要在于当锁被争用时，有些会简单地执行等待，而有些锁会使当前任务睡眠直到锁可用为止。本节将会分析各锁的使用和实现。但是使用锁也会带来副作用，锁使得线程按串行方式对资源进行访问，所以使用锁无疑会降低系统性能；并且锁使用不当还会造成死锁。 下面来看一下linux下同步的方法，包括原子操作、自旋锁、信号量等方式。 原子操作该操作是其它同步方法的基础，原子操作可以保证指令以原子的方式执行，执行过程不会被打断。linux内核提供了两组原子操作接口：原子整数操作和原子位操作。 针对整数的原子操作只能对atomic_t类型的数据进行处理。该类类型定义与文件&lt;include/linux/types.h&gt;:123typedef struct &#123; volatile int counter;&#125; atomic_t; 下面举例说明原子操作的用法：定义一个atomic_c类型的数据很简单，还可以定义时给它设定初值：1234(1) atomic_t u; /*定义 u*/(2) atomic_t v = ATOMIC_INIT(0) /*定义 v 并把它初始化为0*/ 对其操作：123456789(1) atomic_set(&amp;v,4)/* v = 4 ( 原子地)*/(2) atomic_add(2,&amp;v)/* v = v + 2 = 6 (原子地) */(3) atomic_inc(&amp;v) /* v = v + 1 =7（原子地)*/ 如果需要将atomic_t转换成int型，可以使用atomic_read()来完成：1printk(“%d\n”,atomic_read(&amp;v)); /* 会打印7*/ 原子整数操作最常见的用途就是实现计数器。使用复杂的锁机制来保护一个单纯的计数器是很笨拙的，所以，开发者最好使用atomic_inc()和atomic_dec()这两个相对来说轻便一点的操作。还可以用原子整数操作原子地执行一个操作并检查结果。一个常见的例子是原子的减操作和检查。1int atomic_dec_and_test(atomic_t *v) 这个函数让给定的原子变量减1，如果结果为0，就返回1；否则返回0。特定体系结构的所有原子整数操作可以在文件&lt;arch/x86/include/asm/atomic.h&gt;中找到。如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344#ifndef _ASM_X86_ATOMIC_32_H#define _ASM_X86_ATOMIC_32_H #include &lt;linux/compiler.h&gt;#include &lt;linux/types.h&gt;#include &lt;asm/processor.h&gt;#include &lt;asm/cmpxchg.h&gt; #define ATOMIC_INIT(i) &#123; (i) &#125; static inline int atomic_read(const atomic_t *v)&#123; return v-&gt;counter;&#125; static inline void atomic_set(atomic_t *v, int i)&#123; v-&gt;counter = i;&#125; static inline void atomic_add(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;addl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i));&#125; static inline void atomic_sub(int i, atomic_t *v)&#123; asm volatile(LOCK_PREFIX &quot;subl %1,%0&quot; : &quot;+m&quot; (v-&gt;counter) : &quot;ir&quot; (i));&#125; static inline int atomic_sub_and_test(int i, atomic_t *v)&#123; unsigned char c; asm volatile(LOCK_PREFIX &quot;subl %2,%0; sete %1&quot; : &quot;+m&quot; (v-&gt;counter), &quot;=qm&quot; (c) : &quot;ir&quot; (i) : &quot;memory&quot;); return c;&#125;...... 除了原子整数之外，内核还提供了一组针对位操作的函数，这些操作也是和体系结构相关的。例如在x86下set_bit实现如下：12345678910111213static __always_inline voidset_bit(unsigned int nr, volatile unsigned long *addr)&#123; if (IS_IMMEDIATE(nr)) &#123; asm volatile(LOCK_PREFIX &quot;orb %1,%0&quot; : CONST_MASK_ADDR(nr, addr) : &quot;iq&quot; ((u8)CONST_MASK(nr)) : &quot;memory&quot;); &#125; else &#123; asm volatile(LOCK_PREFIX &quot;bts %1,%0&quot; : BITOP_ADDR(addr) : &quot;Ir&quot; (nr) : &quot;memory&quot;); &#125;&#125; 原子操作是对普通内存地址指针进行的操作，只要指针指向了任何你希望的数据，你就可以对它进行操作。原子位操作(以x86为例)相关函数定义在文件&lt;arch/x86/include/asm/bitops.h&gt;中。 自旋锁不是所有的临界区都是像增加或减少变量这么简单，有的时候临界区可能会跨越多个函数，这这时就需要使用更为复杂的同步方法——锁。linux内核中最常见的锁是自旋锁，自旋锁最多只能被一个可执行线程持有，如果一个可执行线程视图获取一个已经被持有的锁，那么该线程将会一直进行忙循环等待锁重新可用。在任意时候，自旋锁都可以防止多余一个执行线程同时进入临界区。由于自旋忙等过程是很费时间的，所以自旋锁不应该被长时间持有。 自旋锁相关方法如下： 方法 spinlock中的定义 定义spin lock并初始化 DEFINE_SPINLOCK() 动态初始化spin lock spin_lock_init() 获取指定的spin lock spin_lock() 获取指定的spin lock同时disable本CPU中断 spin_lock_irq() 保存本CPU当前的irq状态，disable本CPU中断并获取指定的spin lock spin_lock_irqsave() 获取指定的spin lock同时disable本CPU的bottom half spin_lock_bh() 释放指定的spin lock spin_unlock() 释放指定的spin lock同时enable本CPU中断 spin_lock_irq() 释放指定的spin lock同时恢复本CPU的中断状态 spin_lock_irqsave() 获取指定的spin lock同时enable本CPU的bottom half spin_unlock_bh() 尝试去获取spin lock，如果失败，不会spin，而是返回非零值 spin_trylock() 判断spin lock是否是locked，如果其他的thread已经获取了该lock，那么返回非零值，否则返回0 spin_is_locked() 自旋锁的实现和体系结构密切相关，代码通常通过汇编实现。与体系结构相关的部分定义在&lt;asm/spinlock.h&gt;,实际需要用到的接口定义在文件&lt;linux/spinlock.h&gt;中。一个实际的锁的类型为spinlock_t，定义在文件&lt;include/linux/spinlock_types.h&gt;中:12345678910111213typedef struct &#123; raw_spinlock_t raw_lock;#ifdef CONFIG_GENERIC_LOCKBREAK unsigned int break_lock;#endif#ifdef CONFIG_DEBUG_SPINLOCK unsigned int magic, owner_cpu; void *owner;#endif#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125; spinlock_t; 自旋锁基本使用形式如下：1234DEFINE_SPINLOCK(lock);spin_lock(&amp;lock);/* 临界区 */spin_unlock(&amp;lock); 实际上有 4 个函数可以加锁一个自旋锁:12345void spin_lock(spinlock_t *lock);void spin_lock_irq(spinlock_t *lock); //相当于spin_lock() + local_irq_disable()。void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);//禁止中断(只在本地处理器)在获得自旋锁之前; 之前的中断状态保存在 flags里。相当于spin_lock() + local_irq_save()。void spin_lock_bh(spinlock_t *lock); //获取锁之前禁止软件中断, 但是硬件中断留作打开的，相当于spin_lock() + local_bh_disable()。 也有 4 个方法来释放一个自旋锁; 你用的那个必须对应你用来获取锁的函数.1234void spin_unlock(spinlock_t *lock);void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);void spin_unlock_irq(spinlock_t *lock);void spin_unlock_bh(spinlock_t *lock); 下面看一下DEFINE_SPINLOCK()、spin_lock_init()、spin_lock()、spin_lock_irqsave()的实现：1#define DEFINE_SPINLOCK(x) spinlock_t x = __SPIN_LOCK_UNLOCKED(x) 123# define spin_lock_init(lock) \ do &#123; *(lock) = SPIN_LOCK_UNLOCKED; &#125; while (0)#endif spin_lock:1234567891011#define spin_lock(lock) _spin_lock(lock)void __lockfunc _spin_lock(spinlock_t *lock)&#123; __spin_lock(lock);&#125;static inline void __spin_lock(spinlock_t *lock)&#123; preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); LOCK_CONTENDED(lock, _raw_spin_trylock, _raw_spin_lock);&#125; spin_lock_irqsave:123456789101112131415161718192021222324#define spin_lock_irqsave(lock, flags) \ do &#123; \ typecheck(unsigned long, flags); \ flags = _spin_lock_irqsave(lock); \ &#125; while (0)unsigned long __lockfunc _spin_lock_irqsave(spinlock_t *lock)&#123; return __spin_lock_irqsave(lock);&#125;static inline unsigned long __spin_lock_irqsave(spinlock_t *lock)&#123; unsigned long flags; local_irq_save(flags); //spin_lock的实现没有禁止本地中断这一步 preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); #ifdef CONFIG_LOCKDEP LOCK_CONTENDED(lock, _raw_spin_trylock, _raw_spin_lock);#else _raw_spin_lock_flags(lock, &amp;flags);#endif return flags;&#125; 读写自旋锁一种比自旋锁粒度更小的锁机制,它保留了“自旋”的概念,但是在写操作方面,只能最多有1个写进程,在读操作方面,同时可以有多个读执行单元。当然,读和写也不能同时进行。读者写者锁有一个类型 rwlock_t, 在&lt;linux/spinlokc.h&gt;中定义. 它们可以以 2 种方式被声明和被初始化:静态方式：1rwlock_t my_rwlock = RW_LOCK_UNLOCKED; 动态方式：12rwlock_t my_rwlock;rwlock_init(&amp;my_rwlock); 可用函数的列表现在应当看来相当类似。 对于读者, 有下列函数可用:12345678void read_lock(rwlock_t *lock);void read_lock_irqsave(rwlock_t *lock, unsigned long flags);void read_lock_irq(rwlock_t *lock);void read_lock_bh(rwlock_t *lock);void read_unlock(rwlock_t *lock);void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);void read_unlock_irq(rwlock_t *lock);void read_unlock_bh(rwlock_t *lock); 对于写存取的函数是类似的:123456789void write_lock(rwlock_t *lock);void write_lock_irqsave(rwlock_t *lock, unsigned long flags);void write_lock_irq(rwlock_t *lock);void write_lock_bh(rwlock_t *lock);int write_trylock(rwlock_t *lock);void write_unlock(rwlock_t *lock);void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);void write_unlock_irq(rwlock_t *lock);void write_unlock_bh(rwlock_t *lock); 在与下半部配合使用时，锁机制必须要小心使用。由于下半部可以抢占进程上下文的代码，所以当下半部和进程上下文共享数据时，必须对进程上下文的共享数据进行保护，所以需要加锁的同时还要禁止下半部执行。同样的，由于中断处理器可以抢占下半部，所以如果中断处理器程序和下半部共享数据，那么就必须在获取恰当的锁的同时还要禁止中断。 同类的tasklet不可能同时运行，所以对于同类tasklet中的共享数据不需要保护，但是当数据被两个不同种类的tasklet共享时，就需要在访问下半部中的数据前先获得一个普通的自旋锁。由于同种类型的两个软中断也可以同时运行在一个系统的多个处理器上，所以被软中断共享的数据必须得到锁的保护。 信号量一个被占有的自旋锁使得请求它的线程循环等待而不会睡眠，这很浪费处理器时间，所以自旋锁使用段时间占有的情况。linux提供另外的同步方式可以在锁争用时让请求线程睡眠，直到锁重新可用时在唤醒它，这样处理器就不必循环等待，可以去执行其它代码。这种方式就是即将讨论的信号量。 信号量是一种睡眠锁，如果有一个任务试图获得一个已经被占用的信号量时，信号量会将其放入一个等待队列，然后睡眠。当持有的信号量被释放后，处于等待队列中的那个任务将被唤醒，并获得信号量。信号量比自旋锁提供了更好的处理器利用率，因为没有把时间花费在忙等带上。但是信号量也会有一定的开销，被阻塞的线程换入换出有两次明显的上下文切换，这样的开销比自旋锁要大的多。 如果需要在自旋锁和信号量中做出选择，应该根据锁被持有的时间长短做判断，如果加锁时间不长并且代码不会休眠，利用自旋锁是最佳选择。相反，如果加锁时间可能很长或者代码在持有锁有可能睡眠，那么最好使用信号量来完成加锁功能。信号量一个有用特性就是它可以同时允许任意数量的锁持有者，而自旋锁在一个时刻最多允许一个任务持有它。信号量同时允许的持有者数量可以在声明信号量时指定，当为1时，成为互斥信号量，否则成为计数信号量。 信号量的实现与体系结构相关，信号量使用struct semaphore类型用来表示信号量，定义于文件&lt;include/linux/semaphore.h&gt;中:12345struct semaphore &#123; spinlock_t lock; unsigned int count; struct list_head wait_list;&#125;; 信号量初始化方法有如下:方法一:12345678struct semaphore sem; void sema_init(struct semaphore *sem, int val);//初始化信号量,并设置信号量 sem 的值为 val。 static inline void sema_init(struct semaphore *sem, int val)&#123; static struct lock_class_key __key; *sem = (struct semaphore) __SEMAPHORE_INITIALIZER(*sem, val); lockdep_init_map(&amp;sem-&gt;lock.dep_map, &quot;semaphore-&gt;lock&quot;, &amp;__key, 0);&#125; 方法二:1DECLARE_MUTEX(name); 定义一个名为 name 的信号量并初始化为1。其实现为:12#define DECLARE_MUTEX(name) \ struct semaphore name = __SEMAPHORE_INITIALIZER(name, 1) 方法三:1234#define init_MUTEX(sem) sema_init(sem, 1) //以不加锁状态动态创建信号量#define init_MUTEX_LOCKED(sem) sema_init(sem, 0) //以加锁状态动态创建信号量 信号量初始化后就可以使用了，使用信号量主要有如下方法:12345678910void down(struct semaphore * sem);//该函数用于获得信号量 sem，它会导致睡眠，因此不能在中断上下文使用; int down_interruptible(struct semaphore * sem);//该函数功能与 down 类似，不同之处为，因为 down()而进入睡眠状态的进程不能被信号打断，但因为 down_interruptible()而进入睡眠状态的进程能被信号打断，信号也会导致该函数返回，这时候函数的返回值非 0; int down_trylock(struct semaphore * sem);//该函数尝试获得信号量sem，如果能够立刻获得，它就获得该信号量并返回0， 否则,返回非0值。它不会导致调用者睡眠，可以在中断上下文使用。up(struct semaphore * sem); //释放指定信号量，如果睡眠队列不空，则唤醒其中一个队列。 信号量一般这样使用：12345678/* 定义信号量 DECLARE_MUTEX(mount_sem); //down(&amp;mount_sem);/* 获取信号量，保护临界区，信号量被占用之后进入不可中断睡眠状态down_interruptible(&amp;mount_sem);/* 获取信号量，保护临界区，信号量被占用之后进入不可中断睡眠状态. . . critical section /* 临界区 . . . up(&amp;mount_sem);/* 释放信号量 下面看一下这些函数的实现：down():123456789101112131415void down(struct semaphore *sem)&#123; unsigned long flags; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(sem-&gt;count &gt; 0)) sem-&gt;count--; else __down(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125;static noinline void __sched __down(struct semaphore *sem)&#123; __down_common(sem, TASK_UNINTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);&#125; down_interruptible():123456789101112131415161718int down_interruptible(struct semaphore *sem)&#123; unsigned long flags; int result = 0; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(sem-&gt;count &gt; 0)) sem-&gt;count--; else result = __down_interruptible(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags); return result;&#125;static noinline int __sched __down_interruptible(struct semaphore *sem)&#123; return __down_common(sem, TASK_INTERRUPTIBLE, MAX_SCHEDULE_TIMEOUT);&#125; down_trylock():12345678910111213int down_trylock(struct semaphore *sem)&#123; unsigned long flags; int count; spin_lock_irqsave(&amp;sem-&gt;lock, flags); count = sem-&gt;count - 1; if (likely(count &gt;= 0)) sem-&gt;count = count; spin_unlock_irqrestore(&amp;sem-&gt;lock, flags); return (count &lt; 0);&#125; up():12345678910111213141516171819void up(struct semaphore *sem)&#123; unsigned long flags; spin_lock_irqsave(&amp;sem-&gt;lock, flags); if (likely(list_empty(&amp;sem-&gt;wait_list))) sem-&gt;count++; else __up(sem); spin_unlock_irqrestore(&amp;sem-&gt;lock, flags);&#125;static noinline void __sched __up(struct semaphore *sem)&#123; struct semaphore_waiter *waiter = list_first_entry(&amp;sem-&gt;wait_list, struct semaphore_waiter, list); list_del(&amp;waiter-&gt;list); waiter-&gt;up = 1; wake_up_process(waiter-&gt;task);&#125; 正如自旋锁一样，信号量也有区分读写访问的可能，读写信号量在内核中使用rw_semaphore结构表示，x86体系结构定义在&lt;arch/x86/include/asm/rwsem.h&gt;文件中：12345678struct rw_semaphore &#123; signed long count; spinlock_t wait_lock; struct list_head wait_list;#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125;; 读写信号量的使用方法和信号量类似，其操作函数有如下:123456789DECLARE_RWSEM(name) //声明名为name的读写信号量，并初始化它。void init_rwsem(struct rw_semaphore *sem); //对读写信号量sem进行初始化。void down_read(struct rw_semaphore *sem); //读者用来获取sem，若没获得时，则调用者睡眠等待。void up_read(struct rw_semaphore *sem); //读者释放sem。int down_read_trylock(struct rw_semaphore *sem); //读者尝试获取sem，如果获得返回1，如果没有获得返回0。可在中断上下文使用。void down_write(struct rw_semaphore *sem); //写者用来获取sem，若没获得时，则调用者睡眠等待。int down_write_trylock(struct rw_semaphore *sem); //写者尝试获取sem，如果获得返回1，如果没有获得返回0。可在中断上下文使用void up_write(struct rw_semaphore *sem); //写者释放sem。void downgrade_write(struct rw_semaphore *sem); //把写者降级为读者。 互斥体除了信号量之外，内核拥有一个更简单的且可睡眠的锁，那就是互斥体。互斥体的行为和计数是1的信号量类似，其接口简单，实现更高效。 互斥体在内核中使用mutex表示，定义于&lt;include/linux/mutex.h&gt;：1234567struct mutex &#123; /* 1: unlocked, 0: locked, negative: locked, possible waiters */ atomic_t count; spinlock_t wait_lock; struct list_head wait_list; ......&#125;; 静态定义mutex：1DEFINE_MUTEX(name); 实现如下：123456789#define DEFINE_MUTEX(mutexname) \ struct mutex mutexname = __MUTEX_INITIALIZER(mutexname) #define __MUTEX_INITIALIZER(lockname) \ &#123; .count = ATOMIC_INIT(1) \ , .wait_lock = __SPIN_LOCK_UNLOCKED(lockname.wait_lock) \ , .wait_list = LIST_HEAD_INIT(lockname.wait_list) \ __DEBUG_MUTEX_INITIALIZER(lockname) \ __DEP_MAP_MUTEX_INITIALIZER(lockname) &#125; 动态定义mutex：123456789101112131415161718mutex_init(&amp;mutex);# define mutex_init(mutex) \do &#123; \ static struct lock_class_key __key; \ \ __mutex_init((mutex), #mutex, &amp;__key); \&#125; while (0) void__mutex_init(struct mutex *lock, const char *name, struct lock_class_key *key)&#123; atomic_set(&amp;lock-&gt;count, 1); spin_lock_init(&amp;lock-&gt;wait_lock); INIT_LIST_HEAD(&amp;lock-&gt;wait_list); mutex_clear_owner(lock); debug_mutex_init(lock, name, key);&#125; 锁定和解锁如下：12345678910111213141516171819202122232425262728293031mutex_lock(&amp;mutex);/* 临界区 */mutex_unlock(&amp;mutex);void __sched mutex_lock(struct mutex *lock)&#123; might_sleep(); /* * The locking fastpath is the 1-&gt;0 transition from * &apos;unlocked&apos; into &apos;locked&apos; state. */ __mutex_fastpath_lock(&amp;lock-&gt;count, __mutex_lock_slowpath); mutex_set_owner(lock);&#125; void __sched mutex_unlock(struct mutex *lock)&#123; /* * The unlocking fastpath is the 0-&gt;1 transition from &apos;locked&apos; * into &apos;unlocked&apos; state: */#ifndef CONFIG_DEBUG_MUTEXES /* * When debugging is enabled we must not clear the owner before time, * the slow path will always be taken, and that clears the owner field * after verifying that it was indeed current. */ mutex_clear_owner(lock);#endif __mutex_fastpath_unlock(&amp;lock-&gt;count, __mutex_unlock_slowpath);&#125; 其他mutex方法:12int mutex_trylock(struct mutex *); //视图获取指定互斥体，成功返回1；否则返回0。int mutex_is_locked(struct mutex *lock); //判断锁是否被占用，是返回1，否则返回0。 使用mutex时，要注意一下：mutex的使用技术永远是1；在同一上下文中上锁解锁；当进程持有一个mutex时，进程不可退出；mutex不能在中断或下半部中使用。 抢占禁止在前面章节讲进程管理的时候听到过内核抢占，由于内核可抢占，内核中的进程随时都可能被另外一个具有更高优先权的进程打断，这也就意味着一个任务与被抢占的任务可能会在同一个临界区运行。所以才有本节前面自旋锁来避免竞态的发生，自旋锁有禁止内核抢占的功能。但像每cpu变量的数据只能被一个处理器访问，可以不需要使用锁来保护，如果没有使用锁，内核又是抢占式的，那么新调度的任务就可能访问同一个变量。这个时候就可以通过禁止内核抢占来避免竞态的发生，禁止内核抢占使用preetmpt_disable()函数，这是一个可以嵌套调用的函数，可以使用任意次。每次调用都必须有一个相应的preempt_enable()调用，当最后一次preempt_enable()被调用时，内核抢占才重新启用。内核抢占相关函数如下：123456789101112preempt_enable() //内核抢占计数preempt_count减1preempt_disable() //内核抢占计数preempt_count加1，当该值降为0时检查和执行被挂起的需要调度的任务preempt_enable_no_resched()//内核抢占计数preempt_count减1，但不立即抢占式调度preempt_check_resched () //如果必要进行调度preempt_count() //返回抢占计数preempt_schedule() //内核抢占时的调度程序的入口点 以preempt_enable()为例，看一下其实现：123456789101112131415161718192021222324252627282930313233343536373839404142#define preempt_enable() \do &#123; \ preempt_enable_no_resched(); \ barrier(); \ // 加内存屏障，阻止gcc编译器对内存进行优化 preempt_check_resched(); \&#125; while (0)#define preempt_enable_no_resched() \do &#123; \ barrier(); \ dec_preempt_count(); \&#125; while (0)#define dec_preempt_count() sub_preempt_count(1)# define sub_preempt_count(val) do &#123; preempt_count() -= (val); &#125; while (0) //此处减少抢占计数 #define preempt_check_resched() \do &#123; \ if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \ preempt_schedule(); \&#125; while (0) asmlinkage void __sched preempt_schedule(void)&#123; struct thread_info *ti = current_thread_info(); /* * If there is a non-zero preempt_count or interrupts are disabled, * we do not want to preempt the current task. Just return.. */ if (likely(ti-&gt;preempt_count || irqs_disabled())) return; do &#123; add_preempt_count(PREEMPT_ACTIVE); schedule(); sub_preempt_count(PREEMPT_ACTIVE); /* * Check again in case we missed a preemption opportunity * between schedule and now. */ barrier(); &#125; while (need_resched());]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（九）：进程调度]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B9%9D%EF%BC%89%EF%BC%9A%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 linux为多任务系统，正常情况下都存在成百上千个任务。由于linux提供抢占式的多任务模式，所以linux能同时并发地交互执行多个进程，而调度程序将决定哪一个进程投入运行、何时运行、以及运行多长时间。调度程序是像linux这样的多任务操作系统的基础， 只有通过调度程序的合理调度，系统资源才能最大限度地发挥作用，多进程才会有并发执行的效果。当系统中可运行的进程数目比处理器的个数多，就注定在某一时刻有一些进程不能执行，这些不能执行的进程在等待执行。调度程序的基本工作就是停止一个进程的运行，再在这些等待执行的进程中选择一个来执行。 调度程序停止一个进程的运行，再选择一个另外进程的动作开始运行的动作被称作抢占（preemption）。一个进程在被抢占之前能够运行的时间是预先设置好的，这个预先设置好的时间就是进程的的时间片（timeslice）。时间片就是分配给每个可运行进程的处理器时间段，它表明进程在被抢占前所能持续运行时间。 处理器的调度策略决定调度程序在何时让什么进程投入运行。调度策略通常需要在进程响应迅速(相应时间短)和进程吞吐量高之间寻找平衡。所以调度程序通常采用一套非常复杂的算法来决定最值得运行的进程投入运行。调度算法中最基本的一类当然就是基于优先级的调度，也就是说优先级高的先运行，相同优先级的按轮转式进行调度。优先级高 的进程使用的时间片也长。调度程序总是选择时间片未用尽且优先级最高的进程运行。这句话就是说用户和系统可以通过设置进程的优先级来响应系统的调度。基于此，linux设计上一套动态优先级的调度方法。一开始，先为进程设置一个基本的优先级，然而它允许调度程序根据需要来加减优先级。linux内核提供了两组独立的优先级范围。第一种是nice值，范围从-20到19，默认为0。nice值越大优先级越小。另外nice值也用来决定分配给进程时间片的长短。linux下通过命令可以查看进程对应nice值，如下：12345678910111213141516171819$ ps -elF S UID PID PPID C PRI NI ADDR SZ WCHAN TTY TIME CMD 4 S 0 1 0 0 80 0 - 725 ? ? 00:00:01 init 1 S 0 2 0 0 80 0 - 0 ? ? 00:00:00 kthreadd 1 S 0 3 2 0 -40 - - 0 ? ? 00:00:01 migration/0 1 S 0 4 2 0 80 0 - 0 ? ? 00:00:00 ksoftirqd/0 1 S 0 9 2 0 80 0 - 0 ? ? 00:00:00 ksoftirqd/1......1 S 0 39 2 0 85 5 - 0 ? ? 00:00:00 ksmd ......1 S 0 156 2 0 75 -5 - 0 ? ? 00:00:00 kslowd000 1 S 0 157 2 0 75 -5 - 0 ? ? 00:00:00 kslowd001 ...... 4 S 499 2951 1 0 81 1 - 6276 ? ? 00:00:00 rtkit-daemon ...... 第二种范围是实时优先级，默认范围是从0到99。任何实时的优先级都高于普通优先级。 进程执行时，它会根据具体情况改变状态，进程状态是调度和对换的依据。Linux 将进程状态分为五种： TASK_RUNNING 、TASK_INTERRUPTIBLE 、TASK_UNINTERRUPTIBLE、TASK_STOPPED和TASK_ZOMBILE。进程的状态随着进程的调度发生改变 。 状态 TASK_RUNNING 可运行 TASK_INTERRUPTIBLE 可中断的等待状态 TASK_UNINTERRUPTIBLE 不可中断的等待状态 TASK_STOPPED 停止状态 TASK_TRACED 被跟踪状态 TASK_RUNNING （运行）：无论进程是否正在占用 CPU ，只要具备运行条件，都处于该状态。 Linux 把处于该状态的所有 PCB 组织成一个可运行队列 run_queue ，调度程序从这个队列中选择进程运行。事实上， Linux 是将就绪态和运行态合并为了一种状态。 TASK_INTERRUPTIBLE （可中断阻塞）： Linux 将阻塞态划分成 TASK_INTERRUPTIBLE 、 TASK_UNINTERRUPTIBLE 、 TASK_STOPPED 三种不同的状态。处于 TASK_INTERRUPTIBLE 状态的进程在资源有效时被唤醒，也可以通过信号或定时中断唤醒。 TASK_UNINTERRUPTIBLE （不可中断阻塞）：另一种阻塞状态，处于该状态的进程只有当资源有效时被唤醒，不能通过信号或定时中断唤醒。在执行ps命令时，进程状态为D且不能被杀死。 TASK_STOPPED （停止）：第三种阻塞状态，处于该状态的进程只能通过其他进程的信号才能唤醒。 TASK_TRACED （被跟踪）：进程正在被另一个进程监视，比如在调试的时候。 我们在设置这些状态的时候是可以直接用语句进行的比如：p—&gt;state = TASK_RUNNING。同时内核也会使用set_task_state()和set_current_state()函数来进行。 Linux调度器是以模块方式提供的，这样允许不同类型的进程可以有针对性地选择调度算法。完全公平调度（CFS）是针对普通进程的调度类，CFS采用的方法是对时间片分配方式进行根本性的重新设计，完全摒弃时间片而是分配给进程一个处理器使用比重。通过这种方式，CFS确保了进程调度中能有恒定的公平性，而将切换频率置于不断变动之中。 与Linux 2.6之前调度器不同，2.6版本内核的CFS没有将任务维护在链表式的运行队列中，它抛弃了active/expire数组，而是对每个CPU维护一个以时间为顺序的红黑树。该树方法能够良好运行的原因在于： 红黑树可以始终保持平衡，这意味着树上没有路径比任何其他路径长两倍以上。 由于红黑树是二叉树，查找操作的时间复杂度为O(log n)。但是除了最左侧查找以外，很难执行其他查找，并且最左侧的节点指针始终被缓存。 对于大多数操作（插入、删除、查找等），红黑树的执行时间为O(log n)，而以前的调度程序通过具有固定优先级的优先级数组使用 O(1)。O(log n) 行为具有可测量的延迟，但是对于较大的任务数无关紧要。Molnar在尝试这种树方法时，首先对这一点进行了测试。 红黑树可通过内部存储实现，即不需要使用外部分配即可对数据结构进行维护。 要实现平衡，CFS使用“虚拟运行时”表示某个任务的时间量。任务的虚拟运行时越小，意味着任务被允许访问服务器的时间越短，其对处理器的需求越高。 CFS还包含睡眠公平概念以便确保那些目前没有运行的任务（例如，等待 I/O）在其最终需要时获得相当份额的处理器。由于篇幅原因，这里不详细讲解CFS的实现。 对于实时进程， Linux 采用了两种调度策略，即先来先服务调度（ First-In, First-Out ， FIFO ）和时间片轮转调度（ Round Robin ， RR ）。因为实时进程具有一定程度的紧迫性，所以衡量一个实时进程是否应该运行， Linux 采用了一个比较固定的标准。 下面是调度相关的一些数据结构：调度实体：struct sched_entity12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364struct sched_entity &#123; struct load_weight load; /* for load-balancing */ struct rb_node run_node; struct list_head group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 last_wakeup; u64 avg_overlap; u64 nr_migrations; u64 start_runtime; u64 avg_wakeup; u64 avg_running; #ifdef CONFIG_SCHEDSTATS u64 wait_start; u64 wait_max; u64 wait_count; u64 wait_sum; u64 iowait_count; u64 iowait_sum; u64 sleep_start; u64 sleep_max; s64 sum_sleep_runtime; u64 block_start; u64 block_max; u64 exec_max; u64 slice_max; u64 nr_migrations_cold; u64 nr_failed_migrations_affine; u64 nr_failed_migrations_running; u64 nr_failed_migrations_hot; u64 nr_forced_migrations; u64 nr_forced2_migrations; u64 nr_wakeups; u64 nr_wakeups_sync; u64 nr_wakeups_migrate; u64 nr_wakeups_local; u64 nr_wakeups_remote; u64 nr_wakeups_affine; u64 nr_wakeups_affine_attempts; u64 nr_wakeups_passive; u64 nr_wakeups_idle;#endif #ifdef CONFIG_FAIR_GROUP_SCHED struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq &quot;owned&quot; by this entity/group: */ struct cfs_rq *my_q;#endif&#125;; 该结构在./linux/include/linux/sched.h中，表示一个可调度实体（进程，进程组，等等）。它包含了完整的调度信息，用于实现对单个任务或任务组的调度。调度实体可能与进程没有关联。这里包括负载权重load、对应的红黑树结点run_node、虚拟运行时vruntime（表示进程的运行时间，并作为红黑树的索引）、开始执行时间、最后唤醒时间、各种统计数据、用于组调度的CFS运行队列信息cfs_rq，等等。 调度类：struct sched_class该调度类也在sched.h中，是对调度器操作的面向对象抽象，协助内核调度程序的各种工作。调度类是调度器管理器的核心，每种调度算法模块需要实现struct sched_class建议的一组函数。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051struct sched_class &#123; const struct sched_class *next; void (*enqueue_task) (struct rq *rq, struct task_struct *p, int wakeup); void (*dequeue_task) (struct rq *rq, struct task_struct *p, int sleep); void (*yield_task) (struct rq *rq); void (*check_preempt_curr) (struct rq *rq, struct task_struct *p, int flags); struct task_struct * (*pick_next_task) (struct rq *rq); void (*put_prev_task) (struct rq *rq, struct task_struct *p); #ifdef CONFIG_SMP int (*select_task_rq)(struct task_struct *p, int sd_flag, int flags); unsigned long (*load_balance) (struct rq *this_rq, int this_cpu, struct rq *busiest, unsigned long max_load_move, struct sched_domain *sd, enum cpu_idle_type idle, int *all_pinned, int *this_best_prio); int (*move_one_task) (struct rq *this_rq, int this_cpu, struct rq *busiest, struct sched_domain *sd, enum cpu_idle_type idle); void (*pre_schedule) (struct rq *this_rq, struct task_struct *task); void (*post_schedule) (struct rq *this_rq); void (*task_wake_up) (struct rq *this_rq, struct task_struct *task); void (*set_cpus_allowed)(struct task_struct *p, const struct cpumask *newmask); void (*rq_online)(struct rq *rq); void (*rq_offline)(struct rq *rq);#endif void (*set_curr_task) (struct rq *rq); void (*task_tick) (struct rq *rq, struct task_struct *p, int queued); void (*task_new) (struct rq *rq, struct task_struct *p); void (*switched_from) (struct rq *this_rq, struct task_struct *task, int running); void (*switched_to) (struct rq *this_rq, struct task_struct *task, int running); void (*prio_changed) (struct rq *this_rq, struct task_struct *task, int oldprio, int running); unsigned int (*get_rr_interval) (struct task_struct *task); #ifdef CONFIG_FAIR_GROUP_SCHED void (*moved_group) (struct task_struct *p);#endif&#125;; 其中的主要函数： enqueue_task：当某个任务进入可运行状态时，该函数将得到调用。它将调度实体（进程）放入红黑树中，并对 nr_running 变量加 1。从前面“Linux进程管理”的分析中可知，进程创建的最后会调用该函数。 dequeue_task：当某个任务退出可运行状态时调用该函数，它将从红黑树中去掉对应的调度实体，并从 nr_running 变量中减 1。 yield_task：在 compat_yield sysctl 关闭的情况下，该函数实际上执行先出队后入队；在这种情况下，它将调度实体放在红黑树的最右端。 check_preempt_curr：该函数将检查当前运行的任务是否被抢占。在实际抢占正在运行的任务之前，CFS 调度程序模块将执行公平性测试。这将驱动唤醒式（wakeup）抢占。 pick_next_task：该函数选择接下来要运行的最合适的进程。 load_balance：每个调度程序模块实现两个函数，load_balance_start() 和 load_balance_next()，使用这两个函数实现一个迭代器，在模块的load_balance例程中调用。内核调度程序使用这种方法实现由调度模块管理的进程的负载平衡。 set_curr_task：当任务修改其调度类或修改其任务组时，将调用这个函数。 task_tick：该函数通常调用自 time tick 函数；它可能引起进程切换。这将驱动运行时（running）抢占。 调度类的引入是接口和实现分离的设计典范，你可以实现不同的调度算法（例如普通进程和实时进程的调度算法就不一样），但由于有统一的接口，使得调度策略 被模块化，一个Linux调度程序可以有多个不同的调度策略。调度类显著增强了内核调度程序的可扩展性。每个任务都属于一个调度类，这决定了任务将如何调 度。 调度类定义一个通用函数集，函数集定义调度器的行为。例如，每个调度器提供一种方式，添加要调度的任务、调出要运行的下一个任务、提供给调度器等等。每个 调度器类都在一对一连接的列表中彼此相连，使类可以迭代（例如， 要启用给定处理器的禁用）。注意，将任务函数加入队列或脱离队列只需从特定调度结构中加入或移除任务。 核心函数 pick_next_task 选择要执行的下一个任务（取决于调度类的具体策略）。 sched_rt.c, sched_fair.c, sched_idletask.c等（都在kernel/目录下）就是不同的调度算法实现。不要忘了调度类是任务结构本身的一部分（参见 task_struct）。这一点简化了任务的操作，无论其调度类如何。因为进程描述符中有sched_class引用，这样就可以直接通过进程描述符来 调用调度类中的各种操作。在调度类中，随着调度域的增加，其功能也在增加。 这些域允许您出于负载平衡和隔离的目的将一个或多个处理器按层次关系分组。 一个或多个处理器能够共享调度策略（并在其之间保持负载平衡），或实现独立的调度策略。 可运行队列：struct rq调度程序每次在进程发生切换时，都要从可运行队列中选取一个最佳的进程来运行。Linux内核使用rq数据结构（以前的内核中该结构为 runqueue）表示一个可运行队列信息（也就是就绪队列），每个CPU都有且只有一个这样的结构。该结构在kernel/sched.c中，不仅描述 了每个处理器中处于可运行状态（TASK_RUNNING），而且还描述了该处理器的调度信息。如下：12345678910111213141516171819202122232425262728293031323334struct rq &#123; /* runqueue lock: */ spinlock_t lock; unsigned long nr_running; #define CPU_LOAD_IDX_MAX 5 unsigned long cpu_load[CPU_LOAD_IDX_MAX]; /* capture load from *all* tasks on this cpu: */ struct load_weight load; unsigned long nr_load_updates; u64 nr_switches; u64 nr_migrations_in; struct cfs_rq cfs; struct rt_rq rt; unsigned long nr_uninterruptible; struct task_struct *curr, *idle; unsigned long next_balance; struct mm_struct *prev_mm; u64 clock; atomic_t nr_iowait; /* calc_load related fields */ unsigned long calc_load_update; long calc_load_active; ......&#125;; 进程调度的入口点是函数schedule()，该函数调用pick_next_task()，pick_next_task()会以优先级为序，从高到低，一次检查每一个调度类，且从最高优先级的调度类中，选择最高优先级的进程。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899asmlinkage void __sched schedule(void)&#123; struct task_struct *prev, *next; unsigned long *switch_count; struct rq *rq; int cpu; need_resched: preempt_disable(); cpu = smp_processor_id(); rq = cpu_rq(cpu); rcu_sched_qs(cpu); prev = rq-&gt;curr; switch_count = &amp;prev-&gt;nivcsw; release_kernel_lock(prev);need_resched_nonpreemptible: schedule_debug(prev); if (sched_feat(HRTICK)) hrtick_clear(rq); spin_lock_irq(&amp;rq-&gt;lock); update_rq_clock(rq); clear_tsk_need_resched(prev); if (prev-&gt;state &amp;&amp; !(preempt_count() &amp; PREEMPT_ACTIVE)) &#123; if (unlikely(signal_pending_state(prev-&gt;state, prev))) prev-&gt;state = TASK_RUNNING; else deactivate_task(rq, prev, 1); switch_count = &amp;prev-&gt;nvcsw; &#125; pre_schedule(rq, prev); if (unlikely(!rq-&gt;nr_running)) idle_balance(cpu, rq); put_prev_task(rq, prev); &lt;strong&gt;next = pick_next_task(rq); //&lt;span&gt;&lt;span&gt;&lt;span style=&quot;font-size:14px;&quot;&gt;//挑选最高优先级别的任务&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt; if (likely(prev != next)) &#123; sched_info_switch(prev, next); perf_event_task_sched_out(prev, next, cpu); rq-&gt;nr_switches++; rq-&gt;curr = next; ++*switch_count; context_switch(rq, prev, next); /* unlocks the rq */ /* * the context switch might have flipped the stack from under * us, hence refresh the local variables. */ cpu = smp_processor_id(); rq = cpu_rq(cpu); &#125; else spin_unlock_irq(&amp;rq-&gt;lock); post_schedule(rq); if (unlikely(reacquire_kernel_lock(current) &lt; 0)) goto need_resched_nonpreemptible; preempt_enable_no_resched(); if (need_resched()) goto need_resched;&#125;static inline struct task_struct *pick_next_task(struct rq *rq)&#123; const struct sched_class *class; struct task_struct *p; /* * Optimization: we know that if all tasks are in * the fair class we can call that function directly: */ if (likely(rq-&gt;nr_running == rq-&gt;cfs.nr_running)) &#123; p = fair_sched_class.pick_next_task(rq); if (likely(p)) return p; &#125;//从最高优先级类开始，遍历每一个调度类。每一个调度类都实现了pick_next_task，他会返回指向下一个可运行进程的指针，没有时返回NULL。 class = sched_class_highest; for ( ; ; ) &#123; p = class-&gt;pick_next_task(rq); if (p) return p; /* * Will never be NULL as the idle class always * returns a non-NULL p: */ class = class-&gt;next; &#125;&#125; 被阻塞（休眠）的进程处于不可执行状态，是不能被调度的。进程休眠一般是由于等待一些事件，内核首先把自己标记成休眠状态，从可执行红黑树中移出，放入等待队列，然后调用schedule()选择和执行一个其他进程。唤醒的过程刚好相反，进程设置为可执行状态，然后从等待队列中移到可执行红黑树中。 等待队列是由等待某些事件发生的进程组成的简单链表。内核用wake_queue_head_t来代表队列。进程把自己放入等待队列中并设置成不可执状态。当等待队列相关事件发生时，队列上进程会被唤醒。函数inotify_read()是实现等待队列的一个典型用法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static ssize_t inotify_read(struct file *file, char __user *buf, size_t count, loff_t *pos)&#123; struct fsnotify_group *group; struct fsnotify_event *kevent; char __user *start; int ret; DEFINE_WAIT(wait); start = buf; group = file-&gt;private_data; while (1) &#123; //进程的状态变更为TASK_INTERRUPTIBLE或TASK_UNINTERRUPTIBLE。 prepare_to_wait(&amp;group-&gt;notification_waitq, &amp;wait, TASK_INTERRUPTIBLE); mutex_lock(&amp;group-&gt;notification_mutex); kevent = get_one_event(group, count); mutex_unlock(&amp;group-&gt;notification_mutex); if (kevent) &#123; ret = PTR_ERR(kevent); if (IS_ERR(kevent)) break; ret = copy_event_to_user(group, kevent, buf); fsnotify_put_event(kevent); if (ret &lt; 0) break; buf += ret; count -= ret; continue; &#125; ret = -EAGAIN; if (file-&gt;f_flags &amp; O_NONBLOCK) break; ret = -EINTR; if (signal_pending(current)) break; if (start != buf) break; schedule(); &#125; finish_wait(&amp;group-&gt;notification_waitq, &amp;wait); if (start != buf &amp;&amp; ret != -EFAULT) ret = buf - start; return ret;&#125; 唤醒是通过wake_up()进行。她唤醒指定的等待队列上 的所有进程。它调用try_to_wake_up,该函数负责将进程设置为TASK_RUNNING状态，调用active_task()将此进程放入可 执行队列，如果被唤醒进程的优先级比当前正在执行的进程的优先级高，还要设置need_resched标志。 上下文切换，就是从一个可执行进程切换到另一个可执行进程，由定义在kernel/sched.c的context_switch函数负责处理。每当一个新的进程被选出来准备投入运行的时候，schedule就会调用该函数。它主要完成如下两个工作： 调用定义在include/asm/mmu_context.h中的switch_mm()。该函数负责把虚拟内存从上一个进程映射切换到新进程中。 调用定义在include/asm/system.h的switch_to()，该函数负责从上一个进程的处理器状态切换到新进程的处理器状态，这包括保存，恢复栈信息和寄存器信息。 内核也必须知道什么时候调用schedule(),单靠用户 代码显示调用schedule(),他们可能就会永远地执行下去，相反，内核提供了一个need_resched标志来表明是否需要重新执行一次调度。当 某个进程耗尽它的时间片时，scheduler_tick()就会设置这个标志，当一个优先级高的进程进入可执行状态的时 候，try_to_wake_up()也会设置这个标志。内核检查该标志，确认其被设置，调用schedule()来切换到一个新的进程。该标志对内核来讲是一个信息，它表示应当有其他进程应当被运行了。 用于访问和操作need_resched的函数： set_tsk_need_resched(task) 设置指定进程中的need_resched标志clear_tsk_need_resched(task) 清除指定进程中的nedd_resched标志need_resched() 检查need_resched标志的值，如果被设置就返回真，否则返回 再返回用户空间以及从中断返回的时候，内核也会检查 need_resched标志，如果已被设置，内核会在继续执行之前调用该调度程序。最后，每个进程都包含一个need_resched标志，这是因为访 问进程描述符内的数值要比访问一个全局变量要快(因为current宏速度很快并且描述符通常都在高速缓存中)。在2.6内核中，他被移到了 thread_info结构体里。 用户抢占发生在一下情况： 从系统调用返回时； 从终端处理程序返回用户空间时。 内核抢占发生在: 中断处理正在执行，且返回内核空间前； 内核代码再一次具有可抢占性的时候； 内核任务显示调用schedule()函数； 内核中的任务阻塞的时候。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（八）：进程管理分析]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 进程其实就是程序的执行时的实例，是处于执行期的程序。在linux内核中，进程列表被存放在一个双向循环链表中，链表中每一项都是类型为task_struct的结构，该结构称作进程描述符，进程描述符包含一个具体进程的所有信息，这个结构就是我们在操作系统中所说的PCB（Process Control Block）。该结构定义于&lt;include/linux/sched.h&gt;文件中：12345678910111213141516171819202122 struct task_struct &#123; volatile long state; /* -1 unrunnable, 0 runnable, &gt;0 stopped */ void *stack; atomic_t usage; unsigned int flags; /* per process flags, defined below */ unsigned int ptrace; int lock_depth; /* BKL lock depth */ ...... int prio, static_prio, normal_prio; unsigned int rt_priority; const struct sched_class *sched_class; struct sched_entity se; struct sched_rt_entity rt; ...... struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */ struct list_head children; /* list of my children */ struct list_head sibling; /* linkage in my parent&apos;s children list */ ......&#125;; 该结构体中包含的数据可以完整的描述一个正在执行的程序：打开的文件、进程的地址空间、挂起的信号、进程的状态、以及其他很多信息。\ 在系统运行过程中，进程频繁切换，所以我们需要一种方式能够快速获得当前进程的task_struct，于是进程内核堆栈底部存放着struct thread_info。该结构中有一个成员指向当前进程的task_struct。在x86上，struct thread_info在文件&lt;arch/x86/include/asm/thread_info.h&gt;中定义：12345678910111213141516171819 struct thread_info &#123; struct task_struct *task; /* 该指针存放的是指向该任务实际task_struct的指针 */ struct exec_domain *exec_domain; /* execution domain */ __u32 flags; /* low level flags */ __u32 status; /* thread synchronous flags */ __u32 cpu; /* current CPU */ int preempt_count; /* 0 =&gt; preemptable, &lt;0 =&gt; BUG */ mm_segment_t addr_limit; struct restart_block restart_block; void __user *sysenter_return;#ifdef CONFIG_X86_32 unsigned long previous_esp; /* ESP of the previous stack in case of nested (IRQ) stacks */ __u8 supervisor_stack[0];#endif int uaccess_err;&#125;; 使用current宏就可以获得当前进程的进程描述符。 每一个进程都有一个父进程，每个进程管理自己的子进程。每个进程都是init进程的子进程，init进程在内 核系统启动的最后阶段启动init进程，该进程读取系统的初始化脚本并执行其他相关程序，最终完成系统启动的整个过程。每个进程有0个或多个子进程，进程间的关系存放在进程描述符中。task_struct中有一个parent的指针，指向其父进程；还有个children的指针指向其子进程的链表。所以，对于当前进程，可以通过current宏来获得父进程和子进程的进程描述符。下面程序打印当前进程、父进程信息和所有子进程信息：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include &lt;linux/module.h&gt; #include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt; #include &lt;linux/sched.h&gt; void sln_taskstruct_do(void)&#123; struct task_struct *cur, *parent, *task; struct list_head *first_child, *child_list, *cur_chd; //获取当前进程信息 cur = current; printk(KERN_ALERT&quot;Current: %s[%d]\n&quot;, cur-&gt;comm, cur-&gt;pid); //获取父进程信息 parent = current-&gt;parent; printk(KERN_ALERT&quot;Parent: %s[%d]\n&quot;, parent-&gt;comm, parent-&gt;pid); //获取所有祖先进程信息 for (task = cur; task != &amp;init_task; task = task-&gt;parent) &#123; printk(KERN_ALERT&quot;ancestor: %s[%d]\n&quot;, task-&gt;comm, task-&gt;pid); &#125; //获取所有子进程信息 child_list = &amp;cur-&gt;children; first_child = &amp;cur-&gt;children; for (cur_chd = child_list-&gt;next; cur_chd != first_child; cur_chd = cur_chd-&gt;next) &#123; task = list_entry(child_list, struct task_struct, sibling); printk(KERN_ALERT&quot;Children: %s[%d]\n&quot;, task-&gt;comm, task-&gt;pid); &#125; &#125; static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_taskstruct_do(); return 0;&#125; static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__);&#125; module_init(sln_init);module_exit(sln_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 执行结果如下：12345678 # insmod task.ko===sln_init===Current: insmod[4315]Parent: bash[4032]ancestor: insmod[4315]ancestor: bash[4032]ancestor: login[2563]ancestor: init[1] linux操作系统提供产生进程的机制，在Linux下的fork()使用写时拷贝(copy-on-write)页实现。这种技术原理是：内存并不复制整个进程地址空间，而是让父进程和子进程共享同一拷贝，只有在需要写入的时候，数据才会被复制。也就是资源的复制只是发生在需要写入的时候才进行，在此之前都是以只读的方式共享。 linux通过clone()系统调用实现fork()，然后clone()去调用do_fork()，do_fork()完成创建中大部分工作。库函数vfork()、__clone()都根据各自需要的参数标志去调用clone()。fork()的实际开销就是复制父进程的页表以及给子进程创建唯一的进程描述符。用户空间的fork()经过系统调用进入内核，在内核中对应的处理函数为sys_fork()，定义于&lt;arch/x86/kernel/process.c&gt;文件中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354int sys_fork(struct pt_regs *regs) &#123; return do_fork(SIGCHLD, regs-&gt;sp, regs, 0, NULL, NULL);&#125; long do_fork(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr)&#123; struct task_struct *p; int trace = 0; long nr; ...... p = copy_process(clone_flags, stack_start, regs, stack_size, child_tidptr, NULL, trace); ...... return nr;&#125; static struct task_struct *copy_process(unsigned long clone_flags, unsigned long stack_start, struct pt_regs *regs, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace)&#123; int retval; struct task_struct *p; int cgroup_callbacks_done = 0; if ((clone_flags &amp; (CLONE_NEWNS|CLONE_FS)) == (CLONE_NEWNS|CLONE_FS)) return ERR_PTR(-EINVAL); /* * Thread groups must share signals as well, and detached threads * can only be started up within the thread group. */ if ((clone_flags &amp; CLONE_THREAD) &amp;&amp; !(clone_flags &amp; CLONE_SIGHAND)) return ERR_PTR(-EINVAL); /* * Shared signal handlers imply shared VM. By way of the above, * thread groups also imply shared VM. Blocking this case allows * for various simplifications in other code. */ if ((clone_flags &amp; CLONE_SIGHAND) &amp;&amp; !(clone_flags &amp; CLONE_VM)) return ERR_PTR(-EINVAL); /* * Siblings of global init remain as zombies on exit since they are * not reaped by their parent (swapper). To solve this and to avoid * multi-rooted process trees, prevent global and container-inits * from creating siblings. */ if ((clone_flags &amp; CLONE_PARENT) &amp;&amp; current-&gt;signal-&gt;flags &amp; SIGNAL_UNKILLABLE) return ERR_PTR(-EINVAL); retval = security_task_create(clone_flags); if (retval) goto fork_out; retval = -ENOMEM; p = dup_task_struct(current); if (!p) goto fork_out; ftrace_graph_init_task(p); rt_mutex_init_task(p);#ifdef CONFIG_PROVE_LOCKING DEBUG_LOCKS_WARN_ON(!p-&gt;hardirqs_enabled); DEBUG_LOCKS_WARN_ON(!p-&gt;softirqs_enabled);#endif retval = -EAGAIN; if (atomic_read(&amp;p-&gt;real_cred-&gt;user-&gt;processes) &gt;= p-&gt;signal-&gt;rlim[RLIMIT_NPROC].rlim_cur) &#123; if (!capable(CAP_SYS_ADMIN) &amp;&amp; !capable(CAP_SYS_RESOURCE) &amp;&amp; p-&gt;real_cred-&gt;user != INIT_USER) goto bad_fork_free; &#125; retval = copy_creds(p, clone_flags); if (retval &lt; 0) goto bad_fork_free; /* * If multiple threads are within copy_process(), then this check * triggers too late. This doesn&apos;t hurt, the check is only there * to stop root fork bombs. */ retval = -EAGAIN; if (nr_threads &gt;= max_threads) goto bad_fork_cleanup_count; if (!try_module_get(task_thread_info(p)-&gt;exec_domain-&gt;module)) goto bad_fork_cleanup_count; p-&gt;did_exec = 0; delayacct_tsk_init(p); /* Must remain after dup_task_struct() */ copy_flags(clone_flags, p); INIT_LIST_HEAD(&amp;p-&gt;children); INIT_LIST_HEAD(&amp;p-&gt;sibling); rcu_copy_process(p); p-&gt;vfork_done = NULL; spin_lock_init(&amp;p-&gt;alloc_lock); init_sigpending(&amp;p-&gt;pending); p-&gt;utime = cputime_zero; p-&gt;stime = cputime_zero; p-&gt;gtime = cputime_zero; p-&gt;utimescaled = cputime_zero; p-&gt;stimescaled = cputime_zero; p-&gt;prev_utime = cputime_zero; p-&gt;prev_stime = cputime_zero; p-&gt;default_timer_slack_ns = current-&gt;timer_slack_ns; task_io_accounting_init(&amp;p-&gt;ioac); acct_clear_integrals(p); posix_cpu_timers_init(p); p-&gt;lock_depth = -1; /* -1 = no lock */ do_posix_clock_monotonic_gettime(&amp;p-&gt;start_time); p-&gt;real_start_time = p-&gt;start_time; monotonic_to_bootbased(&amp;p-&gt;real_start_time); p-&gt;io_context = NULL; p-&gt;audit_context = NULL; cgroup_fork(p);#ifdef CONFIG_NUMA p-&gt;mempolicy = mpol_dup(p-&gt;mempolicy); if (IS_ERR(p-&gt;mempolicy)) &#123; retval = PTR_ERR(p-&gt;mempolicy); p-&gt;mempolicy = NULL; goto bad_fork_cleanup_cgroup; &#125; mpol_fix_fork_child_flag(p);#endif#ifdef CONFIG_TRACE_IRQFLAGS p-&gt;irq_events = 0;#ifdef __ARCH_WANT_INTERRUPTS_ON_CTXSW p-&gt;hardirqs_enabled = 1;#else p-&gt;hardirqs_enabled = 0;#endif p-&gt;hardirq_enable_ip = 0; p-&gt;hardirq_enable_event = 0; p-&gt;hardirq_disable_ip = _THIS_IP_; p-&gt;hardirq_disable_event = 0; p-&gt;softirqs_enabled = 1; p-&gt;softirq_enable_ip = _THIS_IP_; p-&gt;softirq_enable_event = 0; p-&gt;softirq_disable_ip = 0; p-&gt;softirq_disable_event = 0; p-&gt;hardirq_context = 0; p-&gt;softirq_context = 0;#endif#ifdef CONFIG_LOCKDEP p-&gt;lockdep_depth = 0; /* no locks held yet */ p-&gt;curr_chain_key = 0; p-&gt;lockdep_recursion = 0;#endif#ifdef CONFIG_DEBUG_MUTEXES p-&gt;blocked_on = NULL; /* not blocked yet */#endif p-&gt;bts = NULL; p-&gt;stack_start = stack_start; /* Perform scheduler related setup. Assign this task to a CPU. */ sched_fork(p, clone_flags); retval = perf_event_init_task(p); if (retval) goto bad_fork_cleanup_policy; if ((retval = audit_alloc(p))) goto bad_fork_cleanup_policy; /* copy all the process information */ if ((retval = copy_semundo(clone_flags, p))) goto bad_fork_cleanup_audit; if ((retval = copy_files(clone_flags, p))) goto bad_fork_cleanup_semundo; if ((retval = copy_fs(clone_flags, p))) goto bad_fork_cleanup_files; if ((retval = copy_sighand(clone_flags, p))) goto bad_fork_cleanup_fs; if ((retval = copy_signal(clone_flags, p))) goto bad_fork_cleanup_sighand; if ((retval = copy_mm(clone_flags, p))) goto bad_fork_cleanup_signal; if ((retval = copy_namespaces(clone_flags, p))) goto bad_fork_cleanup_mm; if ((retval = copy_io(clone_flags, p))) goto bad_fork_cleanup_namespaces; retval = copy_thread(clone_flags, stack_start, stack_size, p, regs); if (retval) goto bad_fork_cleanup_io; if (pid != &amp;init_struct_pid) &#123; retval = -ENOMEM; pid = alloc_pid(p-&gt;nsproxy-&gt;pid_ns); if (!pid) goto bad_fork_cleanup_io; if (clone_flags &amp; CLONE_NEWPID) &#123; retval = pid_ns_prepare_proc(p-&gt;nsproxy-&gt;pid_ns); if (retval &lt; 0) goto bad_fork_free_pid; &#125; &#125; p-&gt;pid = pid_nr(pid); p-&gt;tgid = p-&gt;pid; if (clone_flags &amp; CLONE_THREAD) p-&gt;tgid = current-&gt;tgid; if (current-&gt;nsproxy != p-&gt;nsproxy) &#123; retval = ns_cgroup_clone(p, pid); if (retval) goto bad_fork_free_pid; &#125; p-&gt;set_child_tid = (clone_flags &amp; CLONE_CHILD_SETTID) ? child_tidptr : NULL; /* * Clear TID on mm_release()? */ p-&gt;clear_child_tid = (clone_flags &amp; CLONE_CHILD_CLEARTID) ? child_tidptr: NULL;#ifdef CONFIG_FUTEX p-&gt;robust_list = NULL;#ifdef CONFIG_COMPAT p-&gt;compat_robust_list = NULL;#endif INIT_LIST_HEAD(&amp;p-&gt;pi_state_list); p-&gt;pi_state_cache = NULL;#endif /* * sigaltstack should be cleared when sharing the same VM */ if ((clone_flags &amp; (CLONE_VM|CLONE_VFORK)) == CLONE_VM) p-&gt;sas_ss_sp = p-&gt;sas_ss_size = 0; /* * Syscall tracing should be turned off in the child regardless * of CLONE_PTRACE. */ clear_tsk_thread_flag(p, TIF_SYSCALL_TRACE);#ifdef TIF_SYSCALL_EMU clear_tsk_thread_flag(p, TIF_SYSCALL_EMU);#endif clear_all_latency_tracing(p); /* ok, now we should be set up.. */ p-&gt;exit_signal = (clone_flags &amp; CLONE_THREAD) ? -1 : (clone_flags &amp; CSIGNAL); p-&gt;pdeath_signal = 0; p-&gt;exit_state = 0; /* * Ok, make it visible to the rest of the system. * We dont wake it up yet. */ p-&gt;group_leader = p; INIT_LIST_HEAD(&amp;p-&gt;thread_group); /* Now that the task is set up, run cgroup callbacks if * necessary. We need to run them before the task is visible * on the tasklist. */ cgroup_fork_callbacks(p); cgroup_callbacks_done = 1; /* Need tasklist lock for parent etc handling! */ write_lock_irq(&amp;tasklist_lock); /* * The task hasn&apos;t been attached yet, so its cpus_allowed mask will * not be changed, nor will its assigned CPU. * * The cpus_allowed mask of the parent may have changed after it was * copied first time - so re-copy it here, then check the child&apos;s CPU * to ensure it is on a valid CPU (and if not, just force it back to * parent&apos;s CPU). This avoids alot of nasty races. */ p-&gt;cpus_allowed = current-&gt;cpus_allowed; p-&gt;rt.nr_cpus_allowed = current-&gt;rt.nr_cpus_allowed; if (unlikely(!cpu_isset(task_cpu(p), p-&gt;cpus_allowed) || !cpu_online(task_cpu(p)))) set_task_cpu(p, smp_processor_id()); /* CLONE_PARENT re-uses the old parent */ if (clone_flags &amp; (CLONE_PARENT|CLONE_THREAD)) &#123; p-&gt;real_parent = current-&gt;real_parent; p-&gt;parent_exec_id = current-&gt;parent_exec_id; &#125; else &#123; p-&gt;real_parent = current; p-&gt;parent_exec_id = current-&gt;self_exec_id; &#125; spin_lock(¤t-&gt;sighand-&gt;siglock); /* * Process group and session signals need to be delivered to just the * parent before the fork or both the parent and the child after the * fork. Restart if a signal comes in before we add the new process to * it&apos;s process group. * A fatal signal pending means that current will exit, so the new * thread can&apos;t slip out of an OOM kill (or normal SIGKILL). */ recalc_sigpending(); if (signal_pending(current)) &#123; spin_unlock(¤t-&gt;sighand-&gt;siglock); write_unlock_irq(&amp;tasklist_lock); retval = -ERESTARTNOINTR; goto bad_fork_free_pid; &#125; if (clone_flags &amp; CLONE_THREAD) &#123; atomic_inc(¤t-&gt;signal-&gt;count); atomic_inc(¤t-&gt;signal-&gt;live); p-&gt;group_leader = current-&gt;group_leader; list_add_tail_rcu(&amp;p-&gt;thread_group, &amp;p-&gt;group_leader-&gt;thread_group); &#125; if (likely(p-&gt;pid)) &#123; list_add_tail(&amp;p-&gt;sibling, &amp;p-&gt;real_parent-&gt;children); tracehook_finish_clone(p, clone_flags, trace); if (thread_group_leader(p)) &#123; if (clone_flags &amp; CLONE_NEWPID) p-&gt;nsproxy-&gt;pid_ns-&gt;child_reaper = p; p-&gt;signal-&gt;leader_pid = pid; tty_kref_put(p-&gt;signal-&gt;tty); p-&gt;signal-&gt;tty = tty_kref_get(current-&gt;signal-&gt;tty); attach_pid(p, PIDTYPE_PGID, task_pgrp(current)); attach_pid(p, PIDTYPE_SID, task_session(current)); list_add_tail_rcu(&amp;p-&gt;tasks, &amp;init_task.tasks); __get_cpu_var(process_counts)++; &#125; attach_pid(p, PIDTYPE_PID, pid); nr_threads++; &#125; total_forks++; spin_unlock(¤t-&gt;sighand-&gt;siglock); write_unlock_irq(&amp;tasklist_lock); proc_fork_connector(p); cgroup_post_fork(p); perf_event_fork(p); return p;bad_fork_free_pid: if (pid != &amp;init_struct_pid) free_pid(pid);bad_fork_cleanup_io: put_io_context(p-&gt;io_context);bad_fork_cleanup_namespaces: exit_task_namespaces(p);bad_fork_cleanup_mm: if (p-&gt;mm) mmput(p-&gt;mm);bad_fork_cleanup_signal: if (!(clone_flags &amp; CLONE_THREAD)) __cleanup_signal(p-&gt;signal);bad_fork_cleanup_sighand: __cleanup_sighand(p-&gt;sighand);bad_fork_cleanup_fs: exit_fs(p); /* blocking */bad_fork_cleanup_files: exit_files(p); /* blocking */bad_fork_cleanup_semundo: exit_sem(p);bad_fork_cleanup_audit: audit_free(p);bad_fork_cleanup_policy: perf_event_free_task(p);#ifdef CONFIG_NUMA mpol_put(p-&gt;mempolicy);bad_fork_cleanup_cgroup:#endif cgroup_exit(p, cgroup_callbacks_done); delayacct_tsk_free(p); module_put(task_thread_info(p)-&gt;exec_domain-&gt;module);bad_fork_cleanup_count: atomic_dec(&amp;p-&gt;cred-&gt;user-&gt;processes); exit_creds(p);bad_fork_free: free_task(p);fork_out: return ERR_PTR(retval);&#125; 上面执行完以后，回到do_fork()函数，如果copy_process()函数成功返回。新创建的子进程被唤醒并让其投入运行。内核有意选择子进程先运行。因为一般子进程都会马上调用exec()函数，这样可以避免写时拷贝的额外开销。如果父进程首先执行的话，有可能会开始向地址空间写入。 线程机制提供了在同一程序内共享内存地址空间运行的一组线程。线程机制支持并发程序设计技术，可以共享打开的文件和其他资源。如果你的系统是多核心的，那多线程技术可保证系统的真正并行。在linux中，并没有线程这个概念，linux中所有的线程都当作进程来处理，换句话说就是在内核中并没有什么特殊的结构和算法来表示线程。在linux中，线程仅仅是一个使用共享资源的进程。每个线程都拥有一个隶属于自己的task_struct。所以说线程本质上还是进程，只不过该进程可以和其他一些进程共享某些资源信息。 内核有时需要在后台执行一些操作，这种任务可以通过内核线程完成，内核线程独立运行在内核空间的标准进程。内核线程和普通的进程间的区别在于内核线程没有独立的地址空间。它们只在讷河空间运行，从来不切换到用户空间去。内核进程和普通进程一样，可以被调度，也可以被抢占。内核线程也只能由其它内核线程创建，内核是通过从kthreadd内核进程中衍生出所有新的内核线程来自动处理这一点的。在内核中创建一个的内核线程方法如下：123struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...) 该函数实现如下：12345678910111213141516171819202122232425262728struct task_struct *kthread_create(int (*threadfn)(void *data), void *data, const char namefmt[], ...)&#123; struct kthread_create_info create; create.threadfn = threadfn; create.data = data; init_completion(&amp;create.done); spin_lock(&amp;kthread_create_lock); list_add_tail(&amp;create.list, &amp;kthread_create_list); spin_unlock(&amp;kthread_create_lock); wake_up_process(kthreadd_task); wait_for_completion(&amp;create.done); if (!IS_ERR(create.result)) &#123; struct sched_param param = &#123; .sched_priority = 0 &#125;; va_list args; va_start(args, namefmt); vsnprintf(create.result-&gt;comm, sizeof(create.result-&gt;comm), namefmt, args); va_end(args); /* * root may have changed our (kthreadd&apos;s) priority or CPU mask. * The kernel thread should not inherit these properties. */ sched_setscheduler_nocheck(create.result, SCHED_NORMAL, ¶m); set_cpus_allowed_ptr(create.result, cpu_all_mask); &#125; 新的任务是由kthread内核进程通过clone()系统调用而创建的。新的进程将运行threadfn函数，给其传递参数data，新的进程名称为namefmt，新创建的进程处于不可运行状态，需要调用wake_up_process()明确的唤醒它，否则它不会主动运行。也可以通过调用kthread_run()来创建一个进程并让它运行起来。12345678#define kthread_run(threadfn, data, namefmt, ...) \ (&#123; \ struct task_struct *__k \ = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__); \ if (!IS_ERR(__k)) \ wake_up_process(__k); \ __k; \&#125;) kthread_run其实就是创建了一个内核线程并且唤醒了。内核线程启动后就一直运行直到调用do_exit()退出或者内核的其他部分调用kthread_stop()退出。1int kthread_stop(struct task_struct *k); 下面为一个使用内核线程的示例：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;linux/module.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt;#include &lt;linux/sched.h&gt; //schdule_timeout()#include &lt;linux/kthread.h&gt;struct task_struct *sln_task;int sln_kthread_func(void *arg)&#123; while (!kthread_should_stop()) &#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); set_current_state(TASK_INTERRUPTIBLE); schedule_timeout(2*HZ); &#125; return 0;&#125;void sln_init_do(void)&#123; int data = 9527; sln_task = kthread_create(sln_kthread_func, &amp;data, &quot;sln_kthread_task&quot;); if (IS_ERR(sln_task)) &#123; printk(KERN_ALERT&quot;kthread_create() failed!\n&quot;); return; &#125; wake_up_process(sln_task);&#125;void sln_exit_do(void)&#123; if (NULL != sln_task) &#123; kthread_stop(sln_task); sln_task = NULL; &#125;&#125;static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_init_do(); return 0;&#125;static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_exit_do();&#125;module_init(sln_init);module_exit(sln_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 既然有进程的创建，那就有进程的终结，终结时内核必须释放它所占有的资源。内核终结时，大部分任务都是靠do_exit()（定义于）来完成。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109NORET_TYPE void do_exit(long code)&#123; struct task_struct *tsk = current; int group_dead; profile_task_exit(tsk); WARN_ON(atomic_read(&amp;tsk-&gt;fs_excl)); //不可在中断上下文中使用该函数 if (unlikely(in_interrupt())) panic(&quot;Aiee, killing interrupt handler!&quot;); if (unlikely(!tsk-&gt;pid)) panic(&quot;Attempted to kill the idle task!&quot;); tracehook_report_exit(&amp;code); validate_creds_for_do_exit(tsk); /* * We&apos;re taking recursive faults here in do_exit. Safest is to just * leave this task alone and wait for reboot. */ if (unlikely(tsk-&gt;flags &amp; PF_EXITING)) &#123; printk(KERN_ALERT &quot;Fixing recursive fault but reboot is needed!\n&quot;); //设置PF_EXITING:表示进程正在退出 tsk-&gt;flags |= PF_EXITPIDONE; set_current_state(TASK_UNINTERRUPTIBLE); schedule(); &#125; exit_irq_thread(); exit_signals(tsk); /* sets PF_EXITING */ /* * tsk-&gt;flags are checked in the futex code to protect against * an exiting task cleaning up the robust pi futexes. */ smp_mb(); spin_unlock_wait(&amp;tsk-&gt;pi_lock); if (unlikely(in_atomic())) printk(KERN_INFO &quot;note: %s[%d] exited with preempt_count %d\n&quot;, current-&gt;comm, task_pid_nr(current), preempt_count()); acct_update_integrals(tsk); group_dead = atomic_dec_and_test(&amp;tsk-&gt;signal-&gt;live); if (group_dead) &#123; hrtimer_cancel(&amp;tsk-&gt;signal-&gt;real_timer); exit_itimers(tsk-&gt;signal); if (tsk-&gt;mm) setmax_mm_hiwater_rss(&amp;tsk-&gt;signal-&gt;maxrss, tsk-&gt;mm); &#125; acct_collect(code, group_dead); if (group_dead) tty_audit_exit(); if (unlikely(tsk-&gt;audit_context)) audit_free(tsk); tsk-&gt;exit_code = code; taskstats_exit(tsk, group_dead); //调用__exit_mm()函数放弃进程占用的mm_struct,如果没有别的进程使用它们即没被共享，就彻底释放它们 exit_mm(tsk); if (group_dead) acct_process(); trace_sched_process_exit(tsk); exit_sem(tsk); //调用sem_exit()函数。如果进程排队等候IPC信号，它则离开队列 //分别递减文件描述符，文件系统数据等的引用计数。当引用计数的值为0时，就代表没有进程在使用这些资源，此时就释放 exit_files(tsk); exit_fs(tsk); check_stack_usage(); exit_thread(); cgroup_exit(tsk, 1); if (group_dead &amp;&amp; tsk-&gt;signal-&gt;leader) disassociate_ctty(1); module_put(task_thread_info(tsk)-&gt;exec_domain-&gt;module); proc_exit_connector(tsk); /* * Flush inherited counters to the parent - before the parent * gets woken up by child-exit notifications. */ perf_event_exit_task(tsk);//调用exit_notify()向父进程发送信号，将子进程的父进程重新设置为线程组中的其他线程或init进程，并把进程状态设为TASK_ZOMBIE. exit_notify(tsk, group_dead);#ifdef CONFIG_NUMA mpol_put(tsk-&gt;mempolicy); tsk-&gt;mempolicy = NULL;#endif#ifdef CONFIG_FUTEX if (unlikely(current-&gt;pi_state_cache)) kfree(current-&gt;pi_state_cache);#endif /* * Make sure we are holding no locks: */ debug_check_no_locks_held(tsk); /* * We can do this unlocked here. The futex code uses this flag * just to verify whether the pi state cleanup has been done * or not. In the worst case it loops once more. */ tsk-&gt;flags |= PF_EXITPIDONE; if (tsk-&gt;io_context) exit_io_context(); if (tsk-&gt;splice_pipe) __free_pipe_info(tsk-&gt;splice_pipe); validate_creds_for_do_exit(tsk); preempt_disable(); exit_rcu(); /* causes final put_task_struct in finish_task_switch(). */ tsk-&gt;state = TASK_DEAD; schedule(); //调用schedule()切换到其他进程 BUG(); /* Avoid &quot;noreturn function does return&quot;. */ for (;;) cpu_relax(); /* For when BUG is null */&#125; 进程终结时所需的清理工作和进程描述符的删除被分开执行，这样尽管在调用了do_exit()之后，线程已经僵死不能允许情况下，系统还是保留了它的进程描述符。在父进程获得已经终结的子进程信息后，子进程的task_struct结构才被释放。linux中有一系列wait()函数，这些函数都是基于系统调用wait4()实现的。它的动作就是挂起调用它的进程直到其中的一个子进程退出，此时函数会返回该退出子进程的PID。 最终释放进程描述符时，会调用release_task()。123456789101112131415161718192021222324252627282930313233void release_task(struct task_struct * p)&#123; struct task_struct *leader; int zap_leader;repeat: tracehook_prepare_release_task(p); /* don&apos;t need to get the RCU readlock here - the process is dead and * can&apos;t be modifying its own credentials */ atomic_dec(&amp;__task_cred(p)-&gt;user-&gt;processes); proc_flush_task(p); write_lock_irq(&amp;tasklist_lock); tracehook_finish_release_task(p); __exit_signal(p); //释放目前僵死进程所使用的所有剩余资源，并进行统计记录 zap_leader = 0; leader = p-&gt;group_leader; //如果进程是线程组最后一个进程，并且领头进程已经死掉，那么就通知僵死的领头进程的父进程 if (leader != p &amp;&amp; thread_group_empty(leader) &amp;&amp; leader-&gt;exit_state == EXIT_ZOMBIE)&#123; BUG_ON(task_detached(leader)); do_notify_parent(leader, leader-&gt;exit_signal); zap_leader = task_detached(leader); if (zap_leader) leader-&gt;exit_state = EXIT_DEAD; &#125; write_unlock_irq(&amp;tasklist_lock); release_thread(p); call_rcu(&amp;p-&gt;rcu, delayed_put_task_struct); p = leader; if (unlikely(zap_leader)) goto repeat;&#125; 子进程不一定能保证在父进程前边退出，所以必须要有机制来保证子进程在这种情况下能找到一个新的父进程。否则的话，这些成为孤儿的进程就会在退出时永远处于僵死状态，白白的耗费内存。解决这个问题的办法，就是给子进程在当前线程组内找一个线程作为父亲。一旦系统给进程成功地找到和设置了新的父进程，就不会再有出现驻留僵死进程的危险了，init进程会例行调用wait()来等待子进程，清除所有与其相关的僵死进程。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（七）：内核定时器和定时执行]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E5%AE%9A%E6%97%B6%E5%99%A8%E5%92%8C%E5%AE%9A%E6%97%B6%E6%89%A7%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 前面章节说到了把工作推后到除现在以外的时间执行的机制是下半部机制，但是当你需要将工作推后到某个确定的时间段之后执行，使用定时器是很好的选择。 上一节内核时间管理中讲到内核在始终中断发生执行定时器，定时器作为软中断在下半部上下文中执行。时钟中断处理程序会执行update_process_times函数，在该函数中运行run_local_timers()函数来标记一个软中断去处理所有到期的定时器。如下：123456789101112131415161718void update_process_times(int user_tick)&#123; struct task_struct *p = current; int cpu = smp_processor_id(); /* Note: this timer irq context must be accounted for as well. */ account_process_tick(p, user_tick); run_local_timers(); rcu_check_callbacks(cpu, user_tick); printk_tick(); scheduler_tick(); run_posix_cpu_timers(p);&#125;void run_local_timers(void)&#123; hrtimer_run_queues(); raise_softirq(TIMER_SOFTIRQ); softlockup_tick();&#125; 在分析定时器的实现之前我们先来看一看使用内核定时器的一个实例，示例如下:12345678910111213141516171819202122232425262728293031323334#include &lt;linux/module.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/version.h&gt;#include &lt;linux/timer.h&gt;#include &lt;linux/delay.h&gt;struct timer_list sln_timer;void sln_timer_do(unsigned long l)&#123; mod_timer(&amp;sln_timer, jiffies + HZ); printk(KERN_ALERT&quot;param: %ld, jiffies: %ld\n&quot;, l, jiffies);&#125;void sln_timer_set(void)&#123; init_timer(&amp;sln_timer); sln_timer.expires = jiffies + HZ; //1s sln_timer.function = sln_timer_do; sln_timer.data = 9527; add_timer(&amp;sln_timer);&#125;static int __init sln_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_timer_set(); return 0;&#125;static void __exit sln_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); del_timer(&amp;sln_timer);&#125;module_init(sln_init);module_exit(sln_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;allen&quot;); 该示例作用是每秒钟打印出当前系统jiffies的值。 内核定时器由结构timer_list表示，定义在文件&lt;include/linux/timer.h&gt;中。123456789101112131415struct timer_list &#123; struct list_head entry; unsigned long expires; void (*function)(unsigned long); unsigned long data; struct tvec_base *base;#ifdef CONFIG_TIMER_STATS void *start_site; char start_comm[16]; int start_pid;#endif#ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map;#endif&#125;; 如示例，内核提供部分操作接口来简化管理定时器，第一步、定义一个定时器：struct timer_list sln_timer;第二步、初始化定时器数据结构的内部值。1init_timer(&amp;sln_timer);//初始化定时器 12345678910111213141516171819202122#define init_timer(timer)\ init_timer_key((timer), NULL, NULL)void init_timer_key(struct timer_list *timer, const char *name, struct lock_class_key *key)&#123; debug_init(timer); __init_timer(timer, name, key);&#125;static void __init_timer(struct timer_list *timer, const char *name, struct lock_class_key *key)&#123; timer-&gt;entry.next = NULL; timer-&gt;base = __raw_get_cpu_var(tvec_bases);#ifdef CONFIG_TIMER_STATS timer-&gt;start_site = NULL; timer-&gt;start_pid = -1; memset(timer-&gt;start_comm, 0, TASK_COMM_LEN);#endif lockdep_init_map(&amp;timer-&gt;lockdep_map, name, key, 0);&#125; 第三步、填充timer_list结构中需要的值：123sln_timer.expires = jiffies + HZ; //1s后执行 sln_timer.function = sln_timer_do; //执行函数sln_timer.data = 9527; sln_timer.expires表示超时时间，它以节拍为单位的绝对计数值。如果当前jiffies计数等于或大于sln_timer.expires的值，那么sln_timer.function所指向的处理函数sln_timer_do就会执行，并且该函数还要使用长整型参数sln_timer.dat。void sln_timer_do(unsigned long l)； 第四步、激活定时器：1add_timer(&amp;sln_timer); //向内核注册定时器 这样定时器就可以运行了。add_timer()的实现如下：12345void add_timer(struct timer_list *timer)&#123; BUG_ON(timer_pending(timer)); mod_timer(timer, timer-&gt;expires);&#125; add_timer()调用了mod_timer()。mod_timer()用于修改定时器超时时间。1mod_timer(&amp;sln_timer, jiffies + HZ); 由于add_timer()是通过调用mod_timer()来激活定时器，所以也可以直接使用mod_timer()来激活定时器，如果定时器已经初始化但没有激活，mod_timer()也会激活它。 如果需要在定时器超时前停止定时器，使用del_timer()函数来完成。1del_timer(&amp;sln_timer); 该函数实现如下：1234567891011121314151617181920212223242526272829int del_timer(struct timer_list *timer)&#123; struct tvec_base *base; unsigned long flags; int ret = 0; timer_stats_timer_clear_start_info(timer); if (timer_pending(timer)) &#123; base = lock_timer_base(timer, &amp;flags); if (timer_pending(timer)) &#123; detach_timer(timer, 1); if (timer-&gt;expires == base-&gt;next_timer &amp;&amp; !tbase_get_deferrable(timer-&gt;base)) base-&gt;next_timer = base-&gt;timer_jiffies; ret = 1; &#125; spin_unlock_irqrestore(&amp;base-&gt;lock, flags); &#125; return ret;&#125;static inline void detach_timer(struct timer_list *timer, int clear_pending)&#123; struct list_head *entry = &amp;timer-&gt;entry; debug_deactivate(timer); __list_del(entry-&gt;prev, entry-&gt;next); if (clear_pending) entry-&gt;next = NULL; entry-&gt;prev = LIST_POISON2;&#125; 当使用del_timer()返回后，定时器就不会再被激活，但在多处理器机器上定时器上定时器中断可能已经在其他处理器上运行了，所以删除定时器时需要等待可能在其他处理器上运行的定时器处理I程序都退出，这时就要使用del_timer_sync()函数执行删除工作：1del_timer_sync(&amp;sln_timer); 该函数不能在中断上下文中使用。该函数详细实现如下：123456789101112131415161718192021222324252627282930313233343536int del_timer_sync(struct timer_list *timer)&#123;#ifdef CONFIG_LOCKDEP unsigned long flags; local_irq_save(flags); lock_map_acquire(&amp;timer-&gt;lockdep_map); lock_map_release(&amp;timer-&gt;lockdep_map); local_irq_restore(flags);#endif for (;;) &#123; //一直循环，直到删除timer成功再退出 int ret = try_to_del_timer_sync(timer); if (ret &gt;= 0) return ret; cpu_relax(); &#125;&#125;int try_to_del_timer_sync(struct timer_list *timer)&#123; struct tvec_base *base; unsigned long flags; int ret = -1; base = lock_timer_base(timer, &amp;flags); if (base-&gt;running_timer == timer) goto out; ret = 0; if (timer_pending(timer)) &#123; detach_timer(timer, 1); if (timer-&gt;expires == base-&gt;next_timer &amp;&amp; !tbase_get_deferrable(timer-&gt;base)) base-&gt;next_timer = base-&gt;timer_jiffies; ret = 1; &#125;out: spin_unlock_irqrestore(&amp;base-&gt;lock, flags); return ret;&#125; 一般情况下应该使用del_timer_sync()函数代替del_timer()函数，因为无法确定在删除定时器时，他是否在其他处理器上运行。为了防止这种情况的发生，应该调用del_timer_sync()函数而不是del_timer()函数。否则，对定时器执行删除操作后，代码会继续执行，但它有可能会去操作在其它处理器上运行的定时器正在使用的资源，因而造成并发访问，所有优先使用删除定时器的同步方法。 除了使用定时器来推迟任务到指定时间段运行之外，还有其他的方法处理延时请求。有的方法会在延迟任务时挂起处理器，有的却不会。实际上也没有方法能够保证实际的延迟时间刚好等于指定的延迟时间。 最简单的 延迟方法是忙等待，该方法实现起来很简单，只需要在循环中不断旋转直到希望的时钟节拍数耗尽。比如：123unsigned long delay = jiffies+10; //延迟10个节拍while(time_before(jiffies,delay)) ； 这种方法当代码等待时，处理器只能在原地旋转等待，它不会去处理其他任何任务。最好在任务等待时，允许内核重新调度其它任务执行。将上面代码修改如下：123unsigned long delay = jiffies+10; //10个节拍while(time_before(jiffies,delay)) cond_resched(); 看一下cond_resched()函数具体实现代码：1234567891011121314151617181920#define cond_resched() (&#123; \ __might_sleep(__FILE__, __LINE__, 0); \ _cond_resched(); \&#125;) int __sched _cond_resched(void)&#123; if (should_resched()) &#123; __cond_resched(); return 1; &#125; return 0;&#125; static void __cond_resched(void) &#123; add_preempt_count(PREEMPT_ACTIVE); schedule(); //最终还是调用schedule()函数来重新调度其它程序运行 sub_preempt_count(PREEMPT_ACTIVE);&#125; 函数cond_resched()将重新调度一个新程序投入运行，但它只有在设置完need_resched标志后才能生效。换句话说，就是系统中存在更重要的任务需要运行。再由于该方法需要调用调度程序，所以它不能在中断上下文中使用—-只能在进程上下文中使用。事实上，所有延迟方法在进程上下文中使用，因为中断处理程序都应该尽可能快的执行。另外，延迟执行不管在哪种情况下都不应该在持有锁时或者禁止中断时发生。 有时内核需要更短的延迟，甚至比节拍间隔还要短。这时可以使用内核提供的ms、ns、us级别的延迟函数。123void udelay(unsigned long usecs); //arch/x86/include/asm/delay.hvoid ndelay(unsigned long nsecs); //arch/x86/include/asm/delay.hvoid mdelay(unsigned long msecs); udelay()使用忙循环将任务延迟指定的ms后执行,其依靠执行数次循环达到延迟效果，mdelay()函数是通过udelay()函数实现，如下：1234#define mdelay(n) (\ (__builtin_constant_p(n) &amp;&amp; (n)&lt;=MAX_UDELAY_MS) ? udelay((n)*1000) : \ (&#123;unsigned long __ms=(n); while (__ms--) udelay(1000);&#125;))#endif udelay()函数仅能在要求的延迟时间很短的情况下执行，而在高速机器中时间很长的延迟会造成溢出。对于较长的延迟，mdelay()工作良好。 schedule_timeout()函数是更理想的延迟执行方法。该方法会让需要延迟执行的任务睡眠到指定的延迟时间耗尽后再重新运行。但该方法也不能保证睡眠时间正好等于指定的延迟时间，只能尽量是睡眠时间接近指定的延迟时间。当指定的时间到期后，内核唤醒被延迟的任务并将其重新放回运行队列。用法如下：12set_current_state(TASK_INTERRUPTIBLE); //将任务设置为可中断睡眠状态schedule_timeout(s*HZ); //小睡一会儿，“s”秒后唤醒 唯一的参数是延迟的相对时间，单位是jiffies，上例中将相应的任务推入可中断睡眠队列，睡眠s秒。在调用函数schedule_timeout之前，不要要将任务设置成可中断或不和中断的一种，否则任务不会休眠。这个函数需要调用调度程序，所以调用它的代码必须保证能够睡眠，简而言之，调用代码必须处于进程上下文中，并且不能持有锁。 事实上schedule_timeout()函数的实现就是内核定时器的一个简单应用。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455signed long __sched schedule_timeout(signed long timeout)&#123; struct timer_list timer; unsigned long expire; switch (timeout) &#123; case MAX_SCHEDULE_TIMEOUT: /* * These two special cases are useful to be comfortable * in the caller. Nothing more. We could take * MAX_SCHEDULE_TIMEOUT from one of the negative value * but I&apos; d like to return a valid offset (&gt;=0) to allow * the caller to do everything it want with the retval. */ schedule(); goto out; default: /* * Another bit of PARANOID. Note that the retval will be * 0 since no piece of kernel is supposed to do a check * for a negative retval of schedule_timeout() (since it * should never happens anyway). You just have the printk() * that will tell you if something is gone wrong and where. */ if (timeout &lt; 0) &#123; printk(KERN_ERR &quot;schedule_timeout: wrong timeout &quot; &quot;value %lx\n&quot;, timeout); dump_stack(); current-&gt;state = TASK_RUNNING; goto out; &#125; &#125; expire = timeout + jiffies; //下一行代码设置了超时执行函数process_timeout()。 setup_timer_on_stack(&amp;timer, process_timeout, (unsigned long)current); __mod_timer(&amp;timer, expire, false, TIMER_NOT_PINNED); //激活定时器 schedule(); //调度其他新任务 del_singleshot_timer_sync(&amp;timer); /* Remove the timer from the object tracker */ destroy_timer_on_stack(&amp;timer); timeout = expire - jiffies; out: return timeout &lt; 0 ? 0 : timeout;&#125;当定时器超时时，process_timeout()函数被调用：static void process_timeout(unsigned long __data) &#123; wake_up_process((struct task_struct *)__data);&#125; 当任务被重新调度时，将返回代码进入睡眠前的位置继续执行，位置正好在schedule()处。 进程上下文的代码为了等待特定时间发生，可以将自己放入等待队列。但是，等待队列上的某个任务可能既在等待一个特定事件到来，又在等待一个特定时间到期，就看谁来得更快。这种情况下，代码可以简单的使用scedule_timeout()函数代替schedule()函数，这样一来，当希望指定时间到期后，任务都会被唤醒，当然，代码需要检查被唤醒的原因，有可能是被事件唤醒，也有可能是因为延迟的时间到期，还可能是因为接收到了信号，然后执行相应的操作。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（六）：内核时钟中断]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%85%AD%EF%BC%89%EF%BC%9A%E5%86%85%E6%A0%B8%E6%97%B6%E9%92%9F%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 内核中很多函数是基于时间驱动的，其中有些函数需要周期或定期执行。比如有的每秒执行100次，有的在等待一个相对时间之后执行。除此之外，内核还必须管理系统运行的时间日期。 周期性产生的时间都是有系统定时器驱动的，系统定时器是一种可编程硬件芯片，它可以以固定频率产生中断，该中断就是所谓的定时器中断，其所对应的中断处理程序负责更新系统时间，也负责执行需要周期性运行的任务。 系统定时器以某种频率自行触发时钟中断，该频率可以通过编程预定，称作节拍率。当时钟中断发生时，内核就通过一种特殊的中断处理器对其进行处理。内核知道连续两次时钟中断的间隔时间，该间隔时间就称为节拍。内核就是靠这种已知的时钟中断间隔来计算实际时间和系统运行时间的。内核通过控制时钟中断维护实际时间，另外内核也为用户提供一组系统调用获取实际日期和实际时间。时钟中断对才操作系统的管理来说十分重要，系统更新运行时间、更新实际时间、均衡调度程序中个处理器上运行队列、检查进程是否用尽时间片等工作都利用时钟中断来周期执行。 系统定时器频率是通过静态预定义的，也就是HZ，体系结构不同，HZ的值也不同。内核在&lt;asm/param.h&gt;文件中定义，在x86上时钟中断频率为100HZ，也就是说在i386处理上每秒时钟中断100次。 linux内核众多子系统都依赖时钟中断工作，所以是时钟中断频率的选择必须考虑频率所有子系统的影响。提高节拍就使得时钟中断产生的更频繁，中断处理程序就会更加频繁的执行，这样就提高了时间驱动时间的准确度，误差更小。如HZ=100，那么时钟每10ms中断一次，周期事件每10ms运行一次，如果HZ=1000，那么周期事件每1ms就会运行一次，这样依赖定时器的系统调用能够以更高的精度运行。既然提高时钟中断频率这么好，那为何要将HZ设置为100呢？因为提高时钟中断频率也会产生副作用，中断频率越高，系统的负担就增加了，处理器需要花时间来执行中断处理程序，中断处理器占用cpu时间越多。这样处理器执行其他工作的时间及越少，并且还会打乱处理器高速缓存。所以选择时钟中断频率时要考虑多方面，要取得各方面的折中的一个合适频率。 内核有一个全局变量jiffies，该变量用来记录系统起来以后产生的节拍总数。系统启动是，该变量被设置为0，此后每产生一次时钟中断就增加该变量的值。jiffies每一秒增加的值就是HZ。jiffies定义于头文件&lt;include/linux/jiffies.h&gt;中：1extern unsigned long volatile __jiffy_data jiffies; 对于32位unsigned long，可以存放最大值为4294967295，所以当节拍数达到最大值后还要继续增加的话，它的值就会回到0值。内核提供了四个宏（位于文件&lt;include/linux/jiffies.h&gt;中）来比较节拍数，这些宏可以正确处理节拍计数回绕情况。12345678910#define time_after(a,b) \ (typecheck(unsigned long, a) &amp;&amp; \ typecheck(unsigned long, b) &amp;&amp; \ ((long)(b) - (long)(a) &lt; 0))#define time_before(a,b) time_after(b,a)#define time_after_eq(a,b) \ (typecheck(unsigned long, a) &amp;&amp; \ typecheck(unsigned long, b) &amp;&amp; \ ((long)(a) - (long)(b) &gt;= 0))#define time_before_eq(a,b) time_after_eq(b,a) 下面示例来打印出当前系统启动后经过的jiffies以及秒数：12345678910111213141516171819#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/jiffies.h&gt; //jiffies#include &lt;asm/param.h&gt; //HZstatic int __init jiffies_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); printk(KERN_ALERT&quot;Current ticks is: %lu, seconds: %lu\n&quot;, jiffies, jiffies/HZ); return 0;&#125;static void __exit jiffies_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__);&#125;module_init(jiffies_init);module_exit(jiffies_exit);MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 执行输出结果为：123# insmod jfs.ko===jiffies_init===Current ticks is: 10106703, seconds: 10106 时钟中断发生时，会触发时钟中断处理程序，始终中断处理程序部分和体系结构相关，下面简单分析一下x86体系的处理：时钟的初始化在time_init()中，在start_kernel()中调用time_init()，如下：123456asmlinkage void __init start_kernel(void)&#123; ...... time_init(); ......&#125; 下面分析一下time_init()的实现，该函数位于文件&lt;arch/x86/kernel/time.c&gt;中：12345678910void __init time_init(void) &#123; late_time_init = x86_late_time_init;&#125; static __init void x86_late_time_init(void)&#123; x86_init.timers.timer_init(); // tsc_init();&#125; 结构体x86_init位于arch/x86/kernel/x86_init.c中12345678struct x86_init_ops x86_init __initdata = &#123; ...... .timers = &#123; .setup_percpu_clockev&gt;--= setup_boot_APIC_clock, .tsc_pre_init = x86_init_noop, .timer_init = hpet_time_init, &#125;&#125; 默认timer初始化函数为：123456void __init hpet_time_init(void) &#123; if (!hpet_enable()) setup_pit_timer(); setup_default_timer_irq();&#125; 函数setup_default_timer_irq();注册中断处理函数：12345678910void __init setup_default_timer_irq(void) &#123; setup_irq(0, &amp;irq0);&#125; static struct irqaction irq0 = &#123; .handler = timer_interrupt, .flags = IRQF_DISABLED | IRQF_NOBALANCING | IRQF_IRQPOLL | IRQF_TIMER, .name = &quot;timer&quot;&#125;; 对应的中断处理函数为:timer_interrupt():12345678910111213141516171819202122232425262728static irqreturn_t timer_interrupt(int irq, void *dev_id) &#123; /* Keep nmi watchdog up to date */ inc_irq_stat(irq0_irqs); /* Optimized out for !IO_APIC and x86_64 */ if (timer_ack) &#123; /* * Subtle, when I/O APICs are used we have to ack timer IRQ * manually to deassert NMI lines for the watchdog if run * on an 82489DX-based system. */ spin_lock(&amp;i8259A_lock); outb(0x0c, PIC_MASTER_OCW3); /* Ack the IRQ; AEOI will end it automatically. */ inb(PIC_MASTER_POLL); spin_unlock(&amp;i8259A_lock); &#125; //在此处调用体系无关的时钟处理例程 global_clock_event-&gt;event_handler(global_clock_event); /* MCA bus quirk: Acknowledge irq0 by setting bit 7 in port 0x61 */ if (MCA_bus) outb_p(inb_p(0x61)| 0x80, 0x61); return IRQ_HANDLED;&#125; 时钟例程在系统启动时start_kernel()函数中调用tick_init()初始化：12345（位于文件kernel/time/tick-common.c）void __init tick_init(void)&#123; clockevents_register_notifier(&amp;tick_notifier);&#125; tick_notifier定义如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384static struct notifier_block tick_notifier = &#123; .notifier_call = tick_notify,&#125;; static int tick_notify(struct notifier_block *nb, unsigned long reason, void *dev)&#123; switch (reason) &#123; ...... case CLOCK_EVT_NOTIFY_RESUME: tick_resume(); break; default: break; &#125; return NOTIFY_OK;&#125; static void tick_resume(void)&#123; struct tick_device *td = &amp;__get_cpu_var(tick_cpu_device); unsigned long flags; int broadcast = tick_resume_broadcast(); spin_lock_irqsave(&amp;tick_device_lock, flags); clockevents_set_mode(td-&gt;evtdev, CLOCK_EVT_MODE_RESUME); if (!broadcast) &#123; if (td-&gt;mode == TICKDEV_MODE_PERIODIC) tick_setup_periodic(td-&gt;evtdev, 0); else tick_resume_oneshot(); &#125; spin_unlock_irqrestore(&amp;tick_device_lock, flags);&#125; /* * Setup the device for a periodic tick */void tick_setup_periodic(struct clock_event_device *dev, int broadcast)&#123; tick_set_periodic_handler(dev, broadcast); ......&#125; /* * 根据broadcast设置周期性的处理函数（kernel/time/tick-broadcast.c）,这里就设置了始终中断函数timer_interrupt中调用的时钟处理例程 */void tick_set_periodic_handler(struct clock_event_device *dev, int broadcast)&#123; if (!broadcast) dev-&gt;event_handler = tick_handle_periodic; else dev-&gt;event_handler = tick_handle_periodic_broadcast;&#125; /* * ，以tick_handle_periodic为例，每一个始终节拍都调用该处理函数，而该处理过程中，主要处理工作处于tick_periodic()函数中。 */void tick_handle_periodic(struct clock_event_device *dev)&#123; int cpu = smp_processor_id(); ktime_t next; tick_periodic(cpu); if (dev-&gt;mode != CLOCK_EVT_MODE_ONESHOT) return; next = ktime_add(dev-&gt;next_event, tick_period); for (;;) &#123; if (!clockevents_program_event(dev, next, ktime_get())) return; if (timekeeping_valid_for_hres()) tick_periodic(cpu); next = ktime_add(next, tick_period); &#125;&#125; tick_periodic()函数主要有以下工作：下面来看分析一下该函数：123456789101112131415161718/* * Periodic tick */static void tick_periodic(int cpu)&#123; if (tick_do_timer_cpu == cpu) &#123; write_seqlock(&amp;xtime_lock); /* 记录下一个节拍事件 */ tick_next_period = ktime_add(tick_next_period, tick_period); do_timer(1); write_sequnlock(&amp;xtime_lock); &#125; update_process_times(user_mode(get_irq_regs()));//更新所耗费的各种节拍数 profile_tick(CPU_PROFILING);&#125; 其中函数do_timer()(位于kernel/timer.c中)对jiffies_64做增加操作：123456void do_timer(unsigned long ticks)&#123; jiffies_64 += ticks; update_wall_time(); //更新墙上时钟 calc_global_load(); //更新系统平均负载统计值&#125; update_process_times更新所耗费的各种节拍数。12345678910111213void update_process_times(int user_tick)&#123; struct task_struct *p = current; int cpu = smp_processor_id(); /* Note: this timer irq context must be accounted for as well. */ account_process_tick(p, user_tick); run_local_timers(); rcu_check_callbacks(cpu, user_tick); printk_tick(); scheduler_tick(); run_posix_cpu_timers(p);&#125; 函数run_local_timers()会标记一个软中断去处理所有到期的定时器。123456void run_local_timers(void)&#123; hrtimer_run_queues(); raise_softirq(TIMER_SOFTIRQ); softlockup_tick();&#125; 在时钟中断处理函数time_interrupt()函数调用体系结构无关的时钟处理例程完成之后，返回到与体系结构的相关的中断处理函数中。以上所有的工作每一次时钟中断都会运行，也就是说如果HZ=100，那么时钟中断处理程序每一秒就会运行100次。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（五）：下半部机制之工作队列及几种机制的选择]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%BA%94%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97%E5%8F%8A%E5%87%A0%E7%A7%8D%E6%9C%BA%E5%88%B6%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 工作队列是下半部的另外一种将工作推后执行形式。和软中断、tasklet不同，工作队列将工作推后交由一个内核线程去执行，并且该下半部总会在进程上下文中执行。这样，工作队列允许重新调度甚至是睡眠。 所以，如果推后执行的任务需要睡眠，就选择工作队列。如果不需要睡眠，那就选择软中断或tasklet。工作队列是唯一能在进程上下文中运行的下半部实现机制，也只有它才可以睡眠。 工作队列子系统是一个用于创建内核线程的接口，通过它创建的进程负责执行由内核其他部分排到队列里的任务。它创建的这些内核线程称作工作者线程。工作队列可以让你的驱动程序创建一个专门的工作者线程来处理需要推后的工作。不过，工作队列子系统提供了一个缺省的工作者线程来处理这些工作。因此，工作队列最基本的表现形式就转变成一个把需要推后执行的任务交给特定的通用线程这样一种接口。缺省的工作线程叫做event/n.每个处理器对应一个线程，这里的n代表了处理器编号。除非一个驱动程序或者子系统必须建立一个属于自己的内核线程，否则最好还是使用缺省线程。使用下面命令可以看到默认event工作者线程，每个处理器对应一个线程：123# ps x | grep event | grep -v grep 9 ? S 0:00 [events/0] 10 ? S 0:00 [events/1] 工作者线程使用workqueue_struct结构表示（位于&lt;kernel/workqueue.c&gt;中）：1234567891011121314151617181920212223struct workqueue_struct &#123; struct cpu_workqueue_struct *cpu_wq; //该数组每一项对应系统中的一个处理器 struct list_head list; const char *name; int singlethread; int freezeable; /* Freeze threads during suspend */ int rt;#ifdef CONFIG_LOCKDEP struct lockdep_map lockdep_map;#endif&#125;每个处理器，每个工作者线程对应对应一个cpu_workqueue_struct结构体（位于&lt;kernel/workqueue.c&gt;中）：struct cpu_workqueue_struct &#123; spinlock_t lock; //保护该结构 struct list_head worklist; //工作列表 wait_queue_head_t more_work; //等待队列，其中的工作者线程因等待而处于睡眠状态 struct work_struct *current_work; struct workqueue_struct *wq; //关联工作队列结构 struct task_struct *thread; // 关联线程,指向结构中工作者线程的进程描述符指针&#125; ____cacheline_aligned; 每个工作者线程类型关联一个自己的workqueue_struct，在该结构体里面，给每个线程分配一个cpu_workqueue_struct ，因而也就是给每个处理器分配一个，因为每个处理器都有一个该类型的工作者线程。 所有的工作者线程都是使用普通的内核线程实现的，他们都要执行worker_thread()函数。在它初始化完以后，这个函数执行一个死循环执行一个循环并开始休眠，当有操作被插入到队列的时候，线程就会被唤醒，以便执行这些操作。当没有剩余的时候，它又会继续休眠。工作由work_struct（位于&lt;kernel/workqueue.c&gt;中）结构表示：1234567struct work_struct &#123; atomic_long_t data;...... struct list_head entry;//连接所有链表 work_func_t func;.....&#125;; 当一个工作线程被唤醒时，它会执行它的链表上的所有工作。工作一旦执行完毕，它就将相应的work_struct对象从链表上移去，当链表不再有对象时，它就继续休眠。woker_thread()函数如下：1234567891011121314151617181920212223242526272829static int worker_thread(void *__cwq)&#123; struct cpu_workqueue_struct *cwq = __cwq; DEFINE_WAIT(wait); if (cwq-&gt;wq-&gt;freezeable) set_freezable(); for (;;) &#123; //线程将自己设置为休眠状态并把自己加入等待队列 prepare_to_wait(&amp;cwq-&gt;more_work, &amp;wait, TASK_INTERRUPTIBLE); if (!freezing(current) &amp;&amp; !kthread_should_stop() &amp;&amp; list_empty(&amp;cwq-&gt;worklist)) schedule();//如果工作对列是空的，线程调用schedule()函数进入睡眠状态 finish_wait(&amp;cwq-&gt;more_work, &amp;wait); try_to_freeze(); //如果链表有对象，线程就将自己设为运行态，脱离等待队列 if (kthread_should_stop()) break; //再次调用run_workqueue()执行推后的工作 run_workqueue(cwq); &#125; return 0;&#125; 之后由run_workqueue()函数来完成实际推后到此的工作：1234567891011121314151617181920212223242526272829303132static void run_workqueue(struct cpu_workqueue_struct *cwq) &#123; spin_lock_irq(&amp;cwq-&gt;lock); while (!list_empty(&amp;cwq-&gt;worklist)) &#123; //链表不为空时，选取下一个节点对象 struct work_struct *work = list_entry(cwq-&gt;worklist.next, struct work_struct, entry); //获取希望执行的函数func及其参数data work_func_t f = work-&gt;func;...... trace_workqueue_execution(cwq-&gt;thread, work); cwq-&gt;current_work = work; //把该结点从链表上解下来 list_del_init(cwq-&gt;worklist.next); spin_unlock_irq(&amp;cwq-&gt;lock); BUG_ON(get_wq_data(work) != cwq); //将待处理标志位pending清0 work_clear_pending(work); lock_map_acquire(&amp;cwq-&gt;wq-&gt;lockdep_map); lock_map_acquire(&amp;lockdep_map); //执行函数 f(work); lock_map_release(&amp;lockdep_map); lock_map_release(&amp;cwq-&gt;wq-&gt;lockdep_map); ...... spin_lock_irq(&amp;cwq-&gt;lock); cwq-&gt;current_work = NULL; &#125; spin_unlock_irq(&amp;cwq-&gt;lock);&#125; 系统允许有多种类型工作者线程存在，默认情况下内核只有event这一种类型的工作者线程，每个工作者线程都由一个cpu_workqueue_struct 结构体表示，大部分情况下，驱动程序都使用现存的默认工作者线程。 工作队列的使用很简单。可以使用缺省的events任务队列，也可以创建新的工作者线程。第一步、创建需要推后完成的工作。12DECLARE_WORK(name,void (*func)(void *),void *data); //编译时静态创建INIT_WORK(struct work_struct *work, void (*func)(void *)); //运行时动态创建 第二步、编写队列处理函数，处理函数会由工作者线程执行，因此，函数会运行在进程上下文中，默认情况下，允许相应中断，并且不持有锁。如果需要，函数可以睡眠。需要注意的是，尽管处理函数运行在进程上下文中，但它不能访问用户空间，因为内核线程在用户空间没有相应的内存映射。函数原型如下：1void work_hander(void *data); 第三步、调度工作队列。调用schedule_work(&amp;work)；work马上就会被调度，一旦其所在的处理器上的工作者线程被唤醒，它就会被执行。当然如果不想快速执行，而是想延迟一段时间执行，调用schedule_delay_work(&amp;work,delay);delay是要延迟的时间节拍。默认工作者线程的调度函数其实就是做了一层封装，减少了 默认工作者线程的参数输入，如下：123456789int schedule_work(struct work_struct *work)&#123; return queue_work(keventd_wq, work);&#125; int schedule_delayed_work(struct delayed_work *dwork, unsigned long delay) &#123; return queue_delayed_work(keventd_wq, dwork, delay);&#125; 第四步、刷新操作，插入队列的工作会在工作者线程下一次被唤醒的时候执行。有时，在继续下一步工作之前，你必须保证一些操作已经执行完毕等等。由于这些原因，内核提供了一个用于刷新指定工作队列的函数：1void flush_scheduled_work(void); 这个函数会一直等待，直到队列中所有的对象都被执行后才返回。在等待所有待处理的工作执行的时候，该函数会进入休眠状态，所以只能在进程上下文中使用它。需要说明的是，该函数并不取消任何延迟执行的工作。取消延迟执行的工作应该调用：int cancel_delayed_work(struct work_struct *work);这个函数可以取消任何与work_struct 相关挂起的工作。下面为一个示例：12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt; #include &lt;linux/workqueue.h&gt; //work_strcut //struct work_struct ws;struct delayed_work dw; void workqueue_func(struct work_struct *ws) //处理函数&#123; printk(KERN_ALERT&quot;Hello, this is shallnet!\n&quot;);&#125; static int __init kwq_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); //INIT_WORK(&amp;ws, workqueue_func); //建需要推后完成的工作 //schedule_work(&amp;ws); //调度工作 INIT_DELAYED_WORK(&amp;dw, workqueue_func); schedule_delayed_work(&amp;dw, 10000); return 0;&#125; static void __exit kwq_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); flush_scheduled_work();&#125; module_init(kwq_init);module_exit(kwq_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 上面的操作是使用缺省的工作队列，下面来看一下创建一个新的工作队列是如何操作的？ 创建一个新的工作队列和与之相应的工作者线程，方法很简单，使用如下函数：1struct workqueue_struct *create_workqueue(const char *name); name是新内核线程的名字。比如缺省events队列的创建是这样使用的：12struct workqueue_struct *keventd_wq；kevent_wq = create_workqueue(&quot;event&quot;); 这样就创建了所有的工作者线程，每个处理器都有一个。然后调用如下函数进行调度：12int queue_work(struct workqueue_struct *wq, struct work_struct *work);int queue_delayed_work(struct workqueue_struct *wq,struct delayed_work *work,unsigned long delay); 最后可以调用flush_workqueue(struct workqueue_struct *wq);刷新指定工作队列。下面为自定义新的工作队列的示例：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/workqueue.h&gt; //work_strcut struct workqueue_struct *sln_wq = NULL;//struct work_struct ws;struct delayed_work dw; void workqueue_func(struct work_struct *ws)&#123; printk(KERN_ALERT&quot;Hello, this is shallnet!\n&quot;);&#125; static int __init kwq_init(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); sln_wq = create_workqueue(&quot;sln_wq&quot;); //创建名为sln_wq的工作队列 //INIT_WORK(&amp;ws, workqueue_func); //queue_work(sln_wq, &amp;ws); INIT_DELAYED_WORK(&amp;dw, workqueue_func); // queue_delayed_work(sln_wq, &amp;dw, 10000); // return 0;&#125; static void __exit kwq_exit(void)&#123; printk(KERN_ALERT&quot;===%s===\n&quot;, __func__); flush_workqueue(sln_wq);&#125; module_init(kwq_init);module_exit(kwq_exit); MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;shallnet&quot;);MODULE_DESCRIPTION(&quot;blog.csdn.net/shallnet&quot;); 使用ps可以查看到名为sln_wq的工作者线程。 在当前2.6.32版本中，我们讲了三种下半部机制：软中断、tasklet、工作队列。其中tasklet基于软中断，而工作队列靠内核线程实现。 使用软中断必须要确保共享数据的安全，因为相同类别的软中断可能在不同处理器上同时执行。在对于时间要求是否严格和执行频率很高的应用，或准备利用每一处理器上的变量或类型情形，可以考虑使用软中断，如网络子系统。 tasklet接口简单，可以动态创建，且两个通知类型的tasklet不能同时执行，所以实现起来较简单。驱动程序应该尽量选择tasklet而不是软中断。 工作队列工作于进程上下文，易于使用。由于牵扯到内核线程或上下文的切换，可能开销较大。如果你需要把任务推后到进程上下文中，或你需要休眠，那就只有使用工作队列了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（四）：下半部机制之tasklet]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E5%9B%9B%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8Btasklet%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 tasklet是利用软中断实现的一种下半部机制。tasklet相比于软中断，其接口更加简单方便，锁保护要求较低。tasklet由tasklet_struct结构体表示：12345678struct tasklet_struct&#123; struct tasklet_struct *next; //链表中下一个tasklet unsigned long state; //tasklet状态 atomic_t count; //引用计数 void (*func)(unsigned long); //tasklet处理函数 unsigned long data; //给tasklet处理函数的参数&#125;; tasklet还分为了高优先级tasklet与一般tasklet，前面分析软中断时softirq_init()注册的两个tasklet软中断。12345678void __init softirq_init(void)&#123; ...... //此处注册两个软中断 open_softirq(TASKLET_SOFTIRQ, tasklet_action); open_softirq(HI_SOFTIRQ, tasklet_hi_action); ......&#125; 其处理函数分别为 tasklet_action()和tasklet_hi_action()。 tasklet_action()函数实现为：1234567891011121314151617181920212223242526272829303132333435static void tasklet_action(struct softirq_action *a)&#123; struct tasklet_struct *list; local_irq_disable(); list = __get_cpu_var(tasklet_vec).head; __get_cpu_var(tasklet_vec).head = NULL; __get_cpu_var(tasklet_vec).tail = &amp;__get_cpu_var(tasklet_vec).head; local_irq_enable(); while (list) &#123; struct tasklet_struct *t = list; list = list-&gt;next; if (tasklet_trylock(t)) &#123; if (!atomic_read(&amp;t-&gt;count)) &#123; //t-&gt;count为零才会调用task_struct里的函数 if (!test_and_clear_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) BUG(); t-&gt;func(t-&gt;data); //设置了TASKLET_STATE_SCHED标志才会被遍历到链表上对应的函数 tasklet_unlock(t); continue; &#125; tasklet_unlock(t); &#125; local_irq_disable(); t-&gt;next = NULL; *__get_cpu_var(tasklet_vec).tail = t; __get_cpu_var(tasklet_vec).tail = &amp;(t-&gt;next); __raise_softirq_irqoff(TASKLET_SOFTIRQ); local_irq_enable(); &#125;&#125; tasklet_hi_action函数实现类似12345678910111213141516171819202122232425262728293031323334static void tasklet_hi_action(struct softirq_action *a)&#123; struct tasklet_struct *list; local_irq_disable(); list = __get_cpu_var(tasklet_hi_vec).head; __get_cpu_var(tasklet_hi_vec).head = NULL; __get_cpu_var(tasklet_hi_vec).tail = &amp;__get_cpu_var(tasklet_hi_vec).head; local_irq_enable(); while (list) &#123; struct tasklet_struct *t = list; list = list-&gt;next; if (tasklet_trylock(t)) &#123; if (!atomic_read(&amp;t-&gt;count)) &#123; if (!test_and_clear_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) BUG(); t-&gt;func(t-&gt;data); tasklet_unlock(t); continue; &#125; tasklet_unlock(t); &#125; local_irq_disable(); t-&gt;next = NULL; *__get_cpu_var(tasklet_hi_vec).tail = t; __get_cpu_var(tasklet_hi_vec).tail = &amp;(t-&gt;next); __raise_softirq_irqoff(HI_SOFTIRQ); local_irq_enable(); &#125;&#125; 这两个函数主要是做了如下动作： 禁止中断，并为当前处理器检索tasklet_vec或tasklet_hi_vec链表。 将当前处理器上的该链表设置为NULL,达到清空的效果。 运行相应中断。 循环遍历获得链表上的每一个待处理的tasklet。 如果是多处理器系统，通过检查TASKLET_STATE_RUN来判断这个tasklet是否正在其他处理器上运行。如果它正在运行，那么现在就不要执行，跳 到下一个待处理的tasklet去。 如果当前这个tasklet没有执行，将其状态设置为TASKLETLET_STATE_RUN,这样别的处理器就不会再去执行它了。 检查count值是否为0，确保tasklet没有被禁止。如果tasklet被禁止，则跳到下一个挂起的tasklet去。 现在可以确定这个tasklet没有在其他地方执行，并且被我们设置为执行状态，这样它在其他部分就不会被执行，并且引用计数器为0，现在可以执行tasklet的处理程序了。 重复执行下一个tasklet，直至没有剩余的等待处理的tasklets。 一般情况下，都是用tasklet来实现下半部，tasklet可以动态创建、使用方便、执行速度快。下面来看一下如何创建自己的tasklet呢？第一步，声明自己的tasklet。既可以静态也可以动态创建，这取决于选择是想有一个对tasklet的直接引用还是间接引用。静态创建方法(直接引用)，可以使用下列两个宏的一个(在linux/interrupt.h中定义)：12DECLARE_TASKLET(name,func,data)DECLARE_TASKLET_DISABLED(name,func,data) 这两个宏的实现为：12345#define DECLARE_TASKLET(name, func, data) \struct tasklet_struct name = &#123; NULL, 0, ATOMIC_INIT(0), func, data &#125; #define DECLARE_TASKLET_DISABLED(name, func, data) \struct tasklet_struct name = &#123; NULL, 0, ATOMIC_INIT(1), func, data &#125; 这两个宏之间的区别在于引用计数器的初始值不同，前面一个把创建的tasklet的引用计数器设置为0，使其处于激活状态，另外一个将其设置为1，处于禁止状态。而动态创建(间接引用)的方式如下：1tasklet_init(t,tasklet_handler,dev); 其实现代码为：123456789void tasklet_init(struct tasklet_struct *t, void (*func)(unsigned long), unsigned long data)&#123; t-&gt;next = NULL; t-&gt;state = 0; atomic_set(&amp;t-&gt;count, 0); t-&gt;func = func; t-&gt;data = data;&#125; 第二步，编写tasklet处理程序。tasklet处理函数类型是void tasklet_handler(unsigned long data)。因为是靠软中断实现，所以tasklet不能休眠，也就是说不能在tasklet中使用信号量或者其他什么阻塞式的函数。由于tasklet 运行时允许响应中断，所以必须做好预防工作，如果新加入的tasklet和中断处理程序之间共享了某些数据额的话。两个相同的tasklet绝不能同时执 行，如果新加入的tasklet和其他的tasklet或者软中断共享了数据，就必须要进行适当地锁保护。 第三步，调度自己的tasklet。调用tasklet_schedule()（或tasklet_hi_schedule()）函数，tasklet就会进入挂起状态以便执行。如果在还没有得到运行机会之前，如果有一个相同的tasklet又被调度了，那么它仍然只会运行一次。如果这时已经开始运行，那么这个新的tasklet会被重新调度并再次运行。一种优化策略是一个tasklet总在调度它的处理器上执行。 调用tasklet_disable()来禁止某个指定的 tasklet，如果该tasklet当前正在执行，这个函数会等到它执行完毕再返回。调用tasklet_disable_nosync()也是来禁止 的，只是不用在返回前等待tasklet执行完毕，这么做不太安全，因为没法估计该tasklet是否仍在执行。 tasklet_enable()激活一个tasklet。可以使用tasklet_kill()函数从挂起的对列中去掉一个tasklet。这个函数会 首先等待该tasklet执行完毕，然后再将其移去。当然，没有什么可以阻止其他地方的代码重新调度该tasklet。由于该函数可能会引起休眠，所以禁止在中断上下文中使用它。 下面来看一下函数tasklet_schedule的实现：123456789101112131415161718192021222324static inline void tasklet_schedule(struct tasklet_struct *t)&#123;//检查tasklet的状态是否为TASKLET_STATE_SCHED.如果是，说明tasklet已经被调度过了，函数返回。 if (!test_and_set_bit(TASKLET_STATE_SCHED, &amp;t-&gt;state)) __tasklet_schedule(t);&#125; void __tasklet_schedule(struct tasklet_struct *t)&#123; unsigned long flags; //保存中断状态，然后禁止本地中断。在执行tasklet代码时，这么做能够保证处理器上的数据不会弄乱。 local_irq_save(flags); //把需要调度的tasklet加到每个处理器一个的tasklet_vec链表或task_hi_vec链表的表头上去。 t-&gt;next = NULL; *__get_cpu_var(tasklet_vec).tail = t; __get_cpu_var(tasklet_vec).tail = &amp;(t-&gt;next); //唤起TASKLET_SOFTIRQ或HI_SOFTIRQ软中断，这样在下一次调用do_softirq()时就会执行该tasklet。 raise_softirq_irqoff(TASKLET_SOFTIRQ); //恢复中断到原状态并返回。 local_irq_restore(flags);&#125; tasklet_hi_schedule()函数的实现细节类似。 对于软中断，内核会选择几个特殊的实际进行处理(常见的是中 断处理程序返回时)。软中断被触发的频率有时会很好，而且还可能会自行重复触发，这带来的结果就是用户空间的进程无法获得足够的处理器时间，因为处于饥饿 状态。同时，如果单纯的对重复触发的软中断采取不立即处理的策略也是无法接受的。 内核选中的方案是不会立即处理重新触发的软中断，作为改进， 当大量软中断出现的时候，内核会唤醒一组内核线程来处理这些负载。这些线程在最低优先级上运行(nice值为19)。这种这种方案能够保证在软中断负担很 重的时候用户程序不会因为得不到处理时间而处理饥饿状态。相应的，也能保证“过量”的软中断终究会得到处理。最后，在空闲系统上，这个方案同样表现良好， 软中断处理得非常迅速(因为仅存的内存线程肯定会马上调度)。为了保证只要有空闲的处理器，它们就会处理软中断，所以给每个处理器都分配一个这样的线程。 所有线程的名字都叫做ksoftirad/n，区别在于n，它对应的是处理器的编号。一旦该线程被初始化，它就会执行类似下面这样的死循环：12345678910111213for(;;)&#123; if(!softirq_pending(cpu))//softirq_pending()负责发现是否有待处理的软中断 schedule(); //没有待处理软中断就唤起调度程序选择其他可执行进程投入运行 set_current_state(TASK_RUNNING); while(softirq_pending(cpu))&#123; do_softirq();//有待处理的软中断，ksoftirq调用do_softirq()去处理他。 if(need_resched()) //如果有必要的话，每次软中断完成之后调用schedule函数让其他重要进程得到处理机会 schedule(); &#125; //当所有需要执行的操作都完成以后，该内核线程将自己设置为 TASK_INTERRUPTIBLE状态 set_current_state(TASK_INTERRUPTIBLE);&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（三）：下半部机制之软中断]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%9A%E4%B8%8B%E5%8D%8A%E9%83%A8%E6%9C%BA%E5%88%B6%E4%B9%8B%E8%BD%AF%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 中断处理程序以异步方式执行，其会打断其他重要代码，其运行时该中断同级的其他中断会被屏蔽，并且当前处理器上所有其他中断都有可能会被屏蔽掉，还有中断处理程序不能阻塞，所以中断处理需要尽快结束。由于中断处理程序的这些缺陷，导致了中断处理程序只是整个硬件中断处理流程的一部分，对于那些对时间要求不高的任务，留给中断处理流程的另外一部分，也就是本节要讲的中断处理流程的下半部。 那哪些工作由中断处理程序完成，哪些工作留给下半部来执行呢？其实上半部和下半部的工作划分不存在某种严格限制，这主要取决于驱动程序开发者自己的判断，一般最好能将中断处理程序执行时间缩短到最小。中断处理程序几乎都需要通过操作硬件对中断的到达进行确认，有时还会做对时间非常敏感的工作（如拷贝数据），其余的工作基本上留给下半部来处理，下半部就是执行与中断处理密切相关但中断处理程序本身不执行的工作。一般对时间非常敏感、和硬件相关、要保证不被其它中断(特别是相同的中断)打断的这些任务放在中断处理程序中执行，其他任务考虑放在下半部执行。 那下半部什么时候执行呢？下半部不需要指定明确执行时间，只要把任务推迟一点，让它们在系统不太忙且中断恢复后执行就可以了，而且执行期间可以相应所有中断。 上半部只能通过中断处理程序实现，而下半部可以有多种机制来实现，在2.6.32版本中，有三种不同形式的下半部实现机制：软中断、tasklet、工作队列。下面来看一下这三种下半部的实现。 软中断在start_kernerl()函数中，系统初始化软中断。12345678910111213asmlinkage void __init start_kernel(void)&#123; char * command_line; extern struct kernel_param __start___param[], __stop___param[]; smp_setup_processor_id();...... softirq_init();//初始化软中断...... /* Do the rest non-__init&apos;ed, we&apos;re now alive */ rest_init();&#125; 在softirq_init()中会注册两个常用类型的软中断, 具体代码如下（位于kernel/softirq.c）:1234567891011121314151617181920void __init softirq_init(void)&#123; int cpu; for_each_possible_cpu(cpu) &#123; int i; per_cpu(tasklet_vec, cpu).tail = &amp;per_cpu(tasklet_vec, cpu).head; per_cpu(tasklet_hi_vec, cpu).tail = &amp;per_cpu(tasklet_hi_vec, cpu).head; for (i = 0; i &lt; NR_SOFTIRQS; i++) INIT_LIST_HEAD(&amp;per_cpu(softirq_work_list[i], cpu)); &#125; register_hotcpu_notifier(&amp;remote_softirq_cpu_notifier); //此处注册两个软中断 open_softirq(TASKLET_SOFTIRQ, tasklet_action); open_softirq(HI_SOFTIRQ, tasklet_hi_action);&#125; 注册函数open_softirq()参数含义:nr:软中断类型 action:软中断处理函数1234void open_softirq(int nr, void (*action)(struct softirq_action *))&#123; softirq_vec[nr].action = action;&#125; softirq_action结构表示软中断，定义在&lt;include/linux/interrupt.h&gt;1234struct softirq_action&#123; void (*action)(struct softirq_action *);&#125; 文件&lt;kernel/softirq.c&gt;中定义了32个该结构体的数组：1static struct softirq_action softirq_vec[NR_SOFTIRQS] __cacheline_aligned_in_smp; 每注册一个软中断都会占该数组一个位置，因此系统中最多有32个软中断。从上面的代码中,我们可以看到:open_softirq()中.其实就是对softirq_vec数组的nr项赋值.softirq_vec是一个32元素的数组,实际上linux内核只使用了几项：123456789101112131415161718192021/* PLEASE, avoid to allocate new softirqs, if you need not _really_ high frequency threaded job scheduling. For almost all the purposes tasklets are more than enough. F.e. all serial device BHs et al. should be converted to tasklets, not to softirqs. */ enum&#123; HI_SOFTIRQ=0, TIMER_SOFTIRQ, NET_TX_SOFTIRQ, NET_RX_SOFTIRQ, BLOCK_SOFTIRQ, BLOCK_IOPOLL_SOFTIRQ, TASKLET_SOFTIRQ, SCHED_SOFTIRQ, HRTIMER_SOFTIRQ, RCU_SOFTIRQ, /* Preferable RCU should always be the last softirq */ NR_SOFTIRQS&#125;; 那么软中断注册完成之后，什么时候触发软中断处理函数执行呢？通常情况下，软中断会在中断处理程序返回前标记它，使其在稍后合适的时候被执行。在下列地方，待处理的软中断会被检查和执行： 处理完一个硬件中断以后； 在ksoftirqd内核线程中； 在那些显示检查和执行待处理的软中断的代码中，如网络子系统中。 无论如何，软中断会在do_softirq()（位于&lt;kernel/softirq.c&gt;中）中执行，如果有待处理的软中断，do_softirq会循环遍历每一个，调用他们的软中断处理程序。12345678910111213asmlinkage void do_softirq(void) &#123; __u32 pending; unsigned long flags; //如果在硬件中断环境中就退出，软中断不可以在硬件中断上下文或者是在软中断环境中使用，使用in_interrupt()来防止软中断嵌套，和抢占硬中断环境。 if (in_interrupt()) return; //禁止本地中断 local_irq_save(flags); pending = local_softirq_pending(); //如果有软中断要处理，则进入__do_softirq() if (pending) __do_softirq(); local_irq_restore(flags); &#125; 下面看一下__do_softirq()的实现：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859asmlinkage void __do_softirq(void)&#123; struct softirq_action *h; __u32 pending; int max_restart = MAX_SOFTIRQ_RESTART; int cpu; pending = local_softirq_pending(); //pending用于保留待处理软中断32位位图 account_system_vtime(current); __local_bh_disable((unsigned long)__builtin_return_address(0)); lockdep_softirq_enter(); cpu = smp_processor_id();restart: /* Reset the pending bitmask before enabling irqs */ set_softirq_pending(0); local_irq_enable(); h = softirq_vec; do &#123; if (pending &amp; 1) &#123; //如果pending第n位被设置为1，那么处理第n位对应类型的软中断 int prev_count = preempt_count(); kstat_incr_softirqs_this_cpu(h - softirq_vec); trace_softirq_entry(h, softirq_vec); h-&gt;action(h); //执行软中断处理函数 trace_softirq_exit(h, softirq_vec); if (unlikely(prev_count != preempt_count())) &#123; printk(KERN_ERR &quot;huh, entered softirq %td %s %p&quot; &quot;with preempt_count %08x,&quot; &quot; exited with %08x?\n&quot;, h - softirq_vec, softirq_to_name[h - softirq_vec], h-&gt;action, prev_count, preempt_count()); preempt_count() = prev_count; &#125; rcu_bh_qs(cpu); &#125; h++; pending &gt;&gt;= 1; //pending右移一位，循环检查其每一位 &#125; while (pending); //直到pending变为0，pending最多32位，所以循环最多执行32次。 local_irq_disable(); pending = local_softirq_pending(); if (pending &amp;&amp; --max_restart) goto restart; if (pending) wakeup_softirqd(); lockdep_softirq_exit(); account_system_vtime(current); _local_bh_enable();&#125; 使用软中断必须要在编译期间静态注册，一般只有像网络这样对性能要求高的情况才使用软中断，文章前面我们也看到，系统中注册的软中断就那么几个。大部分时候，使用下半部另外一种机制tasklet的情况更多一些，tasklet可以动态的注册，可以被看作是一种性能和易用性之间寻求平衡的一种产物。事实上，大部分驱动程序都是用tasklet来实现他们的下半部。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（二）：硬中断及中断处理]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E7%A1%AC%E4%B8%AD%E6%96%AD%E5%8F%8A%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】 操作系统负责管理硬件设备，为了使系统和硬件设备的协同工作不降低机器性能，系统和硬件的通信使用中断的机制，也就是让硬件在需要的时候向内核发出信号，这样使得内核不用去轮询设备而导致做很多无用功。 中断使得硬件可以发出通知给处理器，硬件设备生成中断的时候并不考虑与处理器的时钟同步，中断可以随时产生。也就是说，内核随时可能因为新到来的中断而被打断。当接收到一个中断后，中断控制器会给处理器发送一个电信号，处理器检测到该信号便中断自己当前工作而处理中断。 在响应一个中断时，内核会执行一个函数，该函数叫做中断处理程序或中断服务例程（ISR）。中断处理程序运行与中断上下文，中断上下文中执行的代码不可阻塞，应该快速执行，这样才能保证尽快恢复被中断的代码的执行。中断处理程序是管理硬件驱动的驱动程序的组成部分，如果设备使用中断，那么相应的驱动程序就注册一个中断处理程序。 在驱动程序中,通常使用request_irq()来注册中断处理程序。该函数在文件&lt;include/linux/interrupt.h&gt;中声明：123extern int __must_checkrequest_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev); 第一个参数为要分配的中断号；第二个参数为指向中断处理程序的指针；第三个参数为中断处理标志。该函数实现如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384static inline int __must_checkrequest_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev)&#123; return request_threaded_irq(irq, handler, NULL, flags, name, dev);&#125; int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id)&#123; struct irqaction *action; struct irq_desc *desc; int retval; /* * handle_IRQ_event() always ignores IRQF_DISABLED except for * the _first_ irqaction (sigh). That can cause oopsing, but * the behavior is classified as &quot;will not fix&quot; so we need to * start nudging drivers away from using that idiom. */ if ((irqflags &amp; (IRQF_SHARED|IRQF_DISABLED)) == (IRQF_SHARED|IRQF_DISABLED)) &#123; pr_warning( &quot;IRQ %d/%s: IRQF_DISABLED is not guaranteed on shared IRQs\n&quot;, irq, devname); &#125;#ifdef CONFIG_LOCKDEP /* * Lockdep wants atomic interrupt handlers: */ irqflags |= IRQF_DISABLED;#endif /* * Sanity-check: shared interrupts must pass in a real dev-ID, * otherwise we&apos;ll have trouble later trying to figure out * which interrupt is which (messes up the interrupt freeing * logic etc). */ if ((irqflags &amp; IRQF_SHARED) &amp;&amp; !dev_id) return -EINVAL; desc = irq_to_desc(irq); if (!desc) return -EINVAL; if (desc-&gt;status &amp; IRQ_NOREQUEST) return -EINVAL; if (!handler) &#123; if (!thread_fn) return -EINVAL; handler = irq_default_primary_handler; &#125; //分配一个irqaction action = kzalloc(sizeof(struct irqaction), GFP_KERNEL); if (!action) return -ENOMEM; action-&gt;handler = handler; action-&gt;thread_fn = thread_fn; action-&gt;flags = irqflags; action-&gt;name = devname; action-&gt;dev_id = dev_id; chip_bus_lock(irq, desc); //将创建并初始化完在的action加入desc retval = __setup_irq(irq, desc, action); chip_bus_sync_unlock(irq, desc); if (retval) kfree(action);#ifdef CONFIG_DEBUG_SHIRQ if (irqflags &amp; IRQF_SHARED) &#123; /* * It&apos;s a shared IRQ -- the driver ought to be prepared for it * to happen immediately, so let&apos;s make sure.... * We disable the irq to make sure that a &apos;real&apos; IRQ doesn&apos;t * run in parallel with our fake. */ unsigned long flags; disable_irq(irq); local_irq_save(flags); handler(irq, dev_id); local_irq_restore(flags); enable_irq(irq); &#125;#endif return retval;&#125; 下面看一下中断处理程序的实例，以rtc驱动程序为例，代码位于&lt;drivers/char/rtc.c&gt;中。当RTC驱动装载时，rtc_init()函数会被调用来初始化驱动程序，包括注册中断处理函数：12345678910/* * XXX Interrupt pin #7 in Espresso is shared between RTC and * PCI Slot 2 INTA# (and some INTx# in Slot 1). */if (request_irq(rtc_irq, rtc_interrupt, IRQF_SHARED, &quot;rtc&quot;, (void *)&amp;rtc_port)) &#123; rtc_has_irq = 0; printk(KERN_ERR &quot;rtc: cannot register IRQ %d\n&quot;, rtc_irq); return -EIO;&#125; 处理程序函数rtc_interrupt()：123456789101112131415161718192021222324252627282930313233343536373839404142/* * A very tiny interrupt handler. It runs with IRQF_DISABLED set, * but there is possibility of conflicting with the set_rtc_mmss() * call (the rtc irq and the timer irq can easily run at the same * time in two different CPUs). So we need to serialize * accesses to the chip with the rtc_lock spinlock that each * architecture should implement in the timer code. * (See ./arch/XXXX/kernel/time.c for the set_rtc_mmss() function.) */static irqreturn_t rtc_interrupt(int irq, void *dev_id)&#123; /* * Can be an alarm interrupt, update complete interrupt, * or a periodic interrupt. We store the status in the * low byte and the number of interrupts received since * the last read in the remainder of rtc_irq_data. */ spin_lock(&amp;rtc_lock); //保证rtc_irq_data不被SMP机器上其他处理器同时访问 rtc_irq_data += 0x100; rtc_irq_data &amp;= ~0xff; if (is_hpet_enabled()) &#123; /* * In this case it is HPET RTC interrupt handler * calling us, with the interrupt information * passed as arg1, instead of irq. */ rtc_irq_data |= (unsigned long)irq &amp; 0xF0; &#125; else &#123; rtc_irq_data |= (CMOS_READ(RTC_INTR_FLAGS) &amp; 0xF0); &#125; if (rtc_status &amp; RTC_TIMER_ON) mod_timer(&amp;rtc_irq_timer, jiffies + HZ/rtc_freq + 2*HZ/100); spin_unlock(&amp;rtc_lock); /* Now do the rest of the actions */ spin_lock(&amp;rtc_task_lock); //避免rtc_callback出现系统情况，RTC驱动允许注册一个回调函数在每个RTC中断到来时执行。 if (rtc_callback) rtc_callback-&gt;func(rtc_callback-&gt;private_data); spin_unlock(&amp;rtc_task_lock); wake_up_interruptible(&amp;rtc_wait); kill_fasync(&amp;rtc_async_queue, SIGIO, POLL_IN); return IRQ_HANDLED;&#125; 在内核中，中断的旅程开始于预定义入口点，这类似于系统调用。对于每条中断线，处理器都会跳到对应的一个唯一的位置。这样，内核就可以知道所接收中断的IRQ号了。初始入口点只是在栈中保存这个号，并存放当前寄存器的值(这些值属于被中断的任务)；然后，内核调用函数do_IRQ().从这里开始，大多数中断处理代码是用C写的。do_IRQ()的声明如下：1unsigned int do_IRQ(struct pt_regs regs) 因为C的调用惯例是要把函数参数放在栈的顶部，因此pt_regs结构包含原始寄存器的值，这些值是以前在汇编入口例程中保存在栈上的。中断的值也会得以保存，所以，do_IRQ()可以将它提取出来，X86的代码为：1int irq = regs.orig_eax &amp; 0xff 计算出中断号后，do_IRQ()对所接收的中断进行应答，禁止这条线上的中断传递。在普通的PC机器上，这些操作是由mask_and_ack_8259A()来完成的，该函数由do_IRQ()调用。接下来，do_IRQ()需要确保在这条中断线上有一个有效的处理程序，而且这个程序已经启动但是当前没有执行。如果这样的话， do_IRQ()就调用handle_IRQ_event()来运行为这条中断线所安装的中断处理程序，函数位于&lt;kernel/irq/handle.c&gt;:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970/** * handle_IRQ_event - irq action chain handler * @irq: the interrupt number * @action: the interrupt action chain for this irq * * Handles the action chain of an irq event */ irqreturn_t handle_IRQ_event(unsigned int irq, struct irqaction *action)&#123; irqreturn_t ret, retval = IRQ_NONE; unsigned int status = 0; //如果没有设置IRQF_DISABLED，将CPU中断打开，应该尽量避免中断关闭情况，本地中断关闭情况下会导致中断丢失。 if (!(action-&gt;flags &amp; IRQF_DISABLED)) local_irq_enable_in_hardirq(); do &#123; //遍历运行中断处理程序 trace_irq_handler_entry(irq, action); ret = action-&gt;handler(irq, action-&gt;dev_id); trace_irq_handler_exit(irq, action, ret); switch (ret) &#123; case IRQ_WAKE_THREAD: /* * Set result to handled so the spurious check * does not trigger. */ ret = IRQ_HANDLED; /* * Catch drivers which return WAKE_THREAD but * did not set up a thread function */ if (unlikely(!action-&gt;thread_fn)) &#123; warn_no_thread(irq, action); break; &#125; /* * Wake up the handler thread for this * action. In case the thread crashed and was * killed we just pretend that we handled the * interrupt. The hardirq handler above has * disabled the device interrupt, so no irq * storm is lurking. */ if (likely(!test_bit(IRQTF_DIED, &amp;action-&gt;thread_flags))) &#123; set_bit(IRQTF_RUNTHREAD, &amp;action-&gt;thread_flags); wake_up_process(action-&gt;thread); &#125; /* Fall through to add to randomness */ case IRQ_HANDLED: status |= action-&gt;flags; break; default: break; &#125; retval |= ret; action = action-&gt;next; &#125; while (action); if (status &amp; IRQF_SAMPLE_RANDOM) add_interrupt_randomness(irq); local_irq_disable();//关中断 return retval;&#125; 前面说到中断应该尽快执行完，以保证被中断代码可以尽快的恢复执行。但事实上中断通常有很多工作要做，包括应答、重设硬件、数据拷贝、处理请求、发送请求等。为了求得平衡，内核把中断处理工作分成两半，中断处理程序是上半部——接收到中断就开始执行。能够稍后完成的工作推迟到下半部操作，下半部在合适的时机被开中段执行。例如网卡收到数据包时立即发出中断，内核执行网卡已注册的中断处理程序，此处工作就是通知硬件拷贝最新的网络数据包到内存，然后将控制权交换给系统之前被中断的任务，其他的如处理和操作数据包等任务被放到随后的下半部中去执行。下一节我们将了解中断处理的下半部。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把握linux内核设计思想（一）：系统调用]]></title>
    <url>%2F2019%2F05%2F14%2F%E6%8A%8A%E6%8F%A1linux%E5%86%85%E6%A0%B8%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[【版权声明：尊重原创，转载请保留出处：blog.csdn.net/shallnet，文章仅供学习交流，请勿用于商业用途】一般情况下进程不能访问内核所占内存空间也不能调用内核函数。为了和用户空间上运行的进程进行交互，内核提供了一组接口。透过该接口，应用程序可以访问硬件设备和其他操作系统资源。这组接口在应用程序和内核之间扮演了使者的角色，应用程序发送各种请求，而内核负责满足这些请求(或者让应用程序暂时搁置)。系统调用就是用户空间应用程序和内核提供的服务之间的一个接口。 系统调用在用户空间进程和硬件设备之间添加了一个中间层，其为用户空间提供了一种统一的硬件的抽象接口，保证了系统的稳定和安全，使用户程序具有可移植性。例如fork(),read(), write()等用户程序可以使用的函数都是系统调用。 用户空间的程序无法直接执行内核代码。它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。那么应用程序应该以何种方式通知系统，系统如何切换到内核态？ 其实这种改变是通过软中断来实现。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。x86系统上的软中断由int产生。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并执行0x80号异常处理程序。此时的异常处理程序实际上就是系统调用处理程序，该处理程序的名字为system_call,它与硬件体系结构紧密相关。对于x86-32系统来说，该处理程序位于arch/x86/kernel/entry_32.S文件中,代码为：1234567891011121314151617181920212223242526...... # system call handler stubENTRY(system_call) RING0_INT_FRAME # can&apos;t unwind into user space anyway pushl %eax # save orig_eax CFI_ADJUST_CFA_OFFSET 4 SAVE_ALL GET_THREAD_INFO(%ebp) # system call tracing in operation / emulation testl $_TIF_WORK_SYSCALL_ENTRY,TI_flags(%ebp) jnz syscall_trace_entry cmpl $(nr_syscalls), %eax jae syscall_badsyssyscall_call: call *sys_call_table(,%eax,4) //此处执行相应的系统调用 movl %eax,PT_EAX(%esp) # store the return valuesyscall_exit: LOCKDEP_SYS_EXIT DISABLE_INTERRUPTS(CLBR_ANY) # make sure we don&apos;t miss an interrupt # setting need_resched or sigpending # between sampling and the iret TRACE_IRQS_OFF movl TI_flags(%ebp), %ecx testl $_TIF_ALLWORK_MASK, %ecx # current-&gt;work jne syscall_exit_work ...... 在Linux中，每个系统调用被赋予一个系统调用号。这样，通过这个独一无二的号就可以关联系统调用。当用户空间的进程执行一个系统调用的时候，这个系统调用号就被用来指明到底是要执行哪个系统调用。进程不会提及系统调用的名称。系统调用号定义文件以及形式如下：1234567891011121314$ cat ./arch/x86/include/asm/unistd.h#ifdef __KERNEL__ # ifdef CONFIG_X86_32# include &quot;unistd_32.h&quot;# else# include &quot;unistd_64.h&quot;# endif#else# ifdef __i386__# include &quot;unistd_32.h&quot;# else# include &quot;unistd_64.h&quot;# endif#endif 12345678910111213141516171819202122232425262728293031# cat arch/x86/include/asm/unistd_32.h#ifndef _ASM_X86_UNISTD_32_H#define _ASM_X86_UNISTD_32_H/* * This file contains the system call numbers. */#define __NR_restart_syscall 0#define __NR_exit 1#define __NR_fork 2#define __NR_read 3#define __NR_write 4#define __NR_open 5#define __NR_close 6#define __NR_waitpid 7#define __NR_creat 8#define __NR_link 9#define __NR_unlink 10#define __NR_execve 11#define __NR_chdir 12#define __NR_time 13#define __NR_mknod 14#define __NR_chmod 15#define __NR_lchown 16#define __NR_break 17#define __NR_oldstat 18#define __NR_lseek 19#define __NR_getpid 20#define __NR_mount 21...... 系统调用号相当关键，一旦分配就不能再有任何变更，否则编译好的应用程序就会崩溃。Linux有一个“未实现”系统调用sys_ni_syscall()，它除了返回一ENOSYS外不做任何其他工作，这个错误号就是专门针对无效的系统调用而设的。 因为所有的系统调用陷入内核的方式都一样，所以仅仅是陷入内核空间是不够的。因此必须把系统调用号一并传给内核。在x86上，系统调用号是通过eax寄存器传递给内核的。在陷人内核之前，用户空间就把相应系统调用所对应的号放入eax中了。这样系统调用处理程序一旦运行，就可以从eax中得到数据。其他体系结构上的实现也都类似。 内核记录了系统调用表中的所有已注册过的系统调用的列表，存储在sys_call_table中。它与体系结构有关，32位x86一般定义在arch/x86/kernel/syscall_table_32.s文件中。这个表中为每一个有效的系统调用指定了惟一的系统调用号。sys_call_table是一张由指向实现各种系统调用的内核函数的函数指针组成的表。syscall_table_32.s文件如下：1234567891011121314151617181920212223242526ENTRY(sys_call_table) .long sys_restart_syscall /* 0 - old &quot;setup()&quot; system call, used for restarting */ .long sys_exit .long ptregs_fork .long sys_read .long sys_write .long sys_open /* 5 */ .long sys_close .long sys_waitpid .long sys_creat .long sys_link .long sys_unlink /* 10 */ .long ptregs_execve ...... .long sys_timerfd_settime /* 325 */ .long sys_timerfd_gettime .long sys_signalfd4 .long sys_eventfd2 .long sys_epoll_create1 .long sys_dup3 /* 330 */ .long sys_pipe2 .long sys_inotify_init1 .long sys_preadv .long sys_pwritev .long sys_rt_tgsigqueueinfo /* 335 */ .long sys_perf_event_open system_call()函数通过将给定的系统调用号与NR_syscalls做比较来检查其有效性。如果它大于或者等于NR syscalls,该函数就返回一ENOSYS。否则，就执行相应的系统调用。1call *sys_call_table(，%eax, 4) 由于系统调用表中的表项是以32位(4字节)类型存放的，所以内核需要将给定的系统调用号乘以4，然后用所得的结果在该表中查询其位置。 除了系统调用号以外，大部分系统调用都还需要一些外部的参数输入。所以，在发生异常的时候，应该把这些参数从用户空间传给内核。最简单的办法就是像传递系统调用号一样把这些参数也存放在寄存器里。在x86系统上，ebx, ecx, edx, esi和edi按照顺序存放前五个参数。需要六个或六个以上参数的情况不多见，此时，应该用一个单独的寄存器存放指向所有这些参数在用户空间地址的指针。给用户空间的返回值也通过寄存器传递。在x86系统上，它存放在eax寄存器中。下面我们看看用中断的方式如何完成系统调用功能：1234567891011121314151617#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;int main(int argc, const char *argv[])&#123; pid_t pid; asm volatile ( &quot;mov $0, %%ebx\n\t&quot; &quot;mov $20, %%eax\n\t&quot; //把系统调用号20放入eax寄存器中，20对应于SYS_getpid()系统调用 &quot;int $0x80\n\t&quot; //0x80中断 &quot;mov %%eax, %0\n\t&quot; //将执行结果存放在pid变量中 :&quot;=m&quot;(pid) ); printf(&quot;int PID: %d\n&quot;, pid); printf(&quot;api PID: %d\n&quot;, getpid()); return 0;&#125; 此处没有传递参数，因为getpid不需要参数。本实例执行结果为：123$ ./target_binint PID: 4911api PID: 4911 一般情况下，应用程序通过在用户空间实现的应用编程接口（API）而不是系统调用来编程。API是一个函数定义，说明了如何获得一个给定的服务，比如read()、malloc()、free（）、abs()等。它有可能和系统调用形式上一致，比如read()接口就和read系统调用对应，但这种对应并非一一对应，往往会出现几种不同的API内部用到统一个系统调用，比如malloc()、free（）内部利用brk( )系统调用来扩大或缩小进程的堆；或一个API利用了好几个系统调用组合完成服务。更有些API甚至不需要任何系统调用——因为它不必需要内核服务，如计算整数绝对值的abs（）接口。 Linux的用户编程接口遵循了在Unix世界中最流行的应用编程界面标准——POSIX标准，这套标准定义了一系列API。在Linux中（Unix也如此）这些API主要是通过C库（libc）实现的，它除了定义的一些标准的C函数外，一个很重要的任务就是提供了一套封装例程将系统调用在用户空间包装后供用户编程使用。不过封装并非必须的，如果你愿意直接调用，内核也提供了一个syscall()函数来实现调用。如下示例为使用c库调用和直接调用分别来获取当前进程ID：12345678910111213#include &lt;stdio.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/syscall.h&gt;int main(int argc, const char *argv[])&#123; pid_t pid, pidt; pid = getpid(); pidt = syscall(SYS_getpid); printf(&quot;getpid: %d\n&quot;, pid); printf(&quot;SYS_getpid: %d\n&quot;, pidt); return 0;&#125; 系统调用在内核有一个实现函数，以getpid为例，其在内核实现为：12345678910111213/** * sys_getpid - return the thread group id of the current process * * Note, despite the name, this returns the tgid not the pid. The tgid and * the pid are identical unless CLONE_THREAD was specified on clone() in * which case the tgid is the same in all threads of the same group. * * This is SMP safe as current-&gt;tgid does not change. */SYSCALL_DEFINE0(getpid)&#123; return task_tgid_vnr(current);&#125; 其中SYSCALL_DEFINE0为一个宏，它定义一个无参数（尾部数字代表参数个数）的系统调用，展开后代码如下：1234asmlinkage long sys_getpid(void)&#123; return current-&gt;tpid;&#125; 其中asmlinkage 是一个编译指令，通知编译器仅从栈中提取该函数参数，所有系统调用都需要这个限定词。系统调用getpid()在内核中被定义成sys_getpid()，这是linux所有系统调用都应该遵守的命名规则。 下面总结一下系统调用的实现过程：Linux中实现系统调用利用了0x86体系结构中的软件中断，也就是调用int $0x80汇编指令，这条汇编指令将产生向量为128的编程异常，此时处理器切换到内核态并执行0x80号异常处理程序。此时的异常处理程序实际上就是系统调用处理程序，该处理程序的名字为system_call()，对于x86-32系统来说，该处理程序位于arch/x86/kernel/entry_32.S文件中，使用汇编语言编写。那么所有的系统调用都会转到这里。在执行int0x80前，系统调用号被装入eax寄存器（相应参数也会传递到其它寄存器中），这个系统调用号被用来指明到底是要执行哪个系统调用，这样系统调用处理程序一旦运行，就从eax中得到系统调用号，然后根据系统调用号在系统调用表中寻找相应服务例程（例如sys_getpid()函数）。当服务例程结束时，system_call( ) 从eax获得系统调用的返回值，并把这个返回值存放在曾保存用户态 eax寄存器栈单元的那个位置上，最后该函数再负责切换到用户空间，使用户进程继续执行。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[23种设计模式总结]]></title>
    <url>%2F2019%2F05%2F14%2F23%E7%A7%8D%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式总结: 前言：个人觉得设计模式就是各个对象在不同的时机、不同的调用方被创建，组合结构和封装的侧重点有些不同，从而形成了各个模式的概念。 简单工厂模式通过在工厂类中进行判断，然后创建需要的功能类。简单工厂模式是工厂模式中最简单的一种，他可以用比较简单的方式隐藏创建对象的细节，一般只需要告诉工厂类所需要的类型，工厂类就会返回需要的产品类，但客户端看到的只是产品的抽象对象，无需关心到底是返回了哪个子类。客户端唯一需要知道的具体子类就是工厂子类。除了这点，基本是达到了依赖倒转原则的要求。 假如，我们不用工厂类，只用AbstractProduct和它的子类，那客户端每次使用不同的子类的时候都需要知道到底是用哪一个子类，当类比较少的时候还没什么问题，但是当类比较多的时候，管理起来就非常的麻烦了，就必须要做大量的替换，一个不小心就会发生错误。 而使用了工厂类之后，就不会有这样的问题，不管里面多少个类，我只需要知道类型号即可。不过，这里还有一个疑问，那就是如果我每次用工厂类创建的类型都不相同，这样修改起来的时候还是会出现问题，还是需要大量的替换。所以简单工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。 客户只需要知道SimpleFactory就可以了，使用的时候也是使用的AbstractFactory，这样客户端只在第一次创建工厂的时候是知道具体的细节的，其他时候它都只知道AbstractFactory，这样就完美的达到了依赖倒转的原则。 常用的场景：例如部署多种数据库的情况，可能在不同的地方要使用不同的数据库，此时只需要在配置文件中设定数据库的类型，每次再根据类型生成实例，这样，不管下面的数据库类型怎么变化，在客户端看来都是只有一个AbstractProduct，使用的时候根本无需修改代码。提供的类型也可以用比较便于识别的字符串，这样不用记很长的类名，还可以保存为配置文件。这样，每次只需要修改配置文件和添加新的产品子类即可。所以简单工厂模式一般应用于多种同类型类的情况，将这些类隐藏起来，再提供统一的接口，便于维护和修改。 优点 隐藏了对象创建的细节，将产品的实例化推迟到子类中实现。 客户端基本不用关心使用的是哪个产品，只需要知道用哪个工厂就行了，提供的类型也可以用比较便于识别的字符串。 方便添加新的产品子类，每次只需要修改工厂类传递的类型值就行了。 遵循了依赖倒转原则。 缺点 要求产品子类的类型差不多，使用的方法名都相同，如果类比较多，而所有的类又必须要添加一种方法，则会是非常麻烦的事情。或者是一种类另一种类有几种方法不相同，客户端无法知道是哪一个产品子类，也就无法调用这几个不相同的方法。 每添加一个产品子类，都必须在工厂类中添加一个判断分支，这违背了开放-封闭原则。 代码演示：抽象产品类代码：12345678910namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象产品类： 汽车 /// &lt;/summary&gt; public interface ICar &#123; void GetCar(); &#125;&#125; 具体产品类代码：123456789101112131415161718192021222324252627282930313233343536373839404142namespace CNBlogs.DesignPattern.Common&#123; public enum CarType &#123; SportCarType = 0, JeepCarType = 1, HatchbackCarType = 2 &#125; /// &lt;summary&gt; /// 具体产品类： 跑车 /// &lt;/summary&gt; public class SportCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把跑车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 越野车 /// &lt;/summary&gt; public class JeepCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把越野车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 两箱车 /// &lt;/summary&gt; public class HatchbackCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把两箱车交给范·迪塞尔&quot;); &#125; &#125;&#125; 简单工厂核心代码：1234567891011121314151617181920namespace CNBlogs.DesignPattern.Common&#123; public class Factory &#123; public ICar GetCar(CarType carType) &#123; switch (carType) &#123; case CarType.SportCarType: return new SportCar(); case CarType.JeepCarType: return new JeepCar(); case CarType.HatchbackCarType: return new HatchbackCar(); default: throw new Exception(&quot;爱上一匹野马,可我的家里没有草原. 你走吧！&quot;); &#125; &#125; &#125;&#125; 客户端调用代码：1234567891011121314151617181920212223242526272829303132//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; ICar car; try &#123; Factory factory = new Factory(); Console.WriteLine(&quot;范·迪塞尔下一场戏开跑车。&quot;); car = factory.GetCar(CarType.SportCarType); car.GetCar(); &#125; catch (Exception ex) &#123; Console.WriteLine(ex.Message); &#125; &#125; &#125;&#125; 策略模式假设一个功能类是一个策略，调用的时候需要创建这个策略的实例，传进一个类似策略控制中心的方法中，然后通过策略基类调用这个传进去的实例子类的方法。 优点：就是相对工厂模式免去了创建那个功能类的判断，简化了工厂模式。缺点：就是把子类实例赋值给了父类，这样就丢掉了子类新增的功能。 工厂方法模式(属于工厂模式)把简单工厂模式中的工厂类，做了进一步的抽象为接口或抽象类，给各个功能创建一个对应的工厂类，然后在这个工厂类里面去创建对应的实例。工厂模式基本与简单工厂模式差不多，上面也说了，每次添加一个产品子类都必须在工厂类中添加一个判断分支，这样违背了开放-封闭原则，因此，工厂模式就是为了解决这个问题而产生的。 既然每次都要判断，那我就把这些判断都生成一个工厂子类，这样，每次添加产品子类的时候，只需再添加一个工厂子类就可以了。这样就完美的遵循了开放-封闭原则。但这其实也有问题，如果产品数量足够多，要维护的量就会增加，好在一般工厂子类只用来生成产品类，只要产品子类的名称不发生变化，那么基本工厂子类就不需要修改，每次只需要修改产品子类就可以了。 同样工厂模式一般应该于程序中大部分地方都只使用其中一种产品，工厂类也不用频繁创建产品类的情况。这样修改的时候只需要修改有限的几个地方即可。 常用的场景基本与简单工厂模式一致，只不过是改进了简单工厂模式中的开放-封闭原则的缺陷，使得模式更具有弹性。将实例化的过程推迟到子类中，由子类来决定实例化哪个。 优点：基本与简单工厂模式一致，多的一点优点就是遵循了开放-封闭原则，使得模式的灵活性更强。缺点：当新增一个功能类，就需要创建对于的工厂类，相比简单工厂模式，免去了判断创建那个具体实例，但会创建过多的类，还不如策略模式。 代码演示： 抽象工厂代码：1234567namespace CNBlogs.DesignPattern.Common&#123; public interface IFactory &#123; ICar CreateCar(); &#125;&#125; 抽象产品代码：1234567namespace CNBlogs.DesignPattern.Common&#123; public interface ICar &#123; void GetCar(); &#125;&#125; 具体工厂代码：1234567891011121314151617181920212223242526272829303132333435namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 具体工厂类： 用于创建跑车类 /// &lt;/summary&gt; public class SportFactory : IFactory &#123; public ICar CreateCar() &#123; return new SportCar(); &#125; &#125; /// &lt;summary&gt; /// 具体工厂类： 用于创建越野车类 /// &lt;/summary&gt; public class JeepFactory : IFactory &#123; public ICar CreateCar() &#123; return new JeepCar(); &#125; &#125; /// &lt;summary&gt; /// 具体工厂类： 用于创建两厢车类 /// &lt;/summary&gt; public class HatchbackFactory : IFactory &#123; public ICar CreateCar() &#123; return new HatchbackCar(); &#125; &#125;&#125; 具体产品代码：1234567891011121314151617181920212223242526272829303132333435namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 具体产品类： 跑车 /// &lt;/summary&gt; public class SportCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把跑车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 越野车 /// &lt;/summary&gt; public class JeepCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把越野车交给范·迪塞尔&quot;); &#125; &#125; /// &lt;summary&gt; /// 具体产品类： 两箱车 /// &lt;/summary&gt; public class HatchbackCar : ICar &#123; public void GetCar() &#123; Console.WriteLine(&quot;场务把两箱车交给范·迪塞尔&quot;); &#125; &#125;&#125; 客户端代码：12345678910111213141516171819202122232425262728293031323334//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System.IO; using System.Configuration; using System.Reflection; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; // 工厂类的类名写在配置文件中可以方便以后修改 string factoryType = ConfigurationManager.AppSettings[&quot;FactoryType&quot;]; // 这里把DLL配置在数据库是因为以后数据可能发生改变 // 比如说现在的数据是从sql server取的，以后需要从oracle取的话只需要添加一个访问oracle数据库的工程就行了 string dllName = ConfigurationManager.AppSettings[&quot;DllName&quot;]; // 利用.NET提供的反射可以根据类名来创建它的实例，非常方便 var currentAssembly = System.Reflection.Assembly.GetExecutingAssembly(); string codeBase = currentAssembly.CodeBase.ToLower().Replace(currentAssembly.ManifestModule.Name.ToLower(), string.Empty); IFactory factory = Assembly.LoadFrom(Path.Combine(codeBase, dllName)).CreateInstance(factoryType) as IFactory; ICar car = factory.CreateCar(); car.GetCar(); &#125; &#125;&#125; 装饰模式一般情况下，当一个基类写好之后，我们也许不愿意去改动，也不能改动，原因是这样的在项目中用得比较久的基类，一旦改动，也许会影响其他功能模块，但是，又要在该类上面添加功能。使用继承，当在A阶段，写出继承类，用过一段时间，发现又要添加新功能，于是又要从原始类或A阶段的类继承，周而复始，慢慢的，子类就越来越多，层级就越来越深。然而，事实上，在C阶段需要A阶段的功能，但不需要B阶段的功能，在这种复杂情形下，继承就显得不灵活，于是想到了装饰模式。装饰模式：需要扩展一个类的功能，或给一个类增加附加责任需要动态地给一个对象增加功能，这些功能可以再动态地撤销。需要增加由一些基本功能的排列组合而产生的非常大量的功能，从而使继承关系变得不现实。 在使用装饰模式前，需要了解虚方法和抽象方法的区别：虚方法，是实例方法，可以在子类中覆盖，也可以由该类对象直接调用。抽象方法需要写在抽象类中，抽象类不能实例化，所以要使用抽象方法必须由子类实现后方可调用。 该模式中，要被扩展的类可以是包含抽象方法的抽象类，也可以是包含虚方法的实例类，也可以是普通实例类。装饰模式就是在原有基类上做扩展，至于基类是什么性质并不重要. 装饰模式在C#代码，和扩展方法，惊人的类似。 Component为统一接口，也是装饰类和被装饰类的基本类型。 ConcreteComponent为具体实现类，也是被装饰类，他本身是个具有一些功能的完整的类。 Decorator是装饰类，实现了Component接口的同时还在内部维护了一个ConcreteComponent的实例，并可以通过构造函数初始化。而Decorator本身，- 通常采用默认实现，他的存在仅仅是一个声明：我要生产出一些用于装饰的子类了。而其子类才是赋有具体装饰效果的装饰产品类。 ConcreteDecorator是具体的装饰产品类，每一种装饰产品都具有特定的装饰效果。可以通过构造器声明装饰哪种类型的ConcreteComponent，从而对其进行装饰。 最简单的代码实现装饰器模式 123456789101112131415161718192021222324252627282930313233343536373839404142//基础接口public interface Component &#123; public void biu();&#125;//具体实现类public class ConcretComponent implements Component &#123; public void biu() &#123; System.out.println(&quot;biubiubiu&quot;); &#125;&#125;//装饰类public class Decorator implements Component &#123; public Component component; public Decorator(Component component) &#123; this.component = component; &#125; public void biu() &#123; this.component.biu(); &#125;&#125;//具体装饰类public class ConcreteDecorator extends Decorator &#123; public ConcreteDecorator(Component component) &#123; super(component); &#125; public void biu() &#123; System.out.println(&quot;ready?go!&quot;); this.component.biu(); &#125;&#125; 这样一个基本的装饰器体系就出来了，当我们想让Component在打印之前都有一个ready？go！的提示时，就可以使用ConcreteDecorator类了。具体方式如下： 1234567 //使用装饰器 Component component = new ConcreteDecorator(new ConcretComponent()); component.biu(); //console： ready?go! biubiubiu 为何使用装饰器模式？一个设计模式的出现一定有他特殊的价值。仅仅看见上面的结构图你可能会想，为何要兜这么一圈来实现？仅仅是想要多一行输出，我直接继承ConcretComponent，或者直接在另一个Component的实现类中实现不是一样吗？ 首先，装饰器的价值在于装饰，他并不影响被装饰类本身的核心功能。在一个继承的体系中，子类通常是互斥的。比如一辆车，品牌只能要么是奥迪、要么是宝马，不可能同时属于奥迪和宝马，而品牌也是一辆车本身的重要属性特征。但当你想要给汽车喷漆，换坐垫，或者更换音响时，这些功能是互相可能兼容的，并且他们的存在不会影响车的核心属性：那就是他是一辆什么车。这时你就可以定义一个装饰器：喷了漆的车。不管他装饰的车是宝马还是奥迪，他的喷漆效果都可以实现。 再回到这个例子中，我们看到的仅仅是一个ConcreteComponent类。在复杂的大型项目中，同一级下的兄弟类通常有很多。当你有五个甚至十个ConcreteComponent时，再想要为每个类都加上“ready？go！”的效果，就要写出五个子类了。毫无疑问这是不合理的。装饰器模式在不影响各个ConcreteComponent核心价值的同时，添加了他特有的装饰效果，具备非常好的通用性，这也是他存在的最大价值。 实战中使用装饰器模式 写这篇博客的初衷也是恰好在工作中使用到了这个模式，觉得非常好用。需求大致是这样：采用sls服务监控项目日志，以Json的格式解析，所以需要将项目中的日志封装成json格式再打印。现有的日志体系采用了log4j + slf4j框架搭建而成。调用起来是这样的:12private static final Logger logger = LoggerFactory.getLogger(Component.class);logger.error(string); 这样打印出来的是毫无规范的一行行字符串。在考虑将其转换成json格式时，我采用了装饰器模式。目前有的是统一接口Logger和其具体实现类，我要加的就是一个装饰类和真正封装成Json格式的装饰产品类。具体实现代码如下：123456789101112131415161718192021222324/** * logger decorator for other extension * this class have no specific implementation * just for a decorator definition * @author jzb * */public class DecoratorLogger implements Logger &#123; public Logger logger; public DecoratorLogger(Logger logger) &#123; this.logger = logger; &#125; @Override public void error(String str) &#123;&#125; @Override public void info(String str) &#123;&#125; //省略其他默认实现&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * json logger for formatted output * @author jzb * */public class JsonLogger extends DecoratorLogger &#123;public JsonLogger(Logger logger) &#123; super(logger); &#125; @Override public void info(String msg) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;MESSAGE&quot;, msg); logger.info(result.toString()); &#125; @Override public void error(String msg) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;MESSAGE&quot;, msg); logger.error(result.toString()); &#125; public void error(Exception e) &#123; JSONObject result = composeBasicJsonResult(); result.put(&quot;EXCEPTION&quot;, e.getClass().getName()); String exceptionStackTrace = ExceptionUtils.getStackTrace(e); result.put(&quot;STACKTRACE&quot;, exceptionStackTrace); logger.error(result.toString()); &#125; public static class JsonLoggerFactory &#123; @SuppressWarnings(&quot;rawtypes&quot;) public static JsonLogger getLogger(Class clazz) &#123; Logger logger = LoggerFactory.getLogger(clazz); return new JsonLogger(logger); &#125; &#125; private JSONObject composeBasicJsonResult() &#123; //拼装了一些运行时信息 &#125;&#125; 可以看到，在JsonLogger中，对于Logger的各种接口，我都用JsonObject对象进行一层封装。在打印的时候，最终还是调用原生接口logger.error(string)，只是这个string参数已经被我们装饰过了。如果有额外的需求，我们也可以再写一个函数去实现。比如error(Exception e)，只传入一个异常对象，这样在调用时就非常方便了。 另外，为了在新老交替的过程中尽量不改变太多的代码和使用方式。我又在JsonLogger中加入了一个内部的工厂类JsonLoggerFactory（这个类转移到DecoratorLogger中可能更好一些），他包含一个静态方法，用于提供对应的JsonLogger实例。最终在新的日志体系中，使用方式如下：12private static final Logger logger = JsonLoggerFactory.getLogger(Component.class);logger.error(string); 他唯一与原先不同的地方，就是LoggerFactory -&gt; JsonLoggerFactory，这样的实现，也会被更快更方便的被其他开发者接受和习惯。 代理模式代理类成为实际想调用对象的中间件，可以控制对实际调用对象的访问权限；维护实际调用对象的一个引用。 原型模式创建好了一个实例，然后用这个实例，通过克隆方式创建另一个同类型的实例，而不必关心这个新实例是如何创建的。 原型模式使用时需要注意浅拷贝与深拷贝的问题。 建造者模式每个对象都具备自己的功能，但是，它们的创建方式却是一样的。这个时候就需要中间这个建造者类来负责功能对象实例的创建。在调用端只需调用特定的方法即可。 这个和策略模式有点类似。 抽象工厂模式使用该功能类的功能类，利用抽象工厂去创建该功能类的实例。这样的好处在于尽可能的避免去创建功能的实例。更牛逼的做法就是使用反射去创建这个功能类的实例，在调用端就一点都不需要知道要去实例化那个具体的功能类。这当然不是抽象工厂模式独有的。抽象工厂模式就变得比工厂模式更为复杂，就像上面提到的缺点一样，工厂模式和简单工厂模式要求产品子类必须要是同一类型的，拥有共同的方法，这就限制了产品子类的扩展。于是为了更加方便的扩展，抽象工厂模式就将同一类的产品子类归为一类，让他们继承同一个抽象子类，我们可以把他们一起视作一组，然后好几组产品构成一族。 此时，客户端要使用时必须知道是哪一个工厂并且是哪一组的产品抽象类。每一个工厂子类负责产生一族产品，而子类的一种方法产生一种类型的产品。在客户端看来只有AbstractProductA和AbstractProductB两种产品，使用的时候也是直接使用这两种产品。而通过工厂来识别是属于哪一族产品。 产品ProductA_1和ProductB_1构成一族产品，对应于有Factory1来创建，也就是说Factory1总是创建的ProductA_1和ProductB_1的产品，在客户端看来只需要知道是哪一类工厂和产品组就可以了。一般来说， ProductA_1和ProductB_1都是适应同一种环境的，所以他们会被归为一族。 常用的场景例如Linux和windows两种操作系统下，有2个挂件A和B，他们在Linux和Windows下面的实现方式不同，Factory1负责产生能在Linux下运行的挂件A和B，Factory2负责产生能在Windows下运行的挂件A和B，这样如果系统环境发生变化了，我们只需要修改工厂就行了。 优点 封装了产品的创建，使得不需要知道具体是哪种产品，只需要知道是哪个工厂就行了。 可以支持不同类型的产品，使得模式灵活性更强。 可以非常方便的使用一族中间的不同类型的产品。 缺点 结构太过臃肿，如果产品类型比较多，或者产品族类比较多，就会非常难于管理。 每次如果添加一组产品，那么所有的工厂类都必须添加一个方法，这样违背了开放-封闭原则。所以一般适用于产品组合产品族变化不大的情况。 抽象工厂代码：1234567891011121314151617181920namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象工厂类 /// &lt;/summary&gt; public abstract class AbstractEquipment &#123; /// &lt;summary&gt; /// 抽象方法： 创建一辆车 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public abstract AbstractCar CreateCar(); /// &lt;summary&gt; /// 抽象方法： 创建背包 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public abstract AbstractBackpack CreateBackpack(); &#125;&#125; 抽象产品代码：12345678910111213141516171819202122232425262728293031323334353637383940414243444546namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 抽象产品: 车抽象类 /// &lt;/summary&gt; public abstract class AbstractCar &#123; /// &lt;summary&gt; /// 车的类型属性 /// &lt;/summary&gt; public abstract string Type &#123; get; &#125; /// &lt;summary&gt; /// 车的颜色属性 /// &lt;/summary&gt; public abstract string Color &#123; get; &#125; &#125; /// &lt;summary&gt; /// 抽象产品: 背包抽象类 /// &lt;/summary&gt; public abstract class AbstractBackpack &#123; /// &lt;summary&gt; /// 包的类型属性 /// &lt;/summary&gt; public abstract string Type &#123; get; &#125; /// &lt;summary&gt; /// 包的颜色属性 /// &lt;/summary&gt; public abstract string Color &#123; get; &#125; &#125;&#125; 具体工厂代码：12345678910111213141516171819202122232425262728293031323334namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 运动装备 /// &lt;/summary&gt; public class SportEquipment : AbstractEquipment &#123; public override AbstractCar CreateCar() &#123; return new SportCar(); &#125; public override AbstractBackpack CreateBackpack() &#123; return new SportBackpack(); &#125; &#125; /// &lt;summary&gt; /// 越野装备 这里就不添加了，同运动装备一个原理，demo里只演示一个，实际项目中可以按需添加 /// &lt;/summary&gt; //public class JeepEquipment : AbstractEquipment //&#123; // public override AbstractCar CreateCar() // &#123; // return new JeeptCar(); // &#125; // public override AbstractBackpack CreateBackpack() // &#123; // return new JeepBackpack(); // &#125; //&#125;&#125; 具体产品代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465namespace CNBlogs.DesignPattern.Common&#123; /// &lt;summary&gt; /// 跑车 /// &lt;/summary&gt; public class SportCar : AbstractCar &#123; private string type = &quot;Sport&quot;; private string color = &quot;Red&quot;; /// &lt;summary&gt; /// 重写基类的Type属性 /// &lt;/summary&gt; public override string Type &#123; get &#123; return type; &#125; &#125; /// &lt;summary&gt; /// 重写基类的Color属性 /// &lt;/summary&gt; public override string Color &#123; get &#123; return color; &#125; &#125; &#125; /// &lt;summary&gt; /// 运动背包 /// &lt;/summary&gt; public class SportBackpack : AbstractBackpack &#123; private string type = &quot;Sport&quot;; private string color = &quot;Red&quot;; /// &lt;summary&gt; /// 重写基类的Type属性 /// &lt;/summary&gt; public override string Type &#123; get &#123; return type; &#125; &#125; /// &lt;summary&gt; /// 重写基类的Color属性 /// &lt;/summary&gt; public override string Color &#123; get &#123; return color; &#125; &#125; &#125;&#125;//具体产品可以有很多很多， 至于越野类的具体产品这里就不列出来了。 创建装备代码：1234567891011121314151617181920212223namespace CNBlogs.DesignPattern.Common&#123; public class CreateEquipment &#123; private AbstractCar fanCar; private AbstractBackpack fanBackpack; public CreateEquipment(AbstractEquipment equipment) &#123; fanCar = equipment.CreateCar(); fanBackpack = equipment.CreateBackpack(); &#125; public void ReadyEquipment() &#123; Console.WriteLine(string.Format(&quot;老范背着&#123;0&#125;色&#123;1&#125;包开着&#123;2&#125;色&#123;3&#125;车。&quot;, fanBackpack.Color, fanBackpack.Type, fanCar.Color, fanCar.Type )); &#125; &#125;&#125; 客户端代码：123456789101112131415161718192021222324252627282930313233//------------------------------------------------------------------------------// &lt;copyright file=&quot;Program.cs&quot; company=&quot;CNBlogs Corporation&quot;&gt;// Copyright (C) 2015-2016 All Rights Reserved// 原博文地址： http://www.cnblogs.com/toutou/// 作 者: 请叫我头头哥// &lt;/copyright&gt; //------------------------------------------------------------------------------namespace CNBlogs.DesignPattern&#123; using System; using System.Configuration; using System.Reflection; using CNBlogs.DesignPattern.Common; class Program &#123; static void Main(string[] args) &#123; // ***具体app.config配置如下*** // //&lt;add key=&quot;assemblyName&quot; value=&quot;CNBlogs.DesignPattern.Common&quot;/&gt; //&lt;add key=&quot;nameSpaceName&quot; value=&quot;CNBlogs.DesignPattern.Common&quot;/&gt; //&lt;add key=&quot;typename&quot; value=&quot;SportEquipment&quot;/&gt; // 创建一个工厂类的实例 string assemblyName = ConfigurationManager.AppSettings[&quot;assemblyName&quot;]; string fullTypeName = string.Concat(ConfigurationManager.AppSettings[&quot;nameSpaceName&quot;], &quot;.&quot;, ConfigurationManager.AppSettings[&quot;typename&quot;]); AbstractEquipment factory = (AbstractEquipment)Assembly.Load(assemblyName).CreateInstance(fullTypeName); CreateEquipment equipment = new CreateEquipment(factory); equipment.ReadyEquipment(); Console.Read(); &#125; &#125;&#125; 外观模式外观模式：为外界调用提供一个统一的接口，把其他类中需要用到的方法提取出来，由外观类进行调用。然后在调用段实例化外观类，以间接调用需要的方法。这种方式形式上和代理模式有异曲同工之妙。 模板模式模板模式：其实就是抽象出各个具体操作类的公共操作方法，在子类重新实现,然后使用子类去实例化父类。这个模板类其实可以使用接口替换。事实上接口才是专门用来定义操作规范。当然，当有些公共方法，各个子类均有一致需求，此时就不应使用接口，使用抽象类。 状态模式一个方法的判断逻辑太长，就不容易修改。方法过长，其本质就是，就是本类在不同条件下的状态转移。状态模式，就是将这些判断分开到各个能表示当前状态的独立类中。 备忘录模式备忘录模式：事实上我觉得这个东西没什么用，按照这种方式进行备份，会因为值类型与引用类型的不同而导致数据丢失。 适配器模式适配器模式：其实就是代理模式的一个变种，代码的编写方式都差不多。只是，使用这两种模式的出发点不一样，导致这两种模式产生了细微的差别。 组合模式当对象或系统之间出现部分与整体，或类似树状结构的情况时，考虑组合模式。相对装饰模式来说，这两个有异曲同工之妙，都强调对象间的组合，但是，装饰模式同时强调组合的顺序，而组合模式则是随意组合与移除。 单例模式能避免同一对象被反复实例化。比如说，访问数据库的连接对象就比普通对象实例化的时间要长;WCF中，维护服务器端远程对象的创建等，这类情况，很有必要用单例模式进行处理对象的实例化。 单例模式也称为单件模式、单子模式，可能是使用最广泛的设计模式。其意图是保证一个类仅有一个实例，并提供一个访问它的全局访问点，该实例被所有程序模块共享。有很多地方需要这样的功能模块，如系统的日志输出，GUI应用必须是单鼠标，MODEM的联接需要一条且只需要一条电话线，操作系统只能有一个窗口管理器，一台PC连一个键盘。 单例模式有许多种实现方法，在C++中，甚至可以直接用一个全局变量做到这一点，但这样的代码显的很不优雅。 使用全局对象能够保证方便地访问实例，但是不能保证只声明一个对象——也就是说除了一个全局实例外，仍然能创建相同类的本地实例。《设计模式》一书中给出了一种很不错的实现，定义一个单例类，使用类的私有静态指针变量指向类的唯一实例，并用一个公有的静态方法获取该实例。 单例模式通过类本身来管理其唯一实例，这种特性提供了解决问题的方法。唯一的实例是类的一个普通对象，但设计这个类时，让它只能创建一个实例并提供对此实例的全局访问。唯一实例类Singleton在静态成员函数中隐藏创建实例的操作。习惯上把这个成员函数叫做Instance()，它的返回值是唯一实例的指针。定义如下：123456789101112131415class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125; static CSingleton *m_pInstance;public: static CSingleton * GetInstance() &#123; if(m_pInstance == NULL) //判断是否第一次调用 m_pInstance = new CSingleton(); return m_pInstance; &#125;&#125;; 用户访问唯一实例的方法只有GetInstance()成员函数。如果不通过这个函数，任何创建实例的尝试都将失败，因为类的构造函数是私有的。GetInstance()使用懒惰初始化，也就是说它的返回值是当这个函数首次被访问时被创建的。这是一种防弹设计——所有GetInstance()之后的调用都返回相同实例的指针：123CSingleton* p1 = CSingleton :: GetInstance();CSingleton* p2 = p1-&gt;GetInstance();CSingleton &amp; ref = * CSingleton :: GetInstance(); 对GetInstance稍加修改，这个设计模板便可以适用于可变多实例情况，如一个类允许最多五个实例。 单例类CSingleton有以下特征： 它有一个指向唯一实例的静态指针m_pInstance，并且是私有的； 它有一个公有的函数，可以获取这个唯一的实例，并且在需要的时候创建该实例； 它的构造函数是私有的，这样就不能从别处创建该类的实例。 大多数时候，这样的实现都不会出现问题。有经验的读者可能会问，m_pInstance指向的空间什么时候释放呢？更严重的问题是，该实例的析构函数什么时候执行？如果在类的析构行为中有必须的操作，比如关闭文件，释放外部资源，那么上面的代码无法实现这个要求。我们需要一种方法，正常的删除该实例。可以在程序结束时调用GetInstance()，并对返回的指针掉用delete操作。这样做可以实现功能，但不仅很丑陋，而且容易出错。因为这样的附加代码很容易被忘记，而且也很难保证在delete之后，没有代码再调用GetInstance函数。一个妥善的方法是让这个类自己知道在合适的时候把自己删除，或者说把删除自己的操作挂在操作系统中的某个合适的点上，使其在恰当的时候被自动执行。我们知道，程序在结束的时候，系统会自动析构所有的全局变量。事实上，系统也会析构所有的类的静态成员变量，就像这些静态成员也是全局变量一样。利用这个特征，我们可以在单例类中定义一个这样的静态成员变量，而它的唯一工作就是在析构函数中删除单例类的实例。如下面的代码中的CGarbo类（Garbo意为垃圾工人）：12345678910111213141516171819202122232425class CSingleton&#123;private: CSingleton() &#123; &#125; static CSingleton *m_pInstance; class CGarbo //它的唯一工作就是在析构函数中删除CSingleton的实例 &#123; public: ~CGarbo() &#123; if(CSingleton::m_pInstance) delete CSingleton::m_pInstance; &#125; &#125;; static CGarbo Garbo; //定义一个静态成员变量，程序结束时，系统会自动调用它的析构函数public: static CSingleton * GetInstance() &#123; if(m_pInstance == NULL) //判断是否第一次调用 m_pInstance = new CSingleton(); return m_pInstance; &#125;&#125;; 类CGarbo被定义为CSingleton的私有内嵌类，以防该类被在其他地方滥用。程序运行结束时，系统会调用CSingleton的静态成员Garbo的析构函数，该析构函数会删除单例的唯一实例。使用这种方法释放单例对象有以下特征： 在单例类内部定义专有的嵌套类； 在单例类内定义私有的专门用于释放的静态成员； 利用程序在结束时析构全局变量的特性，选择最终的释放时机； 使用单例的代码不需要任何操作，不必关心对象的释放。 但是添加一个类的静态对象，总是让人不太满意，所以有人用如下方法来重新实现单例和解决它相应的问题，代码如下：12345678910111213class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125;public: static CSingleton &amp; GetInstance() &#123; static CSingleton instance; //局部静态变量 return instance; &#125;&#125;; 使用局部静态变量，非常强大的方法，完全实现了单例的特性，而且代码量更少，也不用担心单例销毁的问题。但使用此种方法也会出现问题，当如下方法使用单例时问题来了，Singleton singleton = Singleton :: GetInstance();这么做就出现了一个类拷贝的问题，这就违背了单例的特性。产生这个问题原因在于：编译器会为类生成一个默认的构造函数，来支持类的拷贝。最后没有办法，我们要禁止类拷贝和类赋值，禁止程序员用这种方式来使用单例，当时领导的意思是GetInstance()函数返回一个指针而不是返回一个引用，函数的代码改为如下：12345678910111213class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125;public: static CSingleton * GetInstance() &#123; static CSingleton instance; //局部静态变量 return &amp;instance; &#125;&#125;; 但我总觉的不好，为什么不让编译器不这么干呢。这时我才想起可以显示的声明类拷贝的构造函数，和重载 = 操作符，新的单例类如下：123456789101112131415class CSingleton&#123;private: CSingleton() //构造函数是私有的 &#123; &#125; CSingleton(const CSingleton &amp;); CSingleton &amp; operator = (const CSingleton &amp;);public: static CSingleton &amp; GetInstance() &#123; static CSingleton instance; //局部静态变量 return instance; &#125;&#125;; 关于Singleton(const Singleton);和 Singleton &amp; operate = (const Singleton&amp;);函数，需要声明成私有的，并且只声明不实现。这样，如果用上面的方式来使用单例时，不管是在友元类中还是其他的，编译器都是报错。不知道这样的单例类是否还会有问题，但在程序中这样子使用已经基本没有问题了。 考虑到线程安全、异常安全，可以做以下扩展12345678910111213141516171819202122232425262728293031323334353637383940414243class Lock&#123;private: CCriticalSection m_cs;public: Lock(CCriticalSection cs) : m_cs(cs) &#123; m_cs.Lock(); &#125; ~Lock() &#123; m_cs.Unlock(); &#125;&#125;; class Singleton&#123;private: Singleton(); Singleton(const Singleton &amp;); Singleton&amp; operator = (const Singleton &amp;); public: static Singleton *Instantialize(); static Singleton *pInstance; static CCriticalSection cs;&#125;; Singleton* Singleton::pInstance = 0; Singleton* Singleton::Instantialize()&#123; if(pInstance == NULL) &#123; //double check Lock lock(cs); //用lock实现线程安全，用资源管理类，实现异常安全 //使用资源管理类，在抛出异常的时候，资源管理类对象会被析构，析构总是发生的无论是因为异常抛出还是语句块结束。 if(pInstance == NULL) &#123; pInstance = new Singleton(); &#125; &#125; return pInstance;&#125; 之所以在Instantialize函数里面对pInstance 是否为空做了两次判断，因为该方法调用一次就产生了对象，pInstance == NULL 大部分情况下都为false，如果按照原来的方法，每次获取实例都需要加锁，效率太低。而改进的方法只需要在第一次 调用的时候加锁，可大大提高效率。 迭代器模式提供一种方法访问一个容器对象中各个元素，而又不需暴露该对象的内部细节。 Foreach就是这种模式应用的代表。 职责链模式职责链模式：就是一个将请求或命令进行转发的流程，类似工作流。并且，也非常类似状态模式，它们共同的特点就是将一个复杂的判断逻辑，转移到各个子类，然后在由子类进行简单判断。 状态模式与职责链模式的区别：状态模式是让各个状态对象自己知道其下一个处理的对象是谁，即在编译时便设定好了的；而职责链模式中的各个对象并不指定其下一个处理的对象到底是谁，只有在客户端才设定。 命令模式当有客户端发送了一系列的命令或请求，去要求某个对象实现什么操作，可使用命令模式，相当于多个命令发给一个对象。 这一点和观察者模式非常的类似。观察者模式也是某个对象，发出消息，然后由中间对象通知观察者然后去做什么，封装的是要执行操作的对象。而命令模式，则是将各个操作封装成类，然后告知某个对象该做什么。两者的区别是封装的角度不同。 桥接模式依据合成/聚合原则，优先使用类之间的不同组合，来实现各个类要表现的功能,而不是使用继承。比如说：继承会延续父类的功能，然而，并不是所有的子类都需要这样的功能，但是抽象出的东西在父类，导致子类又必须要实现它，这样，父类就越来越庞大，子类又多了很多不必要的东西。因此，桥接模式更强调类之间的组合从而实现解耦。 对比组合模式，它更强调的是部分与整体间的组合，桥接模式强调的是平行级别上不同类的组合。 解释器模式举例：写好了C#代码，VB代码，此时需要个编译器来编译。这时，这个编译器就相当于解释器，解释好了交给CPU执行。 解释器跟适配器模式有点类似，但是，适配器模式不需要预先知道要适配的规则，解释器是根据规则去执行解释。 享元模式享元模式其实是为了避免创建过多的数据对象。比如此列：在象棋中只有红黑双方，红棋子只是红棋中的一颗，很多红棋其实可以使用一个红棋对象表示即可，在外部只需公开该棋的状态即可区分那个红棋，从而达到减少内存消耗的目的。 中介者模式中介者模式：中介者类唯一要干的事情就是给各个成员对象发出通知。因此，中介者事先就应该知道有哪些成员。 中介者模式和代理模式，观察者模式非常的像。但是其它两种模式在调用的时候，并不需要事先设置那个类被代理，或是事先那些对象需要被通知。 访问者模式在不改变原有代码的结构上，又想去影响原来的类，或是访问原来类的成员，此时就可以使用访问者模式。但需要注意的是：事先需要构造好那些要访问的对象的对象结构。这个结构在访问者类中去维护。 观察者模式就是消息订阅–发布模式。本来原始的状况是需要在观察者类内部设置需要通知的对象。结果现在出现了事件。定义委托来通知其他对象，显得更简洁。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode861. Score After Flipping Matrix]]></title>
    <url>%2F2019%2F05%2F13%2FLeetcode861%2F</url>
    <content type="text"><![CDATA[We have a two dimensional matrix A where each value is 0 or 1. A move consists of choosing any row or column, and toggling each value in that row or column: changing all 0s to 1s, and all 1s to 0s. After making any number of moves, every row of this matrix is interpreted as a binary number, and the score of the matrix is the sum of these numbers. Return the highest possible score. Example 1:12345Input: [[0,0,1,1],[1,0,1,0],[1,1,0,0]]Output: 39Explanation:Toggled to [[1,1,1,1],[1,0,0,1],[1,1,1,1]].0b1111 + 0b1001 + 0b1111 = 15 + 9 + 15 = 39 Note: 1 &lt;= A.length &lt;= 201 &lt;= A[0].length &lt;= 20A[i][j] is 0 or 1. 思路：对一个只有0和1的二维矩阵，移动是指选择任一行或任一列，将所有的0变成1，所有的1变成0，在作出任意次数的移动后，将该矩阵中的每一行都按照二进制数来解释，输出和的最大值。要注意的是行和列任意次移动，达到最大值。即以求出最优解为目标（可重复移动）。按二进制数来解释，注意数组[0-n]对应二进制“高位-低位”。 首先对行移动求最优解：二进制数，高位的有效值“1”大于后面所有位数之和，举个例子：10000=16 01010=10 00111=7。所以我们需要判断A[i]0是否为“1”，将为“0”的进行移动操作，本行即达到最优。重复每行即为所有行最优 再对列移动求最优解：本题为矩阵，所以同一列的数字在二进制解释中位于相同的位置（2^n），当一列中”1”的数量最大时,结果值最大。即为列最优解，同理求出所有列最优解。 最后计算矩阵的总和，注意从低位（数组尾部开始计算）。 若行最高位（数组行首元素）不为“1”，移动行。 若列“0”数量多于“1”，移动列。 从低位（行数组尾部）开始计算数组行值。 123456789101112131415161718192021222324252627282930313233class Solution &#123;public: int matrixScore(vector&lt;vector&lt;int&gt;&gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++) if(A[i][0]==0) for(int j=0;j&lt;A[i].size();j++) A[i][j]=1-A[i][j]; for(int j=0;j&lt;A[0].size();j++)&#123; int zero=0,one=0; for(int i=0;i&lt;A.size();i++)&#123; if(A[i][j]==0) zero++; else one++; &#125; if(zero&gt;one) for(int i=0;i&lt;A.size();i++) A[i][j]=1-A[i][j]; &#125; int sum=0; for(int i=0;i&lt;A.size();i++)&#123; int temp = 0,in=1; for(int j=A[i].size()-1;j&gt;=0;j--)&#123; temp+=A[i][j]*in; in*=2; &#125; sum+=temp; &#125; return sum; &#125;&#125;; 附上Solution： Notice that a 1 in the i’th column from the right, contributes 2^i to the score. Say we are finished toggling the rows in some configuration. Then for each column, (to maximize the score), we’ll toggle the column if it would increase the number of 1s. We can brute force over every possible way to toggle rows. Say the matrix has R rows and C columns. For each state, the transition trans = state ^ (state-1) represents the rows that must be toggled to get into the state of toggled rows represented by (the bits of) state. We’ll toggle them, and also maintain the correct column sums of the matrix on the side. Afterwards, we’ll calculate the score. If for example the last column has a column sum of 3, then the score is max(3, R-3), where R-3 represents the score we get from toggling the last column. In general, the score is increased by max(col_sum, R - col_sum) * (1 &lt;&lt; (C-1-c)), where the factor (1 &lt;&lt; (C-1-c)) is the power of 2 that each 1 contributes. Note that this approach may not run in the time allotted. 12345678910111213141516171819202122232425262728293031323334class Solution &#123; public int matrixScore(int[][] A) &#123; int R = A.length, C = A[0].length; int[] colsums = new int[C]; for (int r = 0; r &lt; R; ++r) for (int c = 0; c &lt; C; ++c) colsums[c] += A[r][c]; int ans = 0; for (int state = 0; state &lt; (1&lt;&lt;R); ++state) &#123; // Toggle the rows so that after, &apos;state&apos; represents // the toggled rows. if (state &gt; 0) &#123; int trans = state ^ (state-1); for (int r = 0; r &lt; R; ++r) &#123; if (((trans &gt;&gt; r) &amp; 1) &gt; 0) &#123; for (int c = 0; c &lt; C; ++c) &#123; colsums[c] += A[r][c] == 1 ? -1 : 1; A[r][c] ^= 1; &#125; &#125; &#125; &#125; // Calculate the score with the rows toggled by &apos;state&apos; int score = 0; for (int c = 0; c &lt; C; ++c) score += Math.max(colsums[c], R - colsums[c]) * (1 &lt;&lt; (C-1-c)); ans = Math.max(ans, score); &#125; return ans; &#125;&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[try]]></title>
    <url>%2F2019%2F05%2F13%2Ftry%2F</url>
    <content type="text"><![CDATA[]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么size_t重要?]]></title>
    <url>%2F2019%2F05%2F13%2Fcpp%E4%B8%AD%E7%9A%84size_t%2F</url>
    <content type="text"><![CDATA[前言：使用size_t可能会提高代码的可移植性、有效性或者可读性，或许同时提高这三者。 在标准C库中的许多函数使用的参数或者返回值都是表示的用字节表示的对象大小，比如说malloc(n) 函数的参数n指明了需要申请的空间大小，还有memcpy(s1, s2, n)的最后一个参数，表明需要复制的内存大小，strlen(s)函数的返回值表明了以’\0’结尾的字符串的长度（不包括’\0’），其返回值并不是该字符串的实际长度，因为要去掉’\0’。 或许你会认为这些参数或者返回值应该被申明为int类型（或者long或者unsigned），但是事实上并不是。C标准中将他们定义为size_t。标准中记载malloc的申明应该出现在，定义为：1void *malloc(size_t n); memcpy和strlen的申明应该出现在中：12void *memcpy(void *s1, void const *s2, size_t n);size_t strlen(char const *s); size_t还经常出现在C++标准库中，此外，C++库中经常会使用一个相似的类型size_type，用的可能比size_t还要多。据我所知，大部分的C和C++程序员害怕这些库使用size_t，因为他们不知道size_t代表什么或者为什么这些库需要使用它，归根结底，原因在于他们什么时候什么地方需要用到它。 可移植性问题 早期的C语言（由Brian Kernighan 和 Dennis Ritchie 在The C Programming Language书中所写，Prentice-Hall, 1978）并没有提供size_t类型，C标准委员会为了解决移植性问题将size_t引入，举例如下：让我们来写一个可移植的标准memcpy函数，我们将会看到一些不同的申明和它们在不同平台不同大小的地址空间上编译下的情况。回忆memcpy(s1, s2, n)函数，它将s2指向地址开始的n个字节拷贝到s2指向的地址，返回s1，这个函数可以拷贝任何数据类型，所以参数和返回值的类型应该为可以指向任何类型的void，同时，源地址不应该被改变，所以第二个参数s2类型应该为const void，这些都不是问题。真正的问题在于我们如何申明第三个参数，它代表了源对象的大小，我相信大部分程序员都会选择int：1void *memcpy(void *s1, void const *s2, int n); 使用int类型在大部分情况下都是可以的，但是并不是所有情况下都可以。int是有符号的，它可以表示负数，但是，大小不可能是复数。所以我们可以使用unsigned int代替它让第三个参数表示的范围更大。在大部分机器上，unsigned int的最大值要比int的最大值大两倍，比如说再也给16位的机器上，unsigned int的最大值为65535，int的最大值为32767。尽管int类型的大小依赖于C编译器的实现，但是在给定的平台上int对象的大小和unsigned int对象的大小是一样的。因此，使用unsigned int修饰第三个参数的代价与int是相同的：1void *memcpy(void *s1, void const *s2, unsigned int n); 这样似乎没有问题了，unsigned int可以表示最大类型的对象大小了，这种情况只有在整形和指针类型具有相同大小的情况下，比如说在IP16中，整形和指针都占2个字节（16位），而在IP32上面，整形和指针都占4个字节（32位）。（参见下面C数据模型表示法） C数据模型表示法最近，我偶然发现几篇文章，他们使用简明的标记来表述不同目标平台下c语言数据的实现。我还没有找到这个标记的来源，正式的语法，甚至连名字都没有，但他似乎很简单，即使没有正规的定义也可以很容易使用起来。这些标记的一边形式形如：I nI L nL LL nLL P nP。其中每个大写字母（或成对出现）代表一个C的数据类型，每一个对应的n是这个类型包含的位数。I代表int，L代表long，LL代表long long，以及P代表指针（指向数据，而不是函数）。每个字母和数字都是可选的。例如，I16P32架构支持16位int和32位指针类型，没有指明是否支持long或者long long。如果两个连续的类型具有相同的大小，通常省略第一个数字。例如，你可以将I16L32P32写为I16LP32，这是一个支持16位int，32位long，和32位指针的架构。标记通常把字母分类在一起，所以可以按照其对应的数字升序排列。例如，IL32LL64P32表示支持32位int，32位long，64位long long和32位指针的架构；然而，通常写作ILP32LL64。不幸的是，这种memcpy的申明在I16LP32架构上（整形是16-bit 长整形和指针类型时32-bits）显得不够用了，比如说摩托罗拉第一代处理器68000，在这种情况下，处理器可能拷贝的数据大于65535个字节，但是这个函数第三个参数n不能处理这么大的数据。 什么？你说很容易就可以改正？只需要把memcpy的第三个参数的类型修改一下：1void *memcpy(void *s1, void const *s2, unsigned long n); 你可以在I16LP32目标架构上使用这个函数了，它可以处理更大的数据。而且在IP16和IP32平台上效果也还行，说明它确实给出了memcpy的一种移植性较好的申明。但是，在IP16平台上相比于使用unsigned int，你使用unsigned long可能会使你的代码运行效率大打折扣（代码量变大而且运行变慢）。在标准C中规定，长整形（无论无符号或者有符号）至少占用32位，因此在IP16平台上支持标准C的话，那么它一定是IP16L32 平台。这些平台通常使用一对16位的字来实现32位的长整形。在这种情况下，移动一个长整形需要两条机器指令，每条移动一个16位的块。事实上，这个平台上的大部分的32位操作都需要至上两条指令。以可移植性为名将memcpy的第三个参数申明为unsigned long而降低某些平台的性能是我们所不希望看到的。使用size_t可以有效避免这种情况。size_t类型是一个类型定义，通常将一些无符号的整形定义为size_t，比如说unsigned int或者unsigned long，甚至unsigned long long。每一个标准C实现应该选择足够大的无符号整形来代表该平台上最大可能出现的对象大小。 使用size_tsize_t是一种数据相关的无符号类型，它被设计得足够大以便能够内存中任意对象的大小。在C++中，设计 size_t 就是为了适应多个平台的 。size_t的引入增强了程序在不同平台上的可移植性。size_t的定义在&lt;stddef.h&gt;,&lt;stdio.h&gt;,&lt;stdlib.h&gt;,&lt;string.h&gt;, &lt;time.h&gt;和&lt;wchar.h&gt;这些标准C头文件中，也出现在相应的C++头文件, 等等中，你应该在你的头文件中至少包含一个这样的头文件在使用size_t之前。 包含以上任何C头文件（由C或C++编译的程序）表明将size_t作为全局关键字。包含以上任何C++头文件（当你只能在C++中做某种操作时）表明将size_t作为std命名空间的成员。 根据定义，size_t是sizeof关键字（注：sizeof是关键字，并非运算符）运算结果的类型。所以，应当通过适当的方式声明n来完成赋值：1n = sizeof(thing); 考虑到可移植性和程序效率，n应该被申明为size_t类型。类似的，下面的foo函数的参数也应当被申明为sizeof：1foo(sizeof(thing)); 参数中带有size_t的函数通常会含有局部变量用来对数组的大小或者索引进行计算，在这种情况下，size_t是个不错的选择。适当地使用size_t还会使你的代码变得如同自带文档。当你看到一个对象声明为size_t类型，你马上就知道它代表字节大小或数组索引，而不是错误代码或者是一个普通的算术值。 size_t的大小并非像很多网上描述的那样，其大小是由系统的位数决定的。size_t的大小是由你生成的程序类型决定的，只是生成的程序类型与系统的类型有一定关系。32bits的程序既可以在64bits的系统上运行，也可以在32bits的系统上运行。但是64bits的程序只能在64bits的系统上运行。然而我们编译的程序一般是32bits的，因此size_t的大小也就变成了4个字节。 由此引发指针的大小的问题？ 关于指针的大小，网上描述基本上是千篇一律，认为指针是存放地址的，如果是32位机器就是4字节的，如果是64位机器就是8字节的，根据机器字而决定的。 这里的32位机器和64位机器指的是什么呢？我觉的CPU的架构决定了机器的类型，如果CPU是x86架构，那么就是32位的CPU，当然并非所有的x86架构的CPU都是32位的，比如intel的8086和8088就是16位的CPU。 如果CPU是x86-64的架构，那么就是64位的CPU。CPU的位数是由其字长决定，字长表示CPU在同一时间中能够处理二进制数的位数叫字长。字长是由CPU中寄存器的位数决定的，并非由数据总线的宽度决定的，只是数据总线的宽度一般与CPU的位数相一致。 系统的位数是依赖于CPU的位数，即32位的CPU不能装64位的系统，但是现在（2015年）的CPU基本上都是x86-64的CPU，都支持64位的系统。但是正如上面的讨论，如果编译生成的程序不是64位的，那么指针的大小依然是4个字节。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程间通信:管道]]></title>
    <url>%2F2019%2F05%2F13%2FLinux%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1-%E7%AE%A1%E9%81%93%2F</url>
    <content type="text"><![CDATA[管道的定义管道是第一个广泛应用的进程间通信手段。日常在终端执行shell命令时，会大量用到管道。但管道的缺陷在于只能在有亲缘关系（有共同的祖先）的进程之间使用。为了突破这个限制，后来引入了命名管道。 管道的用途管道是最早出现的进程间通信的手段。在shell中执行命令，经常会将上一个命令的输出作为下一个命令的输入，由多个命令配合完成一件事情。而这就是通过管道来实现的。在图9-3中，进程who的标准输出，通过管道传递给下游的wc进程作为标准输入，从而通过相互配合完成了一件任务。 管道的操作管道的作用是在具有亲缘关系的进程之间传递消息，所谓有亲缘关系，是指有同一个祖先。所以管道并不是只可以用于父子进程通信，也可以在兄弟进程之间还可以用在祖孙之间等，反正只要共同的祖先调用了pipe函数，打开的管道文件就会在fork之后，被各个后代所共享。不过由于管道是字节流通信，没有消息边界，多个进程同时发送的字节流混在一起，则无法分辨消息，所有管道一般用于2个进程之间通信，另外管道的内容读完后不会保存，管道是单向的，一边要么读，一边要么写，不可以又读又写，想要一边读一边写，那就创建2个管道，如下图 管道是一种文件，可以调用read、write和close等操作文件的接口来操作管道。另一方面管道又不是一种普通的文件，它属于一种独特的文件系统：pipefs。管道的本质是内核维护了一块缓冲区与管道文件相关联，对管道文件的操作，被内核转换成对这块缓冲区内存的操作。下面我们来看一下如何使用管道。#include&lt;unistd.h&gt;int pipe(int fd[2]) 如果成功，则返回值是0，如果失败，则返回值是-1，并且设置errno。成功调用pipe函数之后，会返回两个打开的文件描述符，一个是管道的读取端描述符pipefd[0]，另一个是管道的写入端描述符pipefd[1]。管道没有文件名与之关联，因此程序没有选择，只能通过文件描述符来访问管道，只有那些能看到这两个文件描述符的进程才能够使用管道。那么谁能看到进程打开的文件描述符呢？只有该进程及该进程的子孙进程才能看到。这就限制了管道的使用范围。 成功调用pipe函数之后，可以对写入端描述符pipefd[1]调用write，向管道里面写入数据，代码如下所示：1write(pipefd[1],wbuf,count); 一旦向管道的写入端写入数据后，就可以对读取端描述符pipefd[0]调用read，读出管道里面的内容。如下所示，管道上的read调用返回的字节数等于请求字节数和管道中当前存在的字节数的最小值。如果当前管道为空，那么read调用会阻塞（如果没有设置O_NONBLOCK标志位的话）。 管道非法read与write内核实现解析调用pipe函数返回的两个文件描述符中，读取端pipefd[0]支持的文件操作定义在read_pipefifo_fops，写入端pipefd[1]支持的文件操作定义在write_pipefifo_fops，其定义如下：12345678910111213141516171819202122const struct file_operations read_pipefifo_fops = &#123; //读端相关操作 .llseek = no_llseek, .read = do_sync_read, .aio_read = pipe_read, .write = bad_pipe_w, //一旦写，将调用bad_pipe_w .poll = pipe_poll, .unlocked_ioctl = pipe_ioctl, .open = pipe_read_open, .release = pipe_read_release, .fasync = pipe_read_fasync,&#125;;const struct file_operations write_pipefifo_fops = &#123;//写端相关操作 .llseek = no_llseek, .read = bad_pipe_r, //一旦读，将调用bad_pipe_r .write = do_sync_write, .aio_write = pipe_write, .poll = pipe_poll, .unlocked_ioctl = pipe_ioctl, .open = pipe_write_open, .release = pipe_write_release, .fasync = pipe_write_fasync,&#125;; 我们可以看到，对读取端描述符执行write操作，内核就会执行bad_pipe_w函数；对写入端描述符执行read操作，内核就会执行bad_pipe_r函数。这两个函数比较简单，都是直接返回-EBADF。因此对应的read和write调用都会失败，返回-1，并置errno为EBADF。12345678910static ssize_t bad_pipe_r(struct file filp, char __user buf, size_t count, loff_t ppos) &#123; return -EBADF; //返回错误 &#125; static ssize_t bad_pipe_w(struct file filp, const char __user buf, size_t count,loff_t ppos) &#123; return -EBADF; &#125; 管道通信原理及其亲戚通信解析父子进程通信解析我们只介绍了pipe函数接口，至今尚看不出来该如何使用pipe函数进行进程间通信。调用pipe之后，进程发生了什么呢？请看图9-5。 可以看到，调用pipe函数之后，系统给进程分配了两个文件描述符，即pipe函数返回的两个描述符。该进程既可以往写入端描述符写入信息，也可以从读取端描述符读出信息。可是一个进程管道，起不到任何通信的作用。这不是通信，而是自言自语。如果调用pipe函数的进程随后调用fork函数，创建了子进程，情况就不一样了。fork以后，子进程复制了父进程打开的文件描述符（如图9-6所示），两条通信的通道就建立起来了。此时，可以是父进程往管道里写，子进程从管道里面读；也可以是子进程往管道里写，父进程从管道里面读。这两条通路都是可选的，但是不能都选。原因前面介绍过，管道里面是字节流，父子进程都写、都读，就会导致内容混在一起，对于读管道的一方，解析起来就比较困难。常规的使用方法是父子进程一方只能写入，另一方只能读出，管道变成一个单向的通道，以方便使用。如图9-7所示，父进程放弃读，子进程放弃写，变成父进程写入，子进程读出，成为一个通信的通道… 父进程如何放弃读，子进程又如何放弃写？其实很简单，父进程把读端口pipefd[0]这个文件描述符关闭掉，子进程把写端口pipefd[1]这个文件描述符关闭掉就可以了，示例代码如下：123456789101112131415int pipefd[2]; pipe(pipefd); switch(fork()) &#123; case -1: /fork failed, error handler here/ case 0: /子进程/ close(pipefd[1]) ; /关闭掉写入端对应的文件描述符/ /子进程可以对pipefd[0]调用read/ break； default: /父进程/ close(pipefd[0]); /父进程关闭掉读取端对应的文件描述符/ /父进程可以对pipefd[1]调用write, 写入想告知子进程的内容/ break &#125; 亲缘关系的进程管道通信解析图9-8也讲述了如何在兄弟进程之间通过管道通信。如图9-8所示，父进程再次创建一个子进程B，子进程B就持有管道写入端，这时候两个子进程之间就可以通过管道通信了。父进程为了不干扰两个子进程通信，很自觉地关闭了自己的写入端。从此管道成为了两个子进程之间的单向的通信通道。在shell中执行管道命令就是这种情景，只是略有特殊之处，其特殊的地方是管道描述符占用了标准输入和标准输出两个文件描述符 管道的注意事项及其性质管道有以下三条性质 只有当所有的写入端描述符都已经关闭了，而且管道中的数据都被读出，对读取描述符调用read函数才返回0（及读到EOF标志）。 如果所有的读取端描述符都已经关闭了，此时进程再次往管道里面写入数据，写操作将会失败，并且内核会像进程发送一个SIGPIPE信号(默认杀死进程)。 当所有的读端与写端都已经关闭时，管道才会关闭. 就因为有这些特性，我们要及时关闭没用的管道文件描述符 shell管道的实现shell编程会大量使用管道，我们经常看到前一个命令的标准输出作为后一个命令的标准输入，来协作完成任务，如图9-9所示。管道是如何做到的呢？兄弟进程可以通过管道来传递消息，这并不稀奇，前面已经图示了做法。关键是如何使得一个程序的标准输出被重定向到管道中，而另一个程序的标准输入从管道中读取呢？ 答案就是复制文件描述符。对于第一个子进程，执行dup2之后，标准输出对应的文件描述符1，也成为了管道的写入端。这时候，管道就有了两个写入端，按照前面的建议，需要关闭不相干的写入端，使读取端可以顺利地读到EOF，所以应将刚开始分配的管道写入端的文件描述符pipefd[1]关闭掉。12345if(pipefd[1] != STDOUT_FILENO)&#123;dup2(pipefd[1],STDOUT_FILENO);close(pipefd[1]);&#125; 同样的道理,对于第二个子进程,如法炮制:12345if(pipefd[0] != STDIN_FILENO)&#123;dup2(pipefd[0],STDIN_FILENO);close(pipefd[0]);&#125; 简单来说，就是第一个子进程的标准输出被绑定到了管道的写入端，于是第一个命令的输出，写入了管道，而第二个子进程管道将其标准输入绑定到管道的读取端，只要管道里面有了内容，这些内容就成了标准输入。 两个示例代码，为什么要判断管道的文件描述符是否等于标准输入和标准输出呢？原因是，在调用pipe时，进程很可能已经关闭了标准输入和标准输出，调用pipe函数时，内核会分配最小的文件描述符，所以pipe的文件描述符可能等于0或1。在这种情况下，如果没有if判断加以保护，代码就变成了：12dup2(1,1);close(1); 这样的话，第一行代码什么也没做，第二行代码就把管道的写入端给关闭了，于是便无法传递信息了 与shell命令进行通信道的一个重要作用是和外部命令进行通信。在日常编程中，经常会需要调用一个外部命令，并且要获取命令的输出。而有些时候，需要给外部命令提供一些内容，让外部命令处理这些输入。Linux提供了popen接口来帮助程序员做这些事情。就像system函数，即使没有system函数，我们通过fork、exec及wait家族函数一样也可以实现system的功能。但终归是不方便，system函数为我们提供了一些便利。同样的道理，只用pipe函数及dup2等函数，也能完成popen要完成的工作，但popen接口给我们提供了便利。popen接口定义如下：123#include &lt;stdio.h&gt;FILE *popen(const char *command, const char *type);int pclose(FILE *stream); popen函数会创建一个管道，并且创建一个子进程来执行shell，shell会创建一个子进程来执行command。根据type值的不同，分成以下两种情况。 如果type是r：command执行的标准输出，就会写入管道，从而被调用popen的进程读到。通过对popen返回的FILE类型指针执行read或fgets等操作，就可以读取到command的标准输出，如图9-10所示。 如果type是w：调用popen的进程，可以通过对FILE类型的指针fp执行write、fputs等操作，负责往管道里面写入，写入的内容经过管道传给执行command的进程，作为命令的输入，如图9-11所示 popen函数成功时，会返回stdio库封装的FILE类型的指针，失败时会返回NULL，并且设置errno。常见的失败有fork失败，pipe失败，或者分配内存失败。I/O结束了以后，可以调用pclose函数来关闭管道，并且等待子进程的退出。尽管popen函数返回的是FILE类型的指针，也不应调用fclose函数来关闭popen函数打开的文件流指针，因为fclose不会等待子进程的退出。pclose函数成功时会返回子进程中shell的终止状态。popen函数和system函数类似，如果command对应的命令无法执行，就如同执行了exit（127）一样。如果发生其他错误，pclose函数则返回-1。可以从errno中获取到失败的原因。下面给出一个简单的例子，来示范下popen的用法：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;unistd.h&gt;#include&lt;string.h&gt;#include&lt;errno.h&gt;#include&lt;sys/wait.h&gt;#include&lt;signal.h&gt;#define MAX_LINE_SIZE 8192void print_wait_exit(int status)&#123; printf(&quot;status = %d\n&quot;,status); if(WIFEXITED(status)) &#123; printf(&quot;normal termination,exit status = %d\n&quot;,WEXITSTATUS(status)); &#125; else if(WIFSIGNALED(status)) &#123; printf(&quot;abnormal termination,signal number =%d%s\n&quot;, WTERMSIG(status),#ifdef WCOREDUMP WCOREDUMP(status)?&quot;core file generated&quot; : &quot;&quot;);#else &quot;&quot;);#endif &#125;&#125;int main(int argc ,char* argv[])&#123; FILE *fp = NULL ; char command[MAX_LINE_SIZE],buffer[MAX_LINE_SIZE]; if(argc != 2 ) &#123; fprintf(stderr,&quot;Usage: %s filename \n&quot;,argv[0]); exit(1); &#125; snprintf(command,sizeof(command),&quot;cat %s&quot;,argv[1]); fp = popen(command,&quot;r&quot;); if(fp == NULL) &#123; fprintf(stderr,&quot;popen failed (%s)&quot;,strerror(errno)); exit(2); &#125; while(fgets(buffer,MAX_LINE_SIZE,fp) != NULL) &#123; fprintf(stdout,&quot;%s&quot;,buffer); &#125; int ret = pclose(fp); if(ret == 127 ) &#123; fprintf(stderr,&quot;bad command : %s\n&quot;,command); exit(3); &#125; else if(ret == -1) &#123; fprintf(stderr,&quot;failed to get child status (%s)\n&quot;,strerror(errno)); exit(4); &#125; else &#123; print_wait_exit(ret); &#125; exit(0);&#125; 将文件名作为参数传递给程序，执行cat filename的命令。popen创建子进程来负责执行cat filename的命令，子进程的标准输出通过管道传给父进程，父进程可以通过fgets来读取command的标准输出。 system函数与popen函数区别popen函数和system有很多相似的地方，但是也有显著的不同。调用system函数时，shell命令的执行被封装在了函数内部，所以若system函数不返回，调用system的进程就不再继续执行。但是popen函数不同，一旦调用popen函数，调用进程和执行command的进程便处于并行状态。然后pclose函数才会关闭管道，等待执行command的进程退出。换句话说，在popen之后，pclose之前，调用popen的进程和执行command的进程是并行的，这种差异带来了两种显著的不同：在并行期间，调用popen的进程可能会创建其他子进程，所以标准规定popen不能阻塞SIGCHLD信号.这也意味着，popen创建的子进程可能被提前执行的等待操作所捕获。若发生这种情况，调用pclose函数时，已经无法等待command子进程的退出，这种情况下，将返回-1，并且errno为ECHILD。调用进程和command子进程是并行的，所以标准要求popen不能忽略SIGINT和SIGQUIT信号。如果是从键盘产生的上述信号，那么，调用进程和command子进程都会收到信号。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux任务调度机制]]></title>
    <url>%2F2019%2F05%2F13%2FLinux%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[作业调度策略进程调度在近几个版本中都进行了重要的修改。我们先了解一下进程调度的原理： 进程类型在linux调度算法中，将进程分为两种类型，即：I/O消耗型和CPU消耗型。例如文本处理程序与正在执行的Make的程序。文本处理程序大部份时间都在等待I/O设备的输入，而make程序大部份时间都在CPU的处理上。因此为了提高响应速度，I/O消耗程序应该有较高的优先级，才能提高它的交互性。相反的，Make程序相比之下就不那么重要了，只要它能处理完就行了。因此，基于这样的原理，linux有一套交互程序的判断机制。在task_struct结构中新增了一个成员：sleep_avg此值初始值为100。进程在CPU上执行时，此值减少。当进程在等待时，此值增加。最后，在调度的时候。根据sleep_avg的值重新计算优先级。 进程优先级正如我们在上面所说的：交互性强的需要高优先级，交互性弱的需要低优先级。在linux系统中，有两种优先级：普通优先级和实时优先级。我们在这里主要分析的是普通优先级，实时优先级部份可自行了解。 运行时间片进程的时间片是指进程在抢占前可以持续运行的时间。在linux中，时间片长短可根据优先级来调整。进程不一定要一次运行完所有的时间片。可以在运时的中途被切换出去。 进程抢占当一个进程被设为TASK_RUNING状态时，它会判断它的优先级是否高于正在运行的进程，如果是，则设置调度标志位，调用schedule()执行进程的调度。当一个进程的时间片为0时，也会执行进程抢占。 调度程序运行时，要在所有可运行状态的进程中选择最值得运行的进程投入运行。选择进程的依据是什么呢？在每个进程的task_struct结构中有以下四 项：policy、priority、counter、rt_priority。这四项就是调度程序选择进程的依据.其中,policy是进程的调度策略,用来区分两种进程-实时和普通；priority是进程(实时和普通)的优先 级；counter 是进程剩余的时间片,它的大小完全由priority决定;rt_priority是实时优先级,这是实时进程所特有的，用于实时进程间的选择。 首先，Linux 根据policy从整体上区分实时进程和普通进程，因为实时进程和普通进程度调度是不同的，它们两者之间，实时进程应该先于普通进程而运行，然后，对于同一类型的不同进程，采用不同的标准来选择进程： policy的取值会有以下可能： SCHED_OTHER 分时调度策略，（默认的） SCHED_FIFO实时调度策略，先到先服务 SCHED_RR实时调度策略，时间片轮转 实时进程将得到优先调用，实时进程根据实时优先级决定调度权值，分时进程则通过nice和counter值决定权值，nice越小，counter越大，被调度的概率越大，也就是曾经使用了cpu最少的进程将会得到优先调度。 SHCED_RR和SCHED_FIFO的不同：当采用SHCED_RR策略的进程的时间片用完，系统将重新分配时间片，并置于就绪队列尾。放在队列尾保证了所有具有相同优先级的RR任务的调度公平。 SCHED_FIFO一旦占用cpu则一直运行。一直运行直到有 更高优先级任务到达或自己放弃 。 如果有相同优先级的实时进程（根据优先级计算的调度权值是一样的）已经准备好，FIFO时必须等待该进程主动放弃后才可以运行这个优先级相同的任务。而RR可以让每个任务都执行一段时间。 相同点： RR和FIFO都只用于实时任务。 创建时优先级大于0(1-99)。 按照可抢占优先级调度算法进行。 就绪态的实时任务立即抢占非实时任务。 对于普通进程，Linux采用动态优先调度，选择进程的依据就是进程counter的大小。进程创建时，优先级priority被赋一个初值，一般为 0～70之间的数字，这个数字同时也是计数器counter的初值，就是说进程创建时两者是相等的。字面上看，priority是”优先级”、 counter是”计数器”的意思，然而实际上，它们表达的是同一个意思-进程的”时间片”。Priority代表分配给该进程的时间片，counter 表示该进程剩余的时间片。在进程运行过程中，counter不断减少，而priority保持不变，以便在counter变为0的时候（该进程用完了所分 配的时间片）对counter重新赋值。当一个普通进程的时间片用完以后，并不马上用priority对counter进行赋值，只有所有处于可运行状态 的普通进程的时间片(p-&gt;counter==0)都用完了以后，才用priority对counter重新赋值，这个普通进程才有了再次被调度的 机会。这说明，普通进程运行过程中，counter的减小给了其它进程得以运行的机会，直至counter减为0时才完全放弃对CPU的使用，这就相对于 优先级在动态变化，所以称之为动态优先调度。至于时间片这个概念，和其他不同操作系统一样的，Linux的时间单位也是”时钟滴答”，只是不同操作系统对 一个时钟滴答的定义不同而已（Linux为10ms）。进程的时间片就是指多少个时钟滴答，比如，若priority为20，则分配给该进程的时间片就为 20个时钟滴答，也就是20*10ms=200ms。Linux中某个进程的调度策略(policy)、优先级(priority)等可以作为参数由用户 自己决定，具有相当的灵活性。内核创建新进程时分配给进程的时间片缺省为200ms(更准确的，应为210ms)，用户可以通过系统调用改变它。 对于实时进程，Linux采用了两种调度策略，即FIFO(先来先服务调度)和RR（时间片轮转调度）。因为实时进程具有一定程度的紧迫性，所以衡量一个 实时进程是否应该运行，Linux采用了一个比较固定的标准。实时进程的counter只是用来表示该进程的剩余时间片，并不作为衡量它是否值得运行的标 准。实时进程的counter只是用来表示该进程的剩余时间片，并不作为衡量它是否值得运行的标准，这和普通进程是有区别的。上面已经看到，每个进程有两 个优先级（动态优先级和实时优先级），实时优先级就是用来衡量实时进程是否值得运行的。 Linux根据policy的值将进程总体上分为实时进程和普通进程，提供了三种调度算法：一种传统的Unix调度程序和两个由POSIX.1b(原名为 POSIX.4)操作系统标准所规定的”实时”调度程序。但这种实时只是软实时，不满足诸如中断等待时间等硬实时要求，只是保证了当实时进程需要时一定只 把CPU分配给实时进程。 非实时进程有两种优先级，一种是静态优先级，另一种是动态优先级。实时进程又增加了第三种优先级，实时优先级。优先级是一些简单的整数，为了决定应该允许哪一个进程使用CPU的资源，用优先级代表相对权值-优先级越高，它得到CPU时间的机会也就越大。 静态优先级(priority)-不随时间而改变，只能由用户进行修改。它指明了在被迫和其他进程竞争CPU之前，该进程所应该被允许的时间片的最大值（但很可能的，在该时间片耗尽之前，进程就被迫交出了CPU）。 动态优先级(counter)-只要进程拥有CPU，它就随着时间不断减小；当它小于0时，标记进程重新调度。它指明了在这个时间片中所剩余的时间量。 实时优先级(rt_priority)-指明这个进程自动把CPU交给哪一个其他进程；较高权值的进程总是优先于较低权值的进程。如果一个进程不是实时进程，其优先级就是0，所以实时进程总是优先于非实时进程的（但实际上，实时进程也会主动放弃CPU）。 当所有任务都采用FIFO调度策略时（SCHED_FIFO）： 创建进程时指定采用FIFO，并设置实时优先级rt_priority(1-99)。 如果没有等待资源，则将该任务加入到就绪队列中。 调度程序遍历就绪队列，根据实时优先级计算调度权值,选择权值最高的任务使用cpu， 该FIFO任务将一直占有cpu直到有优先级更高的任务就绪(即使优先级相同也不行)或者主动放弃(等待资源)。 调度程序发现有优先级更高的任务到达(高优先级任务可能被中断或定时器任务唤醒，再或被当前运行的任务唤醒，等等)，则调度程序立即在当前任务堆栈中保存当前cpu寄存器的所有数据，重新从高优先级任务的堆栈中加载寄存器数据到cpu，此时高优先级的任务开始运行。重复第3步。 如果当前任务因等待资源而主动放弃cpu使用权，则该任务将从就绪队列中删除，加入等待队列，此时重复第3步。 当所有任务都采用RR调度策略（SCHED_RR）时： 创建任务时指定调度参数为RR， 并设置任务的实时优先级和nice值(nice值将会转换为该任务的时间片的长度)。 如果没有等待资源，则将该任务加入到就绪队列中。 调度程序遍历就绪队列，根据实时优先级计算调度权值,选择权值最高的任务使用cpu。 如果就绪队列中的RR任务时间片为0，则会根据nice值设置该任务的时间片，同时将该任务放入就绪队列的末尾 。重复步骤3。 当前任务由于等待资源而主动退出cpu，则其加入等待队列中。重复步骤3。 系统中既有分时调度，又有时间片轮转调度和先进先出调度： RR调度和FIFO调度的进程属于实时进程，以分时调度的进程是非实时进程。 当实时进程准备就绪后，如果当前cpu正在运行非实时进程，则实时进程立即抢占非实时进程 。 RR进程和FIFO进程都采 作业调度算法： 先来先服务算法 段作业优先调度算法 优先级调度算法 时间片轮转调度算法 最高响应比优先调度算法响应比=周转时间/作业执行时间=(作业执行时间+作业等待时间)/作业执行时间=1+作业等待时间/作业执行时间；作业周转时间=作业完成时间-作业到达时间 多级反馈队列调度算法 进程在进入待调度的队列等待时，首先进入优先级最高的Q1等待。 首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。例如：Q1,Q2,Q3三个队列，只有在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。 对于同一个队列中的各个进程，按照时间片轮转法调度。比如Q1队列的时间片为N，那么Q1中的作业在经历了N个时间片后若还没有完成，则进入Q2队列等待，若Q2的时间片用完后作业还不能完成，一直进入下一级队列，直至完成。 在低优先级的队列中的进程在运行时，又有新到达的作业，那么在运行完这个时间片后，CPU马上分配给新到达的作业（抢占式）。 实时调度算法 最早截止时间优先调度算法 最低松弛度优先调度算法 根据任务紧急的程度，来确定任务的优先级。比如说，一个任务在200ms时必须完成而它本身运行需要100ms，所以此任务就必须在100ms之前调度执行，此任务的松弛度就是100ms。在实现此算法时需要系统中有一个按松弛度排序的实时任务就绪队列，松弛度最低的任务排在最烈的最前面，调度程序总是选择就粗队列中的首任务执行！(可理解为最早额定开始)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[斜堆之图文解析和C语言的实现]]></title>
    <url>%2F2019%2F05%2F12%2F%E6%96%9C%E5%A0%86%E4%B9%8B%E5%9B%BE%E6%96%87%E8%A7%A3%E6%9E%90%E5%92%8CC%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概要本章介绍斜堆。和以往一样，本文会先对斜堆的理论知识进行简单介绍，然后给出C语言的实现。后续再分别给出C++和Java版本的实现；实现的语言虽不同，但是原理如出一辙，选择其中之一进行了解即可。若文章有错误或不足的地方，请不吝指出！ 目录 斜堆的介绍 斜堆的基本操作 斜堆的C实现(完整源码) 斜堆的C测试程序 转载请注明出处：http://www.cnblogs.com/skywang12345/p/3638493.html 斜堆的介绍斜堆(Skew heap)也叫自适应堆(self-adjusting heap)，它是左倾堆的一个变种。和左倾堆一样，它通常也用于实现优先队列。它的合并操作的时间复杂度也是O(lg n)。 相比于左倾堆，斜堆的节点没有”零距离”这个属性。除此之外，它们斜堆的合并操作也不同。斜堆的合并操作算法如下：(01) 如果一个空斜堆与一个非空斜堆合并，返回非空斜堆。(02) 如果两个斜堆都非空，那么比较两个根节点，取较小堆的根节点为新的根节点。将”较小堆的根节点的右孩子”和”较大堆”进行合并。(03) 合并后，交换新堆根节点的左孩子和右孩子。 第(03)步是斜堆和左倾堆的合并操作差别的关键所在，如果是左倾堆，则合并后要比较左右孩子的零距离大小，若右孩子的零距离 &gt; 左孩子的零距离，则交换左右孩子；最后，在设置根的零距离。 斜堆的基本操作头文件12345678910111213141516171819202122232425262728293031323334#ifndef _SKEW_HEAP_H_#define _SKEW_HEAP_H_typedef int Type;typedef struct _SkewNode&#123; Type key; // 关键字(键值) struct _SkewNode *left; // 左孩子 struct _SkewNode *right; // 右孩子&#125;SkewNode, *SkewHeap;// 前序遍历&quot;斜堆&quot;void preorder_skewheap(SkewHeap heap);// 中序遍历&quot;斜堆&quot;void inorder_skewheap(SkewHeap heap);// 后序遍历&quot;斜堆&quot;void postorder_skewheap(SkewHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int skewheap_minimum(SkewHeap heap, int *pval);// 合并&quot;斜堆x&quot;和&quot;斜堆y&quot;，并返回合并后的新树SkewNode* merge_skewheap(SkewHeap x, SkewHeap y);// 将结点插入到斜堆中，并返回根节点SkewNode* insert_skewheap(SkewHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点SkewNode* delete_skewheap(SkewHeap heap);// 销毁斜堆void destroy_skewheap(SkewHeap heap);// 打印斜堆void print_skewheap(SkewHeap heap);#endif SkewNode是斜堆对应的节点类。 合并1234567891011121314151617181920212223242526/* * 合并&quot;斜堆x&quot;和&quot;斜堆y&quot; * * 返回值： * 合并得到的树的根节点 */SkewNode* merge_skewheap(SkewHeap x, SkewHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_skewheap_node(x, y); // 将x的右孩子和y合并， // 合并后直接交换x的左右孩子，而不需要像左倾堆一样考虑它们的npl。 SkewNode *tmp = merge_skewheap(x-&gt;right, y); x-&gt;right = x-&gt;left; x-&gt;left = tmp; return x;&#125; merge_skewheap(x, y)的作用是合并x和y这两个斜堆，并返回得到的新堆。merge_skewheap(x, y)是递归实现的。 添加123456789101112131415161718192021/* * 新建结点(key)，并将其插入到斜堆中 * * 参数说明： * heap 斜堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */SkewNode* insert_skewheap(SkewHeap heap, Type key)&#123; SkewNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (SkewNode *)malloc(sizeof(SkewNode))) == NULL) return heap; node-&gt;key = key; node-&gt;left = node-&gt;right = NULL; return merge_skewheap(heap, node);&#125; insert_skewheap(heap, key)的作用是新建键值为key的结点，并将其插入到斜堆中，并返回堆的根节点。 删除12345678910111213141516/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */SkewNode* delete_skewheap(SkewHeap heap)&#123; SkewNode *l = heap-&gt;left; SkewNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_skewheap(l, r); // 返回左右子树合并后的新树&#125; delete_skewheap(heap)的作用是删除斜堆的最小节点，并返回删除节点后的斜堆根节点。 斜堆的C实现(完整源码)斜堆的头文件(skewheap.h)12345678910111213141516171819202122232425262728293031323334#ifndef _SKEW_HEAP_H_#define _SKEW_HEAP_H_typedef int Type;typedef struct _SkewNode&#123; Type key; // 关键字(键值) struct _SkewNode *left; // 左孩子 struct _SkewNode *right; // 右孩子&#125;SkewNode, *SkewHeap;// 前序遍历&quot;斜堆&quot;void preorder_skewheap(SkewHeap heap);// 中序遍历&quot;斜堆&quot;void inorder_skewheap(SkewHeap heap);// 后序遍历&quot;斜堆&quot;void postorder_skewheap(SkewHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int skewheap_minimum(SkewHeap heap, int *pval);// 合并&quot;斜堆x&quot;和&quot;斜堆y&quot;，并返回合并后的新树SkewNode* merge_skewheap(SkewHeap x, SkewHeap y);// 将结点插入到斜堆中，并返回根节点SkewNode* insert_skewheap(SkewHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点SkewNode* delete_skewheap(SkewHeap heap);// 销毁斜堆void destroy_skewheap(SkewHeap heap);// 打印斜堆void print_skewheap(SkewHeap heap);#endif 斜堆的实现文件(skewheap.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186/** * C语言实现的斜堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;skewheap.h&quot;/* * 前序遍历&quot;斜堆&quot; */void preorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; printf(&quot;%d &quot;, heap-&gt;key); preorder_skewheap(heap-&gt;left); preorder_skewheap(heap-&gt;right); &#125;&#125;/* * 中序遍历&quot;斜堆&quot; */void inorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; inorder_skewheap(heap-&gt;left); printf(&quot;%d &quot;, heap-&gt;key); inorder_skewheap(heap-&gt;right); &#125;&#125;/* * 后序遍历&quot;斜堆&quot; */void postorder_skewheap(SkewHeap heap)&#123; if(heap != NULL) &#123; postorder_skewheap(heap-&gt;left); postorder_skewheap(heap-&gt;right); printf(&quot;%d &quot;, heap-&gt;key); &#125;&#125;/* * 交换两个节点的内容 */static void swap_skewheap_node(SkewNode *x, SkewNode *y)&#123; SkewNode tmp = *x; *x = *y; *y = tmp;&#125;/* * 获取最小值 * * 返回值： * 成功返回0，失败返回-1 */int skewheap_minimum(SkewHeap heap, int *pval)&#123; if (heap == NULL) return -1; *pval = heap-&gt;key; return 0;&#125; /* * 合并&quot;斜堆x&quot;和&quot;斜堆y&quot; * * 返回值： * 合并得到的树的根节点 */SkewNode* merge_skewheap(SkewHeap x, SkewHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_skewheap_node(x, y); // 将x的右孩子和y合并， // 合并后直接交换x的左右孩子，而不需要像左倾堆一样考虑它们的npl。 SkewNode *tmp = merge_skewheap(x-&gt;right, y); x-&gt;right = x-&gt;left; x-&gt;left = tmp; return x;&#125;/* * 新建结点(key)，并将其插入到斜堆中 * * 参数说明： * heap 斜堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */SkewNode* insert_skewheap(SkewHeap heap, Type key)&#123; SkewNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (SkewNode *)malloc(sizeof(SkewNode))) == NULL) return heap; node-&gt;key = key; node-&gt;left = node-&gt;right = NULL; return merge_skewheap(heap, node);&#125;/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */SkewNode* delete_skewheap(SkewHeap heap)&#123; SkewNode *l = heap-&gt;left; SkewNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_skewheap(l, r); // 返回左右子树合并后的新树&#125;/* * 销毁斜堆 */void destroy_skewheap(SkewHeap heap)&#123; if (heap==NULL) return ; if (heap-&gt;left != NULL) destroy_skewheap(heap-&gt;left); if (heap-&gt;right != NULL) destroy_skewheap(heap-&gt;right); free(heap);&#125;/* * 打印&quot;斜堆&quot; * * heap -- 斜堆的节点 * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */static void skewheap_print(SkewHeap heap, Type key, int direction)&#123; if(heap != NULL) &#123; if(direction==0) // heap是根节点 printf(&quot;%2d is root\n&quot;, heap-&gt;key); else // heap是分支节点 printf(&quot;%2d is %2d&apos;s %6s child\n&quot;, heap-&gt;key, key, direction==1?&quot;right&quot; : &quot;left&quot;); skewheap_print(heap-&gt;left, heap-&gt;key, -1); skewheap_print(heap-&gt;right,heap-&gt;key, 1); &#125;&#125;void print_skewheap(SkewHeap heap)&#123; if (heap != NULL) skewheap_print(heap, heap-&gt;key, 0);&#125; 斜堆的测试程序(skewheap_test.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * C语言实现的斜堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &quot;skewheap.h&quot;#define LENGTH(a) ( (sizeof(a)) / (sizeof(a[0])) )void main()&#123; int i; int a[]= &#123;10,40,24,30,36,20,12,16&#125;; int b[]= &#123;17,13,11,15,19,21,23&#125;; int alen=LENGTH(a); int blen=LENGTH(b); SkewHeap ha,hb; ha=hb=NULL; printf(&quot;== 斜堆(ha)中依次添加: &quot;); for(i=0; i&lt;alen; i++) &#123; printf(&quot;%d &quot;, a[i]); ha = insert_skewheap(ha, a[i]); &#125; printf(&quot;\n== 斜堆(ha)的详细信息: \n&quot;); print_skewheap(ha); printf(&quot;\n== 斜堆(hb)中依次添加: &quot;); for(i=0; i&lt;blen; i++) &#123; printf(&quot;%d &quot;, b[i]); hb = insert_skewheap(hb, b[i]); &#125; printf(&quot;\n== 斜堆(hb)的详细信息: \n&quot;); print_skewheap(hb); // 将&quot;斜堆hb&quot;合并到&quot;斜堆ha&quot;中。 ha = merge_skewheap(ha, hb); printf(&quot;\n== 合并ha和hb后的详细信息: \n&quot;); print_skewheap(ha); // 销毁斜堆 destroy_skewheap(ha);&#125;]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[左倾堆之图文解析和C语言的实现]]></title>
    <url>%2F2019%2F05%2F12%2F%E5%B7%A6%E5%80%BE%E5%A0%86%E4%B9%8B%E5%9B%BE%E6%96%87%E8%A7%A3%E6%9E%90%E5%92%8CC%E8%AF%AD%E8%A8%80%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[概要本章介绍左倾堆，它和二叉堆一样，都是堆结构中的一员。和以往一样，本文会先对左倾堆的理论知识进行简单介绍，然后给出C语言的实现。后续再分别给出C++和Java版本的实现；实现的语言虽不同，但是原理如出一辙，选择其中之一进行了解即可。若文章有错误或不足的地方，请不吝指出！ 目录 左倾堆的介绍 左倾堆的图文解析 左倾堆的C实现(完整源码) 左倾堆的C测试程序 转载请注明出处：http://www.cnblogs.com/skywang12345/p/3638327.html 左倾堆的介绍左倾堆(leftist tree 或 leftist heap)，又被成为左偏树、左偏堆，最左堆等。它和二叉堆一样，都是优先队列实现方式。当优先队列中涉及到”对两个优先队列进行合并”的问题时，二叉堆的效率就无法令人满意了，而本文介绍的左倾堆，则可以很好地解决这类问题。 左倾堆的定义左倾堆是一棵二叉树，它的节点除了和二叉树的节点一样具有左右子树指针外，还有两个属性：键值和零距离。(01) 键值的作用是来比较节点的大小，从而对节点进行排序。(02) 零距离(英文名NPL，即Null Path Length)则是从一个节点到一个”最近的不满节点”的路径长度。不满节点是指该该节点的左右孩子至少有有一个为NULL。叶节点的NPL为0，NULL节点的NPL为-1。 上图是一颗左倾堆，它满足左倾堆的基本性质：[性质1] 节点的键值小于或等于它的左右子节点的键值。[性质2] 节点的左孩子的NPL &gt;= 右孩子的NPL。[性质3] 节点的NPL = 它的右孩子的NPL + 1。 左倾堆，顾名思义，是有点向左倾斜的意思了。它在统计问题、最值问题、模拟问题和贪心问题等问题中有着广泛的应用。此外，斜堆是比左倾堆更为一般的数据结构。当然，今天讨论的是左倾堆，关于斜堆，以后再撰文来表。前面说过，它能和好的解决”两个优先队列合并”的问题。实际上，左倾堆的合并操作的平摊时间复杂度为O(lg n)，而完全二叉堆为O(n)。合并就是左倾树的重点，插入和删除操作都是以合并操作为基础的。插入操作，可以看作两颗左倾树合并；删除操作(移除优先队列中队首元素)，则是移除根节点之后再合并剩余的两个左倾树。闲话说到这里，下面开始介绍左倾树的基本方法。 左倾堆的图文解析合并操作是左倾堆的重点。合并两个左倾堆的基本思想如下：(01) 如果一个空左倾堆与一个非空左倾堆合并，返回非空左倾堆。(02) 如果两个左倾堆都非空，那么比较两个根节点，取较小堆的根节点为新的根节点。将”较小堆的根节点的右孩子”和”较大堆”进行合并。(03) 如果新堆的右孩子的NPL &gt; 左孩子的NPL，则交换左右孩子。(04) 设置新堆的根节点的NPL = 右子堆NPL + 1 下面通过图文演示合并以下两个堆的过程。 提示：这两个堆的合并过程和测试程序相对应！ 第1步：将”较小堆(根为10)的右孩子”和”较大堆(根为11)”进行合并。合并的结果，相当于将”较大堆”设置”较小堆”的右孩子，如下图所示： 第2步：将上一步得到的”根11的右子树”和”根为12的树”进行合并，得到的结果如下： 第3步：将上一步得到的”根12的右子树”和”根为13的树”进行合并，得到的结果如下： 第4步：将上一步得到的”根13的右子树”和”根为16的树”进行合并，得到的结果如下： 第5步：将上一步得到的”根16的右子树”和”根为23的树”进行合并，得到的结果如下： 至此，已经成功的将两棵树合并成为一棵树了。接下来，对新生成的树进行调节。第6步：上一步得到的”树16的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 第7步：上一步得到的”树12的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 第8步：上一步得到的”树10的右孩子的NPL &gt; 左孩子的NPL”，因此交换左右孩子。得到的结果如下： 至此，合并完毕。上面就是合并得到的左倾堆！ 下面看看左倾堆的基本操作的代码 头文件1234567891011121314151617181920212223242526272829303132333435#ifndef _LEFTIST_TREE_H_#define _LEFTIST_TREE_H_typedef int Type;typedef struct _LeftistNode&#123; Type key; // 关键字(键值) int npl; // 零路经长度(Null Path Length) struct _LeftistNode *left; // 左孩子 struct _LeftistNode *right; // 右孩子&#125;LeftistNode, *LeftistHeap;// 前序遍历&quot;左倾堆&quot;void preorder_leftist(LeftistHeap heap);// 中序遍历&quot;左倾堆&quot;void inorder_leftist(LeftistHeap heap);// 后序遍历&quot;左倾堆&quot;void postorder_leftist(LeftistHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int leftist_minimum(LeftistHeap heap, int *pval);// 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot;，并返回合并后的新树LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y);// 将结点插入到左倾堆中，并返回根节点LeftistNode* insert_leftist(LeftistHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点LeftistNode* delete_leftist(LeftistHeap heap);// 销毁左倾堆void destroy_leftist(LeftistHeap heap);// 打印左倾堆void print_leftist(LeftistHeap heap);#endif LeftistNode是左倾堆对应的节点类。 合并12345678910111213141516171819202122232425262728293031323334353637/* * 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot; * * 返回值： * 合并得到的树的根节点 */LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_leftist_node(x, y); // 将x的右孩子和y合并，&quot;合并后的树的根&quot;是x的右孩子。 x-&gt;right = merge_leftist(x-&gt;right, y); // 如果&quot;x的左孩子为空&quot; 或者 &quot;x的左孩子的npl&lt;右孩子的npl&quot; // 则，交换x和y if(x-&gt;left == NULL || x-&gt;left-&gt;npl &lt; x-&gt;right-&gt;npl) &#123; LeftistNode *tmp = x-&gt;left; x-&gt;left = x-&gt;right; x-&gt;right = tmp; &#125; // 设置合并后的新树(x)的npl if (x-&gt;right == NULL || x-&gt;left == NULL) x-&gt;npl = 0; else x-&gt;npl = (x-&gt;left-&gt;npl &gt; x-&gt;right-&gt;npl) ? (x-&gt;right-&gt;npl + 1) : (x-&gt;left-&gt;npl + 1); return x;&#125; merge_leftist(x, y)的作用是合并x和y这两个左倾堆，并返回得到的新堆。merge_leftist(x, y)是递归实现的。 添加12345678910111213141516171819202122/* * 新建结点(key)，并将其插入到左倾堆中 * * 参数说明： * heap 左倾堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */LeftistNode* insert_leftist(LeftistHeap heap, Type key)&#123; LeftistNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (LeftistNode *)malloc(sizeof(LeftistNode))) == NULL) return heap; node-&gt;key = key; node-&gt;npl = 0; node-&gt;left = node-&gt;right = NULL; return merge_leftist(heap, node);&#125; insert_leftist(heap, key)的作用是新建键值为key的结点，并将其插入到左倾堆中，并返回堆的根节点。 删除12345678910111213141516171819/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */LeftistNode* delete_leftist(LeftistHeap heap)&#123; if (heap == NULL) return NULL; LeftistNode *l = heap-&gt;left; LeftistNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_leftist(l, r); // 返回左右子树合并后的新树&#125; delete_leftist(heap)的作用是删除左倾堆的最小节点，并返回删除节点后的左倾堆根节点。 左倾堆的C实现(完整源码)左倾堆的头文件(leftist.h)1234567891011121314151617181920212223242526272829303132333435#ifndef _LEFTIST_TREE_H_#define _LEFTIST_TREE_H_typedef int Type;typedef struct _LeftistNode&#123; Type key; // 关键字(键值) int npl; // 零路经长度(Null Path Length) struct _LeftistNode *left; // 左孩子 struct _LeftistNode *right; // 右孩子&#125;LeftistNode, *LeftistHeap;// 前序遍历&quot;左倾堆&quot;void preorder_leftist(LeftistHeap heap);// 中序遍历&quot;左倾堆&quot;void inorder_leftist(LeftistHeap heap);// 后序遍历&quot;左倾堆&quot;void postorder_leftist(LeftistHeap heap);// 获取最小值(保存到pval中)，成功返回0，失败返回-1。int leftist_minimum(LeftistHeap heap, int *pval);// 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot;，并返回合并后的新树LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y);// 将结点插入到左倾堆中，并返回根节点LeftistNode* insert_leftist(LeftistHeap heap, Type key);// 删除结点(key为节点的值)，并返回根节点LeftistNode* delete_leftist(LeftistHeap heap);// 销毁左倾堆void destroy_leftist(LeftistHeap heap);// 打印左倾堆void print_leftist(LeftistHeap heap);#endif 左倾堆的实现文件(leftist.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201/** * C语言实现的左倾堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &quot;leftist.h&quot;/* * 前序遍历&quot;左倾堆&quot; */void preorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; printf(&quot;%d &quot;, heap-&gt;key); preorder_leftist(heap-&gt;left); preorder_leftist(heap-&gt;right); &#125;&#125;/* * 中序遍历&quot;左倾堆&quot; */void inorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; inorder_leftist(heap-&gt;left); printf(&quot;%d &quot;, heap-&gt;key); inorder_leftist(heap-&gt;right); &#125;&#125;/* * 后序遍历&quot;左倾堆&quot; */void postorder_leftist(LeftistHeap heap)&#123; if(heap != NULL) &#123; postorder_leftist(heap-&gt;left); postorder_leftist(heap-&gt;right); printf(&quot;%d &quot;, heap-&gt;key); &#125;&#125;/* * 交换两个节点的内容 */static void swap_leftist_node(LeftistNode *x, LeftistNode *y)&#123; LeftistNode tmp = *x; *x = *y; *y = tmp;&#125;/* * 获取最小值 * * 返回值： * 成功返回0，失败返回-1 */int leftist_minimum(LeftistHeap heap, int *pval)&#123; if (heap == NULL) return -1; *pval = heap-&gt;key; return 0;&#125; /* * 合并&quot;左倾堆x&quot;和&quot;左倾堆y&quot; * * 返回值： * 合并得到的树的根节点 */LeftistNode* merge_leftist(LeftistHeap x, LeftistHeap y)&#123; if(x == NULL) return y; if(y == NULL) return x; // 合并x和y时，将x作为合并后的树的根； // 这里的操作是保证: x的key &lt; y的key if(x-&gt;key &gt; y-&gt;key) swap_leftist_node(x, y); // 将x的右孩子和y合并，&quot;合并后的树的根&quot;是x的右孩子。 x-&gt;right = merge_leftist(x-&gt;right, y); // 如果&quot;x的左孩子为空&quot; 或者 &quot;x的左孩子的npl&lt;右孩子的npl&quot; // 则，交换x和y if(x-&gt;left == NULL || x-&gt;left-&gt;npl &lt; x-&gt;right-&gt;npl) &#123; LeftistNode *tmp = x-&gt;left; x-&gt;left = x-&gt;right; x-&gt;right = tmp; &#125; // 设置合并后的新树(x)的npl if (x-&gt;right == NULL || x-&gt;left == NULL) x-&gt;npl = 0; else x-&gt;npl = (x-&gt;left-&gt;npl &gt; x-&gt;right-&gt;npl) ? (x-&gt;right-&gt;npl + 1) : (x-&gt;left-&gt;npl + 1); return x;&#125;/* * 新建结点(key)，并将其插入到左倾堆中 * * 参数说明： * heap 左倾堆的根结点 * key 插入结点的键值 * 返回值： * 根节点 */LeftistNode* insert_leftist(LeftistHeap heap, Type key)&#123; LeftistNode *node; // 新建结点 // 如果新建结点失败，则返回。 if ((node = (LeftistNode *)malloc(sizeof(LeftistNode))) == NULL) return heap; node-&gt;key = key; node-&gt;npl = 0; node-&gt;left = node-&gt;right = NULL; return merge_leftist(heap, node);&#125;/* * 取出根节点 * * 返回值： * 取出根节点后的新树的根节点 */LeftistNode* delete_leftist(LeftistHeap heap)&#123; if (heap == NULL) return NULL; LeftistNode *l = heap-&gt;left; LeftistNode *r = heap-&gt;right; // 删除根节点 free(heap); return merge_leftist(l, r); // 返回左右子树合并后的新树&#125;/* * 销毁左倾堆 */void destroy_leftist(LeftistHeap heap)&#123; if (heap==NULL) return ; if (heap-&gt;left != NULL) destroy_leftist(heap-&gt;left); if (heap-&gt;right != NULL) destroy_leftist(heap-&gt;right); free(heap);&#125;/* * 打印&quot;左倾堆&quot; * * heap -- 左倾堆的节点 * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */static void leftist_print(LeftistHeap heap, Type key, int direction)&#123; if(heap != NULL) &#123; if(direction==0) // heap是根节点 printf(&quot;%2d(%d) is root\n&quot;, heap-&gt;key, heap-&gt;npl); else // heap是分支节点 printf(&quot;%2d(%d) is %2d&apos;s %6s child\n&quot;, heap-&gt;key, heap-&gt;npl, key, direction==1?&quot;right&quot; : left&quot;); leftist_print(heap-&gt;left, heap-&gt;key, -1); leftist_print(heap-&gt;right,heap-&gt;key, 1); &#125;&#125;void print_leftist(LeftistHeap heap)&#123; if (heap != NULL) leftist_print(heap, heap-&gt;key, 0);&#125; 左倾堆的测试程序(leftist_test.c)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * C语言实现的左倾堆 * * @author skywang * @date 2014/03/31 */#include &lt;stdio.h&gt;#include &quot;leftist.h&quot;#define LENGTH(a) ( (sizeof(a)) / (sizeof(a[0])) )void main()&#123; int i; int a[]= &#123;10,40,24,30,36,20,12,16&#125;; int b[]= &#123;17,13,11,15,19,21,23&#125;; int alen=LENGTH(a); int blen=LENGTH(b); LeftistHeap ha,hb; ha=hb=NULL; printf(&quot;== 左倾堆(ha)中依次添加: &quot;); for(i=0; i&lt;alen; i++) &#123; printf(&quot;%d &quot;, a[i]); ha = insert_leftist(ha, a[i]); &#125; printf(&quot;\n== 左倾堆(ha)的详细信息: \n&quot;); print_leftist(ha); printf(&quot;\n== 左倾堆(hb)中依次添加: &quot;); for(i=0; i&lt;blen; i++) &#123; printf(&quot;%d &quot;, b[i]); hb = insert_leftist(hb, b[i]); &#125; printf(&quot;\n== 左倾堆(hb)的详细信息: \n&quot;); print_leftist(hb); // 将&quot;左倾堆hb&quot;合并到&quot;左倾堆ha&quot;中。 ha = merge_leftist(ha, hb); printf(&quot;\n== 合并ha和hb后的详细信息: \n&quot;); print_leftist(ha); // 销毁左倾堆 destroy_leftist(ha);&#125; 左倾堆的C测试程序左倾堆的测试程序已经包含在它的实现文件(leftist_test.c)中了，这里仅给出它的运行结果：12345678910111213141516171819202122232425262728293031323334353637== 左倾堆(ha)中依次添加: 10 40 24 30 36 20 12 16 == 左倾堆(ha)的详细信息: 10(2) is root24(1) is 10&apos;s left child30(0) is 24&apos;s left child36(0) is 24&apos;s right child12(1) is 10&apos;s right child20(0) is 12&apos;s left child40(0) is 20&apos;s left child16(0) is 12&apos;s right child== 左倾堆(hb)中依次添加: 17 13 11 15 19 21 23 == 左倾堆(hb)的详细信息: 11(2) is root15(1) is 11&apos;s left child19(0) is 15&apos;s left child21(0) is 15&apos;s right child13(1) is 11&apos;s right child17(0) is 13&apos;s left child23(0) is 13&apos;s right child== 合并ha和hb后的详细信息: 10(2) is root11(2) is 10&apos;s left child15(1) is 11&apos;s left child19(0) is 15&apos;s left child21(0) is 15&apos;s right child12(1) is 11&apos;s right child13(1) is 12&apos;s left child17(0) is 13&apos;s left child16(0) is 13&apos;s right child23(0) is 16&apos;s left child20(0) is 12&apos;s right child40(0) is 20&apos;s left child24(1) is 10&apos;s right child30(0) is 24&apos;s left child36(0) is 24&apos;s right child]]></content>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的const关键字]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%ADconst%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[const的用法const是不改变的。在C和C++中，我们使用关键字const来使程序元素保持不变。const关键字可以在C++程序的许多上下文中使用。它可以用于：变量、指针、函数参数和返回类型、类数据成员、类成员函数、对象。 const变量如果你用const关键字做任何变量，你就不能改变它的值。同样，必须在声明的时候初始化常数变量。Example:123456int main&#123; const int i = 10; const int j = i + 10; // works fine i++; // this leads to Compile time error &#125; 上面的代码中，我们使 i 成为常量，因此如果我们试图改变它的值，我们将得到编译时错误。尽管我们可以用它来代替其他变量。 指针与const关键字指针也可以使用const关键字来声明。当我们使用const和指针时，我们可以用两种方式来做：可以把const应用到指针指向的地方，或者我们可以使指针本身成为一个常数。 指向const变量的指针：意味着指针指向一个const变量。1const int* u; 这里，表示u是一个指针，可以指向const int类型变量。指针指向的内容不可改变。简称左定值，因为const位于*号的左边。 我们也可以这样写，1char const* v; 表示v是指向const类型的char的指针。指向const变量的指针非常有用，因为它可以用来使任何字符串或数组不可变 const指针为了使指针保持不变，我们必须把const关键字放到右边。对于const指针p其指向的内存地址不能够被改变，但其内容可以改变。简称，右定向。因为const位于*号的右边。12int x = 1;int* const w = &amp;x; 里，w是一个指针，它是const，指向一个int，现在我们不能改变指针，这意味着它总是指向变量x但是可以改变它指向的值，通过改变x的值。 当你想要一个可以在值中改变但不会在内存中移动的存储器时，常量指针指向一个变量是很有用的。因为指针总是指向相同的内存位置，因为它是用const关键字定义的，但是那个内存位置的值可以被更改。左定值，右定向，const修饰不变量 const函数参数和返回类型123456789void f(const int i)&#123; i++; // error&#125; const int g()&#123; return 1;&#125; 注意几个要点： ①对于内置数据类型，返回const或非const值，不会有任何影响。12345678910const int h()&#123; return 1;&#125;int main()&#123; const int j = h(); int k = h();&#125; j和k都将被赋值为1。不会出现错误。 ②对于用户定义的数据类型，返回const，将阻止它的修改。此时返回的值不能作为左值使用，既不能被赋值，也不能被修改。const 修饰返回的指针或者引用，是否返回一个指向 const 的指针，取决于我们想让用户干什么。 ③在程序执行时创建的临时对象总是const类型。值传递的 const 修饰传递，一般这种情况不需要 const 修饰，因为函数会自动产生临时变量复制实参值。当 const 参数为指针时，可以防止指针被意外篡改。123456789101112131415161718#include&lt;iostream&gt; using namespace std; void Cpf(int *const a)&#123; cout&lt;&lt;*a&lt;&lt;&quot; &quot;; *a = 9;&#125; int main(void)&#123; int a = 8; Cpf(&amp;a); cout&lt;&lt;a; // a 为 9 system(&quot;pause&quot;); return 0;&#125; 自定义类型的参数传递，需要临时对象复制参数，对于临时对象的构造，需要调用构造函数，比较浪费时间，因此我们采取 const 外加引用传递的方法。并且对于一般的 int、double 等内置类型，我们不采用引用的传递方式。1234567891011121314151617181920212223242526272829303132#include&lt;iostream&gt; using namespace std; class Test&#123;public: Test()&#123;&#125; Test(int _m):_cm(_m)&#123;&#125; int get_cm()const &#123; return _cm; &#125; private: int _cm;&#125;; void Cmf(const Test&amp; _tt)&#123; cout&lt;&lt;_tt.get_cm();&#125; int main(void)&#123; Test t(8); Cmf(t); system(&quot;pause&quot;); return 0;&#125; ④如果一个函数有一个非const参数，它在发出调用时不能传递const参数。1234void t(int*) &#123; // function logic&#125; 如果我们把一个const int参数传递给函数t，会出现错误。 ⑤但是，一个具有const类型参数的函数，可以传递一个const类型参数以及一个非const参数。1234void g(const int*) &#123; // function logic&#125; 这个函数可以有一个int，也可以有const int类型参数。 const修饰函数返回值(1)指针传递 如果返回const data,non-const pointer，返回值也必须赋给const data,non-const pointer。因为指针指向的数据是常量不能修改。1234567891011const int * mallocA()&#123; ///const data,non-const pointer int *a=new int(2); return a;&#125;int main()&#123; const int *a = mallocA(); ///int *b = mallocA(); ///编译错误 return 0;&#125; (2)值传递 如果函数返回值采用“值传递方式”，由于函数会把返回值复制到外部临时的存储单元中，加const 修饰没有任何价值。所以，对于值传递来说，加const没有太多意义。 所以： 不要把函数int GetInt(void) 写成const int GetInt(void)。 不要把函数A GetA(void) 写成const A GetA(void)，其中A 为用户自定义的数据类型。 将类数据成员定义为const这些是类中的数据变量，使用const关键字定义。它们在声明期间未初始化。它们的初始化在构造函数中完成。1234567891011121314class Test&#123; const int i; public: Test (int x) : i(x) &#123; &#125;&#125;; int main()&#123; Test t(10); Test s(20);&#125; 在这个程序中，i 是一个常量数据成员，在每个对象中它的独立副本将会出现，因此它使用构造函数对每个对象进行初始化。一旦初始化，它的值就不能改变 把类对象定义为const当一个对象被声明或使用const关键字创建时，它的数据成员在对象的生命周期中永远不会被改变。 语法：1const class_name object; 例如，如果在上面定义的类测试中，我们想要定义一个常数对象，我们可以这样做：1const Test r(30); 将类的成员函数定义为constconst成员函数决不会修改对象中的数据成员。注意：const关键字不能与static关键字同时使用，因为static关键字修饰静态成员函数，静态成员函数不含有this指针，即不能实例化，const成员函数必须具体到某一实例。 如果有个成员函数想修改对象中的某一个成员怎么办？这时我们可以使用mutable关键字修饰这个成员，mutable的意思也是易变的，容易改变的意思，被mutable关键字修饰的成员可以处于不断变化中。 const成员函数不能调用非const成员函数，因为非const成员函数可以会修改成员变量。123456789101112131415161718#include &lt;iostream&gt;using namespace std;class Point&#123; public : Point(int _x):x(_x)&#123;&#125; void testConstFunction(int _x) const&#123; ///错误，在const成员函数中，不能修改任何类成员变量 x=_x; ///错误，const成员函数不能调用非onst成员函数，因为非const成员函数可以会修改成员变量 modify_x(_x); &#125; void modify_x(int _x)&#123; x=_x; &#125; int x;&#125;; 语法：return_type function_name() const;const对象和const成员函数的例子：12345678910111213141516171819202122232425262728293031323334353637class StarWars&#123; public: int i; StarWars(int x) // constructor &#123; i = x; &#125; int falcon() const // constant function &#123; /* can do anything but will not modify any data members */ cout &lt;&lt; &quot;Falcon has left the Base&quot;; &#125; int gamma() &#123; i++; &#125;&#125;; int main()&#123; StarWars objOne(10); // non const object const StarWars objTwo(20); // const object objOne.falcon(); // No error objTwo.falcon(); // No error cout &lt;&lt; objOne.i &lt;&lt; objTwo.i; objOne.gamma(); // No error objTwo.gamma(); // Compile time error&#125; 输出结果：123Falcon has left the BaseFalcon has left the Base10 20 在这里，我们可以看到，const成员函数永远不会改变类的数据成员，并且它可以与const和非const对象一起使用。但是const对象不能与试图改变其数据成员的成员函数一起使用。 关于const的疑问：1.const什么时候为只读变量？2.const什么时候是常量？ const常量的判别标准： 只有字面量初始化的const常量才会进入符号表 使用其他变量初始化的const常量仍然是只读变量 被volatile修饰的const常量不会进入符号表 注意： const引用的类型与初始化变量的类型相同时：初始化变量成为只读变量 const引用的类型与初始化变量的类型不相同时：初生成一个新的只读变量 Example:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#include &lt;stdio.h&gt; int main()&#123; const int x = 1; //字面量初始化，此时x为常量，进入符号表 const int&amp; rx = x; //rx代表只读变量 int&amp; nrx = const_cast&lt;int&amp;&gt;(rx); //去掉rx的只读属性 nrx = 5; //改变了nrx内存空间的值 printf(&quot;x = %d\n&quot;, x); // 1 printf(&quot;rx = %d\n&quot;, rx); // 5 printf(&quot;nrx = %d\n&quot;, nrx); // 5 printf(&quot;&amp;x = %p\n&quot;, &amp;x); // &amp;x = 002CFD80 printf(&quot;&amp;rx = %p\n&quot;, &amp;rx); // &amp;x = 002CFD80 printf(&quot;&amp;nrx = %p\n&quot;, &amp;nrx); // &amp;x = 002CFD80 //输出的地址相同，说明了x、rx、nrx代表同样的内存空间 volatile const int y = 2;//volatile代表易变的 int* p = const_cast&lt;int*&gt;(&amp;y); *p = 6; printf(&quot;y = %d\n&quot;, y); //y = 6 printf(&quot;p = %p\n&quot;, p); //p = 001BF928 //判别是否是常量是编译器在编译时能不能确认它的值 const int z = y; p = const_cast&lt;int*&gt;(&amp;z); *p = 7; printf(&quot;z = %d\n&quot;, z); // z = 7 printf(&quot;p = %p\n&quot;, p); //p = 001BF910 char c = &apos;c&apos;; char&amp; rc = c; const int&amp; trc = c; rc = &apos;a&apos;; printf(&quot;c = %c\n&quot;, c); // c = a printf(&quot;rc = %c\n&quot;, rc);// rc = a printf(&quot;trc = %c\n&quot;, trc);//trc = c //变量c是char类型，而trc是int类型，所以生成了一个新的只读变量 return 0;&#125; 输出结果：]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的变长参数]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%AD%E7%9A%84%E5%8F%98%E9%95%BF%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[变长参数函数 首先回顾一下较多使用的变长参数函数，最经典的便是printf。1extern int printf(const char *format, ...); 以上是一个变长参数的函数声明。我们自己定义一个测试函数：123456789101112131415161718192021#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;int testparams(int count, ...)&#123; va_list args; va_start(args, count); for (int i = 0; i &lt; count; ++i) &#123; int arg = va_arg(args, int); printf(&quot;arg %d = %d&quot;, i, arg); &#125; va_end(args); return 0;&#125;int main()&#123; testparams(3, 10, 11, 12); return 0;&#125; 变长参数函数的解析，使用到三个宏va_start,va_arg 和va_end，再看va_list的定义typedef char* va_list; 只是一个char指针。 这几个宏如何解析传入的参数呢？ 函数的调用，是一个压栈，保存，跳转的过程。简单的流程描述如下： 把参数从右到左依次压入栈； 调用call指令，把下一条要执行的指令的地址作为返回地址入栈；（被调用函数执行完后会回到该地址继续执行） 当前的ebp（基址指针）入栈保存，然后把当前esp（栈顶指针）赋给ebp作为新函数栈帧的基址； 执行被调用函数，局部变量等入栈； 返回值放入eax，leave，ebp赋给esp，esp所存的地址赋给ebp；（这里可能需要拷贝临时返回对象） 从返回地址开始继续执行；（把返回地址所存的地址给eip） 由于开始的时候从右至左把参数压栈，va_start 传入最左侧的参数，往右的参数依次更早被压入栈，因此地址依次递增（栈顶地址最小）。va_arg传入当前需要获得的参数的类型，便可以利用 sizeof 计算偏移量，依次获取后面的参数值。 12345678910111213#define _INTSIZEOF(n) ((sizeof(n) + sizeof(int) - 1) &amp; ~(sizeof(int) - 1))#define _ADDRESSOF(v) (&amp;const_cast&lt;char&amp;&gt;(reinterpret_cast&lt;const volatile char&amp;&gt;(v)))#define __crt_va_start_a(ap, v) ((void)(ap = (va_list)_ADDRESSOF(v) + _INTSIZEOF(v)))#define __crt_va_arg(ap, t) (*(t*)((ap += _INTSIZEOF(t)) - _INTSIZEOF(t)))#define __crt_va_end(ap) ((void)(ap = (va_list)0))#define __crt_va_start(ap, x) ((void)(__vcrt_va_start_verify_argument_type&lt;decltype(x)&gt;(), __crt_va_start_a(ap, x)))#define va_start __crt_va_start#define va_arg __crt_va_arg#define va_end __crt_va_end 上述宏定义中，_INTSIZEOF(n) 将地址的低2位指令，做内存的4字节对齐。每次取参数时，调用__crt_va_arg(ap,t) ，返回t类型参数地址的值，同时将ap偏移到t之后。最后，调用_crt_va_end(ap)将ap置0. 变长参数的函数的使用及其原理看了宏定义是很好理解的。从上文可知，要使用变长参数函数的参数，我们必须知道传入的每个参数的类型。printf中，有format字符串中的特殊字符组合来解析后面的参数类型。但是当传入类的构造函数的参数时，我们并不知道每个参数都是什么类型，虽然参数能够依次传入函数，但无法解析并获取每个参数的数值。因此传统的变长参数函数并不足以解决传入任意构造函数参数的问题。 变长参数模板我们需要用到C++11的新特性，变长参数模板。 这里举一个使用自定义内存池的例子。定义一个内存池类MemPool.h，以count个类型T为单元分配内存，默认分配一个对象。每当内存内空闲内存不够，则一次申请MEMPOOL_NEW_SIZE个内存对象。内存池本身只负责内存分配，不做初始化工作，因此不需要传入任何参数，只需实例化模板分配相应类型的内存即可。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#ifndef UTIL_MEMPOOL_H#define UTIL_MEMPOOL_H#include &lt;stdlib.h&gt;#define MEMPOOL_NEW_SIZE 8template&lt;typename T, size_t count = 1&gt;class MemPool&#123;private: union MemObj &#123; char _obj[1]; MemObj* _freelink; &#125;;public: static void* Allocate() &#123; if (!_freelist) &#123; refill(); &#125; MemObj* alloc_mem = _freelist; _freelist = _freelist-&gt;_freelink; ++_size; return (void*)alloc_mem; &#125; static void DeAllocate(void* p) &#123; MemObj* q = (MemObj*)p; q-&gt;_freelink = _freelist; _freelist = q; --_size; &#125; static size_t TotalSize() &#123; return _totalsize; &#125; static size_t Size() &#123; return _size; &#125;private: static void refill() &#123; size_t size = sizeof(T) * count; char* new_mem = (char*)malloc(size * MEMPOOL_NEW_SIZE); for (int i = 0; i &lt; MEMPOOL_NEW_SIZE; ++i) &#123; MemObj* free_mem = (MemObj*)(new_mem + i * size); free_mem-&gt;_freelink = _freelist; _freelist = free_mem; &#125; _totalsize += MEMPOOL_NEW_SIZE; &#125; static MemObj* _freelist; static size_t _totalsize; static size_t _size;&#125;;template&lt;typename T, size_t count&gt;typename MemPool&lt;T, count&gt;::MemObj* MemPool&lt;T, count&gt;::_freelist = NULL;template&lt;typename T, size_t count&gt;size_t MemPool&lt;T, count&gt;::_totalsize = 0;template&lt;typename T, size_t count&gt;size_t MemPool&lt;T, count&gt;::_size = 0;#endif 接下来在没有变长参数的情况下，实现通用MemNew和MemDelete函数模板。这里不对函数模板作详细解释，用函数模板我们可以对不同的类型实现同样的内存池分配操作。如下：1234567891011121314151617181920212223242526272829303132template&lt;class T&gt;T *MemNew(size_t count)&#123; T *p = (T*)MemPool&lt;T, count&gt;::Allocate(); if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; new (&amp;p[i]) T(); &#125; &#125; &#125; return p;&#125;template&lt;class T&gt;T *MemDelete(T *p, size_t count)&#123; if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; p[i].~T(); &#125; &#125; MemPool&lt;T, count&gt;::DeAllocate(p); &#125;&#125; 上述实现中，使用placement new对申请的内存进行构造，使用了默认构造函数，当申请内存的类型不具备默认构造函数时，placement new将报错。对于pod类型，可以省去调用构造函数的过程。 引入C++11变长模板参数后MemNew修改为如下:12345678910111213141516template&lt;class T, class... Args&gt;T *MemNew(size_t count, Args&amp;&amp;... args)&#123; T *p = (T*)MemPool&lt;T, count&gt;::Allocate(); if (p != NULL) &#123; if (!std::is_pod&lt;T&gt;::value) &#123; for (size_t i = 0; i &lt; count; ++i) &#123; new (&amp;p[i]) T(std::forward&lt;Args&gt;(args)...); &#125; &#125; &#125; return p;&#125; 以上函数定义包含了多个特性，后面我将一一解释，其中class… Args 表示变长参数模板，函数参数中Args&amp;&amp; 为右值引用。std::forward 实现参数的完美转发。这样，无论传入的类型具有什么样的构造函数，都能够完美执行placement new。 C++11中引入了变长参数模板的概念，来解决参数个数不确定的模板。12345678910template&lt;class... T&gt; class Test &#123;&#125;;Test&lt;&gt; test0;Test&lt;int&gt; test1;Test&lt;int,int&gt; test2;Test&lt;int,int,long&gt; test3;template&lt;class... T&gt; void test(T... args);test();test&lt;int&gt;(0);test&lt;int,int,long&gt;(0,0,0L); 变长参数函数模板T… args 为形参包，其中args是模式，形参包中可以有0到任意多个参数。调用函数时，可以传任意多个实参。对于函数定义来说，该如何使用参数包呢？在上文的MemNew中，我们使用std::forward依次将参数包传入构造函数，并不关注每个参数具体是什么。如果需要，我们可以用sizeof…(args)操作获取参数个数，也可以把参数包展开，对每个参数做更多的事。展开的方法有两种，递归函数，逗号表达式。 递归函数方式展开，模板推导的时候，一层层递归展开，最后到没有参数时用定义的一般函数终止。1234567891011121314151617void test()&#123;&#125;template&lt;class T, class... Args&gt; void test(T first, Args... args)&#123; std::cout &lt;&lt; typeid(T).name() &lt;&lt; &quot; &quot; &lt;&lt; first &lt;&lt; std::endl; test(args...);&#125;test&lt;int, int, long&gt;(0, 0, 0L);output:int 0int 0long 0 逗号表达式方式展开，利用数组的参数初始化列表和逗号表达式，逐一执行print每个参数。123456789101112131415161718template&lt;class T&gt;void print(T arg)&#123; std::cout &lt;&lt; typeid(T).name() &lt;&lt; &quot; &quot; &lt;&lt; arg &lt;&lt; std::endl;&#125;template&lt;class... Args&gt;void test(Args... args)&#123; int arr[] = &#123; (print(args), 0)... &#125;;&#125;test(0, 0, 0L);output:int 0int 0long 0 变长参数类模板变长参数类模板，一般情况下可以方便我们做一些编译期计算。可以通过偏特化和递归推导的方式依次展开模板参数。 12345678910111213141516171819202122template&lt;class T, class... Types&gt;class Test&#123;public: enum &#123; value = Test&lt;T&gt;::value + Test&lt;Types...&gt;::value, &#125;;&#125;;template&lt;class T&gt;class Test&lt;T&gt;&#123;public: enum &#123; value = sizeof(T), &#125;;&#125;;Test&lt;int, int, long&gt; test;std::cout &lt;&lt; test.value;output: 12 右值引用和完美转发对于变长参数函数模板，需要将形参包展开逐个处理的需求不多，更多的还是像本文的MemNew这样的需求，最终整个传入某个现有的函数。我们把重点放在参数的传递上。 要理解右值引用，需要先说清楚左值和右值。左值是内存中有确定存储地址的对象的表达式的值；右值则是非左值的表达式的值。const左值不可被赋值，临时对象的右值可以被赋值。左值与右值的根本区别在于是否能用&amp;运算符获得内存地址。123456789101112int i =0;//i 左值int *p = &amp;i;// i 左值int&amp; foo();foo() = 42;// foo() 左值int* p1 = &amp;foo();// foo() 左值int foo1();int j = 0;j = foo1();// foo 右值int k = j + 1;// j + 1 右值int *p2 = &amp;foo1(); // 错误，无法取右值的地址j = 1;// 1 右值 理解左值和右值之后，再来看引用，对左值的引用就是左值引用，对右值（纯右值和临终值）的引用就是右值引用。 如下函数foo，传入int类型，返回int类型，这里传入函数的参数0和返回值0都是右值(不能用&amp;取得地址)。于是，未做优化的情况下，传入参数0的时候，我们需要把右值0拷贝给param，函数返回的时候需要将0拷贝给临时对象，临时对象再拷贝给res。当然现在的编译器都做了返回值优化，返回对象是直接创建在返回后的左值上的，这里只用来举个例子1234567int foo(int param)&#123; printf(&quot;%d&quot;, param); return 0;&#125;int res = foo(0); 显然，这里的拷贝都是多余的。可能我们会想要优化，首先将参数int改为int&amp;，传入左值引用，于是0无法传入了，当然我们可以改成const int&amp;，这样终于省去了传参的拷贝。12345int foo(const int&amp; param)&#123; printf(&quot;%d&quot;, param); return 0;&#125; 由于const int&amp; 既可以是左值也可以是右值，传入0或者int变量都能够满足。(但是似乎既然有左值引用的int&amp;类型，就应该有对应的传入右值引用的类型int&amp;&amp;)。另外，这里返回的右值0，似乎不通过拷贝就无法赋值给左值res。 于是有了移动语义，把临时对象的内容直接移动给被赋值的左值对象(std::move)。和右值引用，X&amp;&amp;是到数据类型X的右值引用。123456789int result = 0;int&amp;&amp; foo(int&amp;&amp; param)&#123; printf(&quot;%d&quot;, param); return std::move(result);&#125;int&amp;&amp; res = foo(0);int *pres = &amp;res; 将foo改为右值引用参数和返回值，返回右值引用，免去拷贝。这里res是具名引用，运算符右侧的右值引用作为左值，可以取地址。右值引用既有左值性质，也有右值性质。 上述例子还只存在于拷贝的性能问题。回到MemNew这样的函数模板。 1234567891011121314151617181920212223template&lt;class T&gt;T* Test(T arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(T&amp; arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(const T&amp; arg)&#123; return new T(arg);&#125;template&lt;class T&gt;T* Test(T&amp;&amp; arg)&#123; return new T(std::forward&lt;T&gt;(arg));&#125; 上述的前三种方式传参，第一种首先有拷贝消耗，其次有的参数就是需要修改的左值。第二种方式则无法传常数等右值。第三种方式虽然左值右值都能传，却无法对传入的参数进行修改。第四种方式使用右值引用，可以解决参数完美转发的问题。 std::forward能够根据实参的数据类型，返回相应类型的左值和右值引用，将参数完整不动的传递下去。解释这个原理涉及到引用塌缩规则 T&amp; &amp; -&gt;T&amp;T&amp; &amp;&amp;-&gt;T&amp;T&amp;&amp; &amp;-&gt;T&amp;T&amp;&amp; &amp;&amp;-&gt;T&amp;&amp; 1234567891011121314template&lt; class T &gt; struct remove_reference &#123;typedef T type;&#125;;template&lt; class T &gt; struct remove_reference&lt;T&amp;&gt; &#123;typedef T type;&#125;;template&lt; class T &gt; struct remove_reference&lt;T&amp;&amp;&gt; &#123;typedef T type;&#125;;template&lt; class T &gt; T&amp;&amp; forward( typename std::remove_reference&lt;T&gt;::type&amp; t )&#123; return static_cast&lt;T&amp;&amp;&gt;(t);&#125;template&lt;class T&gt;typename std::remove_reference&lt;T&gt;::type&amp;&amp; move(T&amp;&amp; a) noexcept&#123; return static_cast&lt;typename std::remove_reference&lt;T&gt;::type&amp;&amp;&gt;(a);&#125; 对于函数模板12345template&lt;class T&gt;T* Test(T&amp;&amp; arg)&#123; return new T(std::forward&lt;T&gt;(arg));&#125; 当传入实参为X类型左值时，T为X&amp;，最后的类型为X&amp;。当实参为X类型右值时，T为X，最后的类型为X&amp;&amp;。 x为左值时：12X x;Test(x); T为X&amp;，实例化后123456789101112131415161718192021X&amp; &amp;&amp; std::forward(remove_reference&lt;X&amp;&gt;::type&amp; a) noexcept&#123; return static_cast&lt;X&amp; &amp;&amp;&gt;(a);&#125;X* Test(X&amp; &amp;&amp; arg)&#123; return new X(std::forward&lt;X&amp;&gt;(arg)); &#125;// 塌陷后X&amp; std::forward(X&amp; a)&#123; return static_cast&lt;X&amp;&gt;(a);&#125;X* Test(X&amp; arg)&#123; return new X(std::forward&lt;X&amp;&gt;(arg));&#125; x为右值时：12X foo();Test(foo()); T为X，实例化后123456789101112131415161718192021X&amp;&amp; std::forward(remove_reference&lt;X&gt;::type&amp; a) noexcept&#123; return static_cast&lt;X&amp;&amp;&gt;(a);&#125;X* Test(X&amp;&amp; arg)&#123; return new X(std::forward&lt;X&gt;(arg)); &#125;// 塌陷后X&amp;&amp; std::forward(X&amp; a)&#123; return static_cast&lt;X&amp;&amp;&gt;(a);&#125;X* Test(X&amp;&amp; arg)&#123; return new X(std::forward&lt;X&gt;(arg));&#125; 可以看到最终实参总是被推导为和传入时相同的类型引用。 至此，我们讨论了变长参数模板，讨论了右值引用和函数模板的完美转发，完整的解释了MemNew对任意多个参数的构造函数的参数传递过程。利用变长参数函数模板，右值引用和std::forward，可以完成参数的完美转发。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的Volatile关键字]]></title>
    <url>%2F2019%2F05%2F08%2Fcpp%E4%B8%ADvolatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/god-of-death/p/7852394.html 概述why volatilevolatile 关键词，最早出现于20世纪70年代，被用于处理 MMIO(Memory-mapped I/O) 带来的问题。在引入 MMIO 之后，一块内存地址既有可能是真正的内存，也有可能是映射的一个I/O端口。因此，读/写一个内存地址，既有可能是真正地操作内存，也有可能是读/写一个I/O设备。 那么 MMIO 为什么需要引入 volatile 关键词呢？我们结合下面这段示例代码进行解释：123456789unsigned int *p = FunB();unsigned int a;unsigned int b; a = *p; // 语句1b = *p; // 语句2 *p = a; // 语句3*p = b; // 语句4 在上述代码片段中，指针p既有可能指向一个内存地址，也有可能指向一个I/O设备。如果指针p指向的是I/O设备，那么语句1和语句2中的变量a和变量b，就会接收到I/O设备的连续两个字节。但是，指针p也有可能指向内存地址，这种情况下，编译器就会进行语句优化，编译器的优化策略会判断变量a和变量b同时从同一个内存地址读取数据，因此在执行完语句1之后，直接将变量a赋值给变量b。对于指针p指向I/O设备的这种情况，就需要防止编译器进行此优化，即不能假设指针b指向的内容不变（对应 volatile 的易变性特性）。 同样，语句3和语句4也有类似的问题，编译器发现将变量a和b同时赋值给指针p是无意义的，因此可能会优化语句3中的赋值操作，而仅仅保留语句4。对于指针p指向I/O设备的情况，也需要防止编译器将类似的写操作给优化消失了（对应 volatile 的不可优化特性）。 对于I/O设备，编译器不能随意交互指令的顺序，因为指令顺序一变，写入I/O设备的内容也就发生变化了（对应 volatile 的顺序性）。 为了满足 MMIO 的这三点需求，就有了 volatile 关键字。 IN C/C++在C/C++语言中，使用 volatile 关键字声明的变量（或对象）通常具有与优化、多线程相关的特殊属性。通常，volatile 关键字用来阻止（伪）编译器对其认为的、无法“被代码本身”改变的代码（变量或对象）进行优化。如在C/C++中，volatile 关键字可以用来提醒编译器使用 volatile 声明的变量随时有可能改变，因此编译器在代码编译时就不会对该变量进行某些激进的优化，故而编译生成的程序在每次存储或读取该变量时，都会直接从内存地址中读取数据。相反，如果该变量没有使用 volatile 关键字进行声明，则编译器可能会优化读取和存储操作，可能暂时使用寄存器中该变量的值，而如果这个变量由别的程序（线程）更新了的话，就会出现（内存中与寄存器中的）变量值不一致的现象。 定义为volatile的变量是说这变量可能会被意想不到地改变，即在你程序运行过程中一直会变，你希望这个值被正确的处理，每次从内存中去读这个值，而不是因编译器优化从缓存的地方读取，比如读取缓存在寄存器中的数值，从而保证volatile变量被正确的读取。 在单任务的环境中，一个函数体内部，如果在两次读取变量的值之间的语句没有对变量的值进行修改，那么编译器就会设法对可执行代码进行优化。由于访问寄存器的速度要快过RAM（从RAM中读取变量的值到寄存器），以后只要变量的值没有改变，就一直从寄存器中读取变量的值，而不对RAM进行访问。 而在多任务环境中，虽然在一个函数体内部，在两次读取变量之间没有对变量的值进行修改，但是该变量仍然有可能被其他的程序（如中断程序、另外的线程等）所修改。如果这时还是从寄存器而不是从RAM中读取，就会出现被修改了的变量值不能得到及时反应的问题。 因为访问寄存器要比访问内存单元快的多,所以编译器一般都会作减少存取内存的优化，但有可能会读脏数据。当要求使用volatile声明变量值的时候，系统总是重新从它所在的内存读取数据，即使它前面的指令刚刚从该处读取过数据。精确地说就是，遇到这个关键字声明的变量，编译器对访问该变量的代码就不再进行优化，从而可以提供对特殊地址的稳定访问；如果不使用valatile，则编译器将对所声明的语句进行优化。（简洁的说就是：volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错。加了volatile修饰的变量，编译器将不对其相关代码执行优化，而是生成对应代码直接存取原始内存地址）。 一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。一般说来，volatile用在如下的几个地方： （1）并行设备的硬件寄存器（如：状态寄存器） （2）中断服务程序中修改的供其它程序检测的变量需要加volatile； （3）多任务环境下各任务间共享的标志应该加volatile； （4）存储器映射的硬件寄存器通常也要加volatile说明，因为每次对它的读写都可能有不同意义； 在C/C++语言中，使用 volatile 关键字声明的变量具有三种特性：易变的、不可优化的、顺序执行的。下面分别对这三种特性进行介绍。 易变的volatile 在词典中的主要释义就是“易变的”。 在 C/C++ 语言中，volatile 的易变性体现在：假设有读、写两条语句，依次对同一个 volatile 变量进行操作，那么后一条的读操作不会直接使用前一条的写操作对应的 volatile 变量的寄存器内容，而是重新从内存中读取该 volatile 变量的值。 上述描述的（部分）示例代码如下：1234volatile int nNum = 0; // 将nNum声明为volatileint nSum = 0;nNum = FunA(); // nNum被写入的新内容，其值会缓存在寄存器中nSum = nNum + 1; // 此处会从内存（而非寄存器）中读取nNum的值 不可优化的在 C/C++ 语言中，volatile 的第二个特性是“不可优化性”。volatile 会告诉编译器，不要对 volatile 声明的变量进行各种激进的优化（甚至将变量直接消除），从而保证程序员写在代码中的指令一定会被执行。 上述描述的（部分）示例代码如下：123volatile int nNum; // 将nNum声明为volatilenNum = 1;printf(&quot;nNum is: %d&quot;, nNum); 在上述代码中，如果变量 nNum 没有声明为 volatile 类型，则编译器在编译过程中就会对其进行优化，直接使用常量“1”进行替换（这样优化之后，生成的汇编代码很简介，执行时效率很高）。而当我们使用 volatile 进行声明后，编译器则不会对其进行优化，nNum 变量仍旧存在，编译器会将该变量从内存中取出，放入寄存器之中，然后再调用 printf() 函数进行打印。 顺序执行的在 C/C++ 语言中，volatile 的第三个特性是“顺序执行特性”，即能够保证 volatile 变量间的顺序性，不会被编译器进行乱序优化。 说明：C/C++ 编译器最基本优化原理：保证一段程序的输出，在优化前后无变化。 为了对本特性进行深入了解，下面以两个变量（nNum1 和 nNum2）为例（既然存在“顺序执行”，那描述对象必然大于一个），结合如下示例代码，介绍 volatile 的顺序执行特性。1234int nNum1;int nNum2;nNum2 = nNum1 + 1; // 语句1nNum1 = 10; // 语句2 在上述代码中： 当 nNum1 和 nNum2 都没有使用 volatile 关键字进行修饰时，编译器会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句2”、再执行“语句1”；当 nNum2 使用 volatile 关键字进行修饰时，编译器也可能会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句2”、再执行“语句1”；当 nNum1 和 nNum2 都使用 volatile 关键字进行修饰时，编译器不会对“语句1”和“语句2”的执行顺序进行优化：即先执行“语句1”、再执行“语句2”；说明：上述论述可通过观察代码的生成的汇编代码进行验证。 volatile与多线程语义对于多线程编程而言，在临界区内部，可以通过互斥锁（mutex）保证只有一个线程可以访问该临界区的内容，因此临界区内的变量不需要是 volatile 的；而在临界区外部，被多个线程访问的变量应声明为 volatile 的，这也符合了 volatile 的原意：防止编译器缓存（cache）了被多个线程并发用到的变量。 不过，需要注意的是，由于 volatile 关键字的“顺序执行特性”并非会完全保证语句的顺序执行（如 volatile 变量与非volatile 变量之间的操作；又如一些 CPU 也会对语句的执行顺序进行优化），因此导致了对 volatile 变量的操作并不是原子的，也不能用来为线程建立严格的 happens-before 关系。 对于上述描述，示例代码如下：1234567891011121314151617181920int nNum1 = 0;volatile bool flag = false; thread1()&#123; // some code nNum1 = 666; // 语句1 flag = true; // 语句2&#125; thread2()&#123; // some code if (true == flag) &#123; // 语句3：按照程序设计的预想，此处的nNum1的值应为666，并据此进行逻辑设计 &#125;&#125; 在上述代码中，我们的设计思路是先执行 thread1() 中的“语句1”、“语句2”、再执行 thread2() 中的“语句3”，不过实际上程序的执行结果未必如此。根据 volatile 的“顺序性”，非 volatile 变量 nNum1 和 volatile 变量 flag 的执行顺序，可能会被编译器（或 CPU）进行乱序优化，最终导致thread1中的“语句2”先于“语句1”执行，当“语句2”执行完成但“语句1”尚未执行时，此时 thread2 中的判断语句“if (true == flag)”是成立的，但实际上 nNum1 尚未进行赋值为666（语句1尚未执行），所以在判断语句中针对 nNum1 为666的前提下进行的相关操作，就会有问题了。 这是一个在多线程编程中，使用 volatile 不容易发现的问题。 实际上，上述多线程代码想实现的就是一个 happens-before 语义，即保证 thread1 代码块中的所有代码，一定要在 thread2 代码块的第一条代码之前完成。使用互斥锁（mutex）可以保证 happens-before 语义。但是，在 C/C++ 中的 volatile 关键词不能保证这个语义，也就意味着在多线程环境下使用 C/C++ 的 volatile 关键词，如果不够细心，就可能会出现上述问题。 说明：由于 Java 语言的 volatile 关键字支持 Acquire、Release 语义，因此 Java 语言的 volatile 能够用来构建 happens-before 语义。也就是说，前面提到的 C/C++ 中 volatile 在多线程下使用出现的问题，在 Java 语言中是不存在的。 不保证原子性volatile只保证其“可见性”，不保证其“原子性”。 执行count++;这条语句由3条指令组成： 将 count 的值从内存加载到 cpu 的某个 寄存器r； 将 寄存器r 的值 +1，结果存放在 寄存器s； 将 寄存器s 中的值写回内存。 所以，如果有多个线程同时在执行 count++，在某个线程执行完第（3）步之前，其它线程是看不到它的执行结果的。（这里有疑惑：线程同时执行count++，为了保证其原子性，为何不加mutex lock？而是寻求volatile?） 在没有volatile的时候，执行完count++，执行结果其实是写到CPU缓存中，没有马上写回到内存中，后续在某些情况下（比如CPU缓存不够用）再将CPU缓存中的值flush到内存。因为没有存到内存里，其他线程是不能及时看到执行结果的。 在有volatile的时候，执行完count++，执行结果写入缓存中，并同时写入内存中，所以可以保证其它线程马上看到执行的结果。 但是，volatile 并没有保证原子性，在某个线程执行（1）（2）（3）的时候，volatile 并没有锁定 count 的值，也就是并不能阻塞其他线程也执行（1）（2）（3）。可能有两个线程同时执行（1），所以（2）计算出来一样的结果，然后（3）存回的也是同一个值。考虑下面一段代码：12345int some_int = 100;while(some_int == 100)&#123; //your code&#125; 因为编译器认为some_int没被改变过，一直是100。但是在多线程时，如果执行完第一行，但是还没执行到第三行时，另一个线程修改了some_int，while就不能进入循环了。加了volatile后，阻止了编译器优化，每次读到some_int会从内存中读取，而不是本线程的寄存去（当然这会损失效率）。这就是volatile的作用。 一句话总结：volatile保证线程能读到最新的数据，因为是从内存中读取，且存入内存中。而不是线程各自的寄存器中读写。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中断子系统之一：中断系统基本原理]]></title>
    <url>%2F2019%2F05%2F08%2FLinux%E4%B8%AD%E6%96%AD%E5%AD%90%E7%B3%BB%E7%BB%9F%E4%B9%8B%E4%B8%80-%E4%B8%AD%E6%96%AD%E7%B3%BB%E7%BB%9F%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[声明：本博内容均由http://blog.csdn.net/droidphone原创。 设备、中断控制器和CPU一个完整的设备中，与中断相关的硬件可以划分为3类，它们分别是：设备、中断控制器和CPU本身，下图展示了一个smp系统中的中断硬件的组成结构： 设备：设备是发起中断的源，当设备需要请求某种服务的时候，它会发起一个硬件中断信号，通常，该信号会连接至中断控制器，由中断控制器做进一步的处理。在现代的移动设备中，发起中断的设备可以位于soc（system-on-chip）芯片的外部，也可以位于soc的内部，因为目前大多数soc都集成了大量的硬件IP，例如I2C、SPI、Display Controller等等。 中断控制器：中断控制器负责收集所有中断源发起的中断，现有的中断控制器几乎都是可编程的，通过对中断控制器的编程，我们可以控制每个中断源的优先级、中断的电器类型，还可以打开和关闭某一个中断源，在smp系统中，甚至可以控制某个中断源发往哪一个CPU进行处理。对于ARM架构的soc，使用较多的中断控制器是VIC（Vector Interrupt Controller），进入多核时代以后，GIC（General Interrupt Controller）的应用也开始逐渐变多。 CPU：CPU是最终响应中断的部件，它通过对可编程中断控制器的编程操作，控制和管理者系统中的每个中断，当中断控制器最终判定一个中断可以被处理时，他会根据事先的设定，通知其中一个或者是某几个cpu对该中断进行处理，虽然中断控制器可以同时通知数个cpu对某一个中断进行处理，实际上，最后只会有一个cpu相应这个中断请求，但具体是哪个cpu进行响应是可能是随机的，中断控制器在硬件上对这一特性进行了保证，不过这也依赖于操作系统对中断系统的软件实现。在smp系统中，cpu之间也通过IPI（inter processor interrupt）中断进行通信。 IRQ编号系统中每一个注册的中断源，都会分配一个唯一的编号用于识别该中断，我们称之为IRQ编号。IRQ编号贯穿在整个Linux的通用中断子系统中。在移动设备中，每个中断源的IRQ编号都会在arch相关的一些头文件中，例如arch/xxx/mach-xxx/include/irqs.h。驱动程序在请求中断服务时，它会使用IRQ编号注册该中断，中断发生时，cpu通常会从中断控制器中获取相关信息，然后计算出相应的IRQ编号，然后把该IRQ编号传递到相应的驱动程序中。 在驱动程序中申请中断Linux中断子系统向驱动程序提供了一系列的API，其中的一个用于向系统申请中断：123int request_threaded_irq(unsigned int irq, irq_handler_t handler, irq_handler_t thread_fn, unsigned long irqflags, const char *devname, void *dev_id) 其中， irq是要申请的IRQ编号， handler是中断处理服务函数，该函数工作在中断上下文中，如果不需要，可以传入NULL，但是不可以和thread_fn同时为NULL； thread_fn是中断线程的回调函数，工作在内核进程上下文中，如果不需要，可以传入NULL，但是不可以和handler同时为NULL； irqflags是该中断的一些标志，可以指定该中断的电气类型，是否共享等信息； devname指定该中断的名称； dev_id用于共享中断时的cookie data，通常用于区分共享中断具体由哪个设备发起； 关于该API的详细工作机理我们后面再讨论。 通用中断子系统（Generic irq）的软件抽象在通用中断子系统（generic irq）出现之前，内核使用do_IRQ处理所有的中断，这意味着do_IRQ中要处理各种类型的中断，这会导致软件的复杂性增加，层次不分明，而且代码的可重用性也不好。事实上，到了内核版本2.6.38，__do_IRQ这种方式已经彻底在内核的代码中消失了。通用中断子系统的原型最初出现于ARM体系中，一开始内核的开发者们把3种中断类型区分出来，他们是： 电平触发中断（level type） 边缘触发中断（edge type） 简易的中断（simple type） 后来又针对某些需要回应eoi（end of interrupt）的中断控制器，加入了fast eoi type，针对smp加入了per cpu type。把这些不同的中断类型抽象出来后，成为了中断子系统的流控层。要使所有的体系架构都可以重用这部分的代码，中断控制器也被进一步地封装起来，形成了中断子系统中的硬件封装层。我们可以用下面的图示表示通用中断子系统的层次结构： 硬件封装层 它包含了体系架构相关的所有代码，包括中断控制器的抽象封装，arch相关的中断初始化，以及各个IRQ的相关数据结构的初始化工作，cpu的中断入口也会在arch相关的代码中实现。中断通用逻辑层通过标准的封装接口（实际上就是struct irq_chip定义的接口）访问并控制中断控制器的行为，体系相关的中断入口函数在获取IRQ编号后，通过中断通用逻辑层提供的标准函数，把中断调用传递到中断流控层中。我们看看irq_chip的部分定义：12345678910111213141516171819struct irq_chip &#123; const char *name; unsigned int (*irq_startup)(struct irq_data *data); void (*irq_shutdown)(struct irq_data *data); void (*irq_enable)(struct irq_data *data); void (*irq_disable)(struct irq_data *data); void (*irq_ack)(struct irq_data *data); void (*irq_mask)(struct irq_data *data); void (*irq_mask_ack)(struct irq_data *data); void (*irq_unmask)(struct irq_data *data); void (*irq_eoi)(struct irq_data *data); int (*irq_set_affinity)(struct irq_data *data, const struct cpumask *dest, bool force); int (*irq_retrigger)(struct irq_data *data); int (*irq_set_type)(struct irq_data *data, unsigned int flow_type); int (*irq_set_wake)(struct irq_data *data, unsigned int on); ......&#125;; 看到上面的结构定义，很明显，它实际上就是对中断控制器的接口抽象，我们只要对每个中断控制器实现以上接口（不必全部），并把它和相应的irq关联起来，上层的实现即可通过这些接口访问中断控制器。而且，同一个中断控制器的代码可以方便地被不同的平台所重用。 中断流控层：所谓中断流控是指合理并正确地处理连续发生的中断，比如一个中断在处理中，同一个中断再次到达时如何处理，何时应该屏蔽中断，何时打开中断，何时回应中断控制器等一系列的操作。该层实现了与体系和硬件无关的中断流控处理操作，它针对不同的中断电气类型（level，edge……），实现了对应的标准中断流控处理函数，在这些处理函数中，最终会把中断控制权传递到驱动程序注册中断时传入的处理函数或者是中断线程中。目前内核提供了以下几个主要的中断流控函数的实现（只列出部分）： handle_simple_irq(); handle_level_irq(); 电平中断流控处理程序 handle_edge_irq(); 边沿触发中断流控处理程序 handle_fasteoi_irq(); 需要eoi的中断处理器使用的中断流控处理程序 handle_percpu_irq(); 该irq只有单个cpu响应时使用的流控处理程序 中断通用逻辑层：该层实现了对中断系统几个重要数据的管理，并提供了一系列的辅助管理函数。同时，该层还实现了中断线程的实现和管理，共享中断和嵌套中断的实现和管理，另外它还提供了一些接口函数，它们将作为硬件封装层和中断流控层以及驱动程序API层之间的桥梁，例如以下API： generic_handle_irq(); irq_to_desc(); irq_set_chip(); irq_set_chained_handler(); 驱动程序API：该部分向驱动程序提供了一系列的API，用于向系统申请/释放中断，打开/关闭中断，设置中断类型和中断唤醒系统的特性等操作。驱动程序的开发者通常只会使用到这一层提供的这些API即可完成驱动程序的开发工作，其他的细节都由另外几个软件层较好地“隐藏”起来了，驱动程序开发者无需再关注底层的实现，这看起来确实是一件美妙的事情，不过我认为，要想写出好的中断代码，还是花点时间了解一下其他几层的实现吧。其中的一些API如下： enable_irq(); disable_irq(); disable_irq_nosync(); request_threaded_irq(); irq_set_affinity(); irq描述结构：struct irq_desc整个通用中断子系统几乎都是围绕着irq_desc结构进行，系统中每一个irq都对应着一个irq_desc结构，所有的irq_desc结构的组织方式有两种： 基于数组方式：平台相关板级代码事先根据系统中的IRQ数量，定义常量：NR_IRQS，在kernel/irq/irqdesc.c中使用该常量定义irq_desc结构数组：1234567struct irq_desc irq_desc[NR_IRQS] __cacheline_aligned_in_smp = &#123; [0 ... NR_IRQS-1] = &#123; .handle_irq = handle_bad_irq, .depth = 1, .lock = __RAW_SPIN_LOCK_UNLOCKED(irq_desc-&gt;lock), &#125;&#125;; 基于基数树方式：当内核的配置项CONFIG_SPARSE_IRQ被选中时，内核使用基数树（radix tree）来管理irq_desc结构，这一方式可以动态地分配irq_desc结构，对于那些具备大量IRQ数量或者IRQ编号不连续的系统，使用该方式管理irq_desc对内存的节省有好处，而且对那些自带中断控制器管理设备自身多个中断源的外部设备，它们可以在驱动程序中动态地申请这些中断源所对应的irq_desc结构，而不必在系统的编译阶段保留irq_desc结构所需的内存。下面我们看一看irq_desc的部分定义：1234567891011121314struct irq_data &#123; unsigned int irq; unsigned long hwirq; unsigned int node; unsigned int state_use_accessors; struct irq_chip *chip; struct irq_domain *domain; void *handler_data; void *chip_data; struct msi_desc *msi_desc;#ifdef CONFIG_SMP cpumask_var_t affinity;#endif&#125;; 1234567891011121314151617181920212223242526struct irq_desc &#123; struct irq_data irq_data; unsigned int __percpu *kstat_irqs; irq_flow_handler_t handle_irq;#ifdef CONFIG_IRQ_PREFLOW_FASTEOI irq_preflow_handler_t preflow_handler;#endif struct irqaction *action; /* IRQ action list */ unsigned int status_use_accessors; unsigned int depth; /* nested irq disables */ unsigned int wake_depth; /* nested wake enables */ unsigned int irq_count; /* For detecting broken IRQs */ raw_spinlock_t lock; struct cpumask *percpu_enabled;#ifdef CONFIG_SMP const struct cpumask *affinity_hint; struct irq_affinity_notify *affinity_notify;#ifdef CONFIG_GENERIC_PENDING_IRQ cpumask_var_t pending_mask;#endif#endif wait_queue_head_t wait_for_threads; const char *name;&#125; ____cacheline_internodealigned_in_smp; 对于irq_desc中的主要字段做一个解释： irq_data 这个内嵌结构在2.6.37版本引入，之前的内核版本的做法是直接把这个结构中的字段直接放置在irq_desc结构体中，然后在调用硬件封装层的chip-&gt;xxx()回调中传入IRQ编号作为参数，但是底层的函数经常需要访问-&gt;handler_data，-&gt;chip_data，-&gt;msi_desc等字段，这需要利用irq_to_desc(irq)来获得irq_desc结构的指针，然后才能访问上述字段，者带来了性能的降低，尤其在配置为sparse irq的系统中更是如此，因为这意味着基数树的搜索操作。为了解决这一问题，内核开发者把几个低层函数需要使用的字段单独封装为一个结构，调用时的参数则改为传入该结构的指针。实现同样的目的，那为什么不直接传入irq_desc结构指针？因为这会破坏层次的封装性，我们不希望低层代码可以看到不应该看到的部分，仅此而已。 kstat_irqs 用于irq的一些统计信息，这些统计信息可以从proc文件系统中查询。 action 中断响应链表，当一个irq被触发时，内核会遍历该链表，调用action结构中的回调handler或者激活其中的中断线程，之所以实现为一个链表，是为了实现中断的共享，多个设备共享同一个irq，这在外围设备中是普遍存在的。 status_use_accessors 记录该irq的状态信息，内核提供了一系列irq_settings_xxx的辅助函数访问该字段，详细请查看kernel/irq/settings.h depth 用于管理enable_irq()/disable_irq()这两个API的嵌套深度管理，每次enable_irq时该值减去1，每次disable_irq时该值加1，只有depth==0时才真正向硬件封装层发出关闭irq的调用，只有depth==1时才会向硬件封装层发出打开irq的调用。disable的嵌套次数可以比enable的次数多，此时depth的值大于1，随着enable的不断调用，当depth的值为1时，在向硬件封装层发出打开irq的调用后，depth减去1后，此时depth为0，此时处于一个平衡状态，我们只能调用disable_irq，如果此时enable_irq被调用，内核会报告一个irq失衡的警告，提醒驱动程序的开发人员检查自己的代码。 lock 用于保护irq_desc结构本身的自旋锁。 affinity_hit 用于提示用户空间，作为优化irq和cpu之间的亲缘关系的依据。 pending_mask 用于调整irq在各个cpu之间的平衡。 wait_for_threads 用于synchronize_irq()，等待该irq所有线程完成。 irq_data结构中的各字段： irq 该结构所对应的IRQ编号。 hwirq 硬件irq编号，它不同于上面的irq； node 通常用于hwirq和irq之间的映射操作； state_use_accessors 硬件封装层需要使用的状态信息，不要直接访问该字段，内核定义了一组函数用于访问该字段：irqd_xxxx()，参见include/linux/irq.h。 chip 指向该irq所属的中断控制器的irq_chip结构指针 handler_data 每个irq的私有数据指针，该字段由硬件封转层使用，例如用作底层硬件的多路复用中断。 chip_data 中断控制器的私有数据，该字段由硬件封转层使用。 msi_desc 用于PCIe总线的MSI或MSI-X中断机制。 affinity 记录该irq与cpu之间的亲缘关系，它其实是一个bit-mask，每一个bit代表一个cpu，置位后代表该cpu可能处理该irq。 这是通用中断子系统系列文章的第一篇，这里不会详细介绍各个软件层次的实现原理，但是有必要对整个架构做简要的介绍： 系统启动阶段，取决于内核的配置，内核会通过数组或基数树分配好足够多的irq_desc结构； 根据不同的体系结构，初始化中断相关的硬件，尤其是中断控制器； 为每个必要irq的irq_desc结构填充默认的字段，例如irq编号，irq_chip指针，根据不同的中断类型配置流控handler； 设备驱动程序在初始化阶段，利用request_threaded_irq() api申请中断服务，两个重要的参数是handler和thread_fn； 当设备触发一个中断后，cpu会进入事先设定好的中断入口，它属于底层体系相关的代码，它通过中断控制器获得irq编号，在对irq_data结构中的某些字段进行处理后，会将控制权传递到中断流控层（通过irq_desc-&gt;handle_irq）； 中断流控处理代码在作出必要的流控处理后，通过irq_desc-&gt;action链表，取出驱动程序申请中断时注册的handler和thread_fn，根据它们的赋值情况，或者只是调用handler回调，或者启动一个线程执行thread_fn，又或者两者都执行； 至此，中断最终由驱动程序进行了响应和处理。 中断子系统的proc文件接口在/proc目录下面，有两个与中断子系统相关的文件和子目录，它们是： /proc/interrupts：文件 /proc/irq：子目录 读取interrupts会依次显示irq编号，每个cpu对该irq的处理次数，中断控制器的名字，irq的名字，以及驱动程序注册该irq时使用的名字，以下是一个例子： /proc/irq目录下面会为每个注册的irq创建一个以irq编号为名字的子目录，每个子目录下分别有以下条目： smp_affinity irq和cpu之间的亲缘绑定关系； smp_affinity_hint 只读条目，用于用户空间做irq平衡只用； spurious 可以获得该irq被处理和未被处理的次数的统计信息； handler_name 驱动程序注册该irq时传入的处理程序的名字； 根据irq的不同，以上条目不一定会全部都出现，以下是某个设备的例子：12345678910111213141516171819202122# cd /proc/irq# lsls332248............1211default_smp_affinity# ls 332bcmsdh_sdmmcspuriousnodeaffinity_hintsmp_affinity# cat 332/smp_affinity3 可见，以上设备是一个使用双核cpu的设备，因为smp_affinity的值是3，系统默认每个中断可以由两个cpu进行处理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信的方式——信号、管道、消息队列、共享内存]]></title>
    <url>%2F2019%2F05%2F08%2F%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84%E6%96%B9%E5%BC%8F-%E4%BF%A1%E5%8F%B7-%E7%AE%A1%E9%81%93-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[多进程首先，先来讲一下fork之后，发生了什么事情。 由fork创建的新进程被称为子进程（child process）。该函数被调用一次，但返回两次。两次返回的区别是子进程的返回值是0，而父进程的返回值则是新进程（子进程）的进程 id。将子进程id返回给父进程的理由是：因为一个进程的子进程可以多于一个，没有一个函数使一个进程可以获得其所有子进程的进程id。对子进程来说，之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid；也可以调用getppid()来获取父进程的id。(进程id 0总是由交换进程使用，所以一个子进程的进程id不可能为0 )。 fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，子进程拥有父进程当前运行到的位置（两进程的程序计数器pc值相同，也就是说，子进程是从fork返回处开始执行的），但有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。可以这样想象，2个进程一直同时运行，而且步调一致，在fork之后，他们分别作不同的工作，也就是分岔了。这也是fork为什么叫fork的原因 至于哪一个最先运行，可能与操作系统（调度算法）有关，而且这个问题在实际应用中并不重要，如果需要父子进程协同，可以通过原语的办法解决。 常见的通信方式： 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。 信号（sinal）：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 信号：信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，知道该进程恢复执行并传递给他为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。 Linux提供了几十种信号，分别代表着不同的意义。信号之间依靠他们的值来区分，但是通常在程序中使用信号的名字来表示一个信号。在Linux系统中，这些信号和以他们的名称命名的常量被定义在/usr/includebitssignum.h文件中。通常程序中直接包含&lt;signal.h&gt;就好。 信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式，信号可以在用户空间进程和内核之间直接交互。内核也可以利用信号来通知用户空间的进程来通知用户空间发生了哪些系统事件。信号事件有两个来源： 硬件来源，例如按下了cltr+C，通常产生中断信号sigint 软件来源，例如使用系统调用或者命令发出信号。最常用的发送信号的系统函数是kill,raise,setitimer,sigation,sigqueue函数。软件来源还包括一些非法运算等操作。 一旦有信号产生，用户进程对信号产生的相应有三种方式： 执行默认操作，linux对每种信号都规定了默认操作。 捕捉信号，定义信号处理函数，当信号发生时，执行相应的处理函数。 忽略信号，当不希望接收到的信号对进程的执行产生影响，而让进程继续执行时，可以忽略该信号，即不对信号进程作任何处理。 有两个信号是应用进程无法捕捉和忽略的，即SIGKILL和SEGSTOP，这是为了使系统管理员能在任何时候中断或结束某一特定的进程。 上图表示了Linux中常见的命令 信号发送：信号发送的关键使得系统知道向哪个进程发送信号以及发送什么信号。下面是信号操作中常用的函数： 例子：创建子进程，为了使子进程不在父进程发出信号前结束，子进程中使用raise函数发送sigstop信号，使自己暂停；父进程使用信号操作的kill函数，向子进程发送sigkill信号，子进程收到此信号，结束子进程。 信号处理当某个信号被发送到一个正在运行的进程时，该进程即对次特定的信号注册相应的信号处理函数，以完成所需处理。设置信号处理方式的是signal函数，在程序正常结束前，在应用signal函数恢复系统对信号的默认处理方式。 信号阻塞有时候既不希望进程在接收到信号时立刻中断进程的执行，也不希望此信号完全被忽略掉，而是希望延迟一段时间再去调用信号处理函数，这个时候就需要信号阻塞来完成。 例子：主程序阻塞了cltr+c的sigint信号。用sigpromask将sigint假如阻塞信号集合。 管道：管道允许在进程之间按先进先出的方式传送数据，是进程间通信的一种常见方式。 管道是Linux 支持的最初Unix IPC形式之一，具有以下特点： 管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道； 匿名管道只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）； 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。 管道分为pipe（无名管道）和fifo（命名管道）两种，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。 pipe用于相关进程之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将自动撤销。 FIFO即命名管道，在磁盘上有对应的节点，但没有数据块——换言之，只是拥有一个名字和相应的访问权限，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。 管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。 无名管道：pipe的例子：父进程创建管道，并在管道中写入数据，而子进程从管道读出数据 命名管道：和无名管道的主要区别在于，命名管道有一个名字，命名管道的名字对应于一个磁盘索引节点，有了这个文件名，任何进程有相应的权限都可以对它进行访问。 而无名管道却不同，进程只能访问自己或祖先创建的管道，而不能访任意访问已经存在的管道——因为没有名字。 Linux中通过系统调用mknod()或makefifo()来创建一个命名管道。最简单的方式是通过直接使用shell1mkfifo myfifo 等价于1mknod myfifo p 以上命令在当前目录下创建了一个名为myfifo的命名管道。用ls -p命令查看文件的类型时，可以看到命名管道对应的文件名后有一条竖线”|”，表示该文件不是普通文件而是命名管道。 使用open()函数通过文件名可以打开已经创建的命名管道，而无名管道不能由open来打开。当一个命名管道不再被任何进程打开时，它没有消失，还可以再次被打开，就像打开一个磁盘文件一样。 可以用删除普通文件的方法将其删除，实际删除的事磁盘上对应的节点信息。 例子：用命名管道实现聊天程序，一个张三端，一个李四端。两个程序都建立两个命名管道，fifo1,fifo2,张三写fifo1，李四读fifo1；李四写fifo2，张三读fifo2。 用select把管道描述符和stdin加入集合，用select进行阻塞，如果有i/o的时候唤醒进程。（粉红色部分为select部分，黄色部分为命名管道部分） 在linux系统中，除了用pipe系统调用建立管道外，还可以使用C函数库中管道函数popen函数来建立管道，使用pclose关闭管道。 例子：设计一个程序用popen创建管道，实现 ls -l |grep main.c的功能 分析：先用popen函数创建一个读管道，调用fread函数将ls -l的结果存入buf变量，用printf函数输出内容，用pclose关闭读管道； 接着用popen函数创建一个写管道，调用fprintf函数将buf的内容写入管道，运行grep命令。 popen的函数原型：1FILE* popen(const char* command,const char* type); 参数说明：command是子进程要执行的命令，type表示管道的类型，r表示读管道，w代表写管道。如果成功返回管道文件的指针，否则返回NULL。 使用popen函数读写管道，实际上也是调用pipe函数调用建立一个管道，再调用fork函数建立子进程，接着会建立一个shell 环境，并在这个shell环境中执行参数所指定的进程。 消息队列：消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。 消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。 可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。 消息队列的常用函数如下表： 进程间通过消息队列通信，主要是：创建或打开消息队列，添加消息，读取消息和控制消息队列。 例子：用函数msget创建消息队列，调用msgsnd函数，把输入的字符串添加到消息队列中，然后调用msgrcv函数，读取消息队列中的消息并打印输出，最后再调用msgctl函数，删除系统内核中的消息队列。（黄色部分是消息队列相关的关键代码，粉色部分是读取stdin的关键代码） 共享内存：共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。 采用共享内存进行通信的一个主要好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。 一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件，因此，采用共享内存的通信方式效率非常高。 共享内存有两种实现方式：1、内存映射 2、共享内存机制 内存映射内存映射 memory map机制使进程之间通过映射同一个普通文件实现共享内存，通过mmap()系统调用实现。普通文件被映射到进程地址空间后，进程可以 像访问普通内存一样对文件进行访问，不必再调用read/write等文件操作函数。 例子：创建子进程，父子进程通过匿名映射实现共享内存。 分析：主程序中先调用mmap映射内存，然后再调用fork函数创建进程。那么在调用fork函数之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap函数的返回地址，这样，父子进程就可以通过映射区域进行通信了。 UNIX System V共享内存机制IPC的共享内存指的是把所有的共享数据放在共享内存区域（IPC shared memory region），任何想要访问该数据的进程都必须在本进程的地址空间新增一块内存区域，用来映射存放共享数据的物理内存页面。 和前面的mmap系统调用通过映射一个普通文件实现共享内存不同，UNIX system V共享内存是通过映射特殊文件系统shm中的文件实现进程间的共享内存通信。 例子：设计两个程序，通过unix system v共享内存机制，一个程序写入共享区域，另一个程序读取共享区域。 分析：一个程序调用fotk函数产生标准的key，接着调用shmget函数，获取共享内存区域的id，调用shmat函数，映射内存，循环计算年龄，另一个程序读取共享内存。 （fotk函数在消息队列部分已经用过了，根据pathname指定的文件（或目录）名称，以及proj参数指定的数字，ftok函数为IPC对象生成一个唯一性的键值。）1key_t ftok(char* pathname,char proj)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[__attribute__二三事]]></title>
    <url>%2F2019%2F05%2F07%2Fc%E4%B8%ADattribute%E4%BA%8C%E4%B8%89%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[123static inline skew_heap_entry_t *skew_heap_insert( skew_heap_entry_t *a, skew_heap_entry_t *b, compare_f comp) __attribute__((always_inline)); 这个函数是在做uCore的时候发现的，有一个特别的地方attribute((always_inline))，之前从来没见过，于是去查了一下，不查不知道，一查下一跳啊，这竟然是GUN C的一个从来没听过的属性。 当我们用__inline__ __attribute__((always_inline))修饰一个函数的时候,编译器会将我们的代码编译.在调用的地方将我们的函数,插入到调用的地方. attribute是GNU C特色之一,在iOS用的比较广泛.系统中有许多地方使用到. attribute可以设置函数属性（Function Attribute ）、变量属性（Variable Attribute ）和类型属性（Type Attribute)等. 函数属性(Function Attribute) noreturn noinline always_inline pure const nothrow sentinel format format_arg no_instrument_function section constructor destructor used unused deprecated weak malloc alias warn_unused_result nonnull 类型属性(Type Attributes) aligned packed transparent_union, unused, deprecated may_alias 变量属性(Variable Attribute) aligned packed Clang特有的 availability overloadable 书写格式书写格式：attribute后面会紧跟一对原括弧，括弧里面是相应的attribute参数1__attribute__(xxx) 常见的系统用法format1#define NS_FORMAT_FUNCTION(F,A) __attribute__((format(__NSString__, F, A))) format属性可以给被声明的函数加上类似printf或者scanf的特征，它可以使编译器检查函数声明和函数实际调用参数之间的格式化字符串是否匹配。该功能十分有用，尤其是处理一些很难发现的bug。对于format参数的使用如下format (archetype, string-index, first-to-check)第一参数需要传递“archetype”指定是哪种风格,这里是 NSString；“string-index”指定传入函数的第几个参数是格式化字符串；“first-to-check”指定第一个可变参数所在的索引. noreturn官方例子: abort() 和 exit() 该属性通知编译器函数从不返回值。当遇到类似函数还未运行到return语句就需要退出来的情况，该属性可以避免出现错误信息。 availability官方例子:12345678910111213- (CGSize)sizeWithFont:(UIFont *)font NS_DEPRECATED_IOS(2_0, 7_0, &quot;Use -sizeWithAttributes:&quot;) __TVOS_PROHIBITED; //来看一下 后边的宏 #define NS_DEPRECATED_IOS(_iosIntro, _iosDep, ...) CF_DEPRECATED_IOS(_iosIntro, _iosDep, __VA_ARGS__) define CF_DEPRECATED_IOS(_iosIntro, _iosDep, ...) __attribute__((availability(ios,introduced=_iosIntro,deprecated=_iosDep,message=&quot;&quot; __VA_ARGS__))) //宏展开以后如下__attribute__((availability(ios,introduced=2_0,deprecated=7_0,message=&quot;&quot;__VA_ARGS__)));//ios即是iOS平台//introduced 从哪个版本开始使用//deprecated 从哪个版本开始弃用//message 警告的消息 availability属性是一个以逗号为分隔的参数列表，以平台的名称开始，包含一些放在附加信息里的一些里程碑式的声明。 introduced：第一次出现的版本。 deprecated：声明要废弃的版本，意味着用户要迁移为其他API obsoleted： 声明移除的版本，意味着完全移除，再也不能使用它 unavailable：在这些平台不可用 message：一些关于废弃和移除的额外信息，clang发出警告的时候会提供这些信息，对用户使用替代的API非常有用。 这个属性支持的平台：ios，macosx。123456789//如果经常用,建议定义成类似系统的宏- (void)oldMethod:(NSString *)string __attribute__((availability(ios,introduced=2_0,deprecated=7_0,message=&quot;用 -newMethod: 这个方法替代 &quot;)))&#123; NSLog(@&quot;我是旧方法,不要调我&quot;);&#125; - (void)newMethod:(NSString *)string&#123; NSLog(@&quot;我是新方法&quot;);&#125; visibility语法:1__attribute__((visibility(&quot;visibility_type&quot;))) 其中，visibility_type 是下列值之一： default:假定的符号可见性可通过其他选项进行更改。缺省可见性将覆盖此类更改。缺省可见性与外部链接对应。 hidden:该符号不存放在动态符号表中，因此，其他可执行文件或共享库都无法直接引用它。使用函数指针可进行间接引用。 internal:除非由特定于处理器的应用二进制接口 (psABI) 指定，否则，内部可见性意味着不允许从另一模块调用该函数。 protected:该符号存放在动态符号表中，但定义模块内的引用将与局部符号绑定。也就是说，另一模块无法覆盖该符号。 除指定 default 可见性外，此属性都可与在这些情况下具有外部链接的声明结合使用。您可在 C 和 C++ 中使用此属性。在 C++ 中，还可将它应用于类型、成员函数和命名空间声明。 系统用法:123456// UIKIT_EXTERN extern #ifdef __cplusplus #define UIKIT_EXTERN extern &quot;C&quot; __attribute__((visibility (&quot;default&quot;))) #else #define UIKIT_EXTERN extern __attribute__((visibility (&quot;default&quot;))) #endif nonnull编译器对函数参数进行NULL的检查,参数类型必须是指针类型(包括对象)1234567- (int)addNum1:(int *)num1 num2:(int *)num2 __attribute__((nonnull (1,2)))&#123;//1,2表示第一个和第二个参数不能为空 return *num1 + *num2;&#125; - (NSString *)getHost:(NSURL *)url __attribute__((nonnull (1)))&#123;//第一个参数不能为空 return url.host;&#125; 常见用法aligned__attribute((aligned (n)))，让所作用的结构成员对齐在n字节自然边界上。如果结构中有成员的长度大于n，则按照最大成员的长度来对齐.例如: 不加修饰的情况123456typedef struct&#123; char member1; int member2; short member3;&#125;Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:45.380 Study[917:436064] Family size is 12 修改字节对齐为1123456typedef struct&#123; char member1; int member2; short member3;&#125;__attribute__ ((aligned (1))) Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:05.315 Study[914:435764] Family size is 12 和上面的结果一致,因为设定的字节对齐为1.而结构体中成员的最大字节数是int 4个字节,1 &lt; 4,按照4字节对齐,和系统默认一致. 修改字节对齐为8123456typedef struct&#123; char member1; int member2; short member3;&#125;__attribute__ ((aligned (8))) Family; 输出字节:1NSLog(@&quot;Family size is %zd&quot;,sizeof(Family)); 输出结果为:12016-07-25 10:28:05.315 Study[914:435764] Family size is 16 这里 8 &gt; 4,按照8字节对齐,结果为16。 可是想了半天,也不知道这玩意有什么用,设定值小于系统默认的,和没设定一样,设定大了,又浪费空间,效率也没提高,感觉学习学习就好. packed让指定的结构结构体按照一字节对齐,测试:1234567//不加packed修饰typedef struct &#123; char version; int16_t sid; int32_t len; int64_t time;&#125; Header; 计算长度:1NSLog(@&quot;size is %zd&quot;,sizeof(Header)); 输出结果为:12016-07-22 11:53:47.728 Study[14378:5523450] size is 16 可以看出,默认系统是按照4字节对齐1234567//加packed修饰typedef struct &#123; char version; int16_t sid; int32_t len; int64_t time;&#125;__attribute__ ((packed)) Header; 计算长度1NSLog(@&quot;size is %zd&quot;,sizeof(Header)); 输出结果为:12016-07-22 11:57:46.970 Study[14382:5524502] size is 15 用packed修饰后,变为1字节对齐,这个常用于与协议有关的网络传输中. noinline &amp; always_inline内联函数:内联函数从源代码层看，有函数的结构，而在编译后，却不具备函数的性质。内联函数不是在调用时发生控制转移，而是在编译时将函数体嵌入在每一个调用处。编译时，类似宏替换，使用函数体替换调用处的函数名。一般在代码中用inline修饰，但是能否形成内联函数，需要看编译器对该函数定义的具体处理 noinline 不内联always_inline 总是内联这两个都是用在函数上内联的本质是用代码块直接替换掉函数调用处,好处是:快代码的执行，减少系统开销. 适用场景:这个函数更小这个函数不被经常调用 使用例子:12//函数声明void test(int a) __attribute__((always_inline)); warn_unused_result当函数或者方法的返回值很重要时,要求调用者必须检查或者使用返回值,否则编译器会发出警告提示1234 - (BOOL)availiable __attribute__((warn_unused_result))&#123; return 10;&#125; constructor / destructor意思是: 构造器和析构器;constructor修饰的函数会在main函数之前执行,destructor修饰的函数会在程序exit前调用.示例如下:1234567891011121314151617181920212223int main(int argc, char * argv[]) &#123; @autoreleasepool &#123; NSLog(@&quot;main&quot;); return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class])); &#125;&#125; __attribute__((constructor))void before()&#123; NSLog(@&quot;before main&quot;);&#125; __attribute__((destructor))void after()&#123; NSLog(@&quot;after main&quot;);&#125; //在viewController中调用exit- (void)viewDidLoad &#123; [super viewDidLoad]; exit(0);&#125; 输出如下:1232016-07-21 21:49:17.446 Study[14162:5415982] before main2016-07-21 21:49:17.447 Study[14162:5415982] main2016-07-21 21:49:17.534 Study[14162:5415982] after main 注意点: 程序退出的时候才会调用after函数,经测试,手动退出程序会执行 上面两个函数不管写在哪个类里,哪个文件中效果都一样 如果存在多个修饰的函数,那么都会执行,顺序不定 实际上如果存在多个修饰过的函数,可以它们的调整优先级 代码如下:123456789101112131415161718192021222324int main(int argc, char * argv[]) &#123; @autoreleasepool &#123; NSLog(@&quot;main&quot;); return UIApplicationMain(argc, argv, nil, NSStringFromClass([AppDelegate class])); &#125;&#125; __attribute__((constructor(101)))void before1()&#123; NSLog(@&quot;before main - 1&quot;);&#125;__attribute__((constructor(102)))void before2()&#123; NSLog(@&quot;before main - 2&quot;);&#125; __attribute__((destructor(201)))void after1()&#123; NSLog(@&quot;after main - 1&quot;);&#125;__attribute__((destructor(202)))void after2()&#123; NSLog(@&quot;after main - 2&quot;);&#125; 输出结果如下:123452016-07-21 21:59:35.622 Study[14171:5418393] before main - 12016-07-21 21:59:35.624 Study[14171:5418393] before main - 22016-07-21 21:59:35.624 Study[14171:5418393] main2016-07-21 21:59:35.704 Study[14171:5418393] after main - 22016-07-21 21:59:35.704 Study[14171:5418393] after main - 1 注意点: 括号内的值表示优先级,[0,100]这个返回时系统保留的,自己千万别调用. 根据输出结果可以看出,main函数之前的,数值越小,越先调用;main函数之后的数值越大,越先调用. 当函数声明和函数实现分开写时,格式如下:12345static void before() __attribute__((constructor)); static void before() &#123; printf(&quot;before\n&quot;);&#125; 讨论:+load,constructor,main的执行顺序,代码如下:1234567+ (void)load&#123; NSLog(@&quot;load&quot;);&#125;__attribute__((constructor))void before()&#123; NSLog(@&quot;before main&quot;);&#125; 输出结果如下:1232016-07-21 22:13:58.591 Study[14185:5421811] load2016-07-21 22:13:58.592 Study[14185:5421811] before main2016-07-21 22:13:58.592 Study[14185:5421811] main 可以看出执行顺序为:load-&gt;constructor-&gt;main为什么呢?因为 dyld（动态链接器，程序的最初起点）在加载 image（可以理解成 Mach-O 文件）时会先通知 objc runtime 去加载其中所有的类，每加载一个类时，它的 +load 随之调用，全部加载完成后，dyld 才会调用这个 image 中所有的 constructor 方法,然后才调用main函数. enable_if用来检查参数是否合法,只能用来修饰函数:12345void printAge(int age)__attribute__((enable_if(age &gt; 0 &amp;&amp; age &lt; 120, &quot;你丫太监?&quot;)))&#123; NSLog(@&quot;%d&quot;,age);&#125; 表示只能输入的参数只能是 0 ~ 120左右,否则编译报错.]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode121. Best Time to Buy and Sell Stock]]></title>
    <url>%2F2019%2F05%2F07%2FLeetcode121%2F</url>
    <content type="text"><![CDATA[Best Time to Buy and Sell Stock Say you have an array for which the ith element is the price of a given stock on day i. If you were only permitted to complete at most one transaction (i.e., buy one and sell one share of the stock), design an algorithm to find the maximum profit. Note that you cannot sell a stock before you buy one. Example 1:12Input: [7,1,5,3,6,4]Output: 5 Explanation: Buy on day 2 (price = 1) and sell on day 5 (price = 6), profit = 6-1 = 5. Not 7-1 = 6, as selling price needs to be larger than buying price.Example 2:12Input: [7,6,4,3,1]Output: 0 Explanation: In this case, no transaction is done, i.e. max profit = 0. 我们按照动态规划的思想来思考这道问题。 状态有 买入（buy） 和 卖出（sell） 这两种状态。 转移方程对于买来说，买之后可以卖出（进入卖状态），也可以不再进行股票交易（保持买状态）。 对于卖来说，卖出股票后不在进行股票交易（还在卖状态）。 只有在手上的钱才算钱，手上的钱购买当天的股票后相当于亏损。也就是说当天买的话意味着损失-prices[i]，当天卖的话意味着增加prices[i]，当天卖出总的收益就是 buy+prices[i] 。 所以我们只要考虑当天买和之前买哪个收益更高，当天卖和之前卖哪个收益更高。 buy = max(buy, -price[i]) （注意：根据定义 buy 是负数）sell = max(sell, prices[i] + buy)边界 第一天 buy = -prices[0], sell = 0，最后返回 sell 即可。 12345678910111213class Solution &#123;public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; if(prices.size()&lt;=1) return 0; int buy = prices[0],sell=0; for(int i=1;i&lt;prices.size();i++)&#123; buy = min(prices[i],buy); sell = max(sell,prices[i]-buy); &#125; return sell; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cannon算法的原理实现以及性能评测]]></title>
    <url>%2F2019%2F05%2F06%2FCannon%E7%AE%97%E6%B3%95%E7%9A%84%E5%8E%9F%E7%90%86%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[简介 算法流程图 算法设计方法和模式任务划分：根据矩阵乘法公式中的累加计算的可分离性，将参与计算的两个矩阵分解成p个小矩阵块(共有p个计算节点)，每个节点只进行局部的小矩阵乘法，最终计算结束后将局部的小结果矩阵发送回Master节点。 通讯分析：由于算法在下发任务和收集结果的时候采用了主从模式，所以使用了Master-Worker的全局通讯，该部分通讯由于发送方只有一个0号线程，所以无法并行执行，只能串行执行。同时，在迭代进行小矩阵运算时，各计算节点之间也需要交换矩阵，进行了结构化通讯。该部分通讯由于通讯的局部特性，可以并行执行，能够提高效率。 任务组合：每个节点负责一个小矩阵的串行计算，同时负责小矩阵之间的通讯传递。 处理器映射：由于任务的划分个数等于处理器个数，所以在组合任务的同时完成了处理器映射。 Cannon算法采用了主从模式的同时也采用了分而治之的模式。一方面，0号线程作为Master，负责矩阵A和矩阵B以及矩阵C的I/O，也负责小矩阵的分发和结果的聚集。而其他节点作为Worker进行本地的小矩阵串行乘法计算。另一方面，Cannon算法将两个大矩阵的乘法运算分解为若干各小矩阵的乘法运算，最终计算结束后，将计算结果聚集回来，也采用了分而治之的思想。cannon算法不仅实现了矩阵乘法运算的并行化，也减少了分块矩阵乘法的局部存储量，节省了节点的内存开销。 算法复杂度设计算的是一个nn的矩阵乘一个nn的矩阵，共有p个节点，那么Cannon算法的时间复杂度计算如下： 矩阵乘加的时间由于采用了并行化，所以所需时间为： n^3 / p 若不考虑节点延迟时间，设节点之间通讯的启动时间为ti，传输每个数字的时间为tw，则在两个节点间传输一个子矩阵的时间是：ti + n^2*tw / p 所以节点之间传输子矩阵所需的时间为：2*sqrt(p)*(ti + n^2*tw / p) 综上，cannon算法总的所需时间为：2*sqrt(p)*(ti + n^2*tw / p) + n^3 / p 时间复杂度：O(n^3 / p)空间复杂度：O(n^2) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468#include&lt;stdio.h&gt;#include&lt;malloc.h&gt;#include&lt;stdlib.h&gt;#include&lt;mpi.h&gt;#include&lt;pthread.h&gt;#include&lt;math.h&gt;#include&lt;cstring&gt;int myrank, p;// Compute C = A*B. A is a n1*n2 matrix. B is a n2*n3 matrix.void matmul(double* A, double* B, double* C, int n1, int n2, int n3)//做矩阵乘法，结果累加到C矩阵中(需要保证C矩阵初始化过)&#123; int i,j,k; //简单的串行矩阵乘法 for (i = 0; i &lt; n1; i++) &#123; for (j = 0; j &lt; n3; j++) &#123; for (k = 0; k &lt; n2; k++) &#123; C[i*n3+j]+=A[i*n2+k]*B[k*n3+j]; &#125; &#125; &#125; &#125;int setup(int argc,char**argv,double** fstreama,double** fstreamb,int* dim)&#123; FILE* fha; FILE* fhb; int n1,n2,n3; int re=1; if (!(fha = fopen(argv[1], &quot;r&quot;))) //打开存储A矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[1], 1);//打开失败输出信息 return -1; &#125; if(fread(&amp;n1,sizeof(int),1,fha)==0)//读取矩阵的行数 &#123; printf(&quot;fread error1!\n&quot;); return -1; &#125; if(fread(&amp;n2,sizeof(int),1,fha)==0)//读取矩阵的列数 &#123; printf(&quot;fread error2!\n&quot;); return -1; &#125; *fstreama = (double *) malloc (n1*n2*sizeof(double));//为矩阵申请内存 if(fread(*fstreama,sizeof(double),n1*n2,fha)==0)//读取矩阵内容 &#123; printf(&quot;fread error3!\n&quot;); return -1; &#125; fclose(fha);//关闭矩阵文件 if (!(fhb = fopen(argv[2], &quot;r&quot;))) //打开存储A矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[2], 2);//打开失败输出信息 return -1; &#125; if(fread(&amp;n2,sizeof(int),1,fhb)==0)//读取矩阵的行数 &#123; printf(&quot;fread error4!\n&quot;); return -1; &#125; if(fread(&amp;n3,sizeof(int),1,fhb)==0)//读取矩阵的列数 &#123; printf(&quot;fread error5!\n&quot;); return -1; &#125; *fstreamb = (double *) malloc (n2*n3*sizeof(double));//为矩阵申请内存 if(fread(*fstreamb,sizeof(double),n2*n3,fhb)==0)//读取矩阵内容 &#123; printf(&quot;fread error6!\n&quot;); return -1; &#125; fclose(fhb);//关闭矩阵文件 dim[0] = n1;//返回矩阵的大小参数 dim[1] = n2;//返回矩阵的大小参数 dim[2] = n3;//返回矩阵的大小参数 return 0;&#125;void scatter_matrix(double* matrixbuf, int rows, int cols, double* local_matrix, int rootp)//将矩阵划分为小矩阵块并分发到各个节点&#123; int row, column, i, j, count; int maxrows_block = (rows + rootp - 1)/rootp;//小A矩阵块行数的最大值 int maxcols_block = (cols + rootp - 1)/rootp;//小矩阵块列数的最大值 double * matrixbuf2 = NULL;//用来格式化原矩阵的缓冲区 MPI_Status status;//返回通信的状态 if(myrank == 0)//0号线程 &#123; if(!(matrixbuf2 = (double *)malloc(maxcols_block*maxrows_block*rootp*rootp*sizeof(double))))//为缓冲区申请内存 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //将矩阵转化为按块连续存放的形式，方便分发每块小矩阵，同时对于边界没有对齐的小矩阵，补零对齐，方便计算 count = 0; for (i = 0; i &lt; rootp; i++)&#123; for (j = 0; j &lt; rootp; j++)&#123; if(i!=(rootp-1)&amp;&amp;j==(rootp-1))//特殊处理除了最后一行以外的最后一列 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if((j * maxcols_block + column)&gt;=cols)//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row ) * cols +j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else if(i==(rootp-1)&amp;&amp;j!=(rootp-1))//特殊处理除了最后一列以外的最后一行 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if((i * maxrows_block + row)&gt;=rows)//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row)*cols + j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else if(i==(rootp-1)&amp;&amp;j==(rootp-1))//特殊处理最后一列最后一行的那个块 &#123; for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; if(((j * maxcols_block + column)&gt;=cols) || ((i * maxrows_block + row)&gt;=rows))//补零对齐 &#123; matrixbuf2[count] = 0; &#125;else&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row) * cols + j * maxcols_block + column]; &#125; count++; &#125; &#125; &#125;else&#123;//普通的块 for (row = 0; row &lt; maxrows_block; row++)&#123; for (column = 0; column &lt; maxcols_block; column++)&#123; matrixbuf2[count] = matrixbuf[(i * maxrows_block + row)*cols + j * maxcols_block + column]; count++; &#125; &#125; &#125; &#125; &#125; if(count!=maxcols_block*maxrows_block*rootp*rootp)//检查是否出错 &#123; printf(&quot;scatter_matrix error!\n&quot;); return ; &#125; //将属于本地的那个块留下来 for(i = 0; i &lt; maxrows_block*maxcols_block; i++) &#123; local_matrix[i] = matrixbuf2[i]; &#125; //分发其他块到对应的线程 for(i = 1; i &lt; rootp*rootp; i++) &#123; MPI_Send((matrixbuf2 + (i * maxcols_block * maxrows_block)), maxcols_block * maxrows_block, MPI_DOUBLE, i, 0, MPI_COMM_WORLD); &#125; &#125; else &#123;//非0号线程 MPI_Recv(local_matrix, maxcols_block * maxrows_block , MPI_DOUBLE, 0, 0, MPI_COMM_WORLD, &amp;status);//非零线程接受0线程发送的小矩阵块 &#125; if(matrixbuf2!=NULL)&#123;//释放缓冲区 free(matrixbuf2); &#125; return;&#125;//A and bufA : n1_block*n2_block; B and bufB : n2_block*n3_block//进行cannon算法，各个节点在本地进行矩阵乘法，并交换矩阵块，进行循环，直到计算完毕void cannon(double* A, double* bufA, double* B, double* bufB, double* C, int n1_block, int n2_block, int n3_block, int rootp)&#123; MPI_Request send_a_req, send_b_req; MPI_Status send_a_status, send_b_status, recv_a_status, recv_b_status; int cycle_count; int rank_next_a,rank_next_b; int rank_last_a,rank_last_b; int curRowP,curColP,i,j; int tag=0;//表示当前正确数据再A中还是bufA中，0表示在A中，1表示在bufA中 //先初始化各个块，即A_ij循环左移i步，B_ij循环上移j步，C_ij初始化为零 //初始化矩阵C，值全部设为0 for(i=0;i&lt;n1_block;i++) &#123; for(j=0;j&lt;n3_block;j++) &#123; C[i*n3_block+j] = 0; &#125; &#125; //循环传播小矩阵 curRowP = myrank/rootp;//当前节点所在行 curColP = myrank%rootp;//当前节点所在列 //获得左移i步后的节点号 if((curColP-curRowP)&lt;0) &#123; rank_next_a = myrank+rootp-curRowP; &#125;else&#123; rank_next_a = myrank-curRowP; &#125; //获得上移j步后的节点号 if((curRowP-curColP)&lt;0) &#123; rank_next_b = myrank -curColP*rootp + rootp*rootp; &#125;else&#123; rank_next_b = myrank -curColP*rootp; &#125; //获得接受左移i步的节点号 if((curColP+curRowP)&gt;=rootp) &#123; rank_last_a = myrank+curRowP-rootp; &#125;else&#123; rank_last_a = myrank+curRowP; &#125; //获得接受上移j步的节点号 if((curRowP+curColP)&gt;=rootp) &#123; rank_last_b = myrank + curColP*rootp - rootp*rootp; &#125;else&#123; rank_last_b = myrank + curColP*rootp; &#125; //非阻塞发送矩阵，如果不需要移动，则直接本地memcpy if(rank_next_a!=myrank) &#123; MPI_Isend(A, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 &#125;else &#123; memcpy(bufA, A, n1_block*n2_block*sizeof(double));//本地直接memcpy &#125; if(rank_next_b!=myrank) &#123; MPI_Isend(B, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 &#125;else &#123; memcpy(bufB, B, n2_block*n3_block*sizeof(double));//本地直接memcpy &#125; //阻塞接受矩阵 if(rank_last_a!=myrank) &#123; MPI_Recv(bufA, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A &#125; if(rank_last_b!=myrank) &#123; MPI_Recv(bufB, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B &#125; //阻塞等待发送矩阵结束 if(rank_next_a!=myrank) &#123; MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 &#125; if(rank_next_b!=myrank) &#123; MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 &#125; MPI_Barrier(MPI_COMM_WORLD);//同步 tag=1; if(myrank%rootp==0)//第一列的节点 &#123; rank_next_a = myrank+rootp-1; &#125;else&#123; rank_next_a = myrank-1; &#125; if(myrank/rootp==0)//第一行的节点 &#123; rank_next_b = myrank+rootp*(rootp-1); &#125;else&#123; rank_next_b = myrank - rootp; &#125; if(myrank%rootp==(rootp-1))//最后一列的节点 &#123; rank_last_a = myrank-rootp+1; &#125;else&#123; rank_last_a = myrank+1; &#125; if(myrank/rootp==(rootp-1))//最后一行的节点 &#123; rank_last_b = myrank-rootp*(rootp-1); &#125;else&#123; rank_last_b = myrank + rootp; &#125; //循环，每次做当前块的乘加运算，并使得A_ij循环左移1步，B_ij循环上移1步 for(cycle_count = 0; cycle_count &lt; rootp; cycle_count++) &#123; if(tag==1)//数据在bufA中 &#123; matmul(bufA, bufB, C, n1_block, n2_block, n3_block);//做当前节点的矩阵乘法 //循环传播小矩阵 MPI_Isend(bufA, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 MPI_Isend(bufB, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 MPI_Recv(A, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A MPI_Recv(B, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 tag = 0; &#125;else&#123;//数据在A中 matmul(A, B, C, n1_block, n2_block, n3_block);//做当前节点的矩阵乘法 //循环传播小矩阵 MPI_Isend(A, n1_block*n2_block, MPI_DOUBLE, rank_next_a, 0, MPI_COMM_WORLD, &amp;send_a_req);//非阻塞发送矩阵A，避免死锁 MPI_Isend(B, n2_block*n3_block, MPI_DOUBLE, rank_next_b, 0, MPI_COMM_WORLD, &amp;send_b_req);//非阻塞发送矩阵B，避免死锁 MPI_Recv(bufA, n1_block*n2_block, MPI_DOUBLE, rank_last_a, 0, MPI_COMM_WORLD, &amp;recv_a_status);//阻塞接受矩阵A MPI_Recv(bufB, n2_block*n3_block, MPI_DOUBLE, rank_last_b, 0, MPI_COMM_WORLD, &amp;recv_b_status);//阻塞接受矩阵B MPI_Wait(&amp;send_a_req, &amp;send_a_status);//阻塞发送矩阵A到结束 MPI_Wait(&amp;send_b_req, &amp;send_b_status);//阻塞发送矩阵B到结束 tag = 1; &#125; MPI_Barrier(MPI_COMM_WORLD);//同步 &#125; return;&#125;//gather_matrix((double*)(fstreamc + sizeof(int)*2), n1, n3, C, rootp);//将各个节点的小矩阵C收集到0号节点void gather_matrix(double* matrixCbuf, int rows, int cols, double* local_C, int rootp, int rows_block_pad, int cols_block_pad)&#123; int curRow, curCol, i, j, curP; MPI_Status status; double * matrixC_pad = NULL;//有零填充的矩阵C if(myrank == 0) &#123;//0号线程 if(!(matrixC_pad = (double *)malloc(rows_block_pad*cols_block_pad*rootp*rootp*sizeof(double))))//为缓冲区申请内存 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //将本地计算结果直接复制过来 for(i = 0; i &lt; rows_block_pad * cols_block_pad; i++)&#123; matrixC_pad[i] = local_C[i]; &#125; //接受其他非0线程的计算结果 for(i = 1; i &lt; rootp*rootp; i++)&#123; MPI_Recv(matrixC_pad + (i * rows_block_pad * cols_block_pad), rows_block_pad * cols_block_pad, MPI_DOUBLE, i, 0,MPI_COMM_WORLD, &amp;status); &#125; //重新整理矩阵C，除去零填充，并且重新整理顺序 for(i=0;i&lt;rows;i++) &#123; for(j=0;j&lt;cols;j++) &#123; curP = (i/rows_block_pad)*rootp+(j/cols_block_pad);//属于第几个节点，从0开始 curRow = i%rows_block_pad;//属于小矩阵的第几行 curCol = j%cols_block_pad;//属于小矩真的第几列 matrixCbuf[i * cols + j] = matrixC_pad[curP * rows_block_pad * cols_block_pad +curRow*cols_block_pad+curCol]; &#125; &#125; &#125; else &#123;//非0号线程 MPI_Send(local_C,rows_block_pad * cols_block_pad, MPI_DOUBLE, 0, 0, MPI_COMM_WORLD);//给0号线程发送计算结果 &#125; if(matrixC_pad!=NULL) &#123; free(matrixC_pad);//释放缓冲区 &#125; return ;&#125;int main(int argc, char** argv)&#123; double elapsed_time; // Suppose A:n1xn2, B:n2xn3. n1~n3 are read from input files int n1, n2, n3,rootp; // Buffers for matrix A, B, C. Because A, B will be shifted, so they each have two buffers double *A, *B, *C, *bufA, *bufB; // On proc 0, buffers to cache matrix files of A, B and C double *fstreama, *fstreamb; char *fstreamc; MPI_Init(&amp;argc, &amp;argv); MPI_Comm_rank(MPI_COMM_WORLD, &amp;myrank); MPI_Comm_size(MPI_COMM_WORLD, &amp;p); rootp = sqrt(p); if (p != rootp*rootp) &#123; printf(&quot;Processor number must be a square!\n&quot;); &#125; // On proc 0, preprocess the command line, read in files for A, B and // put their sizes in dim[]. int dim[3]; if (myrank == 0) &#123;//0号线程负责从文件中读取矩阵A和B以及他们的大小信息 if (setup(argc, argv, &amp;fstreama, &amp;fstreamb, dim)!=0) &#123; MPI_Finalize(); // Something error during preprocessing exit(-1); &#125; &#125; MPI_Bcast(dim, 3, MPI_INT, 0, MPI_COMM_WORLD);//0号线程将A和B矩阵的size广播给所有线程 n1 = dim[0];//A： n1*n2 n2 = dim[1];//B: n2*n3 n3 = dim[2]; // Allocate memories for A, B, C, bufA and bufB. // Suppose an m*n matrix is 2D block-distributed on a rootp*rootp processor grid. // If rootp doesn&apos;t divide m or n, then submatrixes won&apos;t have the same size. // Because we will shift A, B, so we allocate memories according to the max // rows and cols of A and B. //因为有可能rootp不能整除n1,n2,n3,所以在申请内存的时候考虑最大的块的大小 int maxrows_a = (n1 + rootp - 1)/rootp;//A矩阵块行数的最大值 int maxcols_a = (n2 + rootp - 1)/rootp;//A矩阵块列数的最大值 int maxrows_b = maxcols_a;//B矩阵块行数的最大值 int maxcols_b = (n3 + rootp - 1)/rootp;//B矩阵块列数的最大值 int bufA_size = sizeof(double)*maxrows_a*maxcols_a;//大小为一个A矩阵块的大小 int bufB_size = sizeof(double)*maxrows_b*maxcols_b;//大小为一个B矩阵块的大小 int bufC_size = sizeof(double)*maxrows_a*maxcols_b;//大小为一个C矩阵块的大小 char* buf; int i; if(!(buf = (char *)malloc(bufA_size*2 + bufB_size*2 + bufC_size)))//申请两个A矩阵块，两个B矩阵块，和一个C矩阵块 &#123; printf(&quot;Memory allocation failed\n&quot;); &#125; //或者以下4个缓存区的指针位置 A = (double*)buf; bufA = (double*) (buf + bufA_size); B = (double*) (buf + bufA_size*2); bufB = (double*) (buf + bufA_size*2 + bufB_size); C = (double*) (buf + bufA_size*2 + bufB_size*2); // Proc 0 scatters A, B to other procs in a 2D block distribution fashion scatter_matrix((double*)fstreama, n1, n2, A, rootp);//0号线程分发A矩阵块到各个线程 MPI_Barrier(MPI_COMM_WORLD);//同步 scatter_matrix((double*)fstreamb, n2, n3, B, rootp);//0号线程分发B矩阵块到各个线程 MPI_Barrier(MPI_COMM_WORLD);//同步 elapsed_time = MPI_Wtime();//记录计算开始的时间戳 // Compute C=A*B by Cannon algorithm cannon(A, bufA, B, bufB, C, maxrows_a,maxcols_a,maxcols_b, rootp); MPI_Barrier(MPI_COMM_WORLD);//同步 elapsed_time = MPI_Wtime() - elapsed_time;//记录计算所用的时间 // Proc 0 gathers C from other procs and write it out FILE* fhc; int fsizec = sizeof(int)*2 + sizeof(double)*n1*n3;//存储C矩阵以及两个大小参数的空间大小 if(myrank == 0) &#123; if (!(fhc = fopen(argv[3], &quot;w&quot;))) //打开输出C矩阵的文件 &#123; printf(&quot;Can&apos;t open file %s, Errno=%d\n&quot;, argv[3], 3);//打开失败输出信息 MPI_Finalize(); &#125; fstreamc = (char *)malloc(fsizec);//申请存储矩阵C的内存空间 ((int*)fstreamc)[0] = n1;//记录矩阵C的行数 ((int*)fstreamc)[1] = n3;//记录矩阵C的列数 &#125; gather_matrix((double*)(fstreamc + sizeof(int)*2), n1, n3, C, rootp, maxrows_a, maxcols_b);//聚集计算结果，其他线程将自己的C矩阵块发送给线程0 MPI_Barrier(MPI_COMM_WORLD); // Make sure proc 0 read all it needs if(myrank == 0) &#123; printf(&quot;Cannon algrithm: multiply a %dx%d with a %dx%d, use %.2f(s)\n&quot;,n1, n2, n2, n3, elapsed_time); fwrite(fstreamc, sizeof(char), fsizec, fhc);//线程0将矩阵C写入文件 fclose(fhc);//关闭文件 free(fstreama);//释放内存 free(fstreamb);//释放内存 free(fstreamc);//释放内存 &#125; free(buf);//释放存储小矩阵块的内存空间 MPI_Finalize(); return 0;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode933. Number of Recent Calls]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode933%2F</url>
    <content type="text"><![CDATA[Write a class RecentCounter to count recent requests. It has only one method: ping(int t), where t represents some time in milliseconds. Return the number of pings that have been made from 3000 milliseconds ago until now. Any ping with time in [t - 3000, t] will count, including the current ping. It is guaranteed that every call to ping uses a strictly larger value of t than before. Example 1: Input: inputs = [“RecentCounter”,”ping”,”ping”,”ping”,”ping”], inputs = [[],[1],[100],[3001],[3002]]Output: [null,1,2,3,3] Note: Each test case will have at most 10000 calls to ping.Each test case will call ping with strictly increasing values of t.Each call to ping will have 1 &lt;= t &lt;= 10^9. 行吧，我是没看懂这个题是什么意思。。。只是判断t和3000的关系。1234567891011121314151617181920class RecentCounter &#123;public: queue&lt;int&gt; q; RecentCounter() &#123; &#125; int ping(int t) &#123; q.push(t); while(q.front()&lt;t-3000) q.pop(); return q.size(); &#125;&#125;;/** * Your RecentCounter object will be instantiated and called as such: * RecentCounter* obj = new RecentCounter(); * int param_1 = obj-&gt;ping(t); */]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode69. Sqrt(x)]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode69%2F</url>
    <content type="text"><![CDATA[Implement int sqrt(int x). Compute and return the square root of x, where x is guaranteed to be a non-negative integer. Since the return type is an integer, the decimal digits are truncated and only the integer part of the result is returned. Example 1: Input: 4Output: 2Example 2: Input: 8Output: 2Explanation: The square root of 8 is 2.82842…, and since the decimal part is truncated, 2 is returned. 二分求一个数的开方，做的恶心，垃圾题，浪费时间。123456789101112131415class Solution &#123;public: int mySqrt(int x) &#123; int low = 0, high = x, mid; if(x&lt;2) return x; // to avoid mid = 0 while(low&lt;high) &#123; mid = (low + high)/2; if(x/mid &gt;= mid) low = mid+1; else high = mid; &#125; return high-1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode852. Peak Index in a Mountain Array]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode852%2F</url>
    <content type="text"><![CDATA[Let’s call an array A a mountain if the following properties hold: A.length &gt;= 3There exists some 0 &lt; i &lt; A.length - 1 such that A[0] &lt; A[1] &lt; … A[i-1] &lt; A[i] &gt; A[i+1] &gt; … &gt; A[A.length - 1]Given an array that is definitely a mountain, return any i such that A[0] &lt; A[1] &lt; … A[i-1] &lt; A[i] &gt; A[i+1] &gt; … &gt; A[A.length - 1]. Example 1:12Input: [0,1,0]Output: 1 Example 2:12Input: [0,2,1,0]Output: 1 Note: 3 &lt;= A.length &lt;= 100000 &lt;= A[i] &lt;= 10^6A is a mountain, as defined above. 判断一个“山峰”数组的山峰在哪里，本来以为还要判断这个是不是山峰数组的，所以多写了一些，对结果没影响，懒得删了。 123456789101112131415161718192021class Solution &#123;public: int peakIndexInMountainArray(vector&lt;int&gt;&amp; A) &#123; int res; bool isreal=false; if(A.size()&lt;3) return false; for(int i=1;i&lt;A.size();i++)&#123; if(A[i]&gt;A[i-1]) if(!isreal) continue; if(A[i]&lt;A[i-1])&#123; if(!isreal)&#123; res=i-1; isreal=true; &#125; &#125; &#125; return res; &#125;&#125;; 我这个做法不好，可以用二分查找。123456789101112class Solution &#123; public int peakIndexInMountainArray(int[] A) &#123; int lo = 0, hi = A.length - 1; while (lo &lt; hi) &#123; int mi = lo + (hi - lo) / 2; if (A[mi] &lt; A[mi + 1]) lo = mi + 1; else hi = mi; &#125; return lo; &#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode728. Self Dividing Numbers]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode728%2F</url>
    <content type="text"><![CDATA[A self-dividing number is a number that is divisible by every digit it contains. For example, 128 is a self-dividing number because 128 % 1 == 0, 128 % 2 == 0, and 128 % 8 == 0. Also, a self-dividing number is not allowed to contain the digit zero. Given a lower and upper number bound, output a list of every possible self dividing number, including the bounds if possible. Example 1:Input:left = 1, right = 22Output: [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 15, 22]Note: The boundaries of each input argument are 1 &lt;= left &lt;= right &lt;= 10000. 如果一个数能被组成这个数的数字整除，那就是要求的结果之一了。注意0的问题！1234567891011121314151617181920212223class Solution &#123;public: bool is(int x)&#123; int n = x; while(x&gt;0)&#123; int temp = x%10; if(temp==0)&#123; return false; &#125; if(n%temp != 0) return false; x/=10; &#125; return true; &#125; vector&lt;int&gt; selfDividingNumbers(int left, int right) &#123; vector&lt;int&gt; res; for(int x=left;x&lt;=right;x++) if(is(x)) res.push_back(x); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode617. Merge Two Binary Trees]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode617%2F</url>
    <content type="text"><![CDATA[Given two binary trees and imagine that when you put one of them to cover the other, some nodes of the two trees are overlapped while the others are not. You need to merge them into a new binary tree. The merge rule is that if two nodes overlap, then sum node values up as the new value of the merged node. Otherwise, the NOT null node will be used as the node of new tree. Example 1:1234567891011121314Input: Tree 1 Tree 2 1 2 / \ / \ 3 2 1 3 / \ \ 5 4 7 Output: Merged tree: 3 / \ 4 5 / \ \ 5 4 7 把两棵树合并，比较简单，递归即可。 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* res(TreeNode* t1, TreeNode* t2)&#123; if(!t1 &amp;&amp; !t2)&#123; return NULL; &#125; if(t1 &amp;&amp; !t2)&#123; return t1; &#125; if(!t1 &amp;&amp; t2)&#123; return t2; &#125; t1-&gt;val+=t2-&gt;val; t1-&gt;left = res(t1-&gt;left,t2-&gt;left); t1-&gt;right = res(t1-&gt;right,t2-&gt;right); return t1; &#125; TreeNode* mergeTrees(TreeNode* t1, TreeNode* t2) &#123; return res(t1,t2); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode921. Minimum Add to Make Parentheses Valid]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode921%2F</url>
    <content type="text"><![CDATA[Given a string S of ‘(‘ and ‘)’ parentheses, we add the minimum number of parentheses ( ‘(‘ or ‘)’, and in any positions ) so that the resulting parentheses string is valid. Formally, a parentheses string is valid if and only if: It is the empty string, orIt can be written as AB (A concatenated with B), where A and B are valid strings, orIt can be written as (A), where A is a valid string.Given a parentheses string, return the minimum number of parentheses we must add to make the resulting string valid. Example 1:12Input: &quot;())&quot;Output: 1 Example 2:12Input: &quot;(((&quot;Output: 3 Example 3:12Input: &quot;()&quot;Output: 0 Example 4:12Input: &quot;()))((&quot;Output: 4 Note: S.length &lt;= 1000S only consists of ‘(‘ and ‘)’ characters. 一道变形的括号匹配，这里注意如果res为负数的话，要及时纠正成正的且也要在最终结果加一，如上边的Example4的样子，如果只是按照栈的做法，结果是0，是错的，其实要加4个。 1234567891011121314151617class Solution &#123;public: int minAddToMakeValid(string S) &#123; int res=0,result=0; for(int i=0;i&lt;S.size();i++) if(S[i]==&apos;(&apos;) res++; else&#123; res--; if(res&lt;0)&#123; res=0; result++; &#125; &#125; return result+res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1037. Valid Boomerang]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode1037%2F</url>
    <content type="text"><![CDATA[A boomerang is a set of 3 points that are all distinct and not in a straight line. Given a list of three points in the plane, return whether these points are a boomerang. Example 1:12Input: [[1,1],[2,3],[3,2]]Output: true Example 2:12Input: [[1,1],[2,2],[3,3]]Output: false Note: points.length == 3points[i].length == 20 &lt;=points[i][j]&lt;= 100 判断三个点是不是互异且不共线的，简单12345678910111213141516class Solution &#123;public: bool isBoomerang(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; for(int i=0;i&lt;points.size();i++) for(int j=i+1;j&lt;points.size();j++) if(points[i][0]==points[j][0] &amp;&amp; points[i][1]==points[j][1]) return false; int dx1 = points[1][0] - points[0][0]; int dx2 = points[1][1] - points[0][1]; int dx3 = points[2][0] - points[1][0]; int dx4 = points[2][1] - points[1][1]; if(dx1*dx4-dx2*dx3==0) return false; return true; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1038. Binary Search Tree to Greater Sum Tree]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode1038%2F</url>
    <content type="text"><![CDATA[Given the root of a binary search tree with distinct values, modify it so that every node has a new value equal to the sum of the values of the original tree that are greater than or equal to node.val. As a reminder, a binary search tree is a tree that satisfies these constraints: The left subtree of a node contains only nodes with keys less than the node’s key.The right subtree of a node contains only nodes with keys greater than the node’s key.Both the left and right subtrees must also be binary search trees. Example 1: Input: [4,1,6,0,2,5,7,null,null,null,3,null,null,null,8]Output: [30,36,21,36,35,26,15,null,null,null,33,null,null,null,8] 典型的中序遍历，先遍历右子树，再把root赋值，最后看左子树 1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int sum=0; void houxu(TreeNode* root)&#123; if(root-&gt;right) houxu(root-&gt;right); sum+=root-&gt;val; root-&gt;val = sum; if(root-&gt;left) houxu(root-&gt;left); &#125; TreeNode* bstToGst(TreeNode* root) &#123; houxu(root); return root; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode763 Partition Labels]]></title>
    <url>%2F2019%2F05%2F06%2FLeetcode763%2F</url>
    <content type="text"><![CDATA[A string S of lowercase letters is given. We want to partition this string into as many parts as possible so that each letter appears in at most one part, and return a list of integers representing the size of these parts. Example 1:12Input: S = &quot;ababcbacadefegdehijhklij&quot;Output: [9,7,8] Explanation:The partition is “ababcbaca”, “defegde”, “hijhklij”.This is a partition so that each letter appears in at most one part.A partition like “ababcbacadefegde”, “hijhklij” is incorrect, because it splits S into less parts.Note: S will have length in range [1, 500].S will consist of lowercase letters (‘a’ to ‘z’) only. 字符串分割，且每一个字符只能最多出现在一个子串中。1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; partitionLabels(string S) &#123; vector&lt;int&gt; res; int a[26]; for(int i=0;i&lt;S.size();i++)&#123; a[((int)(S[i]-&apos;a&apos;))]=i; &#125; int j=0,temp =0; for(int i=0;i&lt;S.size();i++)&#123; j=max(j,a[((int)(S[i]-&apos;a&apos;))]); if(i==j)&#123; res.push_back(i-temp+1); temp = i+1; &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode561. Array Partition I]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode561%2F</url>
    <content type="text"><![CDATA[Given an array of 2n integers, your task is to group these integers into n pairs of integer, say (a1, b1), (a2, b2), …, (an, bn) which makes sum of min(ai, bi) for all i from 1 to n as large as possible. Example 1:12Input: [1,4,3,2]Output: 4 Explanation: n is 2, and the maximum sum of pairs is 4 = min(1, 2) + min(3, 4).Note:n is a positive integer, which is in the range of [1, 10000].All the integers in the array will be in the range of [-10000, 10000]. 这道题目给了我们一个数组有2n integers， 需要我们把这个数组分成n对，然后从每一对里面拿小的那个数字，把所有的加起来，返回这个sum。并且要使这个sum 尽量最大。如何让sum 最大化呢，我们想一下，如果是两个数字，一个很小，一个很大，这样的话，取一个小的数字，就浪费了那个大的数字。所以我们要使每一对的两个数字尽可能接近。我们先把nums sort 一下，让它从小到大排列，接着每次把index： 0， 2， 4…偶数位的数字加起来就可以了。12345678910class Solution &#123;public: int arrayPairSum(vector&lt;int&gt;&amp; nums) &#123; sort(nums.begin(),nums.end()); int sum=0; for(int i=0;i&lt;nums.size();i+=2) sum+=nums[i]; return sum; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode942. DI String Match]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode942%2F</url>
    <content type="text"><![CDATA[Given a string S that only contains “I” (increase) or “D” (decrease), letN = S.length. Return any permutation A of [0, 1, …, N] such that for alli = 0, ..., N-1: If S[i] == “I”, then A[i] &lt; A[i+1]If S[i] == “D”, then A[i] &gt; A[i+1] Example 1:12Input: &quot;IDID&quot;Output: [0,4,1,3,2] Example 2:12Input: &quot;III&quot;Output: [0,1,2,3] Example 3:12Input: &quot;DDI&quot;Output: [3,2,0,1] Note: 1 &lt;= S.length &lt;= 10000S only contains characters “I” or “D”. 题目的意思是，将字符串与数组一一对应，因为数组多一位，不考虑这一位。剩下的位置，如果字符串写的是‘I’，那么该位置上的数应该比右边所有的数都小。而如果是‘D’，则是比右边的都大。现在需要找到其中任意一组。 其实这个题是一个贪心，并且有点dp的感觉。感觉这个题解不唯一，其实还是比较简单能够证明反例。评论有人提出了解法证明，可以看一下： 只需要证明，对于任何 &gt; 或者 &lt; , 算法的规则都能满足。△N = max-min; 由于每次遇到一个符号，△N-1。当符号为“ &lt; &lt; &lt;”: max–可以保证符号的正确性。当符号为“ &gt; &gt; &gt;”: min++可以保住符号的正确性。当符号为“ ……&lt; &gt; &lt; “: 任意时刻max和min开始比较，是否满足 min &lt; max?答案是：YES! 由于符号的数量为N，最开始△N = N。由于至少出现一对大于号和小于号 , min(△N)= 1，仍然满足min &lt; max;综上，得证。 因为每一位对应的数字只有两种情况：比右边所有数都大，或者都小。那么我们可以设定两个值，初始的话：low = 0，high = N。这样，从左开始遍历字符串，碰见一个字符，如果是‘I’，那么就直接赋值low，同时low++。这样，‘I’右边所有的数，一定是都比这个位置大的。因为此时low&gt;a[i]，同时high &gt; low。 反而言之，碰见‘D’，直接赋值hight，同时high–。这样所有的数就一定比这个小了。大概就是这样，在O(n)的时间复杂度下就能构造出答案数组。 123456789101112131415class Solution &#123;public: vector&lt;int&gt; diStringMatch(string S) &#123; vector&lt;int&gt; res = vector&lt;int&gt;(S.size()+1); int low = 0,high=S.size(); for(int i=0;i&lt;S.size();i++)&#123; if(S[i]==&apos;I&apos;) res[i]=low++; else res[i]=high--; &#125; res[S.size()]=low; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode797. All Paths From Source to Target]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode797%2F</url>
    <content type="text"><![CDATA[Given a directed, acyclic graph of N nodes. Find all possible paths from node 0 to node N-1, and return them in any order. The graph is given as follows: the nodes are 0, 1, …, graph.length - 1. graph[i] is a list of all nodes j for which the edge (i, j) exists. Example:12345678Input: [[1,2], [3], [3], []] Output: [[0,1,3],[0,2,3]] Explanation: The graph looks like this:0---&gt;1| |v v2---&gt;3There are two paths: 0 -&gt; 1 -&gt; 3 and 0 -&gt; 2 -&gt; 3. Note:The number of nodes in the graph will be in the range [2, 15].You can print different paths in any order, but you should keep the order of nodes inside one path. 这道题给了我们一个无回路有向图，包含N个结点，然后让我们找出所有可能的从结点0到结点N-1的路径。 这个图的数据是通过一个类似邻接链表的二维数组给的，最开始的时候博主没看懂输入数据的意思，其实很简单，我们来看例子中的input，[[1,2], [3], [3], []]，这是一个二维数组，最外层的数组里面有四个小数组，每个小数组其实就是和当前结点相通的邻结点，由于是有向图，所以只能是当前结点到邻结点，反过来不一定行。那么结点0的邻结点就是结点1和2，结点1的邻结点就是结点3，结点2的邻结点也是3，结点3没有邻结点。 那么其实这道题的本质就是遍历邻接链表，由于要列出所有路径情况，那么递归就是不二之选了。我们用cur来表示当前遍历到的结点，初始化为0，然后在递归函数中，先将其加入路径path，如果cur等于N-1了，那么说明到达结点N-1了，将path加入结果res。否则我们再遍历cur的邻接结点，调用递归函数即可，参见代码如下：12345678910111213class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; allPathsSourceTarget(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; vector&lt;vector&lt;int&gt;&gt; res; helper(graph, 0, &#123;&#125;, res); return res; &#125; void helper(vector&lt;vector&lt;int&gt;&gt;&amp; graph, int cur, vector&lt;int&gt; path, vector&lt;vector&lt;int&gt;&gt;&amp; res) &#123; path.push_back(cur); if (cur == graph.size() - 1) res.push_back(path); else for (int neigh : graph[cur]) helper(graph, neigh, path, res); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核内存管理学习之三（slab分配器）]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%89%EF%BC%88slab%E5%88%86%E9%85%8D%E5%99%A8%EF%BC%89%2F</url>
    <content type="text"><![CDATA[内核内存分配在linux内核中伙伴系统用来管理物理内存，其分配的单位是页，但是向用户程序一样，内核也需要动态分配内存，而伙伴系统分配的粒度又太大。由于内核无法借助标准的C库，因而需要别的手段来实现内核中动态内存的分配管理，linux采用的是slab分配器。slab分配器不仅可以提供动态内存的管理功能，而且可以作为经常分配并释放的内存的缓存。通过slab缓存，内核能够储备一些对象，供后续使用。需要注意的是slab分配器只管理内核的常规地址空间（准确的说是直接被映射到内核地址空间的那部分内存包括ZONE_NORMAL和ZONE_DMA）。采用了slab分配器后，在释放内存时，slab分配器将释放的内存块保存在一个列表中，而不是返回给伙伴系统。在下一次内核申请同样类型的对象时，会使用该列表中的内存开。slab分配器分配的优点： 可以提供小块内存的分配支持 不必每次申请释放都和伙伴系统打交道，提供了分配释放效率 如果在slab缓存的话，其在CPU高速缓存的概率也会较高。 伙伴系统的操作队系统的数据和指令高速缓存有影响，slab分配器降低了这种副作用 伙伴系统分配的页地址都页的倍数，这对CPU的高速缓存的利用有负面影响，页首地址对齐在页面大小上使得如果每次都将数据存放到从伙伴系统分配的页开始的位置会使得高速缓存的有的行被过度使用，而有的行几乎从不被使用。slab分配器通过着色使得slab对象能够均匀的使用高速缓存，提高高速缓存的利用率。 在引入了slab分配器后，内核的内存管理方案如图所示： slab分配器也不是万能的，它也有缺陷： 对于微型嵌入式系统，它显得比较复杂，这是可以使用经过优化的slob分配器，它使用内存块链表，并使用最先适配算法 对于具有大量内存的大型系统，仅仅建立slab分配器的数据结构就需要大量内存，这时候可以使用经过优化的slub分配器 无论是slab分配器家族的这三个中的那个一，它们提供的接口都是相同的：kmalloc,__kmalloc和kmalloc_node用于普通内存的分配kmem_cache_alloc，kmem_cache_alloc_node用于申请特定类型的内存内核中普通内存的申请使用kmalloc(size,flags),size是申请的大小，flags告诉分配器分配什么样的内存，如何分配等等。内核中普通内存的释放使用kfree(*ptr);释放ptr所指向的内存区。可以通过/proc/slabinfo查看活动的缓存列表。 slab分配器的原理slab算法是1994年开发出来的并首先用于sun microsystem solaris 2.4操作系统。这种算法的使用基于以下几个前提： 所存放数据的类型可以影响存储器取区的分配方式。 内核函数倾向于反复请求同一类型的存储器区。 对存储器区的请求可以根据它们发生的频率来分类。 所引入的对象大小不是几何分布的。 硬件高速缓存的高性能。在这种情况下，伙伴函数的每次调用都增加了对内存的平均访问时间。 slab分配器把对象分组放进高速缓存。每个高速缓存都是同种类型对象的一种“储备”。一个cache管理一组大小固定的内存块（也称为对象实体），每个内存块都可用作一种数据结构。cache中的内存块来自一到多个slab。一个slab来自物理内存管理器的一到多个物理页，该slab被分成一组固定大小的块，被称为slab对象（object），一个slab属于一个cache，其中的对象就是该cache所管理的固定大小的内存块。所以一个cache可以有一到多个slab。下图给出了slab分配器的各个部分及其相互关系： 在基于slab的内核内存管理器中，基本的概念是保存管理型数据的缓存（即slab cache，slab缓存）和保存被管理对象的各个slab。每个缓存都负责一种对象类型，比如kmalloc-128会负责管理65-128字节的内存的kmalloc分配。系统中的所有缓存类型都保存在一个链表slab_caches中。 slab缓存slab缓存的详细结构 如图所示： 每个缓存结构都包括了两个重要的成员： struct kmem_list3 **nodelists：kmem_list3结构中包含了三个链表头，分别对应于完全用尽的slab链表，部分用尽的slab链，空闲的slab链表，其中部分空闲的在最开始 struct array_cache *array[NR_CPUS + MAX_NUMNODES]：array是一个数组，系统中的每一个CPU，每一个内存节点都对应该数组中的一个元素。array_cache结构包含了一些特定于该CPU/节点的管理数据以及一个数组，每个数组元素都指向一个该CPU/节点刚释放的内存对象。该数组有助于提高高速缓存的利用率。 当释放内存对象时，首先将内存对象释放到该数组中对应的元素中 申请内存时，内核假定刚释放的内存对象仍然处于CPU高速缓存中，因而会先从该数组的对应数组元素中查找，看是否可以申请。 当特定于CPU/节点的缓存数组是空时，会用slab缓存中的空闲对象填充它 因此，对象分配的次序为： 特定于CPU/节点的缓存列表中的对象 当前已经存在于slab缓存中中的未用对象 从伙伴系统获得内存，然后创建的对象 slab对象对象在slab中不是连续排列的，其排列如图所示: slab对象的长度并不代表其确切的长度，因为需要对长度进行调整以满足对齐要求。对齐要求可能是： 创建slab时指定了SLAB_HWCACHE_ALIGN标志，则会按照cache_line_size的返回值对齐，即对齐的硬件缓存行上。如果对象小于硬件缓存行的一半，则将多个对象放入一个缓存行。 如果没有指定对齐标记，则对齐到BYTES_PER_WORD，即对齐到void指针所需字节数目。 为了使得slab满足对齐要求，会在slab对象中添加填充字节以满足对齐要求,使用对齐的地址可以会加速内存访问。每个slab都对应一个管理结构，它可能位于slab内部也可能位于slab外部专门为它申请的内存中，它保存了所有的管理数据，也包括一个链表域用于将slab连接起来，还包括一个指针指向它所属的cache。大多数情况下，slab内存区的长度是不能被对象长度整除的，因而就有了一些多余的内存，这些内存可以被用来以偏移量的形式给slab“着色”，着色后，缓存的各个slab成员会指定到不同的偏移量，进而可以将数据定位到不同的缓存行。内核通过对象自身即可找到它对应的slab，过程是:对象的物理地址-&gt;物理地址对应的page结构。然后由page找到对应的slab以及cache（包含在page结构中）。 slab分配器的实现使用的数据结构linux使用struct kmem_cache表示slab缓存，使用struct kmem_list3管理缓存所对应的slab链表的链表头，使用struct array_cache管理特定于CPU的slab对象的缓存(注意不是slab缓存是slab对象的缓存)。 内核采用的其它保护机制为了检测错误，内核采用了一些机制来对内存进行保护，主要的方法有：危险区：在每个对象的开始和结束处增加一个额外的内存区，其中会填充一些特殊的字段。如果这个区域被修改了，可能就是某些代码访问了不该访问的内存区域对象毒化：在建立和释放slab时，将对象用预定义的模式填充。如果在对象分配时发现该模式已经改变，就可能是发生了内存越界。 初始化slab分配器的初始化涉及到一个鸡与蛋的问题。为了初始化slab数据结构，内核需要很多远小于一页的内存区，很显然由kmalloc分配这种内存最合适，但是kmalloc只有在slab分配器初始化完才能使用。内核借助一些技巧来解决该问题。kmem_cache_init函数被内核用来初始化slab分配器。它在伙伴系统启用后调用。在SMP系统中，启动CPU正在运行，其它CPU还未初始化，它要在smp_init之前调用。slab采用多步逐步初始化slab分配器，其工作过程：创建第一个名为kmem_cache的slab缓存，此时该缓存的管理数据结构使用的是静态分配的内存。在slab分配器初始化完成后，会将这里使用的静态数据结构替换为动态分配的内存。初始化其它的slab缓存，由于已经初始化了第一个slab缓存，因此这一步是可行。将初始化过程由于“鸡与蛋”的问题而使用的静态数据结构替换为动态分配的。 API创建缓存slab分配器使用kmem_cache_create创建一个新的slab缓存。该函数的基本工作过程为： 参数检查 计算对齐 分配缓存的管理结构所需的内存 计算slab所需的物理内存大小以及每个slab中slab对象的个数 计算slab管理部分应该放在哪里，并存储在缓存的flags域中 计算slab的颜色，颜色数目存在color中，颜色偏移量存在color_off中 建立每CPU的缓存 将新创建的缓存添加到全局slab缓存链表slab_caches中 分配对象kmem_cache_alloc用于从指定的slab缓存分配对象。与kmalloc相比，它多了一个缓存指针的参数，用于指向所要从其中分配内存的缓存。其工作过程如图： 在NUMA系统中，如果在本节点分配失败，还会尝试其它节点。 cache_grow用于缓存的增长，它会从伙伴系统获取内存。其流程如图所示： 释放对象kmem_cache_free用于将对象归还给指定的slab缓存，类似于kmem_cache_free，它比kfree多了一个指向所归还到的slab缓存指针参数。其流程如图： free_block会将缓存中前batchcount个对象移动到slab链表中，并且将缓存中剩余的对象向数组的头部移动。根据slab对象所属的slab的状态(inuse域)，slab对象可能被归给给部分空闲链表（如果该slab中有些slab对象正在被使用）或者空闲链表（该slab中没有其它对象正在被使用），同时如果加入到空闲slab链表中的slab对象数目超过了free_limit的限制（在kmem_list3结构中），则会调用slab_destroy销毁slab。 缓存收缩可以使用kmem_cache_shrink来回收一个slab缓存所管理的内存。它会释放尽可能多的slab。它会尝试回收用于每CPU缓存的内存空间（调用free_block），以及用于空闲链表的slab内存空间，slab的释放最终都由slab_destroy完成。 通用缓存如果不涉及到特定类型的内存，而只是普通类型的内存，可以使用kmalloc和kfree来申请和释放缓存。内核会找到并使用适用于所申请的大小的通用slab缓存来进行分配和释放。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核内存管理学习之二（物理内存管理--伙伴系统）]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%BA%8C%EF%BC%88%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86--%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[伙伴系统原理伙伴关系定义：由一个母实体分成的两个各方面属性一致的两个子实体，这两个子实体就处于伙伴关系。在操作系统分配内存的过程中，一个内存块常常被分成两个大小相等的内存块，这两个大小相等的内存块就处于伙伴关系。它满足 3 个条件 ： 两个块具有相同大小记为 2^K 它们的物理地址是连续的 从同一个大块中拆分出来 伙伴算法的实现原理为了便于页面的维护，将多个页面组成内存块，每个内存块都有 2 的方幂个页，方幂的指数被称为阶 order。order相同的内存块被组织到一个空闲链表中。伙伴系统基于2的方幂来申请释放内存页。当申请内存页时，伙伴系统首先检查与申请大小相同的内存块链表中，检看是否有空闲页，如果有就将其分配出去，并将其从链表中删除，否则就检查上一级，即大小为申请大小的2倍的内存块空闲链表，如果该链表有空闲内存，就将其分配出去，同时将剩余的一部分（即未分配出去的一半）加入到下一级空闲链表中；如果这一级仍没有空闲内存；就检查它的上一级，依次类推，直到分配成功或者彻底失败，在成功时还要按照伙伴系统的要求，将未分配的内存块进行划分并加入到相应的空闲内存块链表在释放内存页时，会检查其伙伴是否也是空闲的，如果是就将它和它的伙伴合并为更大的空闲内存块，该检查会递归进行，直到发现伙伴正在被使用或者已经合并成了最大的内存块。 linux中的伙伴系统相关的结构系统中的每个物理内存页（页帧）都对应一个struct page数据结构，每个节点都包含了多个zone，每个zone都有struct zone表示，其中保存了用于伙伴系统的数据结构。zone中的struct free_area free_area[MAX_ORDER];用于管理该zone的伙伴系统信息。伙伴系统将基于这些信息管理该zone的物理内存。该数组中每个数组项用于管理一个空闲内存页块链表，同一个链表中的内存页块的大小相同，并且大小为2的数组下标次方页。MAX_ORDER定义了支持的最大的内存页块大小。12345struct free_area的定义如下struct free_area &#123; structlist_head free_list[MIGRATE_TYPES]; unsignedlong nr_free;&#125;; nr_free:其中nr_free表示内存页块的数目，对于0阶的表示以1页为单位计算，对于1阶的以2页为单位计算，n阶的以2的n次方为单位计算。 free_list:用于将具有该大小的内存页块连接起来。由于内存页块表示的是连续的物理页，因而对于加入到链表中的每个内存页块来说，只需要将内存页块中的第一个页加入该链表即可。因此这些链表连接的是每个内存页块中第一个内存页，使用了struct page中的struct list_head成员lru。free_list数组元素的每一个对应一种属性的类型，可用于不同的目地，但是它们的大小和组织方式相同。因此在伙伴系统看来，一个zone中的内存组织方式如下图所示： 基于伙伴系统的内存管理方式专注于内存节点的某个内存域的管理，但是系统中的所有zone都会通过备用列表连接起来。伙伴系统和内存域/节点的关系如下图所示： 系统中伙伴系统的当前信息可以通过/proc/buddyinfo查看： 这是我的PC上的信息，这些信息描述了每个zone中对应于每个阶的空闲内存页块的数目，从左到右阶数依次升高。 避免碎片碎片概念伙伴系统也存在一些问题，在系统长时间运行后，物理内存会出现很多碎片，如图所示： 这时虽然可用内存页还有很多，但是最大的连续物理内存也只有一页，这对于用户程序不成问题，因为用户程序通过页表映射，应用程序看到的总是连续的虚拟内存。但是对于内核来说就不行了，因为内核有时候需要使用连续的物理内存。 Linux解决方案碎片问题也存在于文件系统，文件系统中的碎片可以通过工具来解决，即分析文件系统，然后重新组织文件的位置，但是这种方不适用于内核，因为有些物理页时不能随意移动。内核采用的方法是反碎片（anti-fragmentation）。为此内核根据页的可移动性将其划分为3种不同的类型： 不可移动的页：在内存中有固定位置，不能移动。分配给核心内核的页大多是此种类型 可回收的页：不能移动，但是可以删除，其内容可以从某些源重新生成。 可移动的页：可以随意移动。属于用户进程的页属于这种类型，因为它们是通过页表映射的，因而在移动后只需要更新用户进程页表即可。 页的可移动性取决于它属于上述三类中的哪一类，内核将页面按照不同的可移动性进行分组，通过这种技术，虽然在不可移动页中仍可能出现碎片，但是由于具有不同可移动性的页不会进入同一个组，因而其它两个类型的内存块就可以获得较好的“对抗碎片”的特性。需要注意的是按照可移动性对内存页进行分组时在运行中进行的，而不是在一开始就设置好的。 数据结构内核定义了MIGRATE_TYPES中迁移类型，其定义如下：123456789enum &#123; MIGRATE_UNMOVABLE, MIGRATE_RECLAIMABLE, MIGRATE_MOVABLE, MIGRATE_PCPTYPES, /* the number of types on the pcp lists */ MIGRATE_RESERVE = MIGRATE_PCPTYPES, MIGRATE_ISOLATE, /* can&apos;t allocate from here */ MIGRATE_TYPES&#125;; 其中前三种分别对应于三种可移动性，其它几种的含义： MIGRATE_PCPTYPES：是per_cpu_pageset，即用来表示每CPU页框高速缓存的数据结构中的链表的迁移类型数目 MIGRATE_RESERVE：是在前三种的列表中都没用可满足分配的内存块时，就可以从MIGRATE_RESERVE分配 MIGRATE_ISOLATE：用于跨越NUMA节点移动物理内存页，在大型系统上，它有益于将物理内存页移动到接近于是用该页最频繁地CPU 每种类型都对应free_list中的一个数组项。类似于从zone中的分配，如果无法从指定的迁移类型分配到页，则会按照fallbacks指定的次序从备用迁移类型中尝试分配，它定义在page_alloc.c中。虽然该特性总是编译进去的，但是该特性只有在系统中有足够的内存可以分配到每种迁移类型对应的链表时才有意义，也就是说每个可以迁移性链表都要有“适量”的内存，内核需要对“适量”的判断是基于两个宏的： pageblock_order：内核认为够大的一个分配的阶。 pageblock_nr_pages：内核认为启用该特性时每个迁移链表需要具有的最少的内存页数。它的定义是基于pageblock_order的。 基于这个“适量”的概念内核会在build_all_zonelists中判断是否要启用该特性。page_group_by_mobility_disabled表示是否启用了该特性。内核定义了两个标志：__GFP_MOVABLE和__GFP_RECLAIMABLE分别用来表示可移动迁移类型和可回收迁移类型，如果没有设置这两个标志，则表示是不可移动的。如果页面迁移特性被禁止了，则所有的页都是不可移动页。 struct zone中包含了一个字段pageblock_flags，它用于跟踪包含pageblock_nr_pages个页的内存区的属性。在初始化期间，内核自动保证对每个迁移类型，在pageblock_flags中都分配了足够存储NR_PAGEBLOCK_BITS个比特的空间。 set_pageblock_migratetype用于设置一个以指定的页为起始地址的内存区的迁移类型。页的迁移类型是预先分配好的，对应的比特位总是可用，在页释放时，必须将其返还给正确的链表。get_pageblock_migratetype可用于从struct page中获取页的迁移类型。通过/proc/pagetypeinfo可以获取系统当前的信息。 在内存初始化期间memmap_init_zone会将所有的内存页都初始化为可移动的。该函数在paging_init中会最终被调到（会经过一些中间函数，其中就有free_area_init_node）。 虚拟可移动内存内核还提供了一种机制来解决碎片问题，即使用虚拟内存域ZONE_MOVABLE。其思想是：可用内存划分为两个部分，一部分用于可移动分配，一部分用于不可移动分配。这样就防止了不可移动页向可移动内存区域引入碎片。该机制需要管理员来配置两部分内存的大小。kernel参数kernelcore用于指定用于不可移动分配的内存数量，如果指定了该参数，其值会保存在required_kernelcore会基于它来计算。kernel参数movablecore用于指定用于可移动分配的内存数量，如果指定了该参数，则其值会被保存在required_movablecore中，同时会基于它来计算required_kernelcore，代码如下（函数find_zone_movable_pfns_for_nodes）：12corepages = totalpages - required_movablecore;required_kernelcore = max(required_kernelcore, corepages); 如果计算出来的required_kernelcore为0，则该机制将无效。该zone是一个虚拟zone，它不和任何物理内存相关联，该域中的内存可能来自高端内存或者普通内存。用于不可移动分配的内存会被均匀的分布到系统的各个内存节点中；同时用于可移动分配的内存只会取自最高内存域的内存，zone_movable_pfn记录了取自各个节点的用于可移动分配的内存的起始地址。 初始化内存域和节点数据结构在内存管理的初始化中，架构相关的代码要完成系统中可用内存的检测，并要将相关信息提交给架构无关的代码。架构无关的代码free_area_init_nodes负责完成管理数据结构的创建。该函数需要一个参数max_zone_pfn，它由架构相关的代码提供，其中保存了每个内存域的最大可用页帧号。内核定义了两个数组：12static unsigned long __meminitdata arch_zone_lowest_possible_pfn[MAX_NR_ZONES];static unsigned long __meminitdata arch_zone_highest_possible_pfn[MAX_NR_ZONES]; 这两个数组在free_area_init_nodes用于保存来自max_zone_pfn的信息，并将它转变成[low，high]的形式。然后内核开始调用find_zone_movable_pfns_for_nodes对ZONE_MOVABLE域进行初始化。然后内核开始为每一个节点调用free_area_init_node，这个函数将完成： 调用calculate_node_totalpages计算节点中页的总数 调用alloc_node_mem_map负责初始化struct pglist_data中的node_mem_map，为它分配的内存将用于存储本节点的所有物理内存的struct page结构。这片内存将对其到伙伴系统的最大分配阶上。而且如果当前节点是第0个节点，则该指针信息还将保存在全局变量mem_map中。 调用free_area_init_core完成初始化进一步的初始化 free_area_init_core将完成内存域数据结构的初始化，在这个函数中 nr_kernel_pages记录直接映射的页面数目，而nr_all_pages则记录了包括高端内存中页数在内的页数 会调用zone_pcp_init初始化该内存域的每CPU缓存 会调用init_currently_empty_zone初始化该zone的wait_table，free_area列表 调用memmap_init初始化zone的页，所有页都被初始化为可移动的 分配器API伙伴系统只能分配2的整数幂个页。因此申请时，需要指定请求分配的阶。有很多分配和释放页的API，都定义在gfp.h中。最简单的是alloc_page(gfp_mask)用来申请一个页， free_page(addr)用来释放一个页。这里更值得关注的获取页面时的参数gfp_mask，所有获取页面的API都需要指定该参数。它用来影响分配器的行为，其中有是分配器提供的标志，标志有两种： zone修饰符：用于告诉分配器从哪个zone分配内存 行为修饰符：告诉分配器应该如何进行分配 其中zone修饰符定义为12345#define __GFP_DMA ((__force gfp_t)___GFP_DMA)#define __GFP_HIGHMEM ((__force gfp_t)___GFP_HIGHMEM)#define __GFP_DMA32 ((__force gfp_t)___GFP_DMA32)#define __GFP_MOVABLE ((__force gfp_t)___GFP_MOVABLE) /* Page is movable */#define GFP_ZONEMASK (__GFP_DMA|__GFP_HIGHMEM|__GFP_DMA32|__GFP_MOVABLE) 这些定义都一目了然，需要指出的是如果同时指定了__GFP_MOVABLE和__GFP_HIGHMEM，则会从虚拟的ZONE_MOVABLE分配。更详细的可以参考gfp.h，其中包含了所有的标志及其含义。 分配页__alloc_pages会完成最终的内存分配，它是伙伴系统的核心代码（但是在内核代码中，这种命名方式的函数都是需要小心调用的，一般都是给实现该功能的代码自己调用，不作为API提供出去的，因而它的包装器才是对外提供的API，也就是alloc_pages_node）。 选择页选择页中最重要的函数是get_page_from_freelist，它负责通过标志和分配阶来判断分配是否可以进行，如果可以就进行实际的分配。该函数还会调用zone_watermark_ok根据指定的标识判断是否可以从给定的zone中进行分配。该函数需要struct zonelist的指针指向备用zone，当当前zone不能满足分配需求时就依次遍历该列表尝试进行分配。整体的分配流程是： 调用get_page_from_freelist尝试进行分配，如果成功就返回分配到的页，否则 唤醒kswapd，然后再次调用get_page_from_freelist尝试进行分配，如果成功就返回分配的页，否则 如果分配的标志允许不检查阈值进行分配，则以ALLOC_NO_WATERMARKS为标志再次调用get_page_from_freelist尝试分配，如果成功则返回分配的页；如果不允许不检查阈值或者仍然失败，则 如果不允许等待，就分配失败，否则 如果支持压缩，则尝试先对内存进行一次压缩，然后再调用get_page_from_freelist，如果成功就返回，否则 进行内存回收，然后再调用get_page_from_freelist，如果成功就返回，否则 根据回收内存并尝试分配的结果以及分配标志，可能会调用OOM杀死一个进程然后再尝试分配，也可能不执行OOM这一步的操作，如果执行了，则在失败后可能就彻底失败，也可能重新回到第2步，也可能继续下一步 回到第2步中调用get_page_from_freelist的地方或者再尝试一次先压缩后分配，如果走了先压缩再分配这一步，这就是最后一次尝试了，要么成功要么失败，不会再继续尝试了 移出所选择的页在函数get_page_from_freelist中，会首先在zonelist中找到一个具有足够的空闲页的zone，然后会调用buffered_rmqueue进行处理，在分配成功时，该函数会把所分配的内存页从zone的free_list中移出，并且保证剩余的空闲内存页满足伙伴系统的要求，该函数还会把内存页的迁移类型存放在page的private域中。该函数的步骤如图所示： 可以看出buffered_rmqueue的工作过程为： 如果申请的是单页，会做特殊处理，内核会利用每CPU的缓存加速这个过程。并且在必要的时候会首先填充每CPU的缓存。函数rmqueue_bulk用于从伙伴系统获取内存页，并添加到指定的链表，它会调用函数__rmqueue。 如果是分配多个页，则会首先调用__rmqueue从内存域的伙伴系统中选择合适的内存块，这一步可能失败，因为虽然内存域中有足够数目的空闲页，但是页不一定是连续的，如果是这样这一步就会返回NULL。在这一步中如果需要还会将大的内存块分解成小的内存块来进行分配，即按照伙伴系统的要求进行分配。 无论是分配单页还是多个页，如果分配成功，在返回分配的页之前都要调用prep_new_page，如果这一步的处理不成功就会重新进行分配（跳转到函数buffered_rmqueue的开始），否则返回分配的页。 函数__rmqueue的执行过程： 首先调用__rmqueue_smallest尝试根据指定的zone，分配的阶，迁移类型进行分配，该函数根据指定的信息进行查找，在找到一个可用的空闲内存页块后会将该内存页块从空闲内存页块链表中删除，并且会调用expand使得剩余的内存页块满足伙伴系统的要求。如果在这一步成功就返回，否则执行下一步 调用__rmqueue_fallback尝试从备用zone分配。该函数用于根据前一类型的备用列表尝试从其它备用列表分配，但是需要注意的是这里会首先尝试最大的分配阶，依次降低分配的阶，直到指定的分配的阶，采用这个策略是为了避免碎片—如果要用其它迁移类型的内存，就拿一块大的过来，而不是在其它迁移类型的小区域中到处引入碎片。同时如果从其它迁移类型的空闲内存页块分配到的是一个较大的阶，则整块内存页块的迁移类型可能会发生改变，从原来的类型改变为申请分配时所请求的类型（即迁移类型发生了改变）。分配成功时的动作和__rmqueue_smallest类似，移出内存页，调用expand。 函数prep_new_page的操作 对页进行检查，以确保页确实是可用的，否则就返回一个非0值导致分配失败 设置页的标记以及引用计数等等。 如果设置而来__GFP_COMP标志，则调用prep_compound_page将页组织成复合页（hugetlb会用到这个）。 复合页的结构如图所示： 复合页具有如下特性： 复合页中第一个页称为首页，其它所拥有页都称为尾页 组成复合页的所有的private域都指向首页 第一个尾页的lru的next域指向释放复合页的函数指针 第一个尾页的lru的prev域用于指向复合页所对应的分配的阶，即多少个页 释放页__free_pages是释放页的核心函数，伙伴系统提供出去的API都是它的包装器。其流程： 减小页的引用计数，如果计数不为0则直接返回，否则 如果释放的是单页，则调用free_hot_cold_page，否则 调用__free_pages_ok free_hot_cold_page会把页返还给每-CPU缓存而不是直接返回给伙伴系统，因为如果每次都返还给伙伴系统，那么将会出现每次的分配和释放都需要伙伴系统进行分割和合并的情况，这将极大的降低分配的效率。因而这里采用的是一种“惰性合并”，单页会首先返还给每-CPU缓存，当每-CPU缓存的页面数大于一个阈值时（pcp-&gt;high），则一次将pcp-&gt;patch个页返还给伙伴系统。free_pcppages_bulk在free_hot_cold_page中用于将内存页返还给伙伴系统，它会调用函数__free_one_page。函数__free_pages_ok最终页会调到__free_one_page来释放页，__free_one_page会将页面释放返还给伙伴系统，同时在必要时进行递归合并。在__free_one_page进行合并时，需要找到释放的page的伙伴的页帧号，这是通过__find_buddy_index来完成的，其代码非常简单：1234__find_buddy_index(unsigned long page_idx,unsigned int order)&#123; returnpage_idx ^ (1 &lt;&lt; order);&#125; 根据异或的规则，这个结果刚好可以得到邻居的页帧号。因为根据linux的管理策略以及伙伴系统的定义，伙伴系统中每个内存页块的第一个页帧号用来标志该页，因此对于order阶的两个伙伴，它们只有1&lt;&lt;order这个比特位是不同的，这样，只需要将该比特与取反即可，而根据异或的定义，一个比特和0异或还是本身，一个比特和1异或刚好可以取反。因此就得到了这个算式。如果可以合并还需要取得合并后的页帧号，这个更简单，只需要让两个伙伴的页帧号相与即可。__free_one_page调用page_is_buddy来对伙伴进行判断，以决定是否可以合并。 不连续内存页的分配内核总是尝试使用物理上连续的内存区域，但是在分配内存时，可能无法找到大片的物理上连续的内存区域，这时候就需要使用不连续的内存，内核分配了其虚拟地址空间的一部分（vmalloc区）用于管理不连续内存页的分配。每个vmalloc分配的子区域都自包含的，在内核的虚拟地址空间中vmalloc子区域之间都通过一个内存页隔离开来，这个间隔用来防止不正确的访问。 用vmalloc分配内存vmalloc用来分配在虚拟地址空间连续，但是在物理地址空间不一定连续的内存区域。它只需要一个以字节为单位的长度参数。为了节省宝贵的较低端的内存区域，vmalloc会使用高端内存进行分配。内核使用struct vm_struct来管理vmalloc分配的每个子区域，其定义如下：12345678910struct vm_struct &#123; struct vm_struct *next; void *addr; unsigned long size; unsigned long flags; struct page **pages; unsigned int nr_pages; phys_addr_t phys_addr; const void *caller;&#125;; 每个vmalloc子区域都对应一个该结构的实例。 next：指向下一个vmalloc子区域 addr：vmalloc子区域在内核虚拟地址空间的起始地址 size：vmalloc子区域的长度 flags：与该区域相关标志 pages：指针，指向映射到虚拟地址空间的物理内存页的struct page实例 nr_pages：映射的物理页面数目 phys_addr：仅当用ioremap映射了由物理地址描述的内存页时才需要改域，它保存物理地址caller：申请者 创建vmalloc子区域所有的vmalloc子区域都被连接保存在vmlist中，该链表按照addr排序，顺序是从小到大。当创建一个新的子区域时需要，需要找到一个合适的位置。查找合适的位置采用的是首次适用算法，即从vmalloc区域找到第一个可以满足需求的区域，查找这样的区域是通过函数__get_vm_area_node完成的。其分配过程以下几步： 调用__get_vm_area_node找到合适的区域 调用__vmalloc_area_node分配物理内存页 调用map_vm_area将物理内存页映射到内核的读你地址空间 将新的子区域插入vmlist链表 在从伙伴系统分配物理内存页时使用了标志：GFP_KERNEL | __GFP_HIGHMEM还有其它的方式来建立虚拟地址空间的连续映射： vmalloc_32：与vmallo工作方式相同，但是确保所使用的物理地址总可以用32位指针寻址 vmap：将一组物理页面映射到连续的虚拟地址空间 ioremap：特定于处理器的分配函数，用于将取自物理地址空间而、由系统总线用于I/O操作的一个内存块，映射到内核的虚拟地址空间 释放内存vfree用于释放vmalloc和vmalloc_32分配的内存空间，vunmap用于释放由vmap和ioremap分配的空间（iounmap会调到vunmap）。最终都会归结到函数__vunmap。__vunmap的执行过程： 调用remove_vm_area从vmlist中找到一个子区域，然后将其从子区域删除，再解除物理页面的映射 如果设置了deallocate_pages，则将物理页面归还给伙伴系统 释放管理虚拟内存的数据结构struct vm_struct 内核映射高端内存可通过vmalloc机制映射到内核的虚拟地址空间，但是高端内存往内核虚拟地址空间的映射并不依赖于vmalloc，而vmalloc是用于管理不连续内存的，它也并不依赖于高端内存。 持久内核映射如果想要将高端内存长期映射到内核中，则必须使用kmap函数。该函数需要一个page指针用于指向需要映射的页面。如果没有启用高端内存，则该函数直接返回页的地址，因为所有页面都可以直接映射。如果启用了高端内存，则：如果不是高端内存的页面，则直接返回页面地址，否则调用kmap_high进行处理 使用的数据结构vmalloc区域后的持久映射区域用于建立持久映射。pkmap_count是一个有LAST_PKMAP个元素的数组，每个元素对应一个持久映射。每个元素的值是被映射页的一个使用计数器： 0：相关的页么有被使用 1：该位置关联的页已经映射，但是由于CPU的TLB没有刷新而不能使用 大于1的其它值：表示该页的引用计数，n表示有n-1处在使用该页 数据结构12345struct page_address_map &#123; struct page *page; void *virtual; struct list_head list;&#125;; 用于建立物理页和其在虚拟地址空间位置之间的关系。 page：指向全局数据结构mem_map数组中的page实例的指针 virtual：该页在虚拟地址空间中分配的位置所有的持久映射保存在一个散列表page_address_htable中，并用链表处理冲突，page_slot是散列函数。函数page_address用于根据page实例获取器对应的虚拟地址。其处理过程： 如果不是高端内存直接根据page获得虚拟地址（利用__va(paddr)），否则 在散列表中查找该page对应的struct page_address_map实例，获取其虚拟地址 创建映射函数kmap_high完成映射的实际创建，其工作过程： 调用page_address获取对应的虚拟地址 如果没有获取到，则调用map_new_virtual获取虚拟地址 pkmap_count数组中对应于该虚拟地址的元素的引用计数加1 新映射的创建在map_new_virtual中完成，其工作过程： 执行一个无限循环： 更新last_pkmap_nr为last_pkmap_nr+1 同时如果last_pkmap_nr为0，调用flush_all_zero_pkmaps，flush CPU高速缓存 检查pkmap_count数组中索引last_pkmap_nr对应的元素的引用计数是否为0，如果是0就退出循环，否则 将自己加入到一个等待队列 调度其它任务 被唤醒时会首先检查是否有其它任务已经完成了新映射的创建，如果是就直接返回 回到循环头部重新执行 获取与该索引对应的虚拟地址修改内核页表，将该页映射到获取到的虚拟地址更新该索引对应的pkmap_count元素的引用计数为1调用set_page_address将新的映射加入到page_address_htable中 flush_all_zero_pkmaps的工作过程： 调用flush_cache_kmaps执行高速缓存flush动作 遍历pkmap_count中的元素，如果某个元素的值为1就将其减小为0，并删除相关映射同时设置需要刷新标记 如果需要刷新，则调用flush_tlb_kernel_range刷新指定的区域对应的tlb。 解除映射kunmap用于解除kmap创建的映射，如果不是高端内存，什么都不做，否则kunmap_high将完成实际的工作。kunmap_high的工作很简单，将对应的pkmap_count中的元素的引用计数的值减1，如果新值为1，则看是否有任务在pkmap_map_wait上等待，如果有就唤醒它。根据该机制的涉及原理，该函数不能将引用计数减小到小于1，否则就是一个BUG。 临时内核映射kmap不能用于无法休眠的上线文，如果要在不可休眠的上下文调用，则需要调用kmap_atomic。它是原子的，特定于架构的。同样的只有是高端内存时才会做实际的映射。kmap_atomic使用了固定映射机制。在固定映射区域，系统中每个CPU都有一个对应的“窗口”，每个窗口对应于KM_TYPE_NR中不同的类型都有一项。这个映射的核心代码如下（取自powerpc）：12345type = kmap_atomic_idx_push();idx = type + KM_TYPE_NR*smp_processor_id();vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx); __set_pte_at(&amp;init_mm, vaddr, kmap_pte-idx, mk_pte(page, prot), 1);local_flush_tlb_page(NULL, vaddr); 固定映射区域为用于kmap_atomic预留内存区的代码如下：123456789101112enum fixed_addresses &#123; FIX_HOLE, /* reserve the top 128K for early debugging purposes */ FIX_EARLY_DEBUG_TOP = FIX_HOLE, FIX_EARLY_DEBUG_BASE = FIX_EARLY_DEBUG_TOP+((128*1024)/PAGE_SIZE)-1,#ifdef CONFIG_HIGHMEM FIX_KMAP_BEGIN, /* reserved pte&apos;s for temporary kernel mappings */ FIX_KMAP_END = FIX_KMAP_BEGIN+(KM_TYPE_NR*NR_CPUS)-1,#endif /* FIX_PCIE_MCFG, */ __end_of_fixed_addresses&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux内核内存管理学习之一（基本概念，分页及初始化）]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E5%86%85%E6%A0%B8%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%80%EF%BC%88%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%EF%BC%8C%E5%88%86%E9%A1%B5%E5%8F%8A%E5%88%9D%E5%A7%8B%E5%8C%96%EF%BC%89%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/goodluckwhh/article/details/9970845 概述虚拟地址空间内存是通过指针寻址的，因而CPU的字长决定了CPU所能管理的地址空间的大小，该地址空间就被称为虚拟地址空间，因此32位CPU的虚拟地址空间大小为4G，这和实际的物理内存数量无关。Linux内核将虚拟地址空间分成了两部分：一部分是用户进程可用的，这部分地址是地址空间的低地址部分，从0到TASK_SIZE，称为用户空间一部分是由内核保留使用的，这部分地址是地址空间的高地址部分,从KERNELBASE到结束，称为内核空间与之相关的一些宏：KERNELBASE：内核虚拟地址空间的起始地址，一般和PAGE_OFFSET相同，但是也可能不同PAGE_OFFSET：内核虚拟地址空间中低端内存的起始地址PHYSICAL_START：内核物理地址的起始地址MEMORY_START：内核低端内存的物理起始地址 用户进程可用的部分在进程切换时会发生改变，但是由内核保留使用的部分在进程切换时是不变的。在32位系统上，两部分的典型划分比为3:1(该比例可修改),即4G虚拟地址空间中的3G是用户进程可访问的，而另外1G是保留给内核使用的，在这种划分下用户进程可用的虚拟地址空间是0x00000000-0xbfffffff,内核的虚拟地址空间是0xc0000000-0xffffffff。不同的进程使用不同的用户空间可以使得不同进程的用户空间部分相互隔离，从而保护进程的用户空间部分。 内核空间的保护是通过CPU的特权等级实现的，所有现代CPU都提供了多个特权等级，每个特权等级可以获得的权限是不同的，当CPU处在某个权限等级时就只能执行符合这个等级的权限限制的操作。Linux使用了两个权限等级，分别对应于内核权限和用户权限，并且给属于内核的内存空间添加了权限限制，使得只有处于内核权限等级时CPU才能访问这些内存区域，这就将内核空间也保护了起来。 物理地址到虚拟地址的映射可用的物理内存会被映射到内核虚拟地址空间中。在32位系统中，内核会将一部分物理内存直接映射到内核的虚拟地址空间中，如果访问内存时所使用的虚拟地址与内核虚拟地址起始值的偏移量不超过该部分内存的大小，则该虚拟地址会被直接关联到物理页帧；否则就必须借助”高端内存“来访问，因此也可以看出之所以使用“高端内存”是因为CPU可寻址的虚拟地址可能小于实际的物理内存，因而不得不借助其它机制（“高端内存”）来访问所有的内存。在IA-32系统上，这部分空间大小为896M。 64位系统不使用高端内存，这是因为64位的系统理论上可寻址的地址空间远大于实际的物理内存（至少现在是如此），因而就不必借助“高端内存”了。而对于用户进程来说，由于它的所有内存访问都通过页表进行，不会直接进行，因而对用户进程来说也不存在高端内存之说。高端内存由32位架构的内核使用，在32位架构的内核中，要使用高端内存必须首先使用kmap将高端内存映射进内核的虚拟地址空间。 内存类型从硬件角度来说存在两种不同类型的机器，分别用不同的方式来管理内存。UMA(uniform memory access)：一致内存访问机器，它将可用内存以连续的方式组织起来。SMP系统中，每个CPU都可以以同样的速度访问内存。NUMA(non-uniform memory access)：非一致内存访问机器总是多处理器机器。系统的各个CPU都有本地内存，可以支持快速访问。系统中的所有处理器都通过总线连接起来，进而可以访问其它CPU的本地内存，但是不如访问本地内存快。 Linux中如果要支持NUMA系统，则需要打开CONFIG_NUMA选项。 内存组织linux内核对一致和不一致的内存访问系统使用了同样的数据结构，因此对于不同的内存布局，内存的管理算法几乎没有区别。对于UMA系统，将其看作只有一个NUMA节点的NUMA系统，即将其看成NUMA的特例。这样就将简化了内存管理的其它部分，其它部分都可以认为它们是在处理NUMA系统。 基本概念和相关数据结构linux引入了一个概念称为node，一个node对应一个内存bank，对于UMA系统，只有一个node。其对应的数据结构为“struct pglist_data”。对于NUMA系统来讲， 整个系统的内存由一个名为node_data 的struct pglist_data（page_data_t） 指针数组来管理。NUMA系统的内存划分如图所示： 每个node又被分成多个zone，每个zone对应一片内存区域。内核引入了枚举常量 zone_type 来描述zone的类型：123456789101112131415&lt;mmzone.h&gt;enum zone_type &#123;#ifdef CONFIG_ZONE_DMAZONE_DMA,#endif#ifdef CONFIG_ZONE_DMA32ZONE_DMA32,#endifZONE_NORMAL,#ifdef CONFIG_HIGHMEMZONE_HIGHMEM,#endifZONE_MOVABLE,MAX_NR_ZONES&#125; 它们之间的用途是不一样的： ZONE_DMA：可用作DMA的内存区域。该类型的内存区域在物理内存的低端，主要是ISA设备只能用低端的地址做DMA操作。 ZONE_NORMAL：直接被内核直接映射到自己的虚拟地址空间的地址。 ZONE_HIGHMEM：不能被直接映射到内核的虚拟地址空间的地址。 ZONE_MOVABLE：伪zone，在防止物理内存碎片机制中使用 MAX_NR_ZONES：结束标记 很显然根据内核配置项的不同，zone的类型是有变化的。每个zone都和一个数组关联在一起，该数组用于组织管理属于该zone的物理内存页。zone用数据结构struct zone来表示。所有的node都被保存在一个链表中。在使用时，内核总是尝试从与进程所运行的CPU所关联的NUMA节点申请内存。这是就要用到备用列表，每个节点都通过struct zonelist提供了备用列表，该列表包含了其它节点，可用于代替本节点进行内存分配，其顺序代表了分配的优先级，越靠前优先级越高。 阈值计算当系统中可用内存很少的时候，内核线程kswapd被唤醒，开始回收释放page。pages_min, pages_low and pages_high这些参数影响着回收行为。每个zone有三个阈值标准：pages_min, pages_low and pages_high，帮助确定zone中内存分配使用的压力状态。kswapd和这3个参数的互动关系如下图： 在最新的内核中这三个变量变成了watermark数组的成员，分别对应于WMARK_MIN，WMARK_LOW和WMARK_HIGH。内核在计算这几个值之前会首先计算一个关键参数min_free_kbytes，它是为关键性分配保留的内存空间的最小值。该关键参数有一个约束：不能小于128k，不能大于64M。其计算公式：12lowmem_kbytes = nr_free_buffer_pages() * (PAGE_SIZE &gt;&gt; 10); min_free_kbytes = int_sqrt(lowmem_kbytes * 16); 阈值的计算由init_per_zone_pages_min（ 最新内核中是init_per_zone_wmark_min）完成。该函数还会完成每个zone的lowmem_reserve的计算，该数组用于为不能失败的关键分配预留的内存页。这几个阈值的含义： page_min：如果空闲页数目小于该值，则该zone非常缺页，页面回收压力很大。page_low: 如果空闲页数目小于该值，kswapd线程将被唤醒，并开始释放回收页面。page_high: 如果空闲页面的值大于该值，则该zone的状态很完美, kswapd线程将重新休眠。 Zone等待队列表当对一个page做I/O操作的时候，page需要被锁住，以防止不正确的数据被访问。做法是：进程在访问page前，调用wait_on_page*函数，使进程加入一个等待队列（如果没有其它进程正在访问该页，就直接获得访问权限，否则加入等待队列）。当当前访问page的进程完成自己的访问动作后，会调用unlock_page唤醒在该页上wait的进程，因而进程即可获得对页的访问权。每个page都可以有一个等待队列，但是太多的分离的等待队列使得花费太多的内存访问周期。也可以让一个zone中的所有page都使用同一个队列，但是这就意味着，当一个page unlock的时候，访问这个zone里内存page的所有休眠的进程将都被唤醒，这样就会出现惊群效应（thundering herd）。内核的解决方法是将所有的队列放在struct zone数据结构中，并通过哈希表zone-&gt;wait_table来管理zone中的等待队列。哈希表的方法可能会造成一些进程不必要的唤醒，但是这个是小概率事件是可以容忍的。等待队列的哈希表的分配和建立在free_area_init_core()函数中（最终是在zone_wait_table_init()函数中）进行。 冷热页zone中的pageset用于实现冷热分配器。热页指的是已经加载到CPU高速缓存的页，这种页的访问速度比在主存中的快。冷页就是不在高速缓存中的页。SMP系统中每个CPU都有一个或多个高速缓存，各个CPU的管理必须是独立的（即便在NUMA中每个CPU也都可以访问所有的内存页，因而其高速缓存也可能缓存所有的内存页）。每个CPU都有一个struct per_cpu_pages结构，其定义如下：1234567struct per_cpu_pages &#123; int count; /* number of pages in the list */ int high; /* high watermark, emptying needed */ int batch; /* chunk size for buddy add/remove */ /* Lists of pages, one per migrate type stored on the pcp-lists */ struct list_head lists[MIGRATE_PCPTYPES]; &#125;; count：列表中页的数目high：一个阈值，如果列表中页数目超过该值，则表示列表中页太多了；没有下限的阈值，如果列表中没有成员，则重新填充。batch：如果可能，每次操作多个页，batch是每次操作页数目的参考值。lists：页列表。在这些列表中，热页放在列表头部，冷页放在尾部。 页（Page）页概念内核使用struct page作为基本单位来管理物理内存，在内核看来，所有的RAM都被划分成了固定长度的页帧。每一个页帧包含了一个页，也就是说一个页帧的长度和一个页的长度相同。页帧是主存的一部分，是一个存储区域。页和页帧的区别在于，页是抽象的数据结构，可以存放在任意地方，而页帧是真实的存储区域。struct page包含了跟踪一个物理页帧当前被用于什么的有信息。比如页面计数，标志等等。 映射页面到zone内核使用struct page的flags中的字段来保存页所属于的zone以及node。这是通过set_page_zone和set_page_node，这两个函数由函数set_page_links调用。 页表页表机制CPU管理虚拟地址，因而物理地址需要映射到虚拟地址才能给CPU使用。用于将虚拟地址空间映射到物理地址空间的数据结构称为页表。 在使用4k大小页的情况下，4k地址空间需要2的20次方个页表项。即便每个页表项大小为4字节也需要4M内存，而每个进程都需要有自己的页表，这就成了一个极大的内存开销。而且在大多数情况下，虚拟地址空间的大部分区域都是没有被使用的，因而没必要为虚拟地址空间中的每个页都分配管理结构，因而实际中采用的是如下方案： 使用多级页表，每个线性地址被看为形如“页目录表+页目录表+…+页目录表+页表+页内偏移”的形式，每个比特组按照其含义被用于在相应的表中查找数据，最终找到页表。 进程的页表只包含了它所使用的地址空间。进程不使用的地址空间不需要加入进程的页表。 只有在进程实际需要一个页表时才会给该页分配RAM，而不是在一开始就为进程的所有页都分配空间。 页表中包含了关于该页的信息，例如是否存在于主存中，是否是“脏”的，访问所需权限等级，读写标志，cache策略等等。内核的页表保存在全局变量swapper_pg_dir中，应用进程的页表保存在task_struct-&gt;mm-&gt;pgd中，在应用进程切换时，会切换进程的页表（schedule–&gt;__schedule–&gt;context_switch–&gt;switch_mm–&gt;switch_mmu_context–&gt;local_flush_tlb_mm）。linux中采用了4级分页模型。如下： PGD|PUD|PMD|PTE|OFFSET 虽然采用了4级模型，但是： 对于32位且未使能物理地址扩展的系统，使用二级页表。Linux的做法是让页上级目录表和页中间目录表所包含的比特数目为0，让页全局目录表的比特数目包含除了页表和偏移量之外的所有比特,从而取消这两级目录。同时为了让代码可以同时运行在32比特环境和64比特环境，linux保留了这两级目录在指针序列中的位置，做法是将这两级目录所包含的表项数设置为1（这里需要注意的是即便只有一个比特，也可以表示两个项，因此需要此设置）。 对于32且使能了物理地址扩展的系统，使用三级页表。 对于64位系统，取决于硬件对线性地址位的划分。 在Linux中，每个进程都有自己的页全局目录表（PGD），以及自己的页表集。当发生进程切换时，linux会完成页表的切换。使用该方案后，每个虚拟地址都划分为相应的比特分组，其中PGD用于索引每个进程所专有的页全局表，以找到PUD，PUD用于索引进程的页上级目录表，以找到PMD依次类推直到找到PTE。PTE即页表数组，该表的表项包含了指向页帧的指针以及页的访问控制相关的信息，比如权限，是否在主存中，是否包含“脏”数据等等，OFFSET用做表内偏移。使用该机制后，虚拟地址空间中不存在的内存区域对应的PUD,PMD,PTE将不被创建，这就节省了地址空间。但是使用该机制后每次寻址都需要多次查表，才能找到对应的物理地址，因而降低了速递，CPU使用高速缓存和TLB来加速寻址过程。在访问内存时，如果虚拟地址对应的TLB存在，也就是TLB 命中了，则直接访问，否则就要使用相关的页表项更新TLB（此时可能需要创建新的页表项）然后再继续进行访问。下图是一个CPU的虚拟地址到实地址的转换过程： 当被访问的地址不存在对应的TLB表项时，就会产生TLB中断。在TLB中断中，会： 首先查找访问地址对应的页表，如果找不到对应的页表，就会生成相应的页表项（powerpc通过调用读写异常的处理函数完成该过程）。 使用PTE的内容更新TLB。 在TLB的内容更新完后，仍可能产生读写异常（也就是通常说的page fault），因为页表项虽然存在，但是其内容可能是非法的（比如页表并不在内存中），。 x86架构中的页地址空间当使用x86时，必须区分以下三种不同的地址： 逻辑地址:机器语言指令仍用这种地址指定一个操作数的地址或一条指令的地址。这种寻址方式在Intel的分段结构中表现得尤为具体，它使得MS-DOS或Windows程序员把程序分为若干段。每个逻辑地址都由一个段和偏移量组成。 线性地址：线性地址是一个32位的无符号整数，可以表达高达2的32次方（4GB）的地址。通常用16进制表示线性地址，其取值范围为0x00000000～0xffffffff。 物理地址：也就是内存单元的实际地址，用于芯片级内存单元寻址。物理地址也由32位无符号整数表示。 X86中的MMU包含两个部件，一个是分段部件，一个是分页部件，分段部件（段机制）把一个逻辑地址转换为线性地址；接着，分页部件（分页机制）把一个线性地址转换为物理地址。转化过程如图所示： 分段1)分段机制在x86段机制中，逻辑地址由两部分组成，即段部分（选择符）及偏移部分。 段是形成逻辑地址到线性地址转换的基础。如果我们把段看成一个对象的话，那么对它的描述如下： 段的基地址(Base Address)：在线性地址空间中段的起始地址。 段的界限(Limit)：表示在逻辑地址中，段内可以使用的最大偏移量。 段的属性(Attribute)： 表示段的特性。例如，该段是否可被读出或写入，或者该段是否作为一个程序来执行，以及段的特权级等等。 段的界限定义逻辑地址空间中段的大小。段内在偏移量从0到limit范围内的逻辑地址，对应于从Base到Base+Limit范围内的线性地址。在一个段内，偏移量大于段界限的逻辑地址将没有意义，使用这样的逻辑地址，系统将产生异常。另外，如果要对一个段进行访问，系统会根据段的属性检查访问者是否具有访问权限，如果没有，则产生异常。例如，在80386中，如果要在只读段中进行写入，80386将根据该段的属性检测到这是一种违规操作，则产生异常。下图表示一个段如何从逻辑地址空间，重新定位到线性地址空间。图的左侧表示逻辑地址空间，定义了A，B及C三个段，段容量分别为LimitA、LimitB及LimitC。图中虚线把逻辑地址空间中的段A、B及C与线性地址空间区域连接起来表示了这种转换。 段的基地址、界限及保护属性存储在段的描述符表中，在虚拟—线性地址转换过程中要对描述符进行访问。段描述符又存储在存储器的段描述符表中，该描述符表是段描述符的一个数组。简单的说段描述符表里存储了段描述符，而段描述符又包含了硬件进行逻辑地址到线性地址转换所需的所有信息。每个段描述符都定义了线性地址空间中的一段地址，它的属性以及它和逻辑地址空间之间的映射关系，实际上是如何从逻辑地址空间映射到线性地址空间。 2)linux中的段各种段描述符都存放于段描述符表中，要么在GDT中，要么在LDT中。描述符表(即段表)定义了386系统的所有段的情况。所有的描述符表本身都占据一个字节为8的倍数的存储器空间，空间大小在8个字节(至少含一个描述符)到64K字节(至多含8K)个描述符之间。 全局描述符表(GDT)：全局描述符表GDT(Global Descriptor Table)，包含着系统中所有任务都共用的那些段的描述符。 局部描述符表(LDT)：局部描述符表LDT(local Descriptor Table)，包含了与一个给定任务有关的描述符，每个任务各自有一个的LDT。有了LDT，就可以使给定任务的代码、数据与别的任务相隔离。 每一个任务的局部描述符表LDT本身也用一个描述符来表示，称为LDT描述符，它包含了有关局部描述符表的信息，被放在全局描述符表GDT中。但是Linux很少使用分段机制，这是因为，分段和分页都能用于将物理地址划分为小的地址片段的功能，因而它们是相互冗余的。分段可以为不同的进程分配不同的线性地址空间，而分页可以将相同的线性地址空间映射到不同的物理地址空间。linux采用了分页机制，原因是： 如果所有的进程都使用相同的线性地址空间，内存管理更简单 很多其他架构的CPU对分段的支持很有限 在linux中，所有运行在用户模式的进程都使用相同的指令和数据段，因此这两个段也被成为用户数据段和用户指令段。类似的，内核使用自己的内核数据段和内核数据段。这几个段分别用宏_ _USER_CS,_ _USER_DS,_ _KERNEL_CS, and_ _KERNEL_DS定义。这些段都从0开始，并且大小都相同，因而linux中，线性地址和逻辑地址是相同的，而且内核和用户进程都可以使用相同的逻辑地址，逻辑地址也就是虚拟地址，这就和其它架构统一起来了。单处理器系统只有一个GDT，而多处理器系统中每个CPU都有一个GDT，GDT存放在cpu_gdt_table中GDT包含了用户数据段，用户指令段，内核数据段内核指令段以及一些其他段的信息。绝大多数的linux用户程序并不使用LDT，内核定义了一个缺省的LDT给大多数进程共享。它存放于default_ldt中。如果应用程序需要创建自己的局部描述附表，可以通过modify_ldt系统调用来实现。使用该系统调用创建的LDT需要自己的段。应用程序也可以通过modify_ldt来创建自己的段。 内存管理初始化初始化流程内存初始化关键是page_data_t数据结构以及其下级数据结构（zone，page）的初始化。宏NODE_DATA用于获取指定节点对应的page_data_t，在多节点系统中，节点数据结构为struct pglist_data *node_data[];该宏获取对应节点所对应的数据结构，如果是单节点系统，节点的数据结构为struct pglist_data contig_page_data;该宏直接返回它。 初始化代码流程系统启动代码中与内存管理相关的初始化代码如图： 其功能分别为： setup_arch:架构相关的初始化，其中包括了内存管理中与架构相关部分的初始化。boot分配器在这个时候被初始化。 setup_per_cpu_areas:SMP中，该函数初始化源代码中静态定义的每CPU变量，该类变量对系统中每一个CPU都一个副本。此类变量保存在内核二进制影响的一个独立的段中。 build_all_zonelists:建立节点和zone的数据结构 mem_init:初始化内存分配器 setup_per_cpu_pageset:遍历系统中所有的zone，对于每一个zone为所有的CPU分配pageset（冷热页缓存）并进行初始化，在这个函数被调用之前，只有boot pagesets可用。 节点和zone的初始化build_all_zonelists会遍历系统中所有的节点，并为每个节点的内存域生成数据结构。它最终会使用节点数据结构调用build_zonelists，该函数会在该节点和系统中其它节点的内存之间建立一种距离关系，距离表达的是从其它节点分配的代价，因而距离越大，分配代价也越大；之后的内存分配会依据这种距离进行，优先选择本地的，如果本地的不可用，则按照距离从近到远来分配，直到成功或者所有的都失败。在一个节点的内存域中： 高端内存被看做是最廉价的，因为内核不依赖于高端内存，它被耗尽不会对系统有不良影响 DMA看做是最昂贵的，因为它有特殊用途，它用于和外设交互数据 普通内存介于两者之间，因为内核有些部分是依赖于普通内存的，所以它耗尽对系统会有影响 当分配内存时，假设指定的内存区域的昂贵程度为A，则分配过程为： 首先尝试从本节点分配，并且是按照昂贵程度递增的顺序从A开始尝试，直到最昂贵的区域 如果从本节点分配失败，则按照距离关系依次检查其它几点，在检查每个节点时，仍是按照昂贵程度递增的顺序从A开始尝试，直到最昂贵的区域 特定于体系结构的设置内核在内存中的布局在启动装载器将内核复制到内存，并且初始化代码的汇编部分执行完后，内存布局如图所示： 这是一种默认布局，也存在一些例外： PHYSICAL_START可用于配置修改内核在内存中的位置。 内核可以被编译为可重定位二进制程序，此时由启动装载器决定内核的位置。 默认情况下，内核安装在RAM中从物理地址0x00100000开始的地方。也就是第2M开始的那个。没有安装在第1M地址空间开始的地方的原因： 页帧0由BIOS使用，存在上电自检（POST）期间检查到的系统硬件配置。 物理地址从0x000a0000到0x000fffff的范围通常保留给BIOS程序使用 第一个MB内的其它页帧可能由特定计算机模型保留 从_edata到_end之间的初始化数据部分所占用的内存在初始化完成后有些是不再需要的，可以回收利用，可以控制哪些部分可以回收，哪些部分不能回收。内核占用的内存分为几段，其边界保存在变量中，可以通过System.map查看相关的信息，在系统启动后也可以通过/proc/iomem查看相关的信息。 初始化步骤在start_kernel，在其中会调用setup_arch来进行架构相关的初始化。setup_arch会完成启动分配器的初始化以及各个内存域的初始化（paging_init）。paging_init最终会调用free_area_init_node这是个架构无关的函数，它会完成节点以及zone的数据结构的初始化。 分页机制初始化Linux内核将虚拟地址空间分成了两部分：用户空间和内核空间。用户进程可用的部分在进程切换时会发生改变，但是由内核保留使用的部分在进程切换时是不变的。在32位系统上，两部分的典型划分比为3:1(该比例可修改),即4G虚拟地址空间中的3G是用户进程可访问的，而另外1G是保留给内核使用的。32位系统中，内核地址空间又被分为几部分，其图示如下： 直接映射其中第一部分用于将一部分物理内存直接映射到内核的虚拟地址空间中，如果访问内存时所使用的虚拟地址与内核虚拟地址起始值的偏移量不超过该部分内存的大小，则该虚拟地址会被直接关联到物理页帧；否则就必须借助”高端内存“来访问,在IA-32系统上，这部分空间大小为896M。对于直接映射部分的内存，内核提供了两个宏： __pa(vaddr)：用于返回与虚拟地址vaddr相对应的物理地址。 __va(paddr)：用于返回和物理地址paddr相对应的虚拟地址。 剩余部分被内核用作其它用途：虚拟地址中连续，但是物理地址不连续的内存区域可以从VMALLO区域分配。该机制通常用于用户进程，内核自己会尽量尝试使用连续的物理地址。当然，当直接映射部分不能满足需求时，内核也会使用该区域。在ppc32中ioremap就使用了该区域。持久映射区域用于将高端内存中的非持久页映射到内核中。固定映射用于与物理地址空间中的固定页关联的虚拟地址页，但是物理地址页即页帧可以自由选择。内存的各个区域边界由图中所示的常数定义。high_memory定义了直接映射区域的边界。系统中定义了与页相关的一些常量： num_physpages：最高可用页帧的页帧号 totalram_pages：可用页帧的总数目 min_low_pfn：RAM中在内核映像之后的第一个可用的页帧号 max_pfn：最后一个可用的页帧号 max_low_pfn：被内核直接映射的最后一个页帧的页帧号（低端内存中） totalhigh_pages：没有被内核直接映射的页帧的总数（高端内存中） 在直接映射的内存区域和用于vmalloc的内存区域之间有一个大小为VMALLOC_OFFSET的缺口，它用于对内核进行地址保护，防止内核进行越界访问（越过了直接映射区域）。 vmalloc区vmalloc区域的起始位置取决于high_memory和VMALLOC_OFFSET。而其结束位置则取决于是否启用了高端内存支持。如果没有启用高端内存支持，就不需要持久映射区域，因为所有内存都可以直接映射。 持久映射区持久映射页则开始于PKMAP_BASE，其大小由LAST_PKMAP表示有多少个页。 固定映射区固定映射开始于FIXADDR_START结束于FIXADDR_END。这部分区域指向物理内存的随机位置。在该映射中，虚拟地址和物理地址之间的关联是可以自由定义的，但是定义后就不能更改。该区域一直延伸到虚拟地址空间的顶端。 固定映射的优势在于编译时，对该类地址的处理类似于常数，内核一旦启动即为它分配了物理地址。对此类地址的引用比普通指针要快。在上下文切换期间，内核不会将对应于固定地址映射的TLB刷新出去，因此对这类地址的访问总是通过高速缓存。对于每一个固定地址，都必须创建一个常数并添加到称为fixed_addresses的枚举列表里。内核提供了virt_to_fix和fix_to_virt用于虚拟地址和固定地址常数之间的转换。set_fixmap用于建立固定地址常量和物理页之间的对应关系。 冷热页free_area_init_node最终会调到zone_pcp_init，它会为该zone计算一个batch值。而setup_per_cpu_pageset则会完成冷热缓存的初始化。 启动过程中的内存管理bootmem分配器用于内核在启动过程中分配和内存。这是一个很简单的最先适配的分配器。它使用位图来管理页面，比特1表示页忙，0表示空闲。需要分配内存时就扫描位图，直到找到第一个能够满足需求的内存区域。 数据结构:内核为每个节点都分配了一个struct bootmem_data结构的实例用来管理该node的内存。 初始化:在不同的架构下初始化的代码不尽相同，但是都是在paging_int中被调用。 分配器接口:alloc_bootmem用于分配内存free_bootmem用于释放内存 停用bootmem分配器:当slab系统完成初始化，能够承担内存分配工作时，需要停掉该分配器，这是通过free_all_bootmem(UMA系统)或free_all_bootmem_node(NUMA系统)来完成的 释放初始化数据:内核提供了两个属性init用于标记初始化函数，initdata用于标记初始化数据，这意味着这个函数/数据在初始化完成后其内存就不需了，可以进行回收利用。 内核页表的初始化以powerpc为例，内核页表的初始化由MMU_init来完成，它在start_kernel之前被调用：1MMU_init-&gt;mapin_ram-&gt;__mapin_ram_chunk-&gt;map_page, map_page的代码如下：12345678910111213141516171819202122int map_page(unsigned long va, phys_addr_t pa, int flags)&#123; pmd_t *pd; pte_t *pg; int err = -ENOMEM; /* Use upper 10 bits of VA to index the first level map */ pd = pmd_offset(pud_offset(pgd_offset_k(va), va), va); /* Use middle 10 bits of VA to index the second-level map */ pg = pte_alloc_kernel(pd, va); if (pg != 0) &#123; err = 0; /* The PTE should never be already set nor present in the * hash table */ BUG_ON((pte_val(*pg) &amp; (_PAGE_PRESENT | _PAGE_HASHPTE)) &amp;&amp; flags); set_pte_at(&amp;init_mm, va, pg, pfn_pte(pa &gt;&gt; PAGE_SHIFT, __pgprot(flags))); &#125; return err;&#125; 再看下init_mm的相关定义：12345678910struct mm_struct init_mm = &#123; .mm_rb = RB_ROOT, .pgd = swapper_pg_dir, .mm_users = ATOMIC_INIT(2), .mm_count = ATOMIC_INIT(1), .mmap_sem = __RWSEM_INITIALIZER(init_mm.mmap_sem), .page_table_lock = __SPIN_LOCK_UNLOCKED(init_mm.page_table_lock), .mmlist = LIST_HEAD_INIT(init_mm.mmlist), INIT_MM_CONTEXT(init_mm)&#125;; 因此可见，kernel的页表是保存在swapper_pg_dir中的。它是init_task的active_mm：1234567891011121314#define INIT_TASK(tsk) \&#123; \ .state = 0, \ .stack = &amp;init_thread_info, \ .usage = ATOMIC_INIT(2), \ .flags = PF_KTHREAD, \ .prio = MAX_PRIO-20, \ .static_prio = MAX_PRIO-20, \ .normal_prio = MAX_PRIO-20, \ .policy = SCHED_NORMAL, \ .cpus_allowed = CPU_MASK_ALL, \ .nr_cpus_allowed= NR_CPUS, \ .mm = NULL, \ .active_mm = &amp;init_mm, \ 1truct task_struct init_task = INIT_TASK(init_task); init_task是内核代码开始位置被执行的：1234567/* * This is where the main kernel code starts. */start_here: /* ptr to current */ lis r2,init_task@h ori r2,r2,init_task@l start_here在start_kernel之前被执行。在start_kernel里rest_init会启动kernel_init来启动一个init进程，init_task并不是init进程，init_task是内核启动主代码所在的上下文，该进程最后停在了cpu_idle中（start_kernel-&gt;rest_init-&gt;cpu_idle），好吧，它的真面目出来了，它就是创世界的进程，并且最后变成了无所事事的idle了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解C++的动态绑定和静态绑定]]></title>
    <url>%2F2019%2F05%2F05%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3cpp%E7%9A%84%E5%8A%A8%E6%80%81%E7%BB%91%E5%AE%9A%E5%92%8C%E9%9D%99%E6%80%81%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/chgaowei/article/details/6427731 为了支持c++的多态性，才用了动态绑定和静态绑定。理解他们的区别有助于更好的理解多态性，以及在编程的过程中避免犯错误。需要理解四个名词：1、对象的静态类型：对象在声明时采用的类型。是在编译期确定的。2、对象的动态类型：目前所指对象的类型。是在运行期决定的。对象的动态类型可以更改，但是静态类型无法更改。关于对象的静态类型和动态类型，看一个示例：12345678910111213class B&#123;&#125;class C : public B&#123;&#125;class D : public B&#123;&#125;D* pD = new D();//pD的静态类型是它声明的类型D*，动态类型也是D*B* pB = pD;//pB的静态类型是它声明的类型B*，动态类型是pB所指向的对象pD的类型D*C* pC = new C();pB = pC;//pB的动态类型是可以更改的，现在它的动态类型是C* 3、静态绑定：绑定的是对象的静态类型，某特性（比如函数）依赖于对象的静态类型，发生在编译期。4、动态绑定：绑定的是对象的动态类型，某特性（比如函数）依赖于对象的动态类型，发生在运行期。1234567891011121314151617class B&#123; void DoSomething(); virtual void vfun();&#125;class C : public B&#123; void DoSomething();//首先说明一下，这个子类重新定义了父类的no-virtual函数，这是一个不好的设计，会导致名称遮掩；这里只是为了说明动态绑定和静态绑定才这样使用。 virtual void vfun();&#125;class D : public B&#123; void DoSomething(); virtual void vfun();&#125;D* pD = new D();B* pB = pD; 让我们看一下，pD-&gt;DoSomething()和pB-&gt;DoSomething()调用的是同一个函数吗？不是的，虽然pD和pB都指向同一个对象。因为函数DoSomething是一个no-virtual函数，它是静态绑定的，也就是编译器会在编译期根据对象的静态类型来选择函数。pD的静态类型是D，那么编译器在处理pD-&gt;DoSomething()的时候会将它指向D::DoSomething()。同理，pB的静态类型是B，那pB-&gt;DoSomething()调用的就是B::DoSomething()。 让我们再来看一下，pD-&gt;vfun()和pB-&gt;vfun()调用的是同一个函数吗？是的。因为vfun是一个虚函数，它动态绑定的，也就是说它绑定的是对象的动态类型，pB和pD虽然静态类型不同，但是他们同时指向一个对象，他们的动态类型是相同的，都是D*，所以，他们的调用的是同一个函数：D::vfun()。 上面都是针对对象指针的情况，对于引用（reference）的情况同样适用。 指针和引用的动态类型和静态类型可能会不一致，但是对象的动态类型和静态类型是一致的。D D;D.DoSomething()和D.vfun()永远调用的都是D::DoSomething()和D::vfun()。 我总结了一句话：只有虚函数才使用的是动态绑定，其他的全部是静态绑定。目前我还没有发现不适用这句话的，如果有错误，希望你可以指出来。 特别需要注意的地方 当缺省参数和虚函数一起出现的时候情况有点复杂，极易出错。我们知道，虚函数是动态绑定的，但是为了执行效率，缺省参数是静态绑定的。123456789101112class B&#123; virtual void vfun(int i = 10);&#125;class D : public B&#123; virtual void vfun(int i = 20);&#125;D* pD = new D();B* pB = pD;pD-&gt;vfun();pB-&gt;vfun(); 有上面的分析可知pD-&gt;vfun()和pB-&gt;vfun()调用都是函数D::vfun()，但是他们的缺省参数是多少？分析一下，缺省参数是静态绑定的，pD-&gt;vfun()时，pD的静态类型是D*，所以它的缺省参数应该是20；同理，pB-&gt;vfun()的缺省参数应该是10。编写代码验证了一下，正确。对于这个特性，估计没有人会喜欢。所以，永远记住：“绝不重新定义继承而来的缺省参数（Never redefine function’s inherited default parameters value.）” 关于c++语言目前我基本上都是在c++的子集“面向对象编程”下工作，对于更复杂的知识了解的还不是很多。即便如此，到目前为止编程时需要注意的东西已经很多，而且后面可能还会继续增多，这也许是很多人反对c++的原因。c++是Google的四大官方语言之一。但是Google近几年确推出了go语言，而且定位是和c/c++相似。考虑这种情况，我认为可能是Google的程序员们深感c++的复杂，所以想开发一种c++的替代语言。有时间要了解一下go语言，看它在类似c++的问题上时如何取舍的。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fork()----父子进程共享]]></title>
    <url>%2F2019%2F05%2F05%2Ffork----%E7%88%B6%E5%AD%90%E8%BF%9B%E7%A8%8B%E5%85%B1%E4%BA%AB%2F</url>
    <content type="text"><![CDATA[fork（）会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程。在fork之后exec之前两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间，如果不是因为exec，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而代码段继续共享父进程的物理空间（两者的代码完全相同）。而如果是因为exec，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。 fork之后内核会通过将子进程放在队列的前面，以让子进程先执行，以免父进程执行导致写时复制，而后子进程执行exec系统调用，因无意义的复制而造成效率的下降。fork时子进程获得父进程数据空间、堆和栈的复制，所以变量的地址（当然是虚拟地址）也是一样的。 每个进程都有自己的虚拟地址空间，不同进程的相同的虚拟地址显然可以对应不同的物理地址。因此地址相同（虚拟地址）而值不同没什么奇怪。具体过程是这样的：fork子进程完全复制父进程的栈空间，也复制了页表，但没有复制物理页面，所以这时虚拟地址相同，物理地址也相同，但是会把父子共享的页面标记为“只读”（类似mmap的private的方式），如果父子进程一直对这个页面是同一个页面，知道其中任何一个进程要对共享的页面“写操作”，这时内核会复制一个物理页面给这个进程使用，同时修改页表。而把原来的只读页面标记为“可写”，留给另外一个进程使用。 这就是所谓的“写时复制”。正因为fork采用了这种写时复制的机制，所以fork出来子进程之后，父子进程哪个先调度呢？内核一般会先调度子进程，因为很多情况下子进程是要马上执行exec，会清空栈、堆。。这些和父进程共享的空间，加载新的代码段。。。，这就避免了“写时复制”拷贝共享页面的机会。如果父进程先调度很可能写共享页面，会产生“写时复制”的无用功。所以，一般是子进程先调度滴。 子进程与父进程之间除了代码是共享的之外，堆栈数据和全局数据均是独立的。 pid = fork()返回两次，第一次父进程，第二次子进程：123[root@localhost timetest]# ./testThis is parent process: 4016This is child process: 4017 注意：这里不是绝对的先返回父进程的pid，具体先执行那个进程，要看操作系统的进程调度算法。 操作系统创建一个新的进程（子进程），并且在进程表中相应为它建立一个新的表项。新进程和原有进程的可执行程序是同一个程序；上下文和数据，绝大部分就是原进程（父进程）的拷贝，但它们是两个相互独立的进程！此时程序寄存器pc，在父、子进程的上下文中都声称，这个进程目前执行到fork调用即将返回（此时子进程不占有CPU，子进程的pc不是真正保存在寄存器中，而是作为进程上下文保存在进程表中的对应表项内）。问题是怎么返回，在父子进程中就分道扬镳。 父进程继续执行，操作系统对fork的实现，使这个调用在父进程中返回刚刚创建的子进程的pid（一个正整数），所以下面的if语句中pid&lt;0, pid==0的两个分支都不会执行。所以输出i am the parent process… 子进程在之后的某个时候得到调度，它的上下文被换入，占据 CPU，操作系统对fork的实现，使得子进程中fork调用返回0。所以在这个进程（注意这不是父进程了哦，虽然是同一个程序，但是这是同一个程序的另外一次执行，在操作系统中这次执行是由另外一个进程表示的，从执行的角度说和父进程相互独立）中pid=0。这个进程继续执行的过程中，if语句中 pid&lt;0不满足，但是pid= =0是true。所以输出i am the child process… 为什么看上去程序中互斥的两个分支都被执行了？在一个程序的一次执行中，这当然是不可能的；但是你看到的两行输出是来自两个进程，这两个进程来自同一个程序的两次执行。 fork之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，但只有一点不同，如果fork成功，子进程中fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。 可以这样想象，2个进程一直同时运行，而且步调一致，在fork之后，他们分别作不同的工作，也就是分岔了。这也是fork为什么叫fork的原因。 在程序段里用了fork()之后程序出了分岔，派生出了两个进程。具体哪个先运行就看该系统的调度算法了。 如果需要父子进程协同，可以通过原语的办法解决。 父进程为什么要创建子进程呢? 前面我们已经说过了Linux是一个多用户操作系统,在同一时间会有许多的用户在争夺系统的资源.有时进程为了早一点完成任务就创建子进程来争夺资源. 一旦子进程被创建,父子进程一起从fork处继续执行,相互竞争系统的资源.有时候我们希望子进程继续执行,而父进程阻塞,直到子进程完成任务.这个时候我们可以调用wait或者waitpid系统调用. ,对子进程来说，fork返回给它0,但它的pid绝对不会是0；之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid； fork之后父子进程除非采用了同步手段，否则不能确定谁先运行，也不能确定谁先结束。认为子进程结束后父进程才从fork返回的，这是不对的，fork不是这样的，vfork才这样。 为什么返回0呢 首先必须有一点要清楚，函数的返回值是储存在寄存器eax中的。其次，当fork返回时，新进程会返回0是因为在初始化任务结构时，将eax设置为0；在fork中，把子进程加入到可运行的队列中，由进程调度程序在适当的时机调度运行。也就是从此时开始，当前进程分裂为两个并发的进程。无论哪个进程被调度运行，都将继续执行fork函数的剩余代码，执行结束后返回各自的值。 【NOTE5】对于fork来说，父子进程共享同一段代码空间，所以给人的感觉好像是有两次返回，其实对于调用fork的父进程来说，如果fork出来的子进程没有得到调度，那么父进程从fork系统调用返回，同时分析sys_fork知道，fork返回的是子进程的id。再看fork出来的子进程，由 copy_process函数可以看出，子进程的返回地址为ret_from_fork（和父进程在同一个代码点上返回），返回值直接置为0。所以当子进程得到调度的时候，也从fork返回，返回值为0。关键注意两点：1.fork返回后，父进程或子进程的执行位置。（首先会将当前进程eax的值做为返回值）2.两次返回的pid存放的位置。（eax中） 进程调用copy_process得到lastpid的值（放入eax中，fork正常返回后，父进程中返回的就是lastpid）子进程任务状态段tss的eax被设置成0，fork.c 中p-&gt;tss.eax=0;（如果子进程要执行就需要进程切换，当发生切换时，子进程tss中的eax值就调入eax寄存器，子进程执行时首先会将eax的内容做为返回值）当子进程开始执行时，copy_process返回eax的值。fork()后,就是两个任务同时进行,父进程用他的tss,子进程用自己的tss,在切换时,各用各的eax中的值. 所以，“一次调用两次返回”是2个不同的进程！看这一句：pid＝fork()当执行这一句时，当前进程进入fork()运行，此时，fork()内会用一段嵌入式汇编进行系统调用：int 0x80（具体代码可参见内核版本0.11的unistd.h文件的133行_syscall0函数）。这时进入内核根据此前写入eax的系统调用功能号便会运行sys_fork系统调用。接着，sys_fork中首先会调用C函数find_empty_process产生一个新的进程，然后会调用C函数 copy_process将父进程的内容复制给子进程，但是子进程tss中的eax值赋值为0（这也是为什么子进程中返回0的原因），当赋值完成后， copy_process会返回新进程（该子进程）的pid，这个值会被保存到eax中。这时子进程就产生了，此时子进程与父进程拥有相同的代码空间，程序指针寄存器eip指向相同的下一条指令地址，当fork正常返回调用其的父进程后，因为eax中的值是新创建的子进程号，所以，fork()返回子进程号，执行else（pid&gt;0）;当产生进程切换运行子进程时，首先会恢复子进程的运行环境即装入子进程的tss任务状态段，其中的eax 值(copy_process中置为0)也会被装入eax寄存器，所以，当子进程运行时，fork返回的是0执行if(pid==0)。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux线程切换和进程切换的方法]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E7%BA%BF%E7%A8%8B%E5%88%87%E6%8D%A2%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%88%87%E6%8D%A2%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[进程切换分两步： 切换页目录以使用新的地址空间 切换内核栈和硬件上下文 对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。 切换的性能消耗： 线程上下文切换和进程上下问切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。 另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor’s Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。 系统调用：处于进程上下文 系统调用是在进程上下文中,并没有tasklet之类的延迟运行,系统调用本身可以休眠,这些可以参见内核代码 虽然系统调用实与其他中断实现有点类似,通过IDT表查找入口处理函数,但是系统调用与其他中断最大的不同是,系统调用是代表当前进程执行的,所以current宏/task_struct是有意义的,这个休眠可以被唤醒 系统调用，异常，中断（其中中断是异步时钟，异常时同步时钟），也可以把系统调用成为异常 中断上下文：在中断中执行时依赖的环境，就是中断上下文（不包括系统调用，是硬件中断） 进程上下文：当一个进程在执行时,CPU的所有寄存器中的值、进程的状态以及堆栈中的内容被称为该进程的上下文 首先，这两个上下文都处于内核空间。 其次，两者的区别在于，进程上下文与当前执行进程密切相关，而中断上下文在逻辑上与进程没有关系。 进程上下文主要是异常处理程序和内核线程。内核之所以进入进程上下文是因为进程自身的一些工作需要在内核中做。例如，系统调用是为当前进程服务的，异常通常是处理进程导致的错误状态等。所以在进程上下文中引用current是有意义的。 内核进入中断上下文是因为中断信号而导致的中断处理或软中断。而中断信号的发生是随机的，中断处理程序及软中断并不能事先预测发生中断时当前运行的是哪个进程，所以在中断上下文中引用current是可以的，但没有意义。事实上，对于A进程希望等待的中断信号，可能在B进程执行期间发生。例如，A进程启动写磁盘操作，A进程睡眠后现在时B进程在运行，当磁盘写完后磁盘中断信号打断的是B进程，在中断处理时会唤醒A进程。 上下文这个词会让人想到进程的CPU寄存器状态，但好像进入进程上下文（异常处理系统调用）和进入中断上下文（中断处理），内核所做的工作没有太大区别。所以，这两个上下文的主要区别，我认为在于是否与进程相关。 运行于进程上下文的内核代码是可抢占的，但中断上下文则会一直运行至结束，不会被抢占。因此，内核会限制中断上下文的工作，不允许其执行如下操作： (1) 进入睡眠状态或主动放弃CPU; 由于中断上下文不属于任何进程，它与current没有任何关系（尽管此时current指向被中断的进程），所以中断上下文一旦睡眠或者放弃CPU，将无法被唤醒。所以也叫原子上下文（atomic context）。 (2) 占用互斥体; 为了保护中断句柄临界区资源，不能使用mutexes。如果获得不到信号量，代码就会睡眠，会产生和上面相同的情况，如果必须使用锁，则使用spinlock。 (3) 执行耗时的任务; 中断处理应该尽可能快，因为内核要响应大量服务和请求，中断上下文占用CPU时间太长会严重影响系统功能。在中断处理例程中执行耗时任务时，应该交由中断处理例程底半部来处理。 (4) 访问用户空间虚拟内存。 因为中断上下文是和特定进程无关的，它是内核代表硬件运行在内核空间，所以在中断上下文无法访问用户空间的虚拟地址 (5) 中断处理例程不应该设置成reentrant（可被并行或递归调用的例程）。 因为中断发生时，preempt和irq都被disable，直到中断返回。所以中断上下文和进程上下文不一样，中断处理例程的不同实例，是不允许在SMP上并发运行的。 (6)中断处理例程可以被更高级别的IRQ中断。（不能嵌套中断）使用软中断，上部分关中断，也就是禁止嵌套，下半部分使用软中断 如果想禁止这种中断，可以将中断处理例程定义成快速处理例程，相当于告诉CPU，该例程运行时，禁止本地CPU上所有中断请求。这直接导致的结果是，由于其他中断被延迟响应，系统性能下降。 软中断是一种延时机制，代码执行的优先级比进程要高，比硬中断要低。相比于硬件中断，软中段是在开中断的环境中执行的（长时间关中断对系统的开销太大）， 代码是执行在中断/线程上下文的，是不能睡眠的，虽然每个cpu都有一个对应的ksoftirqd/n线程来执行软中断，但是do_softirq这个函数也还会在中断退出时调用到，因此不能睡眠(中断上下文不能睡眠的原因是由于调度系统是以进程为基本单位的，调度时会把当前进程的上下文保存在task_struct这个数据结构中，当进程被调度重新执行时会找到执行的断点，但是中断上下文是没有特定task_struct结构体的，当然现在有所谓的线程话中断，可以满足在中断处理函数执行阻塞操作，但是实时性可能会有问题。还有就是中断代表当前进程执行的概念，个人感觉有点扯淡，毕竟整个内核空间是由所有进程共享的，不存在代表的概念) 上面我们介绍的可延迟函数运行在中断上下文中（软中断的一个检查点就是do_IRQ退出的时候），于是导致了一些问题：软中断不能睡眠、不能阻塞。由于中断上下文出于内核态，没有进程切换，所以如果软中断一旦睡眠或者阻塞，将无法退出这种状态，导致内核会整个僵死。但可阻塞函数不能用在中断上下文中实现，必须要运行在进程上下文中，例如访问磁盘数据块的函数。因此，可阻塞函数不能用软中断来实现。但是它们往往又具有可延迟的特性。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存管理之mmap详解]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B9%8Bmmap%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/caogenwangbaoqiang/article/details/80780106 mmap系统调用mmap系统调用mmap将一个文件或者其它对象映射进内存。文件被映射到多个页上，如果文件的大小不是所有页的大小之和，最后一个页不被使用的空间将会清零。munmap执行相反的操作，删除特定地址区域的对象映射。 当使用mmap映射文件到进程后,就可以直接操作这段虚拟地址进行文件的读写等操作,不必再调用read,write等系统调用.但需注意,直接对该段内存写时不会写入超过当前文件大小的内容. 采用共享内存通信的一个显而易见的好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝。对于像管道和消息队列等通信方式，则需要在内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次数据：一次从输入文件到共享内存区，另一次从共享内存区到输出文件。实际上，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时，再重新建立共享内存区域。而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件的。因此，采用共享内存的通信方式效率是非常高的。 基于文件的映射，在mmap和munmap执行过程的任何时刻，被映射文件的st_atime可能被更新。如果st_atime字段在前述的情况下没有得到更新，首次对映射区的第一个页索引时会更新该字段的值。用PROT_WRITE 和 MAP_SHARED标志建立起来的文件映射，其st_ctime 和 st_mtime在对映射区写入之后，但在msync()通过MS_SYNC 和 MS_ASYNC两个标志调用之前会被更新。 用法：123void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);int munmap(void *start, size_t length); 返回说明： 成功执行时，mmap()返回被映射区的指针，munmap()返回0。失败时，mmap()返回MAP_FAILED[其值为(void *)-1]，munmap返回-1。errno被设为以下的某个值1234567891011EACCES：访问出错EAGAIN：文件已被锁定，或者太多的内存已被锁定EBADF：fd不是有效的文件描述词EINVAL：一个或者多个参数无效ENFILE：已达到系统对打开文件的限制ENODEV：指定文件所在的文件系统不支持内存映射ENOMEM：内存不足，或者进程已超出最大内存映射数量EPERM：权能不足，操作不允许ETXTBSY：已写的方式打开文件，同时指定MAP_DENYWRITE标志SIGSEGV：试着向只读区写入SIGBUS：试着访问不属于进程的内存区 参数： start：映射区的开始地址。length：映射区的长度。prot：期望的内存保护标志，不能与文件的打开模式冲突。是以下的某个值，可以通过or运算合理地组合在一起PROT_EXEC //页内容可以被执行PROT_READ //页内容可以被读取PROT_WRITE //页可以被写入PROT_NONE //页不可访问flags：指定映射对象的类型，映射选项和映射页是否可以共享。它的值可以是一个或者多个以下位的组合体MAP_FIXED //使用指定的映射起始地址，如果由start和len参数指定的内存区重叠于现存的映射空间，重叠部分将会被丢弃。如果指定的起始地址不可用，操作将会失败。并且起始地址必须落在页的边界上。MAP_SHARED //与其它所有映射这个对象的进程共享映射空间。对共享区的写入，相当于输出到文件。直到msync()或者munmap()被调用，文件实际上不会被更新。MAP_PRIVATE //建立一个写入时拷贝的私有映射。内存区域的写入不会影响到原文件。这个标志和以上标志是互斥的，只能使用其中一个。MAP_DENYWRITE //这个标志被忽略。MAP_EXECUTABLE //同上MAP_NORESERVE //不要为这个映射保留交换空间。当交换空间被保留，对映射区修改的可能会得到保证。当交换空间不被保留，同时内存不足，对映射区的修改会引起段违例信号。MAP_LOCKED //锁定映射区的页面，从而防止页面被交换出内存。MAP_GROWSDOWN //用于堆栈，告诉内核VM系统，映射区可以向下扩展。MAP_ANONYMOUS //匿名映射，映射区不与任何文件关联。MAP_ANON //MAP_ANONYMOUS的别称，不再被使用。MAP_FILE //兼容标志，被忽略。MAP_32BIT //将映射区放在进程地址空间的低2GB，MAP_FIXED指定时会被忽略。当前这个标志只在x86-64平台上得到支持。MAP_POPULATE //为文件映射通过预读的方式准备好页表。随后对映射区的访问不会被页违例阻塞。MAP_NONBLOCK //仅和MAP_POPULATE一起使用时才有意义。不执行预读，只为已存在于内存中的页面建立页表入口。fd：有效的文件描述词。如果MAP_ANONYMOUS被设定，为了兼容问题，其值应为-1。offset：被映射对象内容的起点。 系统调用munmap()int munmap( void * addr, size_t len )该调用在进程地址空间中解除一个映射关系，addr是调用mmap()时返回的地址，len是映射区的大小。当映射关系解除后，对原来映射地址的访问将导致段错误发生。 系统调用msync()int msync ( void * addr , size_t len, int flags)一般说来，进程在映射空间的对共享内容的改变并不直接写回到磁盘文件中，往往在调用munmap（）后才执行该操作。可以通过调用msync()实现磁盘上文件内容与共享内存区的内容一致。 系统调用mmap()用于共享内存的两种方式：使用普通文件提供的内存映射适用于任何进程之间；此时，需要打开或创建一个文件，然后再调用mmap()；典型调用代码如下：1234fd=open(name, flag, mode); if(fd&lt;0) … ptr=mmap(NULL, len , PROT_READ|PROT_WRITE, MAP_SHARED , fd , 0); 通过mmap()实现共享内存的通信方式有许多特点和要注意的地方 使用特殊文件提供匿名内存映射适用于具有亲缘关系的进程之间；由于父子进程特殊的亲缘关系，在父进程中先调用mmap()，然后调用fork()。那么在调用fork()之后，子进程继承父进程匿名映射后的地址空间，同样也继承mmap()返回的地址，这样，父子进程就可以通过映射区域进行通信了。注意，这里不是一般的继承关系。一般来说，子进程单独维护从父进程继承下来的一些变量。而mmap()返回的地址，却由父子进程共同维护。对于具有亲缘关系的进程实现共享内存最好的方式应该是采用匿名内存映射的方式。此时，不必指定具体的文件，只要设置相应的标志即可. mmap进行内存映射的原理mmap系统调用的最终目的是将,设备或文件映射到用户进程的虚拟地址空间,实现用户进程对文件的直接读写,这个任务可以分为以下三步: 在用户虚拟地址空间中寻找空闲的满足要求的一段连续的虚拟地址空间,为映射做准备(由内核mmap系统调用完成) 每个进程拥有3G字节的用户虚存空间。但是，这并不意味着用户进程在这3G的范围内可以任意使用，因为虚存空间最终得映射到某个物理存储空间（内存或磁盘空间），才真正可以使用。 那么，内核怎样管理每个进程3G的虚存空间呢？概括地说，用户进程经过编译、链接后形成的映象文件有一个代码段和数据段（包括data段和bss段），其中代码段在下，数据段在上。数据段中包括了所有静态分配的数据空间，即全局变量和所有申明为static的局部变量，这些空间是进程所必需的基本要求，这些空间是在建立一个进程的运行映像时就分配好的。除此之外，堆栈使用的空间也属于基本要求，所以也是在建立进程时就分配好的. 在内核中,这样每个区域用一个结构struct vm_area_struct 来表示.它描述的是一段连续的、具有相同访问属性的虚存空间，该虚存空间的大小为物理内存页面的整数倍。可以使用 cat /proc//maps来查看一个进程的内存使用情况,pid是进程号.其中显示的每一行对应进程的一个vm_area_struct结构. 下面是struct vm_area_struct结构体的定义：12345678910111213141516171819202122/* This struct defines a memory VMM memory area. */ struct vm_area_struct &#123; struct mm_struct * vm_mm; /* VM area parameters */ unsigned long vm_start; unsigned long vm_end; /* linked list of VM areas per task, sorted by address */ struct vm_area_struct *vm_next; pgprot_t vm_page_prot; unsigned long vm_flags; /* AVL tree of VM areas per task, sorted by address */ short vm_avl_height; struct vm_area_struct * vm_avl_left; struct vm_area_struct * vm_avl_right; /* For areas with an address space and backing store, vm_area_struct *vm_next_share; struct vm_area_struct **vm_pprev_share; struct vm_operations_struct * vm_ops; unsigned long vm_pgoff; /* offset in PAGE_SIZE units, not PAGE_CACHE_SIZE */ struct file * vm_file; unsigned long vm_raend; void * vm_private_data; /* was vm_pte (shared mem) */ &#125;; 通常，进程所使用到的虚存空间不连续，且各部分虚存空间的访问属性也可能不同。所以一个进程的虚存空间需要多个vm_area_struct结构来描述。在vm_area_struct结构的数目较少的时候，各个vm_area_struct按照升序排序，以单链表的形式组织数据（通过vm_next指针指向下一个vm_area_struct结构）。但是当vm_area_struct结构的数据较多的时候，仍然采用链表组织的化，势必会影响到它的搜索速度。针对这个问题，vm_area_struct还添加了vm_avl_hight（树高）、vm_avl_left（左子节点）、vm_avl_right（右子节点）三个成员来实现AVL树，以提高vm_area_struct的搜索速度。 假如该vm_area_struct描述的是一个文件映射的虚存空间，成员vm_file便指向被映射的文件的file结构，vm_pgoff是该虚存空间起始地址在vm_file文件里面的文件偏移，单位为物理页面。 因此,mmap系统调用所完成的工作就是准备这样一段虚存空间,并建立vm_area_struct结构体,将其传给具体的设备驱动程序. 建立虚拟地址空间和文件或设备的物理地址之间的映射(设备驱动完成) 建立文件映射的第二步就是建立虚拟地址和具体的物理地址之间的映射,这是通过修改进程页表来实现的.mmap方法是file_opeartions结构的成员: int (mmap)(struct file ,struct vm_area_struct *); linux有2个方法建立页表: (1) 使用remap_pfn_range一次建立所有页表. int remap_pfn_range(struct vm_area_struct *vma, unsigned long virt_addr, unsigned long pfn, unsigned long size, pgprot_t prot); 返回值: 成功返回 0, 失败返回一个负的错误值参数说明: vma 用户进程创建一个vma区域virt_addr 重新映射应当开始的用户虚拟地址. 这个函数建立页表为这个虚拟地址范围从 virt_addr 到 virt_addr_size.pfn 页帧号, 对应虚拟地址应当被映射的物理地址. 这个页帧号简单地是物理地址右移 PAGE_SHIFT 位. 对大部分使用, VMA 结构的 vm_paoff 成员正好包含你需要的值. 这个函数影响物理地址从 (pfn&lt;&lt;&lt; span=”” style=”word-wrap: break-word;”&gt;size 正在被重新映射的区的大小, 以字节.prot 给新 VMA 要求的”protection”. 驱动可(并且应当)使用在vma-&gt;vm_page_prot 中找到的值. (2) 使用nopage VMA方法每次建立一个页表项.1struct page *(*nopage)(struct vm_area_struct *vma, unsigned long address, int *type); 返回值: 成功则返回一个有效映射页,失败返回NULL. 参数说明: address 代表从用户空间传过来的用户空间虚拟地址. 返回一个有效映射页. (3) 使用方面的限制： remap_pfn_range不能映射常规内存，只存取保留页和在物理内存顶之上的物理地址。因为保留页和在物理内存顶之上的物理地址内存管理系统的各个子模块管理不到。640 KB 和 1MB 是保留页可能映射，设备I/O内存也可以映射。如果想把kmalloc()申请的内存映射到用户空间，则可以通过mem_map_reserve()把相应的内存设置为保留后就可以。 当实际访问新映射的页面时的操作(由缺页中断完成)(1) page cache及swap cache中页面的区分：一个被访问文件的物理页面都驻留在page cache或swap cache中，一个页面的所有信息由struct page来描述。struct page中有一个域为指针mapping ，它指向一个struct address_space类型结构。page cache或swap cache中的所有页面就是根据address_space结构以及一个偏移量来区分的。 (2) 文件与 address_space结构的对应：一个具体的文件在打开后，内核会在内存中为之建立一个struct inode结构，其中的i_mapping域指向一个address_space结构。这样，一个文件就对应一个address_space结构，一个 address_space与一个偏移量能够确定一个page cache 或swap cache中的一个页面。因此，当要寻址某个数据时，很容易根据给定的文件及数据在文件内的偏移量而找到相应的页面。 (3) 进程调用mmap()时，只是在进程空间内新增了一块相应大小的缓冲区，并设置了相应的访问标识，但并没有建立进程空间到物理页面的映射。因此，第一次访问该空间时，会引发一个缺页异常。 (4) 对于共享内存映射情况，缺页异常处理程序首先在swap cache中寻找目标页（符合address_space以及偏移量的物理页），如果找到，则直接返回地址；如果没有找到，则判断该页是否在交换区 (swap area)，如果在，则执行一个换入操作；如果上述两种情况都不满足，处理程序将分配新的物理页面，并把它插入到page cache中。进程最终将更新进程页表。 注：对于映射普通文件情况（非共享映射），缺页异常处理程序首先会在page cache中根据address_space以及数据偏移量寻找相应的页面。如果没有找到，则说明文件数据还没有读入内存，处理程序会从磁盘读入相应的页面，并返回相应地址，同时，进程页表也会更新. (5) 所有进程在映射同一个共享内存区域时，情况都一样，在建立线性地址与物理地址之间的映射之后，不论进程各自的返回地址如何，实际访问的必然是同一个共享内存区域对应的物理页面。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[直接存储器存取DMA]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%9B%B4%E6%8E%A5%E5%AD%98%E5%82%A8%E5%99%A8%E5%AD%98%E5%8F%96DMA%2F</url>
    <content type="text"><![CDATA[DMA（Direct Memory Access）DMA（Direct Memory Access）即直接存储器存取，是一种快速传送数据的机制。 工作原理DMA是指外部设备不通过CPU而直接与系统内存交换数据的接口技术。 要把外设的数据读入内存或把内存的数据传送到外设，一般都要通过CPU控制完成，如CPU程序查询或中断方式。利用中断进行数据传送，可以大大提高CPU的利用率。 但是采用中断传送有它的缺点，对于一个高速I/O设备，以及批量交换数据的情况，只能采用DMA方式，才能解决效率和速度问题。DMA在外设与内存间直接进行数据交换，而不通过CPU，这样数据传送的速度就取决于存储器和外设的工作速度。 通常系统的总线是由CPU管理的。在DMA方式时，就希望CPU把这些总线让出来，即CPU连到这些总线上的线处于第三态–高阻状态，而由DMA控制器接管，控制传送的字节数，判断DMA是否结束，以及发出DMA结束信号。DMA控制器必须有以下功能： 能向CPU发出系统保持（HOLD）信号，提出总线接管请求； 当CPU发出允许接管信号后，负责对总线的控制，进入DMA方式； 能对存储器寻址及能修改地址指针，实现对内存的读写操作； 能决定本次DMA传送的字节数，判断DMA传送是否结束 发出DMA结束信号，使CPU恢复正常工作状态。 DMA流程计算机发展到今天，DMA已不再用于内存到内存的数据传送，因为CPU速度非常快，做这件事，比用DMA控制还要快，但要在适配卡和内存之间传送数据，仍然是非DMA莫属。要从适配卡到内存传送数据，DMA同时触发从适配卡读数据总线(即I/O读操作)和向内存写数据的总线。激活I/O读操作就是让适配卡把一个数据单位(通常是一个字节或一个字)放到PC数据总线上，因为此时内存写总线也被激活，数据就被同时从PC总线上拷贝到内存中。 DMA工作方式 随着大规模集成电路技术的发展，DMA传送已不局限于存储器与外设间的信息交换，而可以扩展为在存储器的两个区域之间，或两种高速的外设之间进行DMA传送，如图所示。DMAC是控制存储器和外部设备之间直接高速地传送数据的硬件电路，它应能取代CPU，用硬件完成数据传送的各项功能。各种DMAC一般都有两种基本的DMA传送方式： 单字节方式：每次DMA请求只传送一个字节数据，每传送完一个字节，都撤除DMA请求信号，释放总线。 多字节方式：每次DMA请求连续传送一个数据块，待规定长度的数据块传送完以后，才撤除DMA请求，释放总线。 在DMA传送中，为了使源和目的间的数据传送取得同步，不同的DMAC在操作时都受到外设的请求信号或准备就绪信号–Ready信号的限制。 工作方式DMA与CPU调度DMA控制器可采用哪几种方式与CPU分时使用内存？直接内存访问（DMA）方式是一种完全由硬件执行I/O交换的工作方式。DMA控制器从CPU完全接管对总线的控制。数据交换不经过CPU，而直接在内存和I/O设备之间进行。DMA控制器采用以下三种方式： 停止CPU访问内存：当外设要求传送一批数据时，由DMA控制器发一个信号给CPU。DMA控制器获得总线控制权后，开始进行数据传送。一批数据传送完毕后，DMA控制器通知CPU可以使用内存，并把总线控制权交还给CPU。 周期挪用：当I/O设备没有 DMA请求时，CPU按程序要求访问内存：一旦 I/O设备有DMA请求，则I/O设备挪用一个或几个周期。 DMA与CPU交替访内：一个CPU周期可分为2个周期，一个专供DMA控制器访内，另一个专供CPU访内。不需要总线使用权的申请、建立和归还过程。 DMA概述DMA的英文拼写是“Direct Memory Access”，汉语的意思就是直接内存访问。DMA既可以指内存和外设直接存取数据这种内存访问的计算机技术，又可以指实现该技术的硬件模块（对于通用计算机PC而言，DMA控制逻辑由CPU和DMA控制接口逻辑芯片共同组成，嵌入式系统的DMA控制器内建在处理器芯片内部，一般称为DMA控制器，DMAC）。 DMA内存访问技术使用DMA的好处就是它不需要CPU的干预而直接服务外设，这样CPU就可以去处理别的事务，从而提高系统的效率，对于慢速设备，如UART，其作用只是降低CPU的使用率，但对于高速设备，如硬盘，它不只是降低CPU的使用率，而且能大大提高硬件设备的吞吐量。因为对于这种设备，CPU直接供应数据的速度太低。 因CPU只能一个总线周期最多存取一次总线，而且对于ARM，它不能把内存中A地址的值直接搬到B地址。它只能先把A地址的值搬到一个寄存器，然后再从这个寄存器搬到B地址。也就是说，对于ARM，要花费两个总线周期才能将A地址的值送到B地址。而DMA就不同了，一般系统中的DMA都有突发（Burst）传输的能力，在这种模式下，DMA能一次传输几个甚至几十个字节的数据，所以使用DMA能使设备的吞吐能力大为增强。 使用DMA时我们必须要注意如下事实： DMA使用物理地址，程序是使用虚拟地址的，所以配置DMA时必须将虚拟地址转化成物理地址。 因为程序使用虚拟地址，而且一般使用cache地址，所以Cache中的内容与其物理地址（内存）的内容不一定一致，所以在启动DMA传输前一定要将该地址的cache刷新，即写入内存。 OS并不能保证每次分配到的内存空间在物理上是连续的。尤其是在系统使用过一段时间而又分配了一块比较大的内存时。所以每次都需要判断地址是不是连续的，如果不连续就需要把这段内存分成几段让DMA完成传输 DMAC的基本配置DMA用于无需CPU的介入而直接由专用控制器（DMA控制器）建立源与目的传输的应用，因此，在大量数据传输中解放了CPU。PIC32微控制器中的DMA可用于映射到内存空间中的不同外设，如从存储区到SPI，UART或I2C等设备。DMA特性详见器件参考手册，这里仅对一些基本原理与功能做一个简析。 |—|—地址寄存器|放DMA传输时存储单元地址字节计数器|存放DMA传输的字节数控制寄存器|存放由CPU设定的DMA传输方式，控制命令等状态寄存器|存放DMAC当前的状态，包括有无DMA请求，是否结束等 独立DMA控制芯片在课程《微机原理》中，会讲到X86下一片独立的DMA控制芯片8237A。8237A控制芯片各通道在PC机内的任务： CH0：用作动态存储器的刷新控制CH1：为用户预留CH2：软盘驱动器数据传输用的DMA控制CH3：硬盘驱动器数据传输用的DMA控制 嵌入式设备中的DMA直接存储器存取(DMA)控制器是一种在系统内部转移数据的独特外设，可以将其视为一种能够通过一组专用总线将内部和外部存储器与每个具有DMA能力的外设连接起来的控制器。它之所以属于外设，是因为它是在处理器的编程控制下来执行传输的。值得注意的是，通常只有数据流量较大(kBps或者更高)的外设才需要支持DMA能力，这些应用方面典型的例子包括视频、音频和网络接口。 一般而言，DMA控制器将包括一条地址总线、一条数据总线和控制寄存器。高效率的DMA控制器将具有访问其所需要的任意资源的能力，而无须处理器本身的介入，它必须能产生中断。最后，它必须能在控制器内部计算出地址。 一个处理器可以包含多个DMA控制器。每个控制器有多个DMA通道，以及多条直接与存储器站(memory bank)和外设连接的总线，如图1所示。在很多高性能处理器中集成了两种类型的DMA控制器。第一类通常称为“系统DMA控制器”，可以实现对任何资源(外设和存储器)的访问，对于这种类型的控制器来说，信号周期数是以系统时钟(SCLK)来计数的，以ADI的Blackfin处理器为例，频率最高可达133MHz。第二类称为内部存储器DMA控制器(IMDMA)，专门用于内部存储器所处位置之间的相互存取操作。因为存取都发生在内部(L1－L1、L1－L2，或者L2－L2)，周期数的计数则以内核时钟(CCLK)为基准来进行，该时钟的速度可以超过600MHz。 每个DMA控制器有一组FIFO，起到DMA子系统和外设或存储器之间的缓冲器的作用。对于MemDMA(Memory DMA)来说，传输的源端和目标端都有一组FIFO存在。当资源紧张而不能完成数据传输的话，则FIFO可以提供数据的暂存区，从而提高性能。 因为通常会在代码初始化过程中对DMA控制器进行配置，内核就只需要在数据传输完成后对中断做出响应即可。你可以对DMA控制进行编程，让其与内核并行地移动数据，而同时让内核执行其基本的处理任务―那些应该让它专注完成的工作。 在一个优化的应用中，内核永远不用参与任何数据的移动，而仅仅对L1存储器中的数据进行读写。于是，内核不需要等待数据的到来，因为DMA引擎会在内核准备读取数据之前将数据准备好。图2给出了处理器和DMA控制器间的交互关系。由处理器完成的操作步骤包括：建立传输，启用中断，生成中断时执行代码。返回到处理器的中断输入可以用来指示“数据已经准备好，可进行处理”。 数据除了往来外设之外，还需要从一个存储器空间转移到另一个空间中。例如，视频源可以从一个 视频端口直接流入L3存储器，因为工作缓冲区规模太大，无法放入到存储器中。我们并不希望让处理器在每次需要执行计算时都从外部存储读取像素信息，因此为 了提高存取的效率，可以用一个存储器到存储器的DMA(MemDMA)来将像素转移到L1或者L2存储器中。 到目前为之，我们还仅专注于数据的移动，但是DMA的传送能力并不总是用来移动数据。 在最简单的MemDMA情况中，我们需要告诉DMA控制器源端地址、目标端地址和待传送的字的个数。每次传输的字的大小可以是8、16或者12位。 我们只需要改变数据传输每次的数据大小，就可以简单地增加DMA的灵活性。例如，采用非单一大小的传输方式时，我们以传输数据块的大小的倍数来作为地址增量。也就是说，若规定32位的传输和4个采样的跨度，则每次传输结束后，地址的增量为16字节(4个32位字)。 DMA的设置目前有两类主要的DMA传输结构：寄存器模式和描述符模式。无论属于哪一类DMA，表1所描述的几类信息都会在DMA控制器中出现。当DMA以寄存器模式工作时，DMA控制器只是简单地利用寄存器中所存储的参数值。在描述符模式中，DMA控制器在存储器中查找自己的配置参数。 基于寄存器的DMA在基于寄存器的DMA内部，处理器直接对DMA控制寄存器进行编程，来启动传输。基于寄存器的DMA提供了最佳的DMA控制器性能，因为寄存器并不需要不断地从存储器中的描述符上载入数据，而内核也不需要保持描述符。 基于寄存器的DMA由两种子模式组成：自动缓冲(Autobuffer)模式和停止模式。在自动缓冲DMA中，当一个传输块传输完毕，控制寄存器就自动重新载入其最初的设定值，同一个DMA进程重新启动，开销为零。 正如我们在图3中所看到的那样，如果将一个自动缓冲DMA设定为从外设传输一定数量的字到 L1数据存储器的缓冲器上，则DMA控制器将会在最后一个字传输完成的时刻就迅速重新载入初始的参数。这构成了一个“循环缓冲器”，因为当一个量值被写入 到缓冲器的最后一个位置上时，下一个值将被写入到缓冲器的第一个位置上。 自动缓冲DMA特别适合于对性能敏感的、存在持续数据流的应用。DMA控制器可以在独立于处理器其他活动的情况下读入数据流，然后在每次传输结束时，向内核发出中断。 停止模式的工作方式与自动缓冲DMA类似，区别在于各寄存器在DMA结束后不会重新载入，因 此整个DMA传输只发生一次。停止模式对于基于某种事件的一次性传输来说十分有用。例如，非定期地将数据块从一个位置转移到另一个位置。当你需要对事件进 行同步时，这种模式也非常有用。例如，如果一个任务必须在下一次传输前完成的话，则停止模式可以确保各事件发生的先后顺序。此外，停止模式对于缓冲器的初 始化来说非常有用。 描述符模型基于描述符(descriptor)的DMA要求在存储器中存入一组参数，以 启动DMA的系列操作。该描述符所包含的参数与那些通常通过编程写入DMA控制寄存器组的所有参数相同。不过，描述符还可以容许多个DMA操作序列串在一 起。在基于描述符的DMA操作中，我们可以对一个DMA通道进行编程，在当前的操作序列完成后，自动设置并启动另一次DMA传输。基于描述符的方式为管理 系统中的DMA传输提供了最大的灵活性。 ADI 的Blackfin处理器上有两种主要的描述符方式―描述符阵列和描述符列表，这两种操作方式所要实现的目标是在灵活性和性能之间实现一种折中平衡。 直接内存访问(DMA)什么是DMA直接内存访问是一种硬件机制，它允许外围设备和主内存之间直接传输它们的I/O数据，而不需要系统处理器的参与。使用这种机制可以大大提高与设备通信的吞吐量。 DMA数据传输有两种方式引发数据传输：第一种情况：软件对数据的请求 当进程调用read，驱动程序函数分配一个DMA缓冲区，并让硬件将数据传输到这个缓冲区中。进程处于睡眠状态。 硬件将数据写入到DMA缓冲区中，当写入完毕，产生一个中断 中断处理程序获取输入的数据，应答中断，并唤起进程，该进程现在即可读取数据 第二种情况发生在异步使用DMA时。 硬件产生中断，宣告新数据的到来 中断处理程序分配一个缓冲区，并且告诉硬件向哪里传输数据 外围设备将数据写入数据区，完成后，产生另外一个中断 处理程序分发新数据，唤醒任何相关进程，然后执行清理工作 高效的DMA处理依赖于中断报告。 分配DMA缓冲区使用DMA缓冲区的主要问题是：当大于一页时，它们必须占据连续的物理页，因为设备使用ISA或PCI系统总线传输数据，而这两种方式使用的都是物理地址。 使用get_free_pasges可以分配多大几M字节的内存(MAX_ORDER是11)，但是对于较大数量(即使是远小于128KB)的请求，通常会失败，这是因为系统内存充满了内存碎片。 解决方法之一就是在引导时分配内存，或者为缓冲区保留顶部物理内存。 例子：在系统引导时，向内核传递参数“mem=value”的方法保留顶部的RAM。比如系统有256内存，参数“mem=255M”，使内核不能使用顶部的1M字节。随后，模块可以使用下面代码获得该内存的访问权： dmabuf=ioremap(0XFF00000/*255M/, 0X100000/1M/*); 解决方法之二是使用GPF_NOFAIL分配标志为缓冲区分配内存，但是该方法为内存管理子系统带来了相当大的压力。 解决方法之三十设备支持分散/聚集I/O，这可以将缓冲区分配成多个小块，设备会很好地处理它们。 通用DMA层DMA操作最终会分配缓冲区，并将总线地址传递给设备。内核提高了一个与总线——体系结构无关的DMA层。强烈建议在编写驱动程序时，为DMA操作使用该层。使用这些函数的头文件是&lt;linux/dmamapping.h&gt;。 int dma_set_mask(struct device *dev, u64 mask); 该掩码显示该设备能寻址能力对应的位。比如说，设备受限于24位寻址，则mask应该是0x0FFFFFF。 DMA映射IOMMU在设备可访问的地址范围内规划了物理内存，使得物理上分散的缓冲区对设备来说成连续的。对IOMMU的运用需要使用到通用DMA层，而vir_to_bus函数不能完成这个任务。但是，x86平台没有对IOMMU的支持。 解决之道就是建立回弹缓冲区，然后，必要时会将数据写入或者读出回弹缓冲区。缺点是降低系统性能。 根据DMA缓冲区期望保留的时间长短，PCI代码区分两种类型的DMA映射： 一是一致性DMA映射，存在于驱动程序生命周期中，一致性映射的缓冲区必须可同时被CPU和外围设备访问。一致性映射必须保存在一致性缓存中。建立和使用一致性映射的开销是很大的。 二是流式DMA映射，内核开发者建议尽量使用流式映射，原因：一是在支持映射寄存器的系统中，每个DMA映射使用总线上的一个或多个映射寄存器，而一致性映射生命周期很长，长时间占用这些这些寄存器，甚至在不使用他们的时候也不释放所有权；二是在一些硬件中，流式映射可以被优化，但优化的方法对一致性映射无效。 建立一致性映射驱动程序可调用pci_alloc_consistent函数建立一致性映射： void dma_alloc_coherent(struct device dev, size_t size, dma_addr_t *dma_handle, int falg); 该函数处理了缓冲区的分配和映射，前两个参数是device结构和所需的缓冲区的大小。函数在两处返回DMA映射的结果：函数的返回值是缓冲区的内核虚拟地址，可以被驱动程序使用；而与其相关的总线地址保存在dma_handle中。 当不再需要缓冲区时，调用下函数： void dma_free_conherent(struct device dev, size_t size, void vaddr, dma_addr_t *dma_handle); DMA池DMA池是一个生成小型，一致性DMA映射的机制。调用dma_alloc_coherent函数获得的映射，可能其最小大小为单个页。如果设备需要的DMA区域比这还小，就是用DMA池。在&lt;linux/dmapool.h&gt;中定义了DMA池函数： struct dma_pool dma_pool_create(const char name, struct device *dev, size_t size, size_t align, size_t allocation); void dma_pool_destroy(struct dma_pool *pool); name是DMA池的名字，dev是device结构，size是从该池中分配的缓冲区的大小，align是该池分配操作所必须遵守的硬件对齐原则(用字节表示)，如果allocation不为零，表示内存边界不能超越allocation。比如说传入的allocation是4K，表示从该池分配的缓冲区不能跨越4KB的界限。 在销毁之前必须向DMA池返回所有分配的内存。 void dma_pool_alloc(sturct dma_pool pool, int mem_flags, dma_addr_t *handle); void dma_pool_free(struct dma_pool pool, void addr, dma_addr_t addr); 建立流式DMA映射在某些体系结构中，流式映射也能够拥有多个不连续的页和多个“分散/聚集”缓冲区。建立流式映射时，必须告诉内核数据流动的方向。 DMA_TO_DEVICE DEVICE_TO_DMA 如果数据被发送到设备，使用DMA_TO_DEVICE；而如果数据被发送到CPU，则使用DEVICE_TO_DMA。 DMA_BIDIRECTTONAL 如果数据可双向移动，则使用该值 DMA_NONE 该符号只是出于调试目的。 当只有一个缓冲区要被传输的时候，使用下函数映射它： dma_addr_t dma_map_single(struct device dev, void buffer, size_t size, enum dma_data_direction direction); 返回值是总线地址，可以把它传递给设备；如果执行错误，返回NULL。 当传输完毕后，使用下函数删除映射： void dma_unmap_single(struct device *dev, dma_addr_t dma_addr, size_t size, enum dma-data_direction direction); 使用流式DMA的原则： 一是缓冲区只能用于这样的传送，即其传送方向匹配与映射时给定的方向值； 二是一旦缓冲区被映射，它将属于设备，不是处理器。直到缓冲区被撤销映射前，驱动程序不能以任何方式访问其中的内容。只用当dma_unmap_single函数被调用后，显示刷新处理器缓存中的数据，驱动程序才能安全访问其中的内容。 三是在DMA出于活动期间内，不能撤销对缓冲区的映射，否则会严重破坏系统的稳定性。 如果要映射的缓冲区位于设备不能访问的内存区段(高端内存)，怎么办？一些体系结构只产生一个错误，但是其他一些系统结构件创建一个回弹缓冲区。回弹缓冲区就是内存中的独立区域，它可被设备访问。如果使用DMA_TO_DEVICE标志映射缓冲区，并且需要使用回弹缓冲区，则在最初缓冲区中的内容作为映射操作的一部分被拷贝。很明显，在拷贝后，最初缓冲区内容的改变对设备不可见。同样DEVICE_TO_DMA回弹缓冲区被dma_unmap_single函数拷贝回最初的缓冲区中，也就是说，直到拷贝操作完成，来自设备的数据才可用。 有时候，驱动程序需要不经过撤销映射就访问流式DMA缓冲区的内容，为此内核提供了如下调用： void dma_sync_single_for_cpu(struct device *dev, dma_handle_t bus_addr, size_t size, enum dma_data_directction direction); 应该在处理器访问流式DMA缓冲区前调用该函数。一旦调用了该函数，处理器将“拥有”DMA缓冲区，并可根据需要对它进行访问。然后在设备访问缓冲区前，应该调用下面的函数将所有权交还给设备： void dma_sync_single_for_device(struct device *dev, dma_handle_t bus_addr, size_t size, enum dma_data_direction direction); 再次强调，处理器在调用该函数后，不能再访问DMA缓冲区了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几道和「黑洞照片」那种海量数据有关的算法问题]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%87%A0%E9%81%93%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E6%9C%89%E5%85%B3%E7%9A%84%E7%AE%97%E6%B3%95%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[原文：https://cxyxiaowu.com/articles/2019/04/11/1554963765366.html 海量数据查找中位数题目描述现在有 10 亿个 int 型的数字（ java 中 int 型占 4B），以及一台可用内存为 1GB 的机器，如何找出这 10 亿个数字的中位数？ 所谓中位数就是有序列表中间的数。如果列表长度是偶数，中位数则是中间两个数的平均值。 题目解析题目中有 10 亿个数字，每个数字在内存中占 4B，那么这 10 亿个数字完全加载到内存中需要：10 10^8 4，大概需要 4GB 的存储空间。根据题目的限制，显然不能把所有的数字都装入内存中。 这里，可以采用基于 二进制位比较 和 快速排序算法中的 分割思想 来寻找中位数，实际上这也是 桶排序 的一种应用。 假设将这 10 亿个数字保存在一个大文件中，依次读一部分文件到内存(不超过内存的限制： 1GB )，将每个数字用二进制表示，比较二进制的最高位(第 32 位)，如果数字的最高位为 0，则将这个数字写入 file_0 文件中；如果最高位为 1，则将该数字写入 file_1 文件中。 注意：最高位为符号位，也就是说 file_1 中的数都是负数，而 file_0 中的数都是正数。 通过这样的操作，这 10 亿个数字分成了两个文件，假设 file_0 文件中有 6 亿个数字，而 file_1 文件中有 4 亿个数字。 这样划分后，思考一下：所求的中位数在哪个文件中？ 10 亿个数字的中位数是10 亿个数排序之后的第 5 亿个数，现在 file_0 有 6 亿个正数，file_1 有 4 亿个负数，file_0 中的数都比 file_1 中的数要大，排序之后的第 5 亿个数一定是正数，那么排序之后的第 5 亿个数一定位于file_0中。 也就是说：中位数就在 file_0 文件中，并且是 file_0 文件中所有数字排序之后的第 1 亿个数字。 现在，我们只需要处理 file_0 文件了（不需要再考虑 file_1 文件）。 而对于 file_0 文件，可以同样的采取上面的措施处理：将 file_0 文件依次读一部分到内存(不超内存限制：1GB )，将每个数字用二进制表示，比较二进制的 次高位（第 31 位），如果数字的次高位为 0，写入 file_0_0 文件中；如果次高位为 1 ，写入 file_0_1 文件中。 现假设 file_0_0 文件中有 3 亿个数字，file_0_1中也有 3 亿个数字，则中位数就是：file_0_0 文件中的数字从小到大排序之后的第 1 亿个数字。 抛弃 file_0_1 文件，继续对 file_0_0 文件 根据次次高位(第 30 位) 划分，假设此次划分的两个文件为：file_0_0_0中有 0.5 亿个数字，file_0_0_1 中有 2.5 亿个数字，那么中位数就是 file_0_0_1 文件中的所有数字排序之后的第 0.5 亿个数。 海量数据中判断数字是否存在题目描述现在有 10 亿个 int 型的数字（ java 中 int 型占 4B），以及一台可用内存为 1GB 的机器，给出一个整数，问如果快速地判断这个整数是否在这 10 亿数字中？ 题目分析这里可以使用 布隆过滤器 进行处理。 布隆过滤器（英语：Bloom Filter）是 1970 年由 Burton Bloom 提出的。 它实际上是一个很长的二进制矢量和一系列随机映射函数。它可以用来判断一个元素是否在一个集合中。它的优势是只需要占用很小的内存空间以及有着高效的查询效率。 对于布隆过滤器而言，它的本质是一个位数组：位数组就是数组的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1。 一开始，布隆过滤器的位数组所有位都初始化为 0。比如，数组长度为 m ，那么将长度为 m 个位数组的所有的位都初始化为 0。 0 0 0 0 0 0 0 0 0 00 0 1 。 。 。 。 。 m-2 m-1在数组中的每一位都是二进制位。 布隆过滤器除了一个位数组，还有 K 个哈希函数。当一个元素加入布隆过滤器中的时候，会进行如下操作： 使用 K 个哈希函数对元素值进行 K 次计算，得到 K 个哈希值。根据得到的哈希值，在位数组中把对应下标的值置为 1。 举个例子，假设布隆过滤器有 3 个哈希函数：f1, f2, f3 和一个位数组 arr。现在要把 2333 插入布隆过滤器中： 对值进行三次哈希计算，得到三个值 n1, n2, n3。 把位数组中三个元素 arr[n1], arr[n2], arr[3] 都置为 1。 当要判断一个值是否在布隆过滤器中，对元素进行三次哈希计算，得到值之后判断位数组中的每个元素是否都为 1，如果值都为 1，那么说明这个值在布隆过滤器中，如果存在一个值不为 1，说明该元素不在布隆过滤器中。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode392. Is Subsequence]]></title>
    <url>%2F2019%2F05%2F05%2FLeetcode392%2F</url>
    <content type="text"><![CDATA[Given a string s and a string t, check if s is subsequence of t. You may assume that there is only lower case English letters in both s and t. t is potentially a very long (length ~= 500,000) string, and s is a short string (&lt;=100). A subsequence of a string is a new string which is formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (ie, “ace” is a subsequence of “abcde” while “aec” is not). Example 1:12s = &quot;abc&quot;, t = &quot;ahbgdc&quot;Return true. Example 2:12s = &quot;axc&quot;, t = &quot;ahbgdc&quot;Return false. Follow up:If there are lots of incoming S, say S1, S2, … , Sk where k &gt;= 1B, and you want to check one by one to see if T has its subsequence. In this scenario, how would you change your code? 检查一个串是不是另一个串的子串，找两个指针即可。123456789101112131415161718192021class Solution &#123;public: bool isSubsequence(string s, string t) &#123; int ss,tt; ss=0; tt=0; while(ss&lt;s.length() &amp;&amp; tt&lt;t.length())&#123; if(s[ss]==t[tt])&#123; ss++; tt++; &#125; else tt++; &#125; if(ss==s.length())&#123; return true; &#125; else return false; &#125;&#125;; 我们可以用俩个指针i，j分别指向字符串s，t. 算法描述如下: j指针一直往后走，碰到t[j]==s[i]的时候，说明匹配上了一个，将i++，否则i不加1，当t都走完的时候，这个时候，我们判断一下i指针是否走完了s字符串，如果走完了，说明也匹配上了，如果没有走完，那么就是没有匹配上，中间的过程，i提前等于s.length()的时候，也可以退出！此时的时间复杂度就是扫描一遍t，s串的线性复杂度O(t_len+s_len)。 算法正确性： 我们算法的关键点就在于，当s[i]=t[j]的时候，i和j都需要加1，那么这俩个指针加1的过程是否一定是对的呢？我们可以这样理解，当s=”abc”,t=”ahbgdc”,i=1,j=1的时候，我们只需要判断s后面的子串bc是否是t的子串hbgdc的子集（相当于分解为子问题），如果s的子串bc满足是t的子串hbgdc的子集，我们就返回true，如果不满足，我们就返回false。这样一步一步贪心下去就能保证算法正确性。 下面举一个简单例子走一遍算法帮助理解: s=”abc”, t=“ahbgdc” 首先i，j都为0，分别指向s，t俩个串开头. 第一步，当j=0&lt;t_len=6的时候，进入循环，此时t[0]=a,s[0]=a,俩者相等，那么i,j都1，此时i=1，j=1，i!=(s_len=3),不跳出, j还是小于t_len。 此时t[1]=h ,s[1]=b,它们不相等，那么只有j加1，此时i=1,j=2，i!=3，不跳出. j还是小于t_len=6，此时t[2]=b,s[1]=b,它们相等，那么i,j分别加1，此时i=2，j=3,i!=3不跳出. 那么t[3]=g,s[2]=c,它们不相等，那么之后j加1，此时i=2,j=4，i!=3不跳出. 此时t[4]=d,s[2]=2,它们不相等,此时j加1,i=2,j=5,i!=3不跳出. j还是小于6，t[5]=c,s[2]=c,此时它们相等，i++，i=3，此时等于s_len，res=true，跳出while循环，返回结果为true。1234567891011121314151617181920212223242526class Solution &#123;public: bool isSubsequence(string s, string t) &#123; //俩个指针都往前走 if(s.length()==0) return true; //空字符串是任何字符串的子串 int i = 0,j = 0; bool res = false; int s_len = s.length(),t_len = t.length(); while(j &lt; t_len) &#123; if(t[j] == s[i]) &#123; i++; if(i==s_len) &#123; res = true; break; &#125; &#125; j++; //无论t[j]是否等于s[i]，j都要加1 &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux文件系统详解]]></title>
    <url>%2F2019%2F05%2F05%2FLinux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/alantu2018/p/8461749.html 概述在LINUX系统中有一个重要的概念：一切都是文件。 其实这是UNIX哲学的一个体现，而Linux是重写UNIX而来，所以这个概念也就传承了下来。在UNIX系统中，把一切资源都看作是文件，包括硬件设备。UNIX系统把每个硬件都看成是一个文件，通常称为设备文件，这样用户就可以用读写文件的方式实现对硬件的访问。这样带来优势也是显而易见的： UNIX 权限模型也是围绕文件的概念来建立的，所以对设备也就可以同样处理了。 硬盘驱动常见的硬盘类型有PATA, SATA和AHCI等，在Linux系统中，对不同硬盘所提供的驱动模块一般都存放在内核目录树drivers/ata中，而对于一般通用的硬盘驱动，也许会直接被编译到内核中，而不会以模块的方式出现，可以通过查看/boot/config-xxx.xxx文件来确认： CONFIG_SATA_AHCI=y General Block Device Layer这一层的作用，正是解答了上面提出的第一个问题，不同的硬盘驱动，会提供不同的IO接口，内核认为这种杂乱的接口，不利于管理，需要把这些接口抽象一下，形成一个统一的对外接口，这样，不管你是什么硬盘，什么驱动，对外而言，它们所提供的IO接口没什么区别，都一视同仁的被看作块设备来处理。 所以，如果在一层做的任何修改，将会直接影响到所有文件系统，不管是ext3,ext4还是其它文件系统，只要在这一层次做了某种修改，对它们都会产生影响。 文件系统文件系统这一层相信大家都再熟悉不过了，目前大多Linux发行版本默认使用的文件系统一般是ext4，另外，新一代的btrfs也呼之欲出，不管什么样的文件系统，都是由一系列的mkfs.xxx命令来创建，如：12mkfs.ext4 /dev/sdamkfs.btrfs /dev/sdb 内核所支持的文件系统类型，可以通过内核目录树 fs 目录中的内容来查看。 虚拟文件系统(VFS)Virtual File System这一层，正是用来解决上面提出的第二个问题，试想，当我们通过mkfs.xxx系列命令创建了很多不同的文件系统，但这些文件系统都有各自的API接口，而用户想要的是，不管你是什么API，他们只关心mount/umount，或open/close等操作。 所以，VFS就把这些不同的文件系统做一个抽象，提供统一的API访问接口，这样，用户空间就不用关心不同文件系统中不一样的API了。VFS所提供的这些统一的API，再经过System Call包装一下，用户空间就可以经过SCI的系统调用来操作不同的文件系统。VFS所提供的常用API有：123mount()， umount() …open()，close() …mkdir() … 和文件系统关系最密切的就是存储介质，存储介质大致有RAM，ROM，磁盘磁带，闪存等。 闪存（Flash Memory）是一种长寿命的非易失性（在断电情况下仍能保持所存储的数据信息）的存储器，数据删除不是以单个的字节为单位而是以固定的区块为单位（注意：NOR Flash 为字节存储。），区块大小一般为256KB到20MB。闪存是电子可擦除只读存储器（EEPROM）的变种，EEPROM与闪存不同的是，它能在字节水平上进行删除和重写而不是整个芯片擦写，这样闪存就比EEPROM的更新速度快。由于其断电时仍能保存数据，闪存通常被用来保存设置信息，如在电脑的BIOS（基本输入输出程序）、PDA（个人数字助理）、数码相机中保存资料等。 外存通常是磁性介质或光盘，像硬盘，软盘，磁带，CD等，能长期保存信息，并且不依赖于电来保存信息，但是由机械部件带动，速度与CPU相比就显得慢的多。内存指的就是主板上的存储部件，是CPU直接与之沟通，并用其存储数据的部件，存放当前正在使用的（即执行中）的数据和程序，它的物理实质就是一组或多组具备数据输入输出和数据存储功能的集成电路，内存只用于暂时存放程序和数据，一旦关闭电源或发生断电，其中的程序和数据就会丢失。RAM又分为动态的和静态。。静态被用作cache，动态的常用作内存。。网上说闪存不能代替DRAM是因为闪存不像RAM（随机存取存储器）一样以字节为单位改写数据，因此不能取代RAM。这个以后可以了解下硬件的知识再来辨别. Linux下的文件系统结构如下： Linux启动时，第一个必须挂载的是根文件系统；若系统不能从指定设备上挂载根文件系统，则系统会出错而退出启动。之后可以自动或手动挂载其他的文件系统。因此，一个系统中可以同时存在不同的文件系统。 不同的文件系统类型有不同的特点，因而根据存储设备的硬件特性、系统需求等有不同的应用场合。在嵌入式Linux应用中，主要的存储设备为RAM(DRAM, SDRAM)和ROM(常采用FLASH存储器)，常用的基于存储设备的文件系统类型包括：jffs2, yaffs, cramfs, romfs, ramdisk, ramfs/tmpfs等。 基于FLASH的文件系统Flash(闪存)作为嵌入式系统的主要存储媒介，有其自身的特性。Flash的写入操作只能把对应位置的1修改为0，而不能把0修改为1(擦除Flash就是把对应存储块的内容恢复为1)，因此，一般情况下，向Flash写入内容时，需要先擦除对应的存储区间，这种擦除是以块(block)为单位进行的。 闪存主要有NOR和NAND两种技术。Flash存储器的擦写次数是有限的，NAND闪存还有特殊的硬件接口和读写时序。因此，必须针对Flash的硬件特性设计符合应用要求的文件系统；传统的文件系统如ext2等，用作Flash的文件系统会有诸多弊端。 在嵌入式Linux下，MTD(Memory Technology Device,存储技术设备)为底层硬件(闪存)和上层(文件系统)之间提供一个统一的抽象接口，即Flash的文件系统都是基于MTD驱动层的(参见上面的Linux下的文件系统结构图)。使用MTD驱动程序的主要优点在于，它是专门针对各种非易失性存储器(以闪存为主)而设计的，因而它对Flash有更好的支持、管理和基于扇区的擦除、读/写操作接口。 顺便一提，一块Flash芯片可以被划分为多个分区，各分区可以采用不同的文件系统；两块Flash芯片也可以合并为一个分区使用，采用一个文件系统。即文件系统是针对于存储器分区而言的，而非存储芯片。(1) jffs2JFFS文件系统最早是由瑞典Axis Communications公司基于Linux2.0的内核为嵌入式系统开发的文件系统。JFFS2是RedHat公司基于JFFS开发的闪存文件系统，最初是针对RedHat公司的嵌入式产品eCos开发的嵌入式文件系统，所以JFFS2也可以用在Linux, uCLinux中。Jffs2: 日志闪存文件系统版本2 (Journalling Flash FileSystem v2)主要用于NOR型闪存，基于MTD驱动层，特点是：可读写的、支持数据压缩的、基于哈希表的日志型文件系统，并提供了崩溃/掉电安全保护，提供“写平衡”支持等。缺点主要是当文件系统已满或接近满时，因为垃圾收集的关系而使jffs2的运行速度大大放慢。目前jffs3正在开发中。关于jffs系列文件系统的使用详细文档，可参考MTD补丁包中mtd-jffs-HOWTO.txt。jffsx不适合用于NAND闪存主要是因为NAND闪存的容量一般较大，这样导致jffs为维护日志节点所占用的内存空间迅速增大，另外，jffsx文件系统在挂载时需要扫描整个FLASH的内容，以找出所有的日志节点，建立文件结构，对于大容量的NAND闪存会耗费大量时间。 (2) yaffs：Yet Another Flash File Systemyaffs/yaffs2是专为嵌入式系统使用NAND型闪存而设计的一种日志型文件系统。与jffs2相比，它减少了一些功能(例如不支持数据压缩)，所以速度更快，挂载时间很短，对内存的占用较小。另外，它还是跨平台的文件系统，除了Linux和eCos，还支持WinCE, pSOS和ThreadX等。yaffs/yaffs2自带NAND芯片的驱动，并且为嵌入式系统提供了直接访问文件系统的API，用户可以不使用Linux中的MTD与VFS，直接对文件系统操作。当然，yaffs也可与MTD驱动程序配合使用。yaffs与yaffs2的主要区别在于，前者仅支持小页(512 Bytes) NAND闪存，后者则可支持大页(2KB) NAND闪存。同时，yaffs2在内存空间占用、垃圾回收速度、读/写速度等方面均有大幅提升。 (3) Cramfs：Compressed ROM File SystemCramfs是Linux的创始人 Linus Torvalds参与开发的一种只读的压缩文件系统。它也基于MTD驱动程序。在cramfs文件系统中，每一页(4KB)被单独压缩，可以随机页访问，其压缩比高达2:1,为嵌入式系统节省大量的Flash存储空间，使系统可通过更低容量的FLASH存储相同的文件，从而降低系统成本。Cramfs文件系统以压缩方式存储，在运行时解压缩，所以不支持应用程序以XIP方式运行，所有的应用程序要求被拷到RAM里去运行，但这并不代表比Ramfs需求的RAM空间要大一点，因为Cramfs是采用分页压缩的方式存放档案，在读取档案时，不会一下子就耗用过多的内存空间，只针对目前实际读取的部分分配内存，尚没有读取的部分不分配内存空间，当我们读取的档案不在内存时，Cramfs文件系统自动计算压缩后的资料所存的位置，再即时解压缩到RAM中。另外，它的速度快，效率高，其只读的特点有利于保护文件系统免受破坏，提高了系统的可靠性。由于以上特性，Cramfs在嵌入式系统中应用广泛。但是它的只读属性同时又是它的一大缺陷，使得用户无法对其内容对进扩充。?Cramfs映像通常是放在Flash中，但是也能放在别的文件系统里，使用loopback 设备可以把它安装别的文件系统里。 (4) Romfs传统型的Romfs文件系统是一种简单的、紧凑的、只读的文件系统，不支持动态擦写保存，按顺序存放数据，因而支持应用程序以XIP(eXecute In Place，片内运行)方式运行，在系统运行时，节省RAM空间。uClinux系统通常采用Romfs文件系统。其他文件系统：fat/fat32也可用于实际嵌入式系统的扩展存储器(例如PDA, Smartphone, 数码相机等的SD卡)，这主要是为了更好的与最流行的Windows桌面操作系统相兼容。ext2也可以作为嵌入式Linux的文件系统，不过将它用于FLASH闪存会有诸多弊端。 基于RAM的文件系统(1) RamdiskRamdisk是将一部分固定大小的内存当作分区来使用。它并非一个实际的文件系统，而是一种将实际的文件系统装入内存的机制，并且可以作为根文件系统。将一些经常被访问而又不会更改的文件(如只读的根文件系统)通过Ramdisk放在内存中，可以明显地提高系统的性能。在Linux的启动阶段，initrd提供了一套机制，可以将内核映像和根文件系统一起载入内存。 (2)ramfs/tmpfsRamfs是Linus Torvalds开发的一种基于内存的文件系统，工作于虚拟文件系统(VFS)层，不能格式化，可以创建多个，在创建时可以指定其最大能使用的内存大小。(实际上，VFS本质上可看成一种内存文件系统，它统一了文件在内核中的表示方式，并对磁盘文件系统进行缓冲。)Ramfs/tmpfs文件系统把所有的文件都放在RAM中，所以读/写操作发生在RAM中，可以用ramfs/tmpfs来存储一些临时性或经常要修改的数据，例如/tmp和/var目录，这样既避免了对Flash存储器的读写损耗，也提高了数据读写速度。Ramfs/tmpfs相对于传统的Ramdisk的不同之处主要在于：不能格式化，文件系统大小可随所含文件内容大小变化。Tmpfs的一个缺点是当系统重新引导时会丢失所有数据。 网络文件系统NFS (Network File System)NFS是由Sun开发并发展起来的一项在不同机器、不同操作系统之间通过网络共享文件的技术。在嵌入式Linux系统的开发调试阶段，可以利用该技术在主机上建立基于NFS的根文件系统，挂载到嵌入式设备，可以很方便地修改根文件系统的内容。以上讨论的都是基于存储设备的文件系统(memory-based file system)，它们都可用作Linux的根文件系统。实际上，Linux还支持逻辑的或伪文件系统(logical or pseudo file system)，例如procfs(proc文件系统)，用于获取系统信息，以及devfs(设备文件系统)和sysfs，用于维护设备文件。 附录：NOR闪存与NAND闪存比较NOR FLASH接口时序同SRAM,易使用读取速度较快擦除速度慢，以64-128KB的块为单位写入速度慢(因为一般要先擦除)随机存取速度较快，支持XIP(eXecute In Place，芯片内执行)，适用于代码存储。在嵌入式系统中，常用于存放引导程序、根文件系统等。单片容量较小，1－32MB最大擦写次数10万次 NAND FLASH地址/数据线复用，数据位较窄读取速度较慢擦除速度快，以8－32KB的块为单位写入速度快顺序读取速度较快，随机存取速度慢，适用于数据存储(如大容量的多媒体应用)。在嵌入式系统中，常用于存放用户文件系统等。单片容量较大，8－128MB，提高了单元密度http://bbs.ednchina.com/BLOG_ARTICLE_142972.HTM 文件存储结构介绍文件存储结构前先来看看文件系统如何划分磁盘，创建一个文件、目录、链接的过程。 物理磁盘到文件系统我们知道文件最终是保存在硬盘上的。硬盘最基本的组成部分是由坚硬金属材料制成的涂以磁性介质的盘片，不同容量硬盘的盘片数不等。每个盘片有两面，都可记录信息。盘片被分成许多扇形的区域，每个区域叫一个扇区，每个扇区可存储128×2的N次方（N＝0.1.2.3）字节信息。在DOS中每扇区是128×2的2次方＝512字节，盘片表面上以盘片中心为圆心，不同半径的同心圆称为磁道。硬盘中，不同盘片相同半径的磁道所组成的圆柱称为柱面。磁道与柱面都是表示不同半径的圆，在许多场合，磁道和柱面可以互换使用，我们知道，每个磁盘有两个面，每个面都有一个磁头，习惯用磁头号来区分。扇区，磁道（或柱面）和磁头数构成了硬盘结构的基本参数，帮这些参数可以得到硬盘的容量，基计算公式为：存储容量＝磁头数×磁道（柱面）数×每道扇区数×每扇区字节数要点：（1）硬盘有数个盘片，每盘片两个面，每个面一个磁头（2）盘片被划分为多个扇形区域即扇区（3）同一盘片不同半径的同心圆为磁道（4）不同盘片相同半径构成的圆柱面即柱面（5）公式： 存储容量＝磁头数×磁道（柱面）数×每道扇区数×每扇区字节数（6）信息记录可表示为：××磁道（柱面），××磁头，××扇区 那么这些空间又是怎么管理起来的呢？unix/linux使用了一个简单的方法。它将磁盘块分为以下三个部分： 超级块，文件系统中第一个块被称为超级块。这个块存放文件系统本身的结构信息。比如，超级块记录了每个区域的大小，超级块也存放未被使用的磁盘块的信息。 I-切点表。超级块的下一个部分就是i-节点表。每个i-节点就是一个对应一个文件/目录的结构，这个结构它包含了一个文件的长度、创建及修改时间、权限、所属关系、磁盘中的位置等信息。一个文件系统维护了一个索引节点的数组，每个文件或目录都与索引节点数组中的唯一一个元素对应。系统给每个索引节点分配了一个号码，也就是该节点在数组中的索引号，称为索引节点号 数据区。文件系统的第3个部分是数据区。文件的内容保存在这个区域。磁盘上所有块的大小都一样。如果文件包含了超过一个块的内容，则文件内容会存放在多个磁盘块中。一个较大的文件很容易分布上千个独产的磁盘块中。 Linux正统的文件系统(如ext2、ext3)一个文件由目录项、inode和数据块组成。 目录项:包括文件名和inode节点号。 Inode：又称文件索引节点，是文件基本信息的存放地和数据块指针存放地。 数据块：文件的具体内容存放地。 Linux正统的文件系统(如ext2、3等)将硬盘分区时会划分出目录块、inode Table区块和data block数据区域。一个文件由一个目录项、inode和数据区域块组成。Inode包含文件的属性(如读写属性、owner等，以及指向数据块的指针)，数据区域块则是文件内容。当查看某个文件时，会先从inode table中查出文件属性及数据存放点，再从数据块中读取数据。 文件存储结构大概如下： 其中目录项的结构如下(每个文件的目录项存储在改文件所属目录的文件内容里)： 其中文件的inode结构如下（inode里所包含的文件信息可以通过stat filename查看得到）： 以上只反映大体的结构，linux文件系统本身在不断发展。但是以上概念基本是不变的。且如ext2、ext3、ext4文件系统也存在很大差别，如果要了解可以查看专门的文件系统介绍。 创建一个文件的过程我们从前面可以知道文件的内容和属性是分开存放的，那么又是如何管理它们的呢?现在我们以创建一个文件为例来讲解。在命令行输入命令：1$ who &gt; userlist 当完成这个命令时。文件系统中增加了一个存放命令who输出内容的新文件userlist，那么这整个过程到底是怎么回事呢？文件主要有属性、内容以及文件名三项。内核将文件内容存放在数据区，文件属性存放在i-节点，文件名存放在目录中。创建成功一个文件主要有以下四个步骤： 存储属性 也就是文件属性的存储，内核先找到一块空的i-节点。例如，内核找到i-节点号921130。内核把文件的信息记录其中。如文件的大小、文件所有者、和创建时间等。 存储数据 即文件内容的存储，由于该文件需要3个数据块。因此内核从自由块的列表中找到3个自由块。如600、200、992，内核缓冲区的第一块数据复制到块600，第二和第三分别复制到922和600. 记录分配情况，数据保存到了三个数据块中。所以必须要记录起来，以后再找到正确的数据。分配情况记录在文件的i-节点中的磁盘序号列表里。这3个编号分别放在最开始的3个位置。 添加文件名到目录，新文件的名字是userlist 内核将文件的入口(47,userlist)添加到目录文件里。文件名和i-节点号之间的对应关系将文件名和文件和文件的内容属性连接起来，找到文件名就找到文件的i-节点号，通过i-节点号就能找到文件的属性和内容。代码具体实现过程参考：http://blog.csdn.net/kai_ding/article/details/9206057 创建一个目录的过程前面说了创建一个文件的大概过程，也了解文件内容、属性以及入口的保存方式，那么创建一个目录时又是怎么回事呢？我现在test目录使用命令mkdir 新增一个子目录child： 从用户的角度看，目录child是目录test的一个子目录，那么在系统中这层关系是怎么实现的呢？实际上test目录包含一个指向子目录child的i-节点的链接，原理跟普通文件一样，因为目录也是文件。 目录其实也是文件，只是它的内容比较特殊。所以它的创建过程和文件创建过程一样，只是第二步写的内容不同。 系统找到空闲的i-节点号887220,写入目录的属性 找到空闲的数据块1002来存储目录的内容，只是目录的内容比较特殊，包含文件名字列表，列表一般包含两个部分：i-节点号和文件名，这个列表其实也就是文件的入口，新建的目录至少包含三个目录”.”和”..”其中”.”指向自己，”..”指向上级目录，我们可以通过比较对应的i-节点号来验证,887270 对应着上级目录中的child对应的i-节点号 记录分配情况。这个和创建文件完全一样 添加目录的入口到父目录，即在父目录中的child入口。 一般都说文件存放在某个目录中，其实目录中存入的只是文件在i-节点表的入口，而文件的内容则存储在数据区。我们一般会说“文件userlist在目录test中”,其实这意味着目录test中有一个指向i-节点921130的链接，这个链接所附加的文件名为userlist,这也可以这样理解：目录包含的是文件的引用，每个引用被称为链接。文件的内容存储在数据块。文件的属性被记录在一个被称为i-节点的结构中。I-节点的编号和文件名关联起来存在目录中。注意：其中“.”表示是当前目录。而“..”是当前目录的父目录。但也有特殊情况：如我们查看根目录/的情况: 发现“.”和“..”都指向i-节点2。实际上当我们用mkfs创建一个文件系统时，mkfs都会将根目录的父目录指向自己。所以根目录下.和..指向同一个i-节点也不奇怪了。代码具体实现参考：http://blog.csdn.net/kai_ding/article/details/9206057 理解链接我们知道文件都有文件名与数据，这在 Linux 上被分成两个部分：用户数据 (user data) 与元数据 (metadata)。用户数据，即文件数据块 (data block)，数据块是记录文件真实内容的地方；而元数据则是文件的附加属性，如文件大小、创建时间、所有者等信息。在 Linux 中，元数据中的 inode 号（inode 是文件元数据的一部分但其并不包含文件名，inode 号即索引节点号）才是文件的唯一标识而非文件名。文件名仅是为了方便人们的记忆和使用，系统或程序通过 inode 号寻找正确的文件数据块。图展示了程序通过文件名获取文件内容的过程。 移动或重命名文件12345678910# stat /home/harris/source/glibc-2.16.0.tar.xz File: `/home/harris/source/glibc-2.16.0.tar.xz&apos; Size: 9990512 Blocks: 19520 IO Block: 4096 regular fileDevice: 807h/2055d Inode: 2485677 Links: 1Access: (0600/-rw-------) Uid: ( 1000/ harris) Gid: ( 1000/ harris)......# mv /home/harris/source/glibc-2.16.0.tar.xz /home/harris/Desktop/glibc.tar.xz# ls -i -F /home/harris/Desktop/glibc.tar.xz2485677 /home/harris/Desktop/glibc.tar.xz 在 Linux 系统中查看 inode 号可使用命令 stat 或 ls -i（若是 AIX 系统，则使用命令 istat）。清单 3.中使用命令 mv 移动并重命名文件 glibc-2.16.0.tar.xz，其结果不影响文件的用户数据及 inode 号，文件移动前后 inode 号均为：2485677。为解决文件的共享使用，Linux 系统引入了两种链接：硬链接 (hard link) 与软链接（又称符号链接，即 soft link 或 symbolic link）。 为 Linux 系统解决了文件的共享使用，还带来了隐藏文件路径、增加权限安全及节省存储等好处。若一个inode号对应多个文件名，则称这些文件为硬链接。换言之，硬链接就是同一个文件使用了多个别名。硬链接可由命令 link 或 ln 创建。如下是对文件 oldfile 创建硬链接。12link oldfile newfileln oldfile newfile 由于硬链接是有着相同 inode 号仅文件名不同的文件，因此硬链接存在以下几点特性： 文件有相同的 inode 及 data block； 只能对已存在的文件进行创建； 不能交叉文件系统进行硬链接的创建； 不能对目录进行创建，只可对文件创建； 删除一个硬链接文件并不影响其他有相同 inode 号的文件。 创建一个链接的步骤大概如下： 通过原文件的文件名找到文件的i-节点号 添加文件名关联到目录，新文件的名字是mylink 内核将文件的入口(921130,mylink)添加到目录文件里。 和创建文件的过程比较发现，链接少了写文件内容的步骤，完全相同的是把文件名关联到目录这一步现在.i- 节点号921130对应了两个文件名。链接数也会变成2个，文件的内容并不会发生任何变化。前面我们已经讲了：目录包含的是文件的引用，每个引用被称为链接。所以链接文件和原始文件本质上是一样的，因为它们都是指向同一个i-节点。由于此原因也就可以理解链接的下列特性：你改变其中任何一个文件的内容，别的链接文件也一样是变化；另外如果你删除某一个文件，系统只会在所指向的i-节点上把链接数减1，只有当链接数减为零时才会真正释放i-节点。硬链接有两个特点： 不能跨文件系统 不能对目录 123456789101112131415161718192021222324252627282930313233# ls -li total 0 // 只能对已存在的文件创建硬连接 # link old.file hard.link link: cannot create link `hard.link&apos; to `old.file&apos;: No such file or directory # echo &quot;This is an original file&quot; &gt; old.file # cat old.file This is an original file # stat old.file File: `old.file&apos; Size: 25 Blocks: 8 IO Block: 4096 regular file Device: 807h/2055d Inode: 660650 Links: 2 Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root) ... // 文件有相同的 inode 号以及 data block # link old.file hard.link | ls -li total 8 660650 -rw-r--r-- 2 root root 25 Sep 1 17:44 hard.link 660650 -rw-r--r-- 2 root root 25 Sep 1 17:44 old.file // 不能交叉文件系统 # ln /dev/input/event5 /root/bfile.txt ln: failed to create hard link `/root/bfile.txt&apos; =&gt; `/dev/input/event5&apos;: Invalid cross-device link // 不能对目录进行创建硬连接 # mkdir -p old.dir/test # ln old.dir/ hardlink.dir ln: `old.dir/&apos;: hard link not allowed for directory # ls -iF 660650 hard.link 657948 old.dir/ 660650 old.file 软链接与硬链接不同，若文件用户数据块中存放的内容是另一文件的路径名的指向，则该文件就是软连接。软链接就是一个普通文件，只是数据块内容有点特殊。软链接有着自己的 inode 号以及用户数据块（见 图 2.）。因此软链接的创建与使用没有类似硬链接的诸多限制：软链接有自己的文件属性及权限等；可对不存在的文件或目录创建软链接；软链接可交叉文件系统；软链接可对文件或目录创建；创建软链接时，链接计数 i_nlink 不会增加；删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。 软链接实际上只是一段文字，里面包含着它所指向的文件的名字，系统看到软链接后自动跳到对应的文件位置处进行处理；相反，硬链接为文件开设一个新的目录项，硬链接与文件原有的名字是平权的，在Linux看来它们是等价的。由于这个原因，硬链接不能连接两个不同文件系统上的文件。 软连接与windows下的快捷方式类似至于硬连接，举个例子说吧，你把dir1/file1硬连接到dir2/file2, 就是在dir2下建立一个dir1/file1的镜像文件file2，它与file1是占用一样大的空间的，并且改动两者中的一个，另一个也会发生同样的改动.软连接和硬连接可以这样理解：硬连接就像一个文件有多个文件名，软连接就是产生一个新文件(这个文件内容,实际上就是记当要链接原文件路径的信息)，这个文件指向另一个文件的位置，硬连接必须在同一文件系统中，而软连接可以跨文件系统硬连接 ：源文件名和链接文件名都指向相同的物理地址，目录不能够有硬连接，文件在磁盘中只有一个复制，可以节省硬盘空间，由于删除文件要在同一个索引节点属于唯一的连接时才能成功，因此可以防止不必要的误删除软连接（符号连接）用ln -s命令创建文件的符号连接，符号连接是linux特殊文件的一种，作为一个文件，它的资料是它所连接的文件的路径名，类似于硬件方式，**可以删除原始文件 而连接文件仍然存在。** 12345678910111213141516171819202122232425262728# ls -li total 0 // 可对不存在的文件创建软链接 # ln -s old.file soft.link # ls -liF total 0 789467 lrwxrwxrwx 1 root root 8 Sep 1 18:00 soft.link -&gt; old.file // 由于被指向的文件不存在，此时的软链接 soft.link 就是死链接 # cat soft.link cat: soft.link: No such file or directory // 创建被指向的文件 old.file，soft.link 恢复成正常的软链接 # echo &quot;This is an original file_A&quot; &gt;&gt; old.file # cat soft.link This is an original file_A // 对不存在的目录创建软链接 # ln -s old.dir soft.link.dir # mkdir -p old.dir/test # tree . -F --inodes . ├ [ 789497] old.dir/ │ └ [ 789498] test/ ├ [ 789495] old.file ├ [ 789495] soft.link -&gt; old.file └ [ 789497] soft.link.dir -&gt; old.dir/ 文件节点inode可以看到inode节点好比是文件的大脑，下面就详细介绍一下inode。 inode是什么理解inode，要从文件储存说起。 扇区（sector）:硬件（磁盘）上的最小的操作单位,是操作系统和块设备（硬件、磁盘）之间传送数据的单位。 block由一个或多个sector组成，文件系统中最小的操作单位；OS的虚拟文件系统从硬件设备上读取一个block，实际为从硬件设备读取一个或多个sector。对于文件管理来说，每个文件对应的多个block可能是不连续的; block最终要映射到sector上，所以block的大小一般是sector的整数倍。不同的文件系统block可使用不同的大小，操作系统会在内存中开辟内存，存放block到所谓的block buffer中。在Ext2中，物理块的大小是可变化的，这取决于在创建文件系统时的选择，之所以不限制大小，也正体现了Ext2的灵活性和可扩充性。通常，Ext2的物理块占一个或几个连续的扇区，显然，物理块的数目是由磁盘容量等硬件因素决定的。具体文件系统所操作的基本单位是逻辑块，只在需要进行I/O操作时才进行逻辑块到物理块的映射，这显然避免了大量的I/O操作，因而文件系统能够变得高效。逻辑块作为一个抽象的概念，它必然要映射到具体的物理块上去，因此，逻辑块的大小必须是物理块大小的整数倍，一般说来，两者是一样大的。 通常，一个文件占用的多个物理块在磁盘上是不连续存储的，因为如果连续存储，则经过频繁的删除、建立、移动文件等操作，最后磁盘上将形成大量的空洞，很快磁盘上将无空间可供使用。因此，必须提供一种方法将一个文件占用的多个逻辑块映射到对应的非连续存储的物理块上去，Ext2等类文件系统是用索引节点解决这个问题的。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。在Unix/Linux上，一个文件由一个inode 表示。inode在系统管理员看来是每一个文件的唯一标识，在系统里面，inode是一个结构，存储了关于这个文件的大部分信息。 inode内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的UserID*文件的GroupID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode*文件数据block的位置可以用stat命令，查看某个文件的inode信息：statexample.txt总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode中存储了一个文件的以下信息: inode结构123456789101112131415161718192021222324252627282930313233343536373839404142434445struct inode &#123; struct hlist_node i_hash; /* 哈希表 */ struct list_head i_list; /* 索引节点链表 */ struct list_head i_dentry; /* 目录项链表 */ unsigned long i_ino; /* 节点号 */ atomic_t i_count; /* 引用记数 */ umode_t i_mode; /* 访问权限控制 */ unsigned int i_nlink; /* 硬链接数 */ uid_t i_uid; /* 使用者id */ gid_t i_gid; /* 使用者id组 */ kdev_t i_rdev; /* 实设备标识符 */ loff_t i_size; /* 以字节为单位的文件大小 */ struct timespec i_atime; /* 最后访问时间 */ struct timespec i_mtime; /* 最后修改(modify)时间 */ struct timespec i_ctime; /* 最后改变(change)时间 */ unsigned int i_blkbits; /* 以位为单位的块大小 */ unsigned long i_blksize; /* 以字节为单位的块大小 */ unsigned long i_version; /* 版本号 */ unsigned long i_blocks; /* 文件的块数 */ unsigned short i_bytes; /* 使用的字节数 */ spinlock_t i_lock; /* 自旋锁 */ struct rw_semaphore i_alloc_sem; /* 索引节点信号量 */ struct inode_operations *i_op; /* 索引节点操作表 */ struct file_operations *i_fop; /* 默认的索引节点操作 */ struct super_block *i_sb; /* 相关的超级块 */ struct file_lock *i_flock; /* 文件锁链表 */ struct address_space *i_mapping; /* 相关的地址映射 */ struct address_space i_data; /* 设备地址映射 */ struct dquot *i_dquot[MAXQUOTAS]; /* 节点的磁盘限额 */ struct list_head i_devices; /* 块设备链表 */ struct pipe_inode_info *i_pipe; /* 管道信息 */ struct block_device *i_bdev; /* 块设备驱动 */ unsigned long i_dnotify_mask; /* 目录通知掩码 */ struct dnotify_struct *i_dnotify; /* 目录通知 */ unsigned long i_state; /* 状态标志 */ unsigned long dirtied_when; /* 首次修改时间 */ unsigned int i_flags; /* 文件系统标志 */ unsigned char i_sock; /* 可能是个套接字吧 */ atomic_t i_writecount; /* 写者记数 */ void *i_security; /* 安全模块 */ __u32 i_generation; /* 索引节点版本号 */ union &#123; void *generic_ip; /* 文件特殊信息 */ &#125; u;&#125;; inode就是一个文件的一部分描述，不是全部，在内核中，inode对应了这样一个实际存在的结构。复制代码纵观整个inode的C语言描述，没有发现关于文件名的东西，也就是说文件名不由inode保存，实际上系统是不关心文件名的，对于系统中任何的操作，大部分情况下你都是通过文件名来做的，但系统最终都要通过找到文件对应的inode来操作文件，由inode结构中 *i_op指向的接口来操作。文件系统如何存取文件的： 根据文件名，通过Directory里的对应关系，找到文件对应的Inodenumber 再根据Inodenumber读取到文件的Inodetable 再根据Inodetable中的Pointer读取到相应的Blocks 这里有一个重要的内容，就是Directory，他不是我们通常说的目录，而是一个列表，记录了一个文件/目录名称对应的Inodenumber。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hash碰撞冲突方法总结]]></title>
    <url>%2F2019%2F05%2F05%2F%E8%A7%A3%E5%86%B3Hash%E7%A2%B0%E6%92%9E%E5%86%B2%E7%AA%81%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Hash碰撞冲突我们知道，对象Hash的前提是实现equals()和hashCode()两个方法，那么HashCode()的作用就是保证对象返回唯一hash值，但当两个对象计算值一样时，这就发生了碰撞冲突。如下将介绍如何处理冲突，当然其前提是一致性hash。 开放地址法开放地执法有一个公式:Hi=(H(key)+di) MOD m i=1,2,…,k(k&lt;=m-1)其中，m为哈希表的表长。di 是产生冲突的时候的增量序列。如果di值可能为1,2,3,…m-1，称线性探测再散列。如果di取1，则每次冲突之后，向后移动1个位置.如果di取值可能为1,-1,2,-2,4,-4,9,-9,16,-16,…kk,-kk(k&lt;=m/2)，称二次探测再散列。如果di取值可能为伪随机数列。称伪随机探测再散列。 再哈希法当发生冲突时，使用第二个、第三个、哈希函数计算地址，直到无冲突时。缺点：计算时间增加。比如上面第一次按照姓首字母进行哈希，如果产生冲突可以按照姓字母首字母第二位进行哈希，再冲突，第三位，直到不冲突为止 链地址法（拉链法）将所有关键字为同义词的记录存储在同一线性链表中。如下： 因此这种方法，可以近似的认为是筒子里面套筒子 建立一个公共溢出区假设哈希函数的值域为[0,m-1],则设向量HashTable[0..m-1]为基本表，另外设立存储空间向量OverTable[0..v]用以存储发生冲突的记录。 拉链法的优缺点：优点： 拉链法处理冲突简单，且无堆积现象，即非同义词决不会发生冲突，因此平均查找长度较短； 由于拉链法中各链表上的结点空间是动态申请的，故它更适合于造表前无法确定表长的情况； 开放定址法为减少冲突，要求装填因子α较小，故当结点规模较大时会浪费很多空间。而拉链法中可取α≥1，且结点较大时，拉链法中增加的指针域可忽略不计，因此节省空间； 在用拉链法构造的散列表中，删除结点的操作易于实现。只要简单地删去链表上相应的结点即可。而对开放地址法构造的散列表，删除结点不能简单地将被删结 点的空间置为空，否则将截断在它之后填人散列表的同义词结点的查找路径。这是因为各种开放地址法中，空地址单元(即开放地址)都是查找失败的条件。因此在 用开放地址法处理冲突的散列表上执行删除操作，只能在被删结点上做删除标记，而不能真正删除结点。 缺点： 指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度。]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多阶hash表]]></title>
    <url>%2F2019%2F05%2F05%2F%E5%A4%9A%E9%98%B6hash%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[原文:https://blog.csdn.net/wm_1991/article/details/52218718 多阶hash表实际上是一个锯齿数组，看起来是这个样子的：■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■■ 每一行是一阶，上面的元素个数多，下面的元素个数依次减少。每一行的元素个数都是素数的。 数组的每个节点用于存储数据的内容，其中，节点的前四个字节用于存储int类型的key或者是hash_code 创建多阶HASH的时候，用户通过参数来指定有多少阶，每一阶最多多少个元素。那么，下面的每一阶究竟应该选择多少个元素呢？从代码注释上看来，是采用了素数集中原理的算法来查找的。例如，假设每阶最多1000个元素，一共10阶，则算法选择十个比1000小的最大素数，从大到小排列，以此作为各阶的元素个数。通过素数集中的算法得到的10个素数分别是：997 991 983 977 971 967 953 947 941 937。可见，虽然是锯齿数组，各层之间的差别并不是很多。 查找过程： 先将key在第一阶内取模，看是否是这个元素，如果这个位置为空，直接返回不存在；如果是这个KEY，则返回这个位置。 如果这个位置有元素，但是又不是这个key，则说明hash冲突，再到第二阶去找。 循环往复。 好处： hash冲突的处理非常简单； 有多个桶，使得空间利用率很高，你并不需要一个很大的桶来减少冲突。 可以考虑动态增长空间，不断加入新的一阶，且对原来的数据没影响。 使用共享内存的多级哈希表的一种实现在一个服务程序运行的时候，它往往要把数据写入共享内存以便在进城需要重新启动的时候可以直接从共享内存中读取数据，另一方面，在服务进程因某种原因挂掉的时候，共享内存中的数据仍然存在，这样就可以减少带来的损失。关于共享内存的内容请google之，在这里，实现了一种在共享内存中存取数据的hash表，它采用了多级存储求模取余的方法，具体内容请看以下代码：http://lmlf001.blog.sohu.com/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237//hash_shm.h#ifndef _STORMLI_HASH_SHM_H_#define _STORMLI_HASH_SHM_H_#include&lt;iostream&gt;#include&lt;cstdlib&gt;#include&lt;cmath&gt;#include&lt;sys/shm.h&gt;using namespace std;template&lt;typename valueType,unsigned long maxLine,int lines&gt;class hash_shm&#123;public: int find(unsigned long _key); //if _key in the table,return 0,and set lastFound the position,otherwise return -1 int remove(unsigned long _key); //if _key not in the table,return-1,else remove the node,set the node key 0 and return 0 //insert node into the table,if the _key exists,return 1,if insert success,return 0;and if fail return -1 int insert(unsigned long _key,const valueType &amp;_value); void clear(); //remove all the datapublic: //some statistic function double getFullRate()const; //the rate of the space used public: //constructor,with the share memory start position and the space size,if the space is not enough,the program will exit hash_shm(void *startShm,unsigned long shmSize=sizeof(hash_node)*maxLine*lines); //constructor,with the share memory key,it will get share memory,if fail,exit hash_shm(key_t shm_key); ~hash_shm()&#123;&#125; //destroy the classprivate: void *mem; //the start position of the share memory // the mem+memSize space used to storage the runtime data:currentSize unsigned long memSize; //the size of the share memory unsigned long modTable[lines]; //modtable,the largest primes unsigned long maxSize; //the size of the table unsigned long *currentSize; //current size of the table ,the pointer of the shm mem+memSize void *lastFound; //write by the find function,record the last find place struct hash_node&#123; //the node of the hash table unsigned long key; //when key==0,the node is empty valueType value; //name-value pair &#125;;private: bool getShm(key_t shm_key); //get share memory,used by the constructor void getMode(); //get the largest primes blow maxLine,use by the constructor void *getPos(unsigned int _row,unsigned long _col); //get the positon with the (row,col)&#125;;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(void *startShm,unsigned long shmSize)&#123; if(startShm!=NULL)&#123; cerr&lt;&lt;&quot;Argument error\n Please check the shm address\n&quot;; exit(-1); &#125; getMode(); maxSize=0; int i; for(i=0;i&lt;lines;i++) //count the maxSize maxSize+=modTable[i]; if(shmSize&lt;sizeof(hash_node)*(maxSize+1))&#123; //check the share memory size cerr&lt;&lt;&quot;Not enough share memory space\n&quot;; exit(-1); &#125; memSize=shmSize; if(*(currentSize=(unsigned long *)((long)mem+memSize))&lt;0) *currentSize=0;;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(key_t shm_key)&#123; //constructor with get share memory getMode(); maxSize=0; for(int i=0;i&lt;lines;i++) maxSize+=modTable[i]; memSize=sizeof(hash_node)*maxSize; if(!getShm(shm_key))&#123; exit(-1); &#125;// memset(mem,0,memSize); if(*(currentSize=(unsigned long *)((long)mem+memSize))&lt;0) *currentSize=0;&#125; template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::find(unsigned long _key)&#123; unsigned long hash; hash_node *pH=NULL; for(int i=0;i&lt;lines;i++) &#123; hash=(_key+maxLine)%modTable[i]; //calculate the col position pH=(hash_node *)getPos(i,hash);// if(pH==NULL)return -2; //almost not need if(pH-&gt;key==_key)&#123; lastFound=pH; return 0; &#125; &#125; return -1;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::remove(unsigned long _key)&#123; if(find(_key)==-1)return -1; //not found hash_node *pH=(hash_node *)lastFound; pH-&gt;key=0; //only set the key 0 (*currentSize)--; return 0;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;int hash_shm&lt;vT,maxLine,lines&gt;::insert(unsigned long _key,const vT &amp;_value)&#123; if(find(_key)==0)return 1; //if the key exists unsigned long hash; hash_node *pH=NULL; for(int i=0;i&lt;lines;i++)&#123; hash=(_key+maxLine)%modTable[i]; pH=(hash_node *)getPos(i,hash); if(pH-&gt;key==0)&#123; //find the insert position,insert the value pH-&gt;key=_key; pH-&gt;value=_value; (*currentSize)++; return 0; &#125; &#125; return -1; //all the appropriate position filled&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::clear()&#123; memset(mem,0,memSize); *currentSize=0;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;bool hash_shm&lt;vT,maxLine,lines&gt;::getShm(key_t shm_key)&#123; int shm_id=shmget(shm_key,memSize,0666); if(shm_id==-1) //check if the shm exists &#123; shm_id=shmget(shm_key,memSize,0666|IPC_CREAT);//create the shm if(shm_id==-1)&#123; cerr&lt;&lt;&quot;Share memory get failed\n&quot;; return false; &#125; &#125; mem=shmat(shm_id,NULL,0); //mount the shm if(int(mem)==-1)&#123; cerr&lt;&lt;&quot;shmat system call failed\n&quot;; return false; &#125; return true;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::getMode()&#123; //采用 6n+1 6n-1 素数集中原理 if(maxLine&lt;5)&#123;exit(-1);&#125; unsigned long t,m,n,p; int i,j,a,b,k; int z=0; for(t=maxLine/6;t&gt;=0,z&lt;lines;t--) &#123; i=1;j=1; k=t%10; m=6*t; /**i,j的值 是是否进行验证的标志也是对应的6t-1和6t+1的素性标志**/ if(((k-4)==0)||((k-9)==0)||((m+1)%3==0))j=0;/*此处是简单验证6*t-1,6*t+1 是不是素数，借以提高素数纯度**/ if(((k-6)==0)||((m-1)%3==0))i=0; /***先通过初步判断去除末尾是5，及被3整除的数***/ for(p=1;p*6&lt;=sqrt(m+1)+2;p++ ) &#123; n=p*6; /**将6*p-1和6*p+1看作伪素数来试除*****/ k=p%10; a=1;b=1; /**同样此处a,b的值也是用来判断除数是否为素数提高除数的素数纯度**/ if(((k-4)==0)||((k-9)==0))a=0; if(((k-6)==0))b=0; if(i)&#123; /*如果i非零就对m-1即所谓6*t-1进行验证，当然还要看除数n+1,n-1,素性纯度*/ if(a)&#123;if((m-1)%(n+1)==0)i=0;&#125; /***一旦被整除就说明不是素数故素性为零即将i 赋值为零***/ if(b)&#123;if((m-1)%(n-1)==0)i=0;&#125; &#125; if(j)&#123; /**如果j非零就对m+1即所谓6*t+1进行验证，当然还要看除数n+1,n-1,素性纯度*/ if(a)&#123;if((m+1)%(n+1)==0)j=0;&#125; /***一旦被整除就说明不是素数故素性为零即将j 赋值为零***/ if(b)&#123;if((m+1)%(n-1)==0)j=0;&#125; &#125; if((i+j)==0)break; /**如果已经知道6*t-1,6*t+1都不是素数了那就结束试除循环***/ &#125; if(j)&#123;modTable[z++]=m+1;if(z&gt;= lines)return;&#125; if(i)&#123;modTable[z++]=m-1;if(z&gt;= lines)return;&#125; &#125;&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;void *hash_shm&lt;vT,maxLine,lines&gt;::getPos(unsigned int _row,unsigned long _col)&#123; unsigned long pos=0UL; for(int i=0;i&lt;_row;i++) //calculate the positon from the start pos+=modTable[i]; pos+=_col; if(pos&gt;=maxSize)return NULL; return (void *)((long)mem+pos*sizeof(hash_node));&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;double hash_shm&lt;vT,maxLine,lines&gt;::getFullRate()const&#123; return double(*currentSize)/maxSize;&#125;#endif 1234567891011121314151617181920212223//test.cpp#include&quot;hash_shm.h&quot;#include&lt;cstdlib&gt;using namespace std;int main()&#123; hash_shm&lt;int,1000,100&gt; ht(key_t(999)); double rate=0.0;// ht.clear(); for(int i=0;i&lt;100;i++)&#123; srand(time(NULL)+i); while(true)&#123; if(ht.insert(rand(),0)==-1)break; &#125; cout&lt;&lt;ht.getFullRate()&lt;&lt;endl; rate+=ht.getFullRate(); ht.clear(); &#125; cout&lt;&lt;&quot;\n\n\n&quot;; cout&lt;&lt;rate/100&lt;&lt;endl;&#125; 这段代码作测试的时候发现了一些问题，用gprof查看函数时间的时候发现，getPos函数占用了大部分的执行时间，始主要的性能瓶颈，后来又新设立了一个数组，用来记录每行开始时的位置，性能提高了很多，改动部分的代码如下：1234567891011121314151617181920212223242526272829303132333435363738template&lt;typename valueType,unsigned long maxLine,int lines&gt;class hash_shm&#123;private: void *mem; //the start position of the share memory // the mem+memSize space used to storage the runtime data:currentSize unsigned long memSize; //the size of the share memory unsigned long modTable[lines]; //modtable,the largest primes unsigned long modTotal[lines]; //modTotal[i] is the summary of the modTable when x&lt;=i //used by getPos to improve the performance ...&#125;;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(void *startShm,unsigned long shmSize)&#123; ... int i; for(i=0;i&lt;lines;i++)&#123; //count the maxSize maxSize+=modTable[i]; if(i!=0)modTotal[i]=modTotal[i-1]+modTable[i-1]; else modTotal[i]=0; //caculate the modTotal &#125; ...&#125;template&lt;typename vT,unsigned long maxLine,int lines&gt;hash_shm&lt;vT,maxLine,lines&gt;::hash_shm(key_t shm_key)&#123; //constructor with get share memory getMode(); maxSize=0; for(int i=0;i&lt;lines;i++)&#123; maxSize+=modTable[i]; if(i!=0)modTotal[i]=modTotal[i-1]+modTable[i-1]; else modTotal[i]=0; &#125; ...&#125; 12345678910template&lt;typename vT,unsigned long maxLine,int lines&gt;void *hash_shm&lt;vT,maxLine,lines&gt;::getPos(unsigned int _row,unsigned long _col)&#123; unsigned long pos=_col+modTotal[_row]; //for(int i=0;i&lt;_row;i++) //calculate the positon from the start // pos+=modTable[i]; if(pos&lt;maxSize) return (void *)((long)mem+pos*sizeof(hash_node)); return NULL; &#125; 新增了一个用于遍历的函数foreach12345678910111213template&lt;typename vT,unsigned long maxLine,int lines&gt;void hash_shm&lt;vT,maxLine,lines&gt;::foreach(void (*fn)(unsigned long _key,vT &amp;_value))&#123; typedef unsigned long u_long; u_long beg=(u_long)mem; u_long end=(u_long)mem+sizeof(hash_node)*(modTable[lines-1]+modTotal[lines-1]); hash_node *p=NULL; for(u_long pos=beg;pos&lt;end;pos+=sizeof(hash_node)) &#123; p=(hash_node *)pos; if(p-&gt;key!=0)fn(p-&gt;key,p-&gt;value); &#125;&#125; 为了利于使用新增一个用于查找的函数find,该函数同find(_key)类似，如果找到_key节点，把它赋给_value以返回1int find(unsigned long _key,vT &amp;_value);]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解inode]]></title>
    <url>%2F2019%2F05%2F05%2F%E7%90%86%E8%A7%A3inode%2F</url>
    <content type="text"><![CDATA[原文：http://www.ruanyifeng.com/blog/2011/12/inode.html inode是什么？理解inode，要从文件储存说起。 文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。 inode的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 用stat命令，查看某个文件的inode信息： 总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。 每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1 df -i 查看每个inode节点的大小，可以用如下命令：1sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。 表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码：1 ls -i example.txt 目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。 目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls命令只列出目录文件中的所有文件名：1 ls /etc ls -i命令列出整个目录文件，即文件名和inode号码：1 ls -i /etc 如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。1 ls -l /etc 理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。 硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。 这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接：1 ln 源文件 目标文件 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。 反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。 软链接除了硬链接以外，还有一种特殊情况。 文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 ln -s命令可以创建软链接。1 ln -s 源文文件或目录 目标文件或目录 inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统调用的实现机制分析]]></title>
    <url>%2F2019%2F05%2F04%2FLinux%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[转载自：http://blog.csdn.net/sailor_8318/archive/2008/09/10/2906968.aspx 系统调用意义linux内核中设置了一组用于实现系统功能的子程序，称为系统调用。系统调用和普通库函数调用非常相似，只是系统调用由操作系统核心提供，运行于核心态，而普通的函数调用由函数库或用户自己提供，运行于用户态。 一般的，进程是不能访问内核的。它不能访问内核所占内存空间也不能调用内核函数。CPU硬件决定了这些（这就是为什么它被称作”保护模式”）。为了和用户空间上运行的进程进行交互，内核提供了一组接口。透过该接口，应用程序可以访问硬件设备和其他操作系统资源。这组接口在应用程序和内核之间扮演了使者的角色，应用程序发送各种请求，而内核负责满足这些请求(或者让应用程序暂时搁置)。实际上提供这组接口主要是为了保证系统稳定可靠，避免应用程序肆意妄行，惹出大麻烦。 系统调用在用户空间进程和硬件设备之间添加了一个中间层。该层主要作用有三个： 它为用户空间提供了一种统一的硬件的抽象接口。比如当需要读些文件的时候，应用程序就可以不去管磁盘类型和介质，甚至不用去管文件所在的文件系统到底是哪种类型。 系统调用保证了系统的稳定和安全。作为硬件设备和应用程序之间的中间人，内核可以基于权限和其他一些规则对需要进行的访问进行裁决。举例来说，这样可以避免应用程序不正确地使用硬件设备，窃取其他进程的资源，或做出其他什么危害系统的事情。 每个进程都运行在虚拟系统中，而在用户空间和系统的其余部分提供这样一层公共接口，也是出于这种考虑。如果应用程序可以随意访问硬件而内核又对此一无所知的话，几乎就没法实现多任务和虚拟内存，当然也不可能实现良好的稳定性和安全性。在Linux中，系统调用是用户空间访问内核的惟一手段；除异常和中断外，它们是内核惟一的合法入口。 API/POSIX/C库的关系一般情况下，应用程序通过应用编程接口(API)而不是直接通过系统调用来编程。这点很重要，因为应用程序使用的这种编程接口实际上并不需要和内核提供的系统调用一一对应。一个API定义了一组应用程序使用的编程接口。它们可以实现成一个系统调用，也可以通过调用多个系统调用来实现，而完全不使用任何系统调用也不存在问题。实际上，API可以在各种不同的操作系统上实现，给应用程序提供完全相同的接口，而它们本身在这些系统上的实现却可能迥异。 在Unix世界中，最流行的应用编程接口是基于POSIX标准的，其目标是提供一套大体上基于Unix的可移植操作系统标准。POSIX是说明API和系统调用之间关系的一个极好例子。在大多数Unix系统上，根据POSIX而定义的API函数和系统调用之间有着直接关系。 Linux的系统调用像大多数Unix系统一样，作为C库的一部分提供如下图所示。C库实现了 Unix系统的主要API，包括标准C库函数和系统调用。所有的C程序都可以使用C库，而由于C语言本身的特点，其他语言也可以很方便地把它们封装起来使用。 从程序员的角度看，系统调用无关紧要，他们只需要跟API打交道就可以了。相反，内核只跟系统调用打交道；库函数及应用程序是怎么使用系统调用不是内核所关心的。 关于Unix的界面设计有一句通用的格言“提供机制而不是策略”。换句话说，Unix的系统调用抽象出了用于完成某种确定目的的函数。至干这些函数怎么用完全不需要内核去关心。区别对待机制(mechanism)和策略(policy)是Unix设计中的一大亮点。大部分的编程问题都可以被切割成两个部分:“需要提供什么功能”(机制)和“怎样实现这些功能”(策略)。 系统调用的实现系统调用处理程序“当我输入 cat /proc/cpuinfo 时，cpuinfo() 函数是如何被调用的？”内核完成引导后，控制流就从相对直观的“接下来调用哪个函数？”改变为取决于系统调用、异常和中断。 用户空间的程序无法直接执行内核代码。它们不能直接调用内核空间中的函数，因为内核驻留在受保护的地址空间上。如果进程可以直接在内核的地址空间上读写的话，系统安全就会失去控制。所以，应用程序应该以某种方式通知系统，告诉内核自己需要执行一个系统调用，希望系统切换到内核态，这样内核就可以代表应用程序来执行该系统调用了。 通知内核的机制是靠软件中断实现的。首先，用户程序为系统调用设置参数。其中一个参数是系统调用编号。参数设置完成后，程序执行“系统调用”指令。x86系统上的软中断由int产生。这个指令会导致一个异常：产生一个事件，这个事件会致使处理器切换到内核态并跳转到一个新的地址，并开始执行那里的异常处理程序。此时的异常处理程序实际上就是系统调用处理程序。它与硬件体系结构紧密相关。 新地址的指令会保存程序的状态，计算出应该调用哪个系统调用，调用内核中实现那个系统调用的函数，恢复用户程序状态，然后将控制权返还给用户程序。系统调用是设备驱动程序中定义的函数最终被调用的一种方式。 系统调用号在Linux中，每个系统调用被赋予一个系统调用号。这样，通过这个独一无二的号就可以关联系统调用。当用户空间的进程执行一个系统调用的时候，这个系统调用号就被用来指明到底是要执行哪个系统调用。进程不会提及系统调用的名称。 系统调用号相当关键，一旦分配就不能再有任何变更，否则编译好的应用程序就会崩溃。Linux有一个“未实现”系统调用sys_ni_syscall()，它除了返回一ENOSYS外不做任何其他工作，这个错误号就是专门针对无效的系统调用而设的。 因为所有的系统调用陷入内核的方式都一样，所以仅仅是陷入内核空间是不够的。因此必须把系统调用号一并传给内核。在x86上，系统调用号是通过eax寄存器传递给内核的。在陷人内核之前，用户空间就把相应系统调用所对应的号放入eax中了。这样系统调用处理程序一旦运行，就可以从eax中得到数据。其他体系结构上的实现也都类似。 内核记录了系统调用表中的所有已注册过的系统调用的列表，存储在sys_call_table中。它与体系结构有关，一般在entry.s中定义。这个表中为每一个有效的系统调用指定了惟一的系统调用号。sys_call_table是一张由指向实现各种系统调用的内核函数的函数指针组成的表：12345678910111213141516ENTRY(sys_call_table).long SYMBOL_NAME(sys_ni_syscall) /* 0 - old &quot;setup()&quot; system call*/.long SYMBOL_NAME(sys_exit).long SYMBOL_NAME(sys_fork).long SYMBOL_NAME(sys_read).long SYMBOL_NAME(sys_write).long SYMBOL_NAME(sys_open) /* 5 */.long SYMBOL_NAME(sys_close).long SYMBOL_NAME(sys_waitpid).long SYMBOL_NAME(sys_capget).long SYMBOL_NAME(sys_capset) /* 185 */.long SYMBOL_NAME(sys_sigaltstack).long SYMBOL_NAME(sys_sendfile).long SYMBOL_NAME(sys_ni_syscall) /* streams1 */.long SYMBOL_NAME(sys_ni_syscall) /* streams2 */.long SYMBOL_NAME(sys_vfork) /* 190 */ system_call()函数通过将给定的系统调用号与NR_syscalls做比较来检查其有效性。如果它大于或者等于NR syscalls,该函数就返回一ENOSYS。否则，就执行相应的系统调用。1call *sys_ call-table(，%eax, 4) 由于系统调用表中的表项是以32位(4字节)类型存放的，所以内核需要将给定的系统调用号乘以4，然后用所得的结果在该表中查询其位置 参数传递除了系统调用号以外，大部分系统调用都还需要一些外部的参数输人。所以，在发生异常的时候，应该把这些参数从用户空间传给内核。最简单的办法就是像传递系统调用号一样把这些参数也存放在寄存器里。在x86系统上，ebx, ecx, edx, esi和edi按照顺序存放前五个参数。需要六个或六个以上参数的情况不多见，此时，应该用一个单独的寄存器存放指向所有这些参数在用户空间地址的指针。 给用户空间的返回值也通过寄存器传递。在x86系统上，它存放在eax寄存器中。接下来许多关于系统调用处理程序的描述都是针对x86版本的。但不用担心，所有体系结构的实现都很类似。 参数验证系统调用必须仔细检查它们所有的参数是否合法有效。举例来说，与文件I/O相关的系统调用必须检查文件描述符是否有效。与进程相关的函数必须检查提供的PID是否有效。必须检查每个参数，保证它们不但合法有效，而且正确。 最重要的一种检查就是检查用户提供的指针是否有效。试想，如果一个进程可以给内核传递指针而又无须被检查，那么它就可以给出一个它根本就没有访问权限的指针，哄骗内核去为它拷贝本不允许它访问的数据，如原本属于其他进程的数据。在接收一个用户空间的指针之前，内核必须保证： 指针指向的内存区域属于用户空间。进程决不能哄骗内核去读内核空间的数据。 指针指向的内存区域在进程的地址空间里。进程决不能哄骗内核去读其他进程的数据。 如果是读，该内存应被标记为可读。如果是写，该内存应被标记为可写。进程决不能绕过内存访问限制。 内核提供了两个方法来完成必须的检查和内核空间与用户空间之间数据的来回拷贝。注意，内核无论何时都不能轻率地接受来自用户空间的指针!这两个方法中必须有一个被调用。为了向用户空间写入数据，内核提供了copy_to_user()，它需要三个参数。第一个参数是进程空间中的目的内存地址。第二个是内核空间内的源地址。最后一个参数是需要拷贝的数据长度(字节数)。 为了从用户空间读取数据，内核提供了copy_from_ user()，它和copy-to-User()相似。该函数把第二个参数指定的位置上的数据拷贝到第一个参数指定的位置上，拷贝的数据长度由第三个参数决定。 如果执行失败，这两个函数返回的都是没能完成拷贝的数据的字节数。如果成功，返回0。当出现上述错误时，系统调用返回标准-EFAULT。 注意copy_to_user()和copy_from_user()都有可能引起阻塞。当包含用户数据的页被换出到硬盘上而不是在物理内存上的时候，这种情况就会发生。此时，进程就会休眠，直到缺页处理程序将该页从硬盘重新换回物理内存。 系统调用的返回值系统调用(在Linux中常称作syscalls)通常通过函数进行调用。它们通常都需要定义一个或几个参数(输入)而且可能产生一些副作用，例如写某个文件或向给定的指针拷贝数据等等。为防止和正常的返回值混淆，系统调用并不直接返回错误码，而是将错误码放入一个名为errno的全局变量中。通常用一个负的返回值来表明错误。返回一个0值通常表明成功。如果一个系统调用失败，你可以读出errno的值来确定问题所在。通过调用perror()库函数，可以把该变量翻译成用户可以理解的错误字符串。 errno不同数值所代表的错误消息定义在errno.h中，你也可以通过命令”man 3 errno”来察看它们。需要注意的是，errno的值只在函数发生错误时设置，如果函数不发生错误，errno的值就无定义，并不会被置为0。另外，在处理errno前最好先把它的值存入另一个变量，因为在错误处理过程中，即使像printf()这样的函数出错时也会改变errno的值。 当然，系统调用最终具有一种明确的操作。举例来说，如getpid()系统调用，根据定义它会返回当前进程的PID。内核中它的实现非常简单:1234asmlinkage long sys_ getpid(void)&#123; return current-&gt; tgid;&#125; 上述的系统调用尽管非常简单，但我们还是可以从中发现两个特别之处。首先，注意函数声明中的asmlinkage限定词，这是一个小戏法，用于通知编译器仅从栈中提取该函数的参数。所有的系统调用都需要这个限定词。其次，注意系统调用get_pid()在内核中被定义成sys_ getpid。这是Linux中所有系统调用都应该遵守的命名规则 添加新系统调用给Linux添加一个新的系统调用是件相对容易的工作。怎样设计和实现一个系统调用是难题所在，而把它加到内核里却无须太多周折。让我们关注一下实现一个新的Linux系统调用所需的步骤。 实现一个新的系统调用的第一步是决定它的用途。它要做些什么？每个系统调用都应该有一个明确的用途。在Linux中不提倡采用多用途的系统调用(一个系统调用通过传递不同的参数值来选择完成不同的工作)。ioctl()就应该被视为一个反例。 新系统调用的参数、返回值和错误码又该是什么呢？系统调用的接口应该力求简洁，参数尽可能少。设计接口的时候要尽量为将来多做考虑。你是不是对函数做了不必要的限制?系统调用设计得越通用越好。不要假设这个系统调用现在怎么用将来也一定就是这么用。系统调用的目的可能不变，但它的用法却可能改变。这个系统调用可移植吗?别对机器的字节长度和字节序做假设。当你写一个系统调用的时候，要时刻注意可移植性和健壮性，不但要考虑当前，还要为将来做打算。 当编写完一个系统调用后，把它注册成一个正式的系统调用是件琐碎的工作： 在系统调用表的最后加入一个表项。每种支持该系统调用的硬件体系都必须做这样的工作。从0开始算起，系统调用在该表中的位置就是它的系统调用号。 对于所支持的各种体系结构，系统调用号都必须定义于&lt;asm/unistd.h&gt;中。 系统调用必须被编译进内核映象(不能被编译成模块)。这只要把它放进kernel/下的一个相关文件中就可以。 让我们通过一个虚构的系统调用f00()来仔细观察一下这些步骤。首先，我们要把sys_foo加入到系统调用表中去。对于大多数体系结构来说，该表位干entry.s文件中，形式如下:123456ENTRY(sys_ call_ table) .long sys_ restart_ syscall/*0*/ .long sys_ exit .long sys_ fork .long sys_ read .long sys_write 我们把新的系统调用加到这个表的末尾:1.long sys_foo 虽然没有明确地指定编号，但我们加入的这个系统调用被按照次序分配给了283这个系统调用号。对于每种需要支持的体系结构，我们都必须将自己的系统调用加人到其系统调用表中去。每种体系结构不需要对应相同的系统调用号。 接下来，我们把系统调用号加入到&lt;asm/unistd.h&gt;中，它的格式如下:1234567/*本文件包含系统调用号*/#define_ NR_ restart_ syscall#define NR exit#define NR fork#define NR read#define NR write#define NR- mq getsetattr 282 然后，我们在该列表中加入下面这行:1#define_ NR_ foo 283 最后，我们来实现f00()系统调用。无论何种配置，该系统调用都必须编译到核心的内核映象中去，所以我们把它放进kernel/sys.c文件中。你也可以将其放到与其功能联系最紧密的代码中去1234asmlinkage long sys-foo(void)&#123; return THREAD SIZE) 就是这样!严格说来，现在就可以在用户空间调用f00()系统调用了。 建立一个新的系统调用非常容易，但却绝不提倡这么做。通常模块可以更好的代替新建一个系统调用。 访问系统调用系统调用上下文内核在执行系统调用的时候处于进程上下文。current指针指向当前任务，即引发系统调用的那个进程。 在进程上下文中，内核可以休眠并且可以被抢占。这两点都很重要。首先，能够休眠说明系统调用可以使用内核提供的绝大部分功能。休眠的能力会给内核编程带来极大便利。在进程上下文中能够被抢占，其实表明，像用户空间内的进程一样，当前的进程同样可以被其他进程抢占。因为新的进程可以使用相同的系统调用，所以必须小心，保证该系统调用是可重人的。当然，这也是在对称多处理中必须同样关心的问题。 当系统调用返回的时候，控制权仍然在system_call()中，它最终会负责切换到用户空间并让用户进程继续执行下去。 系统调用访问示例操作系统使用系统调用表将系统调用编号翻译为特定的系统调用。系统调用表包含有实现每个系统调用的函数的地址。例如，read() 系统调用函数名为 sys_read。read() 系统调用编号是 3，所以 sys_read()位于系统调用表的第四个条目中（因为系统调用起始编号为0）。从地址 sys_call_table + (3 * word_size) 读取数据，得到 sys_read()的地址。 找到正确的系统调用地址后，它将控制权转交给那个系统调用。我们来看定义 sys_read() 的位置，即fs/read_write.c 文件。这个函数会找到关联到 fd 编号（传递给 read() 函数的）的文件结构体。那个结构体包含指向用来读取特定类型文件数据的函数的指针。进行一些检查后，它调用与文件相关的 read() 函数，来真正从文件中读取数据并返回。与文件相关的函数是在其他地方定义的 —— 比如套接字代码、文件系统代码，或者设备驱动程序代码。这是特定内核子系统最终与内核其他部分协作的一个方面。 读取函数结束后，从sys_read()返回，它将控制权切换给ret_from_sys。它会去检查那些在切换回用户空间之前需要完成的任务。如果没有需要做的事情，那么就恢复用户进程的状态，并将控制权交还给用户程序。 从用户空间直接访问系统调用通常，系统调用靠C库支持。用户程序通过包含标准头文件并和C库链接，就可以使用系统调用(或者调用库函数，再由库函数实际调用)。但如果你仅仅写出系统调用，glibc库恐怕并不提供支持。值得庆幸的是，Linux本身提供了一组宏，用于直接对系统调用进行访问。它会设置好寄存器并调用陷人指令。这些宏是_syscalln()，其中n的范围从0到6。代表需要传递给系统调用的参数个数，这是由于该宏必须了解到底有多少参数按照什么次序压入寄存器。举个例子，open()系统调用的定义是:1long open(const char *filename, int flags, int mode) 而不靠库支持，直接调用此系统调用的宏的形式为:12#define NR_ open 5syscall3(long, open, const char*，filename, int, flags, int, mode) 这样，应用程序就可以直接使用open() 对于每个宏来说，都有2+ n个参数。第一个参数对应着系统调用的返回值类型。第二个参数是系统调用的名称。再以后是按照系统调用参数的顺序排列的每个参数的类型和名称。_NR_ open在&lt;asm/unistd.h&gt;中定义，是系统调用号。该宏会被扩展成为内嵌汇编的C函数。由汇编语言执行前一节所讨论的步骤，将系统调用号和参数压入寄存器并触发软中断来陷入内核。调用open()系统调用直接把上面的宏放置在应用程序中就可以了。 让我们写一个宏来使用前面编写的foo()系统调用，然后再写出测试代码炫耀一下我们所做的努力。123456789#define NR foo 283_sysca110(long, foo)int main()&#123; long stack size; stack_ size=foo(); printf(&quot;The kernel stack size is 81d/n&quot;，stack_ size); return;&#125; 系统调用表以下是Linux系统调用的一个列表，包含了大部分常用系统调用和由系统调用派生出的的函数。其中有一些函数的作用完全相同，只是参数不同。可能很多熟悉C++朋友马上就能联想起函数重载，但是别忘了Linux核心是用C语言写的，所以只能取成不同的函数名。 进程控制： 函数名 功能 fork 创建一个新进程 clone 按指定条件创建子进程 execve 运行可执行文件 exit 中止进程 _exit 立即中止当前进程 getdtablesize 进程所能打开的最大文件数 getpgid 获取指定进程组标识号 setpgid 设置指定进程组标志号 getpgrp 获取当前进程组标识号 setpgrp 设置当前进程组标志号 getpid 获取进程标识号 getppid 获取父进程标识号 getpriority 获取调度优先级 setpriority 设置调度优先级 modify_ldt 读写进程的本地描述表 nanosleep 使进程睡眠指定的时间 nice 改变分时进程的优先级 pause 挂起进程，等待信号 personality 设置进程运行域 prctl 对进程进行特定操作 ptrace 进程跟踪 sched_get_priority_max 取得静态优先级的上限 sched_get_priority_min 取得静态优先级的下限 sched_getparam 取得进程的调度参数 sched_getscheduler 取得指定进程的调度策略 sched_rr_get_interval 取得按RR算法调度的实时进程的时间片长度 sched_setparam 设置进程的调度参数 sched_setscheduler 设置指定进程的调度策略和参数 sched_yield 进程主动让出处理器,并将自己等候调度队列队尾 vfork 创建一个子进程，以供执行新程序，常与execve等同时使用 wait 等待子进程终止 wait3 参见wait waitpid 等待指定子进程终止 wait4 参见waitpid capget 获取进程权限 capset 设置进程权限 getsid 获取会晤标识号 setsid 设置会晤标识号 文件系统控制文件读写操作 函数名 功能 fcntl 文件控制 open 打开文件 creat 创建新文件 lose 关闭文件描述字 read 读文件 write 写文件 readv 从文件读入数据到缓冲数组中 writev 将缓冲数组里的数据写入文件 pread 对文件随机读 pwrite 对文件随机写 lseek 移动文件指针 _llseek 在64位地址空间里移动文件指针 dup 复制已打开的文件描述字 dup2 按指定条件复制文件描述字 flock 文件加/解锁 poll I/O多路转换 truncate 截断文件 ftruncate 参见truncate umask 设置文件权限掩码 fsync 把文件在内存中的部分写回磁盘 文件系统操作 函数名 功能 access 确定文件的可存取性 chdir 改变当前工作目录 fchdir 参见chdir chmod 改变文件方式 fchmod 参见chmod chown 改变文件的属主或用户组 fchown 参见chown lchown 参见chown chroot 改变根目录 stat 取文件状态信息 lstat 参见stat fstat 参见stat statfs 取文件系统信息 fstatfs 参见statfs readdir 读取目录项 getdents 读取目录项 mkdir 创建目录 mknod 创建索引节点 rmdir 删除目录 rename 文件改名 link 创建链接 symlink 创建符号链接 unlink 删除链接 readlink 读符号链接的值 mount 安装文件系统 umount 卸下文件系统 ustat 取文件系统信息 utime 改变文件的访问修改时间 utimes 参见utime quotactl 控制磁盘配额 系统控制 函数名 功能 ioctl I/O总控制函数 _sysctl 读/写系统参数 acct 启用或禁止进程记账 getrlimit 获取系统资源上限 setrlimit 设置系统资源上限 getrusage 获取系统资源使用情况 uselib 选择要使用的二进制函数库 ioperm 设置端口I/O权限 iopl 改变进程I/O权限级别 outb 低级端口操作 reboot 重新启动 swapon 打开交换文件和设备 swapoff 关闭交换文件和设备 bdflush 控制bdflush守护进程 sysfs 取核心支持的文件系统类型 sysinfo 取得系统信息 adjtimex 调整系统时钟 alarm 设置进程的闹钟 getitimer 获取计时器值 setitimer 设置计时器值 gettimeofday 取时间和时区 settimeofday 设置时间和时区 stime 设置系统日期和时间 time 取得系统时间 times 取进程运行时间 uname 获取当前UNIX系统的名称、版本和主机等信息 vhangup 挂起当前终端 nfsservctl 对NFS守护进程进行控制 vm86 进入模拟8086模式 create_module 创建可装载的模块项 delete_module 删除可装载的模块项 init_module 初始化模块 query_module 查询模块信息 *get_kernel_syms 取得核心符号,已被query_module代替 内存管理 函数名 功能 brk 改变数据段空间的分配 sbrk 参见brk mlock 内存页面加锁 munlock 内存页面解锁 mlockall 调用进程所有内存页面加锁 munlockall 调用进程所有内存页面解锁 mmap 映射虚拟内存页 munmap 去除内存页映射 mremap 重新映射虚拟内存地址 msync 将映射内存中的数据写回磁盘 mprotect 设置内存映像保护 getpagesize 获取页面大小 sync 将内存缓冲区数据写回硬盘 cacheflush 将指定缓冲区中的内容写回磁盘 网络管理 函数名 功能 getdomainname 取域名 setdomainname 设置域名 gethostid 获取主机标识号 sethostid 设置主机标识号 gethostname 获取本主机名称 sethostname 设置主机名称 socket控制 函数名 功能 socketcall socket系统调用 socket 建立socket bind 绑定socket到端口 connect 连接远程主机 accept 响应socket连接请求 send 通过socket发送信息 sendto 发送UDP信息 sendmsg 参见send recv 通过socket接收信息 recvfrom 接收UDP信息 recvmsg 参见recv listen 监听socket端口 select 对多路同步I/O进行轮询 shutdown 关闭socket上的连接 getsockname 取得本地socket名字 getpeername 获取通信对方的socket名字 getsockopt 取端口设置 setsockopt 设置端口参数 sendfile 在文件或端口间传输数据 socketpair 创建一对已联接的无名socket 用户管理 函数名 功能 getuid 获取用户标识号 setuid 设置用户标志号 getgid 获取组标识号 setgid 设置组标志号 getegid 获取有效组标识号 setegid 设置有效组标识号 geteuid 获取有效用户标识号 seteuid 设置有效用户标识号 setregid 分别设置真实和有效的的组标识号 setreuid 分别设置真实和有效的用户标识号 getresgid 分别获取真实的,有效的和保存过的组标识号 setresgid 分别设置真实的,有效的和保存过的组标识号 getresuid 分别获取真实的,有效的和保存过的用户标识号 setresuid 分别设置真实的,有效的和保存过的用户标识号 setfsgid 设置文件系统检查时使用的组标识号 setfsuid 设置文件系统检查时使用的用户标识号 getgroups 获取后补组标志清单 setgroups 设置后补组标志清单 进程间通信 函数名 功能 ipc 进程间通信总控制调用 信号 函数名 功能 sigaction 设置对指定信号的处理方法 sigprocmask 根据参数对信号集中的信号执行阻塞/解除阻塞等操作 sigpending 为指定的被阻塞信号设置队列 sigsuspend 挂起进程等待特定信号 signal 参见signal kill 向进程或进程组发信号 *sigblock 向被阻塞信号掩码中添加信号,已被sigprocmask代替 *siggetmask 取得现有阻塞信号掩码,已被sigprocmask代替 *sigsetmask 用给定信号掩码替换现有阻塞信号掩码,已被sigprocmask代替 *sigmask 将给定的信号转化为掩码,已被sigprocmask代替 *sigpause 作用同sigsuspend,已被sigsuspend代替 sigvec 为兼容BSD而设的信号处理函数,作用类似sigaction ssetmask ANSI C的信号处理函数,作用类似sigaction 消息 函数名 功能 msgctl 消息控制操作 msgget 获取消息队列 msgsnd 发消息 msgrcv 取消息 管道 函数名 功能 pipe 建管道 信号量 函数名 功能 semctl 信号量控制 semget 获取一组信号量 semop 信号量操作 共享内存 函数名 功能 shmctl 控制共享内存 shmget 获取共享内存 shmat 连接共享内存 shmdt 拆卸共享内存]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[信号中断与慢系统调用]]></title>
    <url>%2F2019%2F05%2F04%2F%E4%BF%A1%E5%8F%B7%E4%B8%AD%E6%96%AD%E4%B8%8E%E6%85%A2%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[术语慢系统调用（Slow system call）该术语适用于那些可能永远阻塞的系统调用。永远阻塞的系统调用是指调用永远无法返回，多数网络支持函数都属于这一类。如：若没有客户连接到服务器上，那么服务器的accept调用就会一直阻塞。 慢系统调用可以被永久阻塞，包括以下几个类别： （1）读写‘慢’设备（包括pipe，终端设备，网络连接等）。读时，数据不存在，需要等待；写时，缓冲区满或其他原因，需要等待。读写磁盘文件一般不会阻塞。 （2）当打开某些特殊文件时，需要等待某些条件，才能打开。例如：打开中断设备时，需要等到连接设备的modem响应才能完成。 （3）pause和wait函数。pause函数使调用进程睡眠，直到捕获到一个信号。wait等待子进程终止。 （4）某些ioctl操作。 （5）某些IPC操作。 EINTR介绍EINTR错误产生的原因早期的Unix系统，如果进程在一个慢系统调用(slow system call)中阻塞时，当捕获到某个信号且相应信号处理函数返回时，这个系统调用被中断，调用返回错误，设置errno为EINTR（相应的错误描述为“Interrupted system call”）。 怎么看哪些系统条用会产生EINTR错误呢？用man啊！ 如下表所示的系统调用就会产生EINTR错误，当然不同的函数意义也不同。 系统调用函数 errno为EINTR表征的意义 write 由于信号中断，没写成功任何数据。 open 由于信号中断，没读到任何数据。 recv 由于信号中断返回，没有任何数据可用。 sem_wait 函数调用被信号处理函数中断。 如何处理被中断的系统调用既然系统调用会被中断，那么别忘了要处理被中断的系统调用。有三种处理方式： 人为重启被中断的系统调用 安装信号时设置 SA_RESTART属性（该方法对有的系统调用无效） 忽略信号（让系统不产生信号中断） 人为重启被中断的系统调用人为当碰到EINTR错误的时候，有一些可以重启的系统调用要进行重启，而对于有一些系统调用是不能够重启的。例如：accept、read、write、select、和open之类的函数来说，是可以进行重启的。不过对于套接字编程中的connect函数我们是不能重启的，若connect函数返回一个EINTR错误的时候，我们不能再次调用它，否则将立即返回一个错误。针对connect不能重启的处理方法是，必须调用select来等待连接完成。 这里的“重启”怎么理解？ 一些IO系统调用执行时，如 read 等待输入期间，如果收到一个信号，系统将中断read， 转而执行信号处理函数. 当信号处理返回后， 系统遇到了一个问题： 是重新开始这个系统调用， 还是让系统调用失败？早期UNIX系统的做法是， 中断系统调用，并让系统调用失败， 比如read返回 -1， 同时设置 errno 为EINTR中断了的系统调用是没有完成的调用，它的失败是临时性的，如果再次调用则可能成功，这并不是真正的失败，所以要对这种情况进行处理， 典型的方式为：123456again: if ((n = read(fd， buf， BUFFSIZE)) &lt; 0) &#123; if (errno == EINTR) goto again; /* just an interrupted system call */ /* handle other errors */ &#125; 可以去github上看看别人怎么处理EINTR错误的。在github上搜索“==EINTR”关键字就有一大堆了。摘取几个看看：12while ((r = read (fd， buf， len)) &lt; 0 &amp;&amp; errno == EINTR) /*donothing*/ ; 1234567891011121314ssize_t Read(int fd， void *ptr， size_t nbytes)&#123; ssize_t n; again: if((n = read(fd， ptr， nbytes)) == -1)&#123; if(errno == EINTR) goto again; else return -1; &#125; return n;&#125; 安装信号时设置 SA_RESTART属性 我们还可以从信号的角度来解决这个问题， 安装信号的时候， 设置 SA_RESTART属性，那么当信号处理函数返回后， 不会让系统调用返回失败，而是让被该信号中断的系统调用将自动恢复。123456789struct sigaction action; action.sa_handler = handler_func;sigemptyset(&amp;action.sa_mask);action.sa_flags = 0;/* 设置SA_RESTART属性 */action.sa_flags |= SA_RESTART; sigaction(SIGALRM, &amp;action, NULL); 但注意，并不是所有的系统调用都可以自动恢复。如msgsnd喝msgrcv就是典型的例子，msgsnd/msgrcv以block方式发送/接收消息时，会因为进程收到了信号而中断。此时msgsnd/msgrcv将返回-1，errno被设置为EINTR。且即使在插入信号时设置了SA_RESTART，也无效。在man msgrcv中就有提到这点： msgsnd and msgrcv are never automatically restarted after being interrupted by a signal handler, regardless of the setting of the SA_RESTART flag when establishing a signal handler. 忽略信号当然最简单的方法是忽略信号，在安装信号时，明确告诉系统不会产生该信号的中断。123456struct sigaction action; action.sa_handler = SIG_IGN;sigemptyset(&amp;action.sa_mask); sigaction(SIGALRM, &amp;action, NULL); 测试代码为了方便大家测试，这里附上两段测试代码。 测试代码一闹钟信号SIGALRM中断read系统调用。安装SIGALRM信号时如果不设置SA_RESTART属性，信号会中断read系统过调用。如果设置了SA_RESTART属性，read就能够自己恢复系统调用，不会产生EINTR错误。123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;signal.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;error.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt; void sig_handler(int signum)&#123; printf(&quot;in handler\n&quot;); sleep(1); printf(&quot;handler return\n&quot;);&#125; int main(int argc, char **argv)&#123; char buf[100]; int ret; struct sigaction action, old_action; action.sa_handler = sig_handler; sigemptyset(&amp;action.sa_mask); action.sa_flags = 0; /* 版本1:不设置SA_RESTART属性 * 版本2:设置SA_RESTART属性 */ //action.sa_flags |= SA_RESTART; sigaction(SIGALRM, NULL, &amp;old_action); if (old_action.sa_handler != SIG_IGN) &#123; sigaction(SIGALRM, &amp;action, NULL); &#125; alarm(3); bzero(buf, 100); ret = read(0, buf, 100); if (ret == -1) &#123; perror(&quot;read&quot;); &#125; printf(&quot;read %d bytes:\n&quot;, ret); printf(&quot;%s\n&quot;, buf); return 0;&#125; 测试代码二闹钟信号SIGALRM中断msgrcv系统调用。即使在插入信号时设置了SA_RESTART，也无效。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/ipc.h&gt;#include &lt;sys/msg.h&gt; void ding(int sig)&#123; printf(&quot;Ding!\n&quot;);&#125; struct msgst&#123; long int msg_type; char buf[1];&#125;; int main()&#123; int nMsgID = -1; // 捕捉闹钟信息号 struct sigaction action; action.sa_handler = ding; sigemptyset(&amp;action.sa_mask); action.sa_flags = 0; // 版本1:不设置SA_RESTART属性 // 版本2:设置SA_RESTART属性 action.sa_flags |= SA_RESTART; sigaction(SIGALRM, &amp;action, NULL); alarm(3); printf(&quot;waiting for alarm to go off\n&quot;); // 新建消息队列 nMsgID = msgget(IPC_PRIVATE, 0666 | IPC_CREAT); if( nMsgID &lt; 0 ) &#123; perror(&quot;msgget fail&quot; ); return; &#125; printf(&quot;msgget success.\n&quot;); // 阻塞 等待消息队列 // // msgrcv会因为进程收到了信号而中断。返回-1，errno被设置为EINTR。 // 即使在插入信号时设置了SA_RESTART，也无效。man msgrcv就有说明。 // struct msgst msg_st; if( -1 == msgrcv( nMsgID, (void*)&amp;msg_st, 1, 0, 0 ) ) &#123; perror(&quot;msgrcv fail&quot;); &#125; printf(&quot;done\n&quot;); exit(0);&#125; 总结慢系统调用(slow system call)会被信号中断，系统调用函数返回失败，并且errno被置为EINTR（错误描述为“Interrupted system call”）。 处理方法有以下三种： 人为重启被中断的系统调用； 安装信号时设置 SA_RESTART属性； 忽略信号（让系统不产生信号中断）。 有时我们需要捕获信号，但又考虑到第2种方法的局限性（设置 SA_RESTART属性对有的系统无效，如msgrcv），所以在编写代码时，一定要“人为重启被中断的系统调用”。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析CPU中断技术]]></title>
    <url>%2F2019%2F05%2F04%2F%E6%B5%85%E6%9E%90CPU%E4%B8%AD%E6%96%AD%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/funeral/archive/2013/03/06/2945485.html 什么是CPU中断？使用计算机的过程中，经常会遇到这么一种情景： 你正在看电影 你的朋友发来一条QQ信息 你一边回复朋友的信息，一边继续看电影 这个过程中，一切是那么的顺其自然。但理论上来说，播放电影的时候，CPU正在一丝不苟的执行着一条又一条的指令，它是如何在维持电影播放的情况下，及时接收并响应你的键盘输入信息呢？这就是CPU中断技术在起作用。 CPU中断技术的定义如下： 计算机处于执行期间系统内发生了非寻常或非预期的急需处理事件CPU暂时中断当前正在执行的程序而转去执行相应的事件处理程序处理完毕后返回原来被中断处继续执行。 在这里，“非寻常或非预期的事件”指的就是你回复朋友的QQ时，用键盘键入信息。为了及时响应你键入的信息，CPU将正在执行的任务“播放电影”暂时中断，处理完你键入的信息后，继续执行“播放电影”的任务。由于这个“中断当前任务-&gt;响应键盘输入-&gt;继续当前任务”的执行周期非常短（一般都是微秒级），所以一般人感觉不出来。 CPU中断的作用早期的CPU处理外设的事件(比如接收键盘输入)，往往采用“轮询”的方式。即CPU像个查岗的一样轮番对外设顺序访问，比如它先看看键盘有没被按下，有的话就处理，没的话继续往下看鼠标有没有移动，再看看打印机……这种方式使CPU的执行效率很低，且CPU与外设不能同时工作（因为要等待CPU来“巡查”）。 中断模式时就是说CPU不主动访问这些设备，只管处理自己的任务。如果有设备要与CPU联系，或要CPU处理一些事情，它会给CPU发一个中断请求信号。这时CPU就会放下正在进行的工作而去处理这个外设的请求。处理完中断后，CPU返回去继续执行中断以前的工作。 中断模式的作用和优点在于： 可以使CPU和外设同时工作，使系统可以及时地响应外部事件。 可允许多个外设同时工作，大大提高了CPU的利用率，也提高了数据输入、输出的速度。 可以使CPU及时处理各种软硬件故障（比如计算机在运行过程中，出现了难以预料的情况或一些故障，如电源掉电、存储出错、运算溢出等等。计算机可以利用中断系统自行处理，而不必停机或报告工作人员。） CPU中断的类型在计算机系统中，根据中断源的不同，通常将中断分为两大类： 硬件中断 软件中断 硬件中断硬件中断又称外部中断，主要分为两种：可屏蔽中断、非屏蔽中断。可屏蔽中断： 常由计算机的外设或一些接口功能产生，如键盘、打印机、串行口等 这种类型的中断可以在CPU要处理其它紧急操作时，被软件屏蔽或忽略 非屏蔽中断： 由意外事件导致，如电源断电、内存校验错误等 对于这种类型的中断事件，无法通过软件进行屏蔽，CPU必须无条件响应 在x86架构的处理器中，CPU的中断控制器由两根引脚(INTR和NMI)接收外部中断请求信号。其中： INTR接收可屏蔽中断请求 NMI接收非屏蔽中断请求 典型事例： 典型的可屏蔽中断的例子是打印机中断，CPU对打印机中断请求的响应可以快一些，也可以慢一些，因为让打印机稍等待一会也是完全合理的。 典型的非屏蔽中断的例子是电源断电，一旦出现此中断请求，必须立即无条件地响应，否则进行其他任何工作都是没有意义的。 软件中断软件中断又称内部中断，是指在程序中调用INTR中断指令引起的中断。比如winAPI中，keybd_event和mouse_event两个函数，就是用来模拟键盘和鼠标的输入（这个仅为笔者本人的猜测）。 CPU中断的过程中断请求中断请求是由中断源向CPU发出中断请求信号。外部设备发出中断请求信号要具备以下两个条件： 外部设备的工作已经告一段落。例如输入设备只有在启动后，将要输入的数据送到接口电路的数据寄存器（即准备好要输入的数据）之后，才可以向CPU发出中断请求。 系统允许该外设发出中断请求。如果系统不允许该外设发出中断请求，可以将这个外设的请求屏蔽。当这个外设中断请求被屏蔽，虽然这个外设准备工作已经完成，也不能发出中断请求。 中断响应、处理和返回当满足了中断的条件后，CPU就会响应中断，转入中断程序处理。具体的工作过程如下： 关闭中断信号接收器 保存现场(context) 给出中断入口，转入相应的中断服务程序 处理完成，返回并恢复现场(context) 开启中断信号接收器 中断排队和中断判优 中断申请是随机的，有时会出现多个中断源同时提出中断申请。 CPU每次只能响应一个中断源的请求。 CPU不可能对所有中断请求一视同仁，它会根据各中断源工作性质的轻重缓急，预先安排一个优先级顺序。当多个中断源同时申请中断时，即按此优先级顺序进行排队，等候CPU处理。 了解了CPU中断处理的过程，就不难理解下面一种常见的情景： 正在拷贝文件时，往某个文本框输入信息，这个文本框会出现短暂的假死，键盘输入的数据不能及时显示在文本框中，需要等一会儿才能逐渐显示出来。这是因为该中断操作(往文本框输入信息)在中断队列的优先级比较低，或者CPU认为正在处理的操作(拷贝文件)进行挂起的代价太大，所以只有等到CPU到了一个挂起代价较低的点，才会挂起当前操作，处理本次中断信息。 多核CPU对中断的处理多核CPU的中断处理和单核有很大不同。多核的各处理器核心之间需要通过中断方式进行通信，所以CPU芯片内部既有各处理器核心的本地中断控制器，又有负责仲裁各核之间中断分配的全局中断控制器。 现今的多核处理器在中断处理和中断控制方面主要使用的是APIC（Advanced Programmable Interrupt Controllers），即高级编程中断控制器。它是基于中断控制器两个基础功能单元——本地单元以及I/O单元的分布式体系结构。在多核系统中，多个本地和I/O APIC单元能够作为一个整体通过APIC总线互相操作。 APIC的功能有： 接受来自处理器中断引脚的内部或外部I/O APIC的中断，然后将这些中断发送给处理器核心进行处理 在多核处理器系统中，接收和发送核内中断消息 对于外部设备发出的中断请求，由全局中断控制器接收请求并决定交给CPU的哪一个核心处理。也可针对APIC编程，让所有的中断都被一个固定的CPU处理。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux-进程、进程组、作业、会话、控制终端详解]]></title>
    <url>%2F2019%2F05%2F04%2FLinux%E4%BC%9A%E8%AF%9D%E6%8E%A7%E5%88%B6%E7%BB%88%E7%AB%AF%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/qq_34376868/article/details/80562288 进程传统上，Unix操作系统下运行的应用程序、 服务器以及其他程序都被称为进程，而Linux也继承了来自unix进程的概念。必须要理解下，程序是指的存储在存储设备上（如磁盘）包含了可执行机器指 令（二进制代码）和数据的静态实体；而进程可以认为是已经被OS从磁盘加载到内存上的、动态的、可运行的指令与数据的集合，是在运行的动态实体。这里指的 指令和数据的集合可以理解为Linux上ELF文件格式中的.text .data数据段。 进程组每个进程除了有一个进程ID之外，还属于一个进程组，那什么是进程组呢？ 顾名思义，进程组就是一个或多个进程的集合。这些进程并不是孤立的，他们彼此之间或者存在父子、兄弟关系，或者在功能上有相近的联系。每个进程都有父进程，而所有的进程以init进程为根，形成一个树状结构。 那为啥Linux里要有进程组呢？其实，提供进程组就是为了方便对进程进行管理。假设要完成一个任务，需要同时并发100个进程。当用户处于某种原因要终止这个任务时，要是没有进程组，就需要手动的一个个去杀死这100个进程，并且必须要严格按照进程间父子兄弟关系顺序，否则会扰乱进程树。有了进程组，就可以将这100个进程设置为一个进程组，它们共有1个组号（pgrp），并且有选取一个进程作为组长（通常是“辈分”最高的那个，通常该进程的ID也就作为进程组的ID）。现在就可以通过杀死整个进程组，来关闭这100个进程，并且是严格有序的。组长进程可以创建一个进程组，创建该组中的进程，然后终止。只要在某个进程组中一个进程存在，则该进程组就存在，这与其组长进程是否终止无关。 进程必定属于一个进程组，也只能属于一个进程组。 一个进程组中可以包含多个进程。 进程组的生命周期从被创建开始，到其内所有进程终止或离开该组。 内核中，sys_getpgrp()系统调用用来获取当前进程所在进程组号；sys_setpgid(int pid, int pgid)调用用来设置置顶进程pid的进程组号为pgid。 作业Shell分前后台来控制的不是进程而是作业（Job）或者进程组（Process Group）。一个前台作业可以由多个进程组成，一个后台也可以由多个进程组成，Shell可以运行一个前台作业和任意多个后台作业，这称为作业控制。 作业与进程组的区别：如果作业中的某个进程又创建了子进程，则子进程不属于作业。一旦作业运行结束，Shell就把自己提到前台，如果原来的前台进程还存在（如果这个子进程还没终止），它自动变为后台进程组。 会话再看下会话。由于Linux是多用户多任务的分时系统，所以必须要支持多个用户同时使用一个操作系统。当一个用户登录一次系统就形成一次会话 。一个会话可包含多个进程组，但只能有一个前台进程组。每个会话都有一个会话首领（leader），即创建会话的进程。 sys_setsid()调用能创建一个会话。必须注意的是，只有当前进程不是进程组的组长时，才能创建一个新的会话。调用setsid 之后，该进程成为新会话的leader。 一个会话可以有一个控制终端。这通常是登陆到其上的终端设备（在终端登陆情况下）或伪终端设备（在网络登陆情况下）。建立与控制终端连接的会话首进程被称为控制进程。一个会话中的几个进程组可被分为一个前台进程组以及一个或多个后台进程组。所以一个会话中，应该包括控制进程（会话首进程），一个前台进程组和任意后台进程组。 一次登录形成一个会话 一个会话可包含多个进程组，但只能有一个前台进程组 控制终端会话的领头进程打开一个终端之后, 该终端就成为该会话的控制终端 (SVR4/Linux) 与控制终端建立连接的会话领头进程称为控制进程 (session leader) 一个会话只能有一个控制终端 产生在控制终端上的输入和信号将发送给会话的前台进程组中的所有进程 终端上的连接断开时 (比如网络断开或 Modem 断开), 挂起信号将发送到控制进程(session leader) 进程属于一个进程组，进程组属于一个会话，会话可能有也可能没有控制终端。一般而言，当用户在某个终端上登录时，一个新的会话就开始了。进程组由组中的领头进程标识，领头进程的进程标识符就是进程组的组标识符。类似地，每个会话也对应有一个领头进程。 同一会话中的进程通过该会话的领头进程和一个终端相连，该终端作为这个会话的控制终端。一个会话只能有一个控制终端，而一个控制终端只能控制一个会话。用户通过控制终端，可以向该控制终端所控制的会话中的进程发送键盘信号。 同一会话中只能有一个前台进程组，属于前台进程组的进程可从控制终端获得输入，而其他进程均是后台进程，可能分属于不同的后台进程组。 我们打开多个终端窗口时，实际上就创建了多个终端会话。每个会话都会有自己的前台工作和后台工作。 会话的维系维系一个会话，最常见的有两种方式： 一是基于某种凭证，比如web网站的登录会话，在登录验证之后，服务器就会返回一个session id作为凭证。用户之后的请求总是会带上这个id，而服务器通过这个id也就能知道用户是谁。直到用户注销登录、或者登录超时，服务器会清洗掉对应的session id，这个id就失效了，会话也就随之而结束。 第二种方式是基于连接的，当用户和系统之间的连接启用时，系统会对用户进行验证，验证通过之后，来自这个连接的操作都是属于这个用户的。直到连接断开，则会话结束。 linux系统的会话就是以第二种方式来维系的。会话基于连接，那么连接的安全性就决定了会话的安全性。以最常见的两种连接为例： 本地连接，用户是直接通过键盘显示器来跟系统交互的，键盘显示器直接连接在主机上，连接被篡改基本上是不可能的； 远程连接，以ssh为例，其协议会进行加密，从而避免连接被篡改； 下面在讨论会话的时候就围绕两种连接来展开。 连接的启用前面说到，会话是基于连接的。会话的源头，就是用户与系统之间连接的启用。 对于本地连接，连接是在系统初始化时建立的。linux会初始化若干个tty（/dev/tty?），形成若干个虚拟终端。本地连接的键盘和显示器通过对应的驱动程序，跟其中某个tty绑定上。用户可以通过ALT+F[1-12]键，将键盘和显示器切换到不同的tty上（也就是说，一套键盘显示器可以对应多个本地连接）。 在系统启动的时候，init程序会根据相应的配置（如：/etc/init/tty1.conf），启动相应的程序来监听这些tty（如：/sbin/getty -8 38400 tty1。下文说到这个监听程序时，就以getty为例）。当用户通过ALT+F?切换到对应的tty?、并有所输入时，在该tty上监听的getty就能读取到输入信息，然后通过exec启动login程序来进行登录验证。从getty得到输入的这一刻起，tty?上的这个连接就算是启用了。 对于远程连接，本文都以ssh为例。系统安装ssh server之后，在/etc/init.d/下会有它对应的启动脚本，这会使得sshd程序（ssh服务器）在系统启动的时候被启动（当然，root用户也可以在系统启动之后，手动启动sshd）。sshd监听网络上的相应端口（如：tcp:22），等待远程用户的连接。用户的连接始于TCP连接，然后sshd和ssh-client会打通ssh隧道。从这时起，连接启用，sshd会要求用户进行登录验证。 登录验证不管是本地终端登录，还是远程登录，登录验证无非就是要让用户输入用户名和密码。用户输入的信息通过已经启用的连接到达对端程序（如：login、sshd），然后由其进行校验。 系统中的用户信息存放在/etc/passwd文件中，里面保存的系统中所有用户的信息。这些信息主要有：用户名、密码、组、home路径、以及登录后执行的程序、等。这些信息可以分两个层面来看： 用于验证的。包括用户名和密码两项。即用户在与系统建立连接后，需要提供用户名和密码来进行验证（注意，密码一般并不是明文保存在passwd文件中的）； 登录后用于设置用户属性的。除密码外的所有项。下面会详细解释； 用户登录后会得到一个进程，关于这个进程，它有如下一些特征： 对于本地连接，它就是原本执行getty的那个进程；而对于ssh连接，它是由sshd fork出来的进程； 进程的用户名、组、当前路径、等都被按/etc/passwd文件中的描述进行设置； 进程的stdin、stdout、stderr连接到一个对应的终端。对于本地连接，这个终端就是getty监听的那个tty；对于ssh连接，它是由sshd打开的pty（伪终端，后面会详细解释）； 这个进程会执行/etc/passwd中配置的”登录后执行的程序”，这个程序一般就是/bin/sh，即登录后为用户提供一个shell控制台。于是用户可以使用自己的终端跟这个shell程序交互，干各种事情。这个”登录后执行的程序”也常被配置为/bin/nologin，表示对应用户是不允许登录的，因为nologin程序不会与用户进行交互，打印错误信息后就会退出了，所以登录只是白费劲。当然，如果你愿意，并且有root权限，也可以将”登录后执行的程序”配置成其他程序； 于是，用户在登录完成之后，系统中就存在这样一个用户名为该登录用户的进程。通常这个进程运行shell程序，并且其输入输出连接到用户的终端，所以用户可以用键盘来操作这个shell，并且用显示器接收shell的输出。 关于终端前面讲到，登录后的shell其输入输出是连接到用户使用的终端的，不管是本地登录的tty，还是远程登录的pty。但是，为什么要有终端呢？shell的输入直接接到键盘、输出直接接到显示器，这样不行么？尤其是远程的情况，shell的输入输出为什么不能直接接到网络，而非要弄一个pty出来呢？最容易想到的一点，终端能够使得上层不必关心输入输出设备本身的细节，只管对其读写就行了。不过这一点似乎并不是终端所特有的，因为vfs已经能够胜任了。应用程序open设备文件，得到fd，然后同样只用管对其读写就行了，而不用关心这个fd代表的是键盘、还是普通文件，具体的细节已经被隐藏在设备驱动程序之中。 不过，相比于普通的读写，终端还实现了很多可以通过ioctl系统调用进行配置的功能，能够完成一些针对输入输出的处理逻辑。如： 回车换行的转换：定义输入输出如何映射回车换行符。比如：回车键是\r、还是\n、还是\r\n；再如：\n应该如何打印到屏幕上，是回车+换行、还是只换行不回车、等等； 行编辑：允许让输入字符不是立马送到应用程序，而是在换行以后才能被读取到。未换行的输入字符可以通过退格键进行编辑（比如在你密码输错的时候，是可以用CTRL+退格来进行编辑的）； 回显：可以让输入字符自动被回显到终端的输出上。于是，键盘每输入一个字符都能在显示器上看到它，而这些字符其实很可能是还没被应用程序读取到的（因为有行编辑）； 功能键：允许定义功能键。比如最常用的Ctrl+C，杀死前台进程，就是由终端来触发的。终端检测到Ctrl+C输入，会向前台进程组发送SIGTERM信号。而谁是前台进程组呢？这是由shell通过ioctl系统调用对终端使用TIOCSPGRP命令来设置的，每当shell启动一个前台进程，它都需要这么设置一下； 输入输出流向控制，只有前台进程组能够从终端中读数据、而不管前台后台程序都能向终端写数据。这点也是必须的，跟用户进程交互的是前台进程，用户的输入当然不能被其他后台进程抢走。但是一个进程是前台还是后台，是它自己是所不知道的，没法靠进程自己来判断什么时候可以读终端、什么时候不能读。所以需要终端来提供支持，如果后台进程读这个终端，终端的驱动程序将向其发送SIGTTIN信号，从而将其挂起。直到shell将其重新置为前台进程时（通过fg命令），该进程才会继续执行； 终端提供的这些功能未必都会被打开它的程序使用到，但是如果要使用，则可以通过统一的ioctl接口来设置，而不需要关心终端具体接的是什么设备，是键盘显示器？还是网络。大多数应用程序则根本不关心终端，只当它是能够满足读写需求的文件。而像shell这样为人机交互而生的程序，则注定会跟终端打交道。对于shell来说，像“行编辑”、“回显”这样的功能，其实是可以不需要依赖终端的，shell程序自己可以做这样的处理，因为要做处理的数据正是shell从终端里面读到的数据。但是像“功能键”、“输入输出流向控制”这样的功能，则又不得不依赖终端。比如“功能键”，因为这时在对终端进行读操作的是shell启动的前台程序，而不是shell自己，所以不可能由shell来读取功能键，然后触发信号。 可以说，终端是人机交互时，应用程序与用户之间的一个中间层。如果应用程序是在跟人交互，使用终端是其不二的选择；否则则没有必要使用终端。这一点在sshd上面有很好的体现。当用户使用ssh登录到远程机器remotehost，并执行一些操作时（比如执行cat test.txt操作），可以有两种方式： ssh user:pass@remotehost，远程登录后，再在shell中执行cat test.txt命令； ssh user:pass@remotehost ‘cat test.txt’，直接由sshd启动一个shell、自动执行’cat test.txt’命令；第一种方式，是登录之后，再通过人机交互输入命令，这时sshd会为登录后得到的shell程序准备一个pty，以支持人机交互；而第二种方式，在登录之后并不需要交互，所以sshd就并不会使用pty，而是直接通过socket将shell的输入输出跟自己连接起来（再由sshd将其转发给ssh-client）。 下面再说一下pty。pty分master和slave两端，跟pipe的两端很像，写入到master端的数据可以原样从slave端读出，反之亦然。在上面所述的第一种方式下，各个进程的联系如下：ssh-client [socket] sshd [master] [slave] shellpty的master和slave两端分别被sshd和shell打开，就像pipe一样，将它们的输入输出连接起来。而pty跟pipe的不同之处，则正是前面所说的终端的功能（pty的slave端对于shell来说就是一个终端）。跟tty不同，tty是系统初始化时生成的，其数目是固定的（比如12个）。而pty是系统启动后动态创建的。其创建的方法是：fd = open(‘/dev/ptms’)，这样就得到了一个pty。open返回的fd代表master端，通过ptyname(fd)可以得到对应slave端的文件路径（比如’/dev/pts/2’），这个设备文件是master端被open之后动态生成的。 权限控制用户登录验证成功后，getty、sshd这样的程序就会为用户启动他所对应的”登录后执行的程序”，并且在此之前会通过setuid()、setgid()这样的系统调用，设置好进程的uid和gid（用户和组）。之后，这个进程对文件的读、写、执行，以及对系统调用的使用，等都会受到进程uid和gid的限制。 用户对系统的各种操作都是通过进程来完成的。而用户的输入输出都被定向到他登录后所得到的那个进程上，于是用户能够控制这个进程，来干他想干的事情（如果这个进程接受控制的话，比如进程运行着一个shell程序）。用户的操作都受限于进程的uid和gid，比如文件访问、向进程发送信号、使用系统调用、监听网络端口、等都需要对其做检查。 除非是root用户，否则没有权限使用setuid()、setgid()这样的系统调用来修改进程的uid和gid。而login时，login、sshd这样的进程之所以能够设置登录后进程的uid和gid，正是因为它们都是root用户的进程。如果想要改变登录用户，则必须利用属于root用户的进程。一种办法是退出登录，然后走老路，重新跟getty、sshd这样的进程打交道，而使用其他用户名登录。另一种办法是执行一个setuid/setgid程序（参见《记一个linux内核内存提权问题》中的说明），临时获得root权限，再实现用户的切换（例如su就是这样一个能实现用户切换的setuid命令）。 为了实现进程权限控制中的各种功能，进程的uid和gid其实并不止一组，主要有如下三组： ruid/rgid，代表实际的用户和组id； euid/egid，代表当前生效的用户和组id； suid/sgid，代表保留的用户和组id； 什么意思呢？一般情况下，在用户登录得到的进程中，这三组id都是相同的值，与登录用户相对应（假设为aaa）。而用户新创建的进程也会全部继承这三组id。当用户执行一个setuid/setgid程序时，执行程序的进程将得到可执行程序owner（假设为bbb）的用户属性，euid/egid和suid/sgid会更新为bbb（而ruid/rgid不会被更新）。这些id在进程操作别的对象时（比如写文件、发信号、等）或被别的进程操作时（比如其他进程向其发信号、等）会被用做校验。ruid/rgid和euid/egid在进程被操作的时候会使用到，euid/egid在进程发起操作的时候会用到。比如有一个进程，其ruid是aaa、euid是bbb，则euid为aaa或bbb的其他进程都可以向其发送信号。而该进程在进行读写文件、创建文件、等操作时，使用的则是用户bbb的权限：它创建的文件owner是bbb、它在访问owner是aaa的文件时以other权限进行校验。那么第三组id，suid/sgid又是干什么用的呢？之前说普通用户没有权限使用setuid()这样的系统调用来改变进程的uid和gid，其实这个说法并不确切。进程其实是有权限将自己的ruid/rgid、euid/egid、suid/sgid的值修改成与这三者之一相等的值。比如ruid/rgid为aaa、suid/sgid为bbb，则用户可以任意将euid/egid设置为aaa或bbb。因为大多数情况下这三组id是等值的，所以一般说用户进程不能修改自己的uid和gid（只能从aaa修改为aaa，相当于不能修改）。但是执行setuid的程序后，进程的这三组id就有了两种不同的取值，ruid/rgid等于aaa、euid/egid和suid/sgid等于bbb，于是进程的uid就有了一定的选择余地。比如此时进程的euid/egid被更新成了bbb，那就不能再以owner身份去操作aaa的文件了（注意，这个进程原本是以aaa用户登录而得到的）。不过没关系，进程是有权限将euid/egid改回aaa的，因为ruid/rgid的值是aaa。但是改回来之后，ruid/rgid和euid/egid都是aaa了，要再想把euid/egid改为bbb怎么办呢？suid/sgid就是为此而生的，作为一个备份，它的值是bbb，这使得euid/egid还能够修改回bbb。当然，进程也有权限将euid/egid和suid/sgid都改回aaa，这将使得它们不再能修改成bbb了。 会话退出用户登录是一个会话的开始。登录之后，用户会得到一个跟用户使用的终端相连的进程，这个进程被称作是这个会话的leader，会话的id就等于该进程的pid。由该进程fork出来的子进程都是这个会话的成员（进程的sid等于该会话id）。leader进程的退出，将导致它所连接的终端被hangup，这意味着会话结束。反过来，像ssh这样的远程连接也可以通过断开连接的方式来使终端hangup，这将使得leader进程收到SIGHUP信号而退出。如果会话使用的是pty，其本身是随会话的建立而创建出来的，会话结束，则pty被销毁；而如果会话使用的是tty，其本身是在系统初始化时创建的，并不依赖于会话的建立，则会话结束时，tty依然存在。init进程检测到使用该tty的会话已经结束，便会重新启动一个getty来监听该tty。 不过，会话结束，并不意味着在该会话中创建的所有进程都结束了。所谓的daemon进程，正是在某个会话中创建，但是却不依赖该会话，而常驻后台的进程。具体来说，当终端hangup时，内核会有如下两个动作： 向对应会话的leader进程发送SIGHUP信号。而一般来说，会话的leader进程很可能是一个shell，它在收到SIGHUP信号后，并不是马上退出，而是会向它所启动的子进程都各自发送一个SIGHUP信号，将它们都杀死，然后自己才退出。不过，如果是这个作为leader进程shell自己退出，而导致终端hangup的话，向其子进程发送SIGHUP信号的事情就不会发生了，因为shell退出在先，它再也不会收到SIGHUP信号； 修改所有打开该终端的文件句柄，改成一个不可读不可写的实现； 所以，在会话退出之后还常驻后台的进程肯定是没法跟终端交互的。而要想让进程常驻后台，一般有如下几种方法： 避免shell发SIGHUP信号；主要有两种办法：1)主动exit，而不是直接断开终端；2)两次fork。因为shell只认识它自己fork出来的子进程，并不知道”子又生孙”的事情，也就不会给孙子进程发送SIGHUP信号了； 忽略SIGHUP信号；终端hangup时进程可能收到shell发送的SIGHUP信号。信号的默认处理动作是退出进程，但是该信号是可以忽略的。忽略信号，就可以使得后台进程不会随会话退出而退出。nohup命令就是做这件事情的，而且它做得更完整一些，不仅忽略SIGHUP，还会将进程的标准输入重定向为/dev/null、输出重定向到nohup.out文件； 使用setsid()系统调用，为进程开启一个新的会话；从一个会话中fork出来的进程，默认都是属于这个会话的。但是进程可以调用setsid()，使自己脱离原先的会话，而成为一个新会话的leader。于是，原先的会话退出，就不会影响到新建的会话了。setsid命令包装了setsid()系统调用，可以为进程创建新的会话。不过它并不对新进程的输入输出进行重定向，这就意味着新进程的输入输出还是连接到原先的那个tty的，这可能跟原先的会话争抢输入。所以，对新会话的进程进行输入输出的重定向也是一件很重要的事情。 一个进程成为daemon进程，可以不随会话的退出而退出，但是进程的uid/gid并不会因此而改变。对应的用户还可以在其他会话中，通过发信号等方式，操作那些原来由他所启动的daemon进程（因为权限控制是以用户为准的，而并不考虑会话）。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬中断和软中断]]></title>
    <url>%2F2019%2F05%2F01%2F%E7%A1%AC%E4%B8%AD%E6%96%AD%E5%92%8C%E8%BD%AF%E4%B8%AD%E6%96%AD%2F</url>
    <content type="text"><![CDATA[概述从本质上来讲，中断是一种电信号，当设备有某种事件发生时，它就会产生中断，通过总线把电信号发送给中断控制器。如果中断的线是激活的，中断控制器就把电信号发送给处理器的某个特定引脚。处理器于是立即停止自己正在做的事，跳到中断处理程序的入口点，进行中断处理。 硬中断 由与系统相连的外设(比如网卡、硬盘)自动产生的。主要是用来通知操作系统系统外设状态的变化。比如当网卡收到数据包的时候，就会发出一个中断。我们通常所说的中断指的是硬中断(hardirq)。 软中断 为了满足实时系统的要求，中断处理应该是越快越好。linux为了实现这个特点，当中断发生的时候，硬中断处理那些短时间就可以完成的工作，而将那些处理事件比较长的工作，放到中断之后来完成，也就是软中断(softirq)来完成。 中断嵌套 Linux下硬中断是可以嵌套的，但是没有优先级的概念，也就是说任何一个新的中断都可以打断正在执行的中断，但同种中断除外。软中断不能嵌套，但相同类型的软中断可以在不同CPU上并行执行。 软中断指令 int是软中断指令。中断向量表是中断号和中断处理函数地址的对应表。int n - 触发软中断n。相应的中断处理函数的地址为：中断向量表地址 + 4 * n。 硬中断和软中断的区别 软中断是执行中断指令产生的，而硬中断是由外设引发的。 硬中断的中断号是由中断控制器提供的，软中断的中断号由指令直接指出，无需使用中断控制器。 硬中断是可屏蔽的，软中断不可屏蔽。 硬中断处理程序要确保它能快速地完成任务，这样程序执行时才不会等待较长时间，称为上半部。 软中断处理硬中断未完成的工作，是一种推后执行的机制，属于下半部。 开关硬中断的开关简单禁止和激活当前处理器上的本地中断：12local_irq_disable();local_irq_enable(); 保存本地中断系统状态下的禁止和激活：123unsigned long flags;local_irq_save(flags);`local_irq_restore(flags); 软中断的开关禁止下半部，如softirq、tasklet和workqueue等：12local_bh_disable();local_bh_enable(); 需要注意的是，禁止下半部时仍然可以被硬中断抢占。 判断中断状态123#define in_interrupt() (irq_count()) // 是否处于中断状态(硬中断或软中断)#define in_irq() (hardirq_count()) // 是否处于硬中断#define in_softirq() (softirq_count()) // 是否处于软中断 硬中断注册中断处理函数注册中断处理函数：1234567891011/** * irq: 要分配的中断号 * handler: 要注册的中断处理函数 * flags: 标志(一般为0) * name: 设备名(dev-&gt;name) * dev: 设备(struct net_device *dev)，作为中断处理函数的参数 * 成功返回0 */ int request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev); 中断处理函数本身：123456789101112131415typedef irqreturn_t (*irq_handler_t) (int, void *);/** * enum irqreturn * @IRQ_NONE: interrupt was not from this device * @IRQ_HANDLED: interrupt was handled by this device * @IRQ_WAKE_THREAD: handler requests to wake the handler thread */enum irqreturn &#123; IRQ_NONE, IRQ_HANDLED, IRQ_WAKE_THREAD,&#125;;typedef enum irqreturn irqreturn_t;#define IRQ_RETVAL(x) ((x) != IRQ_NONE) 注销中断处理函数1234567891011121314/** * free_irq - free an interrupt allocated with request_irq * @irq: Interrupt line to free * @dev_id: Device identity to free * * Remove an interrupt handler. The handler is removed and if the * interrupt line is no longer in use by any driver it is disabled. * On a shared IRQ the caller must ensure the interrupt is disabled * on the card it drives before calling this function. The function does * not return until any executing interrupts for this IRQ have completed. * This function must not be called from interrupt context. */ void free_irq(unsigned int irq, void *dev_id); 软中断定义软中断是一组静态定义的下半部接口，可以在所有处理器上同时执行，即使两个类型相同也可以。但一个软中断不会抢占另一个软中断，唯一可以抢占软中断的是硬中断。 软中断由softirq_action结构体表示：123struct softirq_action &#123; void (*action) (struct softirq_action *); /* 软中断的处理函数 */&#125;; 目前已注册的软中断有10种，定义为一个全局数组：123456789101112131415static struct softirq_action softirq_vec[NR_SOFTIRQS]; enum &#123; HI_SOFTIRQ = 0, /* 优先级高的tasklets */ TIMER_SOFTIRQ, /* 定时器的下半部 */ NET_TX_SOFTIRQ, /* 发送网络数据包 */ NET_RX_SOFTIRQ, /* 接收网络数据包 */ BLOCK_SOFTIRQ, /* BLOCK装置 */ BLOCK_IOPOLL_SOFTIRQ, TASKLET_SOFTIRQ, /* 正常优先级的tasklets */ SCHED_SOFTIRQ, /* 调度程序 */ HRTIMER_SOFTIRQ, /* 高分辨率定时器 */ RCU_SOFTIRQ, /* RCU锁定 */ NR_SOFTIRQS /* 10 */&#125;; 注册软中断处理函数123456789/** * @nr: 软中断的索引号 * @action: 软中断的处理函数 */ void open_softirq(int nr, void (*action) (struct softirq_action *))&#123; softirq_vec[nr].action = action;&#125; 例如：12open_softirq(NET_TX_SOFTIRQ, net_tx_action);open_softirq(NET_RX_SOFTIRQ, net_rx_action); 触发软中断调用raise_softirq()来触发软中断。1234567891011121314151617181920212223void raise_softirq(unsigned int nr)&#123; unsigned long flags; local_irq_save(flags); raise_softirq_irqoff(nr); local_irq_restore(flags);&#125; /* This function must run with irqs disabled */inline void rasie_softirq_irqsoff(unsigned int nr)&#123; __raise_softirq_irqoff(nr); /* If we&apos;re in an interrupt or softirq, we&apos;re done * (this also catches softirq-disabled code). We will * actually run the softirq once we return from the irq * or softirq. * Otherwise we wake up ksoftirqd to make sure we * schedule the softirq soon. */ if (! in_interrupt()) /* 如果不处于硬中断或软中断 */ wakeup_softirqd(void); /* 唤醒ksoftirqd/n进程 */&#125; Percpu变量irq_cpustat_t中的__softirq_pending是等待处理的软中断的位图，通过设置此变量 即可告诉内核该执行哪些软中断。123456789101112131415static inline void __rasie_softirq_irqoff(unsigned int nr)&#123; trace_softirq_raise(nr); or_softirq_pending(1UL &lt;&lt; nr);&#125; typedef struct &#123; unsigned int __softirq_pending; unsigned int __nmi_count; /* arch dependent */&#125; irq_cpustat_t; irq_cpustat_t irq_stat[];#define __IRQ_STAT(cpu, member) (irq_stat[cpu].member)#define or_softirq_pending(x) percpu_or(irq_stat.__softirq_pending, (x))#define local_softirq_pending() percpu_read(irq_stat.__softirq_pending) 唤醒ksoftirqd内核线程处理软中断。12345678static void wakeup_softirqd(void)&#123; /* Interrupts are disabled: no need to stop preemption */ struct task_struct *tsk = __get_cpu_var(ksoftirqd); if (tsk &amp;&amp; tsk-&gt;state != TASK_RUNNING) wake_up_process(tsk);&#125; 在下列地方，待处理的软中断会被检查和执行： 从一个硬件中断代码处返回时 在ksoftirqd内核线程中 在那些显示检查和执行待处理的软中断的代码中，如网络子系统中 而不管是用什么方法唤起，软中断都要在do_softirq()中执行。如果有待处理的软中断，do_softirq()会循环遍历每一个，调用它们的相应的处理程序。在中断处理程序中触发软中断是最常见的形式。中断处理程序执行硬件设备的相关操作，然后触发相应的软中断，最后退出。内核在执行完中断处理程序以后，马上就会调用do_softirq()，于是软中断开始执行中断处理程序完成剩余的任务。 下面来看下do_softirq()的具体实现。123456789101112131415asmlinkage void do_softirq(void)&#123; __u32 pending; unsigned long flags; /* 如果当前已处于硬中断或软中断中，直接返回 */ if (in_interrupt()) return; local_irq_save(flags); pending = local_softirq_pending(); if (pending) /* 如果有激活的软中断 */ __do_softirq(); /* 处理函数 */ local_irq_restore(flags);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* We restart softirq processing MAX_SOFTIRQ_RESTART times, * and we fall back to softirqd after that. * This number has been established via experimentation. * The two things to balance is latency against fairness - we want * to handle softirqs as soon as possible, but they should not be * able to lock up the box. */asmlinkage void __do_softirq(void)&#123; struct softirq_action *h; __u32 pending; /* 本函数能重复触发执行的次数，防止占用过多的cpu时间 */ int max_restart = MAX_SOFTIRQ_RESTART; int cpu; pending = local_softirq_pending(); /* 激活的软中断位图 */ account_system_vtime(current); /* 本地禁止当前的软中断 */ __local_bh_disable((unsigned long)__builtin_return_address(0), SOFTIRQ_OFFSET); lockdep_softirq_enter(); /* current-&gt;softirq_context++ */ cpu = smp_processor_id(); /* 当前cpu编号 */ restart: /* Reset the pending bitmask before enabling irqs */ set_softirq_pending(0); /* 重置位图 */ local_irq_enable(); h = softirq_vec; do &#123; if (pending &amp; 1) &#123; unsigned int vec_nr = h - softirq_vec; /* 软中断索引 */ int prev_count = preempt_count(); kstat_incr_softirqs_this_cpu(vec_nr); trace_softirq_entry(vec_nr); h-&gt;action(h); /* 调用软中断的处理函数 */ trace_softirq_exit(vec_nr); if (unlikely(prev_count != preempt_count())) &#123; printk(KERN_ERR &quot;huh, entered softirq %u %s %p&quot; &quot;with preempt_count %08x,&quot; &quot;exited with %08x?\n&quot;, vec_nr, softirq_to_name[vec_nr], h-&gt;action, prev_count, preempt_count()); &#125; rcu_bh_qs(cpu); &#125; h++; pending &gt;&gt;= 1; &#125; while(pending); local_irq_disable(); pending = local_softirq_pending(); if (pending &amp; --max_restart) /* 重复触发 */ goto restart; /* 如果重复触发了10次了，接下来唤醒ksoftirqd/n内核线程来处理 */ if (pending) wakeup_softirqd(); lockdep_softirq_exit(); account_system_vtime(current); __local_bh_enable(SOFTIRQ_OFFSET);&#125; ksoftirqd内核线程内核不会立即处理重新触发的软中断。当大量软中断出现的时候，内核会唤醒一组内核线程来处理。这些线程的优先级最低(nice值为19)，这能避免它们跟其它重要的任务抢夺资源。但它们最终肯定会被执行，所以这个折中的方案能够保证在软中断很多时用户程序不会因为得不到处理时间而处于饥饿状态，同时也保证过量的软中断最终会得到处理。 每个处理器都有一个这样的线程，名字为ksoftirqd/n，n为处理器的编号。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static int run_ksoftirqd(void *__bind_cpu)&#123; set_current_state(TASK_INTERRUPTIBLE); current-&gt;flags |= PF_KSOFTIRQD; /* I am ksoftirqd */ while(! kthread_should_stop()) &#123; preempt_disable(); if (! local_softirq_pending()) &#123; /* 如果没有要处理的软中断 */ preempt_enable_no_resched(); schedule(); preempt_disable(): &#125; __set_current_state(TASK_RUNNING); while(local_softirq_pending()) &#123; /* Preempt disable stops cpu going offline. * If already offline, we&apos;ll be on wrong CPU: don&apos;t process. */ if (cpu_is_offline(long)__bind_cpu))/* 被要求释放cpu */ goto wait_to_die; do_softirq(); /* 软中断的统一处理函数 */ preempt_enable_no_resched(); cond_resched(); preempt_disable(); rcu_note_context_switch((long)__bind_cpu); &#125; preempt_enable(); set_current_state(TASK_INTERRUPTIBLE); &#125; __set_current_state(TASK_RUNNING); return 0; wait_to_die: preempt_enable(); /* Wait for kthread_stop */ set_current_state(TASK_INTERRUPTIBLE); while(! kthread_should_stop()) &#123; schedule(); set_current_state(TASK_INTERRUPTIBLE); &#125; __set_current_state(TASK_RUNNING); return 0;&#125; 原文：https://blog.csdn.net/zhangskd/article/details/21992933]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准IO与文件IO的区别]]></title>
    <url>%2F2019%2F05%2F01%2F%E6%A0%87%E5%87%86IO%E4%B8%8E%E6%96%87%E4%BB%B6IO%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[先来了解下什么是文件I/O和标准I/O：文件I/O：文件I/O称之为不带缓存的IO（unbuffered I/O)。不带缓存指的是每个read，write都调用内核中的一个系统调用。也就是一般所说的低级I/O——操作系统提供的基本IO服务，与os绑定，特定于linix或unix平台。 标准I/O：标准I/O是ANSI C建立的一个标准I/O模型，是一个标准函数包和stdio.h头文件中的定义，具有一定的可移植性。标准I/O库处理很多细节。例如缓存分配，以优化长度执行I/O等。标准的I/O提供了三种类型的缓存。 全缓存：当填满标准I/O缓存后才进行实际的I/O操作。 行缓存：当输入或输出中遇到新行符时，标准I/O库执行I/O操作。 不带缓存：stderr就是了。 二者的区别文件I/O 又称为低级磁盘I/O，遵循POSIX相关标准。任何兼容POSIX标准的操作系统上都支持文件I/O。标准I/O被称为高级磁盘I/O，遵循ANSI C相关标准。只要开发环境中有标准I/O库，标准I/O就可以使用。（Linux 中使用的是GLIBC，它是标准C库的超集。不仅包含ANSI C中定义的函数，还包括POSIX标准中定义的函数。因此，Linux 下既可以使用标准I/O，也可以使用文件I/O）。 通过文件I/O读写文件时，每次操作都会执行相关系统调用。这样处理的好处是直接读写实际文件，坏处是频繁的系统调用会增加系统开销，标准I/O可以看成是在文件I/O的基础上封装了缓冲机制。先读写缓冲区，必要时再访问实际文件，从而减少了系统调用的次数。 文件I/O中用文件描述符表现一个打开的文件，可以访问不同类型的文件如普通文件、设备文件和管道文件等。而标准I/O中用FILE（流）表示一个打开的文件，通常只用来访问普通文件。 最后来看下他们使用的函数 标准IO 文件IO(低级IO) 打开 fopen,freopen,fdopen open 关闭 fclose close 读 getc,fgetc,getchar,fgets,gets,fread read 写 putc,fputc,putchar,fputs,puts,fwrite write fopen与open标准I/O使用fopen函数打开一个文件：1FILE* fp=fopen(const char* path,const char *mod) 其中path是文件名，mod用于指定文件打开的模式的字符串，比如”r”,”w”,”w+”,”a”等等，可以加上字母b用以指定以二进制模式打开（对于 Unix系统，只有一种文件类型，因此没有区别）,如果成功打开，返回一个FILE文件指针，如果失败返回NULL,这里的文件指针并不是指向实际的文 件，而是一个关于文件信息的数据包，其中包括文件使用的缓冲区信息。 文件IO使用open函数用于打开一个文件：1int fd=open(char *name,int how); 与fopen类似，name表示文件名字符串，而how指定打开的模式：O_RDONLY(只读),O_WRONLY(只写）,O_RDWR （可读可写),还有其他模式请man 2 open。成功返回一个正整数称为文件描述符，这与标准I/O显著不同，失败的话返回-1，与标准I/O返回NULL也是不同的。 open和fopen的区别(2)： 1.缓冲文件系统缓冲文件系统的特点是：在内存开辟一个“缓冲区”，为程序中的每一个文件使用，当执行读文件的操作时，从磁盘文件将数据先读入内存“缓冲区”，装满后再从内存“缓冲区”依此读入接收的变量。执行写文件的操作时，先将数据写入内存“缓冲区”，待内存“缓冲区”装满后再写入文件。由此可以看出，内存“缓冲区”的大小，影响着实际操作外存的次数，内存“缓冲区”越大，则操作外存的次数就少，执行速度就快、效率高。一般来说，文件“缓冲区”的大小随机器而定。fopen, fclose, fread, fwrite, fgetc, fgets, fputc, fputs, freopen, fseek, ftell, rewind等。 2.非缓冲文件系统缓冲文件系统是借助文件结构体指针来对文件进行管理，通过文件指针来对文件进行访问，既可以读写字符、字符串、格式化数据，也可以读写二进制数据。非缓冲文件系统依赖于操作系统，通过操作系统的功能对文件进行读写，是系统级的输入输出，它不设文件结构体指针，只能读写二进制文件，但效率高、速度 快，由于ANSI标准不再包括非缓冲文件系统，因此建议大家最好不要选择它。本书只作简单介绍。open, close, read, write, getc, getchar, putc, putchar 等。 open 是系统调用 返回的是文件句柄，文件的句柄是文件在文件描述副表里的索引，fopen是C的库函数，返回的是一个指向文件结构的指针。 fopen是ANSIC标准中的C语言库函数，在不同的系统中应该调用不同的内核apilinux中的系统函数是open，fopen是其封装函数，个人观点。仅供参考。 文件描述符是linux下的一个概念,linux下的一切设备都是以文件的形式操作.如网络套接字、硬件设备等。当然包括操作文件。fopen是标准c函数。返回文件流而不是linux下文件句柄。 设备文件不可以当成流式文件来用，只能用openfopen是用来操纵正规文件的，并且设有缓冲的，跟open还是有一些区别 一般用fopen打开普通文件，用open打开设备文件 fopen是标准c里的,而open是linux的系统调用.他们的层次不同.fopen可移植,open不能 我认为fopen和open最主要的区别是fopen在用户态下就有了缓存，在进行read和write的时候减少了用户态和内核态的切换，而open则每次都需要进行内核态和用户态的切换；表现为，如果顺序访问文件，fopen系列的函数要比直接调用open系列快；如果随机访问文件open要比fopen快。 来自论坛的经典回答： 前者属于低级IO，后者是高级IO。前者返回一个文件描述符(用户程序区的)，后者返回一个文件指针。前者无缓冲，后者有缓冲。前者与 read, write 等配合使用， 后者与 fread, fwrite等配合使用。后者是在前者的基础上扩充而来的，在大多数情况下，用后者。 fclose与close与打开文件相对的，标准I/O使用fclose关闭文件，将文件指针传入即可，如果成功关闭，返回0，否则返回EOF比如：12if(fclose(fp)!=0) printf(&quot;Error in closing file&quot;); 而文件IO使用close用于关闭open打开的文件，与fclose类似，只不过当错误发生时返回的是-1，而不是EOF，成功关闭同样是返回0。C语言用error code来进行错误处理的传统做法。 读文件，getc,fscanf,fgets和read标准I/O中进行文件读取可以使用getc，一个字符一个字符的读取，也可以使用gets（读取标准io读入的）、fgets以字符串单位进行读取（读到遇 到的第一个换行字符的后面），gets（接受一个参数，文件指针）不判断目标数组是否能够容纳读入的字符，可能导致存储溢出(不建议使用），而fgets使用三个参数：1char * fgets(char *s, int size, FILE *stream); 第一个参数和gets一样，用于存储输入的地址，第二个参数为整数，表示输入字符串的最大长度，最后一个参数就是文件指针，指向要读取的文件。最 后是fscanf，与scanf类似，只不过增加了一个参数用于指定操作的文件，比如fscanf(fp,”%s”,words)文件IO中使用read函数用于读取open函数打开的文件，函数原型如下：1ssize_t numread=read(int fd,void *buf,size_t qty); 其中fd就是open返回的文件描述符，buf用于存储数据的目的缓冲区，而qty指定要读取的字节数。如果成功读取，就返回读取的字节数目（小于等于qty） 判断文件结尾如果尝试读取达到文件结尾，标准IO的getc会返回特殊值EOF，而fgets碰到EOF会返回NULL,而对于*nix的read函数，情况有所 同。read读取qty指定的字节数，最终读取的数据可能没有你所要求的那么多（qty），而当读到结尾再要读的话，read函数将返回0. 写文件：putc,fputs,fprintf和write与读文件相对应的，标准C语言I/O使用putc写入字符，比如：1putc(ch,fp); 第一个参数是字符，第二个是文件指针。而fputs与此类似：1fputs(buf,fp); 仅仅是第一个参数换成了字符串地址。而fprintf与printf类似，增加了一个参数用于指定写入的文件，比如：1fprintf(stdout,&quot;Hello %s.\n&quot;,&quot;dennis&quot;); 切记fscanf和fprintf将FILE指针作为第一个参数，而putc,fputs则是作为第二个参数。 在文件IO中提供write函数用于写入文件，原型与read类似：1ssize_t result=write(int fd,void *buf ,size_t amt); fd是文件描述符，buf是将要写入的内存数据，amt是要写的字节数。如果写入成功返回写入的字节数，通过result与amt的比较可以判断是否写入正常，如果写入失败返回-1 随机存取：fseek()、ftell()和lseek()标准I/O使用fseek和ftell用于文件的随机存取，先看看fseek函数原型 int fseek(FILE *stream, long offset, int whence); 第一个参数是文件指针，第二个参数是一个long类型的偏移量（offset），表示从起始点开始移动的距离。第三个参数就是用于指定起始点的模式，stdio.h指定了下列模式常量：123SEEK_SET 文件开始处 SEEK_CUR 当前位置 SEEK_END 文件结尾处 看几个调用例子：123fseek(fp,0L,SEEK_SET); //找到文件的开始处 fseek(fp,0L,SEEK_END); //定位到文件结尾处 fseek(fp,2L,SEEK_CUR); //文件当前位置向前移动2个字节数 而ftell函数用于返回文件的当前位置，返回类型是一个long类型，比如下面的调用：12fseek(fp,0L,SEEK_END);//定位到结尾 long last=ftell(fp); //返回当前位置 那么此时的last就是文件指针fp指向的文件的字节数。 与标准I/O类似，*nix系统提供了lseek来完成fseek的功能，原型如下：1off_t lseek(int fildes, off_t offset, int whence); fildes是文件描述符，而offset也是偏移量，whence同样是指定起始点模式，唯一的不同是lseek有返回值，如果成功就 返回指针变化前的位置，否则返回-1。whence的取值与fseek相同：SEEK_SET,SEEK_CUR,SEEK_END，但也可以用整数 0,1,2相应代替。 系统调用与库函数上面我们一直在讨论文件I/O与标准I/O的区别，其实可以这样说，文件I/O是系统调用、标准I/O是库函数，看下面这张图： POSIX：Portable Operating System Interface 可移植操作系统接口 ANSI：American National Standrads Institute 美国国家标准学会 系统调用操作系统负责管理和分配所有的计算机资源。为了更好地服务于应用程序，操作系统提供了一组特殊接口——系统调用。通过这组接口用户程序可以使用操作系统内核提供的各种功能。例如分配内存、创建进程、实现进程之间的通信等。 为什么不允许程序直接访问计算机资源？答案是不安全。单片机开发中，由于不需要操作系统，所以开发人员可以编写代码直接访问硬件。而在32位嵌入式系统中通常都要运行操作系统，所以开发人员可以编写代码直接访问硬件。而在32位嵌入式系统中通常都要运行操作系统，程序访问资源的方式都发生了改变。操作系统基本上都支持多任务，即同时可以运行多个程序。如果允许程序直接访问系统资源，肯定会带来很多问题。因此，所有软硬件资源的管理和分配都有操作系统负责。程序要获取资源（如分配内存，读写串口）必须由操作系统来完成，即用户程序向操作系统发出服务请求，操作系统收到请求后执行相关的代码来处理。 用户程序向操作系统提出请求的接口就是系统调用。所有的操作系统都会提供系统调用接口，只不过不同的操作系统提供的系统调用接口各不相同。Linux 系统调用接口非常精简，它继承了Unix 系统调用中最基本的和最有用的部分。这些系统调用按照功能大致可分为进程控制、进程间通信、文件系统控制、存储管理、网络管理、套接字控制、用户管理等几类。 库函数库函数可以说是对系统调用的一种封装，因为系统调用是面对的是操作系统，系统包括Linux、Windows等，如果直接系统调用，会影响程序的移植性，所以这里使用了库函数，比如说C库，这样只要系统中安装了C库，就都可以使用这些函数，比如printf() scanf()等，C库相当于对系统函数进行了翻译，使我们的APP可以调用这些函数； 用户编程接口API前面提到利用系统调用接口程序可以访问各种资源，但在实际开发中程序并不直接使用系统调用接口，而是使用用户编程接口（API）。为什么不直接使用系统调用接口呢？ 原因如下： 系统调用接口功能非常简单，无法满足程序的需求。 不同操作系统的系统调用接口不兼容，程序移植时工作量大。 用户编程接口通俗的解释就是各种库（最重要的就是C库）中的函数。为了提高开发效率，C库中实现了很多函数。这些函数实现了常用的功能，供程序员调用。这样一来，程序员不需要自己编写这些代码，直接调用库函数就可以实现基本功能，提高了代码的复用率。使用用户编程接口还有一个好处：程序具有良好的可移植性。几乎所有的操作系统上都实现了C库，所以程序通常只需要重新编译一下就可以在其他操作系统下运行。 用户编程接口（API）在实现时，通常都要依赖系统调用接口。例如，创建进程的API函数fork()对应于内核空间的sys_fork()系统调用。很多API函数西亚我哦通过多个系统调用来完成其功能。还有一些API函数不要调用任何系统调用。 在Linux 中用户编程接口（API）遵循了在Unix中最流行的应用编程界面标准——POSIX标准。POSIX标准是由IEEE和ISO/IEC共同开发的标准系统。该标准基于当时想用的Unix 实践和经验，描述了操作系统的系统调用编程接口（实际上就是API），用于保证应用程序可以在源代码一级商多种操作系统上运行。这些系统调用编程接口主要是通过C库（libc )实现的。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位图（BitMap）索引]]></title>
    <url>%2F2019%2F05%2F01%2F%E4%BD%8D%E5%9B%BE%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[案例 有张表名为table的表，由三列组成，分别是姓名、性别和婚姻状况，其中性别只有男和女两项，婚姻状况由已婚、未婚、离婚这三项，该表共有100w个记录。现在有这样的查询： select * from table where Gender=‘男’ and Marital=“未婚”。 姓名(Name) 性别(Gender) 婚姻状况(Marital) 张三 男 已婚 李四 女 已婚 王五 男 未婚 赵六 女 离婚 孙七 女 未婚 不使用索引 不使用索引时，数据库只能一行行扫描所有记录，然后判断该记录是否满足查询条件。 B树索引 对于性别，可取值的范围只有’男’,’女’，并且男和女可能各站该表的50%的数据，这时添加B树索引还是需要取出一半的数据， 因此完全没有必要。相反，如果某个字段的取值范围很广，几乎没有重复，比如身份证号，此时使用B树索引较为合适。事实上，当取出的行数据占用表中大部分的数据时，即使添加了B树索引，数据库如oracle、mysql也不会使用B树索引，很有可能还是一行行全部扫描。 位图索引出马如果用户查询的列的基数非常的小， 即只有的几个固定值，如性别、婚姻状况、行政区等等。要为这些基数值比较小的列建索引，就需要建立位图索引。 对于性别这个列，位图索引形成两个向量，男向量为10100…，向量的每一位表示该行是否是男，如果是则位1，否为0，同理，女向量位01011。 RowId 1 2 3 4 5 … 男 1 0 1 0 0 女 0 1 0 1 1 对于婚姻状况这一列，位图索引生成三个向量，已婚为11000…，未婚为00100…，离婚为00010…。 RowId 1 2 3 4 5 … 已婚 1 1 0 0 0 未婚 0 0 1 0 1 离婚 0 0 0 1 0 当我们使用查询语句“select * from table where Gender=‘男’ and Marital=“未婚”;”的时候 首先取出男向量10100…，然后取出未婚向量00100…，将两个向量做and操作，这时生成新向量00100…，可以发现第三位为1，表示该表的第三行数据就是我们需要查询的结果。 RowId 1 2 3 4 5 男 1 0 1 0 0 未婚 0 0 1 0 1 结果 0 0 1 0 0 位图索引的适用条件上面讲了，位图索引适合只有几个固定值的列，如性别、婚姻状况、行政区等等，而身份证号这种类型不适合用位图索引。 此外，位图索引适合静态数据，而不适合索引频繁更新的列。举个例子，有这样一个字段busy，记录各个机器的繁忙与否，当机器忙碌时，busy为1，当机器不忙碌时，busy为0。 这个时候有人会说使用位图索引，因为busy只有两个值。好，我们使用位图索引索引busy字段！假设用户A使用update更新某个机器的busy值，比如update table set table.busy=1 where rowid=100;，但还没有commit，而用户B也使用update更新另一个机器的busy值，update table set table.busy=1 where rowid=12; 这个时候用户B怎么也更新不了，需要等待用户A commit。 原因：用户A更新了某个机器的busy值为1，会导致所有busy为1的机器的位图向量发生改变，因此数据库会将busy＝1的所有行锁定，只有commit之后才解锁。 源地址：http://www.cnblogs.com/LBSer]]></content>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的inode的理解]]></title>
    <url>%2F2019%2F05%2F01%2FLinux%E7%9A%84inode%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[inode是什么？理解inode，要从文件储存说起。文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。 操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。 文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。 inode的内容inode包含文件的元信息，具体来说有以下内容： 文件的字节数 文件拥有者的User ID 文件的Group ID 文件的读、写、执行权限 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。 链接数，即有多少文件名指向这个inode 文件数据block的位置 可以用stat命令，查看某个文件的inode信息：stat example.txt 总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。 inode的大小inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。 查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。1df -i 查看每个inode节点的大小，可以用如下命令：1sudo dumpe2fs -h /dev/hda | grep &quot;Inode size&quot; 由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。 inode号码每个inode都有一个号码，操作系统用inode号码来识别不同的文件。 这里值得重复一遍，Unix/Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。 使用ls -i命令，可以看到文件名对应的inode号码：1ls -i example.txt 目录文件Unix/Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。 目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。 ls命令只列出目录文件中的所有文件名：1ls /etc ls -i命令列出整个目录文件，即文件名和inode号码：1ls -i /etc 如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。1ls -l /etc 硬链接一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，多个文件名指向同一个inode号码。这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。 ln命令可以创建硬链接：1ln 源文件 目标文件 运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。 这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）,这里的2是父目录对其的“硬链接”和当前目录下的”.硬链接“。 软链接除了硬链接以外，还有一种特殊情况。文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。 这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。 ln -s命令可以创建软链接。ln -s 源文文件或目录 目标文件或目录 inode的特殊作用由于inode号码与文件名分离，这种机制导致了一些Unix/Linux系统特有的现象。 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。 移动文件或重命名文件，只是改变文件名，不影响inode号码。 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。 第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。 实际问题在一台配置较低的Linux服务器（内存、硬盘比较小）的/data分区内创建文件时，系统提示磁盘空间不足，用df -h命令查看了一下磁盘使用情况，发现/data分区只使用了66%，还有12G的剩余空间，按理说不会出现这种问题。 后来用df -i查看了一下/data分区的索引节点(inode)，发现已经用满(IUsed=100%)，导致系统无法创建新目录和文件。 查找原因： /data/cache目录中存在数量非常多的小字节缓存文件，占用的Block不多，但是占用了大量的inode。 解决方案： 删除/data/cache目录中的部分文件，释放出/data分区的一部分inode。 用软连接将空闲分区/opt中的newcache目录连接到/data/cache，使用/opt分区的inode来缓解/data分区inode不足的问题： ln -s /opt/newcache /data/cache]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux孤儿进程与僵尸进程]]></title>
    <url>%2F2019%2F05%2F01%2FLinux%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E4%B8%8E%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[基本概念我们知道在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程到底什么时候结束。 当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 问题及危害unix提供了一种机制可以保证只要父进程想知道子进程结束时的状态信息， 就可以得到。这种机制就是: 在每个进程退出的时候,内核释放该进程所有的资源,包括打开的文件,占用的内存等。 但是仍然为其保留一定的信息(包括进程号the process ID,退出状态the termination status of the process,运行时间the amount of CPU time taken by the process等)。直到父进程通过wait / waitpid来取时才释放。 但这样就导致了问题，如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了init进程身上，init进程就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤 儿进程的父进程设置为init，而init进程会循环地wait()它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init进程就会代表党和政府出面处理它的一切善后工作。因此孤儿进程并不会有什么危害。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 僵尸进程危害场景： 例如有个进程，它定期的产 生一个子进程，这个子进程需要做的事情很少，做完它该做的事情之后就退出了，因此这个子进程的生命周期很短，但是，父进程只管生成新的子进程，至于子进程 退出之后的事情，则一概不闻不问，这样，系统运行上一段时间之后，系统中就会存在很多的僵死进程，倘若用ps命令查看的话，就会看到很多状态为Z的进程。 严格地来说，僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的那个父进程。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大 量僵死进程的那个元凶枪毙掉（也就是通过kill发送SIGTERM或者SIGKILL信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程 就能瞑目而去了。 孤儿进程和僵尸进程测试孤儿进程测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;unistd.h&gt;int main()&#123; pid_t pid; //创建一个进程 pid = fork(); //创建失败 if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //子进程 if (pid == 0) &#123; printf(&quot;I am the child process.\n&quot;); //输出进程ID和父进程ID printf(&quot;pid: %d\tppid:%d\n&quot;,getpid(),getppid()); printf(&quot;I will sleep five seconds.\n&quot;); //睡眠5s，保证父进程先退出 sleep(5); printf(&quot;pid: %d\tppid:%d\n&quot;,getpid(),getppid()); printf(&quot;child process is exited.\n&quot;); &#125; //父进程 else &#123; printf(&quot;I am father process.\n&quot;); //父进程睡眠1s，保证子进程输出进程id sleep(1); printf(&quot;father process is exited.\n&quot;); &#125; return 0;&#125;pid=3906 ppid=3905pid=3906 ppid=1 僵尸进程测试程序如下所示：123456789101112131415161718192021222324252627#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;int main()&#123; pid_t pid; pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am child process.I am exiting.\n&quot;); exit(0); &#125; printf(&quot;I am father process.I will sleep two seconds\n&quot;); //等待子进程先退出 sleep(2); //输出进程信息 system(&quot;ps -o pid,ppid,state,tty,command&quot;); printf(&quot;father process is exiting.\n&quot;); return 0;&#125; 僵尸进程测试2：父进程循环创建子进程，子进程退出，造成多个僵尸进程，程序如下所示：1234567891011121314151617181920212223242526272829303132#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main()&#123; pid_t pid; //循环创建子进程 while(1) &#123; pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am a child process.\nI am exiting.\n&quot;); //子进程退出，成为僵尸进程 exit(0); &#125; else &#123; //父进程休眠20s继续创建子进程 sleep(20); continue; &#125; &#125; return 0;&#125; 僵尸进程解决办法通过信号机制子进程退出时向父进程发送SIGCHILD信号，父进程处理SIGCHILD信号。在信号处理函数中调用wait进行处理僵尸进程。测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;#include &lt;stdlib.h&gt;#include &lt;signal.h&gt;static void sig_child(int signo);int main()&#123; pid_t pid; //创建捕捉子进程退出信号 signal(SIGCHLD,sig_child); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; else if (pid == 0) &#123; printf(&quot;I am child process,pid id %d.I am exiting.\n&quot;,getpid()); exit(0); &#125; printf(&quot;I am father process.I will sleep two seconds\n&quot;); //等待子进程先退出 sleep(2); //输出进程信息 system(&quot;ps -o pid,ppid,state,tty,command&quot;); printf(&quot;father process is exiting.\n&quot;); return 0;&#125;static void sig_child(int signo)&#123; pid_t pid; int stat; //处理僵尸进程 while ((pid = waitpid(-1, &amp;stat, WNOHANG)) &gt;0) printf(&quot;child %d terminated.\n&quot;, pid);&#125; fork两次《Unix 环境高级编程》8.6节说的非常详细。原理是将子进程成为孤儿进程，从而其的父进程变为init进程，通过init进程可以处理僵尸进程。测试程序如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;errno.h&gt;int main()&#123; pid_t pid; //创建第一个子进程 pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程 else if (pid == 0) &#123; //子进程再创建子进程 printf(&quot;I am the first child process.pid:%d\tppid:%d\n&quot;,getpid(),getppid()); pid = fork(); if (pid &lt; 0) &#123; perror(&quot;fork error:&quot;); exit(1); &#125; //第一个子进程退出 else if (pid &gt;0) &#123; printf(&quot;first procee is exited.\n&quot;); exit(0); &#125; //第二个子进程 //睡眠3s保证第一个子进程退出，这样第二个子进程的父亲就是init进程里 sleep(3); printf(&quot;I am the second child process.pid: %d\tppid:%d\n&quot;,getpid(),getppid()); exit(0); &#125; //父进程处理第一个子进程退出 if (waitpid(pid, NULL, 0) != pid) &#123; perror(&quot;waitepid error:&quot;); exit(1); &#125; exit(0); return 0;&#125;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode894. All Possible Full Binary Trees]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode894%2F</url>
    <content type="text"><![CDATA[A full binary tree is a binary tree where each node has exactly 0 or 2 children. Return a list of all possible full binary trees with N nodes. Each element of the answer is the root node of one possible tree. Each node of each tree in the answer must have node.val = 0. You may return the final list of trees in any order. Example 1:12Input: 7Output: [[0,0,0,null,null,0,0,null,null,0,0],[0,0,0,null,null,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,null,null,null,null,0,0],[0,0,0,0,0,null,null,0,0]] Explanation: 给出了个N，代表一棵二叉树有N个节点，求所能构成的树。 解题方法所有能构成的树，并且返回的不是数目，而是真正的树。所以一定会把所有的节点都求出来。一般就使用了递归。 这个题中，重点是返回一个列表，也就是说每个能够成的树的根节点都要放到这个列表里。而且当左子树、右子树的节点个数固定的时候，也会出现排列组合的情况，所以使用了两重for循环来完成所有的左右子树的组合。 另外的一个技巧就是，左右子树的个数一定是奇数个。 递归方法，虽然比较慢，但是容易理解，就是组成小的子树，一个个拼接，为啥要减1，是因为一定会有个根节点，先把这个减去再说。 代码如下：12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: vector&lt;TreeNode*&gt; allPossibleFBT(int N) &#123; N--; vector&lt;TreeNode*&gt; res; if(N==0)&#123; res.push_back(new TreeNode(0)); return res; &#125; for (int i = 1; i &lt; N; i += 2) &#123; for (auto&amp; left : allPossibleFBT(i)) &#123; for (auto&amp; right : allPossibleFBT(N - i)) &#123; TreeNode* root = new TreeNode(0); root-&gt;left = left; root-&gt;right = right; res.push_back(root); &#125; &#125; &#125; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode461. Hamming Distance]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode461%2F</url>
    <content type="text"><![CDATA[Hamming Distance The Hamming distance between two integers is the number of positions at which the corresponding bits are different. Given two integers x and y, calculate the Hamming distance. Note:0 ≤ x, y &lt; 231. Example:12345678Input: x = 1, y = 4Output: 2Explanation:1 (0 0 0 1)4 (0 1 0 0) ↑ ↑ The above arrows point to positions where the corresponding bits are different. 求两个数的海明距离，就是判断其二进制有多少不一样的位12345678910class Solution &#123;public: int hammingDistance(int x, int y) &#123; int temp = x ^ y; int res=0; for(int i=temp;i&gt;0;i=i&gt;&gt;1) if(i&amp;1) res++; return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode814. Binary Tree Pruning]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode814%2F</url>
    <content type="text"><![CDATA[We are given the head node root of a binary tree, where additionally every node’s value is either a 0 or a 1. Return the same tree where every subtree (of the given tree) not containing a 1 has been removed. (Recall that the subtree of a node X is X, plus every node that is a descendant of X.) Example 1:Input: [1,null,0,0,1]Output: [1,null,0,null,1] Explanation:Only the red nodes satisfy the property “every subtree not containing a 1”.The diagram on the right represents the answer. Example 2:Input: [1,0,1,0,0,0,1]Output: [1,null,1,null,1] Example 3:Input: [1,1,0,1,1,0,1,0]Output: [1,1,0,1,1,null,1] Note: The binary tree will have at most 100 nodes.The value of each node will only be 0 or 1. 删掉子树里没有1的，返回这棵树。1234567891011121314151617181920212223242526/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: bool dele(TreeNode* root)&#123; if(root == NULL) return false; bool a1=dele(root-&gt;left); bool a2=dele(root-&gt;right); if(!a1) root-&gt;left=NULL; if(!a2) root-&gt;right=NULL; return root-&gt;val==1 || a1 || a2; &#125; TreeNode* pruneTree(TreeNode* root) &#123; return dele(root)?root:NULL; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode890. Find and Replace Pattern]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode890%2F</url>
    <content type="text"><![CDATA[You have a list of words and a pattern, and you want to know which words in words matches the pattern. A word matches the pattern if there exists a permutation of letters p so that after replacing every letter x in the pattern with p(x), we get the desired word. (Recall that a permutation of letters is a bijection from letters to letters: every letter maps to another letter, and no two letters map to the same letter.) Return a list of the words in words that match the given pattern. You may return the answer in any order. Example 1:12345Input: words = [&quot;abc&quot;,&quot;deq&quot;,&quot;mee&quot;,&quot;aqq&quot;,&quot;dkd&quot;,&quot;ccc&quot;], pattern = &quot;abb&quot;Output: [&quot;mee&quot;,&quot;aqq&quot;]Explanation: &quot;mee&quot; matches the pattern because there is a permutation &#123;a -&gt; m, b -&gt; e, ...&#125;. &quot;ccc&quot; does not match the pattern because &#123;a -&gt; c, b -&gt; c, ...&#125; is not a permutation,since a and b map to the same letter. Note: 1 &lt;= words.length &lt;= 501 &lt;= pattern.length = words[i].length &lt;= 20 12345678910111213141516171819202122232425262728293031323334353637383940class Solution &#123;public: bool match(string word,string pattern)&#123; int i,j; bool seen[26]; map&lt;char,char&gt; table; map&lt;char, char&gt;::iterator it; for(i=0;i&lt;26;i++) seen[i]=false; for(j=0;j&lt;word.length();j++)&#123; it = table.find(word[j]); if(it==table.end())&#123; table[word[j]]=pattern[j]; &#125; if(table[word[j]]!=pattern[j] ) return false; &#125; for(i=0;i&lt;26;i++) seen[i]=false; for(it=table.begin();it!=table.end();it++)&#123; if(seen[it-&gt;second-&apos;a&apos;]) return false; seen[it-&gt;second-&apos;a&apos;]=true; &#125; return true; &#125; vector&lt;string&gt; findAndReplacePattern(vector&lt;string&gt;&amp; words, string pattern) &#123; vector&lt;string&gt; res; int i,j; for(i=0;i&lt;words.size();i++)&#123; if(match(words[i],pattern)) res.push_back(words[i]); &#125; return res; &#125;&#125;; 这个题判断给定的字符串是不是符合pattern串的模式，很简单的题搞复杂了。用了一个map来匹配字符组合，用seen判断这个pattern字符是否出现过，如果出现过就是非法的了。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode657. Robot Return to Origin]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode657%2F</url>
    <content type="text"><![CDATA[Robot Return to Origin There is a robot starting at position (0, 0), the origin, on a 2D plane. Given a sequence of its moves, judge if this robot ends up at (0, 0) after it completes its moves. The move sequence is represented by a string, and the character moves[i] represents its ith move. Valid moves are R (right), L (left), U (up), and D (down). If the robot returns to the origin after it finishes all of its moves, return true. Otherwise, return false. Note: The way that the robot is “facing” is irrelevant. “R” will always make the robot move to the right once, “L” will always make it move left, etc. Also, assume that the magnitude of the robot’s movement is the same for each move. Example 1: Input: “UD”Output: trueExplanation: The robot moves up once, and then down once. All moves have the same magnitude, so it ended up at the origin where it started. Therefore, we return true. Example 2: Input: “LL”Output: falseExplanation: The robot moves left twice. It ends up two “moves” to the left of the origin. We return false because it is not at the origin at the end of its moves. 一个序列，判断‘L’和‘R’是不是个数相等，‘U’和‘D’是不是个数相等。12345678910111213141516class Solution &#123;public: bool judgeCircle(string moves) &#123; int ud=0,lr=0; for(int i=0;i&lt;moves.length();i++)&#123; if(moves[i]==&apos;U&apos;) ud++; else if(moves[i]==&apos;D&apos;) ud--; else if(moves[i]==&apos;L&apos;) lr++; else if(moves[i]==&apos;R&apos;) lr--; &#125; if(ud==0 &amp;&amp; lr==0) return true; else return false; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode950. Reveal Cards In Increasing Order]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode950%2F</url>
    <content type="text"><![CDATA[Reveal Cards In Increasing Order In a deck of cards, every card has a unique integer. You can order the deck in any order you want. Initially, all the cards start face down (unrevealed) in one deck. Now, you do the following steps repeatedly, until all cards are revealed: Take the top card of the deck, reveal it, and take it out of the deck.If there are still cards in the deck, put the next top card of the deck at the bottom of the deck.If there are still unrevealed cards, go back to step 1. Otherwise, stop.Return an ordering of the deck that would reveal the cards in increasing order. The first entry in the answer is considered to be the top of the deck. Example 1:12345678910111213141516171819202122232425262728293031Input: [17,13,11,2,3,5,7]Output: [2,13,3,11,5,17,7]Explanation: We get the deck in the order [17,13,11,2,3,5,7] (this order doesn&apos;t matter), and reorder it.After reordering, the deck starts as [2,13,3,11,5,17,7], where 2 is the top of the deck.We reveal 2, and move 13 to the bottom. The deck is now [3,11,5,17,7,13].We reveal 3, and move 11 to the bottom. The deck is now [5,17,7,13,11].We reveal 5, and move 17 to the bottom. The deck is now [7,13,11,17].We reveal 7, and move 13 to the bottom. The deck is now [11,17,13].We reveal 11, and move 17 to the bottom. The deck is now [13,17].We reveal 13, and move 17 to the bottom. The deck is now [17].We reveal 17.Since all the cards revealed are in increasing order, the answer is correct.``` Note:1 &lt;= A.length &lt;= 10001 &lt;= A[i] &lt;= 10^6A[i] != A[j] for all i != jwoc什么乱七八糟的题，这个确实没懂。从牌组顶部抽一张牌，显示它，然后将其从牌组中移出。如果牌组中仍有牌，则将下一张处于牌组顶部的牌放在牌组的底部。如果仍有未显示的牌，那么返回步骤 1。否则，停止行动。得到的序列要求是递增序列。例如 1 3 2 通过上述变换，可以得到1 2 3，满足题目要求。解法是：1 2 3 通过上述变换，可以得到 1 3 2，即这道题的解。 class Solution {public: vector deckRevealedIncreasing(vector&amp; deck) { queue q; vector res(deck.size()); sort(deck.begin(),deck.end()); for(int i=0;i&lt;deck.size();i++) q.push(i); for(int i=0;i&lt;deck.size();i++) { int temp = q.front(); res[temp]=deck[i]; q.pop(); temp = q.front(); q.push(temp); q.pop(); } return res; } };`]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode980. Unique Paths III]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode980%2F</url>
    <content type="text"><![CDATA[Unique Paths IIIHard On a 2-dimensional grid, there are 4 types of squares: 1 represents the starting square. There is exactly one starting square.2 represents the ending square. There is exactly one ending square.0 represents empty squares we can walk over.-1 represents obstacles that we cannot walk over.Return the number of 4-directional walks from the starting square to the ending square, that walk over every non-obstacle square exactly once. Example 1:12345Input: [[1,0,0,0],[0,0,0,0],[0,0,2,-1]]Output: 2Explanation: We have the following two paths: 1. (0,0),(0,1),(0,2),(0,3),(1,3),(1,2),(1,1),(1,0),(2,0),(2,1),(2,2)2. (0,0),(1,0),(2,0),(2,1),(1,1),(0,1),(0,2),(0,3),(1,3),(1,2),(2,2) Example 2:1234567Input: [[1,0,0,0],[0,0,0,0],[0,0,0,2]]Output: 4Explanation: We have the following four paths: 1. (0,0),(0,1),(0,2),(0,3),(1,3),(1,2),(1,1),(1,0),(2,0),(2,1),(2,2),(2,3)2. (0,0),(0,1),(1,1),(1,0),(2,0),(2,1),(2,2),(1,2),(0,2),(0,3),(1,3),(2,3)3. (0,0),(1,0),(2,0),(2,1),(2,2),(1,2),(1,1),(0,1),(0,2),(0,3),(1,3),(2,3)4. (0,0),(1,0),(2,0),(2,1),(1,1),(0,1),(0,2),(0,3),(1,3),(1,2),(2,2),(2,3) Example 3:12345Input: [[0,1],[2,0]]Output: 0Explanation: There is no path that walks over every empty square exactly once.Note that the starting and ending square can be anywhere in the grid. Note: 1 &lt;= grid.length * grid[0].length &lt;= 20 给了一个二维矩阵，1代表起点，2代表终点，0代表可以走的格子，-1代表障碍物。求从起点到终点，把所有的可以走的格子都遍历一遍，所有可能的不同路径数。 1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; dirs = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;; int uniquePathsIII(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int M=grid.size(); int zerosize=0,res=0; int N=grid[0].size(); for(int i=0;i&lt;M;i++) for(int j=0;j&lt;N;j++) if(grid[i][j]==0) zerosize++; for(int i=0;i&lt;M;i++) for(int j=0;j&lt;N;j++) if(grid[i][j]==1) dfs(grid,i,j,0,zerosize,res); return res; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int x, int y, int pathcount, int zerocount, int&amp; res)&#123; if(grid[x][y]==2 &amp;&amp; zerocount == pathcount )&#123; res++; &#125; int M=grid.size(); int N=grid[0].size(); int pre=grid[x][y]; if(pre==0) pathcount++; grid[x][y]=-1; for (auto d : dirs) &#123; int nx = x + d.first; int ny = y + d.second; if (nx &lt; 0 || nx &gt;= M || ny &lt; 0 || ny &gt;= N || grid[nx][ny] == -1) continue; dfs(grid, nx, ny, pathcount, zerocount, res); &#125; grid[x][y]=pre; &#125; &#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode832. Flipping an Image]]></title>
    <url>%2F2019%2F04%2F29%2FLeetcode832%2F</url>
    <content type="text"><![CDATA[Flipping an ImageGiven a binary matrix A, we want to flip the image horizontally, then invert it, and return the resulting image. To flip an image horizontally means that each row of the image is reversed. For example, flipping [1, 1, 0] horizontally results in [0, 1, 1]. To invert an image means that each 0 is replaced by 1, and each 1 is replaced by 0. For example, inverting [0, 1, 1] results in [1, 0, 0]. Example 1:1234Input: [[1,1,0],[1,0,1],[0,0,0]]Output: [[1,0,0],[0,1,0],[1,1,1]]Explanation: First reverse each row: [[0,1,1],[1,0,1],[0,0,0]].Then, invert the image: [[1,0,0],[0,1,0],[1,1,1]] Example 2:1234Input: [[1,1,0,0],[1,0,0,1],[0,1,1,1],[1,0,1,0]]Output: [[1,1,0,0],[0,1,1,0],[0,0,0,1],[1,0,1,0]]Explanation: First reverse each row: [[0,0,1,1],[1,0,0,1],[1,1,1,0],[0,1,0,1]].Then invert the image: [[1,1,0,0],[0,1,1,0],[0,0,0,1],[1,0,1,0]] Notes: 1 &lt;= A.length = A[0].length &lt;= 200 &lt;= A[i][j] &lt;= 1 没啥好说的，普通的矩阵操作。 1234567891011121314151617class Solution &#123;public: vector&lt;vector&lt;int&gt; &gt; flipAndInvertImage(vector&lt;vector&lt;int&gt; &gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++)&#123; for(int j=0,k=A[i].size()-1;j&lt;A[i].size()/2;j++,k--)&#123; int temp = A[i][j]; A[i][j]=A[i][k]; A[i][k]=temp; &#125; for(int j=0,k=A[i].size()-1;j&lt;A[i].size();j++,k--)&#123; A[i][j]=1-A[i][j]; &#125; &#125; return A; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核分析笔记----中断和中断处理程序]]></title>
    <url>%2F2019%2F04%2F29%2FLinux%E5%86%85%E6%A0%B8%E5%88%86%E6%9E%90-%E4%B8%AD%E6%96%AD%E5%92%8C%E4%B8%AD%E6%96%AD%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[原文：http://www.cnblogs.com/hanyan225/archive/2011/07/17/2108609.html 中断还是中断，我讲了很多次的中断了，今天还是要讲中断，为啥呢？因为在操作系统中，中断是必须要讲的.. 那么什么叫中断呢， 中断还是打断，这样一说你就不明白了。唉，中断还真是有点像打断。我们知道linux管理所有的硬件设备，要做的第一件事先是通信。然后，我们天天在说一句话：处理器的速度跟外围硬件设备的速度往往不在一个数量级上，甚至几个数量级的差别，这时咋办，你总不能让处理器在那里傻等着你硬件做好了告诉我一声吧。这很容易就和日常生活联系起来了，这样效率太低，不如我处理器做别的事情，你硬件设备准备好了，告诉我一声就得了。这个告诉，咱们说的轻松，做起来还是挺费劲啊！怎么着，简单一点，轮训(polling)可能就是一种解决方法，缺点是操作系统要做太多的无用功，在那里傻傻的做着不重要而要重复的工作，这里有更好的办法—中断，这个中断不要紧，关键在于从硬件设备的角度上看，已经实现了从被动为主动的历史性突破。 中断的例子我就不说了，这个很显然啊。分析中断，本质上是一种特殊的电信号，由硬件设备发向处理器，处理器接收到中断后，会马上向操作系统反应此信号的带来，然后就由OS负责处理这些新到来的数据，中断可以随时发生，才不用操心与处理器的时间同步问题。不同的设备对应的中断不同，他们之间的不同从操作系统级来看，差别就在于一个数字标识—–中断号。专业一点就叫中断请求(IRQ)线,通常IRQ都是一些数值量。有些体系结构上，中断好是固定的，有的是动态分配的，这不是问题所在，问题在于特定的中断总是与特定的设备相关联，并且内核要知道这些信息，这才是最关键的,不是么？哈哈. 用书上一句话说：讨论中断就不得不提及异常，异常和中断不一样，它在产生时必须要考虑与处理器的时钟同步，实际上，异常也常常称为同步中断，在处理器执行到由于编程失误而导致的错误指令的时候，或者是在执行期间出现特殊情况，必须要靠内核来处理的时候，处理器就会产生一个异常。因为许多处理器体系结构处理异常以及处理中断的方式类似，因此，内核对它们的处理也很类似。这里的讨论，大部分都是适合异常，这时可以看成是处理器本身产生的中断。 中断产生告诉中断控制器，继续告诉操作系统内核，内核总是要处理的，是不？这里内核会执行一个叫做中断处理程序或中断处理例程的函数。这里特别要说明，中断处理程序是和特定中断相关联的，而不是和设备相关联，如果一个设备可以产生很多中断，这时该设备的驱动程序也就需要准备多个这样的函数。一个中断处理程序是设备驱动程序的一部分，这个我们在linux设备驱动中已经说过，就不说了，后面我也会提到一些。前边说过一个问题：中断是可能随时发生的，因此必须要保证中断处理程序也能随时执行，中断处理程序也要尽可能的快速执行，只有这样才能保证尽可能快地恢复中断代码的执行。 但是，不想说但是，大学第一节逃课的情形现在仍记忆犹新：又想马儿跑，又想马儿不吃草，怎么可能！但现实问题或者不像想象那样悲观，我们的中断说不定还真有奇迹发生。这个奇迹就是将中断处理切为两个部分或两半。中断处理程序上半部(top half)—接收到一个中断，它就立即开始开始执行，但只做严格时限的工作，这些工作都是在所有中断被禁止的情况下完成的。同时，能够被允许稍后完成的工作推迟到下半部(bottom half)去，此后，下半部会被执行，通常情况下，下半部都会在中断处理程序返回时立即执行。我会在后面谈论linux所提供的是实现下半部的各种机制。 说了那么多，现在开始第一个问题：如何注册一个中断处理程序。我们在linux驱动程序理论里讲过，通过一下函数可注册一个中断处理程序： 1int request_irq(unsigned int irq,irqreturn_t (*handler)(int, void *,struct pt_regs *),unsigned long irqflags,const char * devname,void *dev_id) 有关这个中断的一些参数说明，我就不说了，一旦注册了一个中断处理程序，就肯定会有释放中断处理，这是调用下列函数： 1void free_irq(unsigned int irq, void *dev_id) 这里需要说明的就是要必须要从进程上下文调用free_irq().好了，现在给出一个例子来说明这个过程,首先声明一个中断处理程序： 1static irqreturn_t intr_handler(int irq, void *dev_id, struct pt_regs *regs) 注意：这里的类型和前边说到的request_irq()所要求的参数类型是匹配的，参数不说了。对于返回值，中断处理程序的返回值是一个特殊类型，irqrequest_t,可能返回两个特殊的值：IRQ_NONE和IRQ_HANDLED.当中断处理程序检测到一个中断时，但该中断对应的设备并不是在注册处理函数期间指定的产生源时，返回IRQ_NONE;当中断处理程序被正确调用，且确实是它所对应的设备产生了中断时，返回IRQ_HANDLED.C此外，也可以使用宏IRQ_RETVAL(x)，如果x非0值，那么该宏返回IRQ_HANDLED,否则，返回IRQ_NONE.利用这个特殊的值，内核可以知道设备发出的是否是一种虚假的(未请求)中断。如果给定中断线上所有中断处理程序返回的都是IRQ_NONE，那么，内核就可以检测到出了问题。最后，需要说明的就是那个static了，中断处理程序通常会标记为static，因为它从来不会被别的文件中的代码直接调用。另外，中断处理程序是无需重入的，当一个给定的中断处理程序正在执行时，相应的中断线在所有处理器上都会被屏蔽掉，以防止在同一个中断上接收另外一个新的中断。通常情况下，所有其他的中断都是打开的，所以这些不同中断线上的其他中断都能被处理，但当前中断总是被禁止的。由此可见，同一个中断处理程序绝对不会被同时调用以处理嵌套的中断。 下面要说到的一个问题是和共享的中断处理程序相关的。共享和非共享在注册和运行方式上比较相似的。差异主要有以下几点： request_irq()的参数flags必须设置为SA_SHIRQ标志。 对每个注册的中断处理来说，dev_id参数必须唯一。指向任一设备结构的指针就可以满足这一要求。通常会选择设备结构，因为它是唯一的，而且中断处理程序可能会用到它，不能给共享的处理程序传递NULL值。 中断处理程序必须能够区分它的设备是否真的产生了中断。这既需要硬件的支持，也需要处理程序有相关的处理逻辑。如果硬件不支持这一功能，那中断处理程序肯定会束手无策，它根本没法知道到底是否与它对应的设备发生了中断，还是共享这条中断线的其他设备发出了中断。 在指定SA_SHIRQ标志以调用request_irq()时，只有在以下两种情况下才能成功：中断当前未被注册或者在该线上的所有已注册处理程序都指定了SA_SHIRQ.A。注意，在这一点上2.6与以前的内核是不同的，共享的处理程序可以混用SA_INTERRUPT. 一旦内核接收到一个中断后，它将依次调用在该中断线上注册的每一个处理程序。因此一个处理程序必须知道它是否应该为这个中断负责。如果与它相关的设备并没有产生中断，那么中断处理程序应该立即退出，这需要硬件设备提供状态寄存器(或类似机制)，以便中断处理程序进行检查。毫无疑问，大多数设备都提这种功能。 当执行一个中断处理程序或下半部时，内核处于中断上下文(interrupt context)中。对比进程上下文，进程上下文是一种内核所处的操作模式，此时内核代表进程执行，可以通过current宏关联当前进程。此外，因为进程是进程上下文的形式连接到内核中，因此，在进程上下文可以随时休眠，也可以调度程序。但中断上下文却完全不是这样，它可以休眠，因为我们不能从中断上下文中调用函数。如果一个函数睡眠，就不能在中断处理程序中使用它，这也是对什么样的函数能在中断处理程序中使用的限制。还需要说明一点的是，中断处理程序没有自己的栈，相反，它共享被中断进程的内核栈，如果没有正在运行的进程，它就使用idle进程的栈。因为中断程序共享别人的堆栈，所以它们在栈中获取空间时必须非常节省。内核栈在32位体系结构上是8KB，在64位体系结构上是16KB.执行的进程上下文和产生的所有中断都共享内核栈。 下面给出中断从硬件到内核的路由过程(截图选自liuux内核分析与设计p61)，然后做出总结： 上面的图内部说明已经很明确了，我这里就不在详谈。在内核中，中断的旅程开始于预定义入口点，这类似于系统调用。对于每条中断线，处理器都会跳到对应的一个唯一的位置。这样，内核就可以知道所接收中断的IRQ号了。初始入口点只是在栈中保存这个号，并存放当前寄存器的值(这些值属于被中断的任务)；然后，内核调用函数do_IRQ().从这里开始，大多数中断处理代码是用C写的。do_IRQ()的声明如下：1unsigned int do_IRQ(struct pt_regs regs) 因为C的调用惯例是要把函数参数放在栈的顶部，因此pt_regs结构包含原始寄存器的值，这些值是以前在汇编入口例程中保存在栈上的。中断的值也会得以保存，所以，do_IRQ()可以将它提取出来，X86的代码为： 1int irq = regs.orig_eax &amp; 0xff 计算出中断号后，do_IRQ()对所接收的中断进行应答，禁止这条线上的中断传递。在普通的PC机器上，这些操作是由mask_and_ack_8259A()来完成的，该函数由do_IRQ()调用。接下来，do_IRQ()需要确保在这条中断线上有一个有效的处理程序，而且这个程序已经启动但是当前没有执行。如果这样的话， do_IRQ()就调用handle_IRQ_event()来运行为这条中断线所安装的中断处理程序，有关处理例子，可以参考linux内核设计分析一书，我这里就不细讲了。在handle_IRQ_event()中，首先是打开处理器中断，因为前面已经说过处理器上所有中断这时是禁止中断(因为我们说过指定SA_INTERRUPT)。接下来，每个潜在的处理程序在循环中依次执行。如果这条线不是共享的，第一次执行后就退出循环，否则，所有的处理程序都要被执行。之后，如果在注册期间指定了SA_SAMPLE_RANDOM标志，则还要调用函数add_interrupt_randomness(),这个函数使用中断间隔时间为随机数产生熵。最后，再将中断禁止(do_IRQ()期望中断一直是禁止的)，函数返回。该函数做清理工作并返回到初始入口点，然后再从这个入口点跳到函数ret_from_intr().该函数类似初始入口代码，以汇编编写，它会检查重新调度是否正在挂起，如果重新调度正在挂起，而且内核正在返回用户空间(也就是说，中断了用户进程)，那么schedule()被调用。如果内核正在返回内核空间(也就是中断了内核本身)，只有在preempt_count为0时，schedule()才会被调用(否则，抢占内核是不安全的)。在schedule()返回之前，或者如果没有挂起的工作，那么，原来的寄存器被恢复，内核恢复到曾经中断的点。在x86上，初始化的汇编例程位于arch/i386/kernel/entry.S,C方法位于arch/i386/kernel/irq.c其它支持的结构类似。 下边给出PC机上位于/proc/interrupts文件的输出结果，这个文件存放的是系统中与中断相关的统计信息，这里就解释一下这个表： 上面是这个文件的输入，第一列是中断线(中断号)，第二列是一个接收中断数目的计数器，第三列是处理这个中断的中断控制器，最后一列是与这个中断有关的设备名字，这个名字是通过参数devname提供给函数request_irq()的。最后，如果中断是共享的，则这条中断线上注册的所有设备都会列出来，如4号中断。 Linux内核给我们提供了一组接口能够让我们控制机器上的中断状态，这些接口可以在&lt;asm/system.h&gt;和&lt;asm/irq.h&gt;中找到。一般来说，控制中断系统的原因在于需要提供同步，通过禁止中断，可以确保某个中断处理程序不会抢占当前的代码。此外，禁止中断还可以禁止内核抢占。然而，不管是禁止中断还是禁止内核抢占，都没有提供任何保护机制来防止来自其他处理器的并发访问。Linux支持多处理器，因此，内核代码一般都需要获取某种锁，防止来自其他处理器对共享数据的并发访问，获取这些锁的同时也伴随着禁止本地中断。锁提供保护机制，防止来自其他处理器的并发访问，而禁止中断提供保护机制，则是防止来自其他中断处理程序的并发访问。 在linux设备驱动理论帖里详细介绍过linux的中断操作接口，这里就大致过一下，禁止/使能本地中断(仅仅是当前处理器)用：12local_irq_disable();local_irq_enable(); 如果在调用local_irq_disable()之前已经禁止了中断，那么该函数往往会带来潜在的危险，同样的local_irq_enable()也存在潜在的危险，因为它将无条件的激活中断，尽管中断可能在开始时就是关闭的。所以我们需要一种机制把中断恢复到以前的状态而不是简单地禁止或激活，内核普遍关心这点，是因为内核中一个给定的代码路径可以在中断激活饿情况下达到，也可以在中断禁止的情况下达到，这取决于具体的调用链。面对这种情况，在禁止中断之前保存中断系统的状态会更加安全一些。相反，在准备激活中断时，只需把中断恢复到它们原来的状态： 123unsigned long flags;local_irq_save(flags);local_irq_restore(flags); 参数包含具体体系结构的数据，也就是包含中断系统的状态。至少有一种体系结构把栈信息与值相结合(SPARC),因此flags不能传递给另一个函数(换句话说，它必须驻留在同一个栈帧中)，基于这个原因，对local_irq_save()的调用和local_irq_restore()的调用必须在同一个函数中进行。前面的所有的函数既可以在中断中调用，也可以在进程上下文使用。 前面我提到过禁止整个CPU上所有中断的函数。但有时候，好奇的我就想，我干么没要禁止掉所有的中断，有时，我只需要禁止系统中一条特定的中断就可以了(屏蔽掉一条中断线)，这就有了我下面给出的接口： 1234void disable_irq(unsigned int irq);void disable_irq_nosync(unsigned int irq);void enable_irq(unsigned int irq);void synchronise_irq(unsigned int irq); 对有关函数的说明和注意，我前边已经说的很清楚了，这里飘过。另外，禁止多个中断处理程序共享的中断线是不合适的。禁止中断线也就禁止了这条线上所有设备的中断传递，因此，用于新设备的驱动程序应该倾向于不使用这些接口。另外，我们也可以通过宏定义在&lt;asm/system.h&gt;中的宏irqs_disable()来获取中断的状态，如果中断系统被禁止，则它返回非0，否则，返回0；用定义在&lt;asm/hardirq.h&gt;中的两个宏in_interrupt()和in_irq()来检查内核的当前上下文的接口。由于代码有时要做一些像睡眠这样只能从进程上下文做的事，这时这两个函数的价值就体现出来了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[可重入和不可重入]]></title>
    <url>%2F2019%2F04%2F29%2F%E5%8F%AF%E9%87%8D%E5%85%A5%E5%92%8C%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%85%A5%2F</url>
    <content type="text"><![CDATA[可重入和不可重入 重入一般可以理解为一个函数在同时多次调用，例如操作系统在进程调度过程中，或者单片机、处理器等的中断的时候会发生重入的现象。一般浮点运算都是由专门的硬件来完成，举个例子假设有个硬件寄存器名字叫做FLOAT，用来计算和存放浮点数的中间运算结果假设有这么个函数void fun(){//…这个函数对FLOAT寄存器进行操作}假如第一次执行，有个对浮点数操作运算的结果临时存在FLOAT寄存器中，而就在这时被中断了，而中断函数或者另一个进程也调用fun函数，这时第二次调用的fun函数在执行的过程中就会破坏第一次FLOAT寄存器中的结果，这样当返回到第一次fun函数的时候，结果就不正确了。 可以把fun函数理解为printf()函数。赞同 可重入和不可重入 这种情况出现在多任务系统当中，在任务执行期间捕捉到信号并对其进行处理时，进程正在执行的指令序列就被信号处理程序临时中断。如果从信号处理程序返回，则继续执行进程断点处的正常指令序列，从重新恢复到断点重新执行的过程中，函数所依赖的环境没有发生改变，就说这个函数是可重入的，反之就是不可重入的。众所周知，在进程中断期间，系统会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而函数内部使用的诸如全局或静态变量，buffer等并不在保护之列，所以如果这些值在函数被中断期间发生了改变，那么当函数回到断点继续执行时，其结果就不可预料了。打个比方，比如malloc，将如一个进程此时正在执行malloc分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个malloc，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用刚好覆盖了进程的操作，造成错误。 满足下面条件之一的多数是不可重入函数：(1)使用了静态数据结构;(2)调用了malloc或free;(3)调用了标准I/O函数;标准io库很多实现都以不可重入的方式使用全局数据结构。(4)进行了浮点运算.许多的处理器/编译器中，浮点一般都是不可重入的 (浮点运算大多使用协处理器或者软件模拟来实现。 1) 信号处理程序A内外都调用了同一个不可重入函数B；B在执行期间被信号打断，进入A (A中调用了B),完事之后返回B被中断点继续执行，这时B函数的环境可能改变，其结果就不可预料了。2) 多线程共享进程内部的资源，如果两个线程A，B调用同一个不可重入函数F，A线程进入F后，线程调度，切换到B，B也执行了F，那么当再次切换到线程A时，其调用F的结果也是不可预料的。在信号处理程序中即使调用可重入函数也有问题要注意。作为一个通用的规则，当在信号处理程序中调用可重入函数时，应当在其前保存errno，并在其后恢复errno。(因为每个线程只有一个errno变量，信号处理函数可能会修改其值，要了解经常被捕捉到的信号是SIGCHLD，其信号处理程序通常要调用一种wait函数，而各种wait函数都能改变errno。) 可重入函数列表: _exit（）、 access（）、alarm（）、cfgetispeed（）、cfgetospeed（）、cfsetispeed（）、cfsetospeed （）、chdir（）、chmod（）、chown（）、close（）、creat（）、dup（）、dup2（）、execle（）、 execve（）、fcntl（）、fork（）、fpathconf （）、fstat（）、fsync（）、getegid（）、 geteuid（）、getgid（）、getgroups（）、getpgrp（）、getpid（）、getppid（）、getuid（）、 kill（）、link（）、lseek（）、mkdir（）、mkfifo（）、 open（）、pathconf（）、pause（）、pipe（）、raise（）、read（）、rename（）、rmdir（）、setgid （）、setpgid（）、setsid（）、setuid（）、 sigaction（）、sigaddset（）、sigdelset（）、sigemptyset（）、sigfillset（）、 sigismember（）、signal（）、sigpending（）、sigprocmask（）、sigsuspend（）、sleep（）、 stat（）、sysconf（）、tcdrain（）、tcflow（）、tcflush（）、tcgetattr（）、tcgetpgrp（）、 tcsendbreak（）、tcsetattr（）、tcsetpgrp（）、time（）、times（）、 umask（）、uname（）、unlink（）、utime（）、wait（）、waitpid（）、write（）。 书上关于信号处理程序中调用不可重入函数的例子:12345678910111213141516171819202122232425262728#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;pwd.h&gt;static void func(int signo)&#123; struct passwd *rootptr; if( ( rootptr = getpwnam( &quot;root&quot; ) ) == NULL ) &#123; err_sys( &quot;getpwnam error&quot; ); &#125; signal(SIGALRM,func); alarm(1);&#125;int main(int argc, char** argv)&#123; signal(SIGALRM,func); alarm(1); for(;;) &#123; if( ( ptr = getpwnam(&quot;sar&quot;) ) == NULL ) &#123; err_sys( &quot;getpwnam error&quot; ); &#125; &#125; return 0;&#125; signal了一个SIGALRM,而后设置一个定时器，在for函数运行期间的某个时刻，也许就是在getpwnam函数运行期间，相应信号发生中断，进入信号处理函数func，在运行func期间又收到alarm发出的信号，getpwnam可能再次中断，这样就很容易发生不可预料的问题。 ================================================================================= 不可重入函数不可以在它还没有返回就再次被调用。例如printf，malloc，free等都是不可重入函数。因为中断可能在任何时候发生，例如在printf执行过程中，因此不能在中断处理函数里调用printf，否则printf将会被重入。 函数不可重入大多数是因为在函数中引用了全局变量。例如，printf会引用全局变量stdout，malloc，free会引用全局的内存分配表。 个人理解：如果中断发生的时候,当运行到printf的时候，假设发生了中断嵌套，而此时stdout资源被占用，所以第二个中断printf等待第一个中断的stdout资源释放，第一个中断等待第二个中断返回，造成了死锁，不知这样理解对不对。 不可重入函数指的是该函数在被调用还没有结束以前，再次被调用可能会产生错误。可重入函数不存在这样的问题。不可重入函数在实现时候通常使用了全局的资源，在多线程的环境下，如果没有很好的处理数据保护和互斥访问，就会发生错误。常见的不可重入函数有：printf ——–引用全局变量stdoutmalloc ——–全局内存分配表free ——–全局内存分配表在unix里面通常都有加上_r后缀的同名可重入函数版本。如果实在没有，不妨在可预见的发生错误的地方尝试加上保护锁同步机制等等。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode905. Sort Array By Parity]]></title>
    <url>%2F2019%2F04%2F26%2FLeetcode905%2F</url>
    <content type="text"><![CDATA[Sort Array By ParityEasy Given an array A of non-negative integers, return an array consisting of all the even elements of A, followed by all the odd elements of A. You may return any answer array that satisfies this condition. Example 1:123Input: [3,1,2,4]Output: [2,4,3,1]The outputs [4,2,3,1], [2,4,1,3], and [4,2,1,3] would also be accepted. Note: 1 &lt;= A.length &lt;= 50000 &lt;= A[i] &lt;= 5000 将奇数和偶数分类。。。简单 1234567891011121314151617class Solution &#123;public: vector&lt;int&gt; sortArrayByParity(vector&lt;int&gt;&amp; A) &#123; for(int i=0;i&lt;A.size();i++)&#123; if(A[i] % 2)&#123; for(int j=i+1;j&lt;A.size();j++)&#123; if(A[j]%2==0)&#123; int temp = A[j]; A[j] = A[i]; A[i] = temp; &#125; &#125; &#125; &#125; return A; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux awk命令详解]]></title>
    <url>%2F2019%2F04%2F24%2FLinux_awk%E5%91%BD%E4%BB%A4%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介awk是一个强大的文本分析工具，相对于grep的查找，sed的编辑，awk在其对数据分析并生成报告时，显得尤为强大。简单来说awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。 awk有3个不同版本: awk、nawk和gawk，未作特别说明，一般指gawk，gawk 是 AWK 的 GNU 版本。 awk其名称得自于它的创始人 Alfred Aho 、Peter Weinberger 和 Brian Kernighan 姓氏的首个字母。实际上 AWK 的确拥有自己的语言： AWK 程序设计语言 ， 三位创建者已将它正式定义为“样式扫描和处理语言”。它允许您创建简短的程序，这些程序读取输入文件、为数据排序、处理数据、对输入执行计算以及生成报表，还有无数其他的功能。 使用方法1awk &apos;&#123;pattern + action&#125;&apos; &#123;filenames&#125; 尽管操作可能会很复杂，但语法总是这样，其中 pattern 表示 AWK 在数据中查找的内容，而 action 是在找到匹配内容时所执行的一系列命令。花括号（{}）不需要在程序中始终出现，但它们用于根据特定的模式对一系列指令进行分组。 pattern就是要表示的正则表达式，用斜杠括起来。 awk语言的最基本功能是在文件或者字符串中基于指定规则浏览和抽取信息，awk抽取信息后，才能进行其他文本操作。完整的awk脚本通常用来格式化文本文件中的信息。 通常，awk是以文件的一行为处理单位的。awk每接收文件的一行，然后执行相应的命令，来处理文本。 调用awk有三种方式调用awk123456789101112131.命令行方式awk [-F field-separator] &apos;commands&apos; input-file(s)其中，commands 是真正awk命令，[-F域分隔符]是可选的。 input-file(s) 是待处理的文件。在awk中，文件的每一行中，由域分隔符分开的每一项称为一个域。通常，在不指名-F域分隔符的情况下，默认的域分隔符是空格。2.shell脚本方式将所有的awk命令插入一个文件，并使awk程序可执行，然后awk命令解释器作为脚本的首行，一遍通过键入脚本名称来调用。相当于shell脚本首行的：#!/bin/sh可以换成：#!/bin/awk3.将所有的awk命令插入一个单独文件，然后调用：awk -f awk-script-file input-file(s)其中，-f选项加载awk-script-file中的awk脚本，input-file(s)跟上面的是一样的。 本章重点介绍命令行方式。 入门实例假设last -n 5的输出如下123456[root@www ~]# last -n 5 &lt;==仅取出前五行root pts/1 192.168.1.100 Tue Feb 10 11:21 still logged inroot pts/1 192.168.1.100 Tue Feb 10 00:46 - 02:28 (01:41)root pts/1 192.168.1.100 Mon Feb 9 11:41 - 18:30 (06:48)dmtsai pts/1 192.168.1.100 Mon Feb 9 11:41 - 11:41 (00:00)root tty1 Fri Sep 5 14:09 - 14:10 (00:01) 如果只是显示最近登录的5个帐号123456#last -n 5 | awk &apos;&#123;print $1&#125;&apos;rootrootrootdmtsairoot awk工作流程是这样的：读入有’\n’换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域。默认域分隔符是”空白键” 或 “[tab]键”,所以$1表示登录用户，$3表示登录用户ip,以此类推。 如果只是显示/etc/passwd的账户12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&#125;&apos; rootdaemonbinsys 这种是awk+action的示例，每行都会执行action{print $1}。 -F指定域分隔符为’:’。 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以tab键分割12345#cat /etc/passwd |awk -F &apos;:&apos; &apos;&#123;print $1&quot;\t&quot;$7&#125;&apos;root /bin/bashdaemon /bin/shbin /bin/shsys /bin/sh 如果只是显示/etc/passwd的账户和账户对应的shell,而账户与shell之间以逗号分割,而且在所有行添加列名name,shell,在最后一行添加”blue,/bin/nosh”。12345678cat /etc/passwd |awk -F &apos;:&apos; &apos;BEGIN &#123;print &quot;name,shell&quot;&#125; &#123;print $1&quot;,&quot;$7&#125; END &#123;print &quot;blue,/bin/nosh&quot;&#125;&apos;name,shellroot,/bin/bashdaemon,/bin/shbin,/bin/shsys,/bin/sh....blue,/bin/nosh awk工作流程是这样的：先执行BEGING，然后读取文件，读入有/n换行符分割的一条记录，然后将记录按指定的域分隔符划分域，填充域，$0则表示所有域,$1表示第一个域,$n表示第n个域,随后开始执行模式所对应的动作action。接着开始读入第二条记录······直到所有的记录都读完，最后执行END操作。 搜索/etc/passwd有root关键字的所有行12#awk -F: &apos;/root/&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash 这种是pattern的使用示例，匹配了pattern(这里是root)的行才会执行action(没有指定action，默认输出每行的内容)。 搜索支持正则，例如找root开头的: awk -F: ‘/^root/‘ /etc/passwd 搜索/etc/passwd有root关键字的所有行，并显示对应的shell12# awk -F: &apos;/root/&#123;print $7&#125;&apos; /etc/passwd /bin/bash 这里指定了action{print $7} awk内置变量awk有许多内置变量用来设置环境信息，这些变量可以被改变，下面给出了最常用的一些变量。1234567891011ARGC 命令行参数个数ARGV 命令行参数排列ENVIRON 支持队列中系统环境变量的使用FILENAME awk浏览的文件名FNR 浏览文件的记录数FS 设置输入域分隔符，等价于命令行 -F选项NF 浏览记录的域的个数NR 已读的记录数OFS 输出域分隔符ORS 输出记录分隔符RS 控制记录分隔符 此外,$0变量是指整条记录。$1表示当前行的第一个域,$2表示当前行的第二个域,……以此类推。 统计/etc/passwd:文件名，每行的行号，每行的列数，对应的完整行内容:12345#awk -F &apos;:&apos; &apos;&#123;print &quot;filename:&quot; FILENAME &quot;,linenumber:&quot; NR &quot;,columns:&quot; NF &quot;,linecontent:&quot;$0&#125;&apos; /etc/passwdfilename:/etc/passwd,linenumber:1,columns:7,linecontent:root:x:0:0:root:/root:/bin/bashfilename:/etc/passwd,linenumber:2,columns:7,linecontent:daemon:x:1:1:daemon:/usr/sbin:/bin/shfilename:/etc/passwd,linenumber:3,columns:7,linecontent:bin:x:2:2:bin:/bin:/bin/shfilename:/etc/passwd,linenumber:4,columns:7,linecontent:sys:x:3:3:sys:/dev:/bin/sh 使用printf替代print,可以让代码更加简洁，易读1awk -F &apos;:&apos; &apos;&#123;printf(&quot;filename:%10s,linenumber:%s,columns:%s,linecontent:%s\n&quot;,FILENAME,NR,NF,$0)&#125;&apos; /etc/passwd print和printfawk中同时提供了print和printf两种打印输出的函数。 其中print函数的参数可以是变量、数值或者字符串。字符串必须用双引号引用，参数用逗号分隔。如果没有逗号，参数就串联在一起而无法区分。这里，逗号的作用与输出文件的分隔符的作用是一样的，只是后者是空格而已。 printf函数，其用法和c语言中printf基本相似,可以格式化字符串,输出复杂时，printf更加好用，代码更易懂。 awk编程变量和赋值除了awk的内置变量，awk还可以自定义变量。 下面统计/etc/passwd的账户人数1234awk &apos;&#123;count++;print $0;&#125; END&#123;print &quot;user count is &quot;, count&#125;&apos; /etc/passwdroot:x:0:0:root:/root:/bin/bash......user count is 40 count是自定义变量。之前的action{}里都是只有一个print,其实print只是一个语句，而action{}可以有多个语句，以;号隔开。 这里没有初始化count，虽然默认是0，但是妥当的做法还是初始化为0:12345awk &apos;BEGIN &#123;count=0;print &quot;[start]user count is &quot;, count&#125; &#123;count=count+1;print $0;&#125; END&#123;print &quot;[end]user count is &quot;, count&#125;&apos; /etc/passwd[start]user count is 0root:x:0:0:root:/root:/bin/bash...[end]user count is 40 统计某个文件夹下的文件占用的字节数12ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size&#125;&apos;[end]size is 8657198 如果以M为单位显示:12ls -l |awk &apos;BEGIN &#123;size=0;&#125; &#123;size=size+$5;&#125; END&#123;print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;&#125;&apos; [end]size is 8.25889 M 注意，统计不包括文件夹的子目录。 条件语句awk中的条件语句是从C语言中借鉴来的，见如下声明方式：12345678910111213141516171819if (expression) &#123; statement; statement; ... ...&#125;if (expression) &#123; statement;&#125; else &#123; statement2;&#125;if (expression) &#123; statement1;&#125; else if (expression1) &#123; statement2;&#125; else &#123; statement3;&#125; 统计某个文件夹下的文件占用的字节数,过滤4096大小的文件(一般都是文件夹):1234567891011ls -l |awk &apos;BEGIN &#123;size=0;print &quot;[start]size is &quot;, size&#125; &#123;if($5!=4096)&#123;size=size+$5;&#125;&#125; END&#123;print &quot;[end]size is &quot;, size/1024/1024,&quot;M&quot;&#125;&apos; [end]size is 8.22339 M``` ## 循环语句awk中的循环语句同样借鉴于C语言，支持while、do/while、for、break、continue，这些关键字的语义和C语言中的语义完全相同。## 数组因为awk中数组的下标可以是数字和字母，数组的下标通常被称为关键字(key)。值和关键字都存储在内部的一张针对key/value应用hash的表格里。由于hash不是顺序存储，因此在显示数组内容时会发现，它们并不是按照你预料的顺序显示出来的。数组和变量一样，都是在使用时自动创建的，awk也同样会自动判断其存储的是数字还是字符串。一般而言，awk中的数组用来从记录中收集信息，可以用于计算总和、统计单词以及跟踪模板被匹配的次数等等。显示/etc/passwd的账户 awk -F ‘:’ ‘BEGIN {count=0;} {name[count] = $1;count++;}; END{for (i = 0; i &lt; NR; i++) print i, name[i]}’ /etc/passwd0 root1 daemon2 bin3 sys4 sync5 games……`这里使用for循环遍历数组]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELF文件的加载和动态链接过程]]></title>
    <url>%2F2019%2F04%2F24%2FELF%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文：https://jzhihui.iteye.com/blog/1447570 本文的目的：大家对于Hello World程序应该非常熟悉，随便使用哪一种语言，即使还不熟悉的语言，写出一个Hello World程序应该毫不费力，但是如果让大家详细的说明这个程序加载和链接的过程，以及后续的符号动态解析过程，可能还会有点困难。本文就是以一个最基本的C语言版本Hello World程序为基础，了解Linux下ELF文件的格式，分析并验证ELF文件和加载和动态链接的具有实现。 123456789/* hello.c */ #include &lt;stdio.h&gt; int main() &#123; printf(“hello world!\n”); return 0; &#125; $ gcc –o hello hello.c 本文的实验平台： Ubuntu 7.04 Linux kernel 2.6.20 gcc 4.1.2 glibc 2.5 gdb 6.6 objdump/readelf 2.17.50 本文的组织： 第一部分大致描述ELF文件的格式； 第二部分分析ELF文件在内核空间的加载过程； 第三部分分析ELF文件在运行过程中符号的动态解析过程；（以上各部分都是以Hello World程序为例说明） 第四部分简要总结； 第五部分阐明需要深入了解的东西。 ELF文件格式概述Executable and Linking Format(ELF)文件是x86 Linux系统下的一种常用目标文件(object file)格式，有三种主要类型: 适于连接的可重定位文件(relocatable file)，可与其它目标文件一起创建可执行文件和共享目标文件。 适于执行的可执行文件(executable file)，用于提供程序的进程映像，加载的内存执行。 共享目标文件(shared object file)，连接器可将它与其它可重定位文件和共享目标文件连接成其它的目标文件，动态连接器又可将它与可执行文件和其它共享目标文件结合起来创建一个进程映像。 ELF文件格式比较复杂，本文只是简要介绍它的结构，希望能给想了解ELF文件结构的读者以帮助。具体详尽的资料请参阅专门的ELF文档。 文件格式为了方便和高效，ELF文件内容有两个平行的视角:一个是程序连接角度，另一个是程序运行角度，如图所示。 ELF header在文件开始处描述了整个文件的组织，Section提供了目标文件的各项信息（如指令、数据、符号表、重定位信息等），Program header table指出怎样创建进程映像，含有每个program header的入口，section header table包含每一个section的入口，给出名字、大小等信息。 数据表示 ELF数据编码顺序与机器相关，数据类型有六种，见下表： ELF文件头 像bmp、exe等文件一样，ELF的文件头包含整个文件的控制结构。它的定义如下：1234567891011121314151617#define EI_NIDENT 16 typedef struct elf32_hdr&#123; unsigned char e_ident[EI_NIDENT]; Elf32_Half e_type; /* file type */ Elf32_Half e_machine; /* architecture */ Elf32_Word e_version; Elf32_Addr e_entry; /* entry point */ Elf32_Off e_phoff; /* PH table offset */ Elf32_Off e_shoff; /* SH table offset */ Elf32_Word e_flags; Elf32_Half e_ehsize; /* ELF header size in bytes */ Elf32_Half e_phentsize; /* PH size */ Elf32_Half e_phnum; /* PH number */ Elf32_Half e_shentsize; /* SH size */ Elf32_Half e_shnum; /* SH number */ Elf32_Half e_shstrndx; /* SH name string table index */ &#125; Elf32_Ehdr; 其中E_ident的16个字节标明是个ELF文件（7F+’E’+’L’+’F’）。e_type表示文件类型，2表示可执行文件。e_machine说明机器类别，3表示386机器，8表示MIPS机器。e_entry给出进程开始的虚地址，即系统将控制转移的位置。e_phoff指出program header table的文件偏移，e_phentsize表示一个program header表中的入口的长度（字节数表示），e_phnum给出program header表中的入口数目。类似的，e_shoff，e_shentsize，e_shnum 分别表示section header表的文件偏移，表中每个入口的的字节数和入口数目。e_flags给出与处理器相关的标志，e_ehsize给出ELF文件头的长度（字节数表示）。e_shstrndx表示section名表的位置，指出在section header表中的索引。 Section Header目标文件的section header table可以定位所有的section，它是一个Elf32_Shdr结构的数组，Section头表的索引是这个数组的下标。有些索引号是保留的，目标文件不能使用这些特殊的索引。Section包含目标文件除了ELF文件头、程序头表、section头表的所有信息，而且目标文件section满足几个条件： 目标文件中的每个section都只有一个section头项描述，可以存在不指示任何section的section头项。每个section在文件中占据一块连续的空间。Section之间不可重叠。目标文件可以有非活动空间，各种headers和sections没有覆盖目标文件的每一个字节，这些非活动空间是没有定义的。Section header结构定义如下：123456789101112typedef struct &#123; Elf32_Word sh_name; /* name of section, index */ Elf32_Word sh_type; Elf32_Word sh_flags; Elf32_Addr sh_addr; /* memory address, if any */ Elf32_Off sh_offset; Elf32_Word sh_size; /* section size in file */ Elf32_Word sh_link; Elf32_Word sh_info; Elf32_Word sh_addralign; Elf32_Word sh_entsize; /* fixed entry size, if have */ &#125; Elf32_Shdr; 其中sh_name指出section的名字，它的值是后面将会讲到的section header string table中的索引，指出一个以null结尾的字符串。sh_type是类别，sh_flags指示该section在进程执行时的特性。sh_addr指出若此section在进程的内存映像中出现，则给出开始的虚地址。sh_offset给出此section在文件中的偏移。其它字段的意义不太常用，在此不细述。 文件的section含有程序和控制信息，系统使用一些特定的section，并有其固定的类型和属性（由sh_type和sh_info指出）。下面介绍几个常用到的section:“.bss”段含有占据程序内存映像的未初始化数据，当程序开始运行时系统对这段数据初始为零，但这个section并不占文件空间。“.data.”和“.data1”段包含占据内存映像的初始化数据。“.rodata”和“.rodata1”段含程序映像中的只读数据。“.shstrtab”段含有每个section的名字，由section入口结构中的sh_name索引。“.strtab”段含有表示符号表(symbol table)名字的字符串。“.symtab”段含有文件的符号表，在后文专门介绍。“.text”段包含程序的可执行指令。 当然一个实际的ELF文件中，会包含很多的section，如.got，.plt等等，我们这里就不一一细述了，需要时再详细的说明。 Program Header目标文件或者共享文件的program header table描述了系统执行一个程序所需要的段或者其它信息。目标文件的一个段（segment）包含一个或者多个section。Program header只对可执行文件和共享目标文件有意义，对于程序的链接没有任何意义。结构定义如下：12345678910typedef struct elf32_phdr&#123; Elf32_Word p_type; Elf32_Off p_offset; Elf32_Addr p_vaddr; /* virtual address */ Elf32_Addr p_paddr; /* ignore */ Elf32_Word p_filesz; /* segment size in file */ Elf32_Word p_memsz; /* size in memory */ Elf32_Word p_flags; Elf32_Word p_align; &#125; Elf32_Phdr; 其中p_type描述段的类型；p_offset给出该段相对于文件开关的偏移量；p_vaddr给出该段所在的虚拟地址；p_paddr给出该段的物理地址，在Linux x86内核中，这项并没有被使用；p_filesz给出该段的大小，在字节为单元，可能为0；p_memsz给出该段在内存中所占的大小，可能为0；p_filesze与p_memsz的值可能会不相等。 Symbol Table目标文件的符号表包含定位或重定位程序符号定义和引用时所需要的信息。符号表入口结构定义如下：12345678typedef struct elf32_sym&#123; Elf32_Word st_name; Elf32_Addr st_value; Elf32_Word st_size; unsigned char st_info; unsigned char st_other; Elf32_Half st_shndx; &#125; Elf32_Sym; 其中st_name包含指向符号表字符串表(strtab)中的索引，从而可以获得符号名。st_value指出符号的值，可能是一个绝对值、地址等。st_size指出符号相关的内存大小，比如一个数据结构包含的字节数等。st_info规定了符号的类型和绑定属性，指出这个符号是一个数据名、函数名、section名还是源文件名；并且指出该符号的绑定属性是local、global还是weak。 Section和Segment的区别和联系可执行文件中，一个program header描述的内容称为一个段（segment）。Segment包含一个或者多个section，我们以Hello World程序为例，看一下section与segment的映射关系： 如上图红色区域所示，就是我们经常提到的文本段和数据段，由图中绿色部分的映射关系可知，文本段并不仅仅包含.text节，数据段也不仅仅包含.data节，而是都包含了多个section。 ELF文件的加载过程加载和动态链接的简要介绍从编译/链接和运行的角度看，应用程序和库程序的连接有两种方式。一种是固定的、静态的连接，就是把需要用到的库函数的目标代码（二进制）代码从程序库中抽取出来，链接进应用软件的目标映像中；另一种是动态链接，是指库函数的代码并不进入应用软件的目标映像，应用软件在编译/链接阶段并不完成跟库函数的链接，而是把函数库的映像也交给用户，到启动应用软件目标映像运行时才把程序库的映像也装入用户空间（并加以定位），再完成应用软件与库函数的连接。 这样，就有了两种不同的ELF格式映像。一种是静态链接的，在装入/启动其运行时无需装入函数库映像、也无需进行动态连接。另一种是动态连接，需要在装入/启动其运行时同时装入函数库映像并进行动态链接。Linux内核既支持静态链接的ELF映像，也支持动态链接的ELF映像，而且装入/启动ELF映像必需由内核完成，而动态连接的实现则既可以在内核中完成，也可在用户空间完成。因此，GNU把对于动态链接ELF映像的支持作了分工：把ELF映像的装入/启动入在Linux内核中；而把动态链接的实现放在用户空间（glibc），并为此提供一个称为“解释器”（ld-linux.so.2）的工具软件，而解释器的装入/启动也由内核负责，这在后面我们分析ELF文件的加载时就可以看到。 这部分主要说明ELF文件在内核空间的加载过程，下一部分对用户空间符号的动态解析过程进行说明。 Linux可执行文件类型的注册机制在说明ELF文件的加载过程以前，我们先回答一个问题，就是：为什么Linux可以运行ELF文件？ 回答：内核对所支持的每种可执行的程序类型都有个struct linux_binfmt的数据结构，定义如下：12345678910111213/* * This structure defines the functions that are used to load the binary formats that * linux accepts. */ struct linux_binfmt &#123; struct linux_binfmt * next; struct module *module; int (*load_binary)(struct linux_binprm *, struct pt_regs * regs); int (*load_shlib)(struct file *) int (*core_dump)(long signr, struct pt_regs * regs, struct file * file); unsigned long min_coredump; /* minimal dump size */ int hasvdso; &#125;; 其中的load_binary函数指针指向的就是一个可执行程序的处理函数。而我们研究的ELF文件格式的定义如下：12345678static struct linux_binfmt elf_format = &#123; .module = THIS_MODULE, .load_binary = load_elf_binary, .load_shlib = load_elf_library, .core_dump = elf_core_dump, .min_coredump = ELF_EXEC_PAGESIZE, .hasvdso = 1 &#125;; 要支持ELF文件的运行，则必须向内核登记这个数据结构，加入到内核支持的可执行程序的队列中。内核提供两个函数来完成这个功能，一个注册，一个注销，即：12int register_binfmt(struct linux_binfmt * fmt) int unregister_binfmt(struct linux_binfmt * fmt) 当需要运行一个程序时，则扫描这个队列，让各个数据结构所提供的处理程序，ELF中即为load_elf_binary，逐一前来认领，如果某个格式的处理程序发现相符后，便执行该格式映像的装入和启动。 内核空间的加载过程内核中实际执行execv()或execve()系统调用的程序是do_execve()，这个函数先打开目标映像文件，并从目标文件的头部（第一个字节开始）读入若干（当前Linux内核中是128）字节（实际上就是填充ELF文件头，下面的分析可以看到），然后调用另一个函数search_binary_handler()，在此函数里面，它会搜索我们上面提到的Linux支持的可执行文件类型队列，让各种可执行程序的处理程序前来认领和处理。如果类型匹配，则调用load_binary函数指针所指向的处理函数来处理目标映像文件。在ELF文件格式中，处理函数是load_elf_binary函数，下面主要就是分析load_elf_binary函数的执行过程（说明：因为内核中实际的加载需要涉及到很多东西，这里只关注跟ELF文件的处理相关的代码）： 1234567891011121314struct &#123; struct elfhdr elf_ex; struct elfhdr interp_elf_ex; struct exec interp_ex; &#125; *loc; loc = kmalloc(sizeof(*loc), GFP_KERNEL); /* Get the exec-header */ loc-&gt;elf_ex = *((struct elfhdr *)bprm-&gt;buf); …… /* First of all, some simple consistency checks */ if (memcmp(loc-&gt;elf_ex.e_ident, ELFMAG, SELFMAG) != 0) goto out; if (loc-&gt;elf_ex.e_type != ET_EXEC &amp;&amp; loc-&gt;elf_ex.e_type != ET_DYN) goto out; 在load_elf_binary之前，内核已经使用映像文件的前128个字节对bprm-&gt;buf进行了填充，563行就是使用这此信息填充映像的文件头（具体数据结构定义见第一部分，ELF文件头节），然后567行就是比较文件头的前四个字节，查看是否是ELF文件类型定义的“\177ELF”。除这4个字符以外，还要看映像的类型是否ET_EXEC和ET_DYN之一；前者表示可执行映像，后者表示共享库。123456789/* Now read in all of the header information */ if (loc-&gt;elf_ex.e_phnum &lt; 1 || loc-&gt;elf_ex.e_phnum &gt; 65536U / sizeof(struct elf_phdr)) goto out; size = loc-&gt;elf_ex.e_phnum * sizeof(struct elf_phdr); …… elf_phdata = kmalloc(size, GFP_KERNEL); …… retval = kernel_read(bprm-&gt;file, loc-&gt;elf_ex.e_phoff, (char *)elf_phdata, size); 这块就是通过kernel_read读入整个program header table。从代码中可以看到，一个可执行程序必须至少有一个段（segment），而所有段的大小之和不能超过64K。1234567891011121314151617181920212223elf_ppnt = elf_phdata; …… for (i = 0; i &lt; loc-&gt;elf_ex.e_phnum; i++) &#123; if (elf_ppnt-&gt;p_type == PT_INTERP) &#123; …… elf_interpreter = kmalloc(elf_ppnt-&gt;p_filesz, GFP_KERNEL); …… retval = kernel_read(bprm-&gt;file, elf_ppnt-&gt;p_offset, elf_interpreter, elf_ppnt-&gt;p_filesz); …… interpreter = open_exec(elf_interpreter); …… retval = kernel_read(interpreter, 0, bprm-&gt;buf, BINPRM_BUF_SIZE); …… /* Get the exec headers */ …… loc-&gt;interp_elf_ex = *((struct elfhdr *)bprm-&gt;buf); break; &#125; elf_ppnt++; &#125; 这个for循环的目的在于寻找和处理目标映像的“解释器”段。“解释器”段的类型为PT_INTERP，找到后就根据其位置的p_offset和大小p_filesz把整个“解释器”段的内容读入缓冲区（640~640）。事个“解释器”段实际上只是一个字符串，即解释器的文件名，如“/lib/ld-linux.so.2”。有了解释器的文件名以后，就通过open_exec()打开这个文件，再通过kernel_read()读入其开关128个字节（695~696），即解释器映像的头部。我们以Hello World程序为例，看一下这段中具体的内容： 其实从readelf程序的输出中，我们就可以看到需要解释器/lib/ld-linux.so.2，为了进一步的验证，我们用hd命令以16进制格式查看下类型为INTERP的段所在位置的内容，在上面的各个域可以看到，它位于偏移量为0x000114的位置，文件内占19个字节： 从上面红色部分可以看到，这个段中实际保存的就是“/lib/ld-linux.so.2”这个字符串。123456789for(i = 0, elf_ppnt = elf_phdata; i &lt; loc-&gt;elf_ex.e_phnum; i++, elf_ppnt++) &#123; …… if (elf_ppnt-&gt;p_type != PT_LOAD) continue; …… error = elf_map(bprm-&gt;file, load_bias + vaddr, elf_ppnt, elf_prot, elf_flags); …… &#125; 这段代码从目标映像的程序头中搜索类型为PT_LOAD的段（Segment）。在二进制映像中，只有类型为PT_LOAD的段才是需要装入的。当然在装入之前，需要确定装入的地址，只要考虑的就是页面对齐，还有该段的p_vaddr域的值（上面省略这部分内容）。确定了装入地址后，就通过elf_map()建立用户空间虚拟地址空间与目标映像文件中某个连续区间之间的映射，其返回值就是实际映射的起始地址。12345678910if (elf_interpreter) &#123; …… elf_entry = load_elf_interp(&amp;loc-&gt;interp_elf_ex, interpreter, &amp;interp_load_addr); …… &#125; else &#123; elf_entry = loc-&gt;elf_ex.e_entry; …… &#125; 这段程序的逻辑非常简单：如果需要装入解释器，就通过load_elf_interp装入其映像（951~953），并把将来进入用户空间的入口地址设置成load_elf_interp()的返回值，即解释器映像的入口地址。而若不装入解释器，那么这个入口地址就是目标映像本身的入口地址。 12345create_elf_tables(bprm, &amp;loc-&gt;elf_ex, (interpreter_type == INTERPRETER_AOUT), load_addr, interp_load_addr); …… start_thread(regs, elf_entry, bprm-&gt;p); 在完成装入，启动用户空间的映像运行之前，还需要为目标映像和解释器准备好一些有关的信息，这些信息包括常规的argc、envc等等，还有一些“辅助向量（Auxiliary Vector）”。这些信息需要复制到用户空间，使它们在CPU进入解释器或目标映像的程序入口时出现在用户空间堆栈上。这里的create_elf_tables()就起着这个作用。 最后，start_thread()这个宏操作会将eip和esp改成新的地址，就使得CPU在返回用户空间时就进入新的程序入口。如果存在解释器映像，那么这就是解释器映像的程序入口，否则就是目标映像的程序入口。那么什么情况下有解释器映像存在，什么情况下没有呢？如果目标映像与各种库的链接是静态链接，因而无需依靠共享库、即动态链接库，那就不需要解释器映像；否则就一定要有解释器映像存在。 以我们的Hello World为例，gcc在编译时，除非显示的使用static标签，否则所有程序的链接都是动态链接的，也就是说需要解释器。由此可见，我们的Hello World程序在被内核加载到内存，内核跳到用户空间后并不是执行Hello World的，而是先把控制权交到用户空间的解释器，由解释器加载运行用户程序所需要的动态库（Hello World需要libc），然后控制权才会转移到用户程序。 ELF文件中符号的动态解析过程上面一节提到，控制权是先交到解释器，由解释器加载动态库，然后控制权才会到用户程序。因为时间原因，动态库的具体加载过程，并没有进行深入分析。大致的过程就是将每一个依赖的动态库都加载到内存，并形成一个链表，后面的符号解析过程主要就是在这个链表中搜索符号的定义。 我们后面主要就是以Hello World为例，分析程序是如何调用printf的： 查看一下gcc编译生成的Hello World程序的汇编代码（main函数部分）：12345608048374 &lt;main&gt;: 8048374: 8d 4c 24 04 lea 0x4(%esp),%ecx …… 8048385: c7 04 24 6c 84 04 08 movl $0x804846c,(%esp) 804838c: e8 2b ff ff ff call 80482bc &lt;puts@plt&gt; 8048391: b8 00 00 00 00 mov $0x0,%eax 从上面的代码可以看出，经过编译后，printf函数的调用已经换成了puts函数（原因读者可以想一下）。其中的call指令就是调用puts函数。但从上面的代码可以看出，它调用的是puts@plt这个标号，它代表什么意思呢？在进一步说明符号的动态解析过程以前，需要先了解两个概念，一个是global offset table，一个是procedure linkage table。 Global Offset Table（GOT）在位置无关代码中，一般不能包含绝对虚拟地址（如共享库）。当在程序中引用某个共享库中的符号时，编译链接阶段并不知道这个符号的具体位置，只有等到动态链接器将所需要的共享库加载时进内存后，也就是在运行阶段，符号的地址才会最终确定。因此，需要有一个数据结构来保存符号的绝对地址，这就是GOT表的作用，GOT表中每项保存程序中引用其它符号的绝对地址。这样，程序就可以通过引用GOT表来获得某个符号的地址。 在x86结构中，GOT表的前三项保留，用于保存特殊的数据结构地址，其它的各项保存符号的绝对地址。对于符号的动态解析过程，我们只需要了解的就是第二项和第三项，即GOT[1]和GOT[2]：GOT[1]保存的是一个地址，指向已经加载的共享库的链表地址（前面提到加载的共享库会形成一个链表）；GOT[2]保存的是一个函数的地址，定义如下：GOT[2] = &amp;_dl_runtime_resolve，这个函数的主要作用就是找到某个符号的地址，并把它写到与此符号相关的GOT项中，然后将控制转移到目标函数，后面我们会详细分析。 Procedure Linkage Table（PLT）过程链接表（PLT）的作用就是将位置无关的函数调用转移到绝对地址。在编译链接时，链接器并不能控制执行从一个可执行文件或者共享文件中转移到另一个中（如前所说，这时候函数的地址还不能确定），因此，链接器将控制转移到PLT中的某一项。而PLT通过引用GOT表中的函数的绝对地址，来把控制转移到实际的函数。 在实际的可执行程序或者共享目标文件中，GOT表在名称为.got.plt的section中，PLT表在名称为.plt的section中。 大致的了解了GOT和PLT的内容后，我们查看一下puts@plt中到底是什么内容：1234567891011121314151617181920Disassembly of section .plt: 0804828c &lt;__gmon_start__@plt-0x10&gt;: 804828c: ff 35 68 95 04 08 pushl 0x8049568 8048292: ff 25 6c 95 04 08 jmp *0x804956c 8048298: 00 00 ...... 0804829c &lt;__gmon_start__@plt&gt;: 804829c: ff 25 70 95 04 08 jmp *0x8049570 80482a2: 68 00 00 00 00 push $0x0 80482a7: e9 e0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 080482ac &lt;__libc_start_main@plt&gt;: 80482ac: ff 25 74 95 04 08 jmp *0x8049574 80482b2: 68 08 00 00 00 push $0x8 80482b7: e9 d0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 080482bc &lt;puts@plt&gt;: 80482bc: ff 25 78 95 04 08 jmp *0x8049578 80482c2: 68 10 00 00 00 push $0x10 80482c7: e9 c0 ff ff ff jmp 804828c &lt;_init+0x18&gt; 可以看到puts@plt包含三条指令，程序中所有对有puts函数的调用都要先来到这里（Hello World里只有一次）。可以看出，除PLT0以外（就是gmon_start@plt-0x10所标记的内容），其它的所有PLT项的形式都是一样的，而且最后的jmp指令都是0x804828c，即PLT0为目标的。所不同的只是第一条jmp指令的目标和push指令中的数据。PLT0则与之不同，但是包括PLT0在内的每个表项都占16个字节，所以整个PLT就像个数组（实际是代码段）。另外，每个PLT表项中的第一条jmp指令是间接寻址的。比如我们的puts函数是以地址0x8049578处的内容为目标地址进行中跳转的。 顺着这个地址，我们进一步查看此处的内容：12(gdb) x/w 0x8049578 0x8049578 &lt;_GLOBAL_OFFSET_TABLE_+20&gt;: 0x080482c2 从上面可以看出，这个地址就是GOT表中的一项。它里面的内容是0x80482c2，即puts@plt中的第二条指令。前面我们不是提到过，GOT中这里本应该是puts函数的地址才对，那为什么会这样呢？原来链接器在把所需要的共享库加载进内存后，并没有把共享库中的函数的地址写到GOT表项中，而是延迟到函数的第一次调用时，才会对函数的地址进行定位。 puts@plt的第二条指令是pushl $0x10，那这个0x10代表什么呢？12345Relocation section &apos;.rel.plt&apos; at offset 0x25c contains 3 entries: Offset Info Type Sym.Value Sym. Name 08049570 00000107 R_386_JUMP_SLOT 00000000 __gmon_start__ 08049574 00000207 R_386_JUMP_SLOT 00000000 __libc_start_main 08049578 00000307 R_386_JUMP_SLOT 00000000 puts 其中的第三项就是puts函数的重定向信息，0x10即代表相对于.rel.plt这个section的偏移位置（每一项占8个字节）。其中的Offset这个域就代表的是puts函数地址在GOT表项中的位置，从上面puts@plt的第一条指令也可以验证这一点。向堆栈中压入这个偏移量的主要作用就是为了找到puts函数的符号名（即上面的Sym.Name域的“puts”这个字符串）以及puts函数地址在GOT表项中所占的位置，以便在函数定位完成后将函数的实际地址写到这个位置。 puts@plt的第三条指令就跳到了PLT0的位置。这条指令只是将0x8049568这个数值压入堆栈，它实际上是GOT表项的第二个元素，即GOT[1]（共享库链表的地址）。 随即PLT0的第二条指令即跳到了GOT[2]中所保存的地址（间接寻址），即_dl_runtime_resolve这个函数的入口。 _dl_runtime_resolve的定义如下：1234567891011_dl_runtime_resolve: pushl %eax # Preserve registers otherwise clobbered. pushl %ecx pushl %edx movl 16(%esp), %edx # Copy args pushed by PLT in register. Note movl 12(%esp), %eax # that `fixup&apos; takes its parameters in regs. call _dl_fixup # Call resolver. popl %edx # Get register content back. popl %ecx xchgl %eax, (%esp) # Get %eax contents end store function address. ret $8 # Jump to function address. 从调用puts函数到现在，总共有两次压栈操作，一次是压入puts函数的重定向信息的偏移量，一次是GOT[1]（共享库链表的地址）。上面的两次movl操作就是将这两个数据分别取到edx和eax，然后调用_dl_fixup（从寄存器取参数），此函数完成的功能就是找到puts函数的实际加载地址，并将它写到GOT中，然后通过eax将此值返回给_dl_runtime_resolve。xchagl这条指令，不仅将eax的值恢复，而且将puts函数的值压到栈顶，这样当执行ret指令后，控制就转移到puts函数内部。ret指令同时也完成了清栈动作，使栈顶为puts函数的返回地址（main函数中call指令的下一条指令），这样，当puts函数返回时，就返回到正确的位置。 当然，如果是第二次调用puts函数，那么就不需要这么复杂的过程，而只要通过GOT表中已经确定的函数地址直接进行跳转即可。下图是前面过程的一个示意图，红色为第一次函数调用的顺序，蓝色为后续函数调用的顺序（第1步都要执行）。 ELF文件加载和链接的简要总结用户通过shell执行程序，shell通过exceve进入系统调用。（User-Mode） sys_execve经过一系列过程，并最终通过ELF文件的处理函数load_elf_binary将用户程序和ELF解释器加载进内存，并将控制权交给解释器。（Kernel-Mode） ELF解释器进行相关库的加载，并最终把控制权交给用户程序。由解释器处理用户程序运行过程中符号的动态解析。（User-Mode）]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解 glibc malloc：主流用户态内存分配器实现原理]]></title>
    <url>%2F2019%2F04%2F24%2F%E7%90%86%E8%A7%A3glibc_malloc_%E4%B8%BB%E6%B5%81%E7%94%A8%E6%88%B7%E6%80%81%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%99%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[来源：https://blog.csdn.net/maokelong95/article/details/51989081 前言堆内存（Heap Memory）是一个很有意思的领域。你可能和我一样，也困惑于下述问题很久了： 如何从内核申请堆内存？ 谁管理它？内核、库函数，还是应用本身？ 内存管理效率怎么这么高？！ 堆内存的管理效率可以进一步提高吗？最近，我终于有时间去深入了解这些问题。下面就让我来谈谈我的调研成果。 开源社区公开了很多现成的内存分配器（Memory Allocators，以下简称为分配器）： dlmalloc – 第一个被广泛使用的通用动态内存分配器； ptmalloc2 – glibc 内置分配器的原型； jemalloc – FreeBSD ＆ Firefox 所用分配器； tcmalloc – Google 贡献的分配器； libumem – Solaris 所用分配器；… 每一种分配器都宣称自己快（fast）、可拓展（scalable）、效率高（memory efficient）！但是并非所有的分配器都适用于我们的应用。内存吞吐量大（memory hungry）的应用程序，其性能很大程度上取决于分配器的性能。 历史：ptmalloc2 基于 dlmalloc 开发，其引入了多线程支持，于 2006 年发布。发布之后，ptmalloc2 整合进了 glibc 源码，此后其所有修改都直接提交到了 glibc malloc 里。因此，ptmalloc2 的源码和 glibc malloc 的源码有很多不一致的地方。（译者注：1996 年出现的 dlmalloc 只有一个主分配区，该分配区为所有线程所争用，1997 年发布的 ptmalloc 在 dlmalloc 的基础上引入了非主分配区的概念。） 申请堆的系统调用我在之前的文章中提到过，malloc 内部通过 brk 或 mmap 系统调用向内核申请堆区。 在内存管理领域，我们一般用「堆」指代用于分配动态内存的虚拟地址空间，而用「栈」指代用于分配静态内存的虚拟地址空间。具体到虚拟内存布局（Memory Layout），堆维护在通过 brk 系统调用申请的「Heap」及通过 mmap 系统调用申请的「Memory Mapping Segment」中；而栈维护在通过汇编栈指令动态调整的「Stack」中。在 Glibc 里，「Heap」用于分配较小的内存及主线程使用的内存。 下图为 Linux 内核 v2.6.7 之后，32 位模式下的虚拟内存布局方式。 多线程支持Linux 的早期版本采用 dlmalloc 作为它的默认分配器，但是因为 ptmalloc2 提供了多线程支持，所以 后来 Linux 就转而采用 ptmalloc2 了。多线程支持可以提升分配器的性能，进而间接提升应用的性能。 在 dlmalloc 中，当两个线程同时 malloc 时，只有一个线程能够访问临界区（critical section）——这是因为所有线程共享用以缓存已释放内存的「空闲列表数据结构」（freelist data structure），所以使用 dlmalloc 的多线程应用会在 malloc 上耗费过多时间，从而导致整个应用性能的下降。 在 ptmalloc2 中，当两个线程同时调用 malloc 时，内存均会得以立即分配——每个线程都维护着单独的堆，各个堆被独立的空闲列表数据结构管理，因此各个线程可以并发地从空闲列表数据结构中申请内存。这种为每个线程维护独立堆与空闲列表数据结构的行为就「per thread arena」。 案例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* Per thread arena example. */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;void* threadFunc(void* arg) &#123; printf(&quot;Before malloc in thread 1\n&quot;); getchar(); char* addr = (char*) malloc(1000); printf(&quot;After malloc and before free in thread 1\n&quot;); getchar(); free(addr); printf(&quot;After free in thread 1\n&quot;); getchar();&#125;int main() &#123; pthread_t t1; void* s; int ret; char* addr; printf(&quot;Welcome to per thread arena example::%d\n&quot;,getpid()); printf(&quot;Before malloc in main thread\n&quot;); getchar(); addr = (char*) malloc(1000); printf(&quot;After malloc and before free in main thread\n&quot;); getchar(); free(addr); printf(&quot;After free in main thread\n&quot;); getchar(); ret = pthread_create(&amp;t1, NULL, threadFunc, NULL); if(ret) &#123; printf(&quot;Thread creation error\n&quot;); return -1; &#125; ret = pthread_join(t1, &amp;s); if(ret) &#123; printf(&quot;Thread join error\n&quot;); return -1; &#125; return 0;&#125; 案例输出在主线程 malloc 之前从如下的输出结果中我们可以看到，这里还没有堆段也没有每个线程的栈，因为 thread1 还没有创建！1234567891011sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main thread...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthreadb7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在主线程 malloc 之后从如下的输出结果中我们可以看到，堆段已经产生，并且其地址区间正好在数据段（0x0804b000 - 0x0806c000）上面，这表明堆内存是移动「Program Break」的位置产生的（也即通过 brk 中断）。此外，请注意，尽管用户只申请了 1000 字节的内存，但是实际产生了 132KB 的堆。这个连续的堆区域被称为「arena」。因为这个 arena 是被主线程建立的，因此其被称为「main arena」。接下来的申请会继续分配这个 arena 的 132KB 中剩余的部分。当分配完毕时，它可以通过继续移动 Program Break 的位置扩容。扩容后，「top chunk」的大小也随之调整，以将这块新增的空间圈进去；相应地，arena 也可以在 top chunk 过大时缩小。 注意：top chunk 是一个 arena 位于最顶层的 chunk。有关 top chunk 的更多信息详见后续章节「top chunk」部分。12345678910111213sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main thread...sploitfun@sploitfun-VirtualBox:~/lsploits/hof/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在主线程 free 之后从如下的输出结果中我们可以看到，当分配的内存区域 free 掉时，其并不会立即归还给操作系统，而仅仅是移交给了作为库函数的分配器。这块 free 掉的内存添加在了「main arenas bin」中（在 glibc malloc 中，空闲列表数据结构被称为「bin」）。随后当用户请求内存时，分配器就不再向内核申请新堆了，而是先试着各个「bin」中查找空闲内存。只有当 bin 中不存在空闲内存时，分配器才会继续向内核申请内存。1234567891011121314sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main thread...sploitfun@sploitfun-VirtualBox:~/lsploits/hof/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7e05000-b7e07000 rw-p 00000000 00:00 0 ...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 malloc 之前从如下的输出结果中我们可以看到，此时 thread1 的堆尚不存在，但其栈已产生。12345678910111213141516sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 malloc 之后从如下的输出结果中我们可以看到，thread1 的堆段(b7500000 - b7521000，132KB)建立在了内存映射段中，这也表明了堆内存是使用 mmap 系统调用产生的，而非同主线程一样使用 sbrk 系统调用。类似地，尽管用户只请求了 1000B，但是映射到程地址空间的堆内存足有 1MB。这 1MB 中，只有 132KB 被设置了读写权限，并成为该线程的堆内存。这段连续内存（132KB）被称为「thread arena」。 注意：当用户请求超过 128KB(比如 malloc(132*1024)) 大小并且此时 arena 中没有足够的空间来满足用户的请求时，内存将通过 mmap 系统调用（不再是 sbrk）分配，而不论请求是发自 main arena 还是 thread arena。12345678910111213141516171819ploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1After malloc and before free in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7500000-b7521000 rw-p 00000000 00:00 0 b7521000-b7600000 ---p 00000000 00:00 0 b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ 在 thread1 free 之后从如下的输出结果中我们可以看到，free 不会把内存归还给操作系统，而是移交给分配器，然后添加在了「thread arenas bin」中。1234567891011121314151617181920sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ./mthread Welcome to per thread arena example::6501Before malloc in main threadAfter malloc and before free in main threadAfter free in main threadBefore malloc in thread 1After malloc and before free in thread 1After free in thread 1...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ cat /proc/6501/maps08048000-08049000 r-xp 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread08049000-0804a000 r--p 00000000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804a000-0804b000 rw-p 00001000 08:01 539625 /home/sploitfun/ptmalloc.ppt/mthread/mthread0804b000-0806c000 rw-p 00000000 00:00 0 [heap]b7500000-b7521000 rw-p 00000000 00:00 0 b7521000-b7600000 ---p 00000000 00:00 0 b7604000-b7605000 ---p 00000000 00:00 0 b7605000-b7e07000 rw-p 00000000 00:00 0 [stack:6594]...sploitfun@sploitfun-VirtualBox:~/ptmalloc.ppt/mthread$ ArenaArena 的数量在以上的例子中我们可以看到，主线程包含 main arena 而 thread 1 包含它自己的 thread arena。所以线程和 arena 之间是否存在一一映射关系，而不论线程的数量有多大？当然不是，部分极端的应用甚至运行比处理器核数还多的线程，在这种情况下，每个线程都拥有一个 arena 开销过高且意义不大。所以，arena 数量其实是限于系统核数的。1234For 32 bit systems:Number of arena = 2 * number of cores + 1.For 64 bit systems:Number of arena = 8 * number of cores + 1. Multiple Arena举例而言：让我们来看一个运行在单核计算机上的 32 位操作系统上的多线程应用（4 线程，主线程 + 3 个线程）的例子。这里线程数量（4）&gt; 2 * 核心数（1） + 1，所以分配器中至少有一个 Arena（也即标题所称「multiple arenas」）会被所有线程共享。那么是如何共享的呢？ 当主线程第一次调用 malloc 时，已经建立的 main arena 会被没有任何竞争地使用； 当 thread 1 和 thread 2 第一次调用 malloc 时，一块新的 arena 将被创建，且将被没有任何竞争地使用。此时线程和 arena 之间存在一一映射关系； 当 thread3 第一次调用 malloc 时，arena 的数量限制被计算出来，结果显示已超出，因此尝试复用已经存在的 arena（也即 Main arena 或 Arena 1 或 Arena 2）； 复用：一旦遍历到可用 arena，就开始自旋申请该 arena 的锁；如果上锁成功（比如说 main arena 上锁成功），就将该 arena 返回用户；如果没找到可用 arena，thread 3 的 malloc 将被阻塞，直到有可用的 arena 为止。 当thread 3 调用 malloc 时(第二次了)，分配器会尝试使用上一次使用的 arena（也即，main arena），从而尽量提高缓存命中率。当 main arena 可用时就用，否则 thread 3 就一直阻塞，直至 main arena 空闲。因此现在 main arena 实际上是被 main thread 和 thread 3 所共享。 Multiple Heaps在「glibc malloc」中主要有 3 种数据结构： heap_info ——Heap Header—— 一个 thread arena 可以维护多个堆。每个堆都有自己的堆 Header（注：也即头部元数据）。什么时候 Thread Arena 会维护多个堆呢？ 一般情况下，每个 thread arena 都只维护一个堆，但是当这个堆的空间耗尽时，新的堆（而非连续内存区域）就会被 mmap 到这个 aerna 里； malloc_state ——Arena header—— 一个 thread arena 可以维护多个堆，这些堆另外共享同一个 arena header。Arena header 描述的信息包括：bins、top chunk、last remainder chunk 等； malloc_chunk ——Chunk header—— 根据用户请求，每个堆被分为若干 chunk。每个 chunk 都有自己的 chunk header。 注意： Main arena 无需维护多个堆，因此也无需 heap_info。当空间耗尽时，与 thread arena 不同，main arena 可以通过 sbrk 拓展堆段，直至堆段「碰」到内存映射段； 与 thread arena 不同，main arena 的 arena header 不是保存在通过 sbrk 申请的堆段里，而是作为一个全局变量，可以在 libc.so 的数据段中找到。 main arena 和 thread arena 的图示如下（单堆段）： thread arena 的图示如下（多堆段）： Chunk堆段中存在的 chunk 类型如下： Allocated chunk; Free chunk; Top chunk; Last Remainder chunk. Allocated chunk「Allocated chunck」就是已经分配给用户的 chunk，其图示如下： 图中左方三个箭头依次表示： chunk：该 Allocated chunk 的起始地址； mem：该 Allocated chunk 中用户可用区域的起始地址（= chunk + sizeof(malloc_chunk)）； next_chunk：下一个 chunck（无论类型）的起始地址。 图中结构体内部各字段的含义依次为： prev_size：若上一个 chunk 可用，则此字段赋值为上一个 chunk 的大小；否则，此字段被用来存储上一个 chunk 的用户数据； size：此字段赋值本 chunk 的大小，其最后三位包含标志信息： PREV_INUSE § – 置「1」表示上个 chunk 被分配； IS_MMAPPED (M) – 置「1」表示这个 chunk 是通过 mmap 申请的（较大的内存）； NON_MAIN_ARENA (N) – 置「1」表示这个 chunk 属于一个 thread arena。 注意： malloc_chunk 中的其余结构成员，如 fd、 bk，没有使用的必要而拿来存储用户数据；用户请求的大小被转换为内部实际大小，因为需要额外空间存储 malloc_chunk，此外还需要考虑对齐。 Free chunk「Free chunck」就是用户已释放的 chunk，其图示如下： 图中结构体内部各字段的含义依次为： prev_size: 两个相邻 free chunk 会被合并成一个，因此该字段总是保存前一个 allocated chunk 的用户数据； size: 该字段保存本 free chunk 的大小； fd: Forward pointer —— 本字段指向同一 bin 中的下个 free chunk（free chunk 链表的前驱指针）； bk: Backward pointer —— 本字段指向同一 bin 中的上个 free chunk（free chunk 链表的后继指针）。 Bins「bins」 就是空闲列表数据结构。它们用以保存 free chunks。根据其中 chunk 的大小，bins 被分为如下几种类型： Fast bin; Unsorted bin; Small bin; Large bin. 保存这些 bins 的字段为： fastbinsY: 这个数组用以保存 fast bins； bins: 这个数组用于保存 unsorted bin、small bins 以及 large bins，共计可容纳 126 个，其中： Bin 1: unsorted bin; Bin 2 - 63: small bins; Bin 64 - 126: large bins. Fast Bin大小为 16 ~ 80 字节的 chunk 被称为「fast chunk」。在所有的 bins 中，fast bins 路径享有最快的内存分配及释放速度。 数量：10 每个 fast bin 都维护着一条 free chunk 的单链表，采用单链表是因为链表中所有 chunk 的大小相等，增删 chunk 发生在链表顶端即可；—— LIFO chunk 大小：8 字节递增 fast bins 由一系列所维护 chunk 大小以 8 字节递增的 bins 组成。也即，fast bin[0] 维护大小为 16 字节的 chunk、fast bin[1] 维护大小为 24 字节的 chunk。依此类推…… 指定 fast bin 中所有 chunk 大小相同； 在 malloc 初始化过程中，最大的 fast bin 的大小被设置为 64 而非 80 字节。因为默认情况下只有大小 16 ~ 64 的 chunk 被归为 fast chunk 。 无需合并 —— 两个相邻 chunk 不会被合并。虽然这可能会加剧内存碎片化，但也大大加速了内存释放的速度！ malloc(fast chunk) 初始情况下 fast chunck 最大尺寸以及 fast bin 相应数据结构均未初始化，因此即使用户请求内存大小落在 fast chunk 相应区间，服务用户请求的也将是 small bin 路径而非 fast bin 路径； 初始化后，将在计算 fast bin 索引后检索相应 bin； 相应 bin 中被检索的第一个 chunk 将被摘除并返回给用户。 free(fast chunk) 计算 fast bin 索引以索引相应 bin； free 掉的 chunk 将被添加到上述 bin 的顶端。 Unsorted Bin当 small chunk 和 large chunk 被 free 掉时，它们并非被添加到各自的 bin 中，而是被添加在 「unsorted bin」 中。这使得分配器可以重新使用最近 free 掉的 chunk，从而消除了寻找合适 bin 的时间开销，进而加速了内存分配及释放的效率。 数量：1 unsorted bin 包括一个用于保存 free chunk 的双向循环链表（又名 binlist）； chunk 大小：无限制，任何大小的 chunk 均可添加到这里。 Small Bin大小小于 512 字节的 chunk 被称为 「small chunk」，而保存 small chunks 的 bin 被称为 「small bin」。在内存分配回收的速度上，small bin 比 large bin 更快。 数量：62 每个 small bin 都维护着一条 free chunk 的双向循环链表。free 掉的 chunk 添加在链表的顶端，而 malloc 的 chunk 从链表尾端摘除。—— FIFO chunk 大小：8 字节递增 Small bins 由一系列所维护 chunk 大小以 8 字节递增的 bins 组成。举例而言，small bin[0] （Bin 2）维护着大小为 16 字节的 chunks、small bin[1]（Bin 3）维护着大小为 24 字节的 chunks ，依此类推…… 指定 small bin 中所有 chunk 大小均相同，因此无需排序； 合并 —— 相邻的 free chunk 将被合并，这减缓了内存碎片化，但是减慢了 free 的速度； malloc(small chunk) 初始情况下，small bins 都是 NULL，因此尽管用户请求 small chunk ，提供服务的将是 unsorted bin 路径而不是 small bin 路径； 第一次调用 malloc 时，维护在 malloc_state 中的 small bins 和 large bins 将被初始化，它们都会指向自身以表示其为空； 此后当 small bin 非空，相应的 bin 会摘除其中最后一个 chunk 并返回给用户； free(small chunk) free chunk 的时候，检查其前后的 chunk 是否空闲，若是则合并，也即把它们从所属的链表中摘除并合并成一个新的 chunk，新 chunk 会添加在unsorted bin 的前端。 Large Bin大小大于等于 512 字节的 chunk 被称为「large chunk」，而保存 large chunks 的 bin 被称为 「large bin」。在内存分配回收的速度上，large bin 比 small bin 慢。 数量：63 每个 large bin 都维护着一条 free chunk 的双向循环链表。free 掉的 chunk 添加在链表的顶端，而 malloc 的 chunk 从链表尾端摘除。——FIFO 这 63 个 bins 32 个 bins 所维护的 chunk 大小以 64B 递增，也即 large chunk[0](Bin 65) 维护着大小为 512B ~ 568B 的 chunk 、large chunk[1](Bin 66) 维护着大小为 576B ~ 632B 的 chunk，依此类推…… 16 个 bins 所维护的 chunk 大小以 512 字节递增； 8 个 bins 所维护的 chunk 大小以 4096 字节递增； 4 个 bins 所维护的 chunk 大小以 32768 字节递增； 2 个 bins 所维护的 chunk 大小以 262144 字节递增； 1 个 bin 维护所有剩余 chunk 大小； 不像 small bin ，large bin 中所有 chunk 大小不一定相同，各 chunk 大小递减保存。最大的 chunk 保存顶端，而最小的 chunk 保存在尾端； 合并 —— 两个相邻的空闲 chunk 会被合并； malloc(large chunk) 初始情况下，large bin 都会是 NULL，因此尽管用户请求 large chunk ，提供服务的将是 next largetst bin 路径而不是 large bin 路劲 。 第一次调用 malloc 时，维护在 malloc_state 中的 small bin 和 large bin 将被初始化，它们都会指向自身以表示其为空； 此后当 large bin 非空，如果相应 bin 中的最大 chunk 大小大于用户请求大小，分配器就从该 bin 顶端遍历到尾端，以找到一个大小最接近用户请求的 chunk。一旦找到，相应 chunk 就会被切分成两块： User chunk（用户请求大小）—— 返回给用户； Remainder chunk （剩余大小）—— 添加到 unsorted bin。 如果相应 bin 中的最大 chunk 大小小于用户请求大小，分配器就会扫描 binmaps，从而查找最小非空 bin。如果找到了这样的 - bin，就从中选择合适的 chunk 并切割给用户；反之就使用 top chunk 响应用户请求。 free(large chunk) —— 类似于 small chunk 。 Top Chunk一个 arena 中最顶部的 chunk 被称为「top chunk」。它不属于任何 bin 。当所有 bin 中都没有合适空闲内存时，就会使用 top chunk 来响应用户请求。 当 top chunk 的大小比用户请求的大小大的时候，top chunk 会分割为两个部分： User chunk，返回给用户； Remainder chunk，剩余部分，将成为新的 top chunk。当 top chunk 的大小比用户请求的大小小的时候，top chunk 就通过 sbrk（main arena）或 mmap（ thread arena）系统调用扩容。 Last Remainder Chunk「last remainder chunk」即最后一次 small request 中因分割而得到的剩余部分，它有利于改进引用局部性，也即后续对 small chunk 的 malloc 请求可能最终被分配得彼此靠近。 那么 arena 中的若干 chunks，哪个有资格成为 last remainder chunk 呢？ 当用户请求 small chunk 而无法从 small bin 和 unsorted bin 得到服务时，分配器就会通过扫描 binmaps 找到最小非空 bin。正如前文所提及的，如果这样的 bin 找到了，其中最合适的 chunk 就会分割为两部分：返回给用户的 User chunk 、添加到 unsorted bin 中的 Remainder chunk。这一 Remainder chunk 就将成为 last remainder chunk。 那么引用局部性是如何达成的呢？ 当用户的后续请求 small chunk，并且 last remainder chunk 是 unsorted bin 中唯一的 chunk，该 last remainder chunk 就将分割成两部分：返回给用户的 User chunk、添加到 unsorted bin 中的 Remainder chunk（也是 last remainder chunk）。因此后续的请求的 chunk 最终将被分配得彼此靠近。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC编译参数]]></title>
    <url>%2F2019%2F04%2F23%2FGCC%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[GNU CC(简称gcc)是GNU项目中符合ANSI C标准的编译系统，能够编译用C、C++、Object C、Jave等多种语言编写的程序。gcc又可以作为交叉编译工具，它能够在当前CPU平台上为多种不同体系结构的硬件平台开发软件，非常适合在嵌入式领域的开发编译，如常用的arm-linux-gcc交叉编译工具 通常后跟一些选项和文件名来使用 GCC 编译器。gcc 命令的基本用法如下: gcc [options] [filenames] 选项指定编译器怎样进行编译。 gcc 编译流程预处理-Pre-Processinggcc -E test.c -o test.i //.i文件 编译-Compilinggcc -S test.i -o test.s //.s文件 汇编-Assembling //.o文件gcc -c test.s -o test.o 链接-Linking //bin文件gcc test.o -o test gcc工程惯用编译gcc -c test.c //.o文件，汇编 gcc -o test test.c //bin可执行文件 gcc test.c //a.out可执行文件 如果是c++ 直接将gcc改为g++即可。 常用参数1）-E参数 选项指示编译器仅对输入文件进行预处理。当这个选项被使用时, 预处理器的输出被送到标准输出而不是储存在文件里. 2）-S参数 编译选项告诉 GCC 在为 C 代码产生了汇编语言文件后停止编译。 GCC 产生的汇编语言文件的缺省扩展名是 .s 。 3）-c参数 选项告诉 GCC 仅把源代码编译为目标代码。缺省时 GCC 建立的目标代码文件有一个 .o 的扩展名。 4）-o参数 编译选项来为将产生的可执行文件用指定的文件名。 5）-O参数 选项告诉 GCC 对源代码进行基本优化。这些优化在大多数情况下都会使程序执行的更快。 -O2 选项告诉GCC 产生尽可能小和尽可能快的代码。 如-O2，-O3，-On（n 常为0–3）；-O 主要进行跳转和延迟退栈两种优化；-O2 除了完成-O1的优化之外，还进行一些额外的调整工作，如指令调整等。-O3 则包括循环展开和其他一些与处理特性相关的优化工作。选项将使编译的速度比使用 -O 时慢， 但通常产生的代码执行速度会更快。 如： [root@localhost test]# gcc test.c -O3 [root@localhost test]# gcc -O3 test.c [root@localhost test]# gcc -o tt test.c -O2 [root@localhost test]# gcc -O2 -o tt test.c 6）调试选项-g和-pg GCC 支持数种调试和剖析选项，常用到的是 -g 和 -pg 。 -g 选项告诉 GCC 产生能被 GNU 调试器使用的调试信息以便调试你的程序。GCC 提供了一个很多其他 C 编译器里没有的特性, 在 GCC 里你能使-g 和 -O (产生优化代码)联用。 -pg 选项告诉 GCC 在编译好的程序里加入额外的代码。运行程序时, 产生 gprof 用的剖析信息以显示你的程序的耗时情况。 7） -l参数和-L参数 -l参数就是用来指定程序要链接的库，-l参数紧接着就是库名，那么库名跟真正的库文件名有什么关系呢？就拿数学库来说，他的库名是m，他的库文件名是libm.so，很容易看出，把库文件名的头lib和尾.so去掉就是库名了。 如： gcc xxx.c -lm( 动态数学库) -lpthread 好了现在我们知道怎么得到库名了，比如我们自已要用到一个第三方提供的库名字叫libtest.so，那么我们只要把libtest.so拷贝到 /usr/lib里，编译时加上-ltest参数，我们就能用上libtest.so库了（当然要用libtest.so库里的函数，我们还需要与 libtest.so配套的头文件）。放在/lib和/usr/lib和/usr/local/lib里的库直接用-l参数就能链接了，但如果库文件没放在这三个目录里，而是放在其他目录里， 这时我们只用-l参数的话，链接还是会出错，出错信息大概是：“/usr/bin/ld: cannot find-lxxx”，也就是链接 程序ld在那3个目录里找不到libxxx.so，这时另外一个参数-L就派上用场了，比如常用的X11的库，它放在/usr/X11R6/lib目录 下，我们编译时就要用-L/usr/X11R6/lib -lX11参数，-L参数跟着的是库文件所在的目录名。再比如我们把libtest.so放在/aaa/bbb/ccc目录下，那链接参数就是-L/aaa/bbb/ccc -ltest 另外，大部分libxxxx.so只是一个链接，以RH9为例，比如libm.so它链接到/lib/libm.so.x，/lib/libm.so.6 又链接到/lib/libm-2.3.2.so，如果没有这样的链接，还是会出错，因为ld只会找libxxxx.so，所以如果你要用到xxxx库，而只有libxxxx.so.x或者libxxxx-x.x.x.so，做一个链接就可以了ln -s libxxxx-x.x.x.so libxxxx.so手工来写链接参数总是很麻烦的，还好很多库开发包提供了生成链接参数的程序，名字一般叫xxxx-config，一般放在/usr/bin目录下，比如 gtk1.2的链接参数生成程序是gtk-config，执行gtk-config –libs就能得到以下输出”-L/usr/lib -L/usr/X11R6/lib -lgtk -lgdk -rdynamic -lgmodule -lglib -ldl -lXi -lXext -lX11 -lm”，这就是编译一个gtk1.2程序所需的gtk链接参数，xxx-config除了–libs参数外还有一个参数是–cflags用来生成头文件包含目录的，也就是-I参数，在下面我们将会讲到。你可以试试执行gtk-config –libs –cflags，看看输出结果。 现在的问题就是怎样用这些输出结果了，最笨的方法就是复制粘贴或者照抄，聪明的办法是在编译命令行里加入这个xxxx-config --libs --cflags，比如编译一个gtk程序：gcc gtktest.c gtk-config --libs --cflags这样差不多了。注意`不是单引号，而是1键左边那个键。 除了xxx-config以外，现在新的开发包一般都用pkg-config来生成链接参数，使用方法跟xxx-config类似，但xxx-config是针对特定的开发包，但pkg-config包含很多开发包的链接参数的生成，用pkg-config –list-all命令可以列出所支持的所有开发包，pkg-config的用法就是pkg-config pagName –libs –cflags，其中pagName是包名，是pkg-config–list-all里列出名单中的一个，比如gtk1.2的名字就是gtk+， pkg-config gtk+ –libs –cflags的作用跟gtk-config –libs –cflags是一样的。比如： gcc gtktest.c pkg-config gtk+ --libs --cflags。 8） -include和-I参数 -include用来包含头文件，但一般情况下包含头文件都在源码里用＃i nclude xxxxxx实现，-include参数很少用。-I参数是用来指定头文件目录，/usr/include目录一般是不用指定的，gcc知道去那里找，但 是如果头文件不在/usr/icnclude里我们就要用-I参数指定了，比如头文件放在/myinclude目录里，那编译命令行就要加上-I/myinclude参数了，如果不加你会得到一个”xxxx.h: No such file or directory”的错误。-I参数可以用相对路径，比如头文件在当前目录，可以用-I.来指定。上面我们提到的–cflags参数就是用来生成-I参数的。 9）-Wall、-w 和 -v参数 -Wall 打印出gcc提供的警告信息 -w 关闭所有警告信息 -v 列出所有编译步骤 10) -m64 64位 11) -shared 将-fPIC生成的位置无关的代码作为动态库，一般情况下，-fPIC和-shared都是一起使用的。生成SO文件，共享库 -static 此选项将禁止使用动态库，所以，编译出来的东西，一般都很大，也不需要什么动态连接库，就可以运行 几个相关的环境变量 PKG_CONFIG_PATH：用来指定pkg-config用到的pc文件的路径，默认是/usr/lib/pkgconfig，pc文件是文本文件，扩展名是.pc，里面定义开发包的安装路径，Libs参数和Cflags参数等等。 CC：用来指定c编译器。 CXX：用来指定cxx编译器。 LIBS：跟上面的–libs作用差不多。 CFLAGS:跟上面的–cflags作用差不多。 CC，CXX，LIBS，CFLAGS手动编译时一般用不上，在做configure时有时用到，一般情况下不用管。 环境变量设定方法：export ENV_NAME=xxxxxxxxxxxxxxxxx 关于交叉编译交叉编译通俗地讲就是在一种平台上编译出能运行在体系结构不同的另一种平台上，比如在我们地PC平台(X86 CPU)上编译出能运行在arm CPU平台上的程序，编译得到的程序在X86 CPU平台上是不能运行的，必须放到arm CPU 平台上才能运行。当然两个平台用的都是linux。这种方法在异平台移植和嵌入式开发时用得非常普遍。相对与交叉编译，我们平常做的编译就叫本地编译，也 就是在当前平台编译，编译得到的程序也是在本地执行。用来编译这种程序的编译器就叫交叉编译器，相对来说，用来做本地编译的就叫本地编译器，一般用的都是gcc，但这种gcc跟本地的gcc编译器是不一样的，需要在编译gcc时用特定的configure参数才能得到支持交叉编译的gcc。为了不跟本地编译器混淆，交叉编译器的名字一般都有前缀，比如armc-xxxx-linux-gnu-gcc，arm-xxxx-linux-gnu- g++ 等等 交叉编译器的使用方法 使用方法跟本地的gcc差不多，但有一点特殊的是：必须用-L和-I参数指定编译器用arm系统的库和头文件，不能用本地(X86)的库（头文件有时可以用本地的）。 例子： arm-xxxx-linux-gnu-gcc test.c -L/path/to/sparcLib -I/path/to/armInclude man gcc 部分GCC(1) GNU GCC(1) NAME gcc - GNU project C and C++ compiler SYNOPSIS gcc [-c | -S | -E] [-std=standard] [-g] [-pg] [-Olevel] [-Wwarn...] [-pedantic] [-Idir...] [-Ldir...] [-Dmacro[=defn]...] [-Umacro] [-foption...] [-mmachine-option...] [-o outfile] infile... Only the most useful options are listed here; see below for the remainder. g++ accepts mostly the same options as gcc.]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELF文件格式]]></title>
    <url>%2F2019%2F04%2F23%2Felf%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[来源：https://www.cnblogs.com/jiqingwu/p/elf_format_research_01.html ELF文件解析（一）：Segment和SectionELF 是Executable and Linking Format的缩写，即可执行和可链接的格式，是Unix/Linux系统ABI (Application Binary Interface)规范的一部分。 Unix/Linux下的可执行二进制文件、目标代码文件、共享库文件和core dump文件都属于ELF文件。下面的图来自于文档 Executable and Linkable Format (ELF)，描述了ELF文件的大致布局。 左边是ELF的链接视图，可以理解为是目标代码文件的内容布局。右边是ELF的执行视图，可以理解为可执行文件的内容布局。注意目标代码文件的内容是由section组成的，而可执行文件的内容是由segment组成的。 要注意区分段(segment)和节(section)的概念，这两个概念在后面会经常提到。我们写汇编程序时，用.text，.bss，.data这些指示，都指的是section，比如.text，告诉汇编器后面的代码放入.text section中。目标代码文件中的section和section header table中的条目是一一对应的。section的信息用于链接器对代码重定位。 而文件载入内存执行时，是以segment组织的，每个segment对应ELF文件中program header table中的一个条目，用来建立可执行文件的进程映像。比如我们通常说的，代码段、数据段是segment，目标代码中的section会被链接器组织到可执行文件的各个segment中。.text section的内容会组装到代码段中，.data, .bss等节的内容会包含在数据段中。 在目标文件中，program header不是必须的，我们用gcc生成的目标文件也不包含program header。一个好用的解析ELF文件的工具是readelf。对我本机上的一个目标代码文件sleep.o执行readelf -S sleep.o，输出如下：1234567891011121314151617181920212223There are 12 section headers, starting at offset 0x270:Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align [ 0] NULL 0000000000000000 00000000 0000000000000000 0000000000000000 0 0 0 [ 1] .text PROGBITS 0000000000000000 00000040 0000000000000015 0000000000000000 AX 0 0 1 [ 2] .rela.text RELA 0000000000000000 000001e0 0000000000000018 0000000000000018 I 9 1 8 [ 3] .data PROGBITS 0000000000000000 00000055 0000000000000000 0000000000000000 WA 0 0 1 [ 4] .bss NOBITS 0000000000000000 00000055 0000000000000000 0000000000000000 WA 0 0 1 ... ... ... ... [11] .shstrtab STRTAB 0000000000000000 00000210 0000000000000059 0000000000000000 0 0 1Key to Flags: W (write), A (alloc), X (execute), M (merge), S (strings), I (info), L (link order), O (extra OS processing required), G (group), T (TLS), C (compressed), x (unknown), o (OS specific), E (exclude), l (large), p (processor specific) readelf -S是显示文件中的Section信息，sleep.o中共有12个section, 我们省略了其中一些Section的信息。可以看到，除了我们熟悉的.text, .data, .bss，还有其它Section，这等我们以后展开讲Section的时候还会专门讲到。看每个Section的Flags我们也可以得到一些信息，比如.text section的Flags是AX，表示要分配内存，并且是可执行的，这一节是代码无疑了。.data 和 .bss的Flags的Flags都是WA，表示可写，需分配内存，这都是数据段的特征。 使用readelf -l可以显示文件的program header信息。我们对sleep.o执行readelf -l sleep.o，会输出There are no program headers in this file.。program header和文件中的segment一一对应，因为目标代码文件中没有segment，program header也就没有必要了。 可执行文件的内容组织成segment，因此program header table是必须的。section header不是必须的，但没有strip过的二进制文件中都含有此信息。对本地可执行文件sleep执行readelf -l sleep，输出如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344Elf file type is DYN (Shared object file)Entry point 0x1040There are 11 program headers, starting at offset 64Program Headers: Type Offset VirtAddr PhysAddr FileSiz MemSiz Flags Align PHDR 0x0000000000000040 0x0000000000000040 0x0000000000000040 0x0000000000000268 0x0000000000000268 R 0x8 INTERP 0x00000000000002a8 0x00000000000002a8 0x00000000000002a8 0x000000000000001c 0x000000000000001c R 0x1 [Requesting program interpreter: /lib64/ld-linux-x86-64.so.2] LOAD 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000560 0x0000000000000560 R 0x1000 LOAD 0x0000000000001000 0x0000000000001000 0x0000000000001000 0x00000000000001d5 0x00000000000001d5 R E 0x1000 LOAD 0x0000000000002000 0x0000000000002000 0x0000000000002000 0x0000000000000110 0x0000000000000110 R 0x1000 LOAD 0x0000000000002de8 0x0000000000003de8 0x0000000000003de8 0x0000000000000248 0x0000000000000250 RW 0x1000 DYNAMIC 0x0000000000002df8 0x0000000000003df8 0x0000000000003df8 0x00000000000001e0 0x00000000000001e0 RW 0x8 NOTE 0x00000000000002c4 0x00000000000002c4 0x00000000000002c4 0x0000000000000044 0x0000000000000044 R 0x4 GNU_EH_FRAME 0x0000000000002004 0x0000000000002004 0x0000000000002004 0x0000000000000034 0x0000000000000034 R 0x4 GNU_STACK 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 0x0000000000000000 RW 0x10 GNU_RELRO 0x0000000000002de8 0x0000000000003de8 0x0000000000003de8 0x0000000000000218 0x0000000000000218 R 0x1 Section to Segment mapping: Segment Sections... 00 01 .interp 02 .interp .note.ABI-tag .note.gnu.build-id .gnu.hash .dynsym .dynstr .gnu.version .gnu.version_r .rela.dyn .rela.plt 03 .init .plt .text .fini 04 .rodata .eh_frame_hdr .eh_frame 05 .init_array .fini_array .dynamic .got .got.plt .data .bss 06 .dynamic 07 .note.ABI-tag .note.gnu.build-id 08 .eh_frame_hdr 09 10 .init_array .fini_array .dynamic .got 如输出所示，文件中共有11个segment。只有类型为LOAD的段是运行时真正需要的。除了段信息，还输出了每个段包含了哪些section。比如第二个LOAD段标志为R（只读）E（可执行）的，它的编号是03，表示它包含哪些section的那一行内容为：03 .init .plt .text .fini。可以发现.text包含在其中，这一段就是代码段。再比如第三个LOAD段，索引是04，标志为R（只读），但没有可执行的属性，它包含的section有.rodata .eh_frame_hdr .eh_frame，其中rodata表示只读的数据，也就是程序中用到的字符串常量等。最后一个LOAD段，索引05，标志RW（可读写），它包含的节是.init_array .fini_array .dynamic .got .got.plt .data .bss，可以看到.data和.bss都包含其中，这段是数据段无疑。 ELF header详解ELF header的定义可以在/usr/include/elf.h中找到。Elf32_Ehdr是32位 ELF header的结构体。Elf64_Ehdr是64位ELF header的结构体。 1234567891011121314151617181920212223242526272829303132333435typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number和其它信息 */ Elf32_Half e_type; /* Object file type */ Elf32_Half e_machine; /* Architecture */ Elf32_Word e_version; /* Object file version */ Elf32_Addr e_entry; /* Entry point virtual address */ Elf32_Off e_phoff; /* Program header table file offset */ Elf32_Off e_shoff; /* Section header table file offset */ Elf32_Word e_flags; /* Processor-specific flags */ Elf32_Half e_ehsize; /* ELF header size in bytes */ Elf32_Half e_phentsize; /* Program header table entry size */ Elf32_Half e_phnum; /* Program header table entry count */ Elf32_Half e_shentsize; /* Section header table entry size */ Elf32_Half e_shnum; /* Section header table entry count */ Elf32_Half e_shstrndx; /* Section header string table index */&#125; Elf32_Ehdr;typedef struct&#123; unsigned char e_ident[EI_NIDENT]; /* Magic number and other info */ Elf64_Half e_type; /* Object file type */ Elf64_Half e_machine; /* Architecture */ Elf64_Word e_version; /* Object file version */ Elf64_Addr e_entry; /* Entry point virtual address */ Elf64_Off e_phoff; /* Program header table file offset */ Elf64_Off e_shoff; /* Section header table file offset */ Elf64_Word e_flags; /* Processor-specific flags */ Elf64_Half e_ehsize; /* ELF header size in bytes */ Elf64_Half e_phentsize; /* Program header table entry size */ Elf64_Half e_phnum; /* Program header table entry count */ Elf64_Half e_shentsize; /* Section header table entry size */ Elf64_Half e_shnum; /* Section header table entry count */ Elf64_Half e_shstrndx; /* Section header string table index */&#125; Elf64_Ehdr; 64位和32位只是个别字段长度不同，比如 Elf64_Addr 和 Elf64_Off 都是64位无符号整数。而Elf32_Addr 和 Elf32_Off是32位无符号整数。这导致ELF header的所占的字节数不同。32位的ELF header占52个字节，64位的ELF header占64个字节。 ELF header详解 e_ident占16个字节。前四个字节被称作ELF的Magic Number。后面的字节描述了ELF文件内容如何解码等信息。等一下详细讲。 e_type，2字节，描述了ELF文件的类型。以下取值有意义： 12345678ET_NONE, 0, No file typeET_REL, 1, Relocatable file（可重定位文件，通常是文件名以.o结尾，目标文件）ET_EXEC, 2, Executable file （可执行文件）ET_DYN, 3, Shared object file （动态库文件，你用gcc编译出的二进制往往也属于这种类型，惊讶吗？）ET_CORE, 4, Core file （core文件，是core dump生成的吧？）ET_NUM, 5，表示已经定义了5种文件类型ET_LOPROC, 0xff00, Processor-specificET_HIPROC, 0xffff, Processor-specific 从ET_LOPROC到ET_HIPROC的值，包含特定于处理器的语义。 e_machine，2字节。描述了文件面向的架构，可取值如下（因为文档较老，现在有更多取值，参见/usr/include/elf.h中的EM_开头的宏定义）： 123456789EM_NONE, 0, No machineEM_M32, 1, AT&amp;T WE 32100EM_SPARC, 2, SPARCEM_386, 3, Intel 80386EM_68K, 4, Motorola 68000EM_88K, 5, Motorola 88000EM_860, 7, Intel 80860EM_MIPS, 8, MIPS RS3000... ... e_version，2字节，描述了ELF文件的版本号，合法取值如下： 123EV_NONE, 0, Invalid versionEV_CURRENT, 1, Current version，通常都是这个取值。EV_NUM, 2, 表示已经定义了2种版本号 e_entry，（32位4字节，64位8字节），执行入口点，如果文件没有入口点，这个域保持0。 e_phoff, （32位4字节，64位8字节），program header table的offset，如果文件没有PH，这个值是0。 e_shoff, （32位4字节，64位8字节）， section header table 的offset，如果文件没有SH，这个值是0。 e_flags, 4字节，特定于处理器的标志，32位和64位Intel架构都没有定义标志，因此eflags的值是0。 e_ehsize, 2字节，ELF header的大小，32位ELF是52字节，64位是64字节。 e_phentsize，2字节。program header table中每个入口的大小。 e_phnum, 2字节。如果文件没有program header table, e_phnum的值为0。e_phentsize乘以e_phnum就得到了整个program header table的大小。 e_shentsize, 2字节，section header table中entry的大小，即每个section header占多少字节。 e_shnum, 2字节，section header table中header的数目。如果文件没有section header table, e_shnum的值为0。e_shentsize乘以e_shnum，就得到了整个section header table的大小。 e_shstrndx, 2字节。section header string table index. 包含了section header table中section name string table。如果没有section name string table, e_shstrndx的值是SHN_UNDEF. e_ident回过头来，我们仔细看看文件前16个字节，也是e_ident。 如图，前4个字节是ELF的Magic Number，固定为7f 45 4c 46。第5个字节指明ELF文件是32位还是64位的。第6个字节指明了数据的编码方式，即我们通常说的little endian或是big endian。little endian我喜欢称作小头在前，低位字节在前，或者直接说低位字节在低位地址，比如0x7f454c46，存储顺序就是46 4c 45 7f。big endian就是大头在前，高位字节在前，直接说就是高位字节在低位地址，比如0x7f454c46，在文件中的存储顺序是7f 45 4c 46。第7个字节指明了ELF header的版本号，目前值都是1。第8-16个字节，都填充为0。 readelf读取ELF header我们使用readelf -h 可以读取文件的ELF header信息。比如我本地有执行文件hello，我执行reaelf -h hello，结果如下：1234567891011121314151617181920ELF Header: Magic: 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&apos;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: DYN (Shared object file) Machine: Advanced Micro Devices X86-64 Version: 0x1 Entry point address: 0x1050 Start of program headers: 64 (bytes into file) Start of section headers: 14768 (bytes into file) Flags: 0x0 Size of this header: 64 (bytes) Size of program headers: 56 (bytes) Number of program headers: 11 Size of section headers: 64 (bytes) Number of section headers: 29 Section header string table index: 28 这是我用gcc生成的执行文件，但注意它的Type是DYN (Shared object file)，这大概是因为，这个文件不能直接执行，是依赖于解释器和c库才能运行。真正的可执行文件是解释器，而hello相对于解释器来说也是个共享库文件。这是我的推断，需要后面深入学习后验证。 ELF格式探析之三：sections我们在讲ELF Header的时候，讲到了section header table。它是一个section header的集合，每个section header是一个描述section的结构体。在同一个ELF文件中，每个section header大小是相同的。（其实看了源码就知道，32位ELF文件中的section header都是一样的大小，64位ELF文件中的section header也是一样的大小） 每个section都有一个section header描述它，但是一个section header可能在文件中没有对应的section，因为有的section是不占用文件空间的。每个section在文件中是连续的字节序列。section之间不会有重叠。 一个目标文件中可能有未覆盖到的空间，比如各种header和section都没有覆盖到。这部分字节的内容是未指定的，也是没有意义的。 section header定义section header结构体的定义可以在 /usr/include/elf.h中找到。1234567891011121314151617181920212223242526272829/* Section header. */typedef struct&#123; Elf32_Word sh_name; /* Section name (string tbl index) */ Elf32_Word sh_type; /* Section type */ Elf32_Word sh_flags; /* Section flags */ Elf32_Addr sh_addr; /* Section virtual addr at execution */ Elf32_Off sh_offset; /* Section file offset */ Elf32_Word sh_size; /* Section size in bytes */ Elf32_Word sh_link; /* Link to another section */ Elf32_Word sh_info; /* Additional section information */ Elf32_Word sh_addralign; /* Section alignment */ Elf32_Word sh_entsize; /* Entry size if section holds table */&#125; Elf32_Shdr;typedef struct&#123; Elf64_Word sh_name; /* Section name (string tbl index) */ Elf64_Word sh_type; /* Section type */ Elf64_Xword sh_flags; /* Section flags */ Elf64_Addr sh_addr; /* Section virtual addr at execution */ Elf64_Off sh_offset; /* Section file offset */ Elf64_Xword sh_size; /* Section size in bytes */ Elf64_Word sh_link; /* Link to another section */ Elf64_Word sh_info; /* Additional section information */ Elf64_Xword sh_addralign; /* Section alignment */ Elf64_Xword sh_entsize; /* Entry size if section holds table */&#125; Elf64_Shdr; 下面我们依次讲解结构体各个字段： sh_name，4字节，是一个索引值，在shstrtable（section header string table，包含section name的字符串表，也是一个section）中的索引。第二讲介绍ELF文件头时，里面专门有一个字段e_shstrndx，其含义就是shstrtable对应的section header在section header table中的索引。 sh_type，4字节，描述了section的类型，常见的取值如下： 1234567891011121314SHT_NULL 0，表明section header无效，没有关联的section。SHT_PROGBITS 1，section包含了程序需要的数据，格式和含义由程序解释。SHT_SYMTAB 2， 包含了一个符号表。当前，一个ELF文件中只有一个符号表。SHT_SYMTAB提供了用于(link editor)链接编辑的符号，当然这些符号也可能用于动态链接。这是一个完全的符号表，它包含许多符号。SHT_STRTAB 3，包含一个字符串表。一个对象文件包含多个字符串表，比如.strtab（包含符号的名字）和.shstrtab（包含section的名称）。SHT_RELA 4，重定位节，包含relocation入口，参见Elf32_Rela。一个文件可能有多个Relocation Section。比如.rela.text，.rela.dyn。SHT_HASH 5，这样的section包含一个符号hash表，参与动态连接的目标代码文件必须有一个hash表。目前一个ELF文件中只包含一个hash表。讲链接的时候再细讲。SHT_DYNAMIC 6，包含动态链接的信息。目前一个ELF文件只有一个DYNAMIC section。SHT_NOTE 7，note section, 以某种方式标记文件的信息，以后细讲。SHT_NOBITS 8，这种section不含字节，也不占用文件空间，section header中的sh_offset字段只是概念上的偏移。SHT_REL 9， 重定位节，包含重定位条目。和SHT_RELA基本相同，两者的区别在后面讲重定位的时候再细讲。SHT_SHLIB 10，保留，语义未指定，包含这种类型的section的elf文件不符合ABI。SHT_DYNSYM 11， 用于动态连接的符号表，推测是symbol table的子集。SHT_LOPROC 0x70000000 到 SHT_HIPROC 0x7fffffff，为特定于处理器的语义保留。SHT_LOUSER 0x80000000 and SHT_HIUSER 0xffffffff，指定了为应用程序保留的索引的下界和上界，这个范围内的索引可以被应用程序使用。 sh_flags, 32位占4字节， 64位占8字节。包含位标志，用 readelf -S 可以看到很多标志。常用的有： 123456SHF_WRITE 0x1，进程执行的时候，section内的数据可写。SHF_ALLOC 0x2，进程执行的时候，section需要占据内存。SHF_EXECINSTR 0x4，节内包含可以执行的机器指令。SHF_STRINGS 0x20，包含0结尾的字符串。SHF_MASKOS 0x0ff00000，这个mask为OS特定的语义保留8位。SHF_MASKPROC 0xf0000000，这个mask包含的所有位保留（也就是最高字节的高4位），为处理器相关的语义使用。 sh_addr, 对32位来说是4字节，64位是8字节。如果section会出现在进程的内存映像中，给出了section第一字节的虚拟地址。 sh_offset，对于32位来说是4字节，64位是8字节。section相对于文件头的字节偏移。对于不占文件空间的section（比如SHT_NOBITS），它的sh_offset只是给出了section逻辑上的位置。 sh_size，section占多少字节，对于SHT_NOBITS类型的section，sh_size没用，其值可能不为0，但它也不占文件空间。 sh_link，含有一个section header的index，该值的解释依赖于section type。 12345如果是SHT_DYNAMIC，sh_link是string table的section header index，也就是说指向字符串表。如果是SHT_HASH，sh_link指向symbol table的section header index，hash table应用于symbol table。如果是重定位节SHT_REL或SHT_RELA，sh_link指向相应符号表的section header index。如果是SHT_SYMTAB或SHT_DYNSYM，sh_link指向相关联的符号表，暂时不解。对于其它的section type，sh_link的值是SHN_UNDEF sh_info，存放额外的信息，值的解释依赖于section type。 123如果是SHT_REL和SHT_RELA类型的重定位节，sh_info是应用relocation的节的节头索引。如果是SHT_SYMTAB和SHT_DYNSYM，sh_info是第一个non-local符号在符号表中的索引。推测local symbol在前面，non-local symbols紧跟在后面，所以文档中也说，sh_info是最后一个本地符号的在符号表中的索引加1。对于其它类型的section，sh_info是0。 sh_addralign，地址对齐，如果一个section有一个doubleword字段，系统在载入section时的内存地址必须是doubleword对齐。也就是说sh_addr必须是sh_addralign的整数倍。只有2的正整数幂是有效的。0和1说明没有对齐约束。 sh_entsize，有些section包含固定大小的记录，比如符号表。这个值给出了每个记录大小。对于不包含固定大小记录的section，这个值是0。 系统预定义的section name 系统预定义了一些节名（以.开头），这些节有其特定的类型和含义。 .bss：包含程序运行时未初始化的数据（全局变量和静态变量）。当程序运行时，这些数据初始化为0。 其类型为SHT_NOBITS，表示不占文件空间。SHF_ALLOC + SHF_WRITE，运行时要占用内存的。 .comment包含版本控制信息（是否包含程序的注释信息？不包含，注释在预处理时已经被删除了）。类型为SHT_PROGBITS。 .data和.data1，包含初始化的全局变量和静态变量。 类型为SHT_PROGBITS，标志为SHF_ALLOC + SHF_WRITE（占用内存，可写）。 .debug，包含了符号调试用的信息，我们要想用gdb等工具调试程序，需要该类型信息，类型为SHT_PROGBITS。 .dynamic，类型SHT_DYNAMIC，包含了动态链接的信息。标志SHF_ALLOC，是否包含SHF_WRITE和处理器有关。 .dynstr，SHT_STRTAB，包含了动态链接用的字符串，通常是和符号表中的符号关联的字符串。标志 SHF_ALLOC .dynsym，类型SHT_DYNSYM，包含动态链接符号表， 标志SHF_ALLOC。 .fini，类型SHT_PROGBITS，程序正常结束时，要执行该section中的指令。标志SHF_ALLOC + SHF_EXECINSTR（占用内存可执行）。现在ELF还包含.fini_array section。 .got，类型SHT_PROGBITS，全局偏移表(global offset table)，以后会重点讲。 .hash，类型SHT_HASH，包含符号hash表，以后细讲。标志SHF_ALLOC。 .init，SHT_PROGBITS，程序运行时，先执行该节中的代码。SHF_ALLOC + SHF_EXECINSTR，和.fini对应。现在ELF还包含.init_array section。 .interp，SHT_PROGBITS，该节内容是一个字符串，指定了程序解释器的路径名。如果文件中有一个可加载的segment包含该节，属性就包含SHF_ALLOC，否则不包含。 .line，SHT_PROGBITS，包含符号调试的行号信息，描述了源程序和机器代码的对应关系。gdb等调试器需要此信息。 .note Note Section, 类型SHT_NOTE，以后单独讲。 .plt 过程链接表（Procedure Linkage Table），类型SHT_PROGBITS,以后重点讲。 .relNAME，类型SHT_REL, 包含重定位信息。如果文件有一个可加载的segment包含该section，section属性将包含SHF_ALLOC，否则不包含。NAME，是应用重定位的节的名字，比如.text的重定位信息存储在.rel.text中。 .relaname类型SHT_RELA，和.rel相同。SHT_RELA和SHT_REL的区别，会在讲重定位的时候说明。 .rodata和.rodata1。类型SHT_PROGBITS, 包含只读数据，组成不可写的段。标志SHF_ALLOC。 .shstrtab，类型SHT_STRTAB，包含section的名字。有读者可能会问：section header中不是已经包含名字了吗，为什么把名字集中存放在这里？ sh_name 包含的是.shstrtab 中的索引，真正的字符串存储在.shstrtab中。那么section names为什么要集中存储？我想是这样：如果有相同的字符串，就可以共用一块存储空间。如果字符串存在包含关系，也可以共用一块存储空间。 .strtab SHT_STRTAB，包含字符串，通常是符号表中符号对应的变量名字。如果文件有一个可加载的segment包含该section，属性将包含SHF_ALLOC。字符串以\0结束， section以\0开始，也以\0结束。一个.strtab可以是空的，它的sh_size将是0。针对空字符串表的非0索引是允许的。 symtab，类型SHT_SYMTAB，Symbol Table，符号表。包含了定位、重定位符号定义和引用时需要的信息。符号表是一个数组，Index 0 第一个入口，它的含义是undefined symbol index， STN_UNDEF。如果文件有一个可加载的segment包含该section，属性将包含SHF_ALLOC。 练习：读取section names从这一讲开始，都会有练习，方便我们把前面的理论知识综合运用。 下面这个练习的目标是：从一个ELF文件中读取存储section name的字符串表。前面讲过，该字符串表也是一个section，section header table中有其对应的section header，并且ELF文件头中给出了节名字符串表对应的section header的索引，e_shstrndx。 我们的思路是这样： 从ELF header中读取section header table的起始位置，每个section header的大小，以及节名字符串表对应section header的索引。 计算section_header_table_offset + section_header_size * e_shstrndx就是节名字符串表对应section header的偏移。 读取section header，可以从中得到节名字符串表在文件中的偏移和大小。 把节名字符串表读取到内存中，打印其内容。代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/* 64位ELF文件读取section name string table */#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdint.h&gt;int main(int argc, char *argv[])&#123; /* 打开本地的ELF可执行文件hello */ FILE *fp = fopen(&quot;./hello&quot;, &quot;rb&quot;); if(!fp) &#123; perror(&quot;open ELF file&quot;); exit(1); &#125; /* 1. 通过读取ELF header得到section header table的偏移 */ /* for 64 bit ELF, e_ident(16) + e_type(2) + e_machine(2) + e_version(4) + e_entry(8) + e_phoff(8) = 40 */ fseek(fp, 40, SEEK_SET); uint64_t sh_off; int r = fread(&amp;sh_off, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section header offset&quot;); exit(2); &#125; /* 得到的这个偏移值，可以用`reaelf -h hello`来验证是否正确 */ printf(&quot;section header offset in file: %ld (0x%lx)\n&quot;, sh_off, sh_off); /* 2. 读取每个section header的大小e_shentsize, section header的数量e_shnum, 以及对应section name字符串表的section header的索引e_shstrndx 得到这些值后，都可以用`readelf -h hello`来验证是否正确 */ /* e_flags(4) + e_ehsize(2) + e_phentsize(2) + e_phnum(2) = 10 */ fseek(fp, 10, SEEK_CUR); uint16_t sh_ent_size; /* 每个section header的大小 */ r = fread(&amp;sh_ent_size, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header entry size&quot;); exit(2); &#125; printf(&quot;section header entry size: %d\n&quot;, sh_ent_size); uint16_t sh_num; /* section header的数量 */ r = fread(&amp;sh_num, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header number&quot;); exit(2); &#125; printf(&quot;section header number: %d\n&quot;, sh_num); uint16_t sh_strtab_index; /* 节名字符串表对应的节头的索引 */ r = fread(&amp;sh_strtab_index, 1, 2, fp); if (r != 2) &#123; perror(&quot;read section header string table index&quot;); exit(2); &#125; printf(&quot;section header string table index: %d\n&quot;, sh_strtab_index); /* 3. read section name string table offset, size */ /* 先找到节头字符串表对应的section header的偏移位置 */ fseek(fp, sh_off + sh_strtab_index * sh_ent_size, SEEK_SET); /* 再从section header中找到节头字符串表的偏移 */ /* sh_name(4) + sh_type(4) + sh_flags(8) + sh_addr(8) = 24 */ fseek(fp, 24, SEEK_CUR); uint64_t str_table_off; r = fread(&amp;str_table_off, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section name string table offset&quot;); exit(2); &#125; printf(&quot;section name string table offset: %ld\n&quot;, str_table_off); /* 从section header中找到节头字符串表的大小 */ uint64_t str_table_size; r = fread(&amp;str_table_size, 1, 8, fp); if (r != 8) &#123; perror(&quot;read section name string table size&quot;); exit(2); &#125; printf(&quot;section name string table size: %ld\n&quot;, str_table_size); /* 动态分配内存，把节头字符串表读到内存中 */ char *buf = (char *)malloc(str_table_size); if(!buf) &#123; perror(&quot;allocate memory for section name string table&quot;); exit(3); &#125; fseek(fp, str_table_off, SEEK_SET); r = fread(buf, 1, str_table_size, fp); if(r != str_table_size) &#123; perror(&quot;read section name string table&quot;); free(buf); exit(2); &#125; uint16_t i; for(i = 0; i &lt; str_table_size; ++i) &#123; /* 如果节头字符串表中的字节是0，就打印`\0` */ if (buf[i] == 0) printf(&quot;\\0&quot;); else printf(&quot;%c&quot;, buf[i]); &#125; printf(&quot;\n&quot;); free(buf); fclose(fp); return 0;&#125; 把以上代码存为chap3_read_section_names.c，执行gcc -Wall -o secnames chap3_read_section_names.c进行编译，输出的执行文件名叫secnames。执行secnames，输出如下：12345678./secnamessection header offset in file: 14768 (0x39b0)section header entry size: 64section header number: 29section header string table index: 28section name string table offset: 14502section name string table size: 259\0.symtab\0.strtab\0.shstrtab\0.interp\0.note.ABI-tag\0.note.gnu.build-id\0.gnu.hash\0.dynsym\0.dynstr\0.gnu.version\0.gnu.version_r\0.rela.dyn\0.rela.plt\0.init\0.text\0.fini\0.rodata\0.eh_frame_hdr\0.eh_frame\0.init_array\0.fini_array\0.dynamic\0.got\0.got.plt\0.data\0.bss\0.comment\0 可以发现，节头字符串表以\0开始，以\0结束。如果一个section的name字段指向0，则他指向的字节值是0，则它没有名称，或名称是空。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ 中的Queue]]></title>
    <url>%2F2019%2F04%2F21%2Fcpp%E4%B8%AD%E7%9A%84queue%2F</url>
    <content type="text"><![CDATA[原文：http://www.cppblog.com/wanghaiguang/archive/2012/06/05/177644.html C++ Queues(队列) C++队列是一种容器适配器，它给予程序员一种先进先出(FIFO)的数据结构。1.back() 返回一个引用，指向最后一个元素2.empty() 如果队列空则返回真3.front() 返回第一个元素4.pop() 删除第一个元素5.push() 在末尾加入一个元素6.size() 返回队列中元素的个数 队列可以用线性表(list)或双向队列(deque)来实现(注意vector container 不能用来实现queue，因为vector 没有成员函数pop_front!)：queue&lt;list&lt;int&gt;&gt; q1queue&lt;deque&lt;int&gt;&gt; q2其成员函数有“判空(empty)” 、“尺寸(Size)” 、“首元(front)” 、“尾元(backt)” 、“加入队列(push)” 、“弹出队列(pop)”等操作。 例：12345678int main()&#123; queue&lt;int&gt; q; q.push(4); q.push(5); printf(&quot;%d\n&quot;,q.front()); q.pop();&#125; C++ Priority Queues(优先队列) C++优先队列类似队列，但是在这个数据结构中的元素按照一定的断言排列有序。1.empty() 如果优先队列为空，则返回真2.pop() 删除第一个元素3.push() 加入一个元素4.size() 返回优先队列中拥有的元素的个数5.top() 返回优先队列中有最高优先级的元素 优先级队列可以用向量(vector)或双向队列(deque)来实现(注意list container 不能用来实现queue，因为list 的迭代器不是任意存取iterator，而pop 中用到堆排序时是要求randomaccess iterator 的!)：priority_queue&lt;vector&lt;int&gt;, less&lt;int&gt;&gt; pq1; 使用递增less函数对象排序priority_queue&lt;deque&lt;int&gt;, greater&lt;int&gt;&gt; pq2; 使用递减greater函数对象排序其成员函数有“判空(empty)” 、“尺寸(Size)” 、“栈顶元素(top)” 、“压栈(push)” 、“弹栈(pop)”等。 priority_queue模版类有三个模版参数，元素类型，容器类型，比较算子。其中后两个都可以省略，默认容器为vector，默认算子为less，即小的往前排，大的往后排（出队时序列尾的元素出队）。 初学者在使用priority_queue时，最困难的可能就是如何定义比较算子了。如果是基本数据类型，或已定义了比较运算符的类，可以直接用STL的less算子和greater算子——默认为使用less算子，即小的往前排，大的先出队。如果要定义自己的比较算子，方法有多种，这里介绍其中的一种：重载比较运算符。优先队列试图将两个元素x和y代入比较运算符(对less算子，调用x&lt;y，对greater算子，调用x&gt;y)，若结果为真，则x排在y前面，y将先于x出队，反之，则将y排在x前面，x将先出队。 例：123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;queue&gt; using namespace std; class T &#123;public: int x, y, z; T(int a, int b, int c):x(a), y(b), z(c) &#123; &#125;&#125;;bool operator &lt; (const T &amp;t1, const T &amp;t2) &#123; return t1.z &lt; t2.z; // 按照z的顺序来决定t1和t2的顺序&#125; int main()&#123; priority_queue&lt;T&gt; q; q.push(T(4,4,3)); q.push(T(2,2,5)); q.push(T(1,5,4)); q.push(T(3,3,6)); while (!q.empty()) &#123; T t = q.top(); q.pop(); cout &lt;&lt; t.x &lt;&lt; &quot; &quot; &lt;&lt; t.y &lt;&lt; &quot; &quot; &lt;&lt; t.z &lt;&lt; endl; &#125; return 1; &#125; 输出结果为(注意是按照z的顺序从大到小出队的)： 3 3 6 2 2 5 1 5 4 4 4 3 再看一个按照z的顺序从小到大出队的例子：123456789101112131415161718192021222324252627282930#include &lt;iostream&gt; #include &lt;queue&gt; using namespace std; class T &#123; public: int x, y, z; T(int a, int b, int c):x(a), y(b), z(c) &#123; &#125; &#125;; bool operator &gt; (const T &amp;t1, const T &amp;t2) &#123; return t1.z &gt; t2.z; &#125; main() &#123; priority_queue&lt;T, vector&lt;T&gt;, greater&lt;T&gt; &gt; q; q.push(T(4,4,3)); q.push(T(2,2,5)); q.push(T(1,5,4)); q.push(T(3,3,6)); while (!q.empty()) &#123; T t = q.top(); q.pop(); cout &lt;&lt; t.x &lt;&lt; &quot; &quot; &lt;&lt; t.y &lt;&lt; &quot; &quot; &lt;&lt; t.z &lt;&lt; endl; &#125; return 1; &#125; 输出结果为： 4 4 3 1 5 4 2 2 5 3 3 6]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git 常用技巧]]></title>
    <url>%2F2019%2F04%2F21%2Fgit%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[Git的奇技淫巧:see_no_evil:Git是一个 “分布式版本管理工具”，简单的理解版本管理工具：大家在写东西的时候都用过 “回撤” 这个功能，但是回撤只能回撤几步，假如想要找回我三天之前的修改，光用 “回撤” 是找不回来的。而 “版本管理工具” 能记录每次的修改，只要提交到版本仓库，你就可以找到之前任何时刻的状态（文本状态）。 下面的内容就是列举了常用的 Git 命令和一些小技巧，可以通过 “页面内查找” 的方式进行快速查询：Ctrl/Command+f。 开卷必读如果之前未使用过 Git，可以学习 Git 小白教程入门 一定要先测试命令的效果后，再用于工作环境中，以防造成不能弥补的后果！到时候别拿着砍刀来找我 所有的命令都在git version 2.7.4 (Apple Git-66)下测试通过 统一概念： 工作区：改动（增删文件和内容） 暂存区：输入命令：git add 改动的文件名，此次改动就放到了 ‘暂存区’ 本地仓库(简称：本地)：输入命令：git commit 此次修改的描述，此次改动就放到了 ’本地仓库’，每个 commit，我叫它为一个 ‘版本’。 远程仓库(简称：远程)：输入命令：git push 远程仓库，此次改动就放到了 ‘远程仓库’（GitHub 等) commit-id：输出命令：git log，最上面那行 commit xxxxxx，后面的字符串就是 commit-id 目录 展示帮助信息 回到远程仓库的状态 重设第一个commit 展示工作区和暂存区的不同 展示暂存区和最近版本的不同 展示暂存区、工作区和最近版本的不同 快速切换到上一个分支 删除已经合并到 master 的分支 展示本地分支关联远程仓库的情况 关联远程分支 列出所有远程分支 列出本地和远程分支 创建并切换到本地分支 从远程分支中创建并切换到本地分支 删除本地分支 删除远程分支 重命名本地分支 查看标签 查看标签详细信息 本地创建标签 推送标签到远程仓库 删除本地标签 删除远程标签 切回到某个标签 放弃工作区的修改 恢复删除的文件 以新增一个 commit 的方式还原某一个 commit 的修改 回到某个 commit 的状态，并删除后面的 commit 修改上一个 commit 的描述 查看 commit 历史 显示本地更新过 HEAD 的 git 命令记录 修改作者名 修改远程仓库的 url 增加远程仓库 列出所有远程仓库 查看两个星期内的改动 把 A 分支的某一个 commit，放到 B 分支上 给 git 命令起别名 存储当前的修改，但不用提交 commit 保存当前状态，包括 untracked 的文件 展示所有 stashes 回到某个 stash 的状态 回到最后一个 stash 的状态，并删除这个 stash 删除所有的 stash 从 stash 中拿出某个文件的修改 展示所有 tracked 的文件 展示所有 untracked 的文件 展示所有忽略的文件 强制删除 untracked 的文件 强制删除 untracked 的目录 展示简化的 commit 历史 查看某段代码是谁写的 把某一个分支到导出成一个文件 从包中导入分支 执行 rebase 之前自动 stash 从远程仓库根据 ID，拉下某一状态，到本地分支 详细展示一行中的修改 清除 .gitignore 文件中记录的文件 展示所有 alias 和 configs 展示忽略的文件 commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit 在 commit log 中显示 GPG 签名 删除全局设置 新建并切换到新分支上，同时这个分支没有任何 commit 展示任意分支某一文件的内容 clone 下来指定的单一分支 忽略某个文件的改动 忽略文件的权限变化 以最后提交的顺序列出所有 Git 分支 在 commit log 中查找相关内容 把暂存区的指定 file 放到工作区中 强制推送 一图详解 优雅的提交Commit信息 联系我 展示帮助信息1git help -g The command output as below: 12345678910111213141516171819The common Git guides are: attributes Defining attributes per path cli Git command-line interface and conventions core-tutorial A Git core tutorial for developers cvs-migration Git for CVS users diffcore Tweaking diff output everyday A useful minimum set of commands for Everyday Git glossary A Git Glossary hooks Hooks used by Git ignore Specifies intentionally untracked files to ignore modules Defining submodule properties namespaces Git namespaces repository-layout Git Repository Layout revisions Specifying revisions and ranges for Git tutorial A tutorial introduction to Git tutorial-2 A tutorial introduction to Git: part two workflows An overview of recommended workflows with Git&apos;git help -a&apos; and &apos;git help -g&apos; list available subcommands and some concept guides. See &apos;git help &lt;command&gt;&apos; or &apos;git help &lt;concept&gt;&apos; to read about a specific subcommand or concept. 回到远程仓库的状态抛弃本地所有的修改，回到远程仓库的状态。1git fetch --all &amp;&amp; git reset --hard origin/master 重设第一个 commit也就是把所有的改动都重新放回工作区，并清空所有的 commit，这样就可以重新提交第一个 commit 了 1git update-ref -d HEAD 展示工作区和暂存区的不同输出工作区和暂存区的 different (不同)。 1git diff 还可以展示本地仓库中任意两个 commit 之间的文件变动：1git diff &lt;commit-id&gt; &lt;commit-id&gt; 展示暂存区和最近版本的不同输出暂存区和本地最近的版本 (commit) 的 different (不同)。1git diff --cached 展示暂存区、工作区和最近版本的不同输出工作区、暂存区 和本地最近的版本 (commit) 的 different (不同)。 1git diff HEAD 快速切换到上一个分支1git checkout - 删除已经合并到 master 的分支1git branch --merged master | grep -v '^\*\| master' | xargs -n 1 git branch -d 展示本地分支关联远程仓库的情况1git branch -vv 关联远程分支关联之后，git branch -vv 就可以展示关联的远程分支名了，同时推送到远程仓库直接：git push，不需要指定远程仓库了。1git branch -u origin/mybranch 或者在 push 时加上 -u 参数1git push origin/mybranch -u 列出所有远程分支-r 参数相当于：remote1git branch -r 列出本地和远程分支-a 参数相当于：all1git branch -a 创建并切换到本地分支1git checkout -b &lt;branch-name&gt; 从远程分支中创建并切换到本地分支1git checkout -b &lt;branch-name&gt; origin/&lt;branch-name&gt; 删除本地分支1git branch -d &lt;local-branchname&gt; 删除远程分支1git push origin --delete &lt;remote-branchname&gt; 或者 1git push origin :&lt;remote-branchname&gt; 重命名本地分支1git branch -m &lt;new-branch-name&gt; 查看标签1git tag 展示当前分支的最近的 tag 1git describe --tags --abbrev=0 查看标签详细信息1git tag -ln 本地创建标签1git tag &lt;version-number&gt; 默认 tag 是打在最近的一次 commit 上，如果需要指定 commit 打 tag：1$ git tag -a &lt;version-number&gt; -m "v1.0 发布(描述)" &lt;commit-id&gt; 推送标签到远程仓库首先要保证本地创建好了标签才可以推送标签到远程仓库： 1git push origin &lt;local-version-number&gt; 一次性推送所有标签，同步到远程仓库： 1git push origin --tags 删除本地标签1git tag -d &lt;tag-name&gt; 删除远程标签删除远程标签需要先删除本地标签，再执行下面的命令： 1git push origin :refs/tags/&lt;tag-name&gt; 切回到某个标签一般上线之前都会打 tag，就是为了防止上线后出现问题，方便快速回退到上一版本。下面的命令是回到某一标签下的状态：1git checkout -b branch_name tag_name 放弃工作区的修改1git checkout &lt;file-name&gt; 放弃所有修改：1git checkout . 恢复删除的文件123git rev-list -n 1 HEAD -- &lt;file_path&gt; #得到 deleting_commitgit checkout &lt;deleting_commit&gt;^ -- &lt;file_path&gt; #回到删除文件 deleting_commit 之前的状态 以新增一个 commit 的方式还原某一个 commit 的修改1git revert &lt;commit-id&gt; 回到某个 commit 的状态，并删除后面的 commit和 revert 的区别：reset 命令会抹去某个 commit id 之后的所有 commit 1234567git reset &lt;commit-id&gt; #默认就是-mixed参数。git reset –mixed HEAD^ #回退至上个版本，它将重置HEAD到另外一个commit,并且重置暂存区以便和HEAD相匹配，但是也到此为止。工作区不会被更改。git reset –soft HEAD~3 #回退至三个版本之前，只回退了commit的信息，暂存区和工作区与回退之前保持一致。如果还要提交，直接commit即可 git reset –hard &lt;commit-id&gt; #彻底回退到指定commit-id的状态，暂存区和工作区也会变为指定commit-id版本的内容 修改上一个 commit 的描述如果暂存区有改动，同时也会将暂存区的改动提交到上一个 commit 1git commit --amend 查看 commit 历史1git log 查看某段代码是谁写的blame 的意思为‘责怪’，你懂的。 1git blame &lt;file-name&gt; 显示本地更新过 HEAD 的 git 命令记录每次更新了 HEAD 的 git 命令比如 commint、amend、cherry-pick、reset、revert 等都会被记录下来（不限分支），就像 shell 的 history 一样。这样你可以 reset 到任何一次更新了 HEAD 的操作之后，而不仅仅是回到当前分支下的某个 commit 之后的状态。 1git reflog 修改作者名1git commit --amend --author='Author Name &lt;email@address.com&gt;' 修改远程仓库的 url1git remote set-url origin &lt;URL&gt; 增加远程仓库1git remote add origin &lt;remote-url&gt; 列出所有远程仓库1git remote 查看两个星期内的改动1git whatchanged --since='2 weeks ago' 把 A 分支的某一个 commit，放到 B 分支上这个过程需要 cherry-pick 命令，参考 1git checkout &lt;branch-name&gt; &amp;&amp; git cherry-pick &lt;commit-id&gt; 给 git 命令起别名简化命令 12345git config --global alias.&lt;handle&gt; &lt;command&gt;比如：git status 改成 git st，这样可以简化命令git config --global alias.st status 存储当前的修改，但不用提交 commit详解可以参考廖雪峰老师的 git 教程1git stash 保存当前状态，包括 untracked 的文件untracked 文件：新建的文件1git stash -u 展示所有 stashes1git stash list 回到某个 stash 的状态1git stash apply &lt;stash@&#123;n&#125;&gt; 回到最后一个 stash 的状态，并删除这个 stash1git stash pop 删除所有的 stash1git stash clear 从 stash 中拿出某个文件的修改1git checkout &lt;stash@&#123;n&#125;&gt; -- &lt;file-path&gt; 展示所有 tracked 的文件1git ls-files -t 展示所有 untracked 的文件1git ls-files --others 展示所有忽略的文件1git ls-files --others -i --exclude-standard 强制删除 untracked 的文件可以用来删除新建的文件。如果不指定文件文件名，则清空所有工作的 untracked 文件。clean 命令，注意两点： clean 后，删除的文件无法找回 不会影响 tracked 的文件的改动，只会删除 untracked 的文件 1git clean &lt;file-name&gt; -f 强制删除 untracked 的目录可以用来删除新建的目录，注意:这个命令也可以用来删除 untracked 的文件。详情见上一条 1git clean &lt;directory-name&gt; -df 展示简化的 commit 历史1git log --pretty=oneline --graph --decorate --all 把某一个分支到导出成一个文件1git bundle create &lt;file&gt; &lt;branch-name&gt; 从包中导入分支新建一个分支，分支内容就是上面 git bundle create 命令导出的内容 1git clone repo.bundle &lt;repo-dir&gt; -b &lt;branch-name&gt; 执行 rebase 之前自动 stash1git rebase --autostash 从远程仓库根据 ID，拉下某一状态，到本地分支1git fetch origin pull/&lt;id&gt;/head:&lt;branch-name&gt; 详细展示一行中的修改1git diff --word-diff 清除 gitignore 文件中记录的文件1git clean -X -f 展示所有 alias 和 configs注意： config 分为：当前目录（local）和全局（golbal）的 config，默认为当前目录的 config 12git config --local --list (当前目录)git config --global --list (全局) 展示忽略的文件1git status --ignored commit 历史中显示 Branch1 有的，但是 Branch2 没有 commit1git log Branch1 ^Branch2 在 commit log 中显示 GPG 签名1git log --show-signature 删除全局设置1git config --global --unset &lt;entry-name&gt; 新建并切换到新分支上，同时这个分支没有任何 commit相当于保存修改，但是重写 commit 历史 1git checkout --orphan &lt;branch-name&gt; 展示任意分支某一文件的内容1git show &lt;branch-name&gt;:&lt;file-name&gt; clone 下来指定的单一分支1git clone -b &lt;branch-name&gt; --single-branch https://github.com/user/repo.git 忽略某个文件的改动关闭 track 指定文件的改动，也就是 Git 将不会在记录这个文件的改动 1git update-index --assume-unchanged path/to/file 恢复 track 指定文件的改动 1git update-index --no-assume-unchanged path/to/file 忽略文件的权限变化不再将文件的权限变化视作改动 1git config core.fileMode false 以最后提交的顺序列出所有 Git 分支最新的放在最上面 1git for-each-ref --sort=-committerdate --format='%(refname:short)' refs/heads/ 在 commit log 中查找相关内容通过 grep 查找，given-text：所需要查找的字段 1git log --all --grep='&lt;given-text&gt;' 把暂存区的指定 file 放到工作区中不添加参数，默认是 -mixed 1git reset &lt;file-name&gt; 强制推送1git push -f &lt;remote-name&gt; &lt;branch-name&gt; 一图详解 优雅的提交Commit信息使用Angular团队提交规范 主要有以下组成 标题行: 必填, 描述主要修改类型和内容 主题内容: 描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释: 放 Breaking Changes 或 Closed Issues 常用的修改项 type: commit 的类型 feat: 新特性 fix: 修改问题 refactor: 代码重构 docs: 文档修改 style: 代码格式修改, 注意不是 css 修改 test: 测试用例修改 chore: 其他修改, 比如构建流程, 依赖管理. scope: commit 影响的范围, 比如: route, component, utils, build… subject: commit 的概述 body: commit 具体修改内容, 可以分为多行 footer: 一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接.]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode72. Edit Distance]]></title>
    <url>%2F2019%2F04%2F21%2FLeetcode72%2F</url>
    <content type="text"><![CDATA[Edit DistanceGiven two words word1 and word2, find the minimum number of operations required to convert word1 to word2. You have the following 3 operations permitted on a word: Insert a characterDelete a characterReplace a characterExample 1:123456Input: word1 = &quot;horse&quot;, word2 = &quot;ros&quot;Output: 3Explanation: horse -&gt; rorse (replace &apos;h&apos; with &apos;r&apos;)rorse -&gt; rose (remove &apos;r&apos;)rose -&gt; ros (remove &apos;e&apos;) Example 2:12345678Input: word1 = &quot;intention&quot;, word2 = &quot;execution&quot;Output: 5Explanation: intention -&gt; inention (remove &apos;t&apos;)inention -&gt; enention (replace &apos;i&apos; with &apos;e&apos;)enention -&gt; exention (replace &apos;n&apos; with &apos;x&apos;)exention -&gt; exection (replace &apos;n&apos; with &apos;c&apos;)exection -&gt; execution (insert &apos;u&apos;) 一道好久不做的dp题，过段时间闲下来复习下dp 给你word1、word2两个字符串，问最少需要几步才能把word1变成word2，下面每种操作都是一步：a)添加一个字符；b)添加一个字符；c)把一个字符用另一个字符代替。 解题思路： 动态规划。用dp[i][j]表示把word1的前i个字符变成word2的前j个字符所需的步数，word1的前i个字符变成word2的前j个字符可以由三种方法得到： word1先删去最后一个字符，然后把word1的前i-1个字符变成word2的前j个字符； word1的前i个字符先变成word2的前j-1个字符；然后word2最后添上一个字符； word1的前i-1个字符先变成word2的前j-1个字符；然后word1的最后一个字符和word2的最后一个字符匹配上。 因此有状态转移方程：当word1[i-1]==word2[j-1]时dp[i][j]=dp[i-1][j-1]，否则dp[i][j]=min(dp[i-1][j]+1,dp[i][j-1]+1,dp[i-1][j-1]+1)。 另外边界需要初始化：dp[0][0]=0，dp[i][0]=i对于i从1到len1，dp[0][i]=i对于i从1到len2,。最终答案为dp[len1][len2]，算法复杂度为O(len1*len2)。 算法正确性： 算法的关键点在于是否可以用动态规划的思想把问题拆分成一个个子问题。可以这么考虑：当你能确定用了若干步把word1的前i个字母变成word2的前j个字母后，接下来就可以处理相邻的状态。对于删除字母，可以把word1的第i+1个字母先删掉，然后再执行那若干步，这样可以得到把word1的前i+1个字母变成word2的前j个字母的步数；对于添加字母，可以先执行那若干步，再加上word2的第j+1个字母，这样可以得到把word1的前i个字母变成word2的前j+1个字母的步数；对于代替字母，可以先执行那若干步，再把word1的第i+1个字母和word2的第j+1个字母匹配上，这样可以得到把word1的前i+1个字母变成word2的前j+1个字母的步数。因此上述算法是正确的。 下面举一个简单例子走一遍算法帮助理解：word1=”ad”，word2=”abc”。初始化：dp[0][0]=0，dp[1][0]=1，dp[2][0]=2，dp[0][1]=1，dp[0][2]=2，dp[0][3]=3；i=1，j=1，word1[0]==word2[0]，dp[1][1]=min(dp[0][1]+1,dp[1][0]+1,dp[0][0])=0；i=1，j=2，word1[0]!=word2[1]，dp[1][2]=min(dp[0][2]+1,dp[1][1]+1,dp[0][1]+1)=2；i=1，j=3，word1[0]!=word2[2]，dp[1][3]=min(dp[0][3]+1,dp[1][2]+1,dp[0][2]+1)=3；i=2，j=1，word1[1]!=word2[0]，dp[2][1]=min(dp[1][1]+1,dp[2][0]+1,dp[1][0]+1)=1；i=2，j=2，word1[1]!=word2[1]，dp[2][2]=min(dp[1][2]+1,dp[2][1]+1,dp[1][1]+1)=1；i=2，j=3，word1[1]!=word2[2]，dp[2][3]=min(dp[1][3]+1,dp[2][2]+1,dp[1][2]+1)=2；最终结果为dp[2][3]=3。 12345678910111213141516171819class Solution &#123;public: int minDistance(string word1, string word2) &#123; int len1=word1.size(),len2=word2.size(); int dp[len1+1][len2+1]; for(int i=0;i&lt;len1+1;i++) dp[i][0]=i; for(int i=0;i&lt;len2+1;i++) dp[0][i]=i; for(int i=1;i&lt;len1+1;i++) for(int j=1;j&lt;len2+1;j++)&#123; if(word1[i-1]==word2[j-1]) dp[i][j]=dp[i-1][j-1];//两个字符相等 else dp[i][j]=min(dp[i-1][j]+1,min(dp[i][j-1]+1,dp[i-1][j-1]+1));//两个字符不相等 &#125; return dp[len1][len2]; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[malloc 函数详解]]></title>
    <url>%2F2019%2F04%2F20%2Fmalloc%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://www.cnblogs.com/Commence/p/5785912.html malloc只是C标准库中提供的一个普通函数 而且很多很多人都对malloc的具体实现机制不是很了解。 关于malloc以及相关的几个函数123456#include &lt;stdlib.h&gt;(Linux下)void *malloc(size_t size);void free(void *ptr);void *calloc(size_t nmemb, size_t size);void *realloc(void *ptr, size_t size); 也可以这样认为（window下）原型：extern void *malloc(unsigned int num_bytes);头文件：#include &lt;malloc.h&gt;或者#include &lt;alloc.h&gt;两者的内容是完全一样的。 如果分配成功：则返回指向被分配内存空间的指针，不然，返回空指针NULL。当内存不再使用的时候，应使用free（）函数将内存块释放掉。void ,表示未确定类型的指针。C，C++规定，void 类型可以强转为任何其他类型的的指针。 malloc returns a void pointer to the allocated space, or NULL if there is insufficient memory available. To return a pointer to a type other than void, use a type cast on the return value. The storage space pointed to by the return value is guaranteed to be suitably aligned for storage of any type of object. If size is 0, malloc allocates a zero-length item in the heap and returns a valid pointer to that item. Always check the return from malloc, even if the amount of memory requested is small. 关于void *的其他说法：123void * p1;int *p2;p1 = p2; 就是说其他任意类型都可以直接赋值给它，无需进行强转，但是反过来不可以。 malloc： malloc分配的内存大小至少为size参数所指定的字节数 malloc的返回值是一个指针，指向一段可用内存的起始地址 多次调用malloc所分配的地址不能有重叠部分，除非某次malloc所分配的地址被释放掉 malloc应该尽快完成内存分配并返回（不能使用NP-hard的内存分配算法） 实现malloc时应同时实现内存大小调整和内存释放函数（realloc和free） malloc和free函数是配对的，如果申请后不释放就是内存泄露;如果无故释放那就是什么都没有做，释放只能释放一次，如果释放两次及两次以上会出现错误（但是释放空指针例外，释放空指针其实也等于什么都没有做，所以，释放多少次都是可以的） malloc和new new返回指定类型的指针，并且可以自动计算所需要的大小。123int *p;p = new int; //返回类型为int *类型，分配的大小为sizeof(int)p = new int[100]; //返回类型为int *类型，分配的大小为sizeof(int) * 100 而malloc则必须由我们计算字节数，并且在返回的时候强转成实际指定类型的指针。12int *p;p = (int *)malloc(sizeof(int)); malloc的返回是void ,如果我们写成了: p = malloc(sizeof(int));间接的说明了（将void 转化给了int *,这不合理） malloc的实参是sizeof(int),用于指明一个整形数据需要的大小，如果我们写成：p = （int *）malloc(1),那么可以看出：只是申请了一个字节的空间，如果向里面存放了一个整数的话，将会占用额外的3个字节，可能会改变原有内存空间中的数据； malloc只管分配内存，并不能对其进行初始化，所以得到的一片新内存中，其值将是随机的。一般意义上：我们习惯性的将其初始化为NULL。当然,也可以用memset函数的。 简单的说： malloc 函数其实就是在内存中：找一片指定大小的空间，然后将这个空间的首地址给一个指针变量，这里的指针变量可以是一个单独的指针，也可以是一个数组的首地址， 这要看malloc函数中参数size的具体内容。我们这里malloc分配的内存空间在逻辑上是连续的，而在物理上可以不连续。我们作为程序员，关注的 是逻辑上的连续，其它的，操作系统会帮着我们处理的。 下面我们聊聊malloc的具体实现机制： Linux内存管理虚拟内存地址与物理内存地址为了简单，现代操作系统在处理内存地址时，普遍采用虚拟内存地址技术。即在汇编程序（或机器语言）层面，当涉及内存地址时， 都是使用虚拟内存地址。采用这种技术时，每个进程仿佛自己独享一片2N字节的内存，其中N是机器位数。例如在64位CPU和64位操作系统下，每个进程的 虚拟地址空间为264Byte。 这种虚拟地址空间的作用主要是简化程序的编写及方便操作系统对进程间内存的隔离管理，真实中的进程不太可能（也用不到）如此大的内存空间，实际能用到的内存取决于物理内存大小。 由于在机器语言层面都是采用虚拟地址，当实际的机器码程序涉及到内存操作时，需要根据当前进程运行的实际上下文将虚拟地址转换为物理内存地址，才能实现对真实内存数据的操作。这个转换一般由一个叫MMU（Memory Management Unit）的硬件完成。 页与地址构成在现代操作系统中，不论是虚拟内存还是物理内存，都不是以字节为单位进行管理的，而是以页（Page）为单位。一个内存页是一段固定大小的连续内存地址的总称，具体到Linux中，典型的内存页大小为4096Byte（4K）。 所以内存地址可以分为页号和页内偏移量。下面以64位机器，4G物理内存，4K页大小为例，虚拟内存地址和物理内存地址的组成如下： 上面是虚拟内存地址，下面是物理内存地址。由于页大小都是4K，所以页内便宜都是用低12位表示，而剩下的高地址表示页号。 MMU映射单位并不是字节，而是页，这个映射通过查一个常驻内存的数据结构页表来实现。现在计算机具体的内存地址映射比较复杂，为了加快速度会引入一系列缓存和优化，例如TLB等机制。下面给出一个经过简化的内存地址翻译示意图，虽然经过了简化，但是基本原理与现代计算机真实的情况的一致的。 内存页与磁盘页我们知道一般将内存看做磁盘的的缓存，有时MMU在工作时，会发现页表表明某个内存页不在物理内存中，此时会触发一个缺页异 常（Page Fault），此时系统会到磁盘中相应的地方将磁盘页载入到内存中，然后重新执行由于缺页而失败的机器指令。关于这部分，因为可以看做对malloc实现 是透明的，所以不再详细讲述，有兴趣的可以参考《深入理解计算机系统》相关章节。附上一张在维基百科找到的更加符合真实地址翻译的流程供大家参考，这张图加入了TLB和缺页异常的流程。 Linux进程级内存管理内存排布明白了虚拟内存和物理内存的关系及相关的映射机制，下面看一下具体在一个进程内是如何排布内存的。 以Linux 64位系统为例。理论上，64bit内存地址可用空间为0x0000000000000000 ~ 0xFFFFFFFFFFFFFFFF，这是个相当庞大的空间，Linux实际上只用了其中一小部分（256T）。 根据Linux内核相关文档描述，Linux64位操作系统仅使用低47位，高17位做扩展（只能是全0或全1）。所以，实际用到的地址为空间为0x0000000000000000 ~ 0x00007FFFFFFFFFFF和0xFFFF800000000000 ~ 0xFFFFFFFFFFFFFFFF，其中前面为用户空间（User Space），后者为内核空间（Kernel Space）。图示如下： 对用户来说，主要关注的空间是User Space。将User Space放大后，可以看到里面主要分为如下几段： Code：这是整个用户空间的最低地址部分，存放的是指令（也就是程序所编译成的可执行机器码） Data：这里存放的是初始化过的全局变量 BSS：这里存放的是未初始化的全局变量 Heap：堆，这是我们本文重点关注的地方，堆自低地址向高地址增长，后面要讲到的brk相关的系统调用就是从这里分配内存 Mapping Area：这里是与mmap系统调用相关的区域。大多数实际的malloc实现会考虑通过mmap分配较大块的内存区域，本文不讨论这种情况。这个区域自高地址向低地址增长 Stack：这是栈区域，自高地址向低地址增长 Heap内存模型一般来说，malloc所申请的内存主要从Heap区域分配（本文不考虑通过mmap申请大块内存的情况）。 由上文知道，进程所面对的虚拟内存地址空间，只有按页映射到物理内存地址，才能真正使用。受物理存储容量限制，整个堆虚拟内存空间不可能全部映射到实际的物理内存。Linux对堆的管理示意如下： Linux维护一个break指针，这个指针指向堆空间的某个地址。从堆起始地址到break之间的地址空间为映射好的，可以供进程访问；而从break往上，是未映射的地址空间，如果访问这段空间则程序会报错。 brk与sbrk由上文知道，要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过brk和sbrk系统调用操作break指针。两个系统调用的原型如下：12int brk(void *addr);void *sbrk(intptr_t increment); brk将break指针直接设置为某个地址，而sbrk将break从当前位置移动increment所指定的增量。brk 在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break移动之前所指向的地址，否则返回(void *)-1。 一个小技巧是，如果将increment设置为0，则可以获得当前break的地址。 另外需要注意的是，由于Linux是按页进行内存映射的，所以如果break被设置为没有按页大小对齐，则系统实际上会在最 后映射一个完整的页，从而实际已映射的内存空间比break指向的地方要大一些。但是使用break之后的地址是很危险的（尽管也许break之后确实有 一小块可用内存地址）。 资源限制与rlimit 系统对每一个进程所分配的资源不是无限的，包括可映射的内存空间，因此每个进程有一个rlimit表示当前进程可用的资源上限。这个限制可以通过getrlimit系统调用得到，下面代码获取当前进程虚拟内存空间的rlimit：12345int main() &#123; struct rlimit *limit = (struct rlimit *)malloc(sizeof(struct rlimit)); getrlimit(RLIMIT_AS, limit); printf(&quot;soft limit: %ld, hard limit: %ld\n&quot;, limit-&gt;rlim_cur, limit-&gt;rlim_max);&#125; 其中rlimit是一个结构体：1234struct rlimit &#123;rlim_t rlim_cur; /* Soft limit */rlim_t rlim_max; /* Hard limit (ceiling for rlim_cur) */&#125;; 每种资源有软限制和硬限制，并且可以通过setrlimit对rlimit进行有条件设置。其中硬限制作为软限制的上限，非特权进程只能设置软限制，且不能超过硬限制。 实现malloc玩具实现在正式开始讨论malloc的实现前，我们可以利用上述知识实现一个简单但几乎没法用于真实的玩具malloc，权当对上面知识的复习：1234567891011/* 一个玩具malloc */#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void *malloc(size_t size)&#123; void *p; p = sbrk(0); if (sbrk(size) == (void *)-1) return NULL; return p;&#125; 这个malloc每次都在当前break的基础上增加size所指定的字节数，并将之前break的地址返回。这个malloc由于对所分配的内存缺乏记录，不便于内存释放，所以无法用于真实场景。 正式实现下面严肃点讨论malloc的实现方案。 数据结构首先我们要确定所采用的数据结构。一个简单可行方案是将堆内存空间以块（Block）的形式组织起来，每个块由meta区和 数据区组成，meta区记录数据块的元信息（数据区大小、空闲标志位、指针等等），数据区是真实分配的内存区域，并且数据区的第一个字节地址即为 malloc返回的地址。 可以用如下结构体定义一个block：12345678typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 由于我们只考虑64位机器，为了方便，我们在结构体最后填充一个int，使得结构体本身的长度为8的倍数，以便内存对齐。示意图如下： 寻找合适的block现在考虑如何在block链中查找合适的block。一般来说有两种查找算法： First fit：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块Best fit：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块 两种方法各有千秋，best fit具有较高的内存使用率（payload较高），而first fit具有更好的运行效率。这里我们采用first fit算法。 123456789/* First fit */t_block find_block(t_block *last, size_t size) &#123;t_block b = first_block;while(b &amp;&amp; !(b-&gt;free &amp;&amp; b-&gt;size &gt;= size)) &#123; *last = b; b = b-&gt;next;&#125;return b;&#125; find_block从frist_block开始，查找第一个符合要求的block并返回block起始地址，如果找不到 这返回NULL。这里在遍历时会更新一个叫last的指针，这个指针始终指向当前遍历的block。这是为了如果找不到合适的block而开辟新 block使用的，具体会在接下来的一节用到。 开辟新的block如果现有block都不能满足size的要求，则需要在链表最后开辟一个新的block。这里关键是如何只使用sbrk创建一个struct：1234567891011121314#define BLOCK_SIZE 24 /* 由于存在虚拟的data字段，sizeof不能正确计算meta长度，这里手工设置 */ t_block extend_heap(t_block last, size_t s) &#123; t_block b; b = sbrk(0); if(sbrk(BLOCK_SIZE + s) == (void *)-1) return NULL; b-&gt;size = s; b-&gt;next = NULL; if(last) last-&gt;next = b; b-&gt;free = 0; return b;&#125; 分裂blockFirst fit有一个比较致命的缺点，就是可能会让很小的size占据很大的一块block，此时，为了提高payload，应该在剩余数据区足够大的情况下，将其分裂为一个新的block，示意如下：123456789void split_block(t_block b, size_t s) &#123; t_block new; new = b-&gt;data + s; new-&gt;size = b-&gt;size - s - BLOCK_SIZE ; new-&gt;next = b-&gt;next; new-&gt;free = 1; b-&gt;size = s; b-&gt;next = new;&#125; malloc的实现有了上面的代码，我们可以利用它们整合成一个简单但初步可用的malloc。注意首先我们要定义个block链表的头first_block，初始化为NULL；另外，我们需要剩余空间至少有BLOCK_SIZE + 8才执行分裂操作。 由于我们希望malloc分配的数据区是按8字节对齐，所以在size不为8的倍数时，我们需要将size调整为大于size的最小的8的倍数：123456789101112131415161718192021222324252627282930313233343536373839size_t align8(size_t s) &#123; if(s &amp; 0x7 == 0) return s; return ((s &gt;&gt; 3) + 1) &lt;&lt; 3;&#125;#define BLOCK_SIZE 24void *first_block=NULL; /* other functions... */ void *malloc(size_t size) &#123; t_block b, last; size_t s; /* 对齐地址 */ s = align8(size); if(first_block) &#123; /* 查找合适的block */ last = first_block; b = find_block(&amp;last, s); if(b) &#123; /* 如果可以，则分裂 */ if ((b-&gt;size - s) &gt;= ( BLOCK_SIZE + 8)) split_block(b, s); b-&gt;free = 0; &#125; else &#123; /* 没有合适的block，开辟一个新的 */ b = extend_heap(last, s); if(!b) return NULL; &#125; &#125; else &#123; b = extend_heap(NULL, s); if(!b) return NULL; first_block = b; &#125; return b-&gt;data;&#125; calloc的实现有了malloc，实现calloc只要两步： malloc一段内存 将数据区内容置为0由于我们的数据区是按8字节对齐的，所以为了提高效率，我们可以每8字节一组置0，而不是一个一个字节设置。我们可以通过新建一个size_t指针，将内存区域强制看做size_t类型来实现。1234567891011void *calloc(size_t number, size_t size) &#123; size_t *new; size_t s8, i; new = malloc(number * size); if(new) &#123; s8 = align8(number * size) &gt;&gt; 3; for(i = 0; i &lt; s8; i++) new[i] = 0; &#125; return new;&#125; free的实现free的实现并不像看上去那么简单，这里我们要解决两个关键问题： 如何验证所传入的地址是有效地址，即确实是通过malloc方式分配的数据区首地址 如何解决碎片问题首先我们要保证传入free的地址是有效的，这个有效包括两方面： 地址应该在之前malloc所分配的区域内，即在first_block和当前break指针范围内 这个地址确实是之前通过我们自己的malloc分配的 第一个问题比较好解决，只要进行地址比较就可以了，关键是第二个问题。这里有两种解决方案：一是在结构体内埋一个magic number字段，free之前通过相对偏移检查特定位置的值是否为我们设置的magic number，另一种方法是在结构体内增加一个magic pointer，这个指针指向数据区的第一个字节（也就是在合法时free时传入的地址），我们在free前检查magic pointer是否指向参数所指地址。这里我们采用第二种方案： 首先我们在结构体中增加magic pointer（同时要修改BLOCK_SIZE）：123456789typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 然后我们定义检查地址合法性的函数：1234567891011121314t_block get_block(void *p) &#123; char *tmp; tmp = p; return (p = tmp -= BLOCK_SIZE);&#125; int valid_addr(void *p) &#123; if(first_block) &#123; if(p &gt; first_block &amp;&amp; p &lt; sbrk(0)) &#123; return p == (get_block(p))-&gt;ptr; &#125; &#125;return 0;&#125; 当多次malloc和free后，整个内存池可能会产生很多碎片block，这些block很小，经常无法使用，甚至出现许多碎片连在一起，虽然总体能满足某此malloc要求，但是由于分割成了多个小block而无法fit，这就是碎片问题。 一个简单的解决方式时当free某个block时，如果发现它相邻的block也是free的，则将block和相邻block合并。为了满足这个实现，需要将s_block改为双向链表。修改后的block结构如下：12345678910typedef struct s_block *t_block;struct s_block &#123; size_t size; /* 数据区大小 */ t_block prev; /* 指向上个块的指针 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */&#125;; 合并方法如下：123456789t_block fusion(t_block b) &#123; if (b-&gt;next &amp;&amp; b-&gt;next-&gt;free) &#123; b-&gt;size += BLOCK_SIZE + b-&gt;next-&gt;size; b-&gt;next = b-&gt;next-&gt;next; if(b-&gt;next) b-&gt;next-&gt;prev = b; &#125; return b;&#125; 有了上述方法，free的实现思路就比较清晰了：首先检查参数地址的合法性，如果不合法则不做任何事；否则，将此block 的free标为1，并且在可以的情况下与后面的block进行合并。如果当前是最后一个block，则回退break指针释放进程内存，如果当前 block是最后一个block，则回退break指针并设置first_block为NULL。实现如下：123456789101112131415161718void free(void *p) &#123; t_block b; if(valid_addr(p)) &#123; b = get_block(p); b-&gt;free = 1; if(b-&gt;prev &amp;&amp; b-&gt;prev-&gt;free) b = fusion(b-&gt;prev); if(b-&gt;next) fusion(b); else &#123; if(b-&gt;prev) b-&gt;prev-&gt;prev = NULL; else first_block = NULL; brk(b); &#125; &#125;&#125; realloc的实现为了实现realloc，我们首先要实现一个内存复制方法。如同calloc一样，为了效率，我们以8字节为单位进行复制：12345678void copy_block(t_block src, t_block dst) &#123; size_t *sdata, *ddata; size_t i; sdata = src-&gt;ptr; ddata = dst-&gt;ptr; for(i = 0; (i * 8) &lt; src-&gt;size &amp;&amp; (i * 8) &lt; dst-&gt;size; i++) ddata[i] = sdata[i];&#125; 然后我们开始实现realloc。一个简单（但是低效）的方法是malloc一段内存，然后将数据复制过去。但是我们可以做的更高效，具体可以考虑以下几个方面： 如果当前block的数据区大于等于realloc所要求的size，则不做任何操作 如果新的size变小了，考虑split 如果当前block的数据区不能满足size，但是其后继block是free的，并且合并后可以满足，则考虑做合并 下面是realloc的实现：1234567891011121314151617181920212223242526272829303132333435void *realloc(void *p, size_t size) &#123; size_t s; t_block b, new; void *newp; if (!p) /* 根据标准库文档，当p传入NULL时，相当于调用malloc */ return malloc(size); if(valid_addr(p)) &#123; s = align8(size); b = get_block(p); if(b-&gt;size &gt;= s) &#123; if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8)) split_block(b,s); &#125; else &#123; /* 看是否可进行合并 */ if(b-&gt;next &amp;&amp; b-&gt;next-&gt;free &amp;&amp; (b-&gt;size + BLOCK_SIZE + b-&gt;next-&gt;size) &gt;= s) &#123; fusion(b); if(b-&gt;size - s &gt;= (BLOCK_SIZE + 8)) split_block(b, s); &#125; else &#123; /* 新malloc */ newp = malloc (s); if (!newp) return NULL; new = get_block(newp); copy_block(b, new); free(p); return(newp); &#125; &#125; return (p); &#125; return NULL;&#125; 遗留问题和优化以上是一个较为简陋，但是初步可用的malloc实现。还有很多遗留的可能优化点，例如： 同时兼容32位和64位系统在分配较大快内存时，考虑使用mmap而非sbrk，这通常更高效可以考虑维护多个链表而非单个，每个链表中的block大小均为一个范围内，例如8字节链表、16字节链表、24-32字节链表等等。此时可以根据size到对应链表中做分配，可以有效减少碎片，并提高查询block的速度可以考虑链表中只存放free的block，而不存放已分配的block，可以减少查找block的次数，提高效率还有很多可能的优化，这里不一一赘述。下面附上一些参考文献，有兴趣的同学可以更深入研究。 其它参考Computer Systems: A Programmer’s Perspective, 2/E一书有许多值得参考的地方]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode961. N-Repeated Element in Size 2N Array]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode961%2F</url>
    <content type="text"><![CDATA[N-Repeated Element in Size 2N ArrayIn a array A of size 2N, there are N+1 unique elements, and exactly one of these elements is repeated N times. Return the element repeated N times. Example 1:12Input: [1,2,3,3]Output: 3 Example 2:12Input: [2,1,2,5,3,2]Output: 2 Example 3:12Input: [5,1,5,2,5,3,5,4]Output: 5 Note: 4 &lt;= A.length &lt;= 100000 &lt;= A[i] &lt; 10000A.length is even 一个桶排序搞定12345678910111213class Solution &#123;public: int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; int counter[10000]; memset(counter,0,sizeof(counter)); for(int i=0;i&lt;A.size();i++)&#123; counter[A[i]]++; if(counter[A[i]]&gt;=A.size()/2) return A[i]; &#125; return -1; &#125;&#125;; 看到了大佬的解法，跪了，如果有两个连续一样的元素，直接返回 The intuition here is that the repeated numbers have to appear either next to each other (A[i] == A[i + 1]), or alternated (A[i] == A[i + 2]). The only exception is sequences like [2, 1, 3, 2]. In this case, the result is the last number, so we just return it in the end. This solution has O(n) runtime.12345int repeatedNTimes(vector&lt;int&gt;&amp; A) &#123; for (auto i = 0; i &lt; A.size() - 2; ++i) if (A[i] == A[i + 1] || A[i] == A[i + 2]) return A[i]; return A[A.size() - 1]; &#125; Another interesting approach is to use randomization (courtesy of @lee215 ). If you pick two numbers randomly, there is a 25% chance you bump into the repeated number. So, in average, we will find the answer in 4 attempts, thus O(4) runtime.1234int repeatedNTimes(vector&lt;int&gt;&amp; A, int i = 0, int j = 0) &#123; while (A[i = rand() % A.size()] != A[j = rand() % A.size()] || i == j); return A[i];&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++函数调用分析]]></title>
    <url>%2F2019%2F04%2F20%2Fcpp%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[这里以一个简单的C语言代码为例，来分析函数调用过程 代码：123456789101112131415161718#include &lt;stdio.h&gt;int func(int param1 ,int param2,int param3)&#123; int var1 = param1; int var2 = param2; int var3 = param3; printf(&quot;var1=%d,var2=%d,var3=%d&quot;,var1,var2,var3); return var1;&#125; int main(int argc, char* argv[])&#123; int result = func(1,2,3); return 0; &#125; 首先说明，在堆栈中变量分布是从高地址到低地址分布，EBP是指向栈底的指针，在过程调用中不变，又称为帧指针。ESP指向栈顶，程序执行时移动，ESP减小分配空间，ESP增大释放空间，ESP又称为栈指针。 下面来逐步分析函数的调用过程 函数main执行，main各个参数从右向左逐步压入栈中，最后压入返回地址 执行第15行，3个参数以从左向右的顺序压入堆栈，及从param3到param1，栈内分布如下图： 然后是返回地址入栈：此时的栈内分布如下： 第3行函数调用时，通过跳转指令进入函数后，函数地址入栈后，EBP入栈，然后把当前ESP的值给EBP，对应的汇编指令：12push ebpmov ebp esp 此时栈顶和栈底指向同一位置，栈内分布如下： 第5行开始执行， int var1 = param1; int var2 = param2; int var3 = param3;按申明顺序依次存储。对应的汇编：12mov 0x8(%ebp),%eaxmov %eax,-0x4(%ebp) 其中将[EBP+0x8]地址里的内容赋给EAX，即把param的值赋给EAX，然后把EAX的中的值放到[EBP-4]这个地址里，即把EAX值赋给var1，完成C代码 int var1 = param1，其他变量雷同。 第9行，输出结果，第10行执行 对应的汇编代码：1mov -0x4(%ebp),%eax 最后通过eax寄存器保存函数的返回值； 调用执行函数完毕，局部变量var3，var2，var1一次出栈，EBP恢复原值，返回地址出栈，找到原执行地址，param1，param2，param3依次出栈，函数调用执行完毕。图略]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1026. Maximum Difference Between Node and Ancestor]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1026%2F</url>
    <content type="text"><![CDATA[Maximum Difference Between Node and AncestorGiven the root of a binary tree, find the maximum value V for which there exists different nodes A and B where V = |A.val - B.val| and A is an ancestor of B. (A node A is an ancestor of B if either: any child of A is equal to B, or any child of A is an ancestor of B.) Example 1:123456789Input: [8,3,10,1,6,null,14,null,null,4,7,13]Output: 7Explanation: We have various ancestor-node differences, some of which are given below :|8 - 3| = 5|3 - 7| = 4|8 - 1| = 7|10 - 13| = 3Among all possible differences, the maximum value of 7 is obtained by |8 - 1| = 7. Note: The number of nodes in the tree is between 2 and 5000.Each node will have value between 0 and 100000. 给一棵树，找到最大值v，这个v是节点和祖先的值的差的绝对值。dfs里一定要有一个最大一个最小，这样才能算出来绝对值最大的一个，之前考虑只放一个值，没有搞定。一个dfs 123456789101112131415161718192021222324252627/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int val=0; void dfs(TreeNode* root,int maxval,int minval)&#123; val = max(val, abs(root-&gt;val - maxval)); val = max(val, abs(root-&gt;val - minval)); maxval = max(maxval, root-&gt;val); minval = min(minval, root-&gt;val); if(root-&gt;right) dfs(root-&gt;right,maxval,minval); if(root-&gt;left) dfs(root-&gt;left,maxval,minval); &#125; int maxAncestorDiff(TreeNode* root) &#123; dfs(root,root-&gt;val,root-&gt;val); return val; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1025. Divisor Game]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1025%2F</url>
    <content type="text"><![CDATA[Divisor GameEasy Alice and Bob take turns playing a game, with Alice starting first. Initially, there is a number N on the chalkboard. On each player’s turn, that player makes a move consisting of: Choosing any x with 0 &lt; x &lt; N and N % x == 0.Replacing the number N on the chalkboard with N - x.Also, if a player cannot make a move, they lose the game. Return True if and only if Alice wins the game, assuming both players play optimally. Example 1:123Input: 2Output: trueExplanation: Alice chooses 1, and Bob has no more moves. Example 2:123Input: 3Output: falseExplanation: Alice chooses 1, Bob chooses 1, and Alice has no more moves. Note: 1 &lt;= N &lt;= 1000 两个人玩游戏，给一个数字N，先轮到A走，A选一个数字x使得0 &lt; x &lt; N且N % x == 0，之后N变为N-x，如果谁选不出来x，那就输了，A遇见偶数赢，奇数输。 如果A看见偶数，就选x=1，则N变成奇数，B只能再选一个奇数，又把N变成偶数，由于1是奇数且1没法再选，故A遇见偶数一定赢，反之则输。 123456class Solution &#123;public: bool divisorGame(int N) &#123; return (N%2)==0; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1024. Video Stitching]]></title>
    <url>%2F2019%2F04%2F20%2FLeetcode1024%2F</url>
    <content type="text"><![CDATA[You are given a series of video clips from a sporting event that lasted T seconds. These video clips can be overlapping with each other and have varied lengths. Each video clip clips[i] is an interval: it starts at time clips[i][0] and ends at time clips[i][1]. We can cut these clips into segments freely: for example, a clip [0, 7] can be cut into segments [0, 1] + [1, 3] + [3, 7]. Return the minimum number of clips needed so that we can cut the clips into segments that cover the entire sporting event ([0, T]). If the task is impossible, return -1. 寻找最少的可以覆盖[0, T]区间的区间数量，一开始没搞定，看答案搞定的。总体思路就是一开始先排序，并且记下来两个end，一个是当前的end，一个是之前一次的end，如果现在这个小区间的end比之前的pre_end还小，直接不考虑了。我做的时候忽略了这一点，如果不记下来之前的per_end的话，可能有区间是重复的（现在这个小区间如果加进去了，就跟上次加进去的那个小区间有重复的部分或者重合） Example 1:1234567Input: clips = [[0,2],[4,6],[8,10],[1,9],[1,5],[5,9]], T = 10Output: 3Explanation: We take the clips [0,2], [8,10], [1,9]; a total of 3 clips.Then, we can reconstruct the sporting event as follows:We cut [1,9] into segments [1,2] + [2,8] + [8,9].Now we have segments [0,2] + [2,8] + [8,10] which cover the sporting event [0, 10]. Example 2:1234Input: clips = [[0,1],[1,2]], T = 5Output: -1Explanation: We can&apos;t cover [0,5] with only [0,1] and [0,2]. Example 3:1234Input: clips = [[0,1],[6,8],[0,2],[5,6],[0,4],[0,3],[6,7],[1,3],[4,7],[1,4],[2,5],[2,6],[3,4],[4,5],[5,7],[6,9]], T = 9Output: 3Explanation: We can take clips [0,4], [4,7], and [6,9]. Example 4:1234Input: clips = [[0,4],[2,8]], T = 5Output: 2Explanation: Notice you can have extra video after the event ends. Note: 1 &lt;= clips.length &lt;= 1000 &lt;= clips[i][0], clips[i][1] &lt;= 1000 &lt;= T &lt;= 100 12345678910111213141516171819202122232425262728class Solution &#123;public: static bool comp(const vector&lt;int&gt; &amp;a, const vector&lt;int&gt; &amp;b) &#123; if(a[0]==b[0]) return a[1] &gt; b[1]; return a[0] &lt; b[0]; &#125; int videoStitching(vector&lt;vector&lt;int&gt;&gt;&amp; clips, int T) &#123; sort(clips.begin(), clips.end(), comp); int count=0, cur_end=0, pre_end=-1; for(int i = 0; i &lt; clips.size(); i ++)&#123; if(clips[i][1] &lt;= cur_end) continue; if(clips[i][0] &gt; cur_end) return -1; if(clips[i][0] &gt; pre_end)&#123; pre_end = cur_end; count++; &#125; cur_end = clips[i][1]; if(cur_end &gt;= T) return count; &#125; return -1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1023. Camelcase Matching]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode1023%2F</url>
    <content type="text"><![CDATA[Camelcase Matching A query word matches a given pattern if we can insert lowercase letters to the pattern word so that it equals the query. (We may insert each character at any position, and may insert 0 characters.) Given a list of queries, and a pattern, return an answer list of booleans, where answer[i] is true if and only if queries[i] matches the pattern. Example 1:123456Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FB&quot;Output: [true,false,true,true,false]Explanation: &quot;FooBar&quot; can be generated like this &quot;F&quot; + &quot;oo&quot; + &quot;B&quot; + &quot;ar&quot;.&quot;FootBall&quot; can be generated like this &quot;F&quot; + &quot;oot&quot; + &quot;B&quot; + &quot;all&quot;.&quot;FrameBuffer&quot; can be generated like this &quot;F&quot; + &quot;rame&quot; + &quot;B&quot; + &quot;uffer&quot;. Example 2:12345Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FoBa&quot;Output: [true,false,true,false,false]Explanation: &quot;FooBar&quot; can be generated like this &quot;Fo&quot; + &quot;o&quot; + &quot;Ba&quot; + &quot;r&quot;.&quot;FootBall&quot; can be generated like this &quot;Fo&quot; + &quot;ot&quot; + &quot;Ba&quot; + &quot;ll&quot;. Example 3:1234Input: queries = [&quot;FooBar&quot;,&quot;FooBarTest&quot;,&quot;FootBall&quot;,&quot;FrameBuffer&quot;,&quot;ForceFeedBack&quot;], pattern = &quot;FoBaT&quot;Output: [false,true,false,false,false]Explanation: &quot;FooBarTest&quot; can be generated like this &quot;Fo&quot; + &quot;o&quot; + &quot;Ba&quot; + &quot;r&quot; + &quot;T&quot; + &quot;est&quot;. Note: 1 &lt;= queries.length &lt;= 1001 &lt;= queries[i].length &lt;= 1001 &lt;= pattern.length &lt;= 100All strings consists only of lower and upper case English letters. 给一个字符串和一个模式串，看能不能在模式串里加小写字母来转换成字符串，比较简单。123456789101112131415161718192021222324class Solution &#123;public: vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; queries, string pattern) &#123; vector&lt;bool&gt; ans; for(int i=0;i&lt;queries.size();i++)&#123; bool succ=true; int index=0; for(int j=0;j&lt;queries[i].size();j++)&#123; while(islower(queries[i][j])&amp;&amp; pattern[index]!=queries[i][j])&#123; j++; &#125; if(pattern[index]==queries[i][j]) index++; else&#123; succ=false; break; &#125; &#125; ans.push_back(succ); &#125; return ans; &#125;&#125;; 我的代码比较慢，可以看看大佬们怎么写的。 Solution 1, FindFor each query, find all letters in pattern left-to-right. If we found all pattern letters, check that the rest of the letters is in the lower case. 对每个查询，从左到右找pattern里的字幕，如果找到了，检查剩余的是否是小写字母。感觉跟我的类似。 For simplicity, we can replace the found pattern letter in query with a lowercase ‘a’.1234567891011121314vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; qs, string pattern, vector&lt;bool&gt; res = &#123;&#125;) &#123; for (auto i = 0; i &lt; qs.size(); ++i) &#123; for (auto p = -1, j = 0; j &lt; pattern.size(); ++j) &#123; p = qs[i].find(pattern[j], p + 1); if (p == string::npos) &#123; res.push_back(false); break; &#125; qs[i][p] = &apos;a&apos;; &#125; if (res.size() &lt;= i) res.push_back(all_of(begin(qs[i]), end(qs[i]), [](char ch) &#123; return islower(ch); &#125;)); &#125; return res;&#125; Solution 2, Simple ScanInstead of using the find function, we can just check all characters in the query. If a character matches the pattern pointer (pattern[p]), we advance that pointer (++p). Otherwise, we check that the query character is in the lower case. 检查查询的字符串，如果一个字符与pattern[p]匹配了，就继续，如果不匹配，看是不是小些 With this solution, it’s also easer to realize that the complexity is O(n), where n is the total number of query characters.12345678910vector&lt;bool&gt; camelMatch(vector&lt;string&gt;&amp; qs, string pattern, vector&lt;bool&gt; res = &#123;&#125;) &#123; for (auto i = 0, j = 0, p = 0; i &lt; qs.size(); ++i) &#123; for (j = 0, p = 0; j &lt; qs[i].size(); ++j) &#123; if (p &lt; pattern.size() &amp;&amp; qs[i][j] == pattern[p]) ++p; else if (!islower(qs[i][j])) break; &#125; res.push_back(j == qs[i].size() &amp;&amp; p == pattern.size()); &#125; return res;&#125; Complexity AnalysisRuntime: O(n), where n is all letters in all queries. We process each letter only once.Memory: O(m), where m is the number of queries (to store the result).时间复杂度O(n)，空间复杂度O(m)]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode129. Sum Root to Leaf Numbers]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode129%2F</url>
    <content type="text"><![CDATA[Sum Root to Leaf Numbers Given a binary tree containing digits from 0-9 only, each root-to-leaf path could represent a number. An example is the root-to-leaf path 1-&gt;2-&gt;3 which represents the number 123. Find the total sum of all root-to-leaf numbers. Note: A leaf is a node with no children. Example:123456789Input: [1,2,3] 1 / \ 2 3Output: 25Explanation:The root-to-leaf path 1-&gt;2 represents the number 12.The root-to-leaf path 1-&gt;3 represents the number 13.Therefore, sum = 12 + 13 = 25. Example 2:123456789101112Input: [4,9,0,5,1] 4 / \ 9 0 / \5 1Output: 1026Explanation:The root-to-leaf path 4-&gt;9-&gt;5 represents the number 495.The root-to-leaf path 4-&gt;9-&gt;1 represents the number 491.The root-to-leaf path 4-&gt;0 represents the number 40.Therefore, sum = 495 + 491 + 40 = 1026. 跟1022一样的代码，只是变成了十进制 12345678910111213141516171819202122232425262728293031/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int result; void dfs(TreeNode* root ,int now)&#123; if(!root) return; if(!root-&gt;left &amp;&amp; !root-&gt;right)&#123; result += (now*10) + root-&gt;val; &#125; int val = (now*10) + root-&gt;val; if(root-&gt;left) dfs(root-&gt;left, val); if(root-&gt;right) dfs(root-&gt;right, val); &#125; int sumNumbers(TreeNode* root) &#123; result=0; dfs(root,0); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1022. Sum of Root To Leaf Binary Numbers]]></title>
    <url>%2F2019%2F04%2F19%2FLeetcode1022%2F</url>
    <content type="text"><![CDATA[Sum of Root To Leaf Binary Numbers Given a binary tree, each node has value 0 or 1. Each root-to-leaf path represents a binary number starting with the most significant bit. For example, if the path is 0 -&gt; 1 -&gt; 1 -&gt; 0 -&gt; 1, then this could represent 01101 in binary, which is 13. For all leaves in the tree, consider the numbers represented by the path from the root to that leaf. Return the sum of these numbers. 深度优先遍历一波，因为好久没写dsf了，所以特地写一写。1234567891011121314151617181920212223242526272829/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int result; void dfs(TreeNode* root ,int now)&#123; if(!root-&gt;left &amp;&amp; !root-&gt;right)&#123; result += (now&lt;&lt;1) + root-&gt;val; &#125; int val = (now&lt;&lt;1) + root-&gt;val; if(root-&gt;left) dfs(root-&gt;left, val); if(root-&gt;right) dfs(root-&gt;right, val); &#125; int sumRootToLeaf(TreeNode* root) &#123; result=0; dfs(root,0); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux shell 逻辑运算符、逻辑表达式详解]]></title>
    <url>%2F2019%2F04%2F19%2FLinux-shell-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6%E3%80%81%E9%80%BB%E8%BE%91%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[链接：https://zhuanlan.zhihu.com/p/65106362 前言在linux下使用shell编程常常能够极大简化我们的工作。本文总结了Shell编程必备的基础知识。 入参和默认变量对于shell脚本而言，有些内容是专门用于处理参数的，它们都有特定的含义，例如： /home/shouwang/test.sh para1 para2 para3 $0 $1 $2 $3 脚本名 第一个参数 第三个参数 除此之外，还有一些其他的默认变量，例如： $# 代表脚本后面跟的参数个数，前面的例子中有3个参数 $@ 代表了所有参数，并且可以被遍历 $* 代表了所有参数，且作为整体，和$@很像，但是有区别 $$ 代表了当前脚本的进程ID $? 代表了上一条命令的退出状态 变量给变量赋值，使用等号即可，但是等号两边千万不要有空格，等号右边有空格的字符串也必须用引号引起来：para1=&quot;hello world&quot;表示字符串直接赋给变量para1 unset用于取消变量。例如：unset para1 如何使用变量呢？使用变量时，需要在变量前加$. 例如要打印前面para1的内容：echo &quot;para1 is $para1&quot;，将会输出para1 is hello world。或者变量名两边添加大括号：echo &quot;para1 is ${para1}!&quot;，将会输出para1 is hello world! 命令执行在shell中执行命令通常只需要像在终端一样执行命令即可，不过，如果想要命令结果打印出来的时候，这样的方式就行不通了。因此，shell的命令方式常有：1a=`ls` “`“是左上角~键，不是单引号。 或者使用$，后面括号内是执行的命令：echo &quot;current path is $(pwd)&quot; 。 另外，前面两种方式对于计算表达式也是行不通的，而要采取下面的方式：echo &quot;1+1=$((1+1))&quot;，打印：1+1=2，即$后面用两重括号将要计算的表达式包裹起来。那如果要执行的命令存储在变量中呢？前面的方法都不可行了，当然括号内的内容被当成命令执行还是成立的。要使用下面的方式，例如： a=&quot;ls&quot; echo &quot;$($a)&quot; 但是如果字符串时多条命令的时候，上面的方式又不可行了，而要采用下面的方式： a=&quot;ls;pwd&quot; echo &quot;$(eval $a)&quot; 这是使用了eval，将a的内容都作为命令来执行。 条件分支一般说明，如果命令执行成功，则其返回值为0，否则为非0，因此，可以通过下面的方式判断上条命令的执行结果：123456if [ $? -eq 0 ]then echo &quot;success&quot;elif [ $? -eq 1 ]then echo &quot;failed,code is 1&quot;else echo &quot;other code&quot;fi case语句使用方法如下：123456789101112131415name=&quot;aa&quot; case $name in &quot;aa&quot;) echo &quot;name is $name&quot; ;; &quot;&quot;) echo &quot;name is empty&quot; ;; &quot;bb&quot;) echo &quot;name is $name&quot; ;; *) echo &quot;other name&quot; ;;esac 初学者特别需要注意以下几点： []前面要有空格，它里面是逻辑表达式 if elif后面要跟then，然后才是要执行的语句 如果想打印上一条命令的执行结果，最好的做法是将$?赋给一个变量，因为一旦执行了一条命令$?的值就可能会变。 case每个分支最后以两个分号结尾，最后是case反过来写，即esac。 多个条件如何使用呢，两种方式，方式一：123if [ 10 -gt 5 -o 10 -gt 4 ];then echo &quot;10&gt;5 or 10 &gt;4&quot;fi 方式二：123if [ 10 -gt 5 ] || [ 10 -gt 4 ];then echo &quot;10&gt;5 or 10 &gt;4&quot;fi 其中-o或者||表示或。这里也有一些常见的条件判定。总结如下： -o or或者，同|| -a and 与，同&amp;&amp; ! 非 整数判断： -eq 两数是否相等 -ne 两数是否不等 -gt 前者是否大于后者（greater then） -lt 前面是否小于后者（less than） -ge 前者是否大于等于后者（greater then or equal） -le 前者是否小于等于后者（less than or equal） 字符串判断str1 exp str2： -z &quot;$str1&quot; str1是否为空字符串 -n &quot;$str1&quot; str1是否不是空字符串 &quot;$str1&quot; == &quot;$str2&quot; str1是否与str2相等 &quot;$str1&quot; != &quot;$str2&quot; str1是否与str2不等 &quot;$str1&quot; =~ &quot;str2&quot; str1是否包含str2 特别注意，字符串变量最好用引号引起来，因为一旦字符串中有空格，这个表达式就错了，有兴趣的可以尝试当str1=”hello world”，而str2=”hello”的时候进行比较。 文件目录判断：filename -f $filename 是否为文件 -e $filename 是否存在 -d $filename 是否为目录 -s $filename 文件存在且不为空 ! -s $filename 文件是否为空 循环循环形式一，和Python的for in很像：12345#遍历输出脚本的参数for i in $@; do echo $idone 循环形式二，和C语言风格很像：12345for ((i = 0 ; i &lt; 10 ; i++)); do echo $idone#循环打印0到9。 循环形式三：12345for i in &#123;1..5&#125;; do echo &quot;Welcome $i&quot;done#循环打印1到5。 循环方式四：1234while [ &quot;$ans&quot; != &quot;yes&quot; ]do read -p &quot;please input yes to exit loop:&quot; ansdone 只有当输入yes时，循环才会退出。即条件满足时，就进行循环。 循环方式五：12345ans=yesuntil [ $ans != &quot;yes&quot; ]do read -p &quot;please input yes to exit loop:&quot; ansdone 这里表示，只有当ans不是yes时，循环就终止。 循环方式六：1234for i in &#123;5..15..3&#125;; do echo &quot;number is $i&quot;done 每隔5打印一次，即打印5,8,11,14。 函数定义函数方式如下：1234myfunc() &#123; echo &quot;hello world $1&quot;&#125; 或者：1234function myfunc() &#123; echo &quot;hello world $1&quot;&#125; 函数调用：12para1=&quot;shouwang&quot;myfunc $para1 返回值通常函数的return返回值只支持0-255，因此想要获得返回值，可以通过下面的方式。1234567function myfunc() &#123; local myresult=&apos;some value&apos; echo $myresult&#125;val=$(myfunc) #val的值为some value 通过return的方式适用于判断函数的执行是否成功：1234567891011function myfunc() &#123; #do something return 0&#125;if myfunc;then echo &quot;success&quot;else echo &quot;failed&quot;fi 日志保存脚本执行后免不了要记录日志，最常用的方法就是重定向。以下面的脚本为例：1234#!/bin/bash#test.shlll #这个命令是没有的，因此会报错date 方式一，将标准输出保存到文件中，打印标准错误：1./test.sh &gt; log.dat 这种情况下，如果命令执行出错，错误将会打印到控制台。所以如果你在程序中调用，这样将不会讲错误信息保存在日志中。 方式二，标准输出和标准错误都保存到日志文件中：1./test.sh &gt; log.dat 2&gt;&amp;1 2&gt;&amp;1的含义可以参考《如何理解linuxshell中的2&gt;&amp;1》 方式三，保存日志文件的同时，也输出到控制台：1./test.sh |tee log.dat 脚本执行最常见的执行方式前面已经看到了：1./test.sh 其它执行方式： sh test.sh，在子进程中执行 sh -x test.sh，会在终端打印执行到命令，适合调试 source test.sh，test.sh在父进程中执行 . test.sh，不需要赋予执行权限，临时执行脚本 退出码很多时候我们需要获取脚本的执行结果，即退出状态，通常0表示执行成功，而非0表示失败。为了获得退出码，我们需要使用exit。例如：1234567891011121314151617#!/bin/bashfunction myfun()&#123; if [ $# -lt 2 ]then echo &quot;para num error&quot; exit 1 fi echo &quot;ok&quot; exit 2&#125;if [ $# -lt 1 ]then echo &quot;para num error&quot; exit 1fireturnVal=`myfun aa`echo &quot;end shell&quot;exit 0 这里需要特别注意的一点是，使用1returnVal=`myfun aa` 这样的句子执行函数，即便函数里面有exit，它也不会退出脚本执行，而只是会退出该函数，这是因为exit是退出当前进程，而这种方式执行函数，相当于fork了一个子进程，因此不会退出当前脚本。最终结果就会看到，无论你的函数参数是什么最后end shell都会打印。1./test.sh;echo $? 10 这里的0就是脚本的执行结果。 逻辑运算符逻辑卷标表示意思关于档案与目录的侦测逻辑卷标-f 常用！侦测『档案』是否存在 eg: if [ -f filename ] -d 常用！侦测『目录』是否存在 -b 侦测是否为一个『 block 档案』 -c 侦测是否为一个『 character 档案』 -S 侦测是否为一个『 socket 标签档案』 -L 侦测是否为一个『 symbolic link 的档案』 -e 侦测『某个东西』是否存在！ 关于程序的逻辑卷标-G 侦测是否由 GID 所执行的程序所拥有 -O 侦测是否由 UID 所执行的程序所拥有 -p 侦测是否为程序间传送信息的 name pipe 或是 FIFO （老实说，这个不太懂！） 关于档案的属性侦测-r 侦测是否为可读的属性 -w 侦测是否为可以写入的属性 -x 侦测是否为可执行的属性 -s 侦测是否为『非空白档案』 -u 侦测是否具有『 SUID 』的属性 -g 侦测是否具有『 SGID 』的属性 -k 侦测是否具有『 sticky bit 』的属性 两个档案之间的判断与比较 ；例如[ test file1 -nt file2 ]-nt 第一个档案比第二个档案新 -ot 第一个档案比第二个档案旧 -ef 第一个档案与第二个档案为同一个档案（ link 之类的档案） 逻辑的『和(and)』『或(or)』&amp;&amp; 逻辑的 AND 的意思 || 逻辑的 OR 的意思 运算符号 代表意义= 等于 应用于：整型或字符串比较 如果在[] 中，只能是字符串 !=不等于 应用于：整型或字符串比较 如果在[] 中，只能是字符串 &lt; 小于 应用于：整型比较 在[] 中，不能使用 表示字符串 > 大于 应用于：整型比较 在[] 中，不能使用 表示字符串 -eq 等于 应用于：整型比较 -ne 不等于 应用于：整型比较 -lt 小于 应用于：整型比较 -gt 大于 应用于：整型比较 -le 小于或等于 应用于：整型比较 -ge 大于或等于 应用于：整型比较 -a 双方都成立（and） 逻辑表达式 –a 逻辑表达式 -o 单方成立（or） 逻辑表达式 –o 逻辑表达式 -z 空字符串 -n 非空字符串 逻辑表达式test 命令使用方法：test EXPRESSION 如：123456789101112131415[root@localhost ~]# test 1 = 1 &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# test -d /etc/ &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# test 1 -eq 1 &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# if test 1 = 1 ; then echo &apos;ok&apos;; fiok 注意：所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。 精简表达式[] 表达式1234567891011121314151617[root@localhost ~]# [ 1 -eq 1 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# [ 2 &lt; 1 ] &amp;&amp; echo &apos;ok&apos;-bash: 2: No such file or directory[root@localhost ~]# [ 2 &lt; 1 ] &amp;&amp; echo &apos;ok&apos;[root@localhost ~]# [ 2 -gt 1 -a 3 -lt 4 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]# [ 2 -gt 1 &amp;&amp; 3 -lt 4 ] &amp;&amp; echo &apos;ok&apos;-bash: [: missing `]&apos; 注意：在[] 表达式中，常见的&gt;,&lt;需要加转义字符，表示字符串大小比较，以acill码 位置作为比较。 不直接支持&lt;&gt;运算符，还有逻辑运算符|| &amp;&amp; 它需要用-a[and] –o[or]表示 [[]] 表达式1234567891011[root@localhost ~]# [ 1 -eq 1 ] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]$ [[ 2 &lt; 3 ]] &amp;&amp; echo &apos;ok&apos;ok[root@localhost ~]$ [[ 2 &lt; 3 &amp;&amp; 4 &gt; 5 ]] &amp;&amp; echo &apos;ok&apos;ok 注意：[[]] 运算符只是[]运算符的扩充。能够支持&lt;,&gt;符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| &amp;&amp; 性能比较bash的条件表达式中有三个几乎等效的符号和命令：test，[]和[[]]。通常，大家习惯用if [];then这样的形式。而[[]]的出现，根据ABS所说，是为了兼容&gt;&lt;之类的运算符。以下是比较它们性能，发现[[]]是最快的。1234567891011121314151617181920212223$ time (for m in &#123;1..100000&#125;; do test -d .;done;)real 0m0.658suser 0m0.558ssys 0m0.100s$ time (for m in &#123;1..100000&#125;; do [ -d . ];done;)real 0m0.609suser 0m0.524ssys 0m0.085s$ time (for m in &#123;1..100000&#125;; do [[ -d . ]];done;)real 0m0.311suser 0m0.275ssys 0m0.036s 不考虑对低版本bash和对sh的兼容的情况下，用[[]]是兼容性强，而且性能比较快，在做条件运算时候，可以使用该运算符。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode136. Single Number]]></title>
    <url>%2F2019%2F04%2F17%2FLeetcode136%2F</url>
    <content type="text"><![CDATA[Single NumberEasy Given a non-empty array of integers, every element appears twice except for one. Find that single one. Note: Your algorithm should have a linear runtime complexity. Could you implement it without using extra memory?1234Example 1:Input: [2,2,1]Output: 1 1234Example 2:Input: [4,1,2,1,2]Output: 4 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。算法应该具有线性时间复杂度。且可以不使用额外空间来实现。 我的：12345678910class Solution &#123;public: int singleNumber(vector&lt;int&gt;&amp; nums) &#123; int a=0; for(int i=0;i&lt;nums.size();i++)&#123; a ^= nums[i]; &#125; return a; &#125;&#125;; 复杂些的：有一个 n 个元素的数组，除了两个数只出现一次外，其余元素都出现两次，让你找出这两个只出现一次的数分别是几，要求时间复杂度为 O(n) 且再开辟的内存空间固定(与 n 无关)。 示例 :输入: [1,2,2,1,3,4]输出: [3,4] 根据前面找一个不同数的思路算法，在这里把所有元素都异或，那么得到的结果就是那两个只出现一次的元素异或的结果。 然后，因为这两个只出现一次的元素一定是不相同的，所以这两个元素的二进制形式肯定至少有某一位是不同的，即一个为 0 ，另一个为 1 ，现在需要找到这一位。 根据异或的性质 任何一个数字异或它自己都等于 0，得到这个数字二进制形式中任意一个为 1 的位都是我们要找的那一位。 再然后，以这一位是 1 还是 0 为标准，将数组的 n 个元素分成两部分。 将这一位为 0 的所有元素做异或，得出的数就是只出现一次的数中的一个 将这一位为 1 的所有元素做异或，得出的数就是只出现一次的数中的另一个。 这样就解出题目。忽略寻找不同位的过程，总共遍历数组两次，时间复杂度为O(n)。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对于可重入、线程安全、异步信号安全几个概念的理解]]></title>
    <url>%2F2019%2F04%2F17%2F%E5%AF%B9%E4%BA%8E%E5%8F%AF%E9%87%8D%E5%85%A5%E3%80%81%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E3%80%81%E5%BC%82%E6%AD%A5%E4%BF%A1%E5%8F%B7%E5%AE%89%E5%85%A8%E5%87%A0%E4%B8%AA%E6%A6%82%E5%BF%B5%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/lg1259156776/article/details/52732879 由于前段时间，程序偶尔异常挂起不工作，检查后发现时死锁了，原因就是：在信号处理函数里面调用了fprintf. printf等io函数是需要对输出缓冲区加锁，这类函数对本身是线程安全的，但是对信号处理函数来说是不可重入的（在没有返回之前，不能再次调用），即不是异步信号安全的。 对于printf这类函数，可以这样理解：它们使用了全局数据结构（iobuffer），所以不是线程安全的（多个线程同时访问共享资源），也是不可重入的（有共享资源，可能损坏）； 通过加锁可以变得线程安全，但是仍然不可重入。 对于返回值共享的函数可以通过自己传入地址的方式变得线程可以重入（即线程安全）“_r”类函数。 如果一个函数返回一个静态地址（如上），同时又使用了全局资源（已经加锁保护），那么即使使用上了的_r方法变得线程可以重入，也不代表信号处理函数可以重入（即异步信号安全）。 一个可重入的函数简单来说就是可以被中断的函数，也就是说，可以在这个函数执行的任何时刻中断它，转入OS调度下去执行另外一段代码，而返回控制时不会出现什么错误。《多线程编程指南》中定义，可以被信号控制器安全调用的函数被称为”异步信号安全”函数。因此，我认为可重入与异步信号安全是一个概念。 有人将可重入函数与线程安全函数混为一谈，我认为是不正确的。 这里引用CSAPP中的描述来说明一下： CSAPP13.7.1 线程安全一个函数被称为线程安全的，当且仅当被多个并发线程反复的调用时，它会一直产生正确的结果。13.7.2 可重入性有一类重要的线程安全函数，叫做可重入函数，其特点在于它们具有一种属性：当它们被多个线程调用时，不会引用任何共享的数据。 尽管线程安全和可重入有时会（不正确的）被用做同义词，但是它们之间还是有清晰的技术差别的。可重入函数是线程安全函数的一个真子集。 重入即表示重复进入，首先它意味着这个函数可以被中断，其次意味着它除了使用自己栈上的变量以外不依赖于任何环境（包括static），这样的函数就是purecode（纯代码）可重入，可以允许有该函数的多个副本在运行，由于它们使用的是分离的栈，所以不会互相干扰。可重入函数是线程安全函数，但是反过来，线程安全函数未必是可重入函数。实际上，可重入函数很少，APUE 10.6节中描述了Single UNIX Specification说明的可重入的函数，只有115个；APUE 12.5节中描述了POSIX.1中不能保证线程安全的函数，只有89个。 信号就像硬件中断一样，会打断正在执行的指令序列。信号处理函数无法判断捕获到信号的时候，进程在何处运行。如果信号处理函数中的操作与打断的函数的操作相同，而且这个操作中有静态数据结构等，当信号处理函数返回的时候（当然这里讨论的是信号处理函数可以返回），恢复原先的执行序列，可能会导致信号处理函数中的操作覆盖了之前正常操作中的数据。不可重入函数的原因在于： 已知它们使用静态数据结构 它们调用malloc和free.因为malloc通常会为所分配的存储区维护一个链接表，而插入执行信号处理函数的时候，进程可能正在修改此链接表。 它们是标准IO函数.因为标准IO库的很多实现都使用了全局数据结构 即使对于可重入函数，在信号处理函数中使用也需要注意一个问题就是errno。一个线程中只有一个errno变量，信号处理函数中使用的可重入函数也有可能会修改errno。例如，read函数是可重入的，但是它也有可能会修改errno。因此，正确的做法是在信号处理函数开始，先保存errno；在信号处理函数退出的时候，再恢复errno。 例如，程序正在调用printf输出，但是在调用printf时，出现了信号，对应的信号处理函数也有printf语句，就会导致两个printf的输出混杂在一起。如果是给printf加锁的话，同样是上面的情况就会导致死锁。对于这种情况，采用的方法一般是在特定的区域屏蔽一定的信号。屏蔽信号的方法： signal(SIGPIPE, SIG_IGN); //忽略一些信号 sigprocmask()sigprocmask只为单线程定义的 pthread_sigmask()pthread_sigmasks可以在多线程中使用 现在看来信号异步安全和可重入的限制似乎是一样的，所以这里把它们等同看待;-) 线程安全线程安全：如果一个函数在同一时刻可以被多个线程安全的调用，就称该函数是线程安全的。 不需要共享时，请为每个线程提供一个专用的数据副本。如果共享非常重要，则提供显式同步，以确保程序以确定的方式操作。通过将过程包含在语句中来锁定和解除锁定互斥，可以使不安全过程变成线程安全过程，而且可以进行串行化。 很多函数并不是线程安全的，因为他们返回的数据是存放在静态的内存缓冲区中的。通过修改接口，由调用者自行提供缓冲区就可以使这些函数变为线程安全的。操作系统实现支持线程安全函数的时候，会对POSIX.1中的一些非线程安全的函数提供一些可替换的线程安全版本。例如,gethostbyname()是线程不安全的，在Linux中提供了gethostbyname_r()的线程安全实现。函数名字后面加上”_r”，以表明这个版本是可重入的（对于线程可重入，也就是说是线程安全的，但并不是说对于信号处理函数也是可重入的，或者是异步信号安全的）。 多线程程序中常见的疏忽性问题 将指针作为新线程的参数传递给调用方栈。 在没有同步机制保护的情况下访问全局内存的共享可更改状态。 两个线程尝试轮流获取对同一对全局资源的权限时导致死锁。其中一个线程控制第一种资源，另一个线程控制第二种资源。其中一个线程放弃之前，任何一个线程都无法继续操作。 尝试重新获取已持有的锁（递归死锁）。 在同步保护中创建隐藏的间隔。如果受保护的代码段包含的函数释放了同步机制，而又在返回调用方之前重新获取了该同步机制，则将在保护中出现此间隔。结果具有误导性。对于调用方，表面上看全局数据已受到保护，而实际上未受到保护。 将UNIX 信号与线程混合时，使用sigwait(2) 模型来处理异步信号。 调用setjmp(3C) 和longjmp(3C)，然后长时间跳跃，而不释放互斥锁。 从对_cond_wait() 或_cond_timedwait() 的调用中返回后无法重新评估条件。 总结判断一个函数是不是可重入函数，在于判断其能否可以被打断，打断后恢复运行能够得到正确的结果。（打断执行的指令序列并不改变函数的数据）判断一个函数是不是线程安全的，在于判断其能否在多个线程同时执行其指令序列的时候，保证每个线程都能够得到正确的结果。 如果一个函数对多个线程来说是可重入的，则说这个函数是线程安全的，但这并不能说明对信号处理程序来说该函数也是可重入的。如果函数对异步信号处理程序的重入是安全的，那么就可以说函数是”异步-信号安全”的。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux程序加载过程]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E7%A8%8B%E5%BA%8F%E5%8A%A0%E8%BD%BD%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原文链接：https://blog.csdn.net/hnzziafyz/article/details/52200265 一个进程在内存中主要占用了以下几个部分，分别是代码段、数据段、BSS，栈，堆，等参数。其中，代码、数据、BSS的内容是可执行文件中对应的内容，加载程序并不是把它们的内容从可执行程序中填充到内存中，而是将它们的信息（基地址、长度等）更新到进程控制块（task_struct）中，当CPU第 一次实际寻址执行的时候，就会引起缺页中断，操作系统再将实际的内容从可执行文件中复制内容到物理内存中。 堆的内容是程序执行中动态分配的，所以加载程序 只是将它的起始地址更新到进程控制块中，执行过程中遇到动态分配内存的操作的时候再在物理内存分配实际的页。参数区在新进程加载的时候要存入环境变量和命令行参数列表。栈在程序加载时候存入的内容就是环境参数列表和命令行参数列表的指针和命令行参数的个数。 1）在shell界面输入./可执行文件名。经shell分析，该参数非shell内建命令，则认为是加载可执行文件。于是调用fork函数开始创建新进程，产生0x80中断，映射到函数sys_fork()中，调用find_empty_process()函数，为新进程申请一个可用的进程号。 2）为可执行程序的管理结构找到存储空间。为了实现对进程的保护，系统为每个进程的管理专门设计了一个结构，即task_struct。内核通过调用get_free_page函数获得用于保存task_struct和内核栈的页面只能在内核的线性地址空间。 3）shell进程为新进程复制task_struct结构。行程序复制了task_struct后，新进程便继承了shell的全部管理信息。但由于每个进程呢的task_struct结构中的信息是不一样的，所以还要对该结构进行个性化设置（为防止在设置的过程中被切换到该进程，应先设置为不可中断状态）。个性化设置主要包括进程号、父进程、时间片、TSS段（为进程间切换而设计的，进程的切换时建立在对进程的保护的基础上的，在进程切换时TSS用来保存或恢复该进程的现场所用到的寄存器的值）。这些都是通过函数copy_process来完成的。 4）复制新进程页表并设置其对应的页目录项。现在调用函数copy_mem为进程分段（LDT），更新代码段和数据段的基地址，即确定线性地址空间（关键在于确定段基址和限长）。接着就是分页，分页是建立在分段的基础上的。 5）建立新进程与全局描述符（GDT）的关联，将新进程的TSS和LDT挂接在GDT的指定位置处。（注：TSS和LDT对进程的保护至关重要） 6）将新进程设置为就绪状态 7）加载可执行文件。进入do_execve函数之后，将可执行文件的头表加载到内存中并检测相关信息。加载执行程序（讲程序按需加载到内存）。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内存描述符mm_struct实例详解]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E5%86%85%E5%AD%98%E6%8F%8F%E8%BF%B0%E7%AC%A6mm-struct%E5%AE%9E%E4%BE%8B%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Linux对于内存的管理涉及到非常多的方面，这篇文章首先从对进程虚拟地址空间的管理说起，具体实例代码大家通过本文学习下吧Linux对于内存的管理涉及到非常多的方面，这篇文章首先从对进程虚拟地址空间的管理说起。(所依据的代码是2.6.32.60） 无论是内核线程还是用户进程，对于内核来说，无非都是task_struct这个数据结构的一个实例而已，task_struct被称为进程描述符（process descriptor),因为它记录了这个进程所有的context。其中有一个被称为’内存描述符‘（memory descriptor)的数据结构mm_struct，抽象并描述了Linux视角下管理进程地址空间的所有信息。 mm_struct定义在include/linux/mm_types.h中，其中的域抽象了进程的地址空间，如下图所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091struct mm_struct &#123; struct vm_area_struct * mmap; //指向虚拟区间(VMA)的链表 struct rb_root mm_rb; //指向线性区对象红黑树的根 struct vm_area_struct * mmap_cache; //指向最近找到的虚拟区间 unsigned long(*get_unmapped_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags);//在进程地址空间中搜索有效线性地址区 unsigned long(*get_unmapped_exec_area) (struct file *filp, unsigned long addr, unsigned long len, unsigned long pgoff, unsigned long flags); void(*unmap_area) (struct mm_struct *mm, unsigned long addr);//释放线性地址区间时调用的方法 unsigned long mmap_base; /* base of mmap area */ unsigned long task_size; /* size of task vm space */ unsigned long cached_hole_size; unsigned long free_area_cache; //内核从这个地址开始搜索进程地址空间中线性地址的空闲区域 pgd_t * pgd; //指向页全局目录 atomic_t mm_users; //次使用计数器，使用这块空间的个数 atomic_t mm_count; //主使用计数器 int map_count; //线性的个数 struct rw_semaphore mmap_sem; //线性区的读/写信号量 spinlock_t page_table_lock; //线性区的自旋锁和页表的自旋锁 struct list_head mmlist; //指向内存描述符链表中的相邻元素 /* Special counters, in some configurations protected by the * page_table_lock, in other configurations by being atomic. */ mm_counter_t _file_rss; //mm_counter_t代表的类型实际是typedef atomic_long_t mm_counter_t _anon_rss; mm_counter_t _swap_usage; unsigned long hiwater_rss; //进程所拥有的最大页框数 unsigned long hiwater_vm; //进程线性区中最大页数 unsigned long total_vm, locked_vm, shared_vm, exec_vm; //total_vm 进程地址空间的大小(页数） //locked_vm 锁住而不能换出的页的个数 //shared_vm 共享文件内存映射中的页数 unsigned long stack_vm, reserved_vm, def_flags, nr_ptes; //stack_vm 用户堆栈中的页数 //reserved_vm 在保留区中的页数或者在特殊线性区中的页数 //def_flags 线性区默认的访问标志 //nr_ptes 进程的页表数 unsigned long start_code, end_code, start_data, end_data; //start_code 可执行代码的起始地址 //end_code 可执行代码的最后地址 //start_data已初始化数据的起始地址 // end_data已初始化数据的最后地址 unsigned long start_brk, brk, start_stack; //start_stack堆的起始位置 //brk堆的当前的最后地址 //用户堆栈的起始地址 unsigned long arg_start, arg_end, env_start, env_end; //arg_start 命令行参数的起始地址 //arg_end命令行参数的起始地址 //env_start环境变量的起始地址 //env_end环境变量的最后地址 unsigned long saved_auxv[AT_VECTOR_SIZE]; /* for /proc/PID/auxv */ struct linux_binfmt *binfmt; cpumask_t cpu_vm_mask; //用于惰性TLB交换的位掩码 /* Architecture-specific MM context */ mm_context_t context; //指向有关特定结构体系信息的表 unsigned int faultstamp; unsigned int token_priority; unsigned int last_interval; unsigned long flags; /* Must use atomic bitops to access the bits */ struct core_state *core_state; /* coredumping support */#ifdef CONFIG_AIO spinlock_t ioctx_lock; //用于保护异步I/O上下文链表的锁 struct hlist_head ioctx_list;//异步I/O上下文#endif#ifdef CONFIG_MM_OWNER struct task_struct *owner;#endif#ifdef CONFIG_PROC_FS unsigned long num_exe_file_vmas;#endif#ifdef CONFIG_MMU_NOTIFIER struct mmu_notifier_mm *mmu_notifier_mm;#endif#ifdef CONFIG_TRANSPARENT_HUGEPAGE pgtable_t pmd_huge_pte; /* protected by page_table_lock */#endif#ifdef __GENKSYMS__ unsigned long rh_reserved[2];#else //有多少任务分享这个mm OOM_DISABLE union &#123; unsigned long rh_reserved_aux; atomic_t oom_disable_count; &#125;; /* base of lib map area (ASCII armour) */ unsigned long shlib_base;#endif&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux信号（signal) 机制分析]]></title>
    <url>%2F2019%2F04%2F17%2FLinux%E4%BF%A1%E5%8F%B7%E6%9C%BA%E5%88%B6%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[【摘要】本文分析了Linux内核对于信号的实现机制和应用层的相关处理。首先介绍了软中断信号的本质及信号的两种不同分类方法尤其是不可靠信号的原理。接着分析了内核对于信号的处理流程包括信号的触发/注册/执行及注销等。最后介绍了应用层的相关处理，主要包括信号处理函数的安装、信号的发送、屏蔽阻塞等，最后给了几个简单的应用实例。 中断和异常中断（也称硬件中断）定义：中断是由其他硬件设备依照CPU时钟周期信号随机产生的。分类： 可屏蔽中断、非可屏蔽中断来源：间隔定时器和I/O 异常（也称软件中断）定义：当指令执行时由CPU控制单元产生的，异常也称为“异步中断”是因为只有在 一条指令终止执行后CPU才会发出中断。分类： 处理器探测到的异常、故障、陷阱、异常终止、编程异常(也称软中断)、int指令来源：程序的错误产生的内核必须处理的异常(例如：缺页和内核服务的请求-int) 异常处理当发生异常时，CPU控制单元产生一个硬件出错码。CPU根据该中断吗找到中断向量表内的对应向量，根据该向量转到中断处理程序。中断处理程序处理完之后向当前进程发送一个SIG***信号。若进程定义了相应的信号处理程序则转移到相应的程序执行，若没有，则执行内核定义的操作。 中断处理设备产生中断，PIC（可编程中断控制器）会产生一个对应的中断向量和中断向量表中的每一个中断向量进行比较，转到对应的中断处理程序，中断处理程序进行保存现场，做相关处理，恢复现场，内核调度，返回用户进程。 硬件中断的上半部和下半部及实现方式硬件中断的分类 紧急的 —— 这类中断必须立即执行 非紧急的 —— 也必须立即执行 非紧急可延迟的 —— 上半部立即执行，下半部延迟执行 硬件中断任务（处理程序）是一个快速、异步、简单地对硬件做出迅速响应并在最短时间内完成必要操作的中断处理程序。硬中断处理程序可以抢占内核任务并且执 行时还会屏蔽同级中断或其它中断，因此中断处理必须要快、不能阻塞。这样一来对于一些要求处理过程比较复杂的任务就不合适在中断任务中一次处理。比如，网卡接收数据的过程中,首先网卡发送中断信号告诉CPU来取数据，然后系统从网卡中读取数据存入系统缓冲区中，再下来解析数据然后送入应用层。这些如果都让中断处理程序来处理显然过程太长，造成新来的中断丢失。因此Linux开发人员将这种任务分割为两个部分，一个叫上底，即中断处理程序，短平快地处理与硬 件相关的操作（如从网卡读数据到系统缓存）；而把对时间要求相对宽松的任务（如解析数据的工作）放在另一个部分执行，这个部分就是我们这里要讲的下半底。 下半底是一种推后执行任务，它将某些不那么紧迫的任务推迟到系统更方便的时刻运行。因为并不是非常紧急，通常还是比较耗时的，因此由系统自行安排运行时机，不在中断服务上下文中执行。内核中实现 下半底的手段经过不断演化，目前已经从最原始的BH(bottom thalf)演生出BH、任务队列（Task queues）、软中断（Softirq）、Tasklet、工作队列（Work queues）（2.6内核中新出现的）。 关于软中断和硬中断的其它解析：软中断一般是指由指令int引起的“伪”中断动作——给CPU制造一个中断的假象；而硬中断则是实实在在由8259的连线触发的中断。因此，严格的 讲，int与IRQ毫无关系，但二者均与中断向量有关系。int引起的中断，CPU是从指令中取得中断向量号；而IRQ引起的中断，CPU必须从数据线上取回中断号，接下来CPU的工作就一样了：保护现场、根据中断号得到中断处理程序地址、执行中断处理、恢复现场继续执行被中断的指令。 在软中断和硬中断之间的区别是什么？ 硬中断是由外部事件引起的因此具有随机性和突发性；软中断是执行中断指令产生的，无面外部施加中断请求信 号，因此中断的发生不是随机的而是由程序安排好的。 硬中断的中断响应周期，CPU需要发中断回合信号（NMI不需要），软中断的中断响应周 期，CPU不需发中断回合信号。 硬中断的中断号是由中断控制器提供的（NMI硬中断中断号系统指定为02H）；软中断的中断号由指令直接给出， 无需使用中断控制器。 硬中断是可屏蔽的（NMI硬中断不可屏蔽），软中断不可屏蔽。 硬中断： 硬中断是由硬件产生的，比如，像磁盘，网卡，键盘，时钟等。每个设备或设备集都有它自己的IRQ（中断请求）。基于IRQ，CPU可以将相应的请求分发到对应的硬件驱动上（注：硬件驱动通常是内核中的一个子程序，而不是一个独立的进程）。 处理中断的驱动是需要运行在CPU上的，因此，当中断产生的时候，CPU会中断当前正在运行的任务，来处理中断。在有多核心的系统上，一个中断通常只能中断一颗CPU（也有一种特殊的情况，就是在大型主机上是有硬件通道的，它可以在没有主CPU的支持下，可以同时处理多个中断。）。 硬中断可以直接中断CPU。它会引起内核中相关的代码被触发。对于那些需要花费一些时间去处理的进程，中断代码本身也可以被其他的硬中断中断。 对于时钟中断，内核调度代码会将当前正在运行的进程挂起，从而让其他的进程来运行。它的存在是为了让调度代码（或称为调度器）可以调度多任务。 软中断： 软中断的处理非常像硬中断。然而，它们仅仅是由当前正在运行的进程所产生的。 通常，软中断是一些对I/O的请求。这些请求会调用内核中可以调度I/O发生的程序。对于某些设备，I/O请求需要被立即处理，而磁盘I/O请求通常可以排队并且可以稍后处理。根据I/O模型的不同，进程或许会被挂起直到I/O完成，此时内核调度器就会选择另一个进程去运行。I/O可以在进程之间产生并且调度过程通常和磁盘I/O的方式是相同。 软中断仅与内核相联系。而内核主要负责对需要运行的任何其他的进程进行调度。一些内核允许设备驱动的一些部分存在于用户空间，并且当需要的时候内核也会调度这个进程去运行。 软中断并不会直接中断CPU。也只有当前正在运行的代码（或进程）才会产生软中断。这种中断是一种需要内核为正在运行的进程去做一些事情（通常为I/O）的请求。有一个特殊的软中断是Yield调用，它的作用是请求内核调度器去查看是否有一些其他的进程可以运行。 信号本质软中断信号（signal，又简称为信号）用来通知进程发生了异步事件。在软件层次上是对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是进程间通信机制中唯一的异步通信机制，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知道信号到底什么时候到达。进程之间可以互相通过系统调用kill发送软中断信号。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。 产生信号的条件主要有： 用户在终端 按下某些键时，终端驱动程序会发送信号给前台进程，例如Ctrl-C产生SIGINT信 号，Ctrl-/产生SIGQUIT信号，Ctrl-Z产生SIGTSTP信号。 硬件异常产生信号，这些条件由硬件检测到并通知内核，然后内核向当前进程发送适当的信号。例如当前进程执行了 除以0的指令，CPU的运算单元会产生异常，内核将这个异常解释为SIGFPE信号发送给进 程。再比如当前进程访问了非法内存地址，，MMU会产生异常，内核将这个异常解释为SIGSEGV信 号发送给进程。 一个进程调用kill(2)函数可以发送信 号给另一个进程。 可以用kill(1)命令发送信号给某个 进程，kill(1)命令也是调用kill(2)函 数实现的，如果不明确指定信号则发送SIGTERM信号，该信号的默认处理动作是终止进程。 当内核检测到某种软件条件发生时也可以通过信号通知进程，例如闹钟超时产生SIGALRM信 号，向读端已关闭的管道写数据时产生SIGPIPE信号。 收到信号的进程对各种信号有不同的处理方法。处理方法可以分为三类： 第一种是类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。 第二种方法是，忽略某个信号，对该信号不做任何处理，就象未发生过一样。 第三种方法是，对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。进程通过系统调用signal来指定进程对某个信号的处理行为。 信号的种类可以从两个不同的分类角度对信号进行分类： 可靠性方面：可靠信号与不可靠信号； 与时间的关系上：实时信号与非实时信号。 可靠信号与不可靠信号Linux信号机制基本上是从Unix系统中继承过来的。早期Unix系统中的信号机制比较简单和原始，信号值小于SIGRTMIN的信号都是不可靠信号。这就是”不可靠信号”的来源。它的主要问题是信号可能丢失。 随着时间的发展，实践证明了有必要对信号的原始机制加以改进和扩充。由于原来定义的信号已有许多应用，不好再做改动，最终只好又新增加了一些信号，并在一开始就把它们定义为可靠信号，这些信号支持排队，不会丢失。 信号值位于SIGRTMIN和SIGRTMAX之间的信号都是可靠信号，可靠信号克服了信号可能丢失的问题。Linux在支持新版本的信号安装函数sigation()以及信号发送函数sigqueue()的同时，仍然支持早期的signal()信号安装函数，支持信号发送函数kill()。 信号的可靠与不可靠只与信号值有关，与信号的发送及安装函数无关。目前linux中的signal()是通过sigation()函数实现的，因此，即使通过signal()安装的信号，在信号处理函数的结尾也不必再调用一次信号安装函数。同时，由signal()安装的实时信号支持排队，同样不会丢失。 对于目前linux的两个信号安装函数：signal()及sigaction()来说，它们都不能把SIGRTMIN以前的信号变成可靠信号（都不支持排队，仍有可能丢失，仍然是不可靠信号），而且对SIGRTMIN以后的信号都支持排队。这两个函数的最大区别在于，经过sigaction安装的信号都能传递信息给信号处理函数，而经过signal安装的信号不能向信号处理函数传递信息。对于信号发送函数来说也是一样的。 实时信号与非实时信号早期Unix系统只定义了32种信号，前32种信号已经有了预定义值，每个信号有了确定的用途及含义，并且每种信号都有各自的缺省动作。如按键盘的CTRL ^C时，会产生SIGINT信号，对该信号的默认反应就是进程终止。后32个信号表示实时信号，等同于前面阐述的可靠信号。这保证了发送的多个实时信号都被接收。 非实时信号都不支持排队，都是不可靠信号；实时信号都支持排队，都是可靠信号。 信号处理流程对于一个完整的信号生命周期(从信号发送到相应的处理函数执行完毕)来说，可以分为三个阶段： 信号诞生 信号在进程中注册 信号的执行和注销 信号诞生信号事件的发生有两个来源：硬件来源(比如我们按下了键盘或者其它硬件故障)；软件来源，最常用发送信号的系统函数是kill, raise, alarm和setitimer以及sigqueue函数，软件来源还包括一些非法运算等操作。 这里按发出信号的原因简单分类，以了解各种信号： 与进程终止相关的信号。当进程退出，或者子进程终止时，发出这类信号。 与进程例外事件相关的信号。如进程越界，或企图写一个只读的内存区域（如程序正文区），或执行一个特权指令及其他各种硬件错误。 与在系统调用期间遇到不可恢复条件相关的信号。如执行系统调用exec时，原有资源已经释放，而目前系统资源又已经耗尽。 与执行系统调用时遇到非预测错误条件相关的信号。如执行一个并不存在的系统调用。 在用户态下的进程发出的信号。如进程调用系统调用kill向其他进程发送信号。 与终端交互相关的信号。如用户关闭一个终端，或按下break键等情况。 跟踪进程执行的信号。 Linux支持的信号列表如下。很多信号是与机器的体系结构相关的 (1) SIGHUP：当用户退出Shell时，由该Shell启的发所有进程都退接收到这个信号，默认动作为终止进程。 (2) SIGINT：用户按下组合键时，用户端时向正在运行中的由该终端启动的程序发出此信号。默认动作为终止进程。 (3) SIGQUIT：当用户按下组合键时产生该信号，用户终端向正在运行中的由该终端启动的程序发出此信号。默认动作为终止进程并产生core文件。 (4) SIGILL ：CPU检测到某进程执行了非法指令。默认动作为终止进程并产生core文件。 (5) SIGTRAP：该信号由断点指令或其他trap指令产生。默认动作为终止进程并产生core文件。 (6) SIGABRT：调用abort函数时产生该信号。默认动作为终止进程并产生core文件。 (7) SIGBUS：非法访问内存地址，包括内存地址对齐（alignment）出错，默认动作为终止进程并产生core文件。 (8) SIGFPE：在发生致命的算术错误时产生。不仅包括浮点运行错误，还包括溢出及除数为0等所有的算术错误。默认动作为终止进程并产生core文件。 (9) SIGKILL：无条件终止进程。本信号不能被忽略、处理和阻塞。默认动作为终止进程。它向系统管理员提供了一种可以杀死任何进程的方法。 (10) SIGUSR1：用户定义的信号，即程序可以在程序中定义并使用该信号。默认动作为终止进程。 (11) SIGSEGV：指示进程进行了无效的内存访问。默认动作为终止进程并使用该信号。默认动作为终止进程。 (12) SIGUSR2：这是另外一个用户定义信号，程序员可以在程序中定义并使用该信号。默认动作为终止进程。 (13) SIGPIPE：Broken pipe：向一个没有读端的管道写数据。默认动作为终止进程。 (14) SIGALRM：定时器超时，超时的时间由系统调用alarm设置。默认动作为终止进程。 (15) SIGTERM：程序结束(terminate)信号，与SIGKILL不同的是，该信号可以被阻塞和处理。通常用来要求程序正常退出。执行Shell命令kill时，缺少产生这个信号。默认动作为终止进程。 (17) SIGCHLD：子程序结束时，父进程会收到这个信号。默认动作为忽略该信号。 (18) SIGCONT：让一个暂停的进程继续执行。 (19) SIGSTOP：停止(stopped)进程的执行。注意它和SIGTERM以及SIGINT的区别：该进程还未结束，只是暂停执行。本信号不能被忽略、处理和阻塞。默认作为暂停进程。 (20) SIGTSTP：停止进程的动作，但该信号可以被处理和忽略。按下组合键时发出该信号。默认动作为暂停进程。 (21) SIGTTIN：当后台进程要从用户终端读数据时，该终端中的所有进程会收到SIGTTIN信号。默认动作为暂停进程。 (22) SIGTTOU：该信号类似于SIGTIN，在后台进程要向终端输出数据时产生。默认动作为暂停进程。 (23) SIGURG：套接字（socket）上有紧急数据时，向当前正在运行的进程发出此信号，报告有紧急数据到达。默认动作为忽略该信号。 (24) SIGXCPU：进程执行时间超过了分配给该进程的CPU时间，系统产生该信号并发送给该进程。默认动作为终止进程。 (25) SIGXFSZ：超过文件最大长度的限制。默认动作为yl终止进程并产生core文件。 (26) SIGVTALRM：虚拟时钟超时时产生该信号。类似于SIGALRM，但是它只计算该进程占有用的CPU时间。默认动作为终止进程。 (27) SIGPROF：类似于SIGVTALRM，它不仅包括该进程占用的CPU时间还抱括执行系统调用的时间。默认动作为终止进程。 (28) SIGWINCH：窗口大小改变时发出。默认动作为忽略该信号。 (29) SIGIO：此信号向进程指示发出一个异步IO事件。默认动作为忽略。 (30) SIGPWR：关机。默认动作为终止进程。 (31) SIGRTMIN~SIGRTMAX：Linux的实时信号，它没有固定的含义(或者说可以由用户自由使用)。注意，Linux线程机制使用了前3个实时信号。所有的实时信号的默认动作都是终止进程。 信号在目标进程中注册在进程表的表项中有一个软中断信号域，该域中每一位对应一个信号。内核给一个进程发送软中断信号的方法，是在进程所在的进程表项的信号域设置对应于该信号的位。如果信号发送给一个正在睡眠的进程，如果进程睡眠在可被中断的优先级上，则唤醒进程；否则仅设置进程表中信号域相应的位，而不唤醒进程。如果发送给一个处于可运行状态的进程，则只置相应的域即可。 进程的task_struct结构中有关于本进程中未决信号的数据成员：struct sigpending pending1234struct sigpending&#123; struct sigqueue *head, *tail; sigset_t signal;&#125;; 第三个成员是进程中所有未决信号集，第一、第二个成员分别指向一个sigqueue类型的结构链（称之为”未决信号信息链”）的首尾，信息链中的每个sigqueue结构刻画一个特定信号所携带的信息，并指向下一个sigqueue结构:1234struct sigqueue&#123; struct sigqueue *next; siginfo_t info;&#125; 信号在进程中注册指的就是信号值加入到进程的未决信号集sigset_t signal（每个信号占用一位）中，并且信号所携带的信息被保留到未决信号信息链的某个sigqueue结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。 当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做”可靠信号”。这意味着同一个实时信号可以在同一个进程的未决信号信息链中占有多个sigqueue结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）。 当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册（通过sigset_t signal指示），则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做”不可靠信号”。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个sigqueue结构。 总之信号注册与否，与发送信号的函数（如kill()或sigqueue()等）以及信号安装函数（signal()及sigaction()）无关，只与信号值有关（信号值小于SIGRTMIN的信号最多只注册一次，信号值在SIGRTMIN及SIGRTMAX之间的信号，只要被进程接收到就被注册） 信号的执行和注销内核处理一个进程收到的软中断信号是在该进程的上下文中，因此，进程必须处于运行状态。当其由于被信号唤醒或者正常调度重新获得CPU时，在其从内核空间返回到用户空间时会检测是否有信号等待处理。如果存在未决信号等待处理且该信号没有被进程阻塞，则在运行相应的信号处理函数前，进程会把信号在未决信号链中占有的结构卸掉。 对于非实时信号来说，由于在未决信号信息链中最多只占用一个sigqueue结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）；而对于实时信号来说，可能在未决信号信息链中占用多个sigqueue结构，因此应该针对占用sigqueue结构的数目区别对待：如果只占用一个sigqueue结构（进程只收到该信号一次），则执行完相应的处理函数后应该把信号在进程的未决信号集中删除（信号注销完毕）。否则待该信号的所有sigqueue处理完毕后再在进程的未决信号集中删除该信号。 当所有未被屏蔽的信号都处理完毕后，即可返回用户空间。对于被屏蔽的信号，当取消屏蔽后，在返回到用户空间时会再次执行上述检查处理的一套流程。 内核处理一个进程收到的信号的时机是在一个进程从内核态返回用户态时。所以，当一个进程在内核态下运行时，软中断信号并不立即起作用，要等到将返回用户态时才处理。进程只有处理完信号才会返回用户态，进程在用户态下不会有未处理完的信号。 处理信号有三种类型： 进程接收到信号后退出； 进程忽略该信号； 进程收到信号后执行用户设定用系统调用signal的函数。 当进程接收到一个它忽略的信号时，进程丢弃该信号，就象没有收到该信号似的继续运行。如果进程收到一个要捕捉的信号，那么进程从内核态返回用户态时执行用户定义的函数。而且执行用户定义的函数的方法很巧妙，内核是在用户栈上创建一个新的层，该层中将返回地址的值设置成用户定义的处理函数的地址，这样进程从内核返回弹出栈顶时就返回到用户定义的函数处，从函数返回再弹出栈顶时，才返回原先进入内核的地方。这样做的原因是用户定义的处理函数不能且不允许在内核态下执行（如果用户定义的函数在内核态下运行的话，用户就可以获得任何权限）。 信号的安装如果进程要处理某一信号，那么就要在进程中安装该信号。安装信号主要用来确定信号值及进程针对该信号值的动作之间的映射关系，即进程将要处理哪个信号；该信号被传递给进程时，将执行何种操作。 linux主要有两个函数实现信号的安装：signal()、sigaction()。其中signal()只有两个参数，不支持信号传递信息，主要是用于前32种非实时信号的安装；而sigaction()是较新的函数（由两个系统调用实现：sys_signal以及sys_rt_sigaction），有三个参数，支持信号传递信息，主要用来与 sigqueue() 系统调用配合使用，当然，sigaction()同样支持非实时信号的安装。sigaction()优于signal()主要体现在支持信号带有参数。 signal()12#include &lt;signal.h&gt;void (*signal(int signum, void (*handler))(int)))(int); 如果该函数原型不容易理解的话，可以参考下面的分解方式来理解：12typedef void (*sighandler_t)(int)；sighandler_t signal(int signum, sighandler_t handler)); 第一个参数指定信号的值，第二个参数指定针对前面信号值的处理，可以忽略该信号（参数设为SIG_IGN）；可以采用系统默认方式处理信号(参数设为SIG_DFL)；也可以自己实现处理方式(参数指定一个函数地址)。 如果signal()调用成功，返回最后一次为安装信号signum而调用signal()时的handler值；失败则返回SIG_ERR。 传递给信号处理例程的整数参数是信号值，这样可以使得一个信号处理例程处理多个信号。1234567891011121314151617181920212223242526#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;void sigroutine(int dunno)&#123; /* 信号处理例程，其中dunno将会得到信号的值 */ switch (dunno) &#123; case 1: printf(&quot;Get a signal -- SIGHUP &quot;); break; case 2: printf(&quot;Get a signal -- SIGINT &quot;); break; case 3: printf(&quot;Get a signal -- SIGQUIT &quot;); break; &#125; return;&#125;int main() &#123; printf(&quot;process id is %d &quot;,getpid()); signal(SIGHUP, sigroutine); //* 下面设置三个信号的处理方法 signal(SIGINT, sigroutine); signal(SIGQUIT, sigroutine); for (;;) ;&#125; 其中信号SIGINT由按下Ctrl-C发出，信号SIGQUIT由按下Ctrl-发出。该程序执行的结果如下：123456789101112localhost:~$ ./sig_testprocess id is 463Get a signal -SIGINT //按下Ctrl-C得到的结果Get a signal -SIGQUIT //按下Ctrl-得到的结果//按下Ctrl-z将进程置于后台 [1]+ Stopped ./sig_testlocalhost:~$ bg [1]+ ./sig_test &amp;localhost:~$ kill -HUP 463 //向进程发送SIGHUP信号localhost:~$ Get a signal – SIGHUPkill -9 463 //向进程发送SIGKILL信号，终止进程localhost:~$ sigaction()12#include &lt;signal.h&gt;int sigaction(int signum,const struct sigaction *act,struct sigaction *oldact)); sigaction函数用于改变进程接收到特定信号后的行为。该函数的第一个参数为信号的值，可以为除SIGKILL及SIGSTOP外的任何一个特定有效的信号（为这两个信号定义自己的处理函数，将导致信号安装错误）。第二个参数是指向结构sigaction的一个实例的指针，在结构sigaction的实例中，指定了对特定信号的处理，可以为空，进程会以缺省方式对信号处理；第三个参数oldact指向的对象用来保存返回的原来对相应信号的处理，可指定oldact为NULL。如果把第二、第三个参数都设为NULL，那么该函数可用于检查信号的有效性。 第二个参数最为重要，其中包含了对指定信号的处理、信号所传递的信息、信号处理函数执行过程中应屏蔽掉哪些信号等等。 sigaction结构定义如下：12345678struct sigaction &#123; union&#123; __sighandler_t _sa_handler; void (*_sa_sigaction)(int,struct siginfo *, void *)； &#125;_u sigset_t sa_mask； unsigned long sa_flags；&#125; 联合数据结构中的两个元素_sa_handler以及*_sa_sigaction指定信号关联函数，即用户指定的信号处理函数。除了可以是用户自定义的处理函数外，还可以为SIG_DFL(采用缺省的处理方式)，也可以为SIG_IGN（忽略信号）。 由_sa_sigaction是指定的信号处理函数带有三个参数，是为实时信号而设的（当然同样支持非实时信号），它指定一个3参数信号处理函数。第一个参数为信号值，第三个参数没有使用，第二个参数是指向siginfo_t结构的指针，结构中包含信号携带的数据值，参数所指向的结构如下： 1234567891011121314151617181920siginfo_t &#123; int si_signo; /* 信号值，对所有信号有意义*/ int si_errno; /* errno值，对所有信号有意义*/ int si_code; /* 信号产生的原因，对所有信号有意义*/ union&#123; /* 联合数据结构，不同成员适应不同信号 */ //确保分配足够大的存储空间 int _pad[SI_PAD_SIZE]; //对SIGKILL有意义的结构 struct&#123; ... &#125;... ... ... ... ... //对SIGILL, SIGFPE, SIGSEGV, SIGBUS有意义的结构 struct&#123; ... &#125;... ... ... &#125;&#125; 前面在讨论系统调用sigqueue发送信号时，sigqueue的第三个参数就是sigval联合数据结构，当调用sigqueue时，该数据结构中的数据就将拷贝到信号处理函数的第二个参数中。这样，在发送信号同时，就可以让信号传递一些附加信息。信号可以传递信息对程序开发是非常有意义的。 sa_mask指定在信号处理程序执行过程中，哪些信号应当被阻塞。缺省情况下当前信号本身被阻塞，防止信号的嵌套发送，除非指定SA_NODEFER或者SA_NOMASK标志位。 注：请注意sa_mask指定的信号阻塞的前提条件，是在由sigaction（）安装信号的处理函数执行过程中由sa_mask指定的信号才被阻塞。 sa_flags中包含了许多标志位，包括刚刚提到的SA_NODEFER及SA_NOMASK标志位。另一个比较重要的标志位是SA_SIGINFO，当设定了该标志位时，表示信号附带的参数可以被传递到信号处理函数中，因此，应该为sigaction结构中的sa_sigaction指定处理函数，而不应该为sa_handler指定信号处理函数，否则，设置该标志变得毫无意义。即使为sa_sigaction指定了信号处理函数，如果不设置SA_SIGINFO，信号处理函数同样不能得到信号传递过来的数据，在信号处理函数中对这些信息的访问都将导致段错误（Segmentation fault）。 信号的发送发送信号的主要函数有：kill()、raise()、 sigqueue()、alarm()、setitimer()以及abort()。 kill()123#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int kill(pid_t pid,int signo) 该系统调用可以用来向任何进程或进程组发送任何信号。参数pid的值为信号的接收进程 pid&gt;0 进程ID为pid的进程 pid=0 同一个进程组的进程 pid&lt;0 pid!=-1 进程组ID为 -pid的所有进程 pid=-1 除发送进程自身外，所有进程ID大于1的进程 Sinno是信号值，当为0时（即空信号），实际不发送任何信号，但照常进行错误检查，因此，可用于检查目标进程是否存在，以及当前进程是否具有向目标发送信号的权限（root权限的进程可以向任何进程发送信号，非root权限的进程只能向属于同一个session或者同一个用户的进程发送信号）。 Kill()最常用于pid&gt;0时的信号发送。该调用执行成功时，返回值为0；错误时，返回-1，并设置相应的错误代码errno。下面是一些可能返回的错误代码： EINVAL：指定的信号sig无效。 ESRCH：参数pid指定的进程或进程组不存在。注意，在进程表项中存在的进程，可能是一个还没有被wait收回，但已经终止执行的僵死进程。 EPERM： 进程没有权力将这个信号发送到指定接收信号的进程。因为，一个进程被允许将信号发送到进程pid时，必须拥有root权力，或者是发出调用的进程的UID 或EUID与指定接收的进程的UID或保存用户ID（savedset-user-ID）相同。如果参数pid小于-1，即该信号发送给一个组，则该错误表示组中有成员进程不能接收该信号。 sigqueue()123#include &lt;sys/types.h&gt;#include &lt;signal.h&gt;int sigqueue(pid_t pid, int sig, const union sigval val) 调用成功返回 0；否则，返回 -1。 sigqueue()是比较新的发送信号系统调用，主要是针对实时信号提出的（当然也支持前32种），支持信号带有参数，与函数sigaction()配合使用。 sigqueue的第一个参数是指定接收信号的进程ID，第二个参数确定即将发送的信号，第三个参数是一个联合数据结构union sigval，指定了信号传递的参数，即通常所说的4字节值。1234typedef union sigval &#123; int sival_int; void *sival_ptr;&#125;sigval_t; sigqueue()比kill()传递了更多的附加信息，但sigqueue()只能向一个进程发送信号，而不能发送信号给一个进程组。如果signo=0，将会执行错误检查，但实际上不发送任何信号，0值信号可用于检查pid的有效性以及当前进程是否有权限向目标进程发送信号。 在调用sigqueue时，sigval_t指定的信息会拷贝到对应sig 注册的3参数信号处理函数的siginfo_t结构中，这样信号处理函数就可以处理这些信息了。由于sigqueue系统调用支持发送带参数信号，所以比kill()系统调用的功能要灵活和强大得多。 alarm（）12#include &lt;unistd.h&gt;unsigned int alarm(unsigned int seconds) 系统调用alarm安排内核为调用进程在指定的seconds秒后发出一个SIGALRM的信号。如果指定的参数seconds为0，则不再发送 SIGALRM信号。后一次设定将取消前一次的设定。该调用返回值为上次定时调用到发送之间剩余的时间，或者因为没有前一次定时调用而返回0。 注意，在使用时，alarm只设定为发送一次信号，如果要多次发送，就要多次使用alarm调用。 setitimer（）现在的系统中很多程序不再使用alarm调用，而是使用setitimer调用来设置定时器，用getitimer来得到定时器的状态，这两个调用的声明格式如下：12int getitimer(int which, struct itimerval *value);int setitimer(int which, const struct itimerval *value, struct itimerval *ovalue); 在使用这两个调用的进程中加入以下头文件：1#include &lt;sys/time.h&gt; 该系统调用给进程提供了三个定时器，它们各自有其独有的计时域，当其中任何一个到达，就发送一个相应的信号给进程，并使得计时器重新开始。三个计时器由参数which指定，如下所示： TIMER_REAL：按实际时间计时，计时到达将给进程发送SIGALRM信号。 ITIMER_VIRTUAL：仅当进程执行时才进行计时。计时到达将发送SIGVTALRM信号给进程。 ITIMER_PROF：当进程执行时和系统为该进程执行动作时都计时。与ITIMER_VIR-TUAL是一对，该定时器经常用来统计进程在用户态和内核态花费的时间。计时到达将发送SIGPROF信号给进程。 定时器中的参数value用来指明定时器的时间，其结构如下：1234struct itimerval &#123; struct timeval it_interval; /* 下一次的取值 */ struct timeval it_value; /* 本次的设定值 */&#125;; 该结构中timeval结构定义如下：1234struct timeval &#123; long tv_sec; /* 秒 */ long tv_usec; /* 微秒，1秒 = 1000000 微秒*/&#125;; 在setitimer 调用中，参数ovalue如果不为空，则其中保留的是上次调用设定的值。定时器将it_value递减到0时，产生一个信号，并将it_value的值设定为it_interval的值，然后重新开始计时，如此往复。当it_value设定为0时，计时器停止，或者当它计时到期，而it_interval 为0时停止。调用成功时，返回0；错误时，返回-1，并设置相应的错误代码errno： EFAULT：参数value或ovalue是无效的指针。 EINVAL：参数which不是ITIMER_REAL、ITIMER_VIRT或ITIMER_PROF中的一个。 下面是关于setitimer调用的一个简单示范，在该例子中，每隔一秒发出一个SIGALRM，每隔0.5秒发出一个SIGVTALRM信号：1234567891011121314151617181920212223242526272829303132333435#include &lt;signal.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/time.h&gt;int sec;void sigroutine(int signo) &#123; switch (signo) &#123; case SIGALRM: printf(&quot;Catch a signal -- SIGALRM &quot;); break; case SIGVTALRM: printf(&quot;Catch a signal -- SIGVTALRM &quot;); break; &#125; return;&#125;int main()&#123; struct itimerval value,ovalue,value2; sec = 5; printf(&quot;process id is %d &quot;,getpid()); signal(SIGALRM, sigroutine); signal(SIGVTALRM, sigroutine); value.it_value.tv_sec = 1; value.it_value.tv_usec = 0; value.it_interval.tv_sec = 1; value.it_interval.tv_usec = 0; setitimer(ITIMER_REAL, &amp;value, &amp;ovalue); value2.it_value.tv_sec = 0; value2.it_value.tv_usec = 500000; value2.it_interval.tv_sec = 0; value2.it_interval.tv_usec = 500000; setitimer(ITIMER_VIRTUAL, &amp;value2, &amp;ovalue); for (;;) ;&#125; 该例子的屏幕拷贝如下：12345678localhost:~$ ./timer_testprocess id is 579Catch a signal – SIGVTALRMCatch a signal – SIGALRMCatch a signal – SIGVTALRMCatch a signal – SIGVTALRMCatch a signal – SIGALRMCatch a signal –GVTALRM abort()12#include &lt;stdlib.h&gt;void abort(void); 向进程发送SIGABORT信号，默认情况下进程会异常退出，当然可定义自己的信号处理函数。即使SIGABORT被进程设置为阻塞信号，调用abort()后，SIGABORT仍然能被进程接收。该函数无返回值。 raise()12#include &lt;signal.h&gt;int raise(int signo) 向进程本身发送信号，参数为即将发送的信号值。调用成功返回 0；否则，返回 -1。 信号集及信号集操作函数：信号集被定义为一种数据类型：123typedef struct &#123; unsigned long sig[_NSIG_WORDS]；&#125; sigset_t 信号集用来描述信号的集合，每个信号占用一位。Linux所支持的所有信号可以全部或部分的出现在信号集中，主要与信号阻塞相关函数配合使用。下面是为信号集操作定义的相关函数：1234567891011#include &lt;signal.h&gt;int sigemptyset(sigset_t *set)；int sigfillset(sigset_t *set)；int sigaddset(sigset_t *set, int signum)int sigdelset(sigset_t *set, int signum)；int sigismember(const sigset_t *set, int signum)；sigemptyset(sigset_t *set)初始化由set指定的信号集，信号集里面的所有信号被清空；sigfillset(sigset_t *set)调用该函数后，set指向的信号集中将包含linux支持的64种信号；sigaddset(sigset_t *set, int signum)在set指向的信号集中加入signum信号；sigdelset(sigset_t *set, int signum)在set指向的信号集中删除signum信号；sigismember(const sigset_t *set, int signum)判定信号signum是否在set指向的信号集中。 信号阻塞与信号未决:每个进程都有一个用来描述哪些信号递送到进程时将被阻塞的信号集，该信号集中的所有信号在递送到进程后都将被阻塞。下面是与信号阻塞相关的几个函数：1234#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *set, sigset_t *oldset))；int sigpending(sigset_t *set));int sigsuspend(const sigset_t *mask))； sigprocmask()函数能够根据参数how来实现对信号集的操作，操作主要有三种： SIG_BLOCK 在进程当前阻塞信号集中添加set指向信号集中的信号 SIG_UNBLOCK 如果进程阻塞信号集中包含set指向信号集中的信号，则解除对该信号的阻塞 SIG_SETMASK 更新进程阻塞信号集为set指向的信号集 sigpending(sigset_t *set))获得当前已递送到进程，却被阻塞的所有信号，在set指向的信号集中返回结果。 sigsuspend(const sigset_t *mask))用于在接收到某个信号之前, 临时用mask替换进程的信号掩码, 并暂停进程执行，直到收到信号为止。sigsuspend 返回后将恢复调用之前的信号掩码。信号处理函数完成后，进程将继续执行。该系统调用始终返回-1，并将errno设置为EINTR。 信号应用实例linux下的信号应用并没有想象的那么恐怖，程序员所要做的最多只有三件事情： 安装信号（推荐使用sigaction()）； 实现三参数信号处理函数，handler(int signal,struct siginfo info, void )； 发送信号，推荐使用sigqueue()。 实际上，对有些信号来说，只要安装信号就足够了（信号处理方式采用缺省或忽略）。其他可能要做的无非是与信号集相关的几种操作。 实例一：信号发送及处理实现一个信号接收程序sigreceive（其中信号安装由sigaction（））。12345678910111213141516171819202122232425262728293031#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; int sig; sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=new_op; if(sigaction(sig,&amp;act,NULL) &lt; 0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); &#125;&#125; void new_op(int signum,siginfo_t *info,void *myact)&#123; printf(&quot;receive signal %d&quot;, signum); sleep(5);&#125; 说明，命令行参数为信号值，后台运行sigreceive signo &amp;，可获得该进程的ID，假设为pid，然后再另一终端上运行kill -s signo pid验证信号的发送接收及处理。同时，可验证信号的排队问题。 实例二：信号传递附加信息主要包括两个实例： 向进程本身发送信号，并传递指针参数123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; union sigval mysigval; int i; int sig; pid_t pid; char data[10]; memset(data,0,sizeof(data)); for(i=0;i &lt; 5;i++) data[i]=&apos;2&apos;; mysigval.sival_ptr=data; sig=atoi(argv[1]); pid=getpid(); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op;//三参数信号处理函数 act.sa_flags=SA_SIGINFO;//信息传递开关，允许传说参数信息给new_op if(sigaction(sig,&amp;act,NULL) &lt; 0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); sigqueue(pid,sig,mysigval);//向本进程发送信号，并传递附加信息 &#125;&#125;void new_op(int signum,siginfo_t *info,void *myact)//三参数信号处理函数的实现&#123; int i; for(i=0;i&lt;10;i++) &#123; printf(&quot;%c\n &quot;,(*( (char*)((*info).si_ptr)+i))); &#125; printf(&quot;handle signal %d over;&quot;,signum);&#125; 这个例子中，信号实现了附加信息的传递，信号究竟如何对这些信息进行处理则取决于具体的应用。 不同进程间传递整型参数： 把1中的信号发送和接收放在两个程序中，并且在发送过程中传递整型参数。 信号接收程序：12345678910111213141516171819202122232425262728293031#include &lt;signal.h&gt;#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;void new_op(int,siginfo_t*,void*);int main(int argc,char**argv)&#123; struct sigaction act; int sig; pid_t pid; pid=getpid(); sig=atoi(argv[1]); sigemptyset(&amp;act.sa_mask); act.sa_sigaction=new_op; act.sa_flags=SA_SIGINFO; if(sigaction(sig,&amp;act,NULL)&lt;0) &#123; printf(&quot;install sigal error\n&quot;); &#125; while(1) &#123; sleep(2); printf(&quot;wait for the signal\n&quot;); &#125;&#125;void new_op(int signum,siginfo_t *info,void *myact)&#123; printf(&quot;the int value is %d \n&quot;,info-&gt;si_int);&#125; 信号发送程序：命令行第二个参数为信号值，第三个参数为接收进程ID。 12345678910111213141516#include &lt;signal.h&gt;#include &lt;sys/time.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;main(int argc,char**argv)&#123; pid_t pid; int signum; union sigval mysigval; signum=atoi(argv[1]); pid=(pid_t)atoi(argv[2]); mysigval.sival_int=8;//不代表具体含义，只用于说明问题 if(sigqueue(pid,signum,mysigval)==-1) printf(&quot;send error\n&quot;); sleep(2);&#125; 注：实例2的两个例子侧重点在于用信号来传递信息，目前关于在linux下通过信号传递信息的实例非常少，倒是Unix下有一些，但传递的基本上都是关于传递一个整数 实例三：信号阻塞及信号集操作12345678910111213141516171819202122232425262728293031323334#include &quot;signal.h&quot;#include &quot;unistd.h&quot;static void my_op(int);main()&#123; sigset_t new_mask,old_mask,pending_mask; struct sigaction act; sigemptyset(&amp;act.sa_mask); act.sa_flags=SA_SIGINFO; act.sa_sigaction=(void*)my_op; if(sigaction(SIGRTMIN+10,&amp;act,NULL)) printf(&quot;install signal SIGRTMIN+10 error\n&quot;); sigemptyset(&amp;new_mask); sigaddset(&amp;new_mask,SIGRTMIN+10); if(sigprocmask(SIG_BLOCK, &amp;new_mask,&amp;old_mask)) printf(&quot;block signal SIGRTMIN+10 error\n&quot;); sleep(10); printf(&quot;now begin to get pending mask and unblock SIGRTMIN+10\n&quot;); if(sigpending(&amp;pending_mask)&lt;0) printf(&quot;get pending mask error\n&quot;); if(sigismember(&amp;pending_mask,SIGRTMIN+10)) printf(&quot;signal SIGRTMIN+10 is pending\n&quot;); if(sigprocmask(SIG_SETMASK,&amp;old_mask,NULL)&lt;0) printf(&quot;unblock signal error\n&quot;); printf(&quot;signal unblocked\n&quot;); sleep(10);&#125;static void my_op(int signum)&#123; printf(&quot;receive signal %d \n&quot;,signum);&#125; 编译该程序，并以后台方式运行。在另一终端向该进程发送信号(运行kill -s 42 pid，SIGRTMIN+10为42)，查看结果可以看出几个关键函数的运行机制，信号集相关操作比较简单。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核poll/epoll/select实现剖析]]></title>
    <url>%2F2019%2F04%2F12%2FLinux%E5%86%85%E6%A0%B8poll_select_epoll%E5%AE%9E%E7%8E%B0%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[poll/select/epoll的实现都是基于文件提供的poll方法(f_op-&gt;poll)，该方法利用poll_table提供的_qproc方法向文件内部事件掩码_key对应的的一个或多个等待队列(wait_queue_head_t)上添加包含唤醒函数(wait_queue_t.func)的节点(wait_queue_t)，并检查文件当前就绪的状态返回给poll的调用者(依赖于文件的实现)。当文件的状态发生改变时(例如网络数据包到达)，文件就会遍历事件对应的等待队列并调用回调函数(wait_queue_t.func)唤醒等待线程。 通常的file.f_ops.poll实现及相关结构体如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105struct file &#123; const struct file_operations *f_op; spinlock_t f_lock; // 文件内部实现细节 void *private_data; #ifdef CONFIG_EPOLL /* Used by fs/eventpoll.c to link all the hooks to this file */ struct list_head f_ep_links; struct list_head f_tfile_llink; #endif /* #ifdef CONFIG_EPOLL */ // 其他细节.... &#125;; // 文件操作 struct file_operations &#123; // 文件提供给poll/select/epoll // 获取文件当前状态, 以及就绪通知接口函数 unsigned int (*poll) (struct file *, struct poll_table_struct *); // 其他方法read/write 等... ... &#125;; // 通常的file.f_ops.poll 方法的实现 unsigned int file_f_op_poll (struct file *filp, struct poll_table_struct *wait) &#123; unsigned int mask = 0; wait_queue_head_t * wait_queue; //1. 根据事件掩码wait-&gt;key_和文件实现filep-&gt;private_data 取得事件掩码对应的一个或多个wait queue head some_code(); // 2. 调用poll_wait 向获得的wait queue head 添加节点 poll_wait(filp, wait_queue, wait); // 3. 取得当前就绪状态保存到mask some_code(); return mask; &#125; // select/poll/epoll 向文件注册就绪后回调节点的接口结构 typedef struct poll_table_struct &#123; // 向wait_queue_head 添加回调节点(wait_queue_t)的接口函数 poll_queue_proc _qproc; // 关注的事件掩码, 文件的实现利用此掩码将等待队列传递给_qproc unsigned long _key; &#125; poll_table; typedef void (*poll_queue_proc)(struct file *, wait_queue_head_t *, struct poll_table_struct *); // 通用的poll_wait 函数, 文件的f_ops-&gt;poll 通常会调用此函数 static inline void poll_wait(struct file * filp, wait_queue_head_t * wait_address, poll_table *p) &#123; if (p &amp;&amp; p-&gt;_qproc &amp;&amp; wait_address) &#123; // 调用_qproc 在wait_address 上添加节点和回调函数 // 调用 poll_table_struct 上的函数指针向wait_address添加节点, 并设置节点的func // (如果是select或poll 则是 __pollwait, 如果是 epoll 则是 ep_ptable_queue_proc), p-&gt;_qproc(filp, wait_address, p); &#125; &#125; // wait_queue 头节点 typedef struct __wait_queue_head wait_queue_head_t; struct __wait_queue_head &#123; spinlock_t lock; struct list_head task_list; &#125;; // wait_queue 节点 typedef struct __wait_queue wait_queue_t; struct __wait_queue &#123; unsigned int flags; #define WQ_FLAG_EXCLUSIVE 0x01 void *private; wait_queue_func_t func; struct list_head task_list; &#125;; typedef int (*wait_queue_func_t)(wait_queue_t *wait, unsigned mode, int flags, void *key); // 当文件的状态发生改变时, 文件会调用此函数，此函数通过调用wait_queue_t.func通知poll的调用者 // 其中key是文件当前的事件掩码 void __wake_up(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, void *key) &#123; unsigned long flags; spin_lock_irqsave(&amp;q-&gt;lock, flags); __wake_up_common(q, mode, nr_exclusive, 0, key); spin_unlock_irqrestore(&amp;q-&gt;lock, flags); &#125; static void __wake_up_common(wait_queue_head_t *q, unsigned int mode, int nr_exclusive, int wake_flags, void *key) &#123; wait_queue_t *curr, *next; // 遍历并调用func 唤醒, 通常func会唤醒调用poll的线程 list_for_each_entry_safe(curr, next, &amp;q-&gt;task_list, task_list) &#123; unsigned flags = curr-&gt;flags; if (curr-&gt;func(curr, mode, wake_flags, key) &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive) &#123; break; &#125; &#125; &#125; poll 和 selectpoll和select的实现基本上是一致的，只是传递参数有所不同，他们的基本流程如下： 复制用户数据到内核空间 估计超时时间 遍历每个文件并调用f_op-&gt;poll 取得文件当前就绪状态， 如果前面遍历的文件都没有就绪，向文件插入wait_queue节点 遍历完成后检查状态：a). 如果已经有就绪的文件转到5； b). 如果有信号产生，重启poll或select（转到 1或3）； c). 否则挂起进程等待超时或唤醒，超时或被唤醒后再次遍历所有文件取得每个文件的就绪状态 将所有文件的就绪状态复制到用户空间 清理申请的资源 关键结构体下面是poll/select共用的结构体及其相关功能: poll_wqueues 是 select/poll 对poll_table接口的具体化实现,其中的table, inline_index和inline_entries都是为了管理内存。poll_table_entry 与一个文件相关联，用于管理插入到文件的wait_queue节点。1234567891011121314151617181920212223// select/poll 对poll_table的具体化实现 struct poll_wqueues &#123; poll_table pt; struct poll_table_page *table; // 如果inline_entries 空间不足, 从poll_table_page 中分配 struct task_struct *polling_task; // 调用poll 或select 的进程 int triggered; // 已触发标记 int error; int inline_index; // 下一个要分配的inline_entrie 索引 struct poll_table_entry inline_entries[N_INLINE_POLL_ENTRIES];// &#125;; // 帮助管理select/poll 申请的内存 struct poll_table_page &#123; struct poll_table_page * next; // 下一个 page struct poll_table_entry * entry; // 指向第一个entries struct poll_table_entry entries[0]; &#125;; // 与一个正在poll /select 的文件相关联, struct poll_table_entry &#123; struct file *filp; // 在poll/select中的文件 unsigned long key; wait_queue_t wait; // 插入到wait_queue_head_t 的节点 wait_queue_head_t *wait_address; // 文件上的wait_queue_head_t 地址 &#125;; 公共函数 下面是poll/select公用的一些函数，这些函数实现了poll和select的核心功能。 poll_initwait 用于初始化poll_wqueues， __pollwait 实现了向文件中添加回调节点的逻辑， pollwake 当文件状态发生改变时，由文件调用，用来唤醒线程， poll_get_entry，free_poll_entry，poll_freewait用来申请释放poll_table_entry 占用的内存，并负责释放文件上的wait_queue节点。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374// poll_wqueues 的初始化: // 初始化 poll_wqueues , __pollwait会在文件就绪时被调用 void poll_initwait(struct poll_wqueues *pwq) &#123; // 初始化poll_table, 相当于调用基类的构造函数 init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait); /* * static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc) * &#123; * pt-&gt;_qproc = qproc; * pt-&gt;_key = ~0UL; * &#125; */ pwq-&gt;polling_task = current; pwq-&gt;triggered = 0; pwq-&gt;error = 0; pwq-&gt;table = NULL; pwq-&gt;inline_index = 0; &#125; // wait_queue设置函数 // poll/select 向文件wait_queue中添加节点的方法 static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p) &#123; struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt); struct poll_table_entry *entry = poll_get_entry(pwq); if (!entry) &#123; return; &#125; get_file(filp); //put_file() in free_poll_entry() entry-&gt;filp = filp; entry-&gt;wait_address = wait_address; // 等待队列头 entry-&gt;key = p-&gt;key; // 设置回调为 pollwake init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake); entry-&gt;wait.private = pwq; // 添加到等待队列 add_wait_queue(wait_address, &amp;entry-&gt;wait); &#125; // 在等待队列(wait_queue_t)上回调函数(func) // 文件就绪后被调用，唤醒调用进程，其中key是文件提供的当前状态掩码 static int pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key) &#123; struct poll_table_entry *entry; // 取得文件对应的poll_table_entry entry = container_of(wait, struct poll_table_entry, wait); // 过滤不关注的事件 if (key &amp;&amp; !((unsigned long)key &amp; entry-&gt;key)) &#123; return 0; &#125; // 唤醒 return __pollwake(wait, mode, sync, key); &#125; static int __pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key) &#123; struct poll_wqueues *pwq = wait-&gt;private; // 将调用进程 pwq-&gt;polling_task 关联到 dummy_wait DECLARE_WAITQUEUE(dummy_wait, pwq-&gt;polling_task); smp_wmb(); pwq-&gt;triggered = 1;// 标记为已触发 // 唤醒调用进程 return default_wake_function(&amp;dummy_wait, mode, sync, key); &#125; // 默认的唤醒函数,poll/select 设置的回调函数会调用此函数唤醒 // 直接唤醒等待队列上的线程,即将线程移到运行队列(rq) int default_wake_function(wait_queue_t *curr, unsigned mode, int wake_flags, void *key) &#123; // 这个函数比较复杂, 这里就不具体分析了 return try_to_wake_up(curr-&gt;private, mode, wake_flags); &#125; poll，select对poll_table_entry的申请和释放采用的是类似内存池的管理方式，先使用预分配的空间，预分配的空间不足时，分配一个内存页，使用内存页上的空间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// 分配或使用已先前申请的 poll_table_entry, static struct poll_table_entry *poll_get_entry(struct poll_wqueues *p) &#123; struct poll_table_page *table = p-&gt;table; if (p-&gt;inline_index &lt; N_INLINE_POLL_ENTRIES) &#123; return p-&gt;inline_entries + p-&gt;inline_index++; &#125; if (!table || POLL_TABLE_FULL(table)) &#123; struct poll_table_page *new_table; new_table = (struct poll_table_page *) __get_free_page(GFP_KERNEL); if (!new_table) &#123; p-&gt;error = -ENOMEM; return NULL; &#125; new_table-&gt;entry = new_table-&gt;entries; new_table-&gt;next = table; p-&gt;table = new_table; table = new_table; &#125; return table-&gt;entry++; &#125; // 清理poll_wqueues 占用的资源 void poll_freewait(struct poll_wqueues *pwq) &#123; struct poll_table_page * p = pwq-&gt;table; // 遍历所有已分配的inline poll_table_entry int i; for (i = 0; i &lt; pwq-&gt;inline_index; i++) &#123; free_poll_entry(pwq-&gt;inline_entries + i); &#125; // 遍历在poll_table_page上分配的inline poll_table_entry // 并释放poll_table_page while (p) &#123; struct poll_table_entry * entry; struct poll_table_page *old; entry = p-&gt;entry; do &#123; entry--; free_poll_entry(entry); &#125; while (entry &gt; p-&gt;entries); old = p; p = p-&gt;next; free_page((unsigned long) old); &#125; &#125; static void free_poll_entry(struct poll_table_entry *entry) &#123; // 从等待队列中删除, 释放文件引用计数 remove_wait_queue(entry-&gt;wait_address, &amp;entry-&gt;wait); fput(entry-&gt;filp); &#125; poll/select核心结构关系下图是 poll/select 实现公共部分的关系图，包含了与文件直接的关系，以及函数之间的依赖。 poll的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227// poll 使用的结构体 struct pollfd &#123; int fd; // 描述符 short events; // 关注的事件掩码 short revents; // 返回的事件掩码 &#125;; // long sys_poll(struct pollfd *ufds, unsigned int nfds, long timeout_msecs) SYSCALL_DEFINE3(poll, struct pollfd __user *, ufds, unsigned int, nfds, long, timeout_msecs) &#123; struct timespec end_time, *to = NULL; int ret; if (timeout_msecs &gt;= 0) &#123; to = &amp;end_time; // 将相对超时时间msec 转化为绝对时间 poll_select_set_timeout(to, timeout_msecs / MSEC_PER_SEC, NSEC_PER_MSEC * (timeout_msecs % MSEC_PER_SEC)); &#125; // do sys poll ret = do_sys_poll(ufds, nfds, to); // do_sys_poll 被信号中断, 重新调用, 对使用者来说 poll 是不会被信号中断的. if (ret == -EINTR) &#123; struct restart_block *restart_block; restart_block = &amp;current_thread_info()-&gt;restart_block; restart_block-&gt;fn = do_restart_poll; // 设置重启的函数 restart_block-&gt;poll.ufds = ufds; restart_block-&gt;poll.nfds = nfds; if (timeout_msecs &gt;= 0) &#123; restart_block-&gt;poll.tv_sec = end_time.tv_sec; restart_block-&gt;poll.tv_nsec = end_time.tv_nsec; restart_block-&gt;poll.has_timeout = 1; &#125; else &#123; restart_block-&gt;poll.has_timeout = 0; &#125; // ERESTART_RESTARTBLOCK 不会返回给用户进程, // 而是会被系统捕获, 然后调用 do_restart_poll, ret = -ERESTART_RESTARTBLOCK; &#125; return ret; &#125; int do_sys_poll(struct pollfd __user *ufds, unsigned int nfds, struct timespec *end_time) &#123; struct poll_wqueues table; int err = -EFAULT, fdcount, len, size; /* 首先使用栈上的空间，节约内存，加速访问 */ long stack_pps[POLL_STACK_ALLOC/sizeof(long)]; struct poll_list *const head = (struct poll_list *)stack_pps; struct poll_list *walk = head; unsigned long todo = nfds; if (nfds &gt; rlimit(RLIMIT_NOFILE)) &#123; // 文件描述符数量超过当前进程限制 return -EINVAL; &#125; // 复制用户空间数据到内核 len = min_t(unsigned int, nfds, N_STACK_PPS); for (;;) &#123; walk-&gt;next = NULL; walk-&gt;len = len; if (!len) &#123; break; &#125; // 复制到当前的 entries if (copy_from_user(walk-&gt;entries, ufds + nfds-todo, sizeof(struct pollfd) * walk-&gt;len)) &#123; goto out_fds; &#125; todo -= walk-&gt;len; if (!todo) &#123; break; &#125; // 栈上空间不足，在堆上申请剩余部分 len = min(todo, POLLFD_PER_PAGE); size = sizeof(struct poll_list) + sizeof(struct pollfd) * len; walk = walk-&gt;next = kmalloc(size, GFP_KERNEL); if (!walk) &#123; err = -ENOMEM; goto out_fds; &#125; &#125; // 初始化 poll_wqueues 结构, 设置函数指针_qproc 为__pollwait poll_initwait(&amp;table); // poll fdcount = do_poll(nfds, head, &amp;table, end_time); // 从文件wait queue 中移除对应的节点, 释放entry. poll_freewait(&amp;table); // 复制结果到用户空间 for (walk = head; walk; walk = walk-&gt;next) &#123; struct pollfd *fds = walk-&gt;entries; int j; for (j = 0; j &lt; len; j++, ufds++) if (__put_user(fds[j].revents, &amp;ufds-&gt;revents)) &#123; goto out_fds; &#125; &#125; err = fdcount; out_fds: // 释放申请的内存 walk = head-&gt;next; while (walk) &#123; struct poll_list *pos = walk; walk = walk-&gt;next; kfree(pos); &#125; return err; &#125; // 真正的处理函数 static int do_poll(unsigned int nfds, struct poll_list *list, struct poll_wqueues *wait, struct timespec *end_time) &#123; poll_table* pt = &amp;wait-&gt;pt; ktime_t expire, *to = NULL; int timed_out = 0, count = 0; unsigned long slack = 0; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; // 已经超时,直接遍历所有文件描述符, 然后返回 pt = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) &#123; // 估计进程等待时间，纳秒 slack = select_estimate_accuracy(end_time); &#125; // 遍历文件，为每个文件的等待队列添加唤醒函数(pollwake) for (;;) &#123; struct poll_list *walk; for (walk = list; walk != NULL; walk = walk-&gt;next) &#123; struct pollfd * pfd, * pfd_end; pfd = walk-&gt;entries; pfd_end = pfd + walk-&gt;len; for (; pfd != pfd_end; pfd++) &#123; // do_pollfd 会向文件对应的wait queue 中添加节点 // 和回调函数(如果 pt 不为空) // 并检查当前文件状态并设置返回的掩码 if (do_pollfd(pfd, pt)) &#123; // 该文件已经准备好了. // 不需要向后面文件的wait queue 中添加唤醒函数了. count++; pt = NULL; &#125; &#125; &#125; // 下次循环的时候不需要向文件的wait queue 中添加节点, // 因为前面的循环已经把该添加的都添加了 pt = NULL; // 第一次遍历没有发现ready的文件 if (!count) &#123; count = wait-&gt;error; // 有信号产生 if (signal_pending(current)) &#123; count = -EINTR; &#125; &#125; // 有ready的文件或已经超时 if (count || timed_out) &#123; break; &#125; // 转换为内核时间 if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; // 等待事件就绪, 如果有事件发生或超时，就再循 // 环一遍，取得事件状态掩码并计数, // 注意此次循环中, 文件 wait queue 中的节点依然存在 if (!poll_schedule_timeout(wait, TASK_INTERRUPTIBLE, to, slack)) &#123; timed_out = 1; &#125; &#125; return count; &#125; static inline unsigned int do_pollfd(struct pollfd *pollfd, poll_table *pwait) &#123; unsigned int mask; int fd; mask = 0; fd = pollfd-&gt;fd; if (fd &gt;= 0) &#123; int fput_needed; struct file * file; // 取得fd对应的文件结构体 file = fget_light(fd, &amp;fput_needed); mask = POLLNVAL; if (file != NULL) &#123; // 如果没有 f_op 或 f_op-&gt;poll 则认为文件始终处于就绪状态. mask = DEFAULT_POLLMASK; if (file-&gt;f_op &amp;&amp; file-&gt;f_op-&gt;poll) &#123; if (pwait) &#123; // 设置关注的事件掩码 pwait-&gt;key = pollfd-&gt;events | POLLERR | POLLHUP; &#125; // 注册回调函数，并返回当前就绪状态，就绪后会调用pollwake mask = file-&gt;f_op-&gt;poll(file, pwait); &#125; mask &amp;= pollfd-&gt;events | POLLERR | POLLHUP; // 移除不需要的状态掩码 fput_light(file, fput_needed);// 释放文件 &#125; &#125; pollfd-&gt;revents = mask; // 更新事件状态 return mask; &#125; static long do_restart_poll(struct restart_block *restart_block) &#123; struct pollfd __user *ufds = restart_block-&gt;poll.ufds; int nfds = restart_block-&gt;poll.nfds; struct timespec *to = NULL, end_time; int ret; if (restart_block-&gt;poll.has_timeout) &#123; // 获取先前的超时时间 end_time.tv_sec = restart_block-&gt;poll.tv_sec; end_time.tv_nsec = restart_block-&gt;poll.tv_nsec; to = &amp;end_time; &#125; ret = do_sys_poll(ufds, nfds, to); // 重新调用 do_sys_poll if (ret == -EINTR) &#123; // 又被信号中断了, 再次重启 restart_block-&gt;fn = do_restart_poll; ret = -ERESTART_RESTARTBLOCK; &#125; return ret; &#125; select 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258typedef struct &#123; unsigned long *in, *out, *ex; unsigned long *res_in, *res_out, *res_ex; &#125; fd_set_bits; // long sys_select(int n, fd_set *inp, fd_set *outp, fd_set *exp, struct timeval *tvp) SYSCALL_DEFINE5(select, int, n, fd_set __user *, inp, fd_set __user *, outp, fd_set __user *, exp, struct timeval __user *, tvp) &#123; struct timespec end_time, *to = NULL; struct timeval tv; int ret; if (tvp) &#123; if (copy_from_user(&amp;tv, tvp, sizeof(tv))) &#123; return -EFAULT; &#125; // 计算超时时间 to = &amp;end_time; if (poll_select_set_timeout(to, tv.tv_sec + (tv.tv_usec / USEC_PER_SEC), (tv.tv_usec % USEC_PER_SEC) * NSEC_PER_USEC)) &#123; return -EINVAL; &#125; &#125; ret = core_sys_select(n, inp, outp, exp, to); // 复制剩余时间到用户空间 ret = poll_select_copy_remaining(&amp;end_time, tvp, 1, ret); return ret; &#125; int core_sys_select(int n, fd_set __user *inp, fd_set __user *outp, fd_set __user *exp, struct timespec *end_time) &#123; fd_set_bits fds; void *bits; int ret, max_fds; unsigned int size; struct fdtable *fdt; //小对象使用栈上的空间,节约内存, 加快访问速度 long stack_fds[SELECT_STACK_ALLOC/sizeof(long)]; ret = -EINVAL; if (n &lt; 0) &#123; goto out_nofds; &#125; rcu_read_lock(); // 取得进程对应的 fdtable fdt = files_fdtable(current-&gt;files); max_fds = fdt-&gt;max_fds; rcu_read_unlock(); if (n &gt; max_fds) &#123; n = max_fds; &#125; size = FDS_BYTES(n); bits = stack_fds; if (size &gt; sizeof(stack_fds) / 6) &#123; // 栈上的空间不够, 申请内存, 全部使用堆上的空间 ret = -ENOMEM; bits = kmalloc(6 * size, GFP_KERNEL); if (!bits) &#123; goto out_nofds; &#125; &#125; fds.in = bits; fds.out = bits + size; fds.ex = bits + 2*size; fds.res_in = bits + 3*size; fds.res_out = bits + 4*size; fds.res_ex = bits + 5*size; // 复制用户空间到内核 if ((ret = get_fd_set(n, inp, fds.in)) || (ret = get_fd_set(n, outp, fds.out)) || (ret = get_fd_set(n, exp, fds.ex))) &#123; goto out; &#125; // 初始化fd set zero_fd_set(n, fds.res_in); zero_fd_set(n, fds.res_out); zero_fd_set(n, fds.res_ex); ret = do_select(n, &amp;fds, end_time); if (ret &lt; 0) &#123; goto out; &#125; if (!ret) &#123; // 该返回值会被系统捕获, 并以同样的参数重新调用sys_select() ret = -ERESTARTNOHAND; if (signal_pending(current)) &#123; goto out; &#125; ret = 0; &#125; // 复制到用户空间 if (set_fd_set(n, inp, fds.res_in) || set_fd_set(n, outp, fds.res_out) || set_fd_set(n, exp, fds.res_ex)) &#123; ret = -EFAULT; &#125; out: if (bits != stack_fds) &#123; kfree(bits); &#125; out_nofds: return ret; &#125; int do_select(int n, fd_set_bits *fds, struct timespec *end_time) &#123; ktime_t expire, *to = NULL; struct poll_wqueues table; poll_table *wait; int retval, i, timed_out = 0; unsigned long slack = 0; rcu_read_lock(); // 检查fds中fd的有效性, 并获取当前最大的fd retval = max_select_fd(n, fds); rcu_read_unlock(); if (retval &lt; 0) &#123; return retval; &#125; n = retval; // 初始化 poll_wqueues 结构, 设置函数指针_qproc 为__pollwait poll_initwait(&amp;table); wait = &amp;table.pt; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; wait = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) &#123; // 估计需要等待的时间. slack = select_estimate_accuracy(end_time); &#125; retval = 0; for (;;) &#123; unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp; inp = fds-&gt;in; outp = fds-&gt;out; exp = fds-&gt;ex; rinp = fds-&gt;res_in; routp = fds-&gt;res_out; rexp = fds-&gt;res_ex; // 遍历所有的描述符, i 文件描述符 for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) &#123; unsigned long in, out, ex, all_bits, bit = 1, mask, j; unsigned long res_in = 0, res_out = 0, res_ex = 0; const struct file_operations *f_op = NULL; struct file *file = NULL; // 检查当前的 slot 中的描述符 in = *inp++; out = *outp++; ex = *exp++; all_bits = in | out | ex; if (all_bits == 0) &#123; // 没有需要监听的描述符, 下一个slot i += __NFDBITS; continue; &#125; for (j = 0; j &lt; __NFDBITS; ++j, ++i, bit &lt;&lt;= 1) &#123; int fput_needed; if (i &gt;= n) &#123; break; &#125; // 不需要监听描述符 i if (!(bit &amp; all_bits)) &#123; continue; &#125; // 取得文件结构 file = fget_light(i, &amp;fput_needed); if (file) &#123; f_op = file-&gt;f_op; // 没有 f_op 的话就认为一直处于就绪状态 mask = DEFAULT_POLLMASK; if (f_op &amp;&amp; f_op-&gt;poll) &#123; // 设置等待事件的掩码 wait_key_set(wait, in, out, bit); /* static inline void wait_key_set(poll_table *wait, unsigned long in, unsigned long out, unsigned long bit) &#123; wait-&gt;_key = POLLEX_SET;// (POLLPRI) if (in &amp; bit) wait-&gt;_key |= POLLIN_SET;//(POLLRDNORM | POLLRDBAND | POLLIN | POLLHUP | POLLERR) if (out &amp; bit) wait-&gt;_key |= POLLOUT_SET;//POLLOUT_SET (POLLWRBAND | POLLWRNORM | POLLOUT | POLLERR) &#125; */ // 获取当前的就绪状态, 并添加到文件的对应等待队列中 mask = (*f_op-&gt;poll)(file, wait); // 和poll完全一样 &#125; fput_light(file, fput_needed); // 释放文件 // 检查文件 i 是否已有事件就绪， if ((mask &amp; POLLIN_SET) &amp;&amp; (in &amp; bit)) &#123; res_in |= bit; retval++; // 如果已有就绪事件就不再向其他文件的 // 等待队列中添加回调函数 wait = NULL; &#125; if ((mask &amp; POLLOUT_SET) &amp;&amp; (out &amp; bit)) &#123; res_out |= bit; retval++; wait = NULL; &#125; if ((mask &amp; POLLEX_SET) &amp;&amp; (ex &amp; bit)) &#123; res_ex |= bit; retval++; wait = NULL; &#125; &#125; &#125; if (res_in) &#123; *rinp = res_in; &#125; if (res_out) &#123; *routp = res_out; &#125; if (res_ex) &#123; *rexp = res_ex; &#125; cond_resched(); &#125; wait = NULL; // 该添加回调函数的都已经添加了 if (retval || timed_out || signal_pending(current)) &#123; break; // 信号发生，监听事件就绪或超时 &#125; if (table.error) &#123; retval = table.error; // 产生错误了 break; &#125; // 转换到内核时间 if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; // 等待直到超时, 或由回调函数唤醒, 超时后会再次遍历文件描述符 if (!poll_schedule_timeout(&amp;table, TASK_INTERRUPTIBLE, to, slack)) &#123; timed_out = 1; &#125; &#125; poll_freewait(&amp;table); return retval; &#125; epoll实现epoll 的实现比poll/select 复杂一些，这是因为： epoll_wait, epoll_ctl 的调用完全独立开来,内核需要锁机制对这些操作进行保护，并且需要持久的维护添加到epoll的文件 epoll本身也是文件，也可以被poll/select/epoll监视，这可能导致epoll之间循环唤醒的问题 单个文件的状态改变可能唤醒过多监听在其上的epoll，产生唤醒风暴 epoll各个功能的实现要非常小心面对这些问题，使得复杂度大大增加。 epoll的核心数据结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// epoll的核心实现对应于一个epoll描述符 struct eventpoll &#123; spinlock_t lock; struct mutex mtx; wait_queue_head_t wq; // sys_epoll_wait() 等待在这里 // f_op-&gt;poll() 使用的, 被其他事件通知机制利用的wait_address wait_queue_head_t poll_wait; /* 已就绪的需要检查的epitem 列表 */ struct list_head rdllist; /* 保存所有加入到当前epoll的文件对应的epitem*/ struct rb_root rbr; // 当正在向用户空间复制数据时, 产生的可用文件 struct epitem *ovflist; /* The user that created the eventpoll descriptor */ struct user_struct *user; struct file *file; /*优化循环检查，避免循环检查中重复的遍历 */ int visited; struct list_head visited_list_link; &#125; // 对应于一个加入到epoll的文件 struct epitem &#123; // 挂载到eventpoll 的红黑树节点 struct rb_node rbn; // 挂载到eventpoll.rdllist 的节点 struct list_head rdllink; // 连接到ovflist 的指针 struct epitem *next; /* 文件描述符信息fd + file, 红黑树的key */ struct epoll_filefd ffd; /* Number of active wait queue attached to poll operations */ int nwait; // 当前文件的等待队列(eppoll_entry)列表 // 同一个文件上可能会监视多种事件, // 这些事件可能属于不同的wait_queue中 // (取决于对应文件类型的实现), // 所以需要使用链表 struct list_head pwqlist; // 当前epitem 的所有者 struct eventpoll *ep; /* List header used to link this item to the &amp;quot;struct file&amp;quot; items list */ struct list_head fllink; /* epoll_ctl 传入的用户数据 */ struct epoll_event event; &#125;; struct epoll_filefd &#123; struct file *file; int fd; &#125;; // 与一个文件上的一个wait_queue_head 相关联，因为同一文件可能有多个等待的事件，这些事件可能使用不同的等待队列 struct eppoll_entry &#123; // List struct epitem.pwqlist struct list_head llink; // 所有者 struct epitem *base; // 添加到wait_queue 中的节点 wait_queue_t wait; // 文件wait_queue 头 wait_queue_head_t *whead; &#125;; // 用户使用的epoll_event struct epoll_event &#123; __u32 events; __u64 data; &#125; EPOLL_PACKED; 文件系统初始化和epoll_create12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// epoll 文件系统的相关实现 // epoll 文件系统初始化, 在系统启动时会调用 static int __init eventpoll_init(void) &#123; struct sysinfo si; si_meminfo(&amp;si); // 限制可添加到epoll的最多的描述符数量 max_user_watches = (((si.totalram - si.totalhigh) / 25) &lt;&lt; PAGE_SHIFT) / EP_ITEM_COST; BUG_ON(max_user_watches &lt; 0); // 初始化递归检查队列 ep_nested_calls_init(&amp;poll_loop_ncalls); ep_nested_calls_init(&amp;poll_safewake_ncalls); ep_nested_calls_init(&amp;poll_readywalk_ncalls); // epoll 使用的slab分配器分别用来分配epitem和eppoll_entry epi_cache = kmem_cache_create(&quot;eventpoll_epi&quot;, sizeof(struct epitem), 0, SLAB_HWCACHE_ALIGN | SLAB_PANIC, NULL); pwq_cache = kmem_cache_create(&quot;eventpoll_pwq&quot;, sizeof(struct eppoll_entry), 0, SLAB_PANIC, NULL); return 0; &#125; SYSCALL_DEFINE1(epoll_create, int, size) &#123; if (size &lt;= 0) &#123; return -EINVAL; &#125; return sys_epoll_create1(0); &#125; SYSCALL_DEFINE1(epoll_create1, int, flags) &#123; int error, fd; struct eventpoll *ep = NULL; struct file *file; /* Check the EPOLL_* constant for consistency. */ BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC); if (flags &amp; ~EPOLL_CLOEXEC) &#123; return -EINVAL; &#125; /* * Create the internal data structure (&quot;struct eventpoll&quot;). */ error = ep_alloc(&amp;ep); if (error &lt; 0) &#123; return error; &#125; /* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */ fd = get_unused_fd_flags(O_RDWR | (flags &amp; O_CLOEXEC)); if (fd &lt; 0) &#123; error = fd; goto out_free_ep; &#125; // 设置epfd的相关操作，由于epoll也是文件也提供了poll操作 file = anon_inode_getfile(&quot;[eventpoll]&quot;, &amp;eventpoll_fops, ep, O_RDWR | (flags &amp; O_CLOEXEC)); if (IS_ERR(file)) &#123; error = PTR_ERR(file); goto out_free_fd; &#125; fd_install(fd, file); ep-&gt;file = file; return fd; out_free_fd: put_unused_fd(fd); out_free_ep: ep_free(ep); return error; &#125; epoll中的递归死循环和深度检查递归深度检测(ep_call_nested)epoll本身也是文件，也可以被poll/select/epoll监视，如果epoll之间互相监视就有可能导致死循环。epoll的实现中，所有可能产生递归调用的函数都由函函数ep_call_nested进行包裹，递归调用过程中出现死循环或递归过深就会打破死循环和递归调用直接返回。该函数的实现依赖于一个外部的全局链表nested_call_node(不同的函数调用使用不同的节点)，每次调用可能发生递归的函数(nproc)就向链表中添加一个包含当前函数调用上下文ctx(进程，CPU，或epoll文件)和处理的对象标识cookie的节点，通过检测是否有相同的节点就可以知道是否发生了死循环，检查链表中同一上下文包含的节点个数就可以知道递归的深度。以下就是这一过程的源码。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162struct nested_call_node &#123; struct list_head llink; void *cookie; // 函数运行标识, 任务标志 void *ctx; // 运行环境标识 &#125;; struct nested_calls &#123; struct list_head tasks_call_list; spinlock_t lock; &#125;; // 全局的不同调用使用的链表 // 死循环检查和唤醒风暴检查链表 static nested_call_node poll_loop_ncalls; // 唤醒时使用的检查链表 static nested_call_node poll_safewake_ncalls; // 扫描readylist 时使用的链表 static nested_call_node poll_readywalk_ncalls; // 限制epoll 中直接或间接递归调用的深度并防止死循环 // ctx: 任务运行上下文(进程, CPU 等) // cookie: 每个任务的标识 // priv: 任务运行需要的私有数据 // 如果用面向对象语言实现应该就会是一个wapper类 static int ep_call_nested(struct nested_calls *ncalls, int max_nests, int (*nproc)(void *, void *, int), void *priv, void *cookie, void *ctx) &#123; int error, call_nests = 0; unsigned long flags; struct list_head *lsthead = &amp;ncalls-&gt;tasks_call_list; struct nested_call_node *tncur; struct nested_call_node tnode; spin_lock_irqsave(&amp;ncalls-&gt;lock, flags); // 检查原有的嵌套调用链表ncalls, 查看是否有深度超过限制的情况 list_for_each_entry(tncur, lsthead, llink) &#123; // 同一上下文中(ctx)有相同的任务(cookie)说明产生了死循环 // 同一上下文的递归深度call_nests 超过限制 if (tncur-&gt;ctx == ctx &amp;&amp; (tncur-&gt;cookie == cookie || ++call_nests &gt; max_nests)) &#123; error = -1; &#125; goto out_unlock; &#125; /* 将当前的任务请求添加到调用列表*/ tnode.ctx = ctx; tnode.cookie = cookie; list_add(&amp;tnode.llink, lsthead); spin_unlock_irqrestore(&amp;ncalls-&gt;lock, flags); /* nproc 可能会导致递归调用(直接或间接)ep_call_nested * 如果发生递归调用, 那么在此函数返回之前, * ncalls 又会被加入额外的节点, * 这样通过前面的检测就可以知道递归调用的深度 */ error = (*nproc)(priv, cookie, call_nests); /* 从链表中删除当前任务*/ spin_lock_irqsave(&amp;ncalls-&gt;lock, flags); list_del(&amp;tnode.llink); out_unlock: spin_unlock_irqrestore(&amp;ncalls-&gt;lock, flags); return error; &#125; 循环检测(ep_loop_check)循环检查(ep_loop_check)，该函数递归调用ep_loop_check_proc利用ep_call_nested来实现epoll之间相互监视的死循环。因为ep_call_nested中已经对死循环和过深的递归做了检查，实际的ep_loop_check_proc的实现只是递归调用自己。其中的visited_list和visited标记完全是为了优化处理速度，如果没有visited_list和visited标记函数也是能够工作的。该函数中得上下文就是当前的进程，cookie就是正在遍历的epoll结构。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static LIST_HEAD(visited_list); // 检查 file (epoll)和ep 之间是否有循环 static int ep_loop_check(struct eventpoll *ep, struct file *file) &#123; int ret; struct eventpoll *ep_cur, *ep_next; ret = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, ep_loop_check_proc, file, ep, current); /* 清除链表和标志 */ list_for_each_entry_safe(ep_cur, ep_next, &amp;visited_list, visited_list_link) &#123; ep_cur-&gt;visited = 0; list_del(&amp;ep_cur-&gt;visited_list_link); &#125; return ret; &#125; static int ep_loop_check_proc(void *priv, void *cookie, int call_nests) &#123; int error = 0; struct file *file = priv; struct eventpoll *ep = file-&gt;private_data; struct eventpoll *ep_tovisit; struct rb_node *rbp; struct epitem *epi; mutex_lock_nested(&amp;ep-&gt;mtx, call_nests + 1); // 标记当前为已遍历 ep-&gt;visited = 1; list_add(&amp;ep-&gt;visited_list_link, &amp;visited_list); // 遍历所有ep 监视的文件 for (rbp = rb_first(&amp;ep-&gt;rbr); rbp; rbp = rb_next(rbp)) &#123; epi = rb_entry(rbp, struct epitem, rbn); if (unlikely(is_file_epoll(epi-&gt;ffd.file))) &#123; ep_tovisit = epi-&gt;ffd.file-&gt;private_data; // 跳过先前已遍历的, 避免循环检查 if (ep_tovisit-&gt;visited) &#123; continue; &#125; // 所有ep监视的未遍历的epoll error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, ep_loop_check_proc, epi-&gt;ffd.file, ep_tovisit, current); if (error != 0) &#123; break; &#125; &#125; else &#123; // 文件不在tfile_check_list 中, 添加 // 最外层的epoll 需要检查子epoll监视的文件 if (list_empty(&amp;epi-&gt;ffd.file-&gt;f_tfile_llink)) list_add(&amp;epi-&gt;ffd.file-&gt;f_tfile_llink, &amp;tfile_check_list); &#125; &#125; mutex_unlock(&amp;ep-&gt;mtx); return error; &#125; 唤醒风暴检测（reverse_path_check） 当文件状态发生改变时，会唤醒监听在其上的epoll文件，而这个epoll文件还可能唤醒其他的epoll文件，这种连续的唤醒就形成了一个唤醒路径，所有的唤醒路径就形成了一个有向图。如果文件对应的epoll唤醒有向图的节点过多，那么文件状态的改变就会唤醒所有的这些epoll(可能会唤醒很多进程，这样的开销是很大的)，而实际上一个文件经过少数epoll处理以后就可能从就绪转到未就绪，剩余的epoll虽然认为文件已就绪而实际上经过某些处理后已不可用。epoll的实现中考虑到了此问题，在每次添加新文件到epoll中时，就会首先检查是否会出现这样的唤醒风暴。 该函数的实现逻辑是这样的，递归调用reverse_path_check_proc遍历监听在当前文件上的epoll文件，在reverse_pach_check_proc中统计并检查不同路径深度上epoll的个数，从而避免产生唤醒风暴。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#define PATH_ARR_SIZE 5 // 在EPOLL_CTL_ADD 时, 检查是否有可能产生唤醒风暴 // epoll 允许的单个文件的唤醒深度小于5, 例如 // 一个文件最多允许唤醒1000个深度为1的epoll描述符, //允许所有被单个文件直接唤醒的epoll描述符再次唤醒的epoll描述符总数是500 // // 深度限制 static const int path_limits[PATH_ARR_SIZE] = &#123; 1000, 500, 100, 50, 10 &#125;; // 计算出来的深度 static int path_count[PATH_ARR_SIZE]; static int path_count_inc(int nests) &#123; /* Allow an arbitrary number of depth 1 paths */ if (nests == 0) &#123; return 0; &#125; if (++path_count[nests] &gt; path_limits[nests]) &#123; return -1; &#125; return 0; &#125; static void path_count_init(void) &#123; int i; for (i = 0; i &lt; PATH_ARR_SIZE; i++) &#123; path_count[i] = 0; &#125; &#125; // 唤醒风暴检查函数 static int reverse_path_check(void) &#123; int error = 0; struct file *current_file; /* let&apos;s call this for all tfiles */ // 遍历全局tfile_check_list 中的文件, 第一级 list_for_each_entry(current_file, &amp;tfile_check_list, f_tfile_llink) &#123; // 初始化 path_count_init(); // 限制递归的深度, 并检查每个深度上唤醒的epoll 数量 error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, reverse_path_check_proc, current_file, current_file, current); if (error) &#123; break; &#125; &#125; return error; &#125; static int reverse_path_check_proc(void *priv, void *cookie, int call_nests) &#123; int error = 0; struct file *file = priv; struct file *child_file; struct epitem *epi; list_for_each_entry(epi, &amp;file-&gt;f_ep_links, fllink) &#123; // 遍历监视file 的epoll child_file = epi-&gt;ep-&gt;file; if (is_file_epoll(child_file)) &#123; if (list_empty(&amp;child_file-&gt;f_ep_links)) &#123; // 没有其他的epoll监视当前的这个epoll, // 已经是叶子了 if (path_count_inc(call_nests)) &#123; error = -1; break; &#125; &#125; else &#123; // 遍历监视这个epoll 文件的epoll, // 递归调用 error = ep_call_nested(&amp;poll_loop_ncalls, EP_MAX_NESTS, reverse_path_check_proc, child_file, child_file, current); &#125; if (error != 0) &#123; break; &#125; &#125; else &#123; // 不是epoll , 不可能吧? printk(KERN_ERR &quot;reverse_path_check_proc: &quot; &quot;file is not an ep!\n&quot;); &#125; &#125; return error; &#125; epoll 的唤醒过程12345678910111213141516171819202122232425static void ep_poll_safewake(wait_queue_head_t *wq) &#123; int this_cpu = get_cpu(); ep_call_nested(&amp;poll_safewake_ncalls, EP_MAX_NESTS, ep_poll_wakeup_proc, NULL, wq, (void *) (long) this_cpu); put_cpu(); &#125; static int ep_poll_wakeup_proc(void *priv, void *cookie, int call_nests) &#123; ep_wake_up_nested((wait_queue_head_t *) cookie, POLLIN, 1 + call_nests); return 0; &#125; static inline void ep_wake_up_nested(wait_queue_head_t *wqueue, unsigned long events, int subclass) &#123; // 这回唤醒所有正在等待此epfd 的select/epoll/poll 等 // 如果唤醒的是epoll 就可能唤醒其他的epoll, 产生连锁反应 // 这个很可能在中断上下文中被调用 wake_up_poll(wqueue, events); &#125; epoll_ctl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114// long epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event) &#123; int error; int did_lock_epmutex = 0; struct file *file, *tfile; struct eventpoll *ep; struct epitem *epi; struct epoll_event epds; error = -EFAULT; if (ep_op_has_event(op) &amp;&amp; // 复制用户空间数据到内核 copy_from_user(&amp;epds, event, sizeof(struct epoll_event))) &#123; goto error_return; &#125; // 取得 epfd 对应的文件 error = -EBADF; file = fget(epfd); if (!file) &#123; goto error_return; &#125; // 取得目标文件 tfile = fget(fd); if (!tfile) &#123; goto error_fput; &#125; // 目标文件必须提供 poll 操作 error = -EPERM; if (!tfile-&gt;f_op || !tfile-&gt;f_op-&gt;poll) &#123; goto error_tgt_fput; &#125; // 添加自身或epfd 不是epoll 句柄 error = -EINVAL; if (file == tfile || !is_file_epoll(file)) &#123; goto error_tgt_fput; &#125; // 取得内部结构eventpoll ep = file-&gt;private_data; // EPOLL_CTL_MOD 不需要加全局锁 epmutex if (op == EPOLL_CTL_ADD || op == EPOLL_CTL_DEL) &#123; mutex_lock(&amp;epmutex); did_lock_epmutex = 1; &#125; if (op == EPOLL_CTL_ADD) &#123; if (is_file_epoll(tfile)) &#123; error = -ELOOP; // 目标文件也是epoll 检测是否有循环包含的问题 if (ep_loop_check(ep, tfile) != 0) &#123; goto error_tgt_fput; &#125; &#125; else &#123; // 将目标文件添加到 epoll 全局的tfile_check_list 中 list_add(&amp;tfile-&gt;f_tfile_llink, &amp;tfile_check_list); &#125; &#125; mutex_lock_nested(&amp;ep-&gt;mtx, 0); // 以tfile 和fd 为key 在rbtree 中查找文件对应的epitem epi = ep_find(ep, tfile, fd); error = -EINVAL; switch (op) &#123; case EPOLL_CTL_ADD: if (!epi) &#123; // 没找到, 添加额外添加ERR HUP 事件 epds.events |= POLLERR | POLLHUP; error = ep_insert(ep, &amp;epds, tfile, fd); &#125; else &#123; error = -EEXIST; &#125; // 清空文件检查列表 clear_tfile_check_list(); break; case EPOLL_CTL_DEL: if (epi) &#123; error = ep_remove(ep, epi); &#125; else &#123; error = -ENOENT; &#125; break; case EPOLL_CTL_MOD: if (epi) &#123; epds.events |= POLLERR | POLLHUP; error = ep_modify(ep, epi, &amp;epds); &#125; else &#123; error = -ENOENT; &#125; break; &#125; mutex_unlock(&amp;ep-&gt;mtx); error_tgt_fput: if (did_lock_epmutex) &#123; mutex_unlock(&amp;epmutex); &#125; fput(tfile); error_fput: fput(file); error_return: return error; &#125; EPOLL_CTL_ADD 实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129// EPOLL_CTL_ADD static int ep_insert(struct eventpoll *ep, struct epoll_event *event, struct file *tfile, int fd) &#123; int error, revents, pwake = 0; unsigned long flags; long user_watches; struct epitem *epi; struct ep_pqueue epq; /* struct ep_pqueue &#123; poll_table pt; struct epitem *epi; &#125;; */ // 增加监视文件数 user_watches = atomic_long_read(&amp;ep-&gt;user-&gt;epoll_watches); if (unlikely(user_watches &gt;= max_user_watches)) &#123; return -ENOSPC; &#125; // 分配初始化 epi if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL))) &#123; return -ENOMEM; &#125; INIT_LIST_HEAD(&amp;epi-&gt;rdllink); INIT_LIST_HEAD(&amp;epi-&gt;fllink); INIT_LIST_HEAD(&amp;epi-&gt;pwqlist); epi-&gt;ep = ep; // 初始化红黑树中的key ep_set_ffd(&amp;epi-&gt;ffd, tfile, fd); // 直接复制用户结构 epi-&gt;event = *event; epi-&gt;nwait = 0; epi-&gt;next = EP_UNACTIVE_PTR; // 初始化临时的 epq epq.epi = epi; init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc); // 设置事件掩码 epq.pt._key = event-&gt;events; // 内部会调用ep_ptable_queue_proc, 在文件对应的wait queue head 上 // 注册回调函数, 并返回当前文件的状态 revents = tfile-&gt;f_op-&gt;poll(tfile, &amp;epq.pt); // 检查错误 error = -ENOMEM; if (epi-&gt;nwait &lt; 0) &#123; // f_op-&gt;poll 过程出错 goto error_unregister; &#125; // 添加当前的epitem 到文件的f_ep_links 链表 spin_lock(&amp;tfile-&gt;f_lock); list_add_tail(&amp;epi-&gt;fllink, &amp;tfile-&gt;f_ep_links); spin_unlock(&amp;tfile-&gt;f_lock); // 插入epi 到rbtree ep_rbtree_insert(ep, epi); /* now check if we&apos;ve created too many backpaths */ error = -EINVAL; if (reverse_path_check()) &#123; goto error_remove_epi; &#125; spin_lock_irqsave(&amp;ep-&gt;lock, flags); /* 文件已经就绪插入到就绪链表rdllist */ if ((revents &amp; event-&gt;events) &amp;&amp; !ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); if (waitqueue_active(&amp;ep-&gt;wq)) // 通知sys_epoll_wait , 调用回调函数唤醒sys_epoll_wait 进程 &#123; wake_up_locked(&amp;ep-&gt;wq); &#125; // 先不通知调用eventpoll_poll 的进程 if (waitqueue_active(&amp;ep-&gt;poll_wait)) &#123; pwake++; &#125; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); atomic_long_inc(&amp;ep-&gt;user-&gt;epoll_watches); if (pwake) // 安全通知调用eventpoll_poll 的进程 &#123; ep_poll_safewake(&amp;ep-&gt;poll_wait); &#125; return 0; error_remove_epi: spin_lock(&amp;tfile-&gt;f_lock); // 删除文件上的 epi if (ep_is_linked(&amp;epi-&gt;fllink)) &#123; list_del_init(&amp;epi-&gt;fllink); &#125; spin_unlock(&amp;tfile-&gt;f_lock); // 从红黑树中删除 rb_erase(&amp;epi-&gt;rbn, &amp;ep-&gt;rbr); error_unregister: // 从文件的wait_queue 中删除, 释放epitem 关联的所有eppoll_entry ep_unregister_pollwait(ep, epi); /* * We need to do this because an event could have been arrived on some * allocated wait queue. Note that we don&apos;t care about the ep-&gt;ovflist * list, since that is used/cleaned only inside a section bound by &quot;mtx&quot;. * And ep_insert() is called with &quot;mtx&quot; held. */ // TODO: spin_lock_irqsave(&amp;ep-&gt;lock, flags); if (ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_del_init(&amp;epi-&gt;rdllink); &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 释放epi kmem_cache_free(epi_cache, epi); return error; &#125; EPOLL_CTL_DELEPOLL_CTL_DEL 的实现调用的是 ep_remove 函数，函数只是清除ADD时， 添加的各种结构，EPOLL_CTL_MOD 的实现调用的是ep_modify，在ep_modify中用新的事件掩码调用f_ops-&gt;poll，检测事件是否已可用，如果可用就直接唤醒epoll，这两个的实现与EPOLL_CTL_ADD 类似，代码上比较清晰，这里就不具体分析了。1234567891011121314151617181920212223242526272829303132333435static int ep_remove(struct eventpoll *ep, struct epitem *epi) &#123; unsigned long flags; struct file *file = epi-&gt;ffd.file; /* * Removes poll wait queue hooks. We _have_ to do this without holding * the &quot;ep-&gt;lock&quot; otherwise a deadlock might occur. This because of the * sequence of the lock acquisition. Here we do &quot;ep-&gt;lock&quot; then the wait * queue head lock when unregistering the wait queue. The wakeup callback * will run by holding the wait queue head lock and will call our callback * that will try to get &quot;ep-&gt;lock&quot;. */ ep_unregister_pollwait(ep, epi); /* Remove the current item from the list of epoll hooks */ spin_lock(&amp;file-&gt;f_lock); if (ep_is_linked(&amp;epi-&gt;fllink)) list_del_init(&amp;epi-&gt;fllink); spin_unlock(&amp;file-&gt;f_lock); rb_erase(&amp;epi-&gt;rbn, &amp;ep-&gt;rbr); spin_lock_irqsave(&amp;ep-&gt;lock, flags); if (ep_is_linked(&amp;epi-&gt;rdllink)) list_del_init(&amp;epi-&gt;rdllink); spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* At this point it is safe to free the eventpoll item */ kmem_cache_free(epi_cache, epi); atomic_long_dec(&amp;ep-&gt;user-&gt;epoll_watches); return 0; &#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * Modify the interest event mask by dropping an event if the new mask * has a match in the current file status. Must be called with &quot;mtx&quot; held. */ static int ep_modify(struct eventpoll *ep, struct epitem *epi, struct epoll_event *event) &#123; int pwake = 0; unsigned int revents; poll_table pt; init_poll_funcptr(&amp;pt, NULL); /* * Set the new event interest mask before calling f_op-&gt;poll(); * otherwise we might miss an event that happens between the * f_op-&gt;poll() call and the new event set registering. */ epi-&gt;event.events = event-&gt;events; pt._key = event-&gt;events; epi-&gt;event.data = event-&gt;data; /* protected by mtx */ /* * Get current event bits. We can safely use the file* here because * its usage count has been increased by the caller of this function. */ revents = epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, &amp;pt); /* * If the item is &quot;hot&quot; and it is not registered inside the ready * list, push it inside. */ if (revents &amp; event-&gt;events) &#123; spin_lock_irq(&amp;ep-&gt;lock); if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); /* Notify waiting tasks that events are available */ if (waitqueue_active(&amp;ep-&gt;wq)) wake_up_locked(&amp;ep-&gt;wq); if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; spin_unlock_irq(&amp;ep-&gt;lock); &#125; /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(&amp;ep-&gt;poll_wait); return 0; &#125; epoll_wait123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197/* epoll_wait实现 */ SYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout) &#123; int error; struct file *file; struct eventpoll *ep; // 检查输入数据有效性 if (maxevents &lt;= 0 || maxevents &gt; EP_MAX_EVENTS) &#123; return -EINVAL; &#125; if (!access_ok(VERIFY_WRITE, events, maxevents * sizeof(struct epoll_event))) &#123; error = -EFAULT; goto error_return; &#125; /* Get the &quot;struct file *&quot; for the eventpoll file */ error = -EBADF; file = fget(epfd); if (!file) &#123; goto error_return; &#125; error = -EINVAL; if (!is_file_epoll(file)) &#123; goto error_fput; &#125; // 取得ep 结构 ep = file-&gt;private_data; // 等待事件 error = ep_poll(ep, events, maxevents, timeout); error_fput: fput(file); error_return: return error; &#125; static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout) &#123; int res = 0, eavail, timed_out = 0; unsigned long flags; long slack = 0; wait_queue_t wait; ktime_t expires, *to = NULL; if (timeout &gt; 0) &#123; // 转换为内核时间 struct timespec end_time = ep_set_mstimeout(timeout); slack = select_estimate_accuracy(&amp;end_time); to = &amp;expires; *to = timespec_to_ktime(end_time); &#125; else if (timeout == 0) &#123; // 已经超时直接检查readylist timed_out = 1; spin_lock_irqsave(&amp;ep-&gt;lock, flags); goto check_events; &#125; fetch_events: spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 没有可用的事件，ready list 和ovflist 都为空 if (!ep_events_available(ep)) &#123; // 添加当前进程的唤醒函数 init_waitqueue_entry(&amp;wait, current); __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); for (;;) &#123; /* * We don&apos;t want to sleep if the ep_poll_callback() sends us * a wakeup in between. That&apos;s why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ set_current_state(TASK_INTERRUPTIBLE); if (ep_events_available(ep) || timed_out) &#123; break; &#125; if (signal_pending(current)) &#123; res = -EINTR; break; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 挂起当前进程，等待唤醒或超时 if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) &#123; timed_out = 1; &#125; spin_lock_irqsave(&amp;ep-&gt;lock, flags); &#125; __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); set_current_state(TASK_RUNNING); &#125; check_events: // 再次检查是否有可用事件 eavail = ep_events_available(ep); spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* * Try to transfer events to user space. In case we get 0 events and * there&apos;s still timeout left over, we go trying again in search of * more luck. */ if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) // 复制事件到用户空间 &amp;&amp; !timed_out) // 复制事件失败并且没有超时，重新等待。 &#123; goto fetch_events; &#125; return res; &#125; static inline int ep_events_available(struct eventpoll *ep) &#123; return !list_empty(&amp;ep-&gt;rdllist) || ep-&gt;ovflist != EP_UNACTIVE_PTR; &#125; struct ep_send_events_data &#123; int maxevents; struct epoll_event __user *events; &#125;; static int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents) &#123; struct ep_send_events_data esed; esed.maxevents = maxevents; esed.events = events; return ep_scan_ready_list(ep, ep_send_events_proc, &amp;esed, 0); &#125; static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) &#123; struct ep_send_events_data *esed = priv; int eventcnt; unsigned int revents; struct epitem *epi; struct epoll_event __user *uevent; // 遍历已就绪链表 for (eventcnt = 0, uevent = esed-&gt;events; !list_empty(head) &amp;&amp; eventcnt &lt; esed-&gt;maxevents;) &#123; epi = list_first_entry(head, struct epitem, rdllink); list_del_init(&amp;epi-&gt;rdllink); // 获取ready 事件掩码 revents = epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, NULL) &amp; epi-&gt;event.events; /* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding &quot;mtx&quot;, so no operations coming from userspace * can change the item. */ if (revents) &#123; // 事件就绪, 复制到用户空间 if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123; list_add(&amp;epi-&gt;rdllink, head); return eventcnt ? eventcnt : -EFAULT; &#125; eventcnt++; uevent++; if (epi-&gt;event.events &amp; EPOLLONESHOT) &#123; epi-&gt;event.events &amp;= EP_PRIVATE_BITS; &#125; else if (!(epi-&gt;event.events &amp; EPOLLET)) &#123; // 不是边缘模式, 再次添加到ready list, // 下次epoll_wait 时直接进入此函数检查ready list是否仍然继续 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); &#125; // 如果是边缘模式, 只有当文件状态发生改变时, // 才文件会再次触发wait_address 上wait_queue的回调函数, &#125; &#125; return eventcnt; &#125; eventpoll_poll 由于epoll自身也是文件系统，其描述符也可以被poll/select/epoll监视，因此需要实现poll方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119static const struct file_operations eventpoll_fops = &#123; .release = ep_eventpoll_release, .poll = ep_eventpoll_poll, .llseek = noop_llseek, &#125;; static unsigned int ep_eventpoll_poll(struct file *file, poll_table *wait) &#123; int pollflags; struct eventpoll *ep = file-&gt;private_data; // 插入到wait_queue poll_wait(file, &amp;ep-&gt;poll_wait, wait); // 扫描就绪的文件列表, 调用每个文件上的poll 检测是否真的就绪, // 然后复制到用户空间 // 文件列表中有可能有epoll文件, 调用poll的时候有可能会产生递归, // 调用所以用ep_call_nested 包装一下, 防止死循环和过深的调用 pollflags = ep_call_nested(&amp;poll_readywalk_ncalls, EP_MAX_NESTS, ep_poll_readyevents_proc, ep, ep, current); // static struct nested_calls poll_readywalk_ncalls; return pollflags != -1 ? pollflags : 0; &#125; static int ep_poll_readyevents_proc(void *priv, void *cookie, int call_nests) &#123; return ep_scan_ready_list(priv, ep_read_events_proc, NULL, call_nests + 1); &#125; static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv, int depth) &#123; int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); /* * We need to lock this because we could be hit by * eventpoll_release_file() and epoll_ctl(). */ mutex_lock_nested(&amp;ep-&gt;mtx, depth); spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 移动rdllist 到新的链表txlist list_splice_init(&amp;ep-&gt;rdllist, &amp;txlist); // 改变ovflist 的状态, 如果ep-&gt;ovflist != EP_UNACTIVE_PTR, // 当文件激活wait_queue时，就会将对应的epitem加入到ep-&gt;ovflist // 否则将文件直接加入到ep-&gt;rdllist， // 这样做的目的是避免丢失事件 // 这里不需要检查ep-&gt;ovflist 的状态，因为ep-&gt;mtx的存在保证此处的ep-&gt;ovflist // 一定是EP_UNACTIVE_PTR ep-&gt;ovflist = NULL; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); // 调用扫描函数处理txlist error = (*sproc)(ep, &amp;txlist, priv); spin_lock_irqsave(&amp;ep-&gt;lock, flags); // 调用 sproc 时可能有新的事件，遍历这些新的事件将其插入到ready list for (nepi = ep-&gt;ovflist; (epi = nepi) != NULL; nepi = epi-&gt;next, epi-&gt;next = EP_UNACTIVE_PTR) &#123; // #define EP_UNACTIVE_PTR (void *) -1 // epi 不在rdllist, 插入 if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); &#125; &#125; // 还原ep-&gt;ovflist的状态 ep-&gt;ovflist = EP_UNACTIVE_PTR; // 将处理后的 txlist 链接到 rdllist list_splice(&amp;txlist, &amp;ep-&gt;rdllist); if (!list_empty(&amp;ep-&gt;rdllist)) &#123; // 唤醒epoll_wait if (waitqueue_active(&amp;ep-&gt;wq)) &#123; wake_up_locked(&amp;ep-&gt;wq); &#125; // 当前的ep有其他的事件通知机制监控 if (waitqueue_active(&amp;ep-&gt;poll_wait)) &#123; pwake++; &#125; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); mutex_unlock(&amp;ep-&gt;mtx); if (pwake) &#123; // 安全唤醒外部的事件通知机制 ep_poll_safewake(&amp;ep-&gt;poll_wait); &#125; return error; &#125; static int ep_read_events_proc(struct eventpoll *ep, struct list_head *head, void *priv) &#123; struct epitem *epi, *tmp; poll_table pt; init_poll_funcptr(&amp;pt, NULL); list_for_each_entry_safe(epi, tmp, head, rdllink) &#123; pt._key = epi-&gt;event.events; if (epi-&gt;ffd.file-&gt;f_op-&gt;poll(epi-&gt;ffd.file, &amp;pt) &amp; epi-&gt;event.events) &#123; return POLLIN | POLLRDNORM; &#125; else &#123; // 这个事件虽然在就绪列表中, // 但是实际上并没有就绪, 将他移除 // 这有可能是水平触发模式中没有将文件从就绪列表中移除 // 也可能是事件插入到就绪列表后有其他的线程对文件进行了操作 list_del_init(&amp;epi-&gt;rdllink); &#125; &#125; return 0; &#125; epoll全景以下是epoll使用的全部数据结构之间的关系图，采用的是一种类UML图，希望对理解epoll的内部实现有所帮助。 poll/select/epoll 对比通过以上的分析可以看出，poll和select的实现基本是一致，只是用户到内核传递的数据格式有所不同， select和poll即使只有一个描述符就绪，也要遍历整个集合。如果集合中活跃的描述符很少，遍历过程的开销就会变得很大，而如果集合中大部分的描述符都是活跃的，遍历过程的开销又可以忽略。 epoll的实现中每次只遍历活跃的描述符(如果是水平触发，也会遍历先前活跃的描述符)，在活跃描述符较少的情况下就会很有优势，在代码的分析过程中可以看到epoll的实现过于复杂并且其实现过程中需要同步处理(锁)，如果大部分描述符都是活跃的，epoll的效率可能不如select或poll。(参见epoll 和poll的性能测试 http://jacquesmattheij.com/Poll+vs+Epoll+once+again) select能够处理的最大fd无法超出FDSETSIZE。 select会复写传入的fd_set 指针，而poll对每个fd返回一个掩码，不更改原来的掩码，从而可以对同一个集合多次调用poll，而无需调整。 select对每个文件描述符最多使用3个bit，而poll采用的pollfd需要使用64个bit，epoll采用的 epoll_event则需要96个bit 如果事件需要循环处理select, poll 每一次的处理都要将全部的数据复制到内核，而epoll的实现中，内核将持久维护加入的描述符，减少了内核和用户复制数据的开销。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[select、poll、epoll之间的区别总结[整理]]]></title>
    <url>%2F2019%2F04%2F12%2Fselect_poll_epoll%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E6%80%BB%E7%BB%93%5B%E6%95%B4%E7%90%86%5D%2F</url>
    <content type="text"><![CDATA[原文：http://www.cnblogs.com/Anker/p/3265058.html select、poll、epoll之间的区别总结[整理] select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。 select实现select的调用过程如下所示： （1）使用copy_from_user从用户空间拷贝fd_set到内核空间 （2）注册回调函数__pollwait （3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） （4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 （5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 （6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 （7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 （8）把fd_set从内核空间拷贝到用户空间。 总结： select的几大缺点： （1）每次调用select，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大 （2）同时每次调用select都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大 （3）select支持的文件描述符数量太小了，默认是1024 poll实现 poll的实现和select非常相似，只是描述fd集合的方式不同，poll使用pollfd结构而不是select的fd_set结构，其他的都差不多。 epollepoll既然是对select和poll的改进，就应该能避免上述的三个缺点。那epoll都是怎么解决的呢？在此之前，我们先看一下epoll和select和poll的调用接口上的不同，select和poll都只提供了一个函数——select或者poll函数。而epoll提供了三个函数，epoll_create,epoll_ctl和epoll_wait，epoll_create是创建一个epoll句柄；epoll_ctl是注册要监听的事件类型；epoll_wait则是等待事件的产生。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。 总结： （1）select，poll实现需要自己不断轮询所有fd集合，直到设备就绪，期间可能要睡眠和唤醒多次交替。而epoll其实也需要调用epoll_wait不断轮询就绪链表，期间也可能多次睡眠和唤醒交替，但是它是设备就绪时，调用回调函数，把就绪fd放入就绪链表中，并唤醒在epoll_wait中进入睡眠的进程。虽然都要睡眠和交替，但是select和poll在“醒着”的时候要遍历整个fd集合，而epoll在“醒着”的时候只要判断一下就绪链表是否为空就行了，这节省了大量的CPU时间。这就是回调机制带来的性能提升。 （2）select，poll每次调用都要把fd集合从用户态往内核态拷贝一次，并且要把current往设备等待队列中挂一次，而epoll只要一次拷贝，而且把current往等待队列上挂也只挂一次（在epoll_wait的开始，注意这里的等待队列并不是设备等待队列，只是一个epoll内部定义的等待队列）。这也能节省不少的开销。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[qsub教程]]></title>
    <url>%2F2019%2F04%2F12%2Fqsub%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[PBS作业管理，即以qsub、qstat、qdel命令为核心的集群作业管理系统，且它是开源的。 在此环境下运行，用户不需要指定程序在哪些节点上运行，程序所需的硬件资源由PBS管理和分配。 qsub、qstat、qdel的功能分别为“提交作业”、“查看作业状态”、“删除作业”。 非PBS下mpi计算通常来说，使用mpirun即可，例如mpirun -np 16 ./pom.kii2b.exe &lt; /dev/null &gt; pom.log，意为在一个节点上使用16核执行pom.kii2b.exe，stdin重定向至空，stdout重定向至pom.log。 之后可能会再执行几个mv命令之类的，例如把pom.log文件移动至别处，防止多次调用时覆盖log。 PBS作业提交直接执行qsub会提示输入PBS作业脚本，这样很不方便，因此通常来说都是把qsub脚本写到文件里，重定向输入来进行作业提交，例如qsub &lt; cess.sbpom.qsub（其实不加&lt;也可以），提交一个写在cess.sbpom.qsub文件里的PBS脚本。 PBS脚本形如下面那段代码从#!/bin/sh到mv pom.log ../$TIME.pom.log的部分。 由于存在需要多次提交相似作业的可能，例如我有20个文件夹的数据，每个文件夹里数据的处理方式相同，调用同一个程序，总不能写20个PBS脚本。因此更为通常的做法是，使用shell脚本进行qsub脚本输出再提交，举例如下：123456789101112131415161718192021 PNAME=fz_letkf NODE=1 NP=16 QSUBTIME=&quot;24:00:00&quot; NOWDIR=`pwd` QSUB=cess.letkf.qsub LETKF=letkf020.m01cat &lt;&lt;EOF &gt;$QSUB#!/bin/sh#PBS -q hpca #PBS -V #PBS -N $PNAME#PBS -l nodes=$NODE:ppn=$NP#PBS -l walltime=&quot;$QSUBTIME&quot;#PBS -o /home/xfh_stu/WORK3/qsublog#PBS -j oe cd $NOWDIRmpirun ./$LETKF &lt; /dev/nullmv pom.log ../$TIME.pom.logEOF qsub $QSUB &gt;cessrunid 调用此脚本就会自动将PBS脚本输出至$QSUB文件中，并提交此作业。通常在这段代码外面会套上循环，每次修改相应变量，从而实现一次提交多个相似作业。 在这里cat命令使用了一种叫做heredoc的写法，用于输出大段文字，同时还要替换其中的变量。界定符EOF是可以自定义的，不过通常来说都使用EOF。另外，用于结束的界定符必须顶格写（想不顶格也是可以的，但是有其他限制，且不方便）。 命令格式：123456qsub [-a date_time] [-c interval] [-C directive_prefix][-e path] [-I] [-j join] [-k keep] [-l resource_list] [-m mail_options][-M user_list][-N name] [-o path] [-p priority] [-q destination] [-r c][-S path_list] [-u user_list][-v variable_list] [-V][-W additional_attributes] [-z][script] 下面解释一下参数的意思。 -q：指定使用的队列。可使用qstat -q查看队列信息，包括队列名、资源限制、正在运行的任务数等。 -V：将执行qsub命令时拥有的环境变量都export该作业。 -N：指定作业名。 -l：指定作业使用的节点数与核数、时间限制等。 -o：重定向此作业的stdout至指定的文件夹中，名为作业名.o作业ID。 -j oe：合并此作业的stdout与stderr。 qsub成功提交作业后，会在stdout输出Job ID，形如作业ID.主机名，例如15252.manager。在上面的例子中，我将qsub的结果重定向至cessrunid文件中，用于存储作业ID，以便后续处理。 查看作业状态执行qstat即可查看当前正在执行的作业以及刚刚完成的作业。在S那一列，C表示已完成，R表示正在执行，Q表示正在等待，还有一些其他不常见的状态，可以man qstat并以job state为关键词查询即可。 命令格式：qatat [-f][-a][-i] [-n][-s] [-R] [-Q][-q][-B][-u]参数说明：-f jobid 列出指定作业的信息-a 列出系统所有作业-i 列出不在运行的作业-n 列出分配给此作业的结点-s 列出队列管理员与scheduler所提供的建议-R 列出磁盘预留信息-Q 操作符是destination id，指明请求的是队列状态-q 列出队列状态，并以alternative形式显示-au userid 列出指定用户的所有作业-B 列出PBS Server信息-r 列出所有正在运行的作业-Qf queue 列出指定队列的信息-u 若操作符为作业号，则列出其状态。若操作符为destination id，则列出运行在其上的属于user_list中用户的作业状态。 现在还有个问题，即如何在脚本中判断作业完成与否呢？一个很实际的例子是，我在脚本中一次提交完多个作业后，后续的脚本必须在完成这些作业后才能继续执行，那么就需要知道这些作业有没有完成。 通常有两种思路： 一是查看程序本应输出的文件有没有正常输出，即判断输出文件是否存在。或者在程序中写一些日志输出语句，脚本就可以通过查找日志文件某关键的一句话有没有输出从而知道程序运行有没有正常完成。 二是查看上文中通过-o参数指定的作业stdout输出文件，文件名为作业名.o作业ID。这也就是为什么我要把qsub提交信息保存到cessrunid这个文件里。通常来说，只要作业正常完成了，就会生成此文件。 对于第一种思路，就要根据程序具体情况来编写了。 对于第二种思路，一个典型的判断脚本如下：12345678910111213while :do temp=`cat cessrunid` runid=$&#123;PNAME&#125;.o$&#123;temp%.manager&#125; runfilename=&apos;/home/xfh_stu/WORK3/qsublog/&apos;$runid if [ -f &quot;$runfilename&quot; ]; then break fi sleep 60done 大意为： 提取出cessrunid这个文件里的qsub提交信息，并去掉后面的.manager主机名（CESS集群主机名为manager），之后改写成作业名.o作业ID的形式，并加上路径，判断该文件是否存在。 如果文件存在，则说明作业已完成，即可break掉这个无限循环，继续后面的操作了。 这里需要注意的一个地方就是，在无限循环里的每次判断中间要加上一个sleep语句，比如我设置的是每分钟跑一次循环，这样机器就不会由于每时每刻都在执行判断而耗尽资源。 删除作业执行qdel -W 15 15303即可在15秒后停止并删除Job ID为15303的作业。 管理作业qmgr 命令—用于队列管理qmgr -c “create queue batch queue_type=execution”qmgr -c “set queue batch started=true”qmgr -c “set queue batch enabled=true”qmgr -c “set queue batch resources_default.nodes=1″qmgr -c “set queue batch resources_default.walltime=3600″qmgr -c “set server default_queue=batch” 脚本的正确使用方法通常来说，我们都是在shell脚本中进行qsub脚本输出再提交该qsub脚本。 这里存在一个问题，即shell脚本自身需要后台执行。如果执行前台执行脚本，就会导致断开SSH连接后，脚本就会停止执行。 因此，需要使用nohup ./your.script.name.sh &amp;命令，它可以脚本在后台执行且将stdout重定向至nohup.out文件中。要注意命令最后的&amp;是不可缺少的，如果不写，脚本虽然也会在后台执行，但是在关闭SSH后就会停止。 另外，在执行完这个命令之后要按一下回车，使其回到shell上来。 当我们解决脚本后台执行的问题后，又出现了新问题，即如何停止该脚本？ 通过脚本提交的PBS作业可以通过qdel命令结束掉，而脚本本身停止就需要kill掉该脚本的进程了。 首先，我们使用ps -ef | grep your.script.name.sh查询到脚本的进程PID，之后执行kill xxxxx即可停止PID为xxxxx的进程了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux IO模式及 select、poll、epoll详解]]></title>
    <url>%2F2019%2F04%2F12%2FLinux_IO%E6%A8%A1%E5%8F%8Aselect_poll_epoll%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://segmentfault.com/a/1190000003063859?utm_source=tag-newest 本文讨论的背景是Linux环境下的network IO。 概念说明在进行解释之前，首先要说明几个概念： 用户空间和内核空间 进程切换 进程的阻塞 文件描述符 缓存 I/O 用户空间与内核空间现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操作系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核（kernel），保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。 进程切换为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行。这种行为被称为进程切换。因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。 从一个进程的运行转到另一个进程上运行，这个过程中经过下面这些变化： 保存处理机上下文，包括程序计数器和其他寄存器。 更新PCB信息。 把进程的PCB移入相应的队列，如就绪、在某事件阻塞等队列。 选择另一个进程执行，并更新其PCB。 更新内存管理的数据结构。 恢复处理机上下文。 注：总而言之就是很耗资源，具体的可以参考这篇文章：进程切换 进程的阻塞正在执行的进程，由于期待的某些事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新工作做等，则由系统自动执行阻塞原语(Block)，使自己由运行状态变为阻塞状态。可见，进程的阻塞是进程自身的一种主动行为，也因此只有处于运行态的进程（获得CPU），才可能将其转为阻塞状态。当进程进入阻塞状态，是不占用CPU资源的。 文件描述符fd文件描述符（File descriptor）是计算机科学中的一个术语，是一个用于表述指向文件的引用的抽象化概念。 文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。 缓存 I/O缓存 I/O 又被称作标准 I/O，大多数文件系统的默认 I/O 操作都是缓存 I/O。在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。 缓存 I/O 的缺点：数据在传输过程中需要在应用程序地址空间和内核进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。 IO模式刚才说了，对于一次IO访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。所以说，当一个read操作发生时，它会经历两个阶段： 等待数据准备 (Waiting for the data to be ready) 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process) 正式因为这两个阶段，linux系统产生了下面五种网络模式的方案。 阻塞 I/O（blocking IO） 非阻塞 I/O（nonblocking IO） I/O 多路复用（ IO multiplexing） 信号驱动 I/O（ signal driven IO） 异步 I/O（asynchronous IO） 注：由于signal driven IO在实际中并不常用，所以我这只提及剩下的四种IO Model。 阻塞 I/O（blocking IO）在linux中，默认情况下所有的socket都是blocking，一个典型的读操作流程大概是这样： 当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。 所以，blocking IO的特点就是在IO执行的两个阶段都被block了。 非阻塞 I/O（nonblocking IO）linux下，可以通过设置socket使其变为non-blocking。当对一个non-blocking socket执行读操作时，流程是这个样子： 当用户进程发出read操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。 所以，nonblocking IO的特点是用户进程需要不断的主动询问kernel数据好了没有。 I/O 多路复用（ IO multiplexing）IO multiplexing就是我们说的select，poll，epoll，有些地方也称这种IO方式为event driven IO。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 这个图和blocking IO的图其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 异步 I/O（asynchronous IO）Linux下的asynchronous IO其实用得很少。先看一下它的流程： 用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 总结blocking和non-blocking的区别调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO在kernel还准备数据的情况下会立刻返回。 synchronous IO和asynchronous IO的区别在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。POSIX的定义是这样子的： A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes; An asynchronous I/O operation does not cause the requesting process to be blocked; 两者的区别就在于synchronous IO做”IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。 有人会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的”IO operation”是指真实的IO操作，就是例子中的recvfrom这个system call。non-blocking IO在执行recvfrom这个system call的时候，如果kernel的数据没有准备好，这时候不会block进程。但是，当kernel中数据准备好的时候，recvfrom会将数据从kernel拷贝到用户内存中，这个时候进程是被block了，在这段时间内，进程是被block的。 而asynchronous IO则不一样，当进程发起IO 操作之后，就直接返回再也不理睬了，直到kernel发送一个信号，告诉进程说IO完成。在这整个过程中，进程完全没有被block。 各个IO Model的比较如图所示： 通过上面的图片，可以发现non-blocking IO和asynchronous IO的区别还是很明显的。在non-blocking IO中，虽然进程大部分时间都不会被block，但是它仍然要求进程去主动的check，并且当数据准备完成以后，也需要进程主动的再次调用recvfrom来将数据拷贝到用户内存。而asynchronous IO则完全不同。它就像是用户进程将整个IO操作交给了他人（kernel）完成，然后他人做完后发信号通知。在此期间，用户进程不需要去检查IO操作的状态，也不需要主动的去拷贝数据。 I/O 多路复用之select、poll、epoll详解select，poll，epoll都是IO多路复用的机制。I/O多路复用就是通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。但select，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。（这里啰嗦下） select1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 poll1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 epollepoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll操作过程epoll操作过程需要三个接口，分别如下：123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： 1234struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;; //events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 工作模式epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 总结假如有这样一个例子： 我们已经把一个用来从管道中读取数据的文件句柄(RFD)添加到epoll描述符 这个时候从管道的另一端被写入了2KB的数据 调用epoll_wait(2)，并且它会返回RFD，说明它已经准备好读取操作 然后我们读取了1KB的数据 调用epoll_wait(2)…… LT模式：如果是LT模式，那么在第5步调用epoll_wait(2)之后，仍然能受到通知。 ET模式：如果我们在第1步将RFD添加到epoll描述符的时候使用了EPOLLET标志，那么在第5步调用epoll_wait(2)之后将有可能会挂起，因为剩余的数据还存在于文件的输入缓冲区内，而且数据发出端还在等待一个针对已经发出数据的反馈信息。只有在监视的文件句柄上发生了某个事件的时候 ET 工作模式才会汇报事件。因此在第5步的时候，调用者可能会放弃等待仍在存在于文件输入缓冲区内的剩余数据。 当使用epoll的ET模型来工作时，当产生了一个EPOLLIN事件后，读数据的时候需要考虑的是当recv()返回的大小如果等于请求的大小，那么很有可能是缓冲区还有数据未读完，也意味着该次事件还没有处理完，所以还需要再次读取：1234567891011121314151617181920212223while(rs)&#123; buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0); if(buflen &lt; 0)&#123; // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读 // 在这里就当作是该次事件已处理处. if(errno == EAGAIN)&#123; break; &#125; else&#123; return; &#125; &#125; else if(buflen == 0)&#123; // 这里表示对端的socket已正常关闭. &#125; if(buflen == sizeof(buf)&#123; rs = 1; // 需要再次读取 &#125; else&#123; rs = 0; &#125;&#125; Linux中的EAGAIN含义 Linux环境下开发经常会碰到很多错误(设置errno)，其中EAGAIN是其中比较常见的一个错误(比如用在非阻塞操作中)。从字面上来看，是提示再试一次。这个错误经常出现在当应用程序进行一些非阻塞(non-blocking)操作(对文件或socket)的时候。 例如，以 O_NONBLOCK的标志打开文件/socket/FIFO，如果你连续做read操作而没有数据可读。此时程序不会阻塞起来等待数据准备就绪返回，read函数会返回一个错误EAGAIN，提示你的应用程序现在没有数据可读请稍后再试。又例如，当一个系统调用(比如fork)因为没有足够的资源(比如虚拟内存)而执行失败，返回EAGAIN提示其再调用一次(也许下次就能成功)。 代码演示下面是一段不完整的代码且格式不对，意在表述上面的过程，去掉了一些模板代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116#define IPADDRESS &quot;127.0.0.1&quot;#define PORT 8787#define MAXSIZE 1024#define LISTENQ 5#define FDSIZE 1000#define EPOLLEVENTS 100listenfd = socket_bind(IPADDRESS,PORT);struct epoll_event events[EPOLLEVENTS];//创建一个描述符epollfd = epoll_create(FDSIZE);//添加监听描述符事件add_event(epollfd,listenfd,EPOLLIN);//循环等待for ( ; ; )&#123; //该函数返回已经准备好的描述符事件数目 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); //处理接收到的连接 handle_events(epollfd,events,ret,listenfd,buf);&#125;//事件处理函数static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf)&#123; int i; int fd; //进行遍历;这里只要遍历已经准备好的io事件。num并不是当初epoll_create时的FDSIZE。 for (i = 0;i &lt; num;i++) &#123; fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) &amp;&amp;(events[i].events &amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events &amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events &amp; EPOLLOUT) do_write(epollfd,fd,buf); &#125;&#125;//添加事件static void add_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,&amp;ev);&#125;//处理接收到的连接static void handle_accpet(int epollfd,int listenfd)&#123; int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)&amp;cliaddr,&amp;cliaddrlen); if (clifd == -1) perror(&quot;accpet error:&quot;); else &#123; printf(&quot;accept a new client: %s:%d\n&quot;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); &#125; &#125;//读处理static void do_read(int epollfd,int fd,char *buf)&#123; int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) &#123; perror(&quot;read error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else if (nread == 0) &#123; fprintf(stderr,&quot;client close.\n&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLIN); //删除监听 &#125; else &#123; printf(&quot;read message is : %s&quot;,buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); &#125; &#125;//写处理static void do_write(int epollfd,int fd,char *buf) &#123; int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1)&#123; perror(&quot;write error:&quot;); close(fd); //记住close fd delete_event(epollfd,fd,EPOLLOUT); //删除监听 &#125;else&#123; modify_event(epollfd,fd,EPOLLIN); &#125; memset(buf,0,MAXSIZE); &#125;//删除事件static void delete_event(int epollfd,int fd,int state) &#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,&amp;ev);&#125;//修改事件static void modify_event(int epollfd,int fd,int state)&#123; struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,&amp;ev);&#125; epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面： 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode977. Squares of a Sorted Array]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode977%2F</url>
    <content type="text"><![CDATA[Squares of a Sorted Array Given an array of integers A sorted in non-decreasing order, return an array of the squares of each number, also in sorted non-decreasing order. Example 1:12Input: [-4,-1,0,3,10]Output: [0,1,9,16,100] Example 2:12Input: [-7,-3,2,3,11]Output: [4,9,9,49,121] Note: 1 &lt;= A.length &lt;= 10000-10000 &lt;= A[i] &lt;= 10000A is sorted in non-decreasing order. 给一个vector，有正有负，输出排序之后的平方数组。123456789101112class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; res(A.size()); int l = 0,r = A.size()-1, p = A.size() - 1; while(l&lt;=r)&#123; res[p--]=pow(A[abs(A[l])&gt;abs(A[r])?l++:r--],2); &#125; return res; &#125;&#125;; 另一种方法：1234567891011121314151617181920class Solution &#123;public: vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; A) &#123; vector&lt;int&gt; res(A.size()); int i=0,j=0,k=0; while(i&lt;A.size() &amp;&amp; A[i]&lt;0) i++; j=i-1; while(j&gt;=0 &amp;&amp; i&lt;A.size())&#123; res[k++] = pow(A[abs(A[i])&lt;abs(A[j])?i++:j--],2); &#125; while(j&gt;=0) res[k++]=pow(A[j--],2); while(i&lt;A.size()) res[k++]=pow(A[i++],2); return res; &#125;&#125;;]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的nohup命令的用法]]></title>
    <url>%2F2019%2F04%2F12%2FLinux%E7%9A%84nohup%E5%91%BD%E4%BB%A4%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在应用Unix/Linux时，我们一般想让某个程序在后台运行，于是我们将常会用 &amp; 在程序结尾来让程序自动运行。比如我们要运行mysql在后台： /usr/local/mysql/bin/mysqld_safe –user=mysql &amp;。可是有很多程序并不想mysqld一样，这样我们就需要nohup命令，怎样使用nohup命令呢？这里讲解nohup命令的一些用法。 nohup /root/start.sh &amp; 在shell中回车后提示： [~]$ appending output to nohup.out 原程序的的标准输出被自动改向到当前目录下的nohup.out文件，起到了log的作用。 但是有时候在这一步会有问题，当把终端关闭后，进程会自动被关闭，察看nohup.out可以看到在关闭终端瞬间服务自动关闭。 咨询红旗Linux工程师后，他也不得其解，在我的终端上执行后，他启动的进程竟然在关闭终端后依然运行。 在第二遍给我演示时，我才发现我和他操作终端时的一个细节不同：他是在当shell中提示了nohup成功后还需要按终端上键盘任意键退回到shell输入命令窗口，然后通过在shell中输入exit来退出终端；而我是每次在nohup执行成功后直接点关闭程序按钮关闭终端.。所以这时候会断掉该命令所对应的session，导致nohup对应的进程被通知需要一起shutdown。 这个细节有人和我一样没注意到，所以在这儿记录一下了。 附：nohup命令参考 nohup 命令 用途：不挂断地运行命令。 语法：nohup Command [ Arg … ] [ &amp; ] 描述：nohup 命令运行由 Command 参数和任何相关的 Arg 参数指定的命令，忽略所有挂断（SIGHUP）信号。在注销后使用 nohup 命令运行后台中的程序。要运行后台中的 nohup 命令，添加 &amp; （ 表示”and”的符号）到命令的尾部。 无论是否将 nohup 命令的输出重定向到终端，输出都将附加到当前目录的 nohup.out 文件中。如果当前目录的 nohup.out 文件不可写，输出重定向到 $HOME/nohup.out 文件中。如果没有文件能创建或打开以用于追加，那么 Command 参数指定的命令不可调用。如果标准错误是一个终端，那么把指定的命令写给标准错误的所有输出作为标准输出重定向到相同的文件描述符。 退出状态：该命令返回下列出口值： 126 可以查找但不能调用 Command 参数指定的命令。 127 nohup 命令发生错误或不能查找由 Command 参数指定的命令。 否则，nohup 命令的退出状态是 Command 参数指定命令的退出状态。 nohup命令及其输出文件 nohup命令：如果你正在运行一个进程，而且你觉得在退出帐户时该进程还不会结束，那么可以使用nohup命令。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。nohup就是不挂起的意思( n ohang up)。 该命令的一般形式为：nohup command &amp; 使用nohup命令提交作业 如果使用nohup命令提交作业，那么在缺省情况下该作业的所有输出都被重定向到一个名为nohup.out的文件中，除非另外指定了输出文件： nohup command &gt; myout.file 2&gt;&amp;1 &amp; 在上面的例子中，输出被重定向到myout.file文件中。 使用 jobs 查看任务。 使用 fg %n 关闭。 另外有两个常用的ftp工具ncftpget和ncftpput，可以实现后台的ftp上传和下载，这样就可以利用这些命令在后台上传和下载文件了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c-cpp中mem函数的类型及用法]]></title>
    <url>%2F2019%2F04%2F12%2Fc-cpp%E4%B8%ADmem%E5%87%BD%E6%95%B0%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%8F%8A%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[函数名称: memccpy函数原型: void memccpy(void dest, const void *src, int c, size_t n)函数功能: 字符串拷贝，到指定长度或遇到指定字符时停止拷贝函数返回:参数说明: src-源字符串指针，c-中止拷贝检查字符，n-长度,dest-拷贝底目的字符串指针所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314151617#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char *src= &quot;This is the source string &quot;; char dest[50]; char *ptr; ptr=memccpy(dest,src, &apos;c &apos;,strlen(src)); if (ptr) &#123; *ptr= &apos;\0 &apos;; printf( &quot;The character was found:%s &quot;,dest); &#125; else printf( &quot;The character wasn &apos;t found &quot;); return 0; &#125; @函数名称: memchr函数原型: void memchr(const void s, int c, size_t n)函数功能: 在字符串中第开始n个字符中寻找某个字符c的位置函数返回: 返回c的位置指针，返回NULL时表示未找到参数说明: s-要搜索的字符串，c-要寻找的字符，n-指定长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char str[17]; char *ptr; strcpy(str, &quot;This is a string &quot;); ptr=memchr(str, &apos;r &apos;,strlen(str)); if(ptr) printf( &quot;The character &apos;r &apos; is at position:%d &quot;,ptr-str); else printf( &quot;The character was not found &quot;); return 0; &#125; @函数名称: memcmp函数原型: int memcmp(const void s1, const void s2, size_t n)函数功能: 按字典顺序对字符串s1,s2比较，并只比较前n个字符函数返回: 返回数值表示比较结果参数说明: s1,s2-要比较的字符串，n-比较的长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; auto char buffer[80]; strcpy(buffer, &quot;world &quot;); if( memcmp(buffer, &quot;would &quot;,6)&lt;0)&#123; printf( &quot;Less than\n &quot;); &#125; return 0; &#125; @函数名称: memicmp函数原型: int memicmp(const void s1, const void s2, size_t n)函数功能: 按字典顺序、不考虑字母大小写对字符串s1,s2比较，并只比较前n个字符函数返回: 返回数值表示比较结果参数说明: s1,s2-要比较的字符串，n-比较的长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011121314#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; char *buf1 = &quot;ABCDE123 &quot;; char *buf2 = &quot;abcde456 &quot;; int stat; stat = memicmp(buf1, buf2, 5); printf( &quot;The strings to position 5 are &quot;); if(stat) printf( &quot;not &quot;); printf( &quot;the same &quot;); return 0; &#125; @函数名称: memcpy函数原型: void memcpy(void dest, const void *src, size_t n)函数功能: 字符串拷贝函数返回: 指向dest的指针参数说明: src-源字符串，n-拷贝的最大长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;123456789101112131415#include &lt;stdio.h&gt;; #include &lt;string.h&gt;; int main() &#123; char src[] = &quot;****************************** &quot;; char dest[] = &quot;abcdefghijlkmnopqrstuvwxyz0123456709 &quot;; char *ptr; printf( &quot;destination before memcpy: %s &quot;,dest); ptr=memcpy(dest,src,strlen(src)); if(ptr) printf( &quot;destination after memcpy:%s &quot;,dest); else printf( &quot;memcpy failed &quot;); return 0; &#125; @函数名称: memmove函数原型: void memmove(void dest, const void *src, size_t n)函数功能: 字符串拷贝函数返回: 指向dest的指针参数说明: src-源字符串，n-拷贝的最大长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;12345678910#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; int main() &#123; char dest[40]= &quot;abcdefghijklmnopqrstuvwxyz0123456789 &quot;; printf( &quot;destination prior to memmove:%s\n &quot;,dest); memmove(dest+1,dest,35); printf( &quot;destination after memmove:%s &quot;,dest); return 0; &#125; @函数名称: memset函数原型: void memset(void s, int c, size_t n)函数功能: 字符串中的n个字节内容设置为c函数返回:参数说明: s-要设置的字符串，c-设置的内容，n-长度所属文件: &lt;string.h&gt;;,&lt;mem.h&gt;;1234567891011#include &lt;string.h&gt;; #include &lt;stdio.h&gt;; #include &lt;mem.h&gt;; int main() &#123; char buffer[] = &quot;Hello world &quot;; printf( &quot;Buffer before memset:%s &quot;,buffer); memset(buffer, &apos;* &apos;,strlen(buffer)-1); printf( &quot;Buffer after memset:%s &quot;,buffer); return 0; &#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode929. Unique Email Addresses]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode929%2F</url>
    <content type="text"><![CDATA[Unique Email AddressesEasy Every email consists of a local name and a domain name, separated by the @ sign. For example, in alice@leetcode.com, alice is the local name, and leetcode.com is the domain name. Besides lowercase letters, these emails may contain ‘.’s or ‘+’s. If you add periods (‘.’) between some characters in the local name part of an email address, mail sent there will be forwarded to the same address without dots in the local name. For example, “alice.z@leetcode.com“ and “alicez@leetcode.com“ forward to the same email address. (Note that this rule does not apply for domain names.) If you add a plus (‘+’) in the local name, everything after the first plus sign will be ignored. This allows certain emails to be filtered, for example m.y+name@email.com will be forwarded to my@email.com. (Again, this rule does not apply for domain names.) It is possible to use both of these rules at the same time. Given a list of emails, we send one email to each address in the list. How many different addresses actually receive mails? Example 1:123Input: [&quot;test.email+alex@leetcode.com&quot;,&quot;test.e.mail+bob.cathy@leetcode.com&quot;,&quot;testemail+david@lee.tcode.com&quot;]Output: 2Explanation: &quot;testemail@leetcode.com&quot; and &quot;testemail@lee.tcode.com&quot; actually receive mails Note: 1 &lt;= emails[i].length &lt;= 1001 &lt;= emails.length &lt;= 100Each emails[i] contains exactly one ‘@’ character.All local and domain names are non-empty.Local names do not start with a ‘+’ character. 字符串处理，如果一个email地址里有点(‘.’)的话，就忽略这个点，如果有加号(‘+’)，忽略这个加号到(‘@’)之间的字符。判断一共有几个一样的email地址。不难，但是涉及字符串处理的话总归有些麻烦的。 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: int numUniqueEmails(vector&lt;string&gt;&amp; emails) &#123; char result[100][100]; memset(result,&apos;\0&apos;,sizeof(result)); int result_len=0; for(unsigned int i=0; i&lt;emails.size(); i++) &#123; char temp[100]; memset(temp,&apos;\0&apos;,100); int temp_len = 0, k=0; unsigned int j; for(j=0; j&lt;emails[i].length(); j++) &#123; if(emails[i][j]==&apos;.&apos;) continue; else if(emails[i][j]==&apos;+&apos; || emails[i][j]==&apos;@&apos; ) break; else temp[temp_len++]=emails[i][j]; &#125; for(j=emails[i].find(&apos;@&apos;); j&lt;emails[i].length(); j++) temp[temp_len++]=emails[i][j]; for(k=0; k&lt;result_len; k++) if(strcmp(result[k],temp)==0) break; if(k==result_len) memcpy(result[result_len++], temp, sizeof(temp)); memset(temp,&apos;\0&apos;,100); &#125; return result_len; &#125;&#125;; 解析：For each email address, convert it to the canonical address that actually receives the mail. This involves a few steps: Separate the email address into a local part and the rest of the address. If the local part has a ‘+’ character, remove it and everything beyond it from the local part. Remove all the zeros from the local part. The canonical address is local + rest. After, we can count the number of unique canonical addresses with a Set structure.1234567891011121314151617class Solution &#123; public int numUniqueEmails(String[] emails) &#123; Set&lt;String&gt; seen = new HashSet(); for (String email: emails) &#123; int i = email.indexOf(&apos;@&apos;); String local = email.substring(0, i); String rest = email.substring(i); if (local.contains(&quot;+&quot;)) &#123; local = local.substring(0, local.indexOf(&apos;+&apos;)); &#125; local = local.replaceAll(&quot;.&quot;, &quot;&quot;); seen.add(local + rest); &#125; return seen.size(); &#125;&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[STL vector的内部实现原理及基本用法]]></title>
    <url>%2F2019%2F04%2F12%2FSTL-vector%E7%9A%84%E5%86%85%E9%83%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%8F%8A%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[原文地址：https://blog.csdn.net/u012658346/article/details/50725933 本文基于STL vector源代码，但是不考虑分配器allocator，迭代器iterator，异常处理try/catch等内容，同时对_Ucopy（）、 _Umove（）、 _Ufill（）函数也不会过度分析。 vector的定义123456789101112template&lt;class _Ty, class _Ax&gt; class vector : public _Vector_val&lt;_Ty, _Ax&gt; &#123; // varying size array of valuespublic: /********/protected: pointer _Myfirst; // pointer to beginning of array pointer _Mylast; // pointer to current end of sequence pointer _Myend; // pointer to end of array &#125;; 简单理解，就是vector是利用上述三个指针来表示的，基本示意图如下： 两个关键大小：大小：size=_Mylast - _Myfirst;容量：capacity=_Myend - _Myfirst;分别对应于resize()、reserve()两个函数。size表示vector中已有元素的个数，容量表示vector最多可存储的元素的个数；为了降低二次分配时的成本，vector实际配置的大小可能比客户需求的更大一些，以备将来扩充，这就是容量的概念。即capacity&gt;=size，当等于时，容器此时已满，若再要加入新的元素时，就要重新进行内存分配，整个vector的数据都要移动到新内存。二次分配成本较高，在实际操作时，应尽量预留一定空间，避免二次分配。 构造与析构构造vector的构造函数主要有以下几种：1234567891011121314151617vector() : _Mybase() &#123; // construct empty vector _Buy(0); &#125; explicit vector(size_type _Count) : _Mybase() &#123; // construct from _Count * _Ty() _Construct_n(_Count, _Ty()); &#125;vector(size_type _Count, const _Ty&amp; _Val) : _Mybase() &#123; // construct from _Count * _Val _Construct_n(_Count, _Val); &#125;vector(const _Myt&amp; _Right) : _Mybase(_Right._Alval) &#123; // construct by copying _Right if (_Buy(_Right.size())) _Mylast = _Ucopy(_Right.begin(), _Right.end(), _Myfirst); &#125; vector优异性能的秘诀之一，就是配置比其所容纳的元素所需更多的内存，一般在使用vector之前，就先预留足够空间，以避免二次分配，这样可以使vector的性能达到最佳。因此元素个数_Count是个远比元素值 _Val重要的参数，因此当构造一个vector时，首要参数一定是元素个数。由上各构造函数可知，基本上所有构造函数都是基于_Construct _n() 的12345678910111213141516171819bool _Buy(size_type _Capacity) &#123; // allocate array with _Capacity elements _Myfirst = 0, _Mylast = 0, _Myend = 0; if (_Capacity == 0) //_Count为0时，直接返回 return (false); else &#123; // nonempty array, allocate storage _Myfirst = this-&gt;_Alval.allocate(_Capacity); //分配内存，并更新成员变量 _Mylast = _Myfirst; _Myend = _Myfirst + _Capacity; &#125; return (true); &#125;void _Construct_n(size_type _Count, const _Ty&amp; _Val) &#123; // 构造含有_Count个值为_Val的元素的容器 if (_Buy(_Count)) _Mylast = _Ufill(_Myfirst, _Count, _Val); &#125; 这样就完成了vector容器的构造了。 析构vector的析构函数很简单，就是先销毁所有已存在的元素，然后释放所有内存123456789void _Tidy() &#123; // free all storage if (_Myfirst != 0) &#123; // something to free, destroy and deallocate it _Destroy(_Myfirst, _Mylast); this-&gt;_Alval.deallocate(_Myfirst, _Myend - _Myfirst); &#125; _Myfirst = 0, _Mylast = 0, _Myend = 0; &#125; 插入和删除元素vector的插入和删除元素是通过push_ back () 、 pop_back()两个接口来实现的，他们的内部实现也非常简单12345678910111213141516void push_back(const _Ty&amp; _Val) &#123; // insert element at end if (size() &lt; capacity()) _Mylast = _Ufill(_Mylast, 1, _Val); else insert(end(), _Val); //空间不足时，就会触发内存的二次分配 &#125;void pop_back() &#123; // erase element at end if (!empty()) &#123; // erase last element _Destroy(_Mylast - 1, _Mylast); --_Mylast; &#125; &#125; 其他接口1、reserve()操作 之前提到过reserve（Count） 函数主要是预留Count大小的空间，对应的是容器的容量，目的是保证（_Myend - _Myfirst）&gt;=Count。只有当空间不足时，才会操作，即重新分配一块内存，将原有元素拷贝到新内存，并销毁原有内存1234567891011121314151617void reserve(size_type _Count) &#123; // determine new minimum length of allocated storage if (capacity() &lt; _Count) &#123; // not enough room, reallocate pointer _Ptr = this-&gt;_Alval.allocate(_Count); _Umove(begin(), end(), _Ptr); size_type _Size = size(); if (_Myfirst != 0) &#123; // destroy and deallocate old array _Destroy(_Myfirst, _Mylast); this-&gt;_Alval.deallocate(_Myfirst, _Myend - _Myfirst); &#125; _Myend = _Ptr + _Count; _Mylast = _Ptr + _Size; _Myfirst = _Ptr; &#125; &#125; 2、resize()操作resize（Count） 函数主要是用于改变size的，也就是改变vector的大小，最终改变的是（_Mylast - _Myfirst）的值，当size &lt; Count时,就插入元素，当size &gt;Count时，就擦除元素。1234567void resize(size_type _Newsize, _Ty _Val) &#123; // determine new length, padding with _Val elements as needed if (size() &lt; _Newsize) _Insert_n(end(), _Newsize - size(), _Val); else if (_Newsize &lt; size()) erase(begin() + _Newsize, end()); &#125; 3、_Insert_n()操作 resize()操作和insert()操作都会利用到_Insert_n()这个函数，这个函数非常重要，也比其他函数稍微复杂一点虽然_Insert_n(_where, _Count, _Val ) 函数比较长，但是操作都非常简单，主要可以分为以下几种情况： _Count == 0，不需要插入，直接返回 max_size() - size() &lt; _Count，超过系统设置的最大容量，会溢出，造成Xlen（）异常 _Capacity &lt; size() + _Count，vector的容量不足以插入Count个元素，需要进行二次分配，扩大vector的容量。 在VS下，vector容量会扩大50%，即 _Capacity = _Capacity + _Capacity / 2;若仍不足，则 _Capacity = size() + _Count; 12345678910111213else if (_Capacity &lt; size() + _Count) &#123; // not enough room, reallocate _Capacity = max_size() - _Capacity / 2 &lt; _Capacity ? 0 : _Capacity + _Capacity / 2; // try to grow by 50% if (_Capacity &lt; size() + _Count) _Capacity = size() + _Count; pointer _Newvec = this-&gt;_Alval.allocate(_Capacity); pointer _Ptr = _Newvec; _Ptr = _Umove(_Myfirst, _VEC_ITER_BASE(_Where),_Newvec); // copy prefix _Ptr = _Ufill(_Ptr, _Count, _Val); // add new stuff _Umove(_VEC_ITER_BASE(_Where), _Mylast, _Ptr); // copy suffix //内存释放与变量更新 &#125; 这种情况下，数据从原始容器移动到新分配内存时是从前到后移动的 空间足够，且被插入元素的位置比较靠近_Mylast,即已有元素的尾部 这种情况下不需要再次进行内存分配，且数据是从后往前操作的。首先是将where~last向后移动，为待插入数据预留Count大小的空间，然后从_Mylast处开始填充，然后将从where处开始填充剩余元素12345678910else if ((size_type)(_Mylast - _VEC_ITER_BASE(_Where)) &lt; _Count) &#123; // new stuff spills off end _Umove(_VEC_ITER_BASE(_Where), _Mylast, _VEC_ITER_BASE(_Where) + _Count); // copy suffix _Ufill(_Mylast, _Count - (_Mylast - _VEC_ITER_BASE(_Where)), _Val); // insert new stuff off end _Mylast += _Count; std::fill(_VEC_ITER_BASE(_Where), _Mylast - _Count, _Val); // insert up to old end &#125; 空间足够，但插入的位置比较靠前1234567891011&#123; // new stuff can all be assigned_Ty _Tmp = _Val; // in case _Val is in sequencepointer _Oldend = _Mylast;_Mylast = _Umove(_Oldend - _Count, _Oldend, _Mylast); // copy suffix_STDEXT _Unchecked_move_backward(_VEC_ITER_BASE(_Where), _Oldend - _Count, _Oldend); // copy holestd::fill(_VEC_ITER_BASE(_Where), _VEC_ITER_BASE(_Where) + _Count, _Tmp); // insert into hole&#125; 4、erase()操作12345678910111213141516iterator erase(const_iterator _First_arg, const_iterator _Last_arg) &#123; // erase [_First, _Last) iterator _First = _Make_iter(_First_arg); iterator _Last = _Make_iter(_Last_arg); if (_First != _Last) &#123; // worth doing, copy down over hole pointer _Ptr = _STDEXT unchecked_copy(_VEC_ITER_BASE(_Last), _Mylast, _VEC_ITER_BASE(_First)); _Destroy(_Ptr, _Mylast); _Mylast = _Ptr; &#125; return (_First); &#125; 主要操作就是将后半部分的有效元素向前拷贝，并将后面空间的无效元素析构，并更新_Mylast变量 5、assign()操作 assign()操作最终都会调用到下面的函数，主要操作是首先擦除容器中已有的全部元素，在从头开始插入Count个Val元素123456void _Assign_n(size_type _Count, const _Ty&amp; _Val) &#123; // assign _Count * _Val _Ty _Tmp = _Val; // in case _Val is in sequence erase(begin(), end()); insert(begin(), _Count, _Tmp); &#125; 基本使用在经过上述对vector内部实现的分析后，再来理解相应接口就变得简单得多。vector对外接口主要可以分为： 构造、析构：12345678vector&lt;Elem&gt; cvector &lt;Elem&gt; c1(c2)vector &lt;Elem&gt; c(n)vector &lt;Elem&gt; c(n, elem)vector &lt;Elem&gt; c(beg,end)c.~ vector &lt;Elem&gt;()``插入、删除、赋值 c.push_back(elem)c.pop_back()c.insert(pos,elem)c.insert(pos,n,elem)c.insert(pos,beg,end)c.erase(pos)c.erase(beg,end)c.clear()c.assign(beg,end)c.assign(n,elem)1大小相关 c.capacity()c.max_size()c.resize(num)c.reserve()c.size()1获取迭代器 c.begin()c.end()c.rbegin()c.rend()1获取数据 operator[]c.at(idx)c.front()c.back()`]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c语言str相关的函数]]></title>
    <url>%2F2019%2F04%2F12%2Fc%E8%AF%AD%E8%A8%80str%E7%9B%B8%E5%85%B3%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[C语言str系列库函数在不同的库中有不同的实现方法，但原理都是一样的。因为库函数都是没有进行入口参数检查的，并且str系列库函数在面试中经常容易被面试官喊在纸上写某一个函数的实现，因此本文参考了OpenBSD和vc++ 8.0库中的代码，结合自己的编程习惯，部分整理如下： 1、strcpy12345678910111213char * strcpy(char *dst, const char *src) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d++ = *src++) // while ((*d++ = *src++) != &apos;\0&apos;) ; return dst; &#125; 2、strncpy123456789101112131415161718//copy at most n characters of src to dst //Pad with &apos;\0&apos; if src fewer than n characters char *strncpy(char *dst, const char*src, size_t n) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (n != 0 &amp;&amp; (*d++ = *src++)) /* copy string */ n--; if (n != 0) while (--n != 0) *d++ == &apos;\0&apos;; /* pad out with zeroes */ return dst; &#125; 注意n是unsigned int，在进行n–操作时特别要小心。如果不小心写成下面这样就会出错：1234while (n-- != 0 &amp;&amp; (*d++ = *src++)) ; while (n-- != 0) *d++ = &apos;\0&apos;; 第一个while循环中，当n变为0时，仍然会执行n–一，此时n等于经由-1变成的大正数，导致后面对n的使用出错。3、strcat1234567891011121314151617char *strcat(char *dst, const char *src) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d) d++; //while (*d++ != 0); //d--; while (*d++ = *src++) ; return dst; &#125; 4、strncat写法1：123456789101112131415161718192021//concatenate at most n characters of src to the end of dst //terminates dst with &apos;\0&apos; char *strncat(char *dst, const char *src, size_t n) &#123; if (NULL == dst || NULL == src) return dst; if (n != 0) &#123; char *d = dst; do &#123; if ((*d = *src++) == &apos;\0&apos; ) return dst; //break d++; &#125; while (--n != 0); *d = &apos;\0&apos;; &#125; return dst; &#125; 写法2：123456789101112131415161718192021222324252627char *strncat(char *dst, const char *src, size_t n) &#123; char *d; if (dst == NULL || src == NULL) return dst; d = dst; while (*d) d++; //(1) while (n != 0) &#123; if ((*d++ = *src++) == &apos;\0&apos;) return dst; n--; &#125; //(2) //while (n--) //这种方式写最后n的值不为0，不过这个n后面不会再被使用 // if ((*d++ == *src++) == &apos;\0&apos;) // return dst; *d = &apos;\0&apos;; return dst; &#125; 5、strcmp123456789101112131415int strcmp(const char *s1, const char *s2) &#123; if (s1 == NULL || s2 == NULL) return 0; //(1) //while (*s1 == *s2++) // if (*s1++ == &apos;\0&apos;) // return 0; //(2) for (; *s1 == *s2; s1++, s2++) if (*s1 == &apos;\0&apos;) return 0; return *(unsigned char*)s1 - *(unsigned char*)s2; &#125; 6、strncmp123456789101112131415161718192021222324252627int strncmp(const char *s1, const char *s2, size_t n) &#123; if (s1 == NULL || s2 == NULL) return 0; if (n == 0) return 0; do &#123; if (*s1 != *s2++) return *(unsigned char*)s1 - *(unsigned char*)--s2; if (*s1++ == &apos;\0&apos;) break; &#125; while (--n != 0); //do //&#123; // if (*s1 != *s2) // return *(unsigned char*)s1 - *(unsigned char*)s2; // if (*s1 == &apos;\0&apos;) // break; // s1++; // s2++; //&#125; while (--n != 0); return 0; &#125; 7、strstr写法1：12345678910111213141516171819202122232425//return pointer to first occurrence of find in s //or NULL if not present char *strstr(const char *s, const char *find) &#123; char *cp = (char*)s; char *s1, *s2; if (s == NULL || find == NULL) return NULL; while (*cp != &apos;\0&apos;) &#123; s1 = cp; s2 = (char*)find; while (*s1 &amp;&amp; *s2 &amp;&amp; *s1 == *s2) s1++, s2++; if(*s2 == &apos;\0&apos;) return cp; cp++; &#125; return NULL; &#125; 写法2：参照简单模式匹配算法12345678910111213141516char *strstr(const char *s, const char *find) &#123; int i = 0, j = 0; while (*(s + i) != &apos;\0&apos; &amp;&amp; *(find + j) != &apos;\0&apos;) &#123; if (*(s + i + j) == *(find + j)) j++; //继续比较后一字符 else &#123; i++; //开始新一轮比较 j = 0; &#125; &#125; return *(find + j) == &apos;\0&apos; ? (char*)(s + i) : NULL; &#125; 8、strchr1234567891011//return pointer to first occurrence of ch in str //NULL if not present char *strchr(const char*str, int ch) &#123; while (*str != &apos;\0&apos; &amp;&amp; *str != (char)ch) str++; if(*str == (char)ch) return (char*)str; return NULL; &#125; 9、strrchr12345678910111213141516171819//return pointer to last occurrence of ch in str //NULL if not present char *strrchr(const char *str, int ch) &#123; if (str == NULL) return NULL; char *s = (char*)str; while (*s++) ; /* find end of string */ while (--s != str &amp;&amp; *s != (char)ch) ; /* search towards front */ if(*s == (char)ch) return (char*)s; return NULL; &#125; 10、strlen12345678910size_t strlen(const char *str) &#123; if (str == NULL) return 0; const char *eos = str; while (*eos++) ; return (eos - 1 - str); &#125;]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode804. Unique Morse Code Words]]></title>
    <url>%2F2019%2F04%2F12%2FLeetcode804%2F</url>
    <content type="text"><![CDATA[Unique Morse Code WordsEasy International Morse Code defines a standard encoding where each letter is mapped to a series of dots and dashes, as follows: “a” maps to “.-“, “b” maps to “-…”, “c” maps to “-.-.”, and so on. For convenience, the full table for the 26 letters of the English alphabet is given below: [“.-“,”-…”,”-.-.”,”-..”,”.”,”..-.”,”–.”,”….”,”..”,”.—“,”-.-“,”.-..”,”–”,”-.”,”—“,”.–.”,”–.-“,”.-.”,”…”,”-“,”..-“,”…-“,”.–”,”-..-“,”-.–”,”–..”]Now, given a list of words, each word can be written as a concatenation of the Morse code of each letter. For example, “cba” can be written as “-.-..–…”, (which is the concatenation “-.-.” + “-…” + “.-“). We’ll call such a concatenation, the transformation of a word. Return the number of different transformations among all words we have. Example:123456789Input: words = [&quot;gin&quot;, &quot;zen&quot;, &quot;gig&quot;, &quot;msg&quot;]Output: 2Explanation: The transformation of each word is:&quot;gin&quot; -&gt; &quot;--...-.&quot;&quot;zen&quot; -&gt; &quot;--...-.&quot;&quot;gig&quot; -&gt; &quot;--...--.&quot;&quot;msg&quot; -&gt; &quot;--...--.&quot;There are 2 different transformations, &quot;--...-.&quot; and &quot;--...--.&quot;. Note: The length of words will be at most 100.Each words[i] will have length in range [1, 12].words[i] will only consist of lowercase letters. 也比较简单，主要是字符串的表示太麻烦，不太了解char*和string的表示，还有vector的使用也要新开一个Markdown记一下。 12345678910111213141516171819202122232425262728class Solution &#123;public: vector&lt;string&gt; codes=&#123;&quot;.-&quot;,&quot;-...&quot;,&quot;-.-.&quot;,&quot;-..&quot;,&quot;.&quot;,&quot;..-.&quot;,&quot;--.&quot;,&quot;....&quot;,&quot;..&quot;,&quot;.---&quot;,&quot;-.-&quot;,&quot;.-..&quot;,&quot;--&quot;,&quot;-.&quot;,&quot;---&quot;,&quot;.--.&quot;,&quot;--.-&quot;,&quot;.-.&quot;,&quot;...&quot;,&quot;-&quot;,&quot;..-&quot;,&quot;...-&quot;,&quot;.--&quot;,&quot;-..-&quot;,&quot;-.--&quot;,&quot;--..&quot;&#125;; int uniqueMorseRepresentations(vector&lt;string&gt;&amp; words) &#123;// map&lt;char,int&gt; table;// for(int i=0;i&lt;26;i++)&#123;// table.insert(map&lt;char, int&gt;::value_type(&apos;a&apos;+i,i));// &#125;// vector&lt;string&gt; result; for(unsigned int i=0;i&lt;words.size();i++)&#123; string temp = &quot;&quot;; for(unsigned int j=0;j&lt;words[i].length();j++)&#123; temp.append(codes[words[i][j]]-&apos;a&apos;);// temp.append(codes[table[words[i][j]]]); &#125; unsigned int k=0; for(k=0;k&lt;result.size();k++)&#123; if(result[k]==temp) break; &#125; if(k==result.size()) result.push_back(temp); temp=&quot;&quot;; &#125; return result.size(); &#125;&#125;; Runtime: 8 ms, faster than 74.00% of C++ online submissions for Unique Morse Code Words.Memory Usage: 9 MB, less than 100.00% of C++ online submissions for Unique Morse Code Words.被注释的原先的代码，比较慢，但是内存占的少。如果把代码换成上边的，取消map，就会把时间减少到4ms。 贴一个大佬的代码：1234567891011121314151617 vector&lt;string&gt; output; for(int i=0; i&lt;words.size(); i++) &#123; string s = words[i]; string morseCode = &quot;&quot;; for(int j=0; j&lt;s.length(); j++) &#123; char c = s[j]; int k = c - &apos;a&apos;; morseCode+=morseCodes[k]; &#125; if(find(output.begin(),output.end(),morseCode) == output.end()) output.push_back(morseCode); &#125; return output.size();&#125;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode701. Insert into a Binary Search Tree]]></title>
    <url>%2F2019%2F04%2F11%2FLeetcode701%2F</url>
    <content type="text"><![CDATA[Insert into a Binary Search TreeMedium Given the root node of a binary search tree (BST) and a value to be inserted into the tree, insert the value into the BST. Return the root node of the BST after the insertion. It is guaranteed that the new value does not exist in the original BST. Note that there may exist multiple valid ways for the insertion, as long as the tree remains a BST after insertion. You can return any of them. For example,1234567891011121314151617181920212223Given the tree: 4 / \ 2 7 / \ 1 3And the value to insert: 5You can return this binary search tree: 4 / \ 2 7 / \ / 1 3 5This tree is also valid: 5 / \ 2 7 / \ 1 3 \ 4 非常简单，不用详细说了，递归插入一个节点即可。 1234567891011121314151617181920212223/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: TreeNode* insertIntoBST(TreeNode* root, int val) &#123; if(root == NULL)&#123; root = new TreeNode(val); return root; &#125; if(val &lt; root-&gt;val) root-&gt;left = insertIntoBST(root-&gt;left,val); else root-&gt;right = insertIntoBST(root-&gt;right,val); return root; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode654. Maximum Binary Tree]]></title>
    <url>%2F2019%2F04%2F11%2FLeetcode654%2F</url>
    <content type="text"><![CDATA[Maximum Binary TreeMedium Given an integer array with no duplicates. A maximum tree building on this array is defined as follow: The root is the maximum number in the array.The left subtree is the maximum tree constructed from left part subarray divided by the maximum number.The right subtree is the maximum tree constructed from right part subarray divided by the maximum number.Construct the maximum tree by the given array and output the root node of this tree. Example 1:12345678910Input: [3,2,1,6,0,5]Output: return the tree root node representing the following tree: 6 / \ 3 5 \ / 2 0 \ 1 Note:The size of the given array will be in the range [1,1000]. 这个题比较奇怪，其实每太懂题意，主要是给一个数组，把数组建立成一个树，找到最大的数作为root，然后递归建立，大概是这个意思。 1234567891011121314151617181920212223242526272829303132333435/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int max(vector&lt;int&gt;&amp; nums, int l,int r)&#123; int biggest = l; for(int i=l;i&lt;r;i++)&#123; if(nums[biggest]&lt;nums[i]) biggest = i; &#125; return biggest; &#125; TreeNode* construct(vector&lt;int&gt;&amp; nums, int l, int r)&#123; if(l == r) return NULL; int biggest = max(nums,l,r); TreeNode* root = new TreeNode(nums[biggest]); root-&gt;left=construct(nums,l,biggest); root-&gt;right=construct(nums,biggest+1,r); return root; &#125; TreeNode* constructMaximumBinaryTree(vector&lt;int&gt;&amp; nums) &#123; return construct(nums, 0, nums.size()); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[c_cpp内存对齐原则及作用]]></title>
    <url>%2F2019%2F04%2F11%2Fc-cpp%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90%E5%8E%9F%E5%88%99%E5%8F%8A%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[struct/class/union内存对齐原则有四个： 数据成员对齐规则：结构(struct)(或联合(union))的数据成员，第一个数据成员放在offset为0的地方，以后每个数据成员存储的起始位置要从该成员大小或者成员的子成员大小（只要该成员有子成员，比如说是数组，结构体等）的整数倍开始(比如int在３２位机为４字节, 则要从４的整数倍地址开始存储),基本类型不包括struct/class/uinon。 结构体作为成员:如果一个结构里有某些结构体成员,则结构体成员要从其内部”最宽基本类型成员”的整数倍地址开始存储.(struct a里存有struct b,b里有char,int ,double等元素,那b应该从8的整数倍开始存储.)。 收尾工作:结构体的总大小,也就是sizeof的结果,.必须是其内部最大成员的”最宽基本类型成员”的整数倍.不足的要补齐.(基本类型不包括struct/class/uinon)。 sizeof(union)，以结构里面size最大元素为union的size,因为在某一时刻，union只有一个成员真正存储于该地址。 实例解释：下面以class为代表1234567No. 1class Data&#123; char c; int a;&#125;;cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 12345678No. 2class Data&#123; char c; double a;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 显然程序No.1 输出的结果为 8， No.2 输出的结果为 16。No.1最大的数据成员是4bytes，1+4=5，补齐为4的倍数，也就是8。而No.2为8bytes，1+8=9，补齐为8的倍数，也就是16。 123456789No.3class Data&#123; char c; int a; char d;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; 123456789No.4class Data&#123; char c; char d; int a;&#125;; cout &lt;&lt; sizeof(Data) &lt;&lt; endl; No.3运行结果为 12 No.4运行结果为 8 class中的数据成员放入内存的时候，内存拿出一个内存块来，数据成员们排队一个一个往里放，遇到太大的，不是把自己劈成两半，能放多少放多少，而是等下一个内存块过来。这样的话，就可以理解为什么No.3,No.4两端的代码输出结果不一样了，因为左边是1+（3）+4+1+（3）=12，而右边是1+1+（2）+4=8。括号中为补齐的bytes。 1234567891011121314No.5class BigData&#123; char array[33];&#125;; class Data&#123; BigData bd; int integer; double d;&#125;; cout &lt;&lt; sizeof(BigData) &lt;&lt; &quot; &quot; &lt;&lt; sizeof(Data) &lt;&lt; endl; 12345678910111213No.6class BigData&#123; char array[33];&#125;; class Data&#123; BigData bd; double d;&#125;; cout &lt;&lt; sizeof(BigData) &lt;&lt; &quot; &quot; &lt;&lt; sizeof(Data) &lt;&lt; endl; No.5和No.6运行结果均为： 48 在默认条件下，内存对齐是以class中最大的那个基本类型为基准的，如果class中有自定义类型，则递归的取其中最大的基本类型来参与比较。在No.5和No.6中内存块一个接一个的过来接走数据成员，一直到第5块的时候，BigData里只剩1个char了，将它放入内存块中，内存块还剩7个bytes，接下来是个int（4bytes），能够放下，所以也进入第5个内存块，这时候内存块还剩3bytes，而接下来是个double（8bytes），放不下，所以要等下一个内存快到来。因此，No.5的Data的size=33+4+（3）+8=48，同理No.6应该是33+（7）+8=48。 顺便提一下Union： 共用体表示几个变量共用一个内存位置，在不同的时间保存不同的数据类型和不同长度的变量。在union中，所有的共用体成员共用一个空间，并且同一时间只能储存其中一个成员变量的值。 内存对齐的主要作用是： 1、 平台原因(移植原因)：不是所有的硬件平台都能访问任意地址上的任意数据的；某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。 2、 性能原因：经过内存对齐后，CPU的内存访问速度大大提升。具体原因稍后解释。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内存管理器ptmalloc]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%99%A8ptmalloc%2F</url>
    <content type="text"><![CDATA[内存管理器ptmalloc 内存布局了解ptmalloc内存管理器，就必须得先了解操作系统的内存布局方式。通过下面这个图，我很很清晰的可以看到堆、栈等的内存分布。 X86平台LINUX进程内存布局： 上图就是linux操作系统的内存布局。内存从低到高分别展示了操作系统各个模块的内存分布。 Test Segment：存放程序代码，只读，编译的时候确定 Data Segment：存放程序运行的时候就能确定的数据，可读可写 BBS Segment：定义而没有初始化的全局变量和静态变量 Heap：堆。堆的内存地址由低到高。 Mmap：映射区域。 Stack：栈。编译器自动分配和释放。内存地址由高到低 ptmalloc内存管理器ptmalloc是glibc默认的内存管理器。我们常用的malloc和free就是由ptmalloc内存管理器提供的基础内存分配函数。ptmalloc有点像我们自己写的内存池，当我们通过malloc或者free函数来申请和释放内存的时候，ptmalloc会将这些内存管理起来，并且通过一些策略来判断是否需要回收给操作系统。这样做的最大好处就是：让用户申请内存和释放内存的时候更加高效。 为了内存分配函数malloc的高效性，ptmalloc会预先向操作系统申请一块内存供用户使用，并且ptmalloc会将已经使用的和空闲的内存管理起来；当用户需要销毁内存free的时候，ptmalloc又会将回收的内存管理起来，根据实际情况是否回收给操作系统。 设计假设ptmalloc在设计时折中了高效率，高空间利用率，高可用性等设计目标。所以有了下面一些设计上的假设条件： 具有长生命周期的大内存分配使用mmap。 特别大的内存分配总是使用mmap。 具有短生命周期的内存分配使用brk。 尽量只缓存临时使用的空闲小内存块，对大内存块或是长生命周期的大内存块在释放时都直接归还给操作系统。 对空闲的小内存块只会在malloc和free的时候进行合并，free时空闲内存块可能放入pool中，不一定归还给操作系统。 收缩堆的条件是当前free的块大小加上前后能合并chunk的大小大于64KB、，并且堆顶的大小达到阈值，才有可能收缩堆，把堆最顶端的空闲内存返回给操作系统。 需要保持长期存储的程序不适合用ptmalloc来管理内存。 不停的内存分配ptmalloc会对内存进行切割和合并，会导致一定的内存碎片 主分配区和非主分配区ptmalloc的内存分配器中，为了解决多线程锁争夺问题，分为主分配区main_area和非主分配区no_main_area。 每个进程有一个主分配区，也可以允许有多个非主分配区。 主分配区可以使用brk和mmap来分配，而非主分配区只能使用mmap来映射内存块 非主分配区的数量一旦增加，则不会减少。 主分配区和非主分配区形成一个环形链表进行管理。 chunk 内存块的基本组织单元ptmalloc通过chunk的数据结构来组织每个内存单元。当我们使用malloc分配得到一块内存的时候，这块内存就会通过chunk的形式被记录到glibc上并且管理起来。你可以把它想象成自己写内存池的时候的一个内存数据结构。chunk的结构可以分为使用中的chunk和空闲的chunk。使用中的chunk和空闲的chunk数据结构基本项同，但是会有一些设计上的小技巧，巧妙的节省了内存。 使用中的chunk： chunk指针指向chunk开始的地址；mem指针指向用户内存块开始的地址。 p=0时，表示前一个chunk为空闲，prev_size才有效 p=1时，表示前一个chunk正在使用，prev_size无效 p主要用于内存块的合并操作 ptmalloc 分配的第一个块总是将p设为1, 以防止程序引用到不存在的区域 M=1 为mmap映射区域分配；M=0为heap区域分配 A=1 为非主分区分配；A=0 为主分区分配 空闲的chunk： 空闲的chunk会被放置到空闲的链表bins上。当用户申请内存malloc的时候，会先去查找空闲链表bins上是否有合适的内存。 fp和bp分别指向前一个和后一个空闲链表上的chunk fp_nextsize和bp_nextsize分别指向前一个空闲chunk和后一个空闲chunk的大小，主要用于在空闲链表上快速查找合适大小的chunk。 fp、bp、fp_nextsize、bp_nextsize的值都会存在原本的用户区域，这样就不需要专门为每个chunk准备单独的内存存储指针了。 空闲链表bins当用户使用free函数释放掉的内存，ptmalloc并不会马上交还给操作系统（这边很多时候我们明明执行了free函数，但是进程内存并没有回收就是这个原因），而是被ptmalloc本身的空闲链表bins管理起来了，这样当下次进程需要malloc一块内存的时候，ptmalloc就会从空闲的bins上寻找一块合适大小的内存块分配给用户使用。这样的好处可以避免频繁的系统调用，降低内存分配的开销。 ptmalloc一共维护了128bin。每个bins都维护了大小相近的双向链表的chunk。 通过上图这个bins的列表就能看出，当用户调用malloc的时候，能很快找到用户需要分配的内存大小是否在维护的bin上，如果在某一个bin上，就可以通过双向链表去查找合适的chunk内存块给用户使用。 fast bins。fast bins是bins的高速缓冲区，大约有10个定长队列。当用户释放一块不大于max_fast（默认值64）的chunk（一般小内存）的时候，会默认会被放到fast bins上。当用户下次需要申请内存的时候首先会到fast bins上寻找是否有合适的chunk，然后才会到bins上空闲的chunk。ptmalloc会遍历fast bin，看是否有合适的chunk需要合并到bins上。 unsorted bin。是bins的一个缓冲区。当用户释放的内存大于max_fast或者fast bins合并后的chunk都会进入unsorted bin上。当用户malloc的时候，先会到unsorted bin上查找是否有合适的bin，如果没有合适的bin，ptmalloc会将unsorted bin上的chunk放入bins上，然后到bins上查找合适的空闲chunk。 small bins和large bins。small bins和large bins是真正用来放置chunk双向链表的。每个bin之间相差8个字节，并且通过上面的这个列表，可以快速定位到合适大小的空闲chunk。前64个为small bins，定长；后64个为large bins，非定长。 Top chunk。并不是所有的chunk都会被放到bins上。top chunk相当于分配区的顶部空闲内存，当bins上都不能满足内存分配要求的时候，就会来top chunk上分配。 mmaped chunk。当分配的内存非常大（大于分配阀值，默认128K）的时候，需要被mmap映射，则会放到mmaped chunk上，当释放mmaped chunk上的内存的时候会直接交还给操作系统。 内存分配malloc流程 获取分配区的锁，防止多线程冲突。 计算出需要分配的内存的chunk实际大小。 判断chunk的大小，如果小于max_fast（64b），则取fast bins上去查询是否有适合的chunk，如果有则分配结束。 chunk大小是否小于512B，如果是，则从small bins上去查找chunk，如果有合适的，则分配结束。 继续从 unsorted bins上查找。如果unsorted bins上只有一个chunk并且大于待分配的chunk，则进行切割，并且剩余的chunk继续扔回unsorted bins；如果unsorted bins上有大小和待分配chunk相等的，则返回，并从unsorted bins删除；如果unsorted bins中的某一chunk大小 属于small bins的范围，则放入small bins的头部；如果unsorted bins中的某一chunk大小 属于large bins的范围，则找到合适的位置放入。 从large bins中查找，找到链表头后，反向遍历此链表，直到找到第一个大小 大于待分配的chunk，然后进行切割，如果有余下的，则放入unsorted bin中去，分配则结束。 如果搜索fast bins和bins都没有找到合适的chunk，那么就需要操作top chunk来进行分配了（top chunk相当于分配区的剩余内存空间）。判断top chunk大小是否满足所需chunk的大小，如果是，则从top chunk中分出一块来。 如果top chunk也不能满足需求，则需要扩大top chunk。主分区上，如果分配的内存小于分配阀值（默认128k），则直接使用brk()分配一块内存；如果分配的内存大于分配阀值，则需要mmap来分配；非主分区上，则直接使用mmap来分配一块内存。通过mmap分配的内存，就会放入mmap chunk上，mmap chunk上的内存会直接回收给操作系统。 内存释放free流程 获取分配区的锁，保证线程安全。 如果free的是空指针，则返回，什么都不做。 判断当前chunk是否是mmap映射区域映射的内存，如果是，则直接munmap()释放这块内存。前面的已使用chunk的数据结构中，我们可以看到有M来标识是否是mmap映射的内存。 判断chunk是否与top chunk相邻，如果相邻，则直接和top chunk合并（和top chunk相邻相当于和分配区中的空闲内存块相邻）。转到步骤8 如果chunk的大小大于max_fast（64b），则放入unsorted bin，并且检查是否有合并，有合并情况并且和top chunk相邻，则转到步骤8；没有合并情况则free。 如果chunk的大小小于 max_fast（64b），则直接放入fast bin，fast bin并没有改变chunk的状态。没有合并情况，则free；有合并情况，转到步骤7 在fast bin，如果当前chunk的下一个chunk也是空闲的，则将这两个chunk合并，放入unsorted bin上面。合并后的大小如果大于64KB，会触发进行fast bins的合并操作，fast bins中的chunk将被遍历，并与相邻的空闲chunk进行合并，合并后的chunk会被放到unsorted bin中，fast bin会变为空。合并后的chunk和topchunk相邻，则会合并到topchunk中。转到步骤8 判断top chunk的大小是否大于mmap收缩阈值（默认为128KB），如果是的话，对于主分配区，则会试图归还top chunk中的一部分给操作系统。free结束。 mallopt 参数调优 M_MXFAST：用于设置fast bins中保存的chunk的最大大小，默认值为64B。最大80B M_TRIM_THRESHOLD：用于设置mmap收缩阈值，默认值为128KB。 M_MMAP_THRESHOLD：M_MMAP_THRESHOLD用于设置mmap分配阈值，默认值为128KB。当用户需要分配的内存大于mmap分配阈值，ptmalloc的malloc()函数其实相当于mmap()的简单封装，free函数相当于munmap()的简单封装。 M_MMAP_MAX：M_MMAP_MAX用于设置进程中用mmap分配的内存块的地址段数量，默认值为65536 M_TOP_PAD：该参数决定了，当libc内存管理器调用brk释放内存时，堆顶还需要保留的空闲内存数量。该值缺省为 0. 使用注意事项为了避免Glibc内存暴增，需要注意： 后分配的内存先释放，因为ptmalloc收缩内存是从top chunk开始，如果与top chunk相邻的chunk不能释放，top chunk以下的chunk都无法释放。 Ptmalloc不适合用于管理长生命周期的内存，特别是持续不定期分配和释放长生命周期的内存，这将导致ptmalloc内存暴增。 多线程分阶段执行的程序不适合用ptmalloc，这种程序的内存更适合用内存池管理 尽量减少程序的线程数量和避免频繁分配/释放内存。频繁分配，会导致锁的竞争，最终导致非主分配区增加，内存碎片增高，并且性能降低。 防止内存泄露，ptmalloc对内存泄露是相当敏感的，根据它的内存收缩机制，如果与top chunk相邻的那个chunk没有回收，将导致top chunk一下很多的空闲内存都无法返回给操作系统。 防止程序分配过多内存，或是由于Glibc内存暴增，导致系统内存耗尽，程序因OOM被系统杀掉。预估程序可以使用的最大物理内存大小，配置系统的/proc/sys/vm/overcommit_memory，/proc/sys/vm/overcommit_ratio，以及使用ulimt –v限制程序能使用虚拟内存空间大小，防止程序因OOM被杀掉。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[经典字符串hash函数介绍及性能比较]]></title>
    <url>%2F2019%2F04%2F11%2F%E7%BB%8F%E5%85%B8%E5%AD%97%E7%AC%A6%E4%B8%B2hash%E5%87%BD%E6%95%B0%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/djinglan/article/details/8812934 今天根据自己的理解重新整理了一下几个字符串hash函数，使用了模板，使其支持宽字符串，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183/// @brief BKDR Hash Function /// @detail 本 算法由于在Brian Kernighan与Dennis Ritchie的《The C Programming Language》一书被展示而得 名，是一种简单快捷的hash算法，也是Java目前采用的字符串的Hash算法（累乘因子为31）。 template&lt;class T&gt; size_t BKDRHash(const T *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = hash * 131 + ch; // 也可以乘以31、131、1313、13131、131313.. // 有人说将乘法分解为位运算及加减法可以提高效率，如将上式表达为：hash = hash &lt;&lt; 7 + hash &lt;&lt; 1 + hash + ch; // 但其实在Intel平台上，CPU内部对二者的处理效率都是差不多的， // 我分别进行了100亿次的上述两种运算，发现二者时间差距基本为0（如果是Debug版，分解成位运算后的耗时还要高1/3）； // 在ARM这类RISC系统上没有测试过，由于ARM内部使用Booth&apos;s Algorithm来模拟32位整数乘法运算，它的效率与乘数有关： // 当乘数8-31位都为1或0时，需要1个时钟周期 // 当乘数16-31位都为1或0时，需要2个时钟周期 // 当乘数24-31位都为1或0时，需要3个时钟周期 // 否则，需要4个时钟周期 // 因此，虽然我没有实际测试，但是我依然认为二者效率上差别不大 &#125; return hash; &#125; /// @brief SDBM Hash Function /// @detail 本算法是由于在开源项目SDBM（一种简单的数据库引擎）中被应用而得名，它与BKDRHash思想一致，只是种子不同而已。 template&lt;class T&gt; size_t SDBMHash(const T *str) &#123; register size_t hash = 0; while (size_t ch = (size_t)*str++) &#123; hash = 65599 * hash + ch; //hash = (size_t)ch + (hash &lt;&lt; 6) + (hash &lt;&lt; 16) - hash; &#125; return hash; &#125; /// @brief RS Hash Function /// @detail 因Robert Sedgwicks在其《Algorithms in C》一书中展示而得名。 template&lt;class T&gt; size_t RSHash(const T *str) &#123; register size_t hash = 0; size_t magic = 63689; while (size_t ch = (size_t)*str++) &#123; hash = hash * magic + ch; magic *= 378551; &#125; return hash; &#125; /// @brief AP Hash Function /// @detail 由Arash Partow发明的一种hash算法。 template&lt;class T&gt; size_t APHash(const T *str) &#123; register size_t hash = 0; size_t ch; for (long i = 0; ch = (size_t)*str++; i++) &#123; if ((i &amp; 1) == 0) &#123; hash ^= ((hash &lt;&lt; 7) ^ ch ^ (hash &gt;&gt; 3)); &#125; else &#123; hash ^= (~((hash &lt;&lt; 11) ^ ch ^ (hash &gt;&gt; 5))); &#125; &#125; return hash; &#125; /// @brief JS Hash Function /// 由Justin Sobel发明的一种hash算法。 template&lt;class T&gt; size_t JSHash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 1315423911; while (size_t ch = (size_t)*str++) &#123; hash ^= ((hash &lt;&lt; 5) + ch + (hash &gt;&gt; 2)); &#125; return hash; &#125; /// @brief DEK Function /// @detail 本算法是由于Donald E. Knuth在《Art Of Computer Programming Volume 3》中展示而得名。 template&lt;class T&gt; size_t DEKHash(const T* str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 1315423911; while (size_t ch = (size_t)*str++) &#123; hash = ((hash &lt;&lt; 5) ^ (hash &gt;&gt; 27)) ^ ch; &#125; return hash; &#125; /// @brief FNV Hash Function /// @detail Unix system系统中使用的一种著名hash算法，后来微软也在其hash_map中实现。 template&lt;class T&gt; size_t FNVHash(const T* str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 2166136261; while (size_t ch = (size_t)*str++) &#123; hash *= 16777619; hash ^= ch; &#125; return hash; &#125; /// @brief DJB Hash Function /// @detail 由Daniel J. Bernstein教授发明的一种hash算法。 template&lt;class T&gt; size_t DJBHash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 5381; while (size_t ch = (size_t)*str++) &#123; hash += (hash &lt;&lt; 5) + ch; &#125; return hash; &#125; /// @brief DJB Hash Function 2 /// @detail 由Daniel J. Bernstein 发明的另一种hash算法。 template&lt;class T&gt; size_t DJB2Hash(const T *str) &#123; if(!*str) // 这是由本人添加，以保证空字符串返回哈希值0 return 0; register size_t hash = 5381; while (size_t ch = (size_t)*str++) &#123; hash = hash * 33 ^ ch; &#125; return hash; &#125; /// @brief PJW Hash Function /// @detail 本算法是基于AT&amp;T贝尔实验室的Peter J. Weinberger的论文而发明的一种hash算法。 template&lt;class T&gt; size_t PJWHash(const T *str) &#123; static const size_t TotalBits = sizeof(size_t) * 8; static const size_t ThreeQuarters = (TotalBits * 3) / 4; static const size_t OneEighth = TotalBits / 8; static const size_t HighBits = ((size_t)-1) &lt;&lt; (TotalBits - OneEighth); register size_t hash = 0; size_t magic = 0; while (size_t ch = (size_t)*str++) &#123; hash = (hash &lt;&lt; OneEighth) + ch; if ((magic = hash &amp; HighBits) != 0) &#123; hash = ((hash ^ (magic &gt;&gt; ThreeQuarters)) &amp; (~HighBits)); &#125; &#125; return hash; &#125; /// @brief ELF Hash Function /// @detail 由于在Unix的Extended Library Function被附带而得名的一种hash算法，它其实就是PJW Hash的变形。 template&lt;class T&gt; size_t ELFHash(const T *str) &#123; static const size_t TotalBits = sizeof(size_t) * 8; static const size_t ThreeQuarters = (TotalBits * 3) / 4; static const size_t OneEighth = TotalBits / 8; static const size_t HighBits = ((size_t)-1) &lt;&lt; (TotalBits - OneEighth); register size_t hash = 0; size_t magic = 0; while (size_t ch = (size_t)*str++) &#123; hash = (hash &lt;&lt; OneEighth) + ch; if ((magic = hash &amp; HighBits) != 0) &#123; hash ^= (magic &gt;&gt; ThreeQuarters); hash &amp;= ~magic; &#125; &#125; return hash; &#125; 我对这些hash的散列质量及效率作了一个简单测试，测试结果如下： 测试1：对100000个由大小写字母与数字随机的ANSI字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 测试2：对100000个由任意UNICODE组成随机字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 测试3：对1000000个随机ANSI字符串（无重复，每个字符串最大长度不超过64字符）进行散列： 结论：也许是我的样本存在一些特殊性，在对ASCII码字符串进行散列时，PJW与ELF Hash（它们其实是同一种算法）无论是质量还是效率，都相当糟糕；例如：”b5”与“aE”，这两个字符串按照PJW散列出来的hash值就是一样的。 另外，其它几种依靠异或来散列的哈希函数，如：JS/DEK/DJB Hash，在对字母与数字组成的字符串的散列效果也不怎么好。相对而言，还是BKDR与SDBM这类简单的Hash效率与效果更好。 常用的字符串Hash函数还有ELFHash，APHash等等，都是十分简单有效的方法。这些函数使用位运算使得每一个字符都对最后的函数值产生 影响。另外还有以MD5和SHA1为代表的杂凑函数，这些函数几乎不可能找到碰撞。 常用字符串哈希函数有 BKDRHash，APHash，DJBHash，JSHash，RSHash，SDBMHash，PJWHash，ELFHash等等。对于以上几种哈 希函数，我对其进行了一个小小的评测。 其中数据1为100000个字母和数字组成的随机串哈希冲突个数。数据2为100000个有意义的英文句子哈希冲突个数。数据3为数据1的哈希值与 1000003(大素数)求模后存储到线性表中冲突的个数。数据4为数据1的哈希值与10000019(更大素数)求模后存储到线性表中冲突的个数。 经过比较，得出以上平均得分。平均数为平方平均数。可以发现，BKDRHash无论是在实际效果还是编码实现中，效果都是最突出的。APHash也 是较为优秀的算法。DJBHash,JSHash,RSHash与SDBMHash各有千秋。PJWHash与ELFHash效果最差，但得分相似，其算 法本质是相似的。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用的正则表达式]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%B8%B8%E7%94%A8%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[常用的正则表达式 校验数字的表达式12345678910111213141516171819数字：^[0-9]*$n位的数字：^\d&#123;n&#125;$至少n位的数字：^\d&#123;n,&#125;$m-n位的数字：^\d&#123;m,n&#125;$零和非零开头的数字：^(0|[1-9][0-9]*)$非零开头的最多带两位小数的数字：^([1-9][0-9]*)+(.[0-9]&#123;1,2&#125;)?$带1-2位小数的正数或负数：^(\-)?\d+(\.\d&#123;1,2&#125;)?$正数、负数、和小数：^(\-|\+)?\d+(\.\d+)?$有两位小数的正实数：^[0-9]+(.[0-9]&#123;2&#125;)?$有1~3位小数的正实数：^[0-9]+(.[0-9]&#123;1,3&#125;)?$非零的正整数：^[1-9]\d*$ 或 ^([1-9][0-9]*)&#123;1,3&#125;$ 或 ^\+?[1-9][0-9]*$非零的负整数：^\-[1-9][]0-9&quot;*$ 或 ^-[1-9]\d*$非负整数：^\d+$ 或 ^[1-9]\d*|0$非正整数：^-[1-9]\d*|0$ 或 ^((-\d+)|(0+))$非负浮点数：^\d+(\.\d+)?$ 或 ^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$非正浮点数：^((-\d+(\.\d+)?)|(0+(\.0+)?))$ 或 ^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$正浮点数：^[1-9]\d*\.\d*|0\.\d*[1-9]\d*$ 或 ^(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*))$负浮点数：^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$ 或 ^(-(([0-9]+\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\.[0-9]+)|([0-9]*[1-9][0-9]*)))$浮点数：^(-?\d+)(\.\d+)?$ 或 ^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$ 校验字符的表达式123456789101112汉字：^[\u4e00-\u9fa5]&#123;0,&#125;$英文和数字：^[A-Za-z0-9]+$ 或 ^[A-Za-z0-9]&#123;4,40&#125;$长度为3-20的所有字符：^.&#123;3,20&#125;$由26个英文字母组成的字符串：^[A-Za-z]+$由26个大写英文字母组成的字符串：^[A-Z]+$由26个小写英文字母组成的字符串：^[a-z]+$由数字和26个英文字母组成的字符串：^[A-Za-z0-9]+$由数字、26个英文字母或者下划线组成的字符串：^\w+$ 或 ^\w&#123;3,20&#125;$中文、英文、数字包括下划线：^[\u4E00-\u9FA5A-Za-z0-9_]+$中文、英文、数字但不包括下划线等符号：^[\u4E00-\u9FA5A-Za-z0-9]+$ 或 ^[\u4E00-\u9FA5A-Za-z0-9]&#123;2,20&#125;$可以输入含有^%&amp;&apos;,;=?$\&quot;等字符：[^%&amp;&apos;,;=?$\x22]+禁止输入含有~的字符：[^~\x22]+ 特殊需求表达式123456789101112131415161718192021222324252627282930313233Email地址：^\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*$域名：[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;(/.[a-zA-Z0-9][-a-zA-Z0-9]&#123;0,62&#125;)+/.?InternetURL：[a-zA-z]+://[^\s]* 或 ^http://([\w-]+\.)+[\w-]+(/[\w-./?%&amp;=]*)?$手机号码：^(13[0-9]|14[0-9]|15[0-9]|16[0-9]|17[0-9]|18[0-9]|19[0-9])\d&#123;8&#125;$ (由于工信部放号段不定时，所以建议使用泛解析 ^([1][3,4,5,6,7,8,9])\d&#123;9&#125;$)电话号码(&quot;XXX-XXXXXXX&quot;、&quot;XXXX-XXXXXXXX&quot;、&quot;XXX-XXXXXXX&quot;、&quot;XXX-XXXXXXXX&quot;、&quot;XXXXXXX&quot;和&quot;XXXXXXXX)：^(\(\d&#123;3,4&#125;-)|\d&#123;3.4&#125;-)?\d&#123;7,8&#125;$ 国内电话号码(0511-4405222、021-87888822)：\d&#123;3&#125;-\d&#123;8&#125;|\d&#123;4&#125;-\d&#123;7&#125; 18位身份证号码(数字、字母x结尾)：^((\d&#123;18&#125;)|([0-9x]&#123;18&#125;)|([0-9X]&#123;18&#125;))$帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]&#123;4,15&#125;$密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：^[a-zA-Z]\w&#123;5,17&#125;$强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\d)(?=.*[a-z])(?=.*[A-Z]).&#123;8,10&#125;$ 日期格式：^\d&#123;4&#125;-\d&#123;1,2&#125;-\d&#123;1,2&#125;一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式： 1.有四种钱的表示形式我们可以接受:&quot;10000.00&quot; 和 &quot;10,000.00&quot;, 和没有 &quot;分&quot; 的 &quot;10000&quot; 和 &quot;10,000&quot;：^[1-9][0-9]*$ 2.这表示任意一个不以0开头的数字,但是,这也意味着一个字符&quot;0&quot;不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 3.一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 4.这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：^[0-9]+(.[0-9]+)?$ 5.必须说明的是,小数点后面至少应该有1位数,所以&quot;10.&quot;是不通过的,但是 &quot;10&quot; 和 &quot;10.2&quot; 是通过的：^[0-9]+(.[0-9]&#123;2&#125;)?$ 6.这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：^[0-9]+(.[0-9]&#123;1,2&#125;)?$ 7.这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：^[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*(.[0-9]&#123;1,2&#125;)?$ 8.1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]&#123;1,3&#125;(,[0-9]&#123;3&#125;)*)(.[0-9]&#123;1,2&#125;)?$ 备注：这就是最终结果了,别忘了&quot;+&quot;可以用&quot;*&quot;替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$中文字符的正则表达式：[\u4e00-\u9fa5]双字节字符：[^\x00-\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1))空白行的正则表达式：\n\s*\r (可以用来删除空白行)HTML标记的正则表达式：&lt;(\S*?)[^&gt;]*&gt;.*?&lt;/\1&gt;|&lt;.*? /&gt; (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力)首尾空白字符的正则表达式：^\s*|\s*$或(^\s*)|(\s*$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式)腾讯QQ号：[1-9][0-9]&#123;4,&#125; (腾讯QQ号从10000开始)中国邮政编码：[1-9]\d&#123;5&#125;(?!\d) (中国邮政编码为6位数字)IP地址：\d+\.\d+\.\d+\.\d+ (提取IP地址时有用)IP地址：((?:(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d)\\.)&#123;3&#125;(?:25[0-5]|2[0-4]\\d|[01]?\\d?\\d))]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于按字寻址和按字节寻址的理解]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E6%8C%89%E5%AD%97%E5%AF%BB%E5%9D%80%E5%92%8C%E6%8C%89%E5%AD%97%E8%8A%82%E5%AF%BB%E5%9D%80%E7%9A%84%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/lishuhuakai/article/details/8934540 关于按字寻址和按字节寻址的理解 我们先从一道简单的问题说起！ 设有一个1MB容量的存储器，字长32位，问：按字节编址，字编址的寻址范围以及各自的寻址范围大小? 如果按字节编址，则 1MB = 2^20B 1字节=1B=8bit 2^20B/1B = 2^20 地址范围为0~(2^20)-1,也就是说需要二十根地址线才能完成对1MB空间的编码，所以地址寄存器为20位,寻址范围大小为2^20=1M 如果按字编址，则 1MB=2^20B 1字=32bit=4B 2^20B/4B = 2^18 地范围为0~2^18-1，也就是说我们至少要用18根地址线才能完成对1MB空间的编码。因此按字编址的寻址范围是2^18 以上题目注意几点： 区分寻址空间与寻址范围两个不同的概念，寻址范围仅仅是一个数字范围，不带有单位。而寻址范围的大小很明显是一个数，指寻址区间的大小；而寻址空间指能够寻址最大容量，单位一般用MB、B来表示；本题中寻址范围为0~(2^20)-1,寻址空间为1MB。 按字节寻址，指的是存储空间的最小编址单位是字节，按字编址，是指存储空间的最小编址单位是字，以上题为例，总的存储器容量是一定的，按字编址和按字节编址所需要的编码数量是不同的，按字编址由于编址单位比较大（1字=32bit=4B），从而编码较少，而按字节编址由于编码单位较小（1字节=1B=8bit），从而编码较多。 区别M和MB。 M为数量单位。1024=1K，1024K=1M MB指容量大小。1024B=1KB，1024KB=1MB. 想要搞清按字寻址和按字节寻址就要先搞清位、字节、字长、字的定义 ： 位：数据存储的最小单位。计算机中最小的数据单位，一个位的取值只能是0或1； 字节：由八位二进制数组成，是计算机中最基本的计量单位，也是最重要的计量单位（个人理解）。 字长：计算机中对CPU在单位时间内能处理的最大二进制数的位数叫做字长。 字：字是不同计算机系统中占据一个单独的地址(内存单元的编号)并作为一个单元(由一个或多个字节组合而成)处理的一组二进制数。 下面是我对于按字寻址和按字节寻址的理解： 按字节寻址：最通俗的理解就是一组地址线的每个不同状态对应一个字节的地址。比如说有24根地址线，按字节寻址，而且每根线有两个状态，那么24根地址线组成的地址信号就有2^24个不同状态，每个状态对应一个字节的地址空间的话，24根地址线的可寻址空间2^24B，即16MB。 按字寻址：最通俗的理解就是一组地址线的每个不同状态对应一个字的地址。因为字节是计算机中最基本的计量单位且一个字由若干字节构成，所以计算机在寻址过程中会区分字里面的字节，即会给字里面的字节编址，这样就会占用部分地址线。比如说有24根地址线，按字寻址，字长16位，16位即两个字节，这样就会占用一根地址线用来字内寻址，这样就剩下23根地址线，所以寻址范围是2^23W，即8MW，这里W是字长的意思。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于数据库缓存的若干问题]]></title>
    <url>%2F2019%2F04%2F11%2F%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%93%E5%AD%98%E7%9A%84%E8%8B%A5%E5%B9%B2%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[关于【缓存穿透、缓存击穿、缓存雪崩、热点数据失效】问题的解决方案 本文是某大佬的面试记录，扒过来学习 前言昨天晚上接到阿里的电面电话，过程中就问到了关于缓存相关的问题。 虽然以前接触过，多多少少了解了一些。但是之前自己并没有好好记录这些内容，在真正面试的时候，并没有回答得出来。今天记录一下，长长记性。 在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。 特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。 今天我们不牵涉多级缓存的知识，就把系统使用到的缓存方案，不管是一级还是多级的都统称为缓存，主要是为了讲述使用缓存的时候可能会遇到的一些问题以及一些解决办法。 我们使用缓存时，我们的业务系统大概的调用流程如下图： 当我们查询一条数据时，先去查询缓存，如果缓存有就直接返回，如果没有就去查询数据库，然后返回。这种情况下就可能会出现一些现象。 缓存穿透什么是缓存穿透正常情况下，我们去查询数据都是存在。那么请求去查询一条压根儿数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象我们称为缓存穿透。 穿透带来的问题试想一下，如果有黑客会对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库去查询。可能会导致你的数据库由于压力过大而宕掉。 解决办法缓存空值之所以会发生穿透，就是因为缓存中没有存储这些空数据的key。从而导致每次查询都到数据库去了。那么我们就可以为这些key对应的值设置为null 丢到缓存里面去。后面再出现查询这个key 的请求的时候，直接返回null 。这样，就不用在到数据库中去走一圈了，但是别忘了设置过期时间。 BloomFilterBloomFilter 类似于一个hbase set 用来判断某个元素（key）是否存在于某个集合中。这种方式在大数据场景应用比较多，比如 Hbase 中使用它去判断数据是否在磁盘上。还有在爬虫场景判断url 是否已经被爬取过。这种方案可以加在第一种方案中，在缓存之前在加一层 BloomFilter ，在查询的时候先去 BloomFilter 去查询 key 是否存在，如果不存在就直接返回，存在再走查缓存 -&gt; 查 DB。 流程图如下： 如何选择针对于一些恶意攻击，攻击带过来的大量key 是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据。此时我们采用第一种方案就不合适了，我们完全可以先对使用第二种方案进行过滤掉这些key。针对这种key异常多、请求重复率比较低的数据，我们就没有必要进行缓存，使用第二种方案直接过滤掉。而对于空数据的key有限的，重复率比较高的，我们则可以采用第一种方式进行缓存。 缓存击穿什么是击穿缓存击穿是我们可能遇到的第二个使用缓存方案可能遇到的问题。在平常高并发的系统中，大量的请求同时查询一个 key 时，此时这个key正好失效了，就会导致大量的请求都打到数据库上面去。这种现象我们称为缓存击穿。 会带来什么问题会造成某一时刻数据库请求量过大，压力剧增。 如何解决上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。 缓存雪崩什么是缓存雪崩缓存雪崩的情况是说，当某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上面。结果就是DB 称不住，挂掉。 解决办法事前：使用集群缓存，保证缓存服务的高可用。这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。 事中：ehcache本地缓存 + Hystrix限流&amp;降级,避免MySQL被打死。使用 ehcache 本地缓存的目的也是考虑在 Redis Cluster 完全不可用的时候，ehcache 本地缓存还能够支撑一阵。使用 Hystrix进行限流 &amp; 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。 事后：开启Redis持久化机制，尽快恢复缓存集群。一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。防止雪崩方案如下图所示： 解决热点数据集中失效问题我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效了。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库去，从而可能导致数据库崩溃的情况。 解决办法设置不同的失效时间为了避免这些热点的数据集中失效，那么我们在设置缓存过期时间的时候，我们让他们失效的时间错开。比如在一个基础的时间上加上或者减去一个范围内的随机值。 互斥锁结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。]]></content>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出全面解析RDMA]]></title>
    <url>%2F2019%2F04%2F11%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E5%85%A8%E9%9D%A2%E8%A7%A3%E6%9E%90RDMA%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/qq_21125183/article/details/80563463 RDMA(RemoteDirect Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。它将数据直接从一台计算机的内存传输到另一台计算机，无需双方操作系统的介入。这允许高吞吐、低延迟的网络通信，尤其适合在大规模并行计算机集群中使用。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理能力。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。 本次详解我们从三个方面详细介绍RDMA：RDMA背景、RDMA相关工作、RDMA技术详解。 背景介绍 传统TCP/IP通信模式传统的TCP/IP网络通信，数据需要通过用户空间发送到远程机器的用户空间。数据发送方需要讲数据从用户应用空间Buffer复制到内核空间的Socket Buffer中。然后Kernel空间中添加数据包头，进行数据封装。通过一系列多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。数据才被Push到NIC网卡中的Buffer进行网络传输。消息接受方接受从远程机器发送的数据包后，要将数据包从NIC buffer中复制数据到Socket Buffer。然后经过一些列的多层网络协议进行数据包的解析工作。解析后的数据被复制到相应位置的用户应用空间Buffer。这个时候再进行系统上下文切换，用户应用程序才被调用。以上就是传统的TCP/IP协议层的工作。 通信网络定义计算机网络通信中最重要两个衡量指标主要是指高带宽和低延迟。通信延迟主要是指：处理延迟和网络传输延迟。处理延迟开销指的就是消息在发送和接收阶段的处理时间。网络传输延迟指的就是消息在发送和接收方的网络传输时延。如果网络通信状况很好的情况下，网络基本上可以 达到高带宽和低延迟。 当今网络现状当今随着计算机网络的发展。消息通信主要分为两类消息，一类是Large messages，在这类消息通信中，网络传输延迟占整个通信中的主导位置。还有一类消息是Small messages，在这类消息通信中，消息发送端和接受端的处理开销占整个通信的主导地位。然而在现实计算机网络中的通信场景中，主要是以发送小消息为主。所有说发送消息和接受消息的处理开销占整个通信的主导的地位。具体来说，处理开销指的是buffer管理、在不同内存空间中消息复制、以及消息发送完成后的系统中断。 传统TCP/IP存在的问题传统的TPC/IP存在的问题主要是指I/O bottleneck瓶颈问题。在高速网络条件下与网络I/O相关的主机处理的高开销限制了可以在机器之间发送的带宽。这里感兴趣的高额开销是数据移动操作和复制操作。具体来讲，主要是传统的TCP/IP网络通信是通过内核发送消息。Messaging passing through kernel这种方式会导致很低的性能和很低的灵活性。性能低下的原因主要是由于网络通信通过内核传递，这种通信方式存在的很高的数据移动和数据复制的开销。并且现如今内存带宽性相较如CPU带宽和网络带宽有着很大的差异。很低的灵活性的原因主要是所有网络通信协议通过内核传递，这种方式很难去支持新的网络协议和新的消息通信协议以及发送和接收接口。 相关工作高性能网络通信历史发展主要有以下四个方面：TCP Offloading Engine（TOE）、User-Net Networking(U-Net)、Virtual interface Architecture（VIA）、Remote Direct Memroy Access(RDMA)。U-Net是第一个跨过内核网络通信的模式之一。VIA首次提出了标准化user-level的网络通信模式，其次它组合了U-Net接口和远程DMA设备。RDMA就是现代化高性能网络通信技术。 TCP Offloading Engine在主机通过网络进行通信的过程中，主机处理器需要耗费大量资源进行多层网络协议的数据包处理工作，这些协议包括传输控制协议（TCP）、用户数据报协议（UDP）、互联网协议（IP）以及互联网控制消息协议（ICMP）等。由于CPU需要进行繁重的封装网络数据包协议，为了将占用的这部分主机处理器资源解放出来专注于其他应用，人们发明了TOE（TCP/IP Offloading Engine）技术，将上述主机处理器的工作转移到网卡上。 这种技术需要特定网络接口-网卡支持这种Offloading操作。这种特定网卡能够支持封装多层网络协议的数据包，这个功能常见于高速以太网接口上，如吉比特以太网（GbE）或10吉比特以太网（10GbE）。 User-Net Networking(U-Net)U-Net的设计目标是将协议处理部分移动到用户空间去处理。这种方式避免了用户空间将数据移动和复制到内核空间的开销。它的设计宗旨就是移动整个协议栈到用户空间中去，并且从数据通信路径中彻底删除内核。这种设计带来了高性能的提升和高灵活性的提升。 U-Net的virtual NI 为每个进程提供了一种拥有网络接口的错觉，内核接口只涉及到连接步骤。传统上的网络，内核控制整个网络通信，所有的通信都需要通过内核来传递。U-Net应用程序可以通过MUX直接访问网络，应用程序通过MUX直接访问内核，而不需要将数据移动和复制到内核空间中去。 RDMA详解RDMA(Remote Direct Memory Access)技术全称远程直接内存访问，就是为了解决网络传输中服务器端数据处理的延迟而产生的。RDMA通过网络把资料直接传入计算机的存储区，将数据从一个系统快速移动到远程系统存储器中，而不对操作系统造成任何影响，这样就不需要用到多少计算机的处理功能。它消除了外部存储器复制和上下文切换的开销，因而能解放内存带宽和CPU周期用于改进应用系统性能。 RDMA主要有以下三个特性：1.Low-Latency 2.Low CPU overhead 3. high bandwidth RDMA 简介Remote：数据通过网络与远程机器间进行数据传输 Direct：没有内核的参与，有关发送传输的所有内容都卸载到网卡上 Memory：在用户空间虚拟内存与RNIC网卡直接进行数据传输不涉及到系统内核，没有额外的数据移动和复制 Access：send、receive、read、write、atomic操作 RDMA基本概念RDMA有两种基本操作。 Memory verbs: 包括RDMA read、write和atomic操作。这些操作指定远程地址进行操作并且绕过接收者的CPU。 Messaging verbs:包括RDMA send、receive操作。这些动作涉及响应者的CPU，发送的数据被写入由响应者的CPU先前发布的接受所指定的地址。 RDMA传输分为可靠和不可靠的，并且可以连接和不连接的（数据报）。凭借可靠的传输，NIC使用确认来保证消息的按序传送。不可靠的传输不提供这样的保证。然而，像InfiniBand这样的现代RDMA实现使用了一个无损链路层，它可以防止使用链路层流量控制的基于拥塞的损失，以及使用链路层重传的基于位错误的损失。因此，不可靠的传输很少会丢弃数据包。 目前的RDMA硬件提供一种数据报传输：不可靠的数据报（UD），并且不支持memory verbs。 RDMA三种不同的硬件实现目前RDMA有三种不同的硬件实现。分别是InfiniBand、iWarp（internet Wide Area RDMA Protocol）、RoCE(RDMA over Converged Ethernet)。 目前，大致有三类RDMA网络，分别是Infiniband、RoCE、iWARP。其中，Infiniband是一种专为RDMA设计的网络，从硬件级别保证可靠传输 ， 而RoCE 和 iWARP都是基于以太网的RDMA技术，支持相应的verbs接口，如图1所示。从图中不难发现，RoCE协议存在RoCEv1和RoCEv2两个版本，主要区别RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，而RoCEv2是以太网TCP/IP协议中UDP层实现。从性能上，很明显Infiniband网络最好，但网卡和交换机是价格也很高，然而RoCEv2和iWARP仅需使用特殊的网卡就可以了，价格也相对便宜很多。 Infiniband，支持RDMA的新一代网络协议。 由于这是一种新的网络技术，因此需要支持该技术的NIC和交换机。 RoCE，一个允许在以太网上执行RDMA的网络协议。 其较低的网络标头是以太网标头，其较高的网络标头（包括数据）是InfiniBand标头。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，支持RoCE。 iWARP，一个允许在TCP上执行RDMA的网络协议。 IB和RoCE中存在的功能在iWARP中不受支持。 这支持在标准以太网基础设施（交换机）上使用RDMA。 只有网卡应该是特殊的，并且支持iWARP（如果使用CPU卸载），否则所有iWARP堆栈都可以在SW中实现，并且丧失了大部分RDMA性能优势。 RDMA技术 传统上的RDMA技术设计内核封装多层网络协议并且涉及内核数据传输。RDMA通过专有的RDMA网卡RNIC，绕过内核直接从用户空间访问RDMA enabled NIC网卡。RDMA提供一个专有的verbs interface而不是传统的TCP/IP Socket interface。要使用RDMA首先要建立从RDMA到应用程序内存的数据路径 ，可以通过RDMA专有的verbs interface接口来建立这些数据路径，一旦数据路径建立后，就可以直接访问用户空间buffer。 RDMA整体系统架构图 上诉介绍的是RDMA整体框架架构图。从图中可以看出，RDMA在应用程序用户空间，提供了一系列verbs interface接口操作RDMA硬件。RDMA绕过内核直接从用户空间访问RDMA 网卡(RNIC)。RNIC网卡中包括Cached Page Table Entry，页表就是用来将虚拟页面映射到相应的物理页面。 RDMA技术详解RDMA 的工作过程如下: 当一个应用执行RDMA 读或写请求时，不执行任何数据复制.在不需要任何内核内存参与的条件下，RDMA 请求从运行在用户空间中的应用中发送到本地NIC( 网卡)。 NIC 读取缓冲的内容，并通过网络传送到远程NIC。 在网络上传输的RDMA 信息包含目标虚拟地址、内存钥匙和数据本身.请求既可以完全在用户空间中处理(通过轮询用户级完成排列) ，又或者在应用一直睡眠到请求完成时的情况下通过系统中断处理.RDMA 操作使应用可以从一个远程应用的内存中读数据或向这个内存写数据。 目标NIC 确认内存钥匙，直接将数据写人应用缓存中.用于操作的远程虚拟内存地址包含在RDMA 信息中。 RDMA操作细节RDMA提供了基于消息队列的点对点通信，每个应用都可以直接获取自己的消息，无需操作系统和协议栈的介入。 消息服务建立在通信双方本端和远端应用之间创建的Channel-IO连接之上。当应用需要通信时，就会创建一条Channel连接，每条Channel的首尾端点是两对Queue Pairs（QP）。每对QP由Send Queue（SQ）和Receive Queue（RQ）构成，这些队列中管理着各种类型的消息。QP会被映射到应用的虚拟地址空间，使得应用直接通过它访问RNIC网卡。除了QP描述的两种基本队列之外，RDMA还提供一种队列Complete Queue（CQ），CQ用来知会用户WQ上的消息已经被处理完。 RDMA提供了一套软件传输接口，方便用户创建传输请求Work Request(WR），WR中描述了应用希望传输到Channel对端的消息内容，WR通知QP中的某个队列Work Queue(WQ)。在WQ中，用户的WR被转化为Work Queue Element（WQE）的格式，等待RNIC的异步调度解析，并从WQE指向的Buffer中拿到真正的消息发送到Channel对端。 RDAM单边操作 (RDMA READ)READ和WRITE是单边操作，只需要本端明确信息的源和目的地址，远端应用不必感知此次通信，数据的读或写都通过RDMA在RNIC与应用Buffer之间完成，再由远端RNIC封装成消息返回到本端。 对于单边操作，以存储网络环境下的存储为例，数据的流程如下： 首先A、B建立连接，QP已经创建并且初始化。 数据被存档在B的buffer地址VB，注意VB应该提前注册到B的RNIC (并且它是一个Memory Region) ，并拿到返回的local key，相当于RDMA操作这块buffer的权限。 B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。 A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身存储地址VA到封装RDMA READ请求，将这个消息请求发送给B，这个过程A、B两端不需要任何软件参与，就可以将B的数据存储到A的VA虚拟地址。 A在存储完成后，会向B返回整个数据传输的状态信息。 单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。 RDMA 单边操作 (RDMA WRITE)对于单边操作，以存储网络环境下的存储为例，数据的流程如下： 首先A、B建立连接，QP已经创建并且初始化。 数据remote目标存储buffer地址VB，注意VB应该提前注册到B的RNIC(并且它是一个Memory Region)，并拿到返回的local key，相当于RDMA操作这块buffer的权限。 B把数据地址VB，key封装到专用的报文传送到A，这相当于B把数据buffer的操作权交给了A。同时B在它的WQ中注册进一个WR，以用于接收数据传输的A返回的状态。 A在收到B的送过来的数据VB和R_key后，RNIC会把它们连同自身发送地址VA到封装RDMA WRITE请求，这个过程A、B两端不需要任何软件参与，就可以将A的数据发送到B的VB虚拟地址。 A在发送数据完成后，会向B返回整个数据传输的状态信息。 单边操作传输方式是RDMA与传统网络传输的最大不同，只需提供直接访问远程的虚拟地址，无须远程应用的参与其中，这种方式适用于批量数据传输。 RDMA 双边操作 (RDMA SEND/RECEIVE)RDMA中SEND/RECEIVE是双边操作，即必须要远端的应用感知参与才能完成收发。在实际中，SEND/RECEIVE多用于连接控制类报文，而数据报文多是通过READ/WRITE来完成的。对于双边操作为例，主机A向主机B(下面简称A、B)发送数据的流程如下： 首先，A和B都要创建并初始化好各自的QP，CQ A和B分别向自己的WQ中注册WQE，对于A，WQ=SQ，WQE描述指向一个等到被发送的数据；对于B，WQ=RQ，WQE描述指向一块用于存储数据的Buffer。 A的RNIC异步调度轮到A的WQE，解析到这是一个SEND消息，从Buffer中直接向B发出数据。数据流到达B的RNIC后，B的WQE被消耗，并把数据直接存储到WQE指向的存储位置。 AB通信完成后，A的CQ中会产生一个完成消息CQE表示发送完成。与此同时，B的CQ中也会产生一个完成消息表示接收完成。每个WQ中WQE的处理完成都会产生一个CQE。 双边操作与传统网络的底层Buffer Pool类似，收发双方的参与过程并无差别，区别在零拷贝、Kernel Bypass，实际上对于RDMA，这是一种复杂的消息传输模式，多用于传输短的控制消息。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中的string]]></title>
    <url>%2F2019%2F04%2F10%2Fcpp%E4%B8%AD%E7%9A%84string%2F</url>
    <content type="text"><![CDATA[标准C++中的string类的用法总结 相信使用过MFC编程的朋友对CString这个类的印象应该非常深刻吧？的确，MFC中的CString类使用起来真的非常的方便好用。但是如果离开了MFC框架，还有没有这样使用起来非常方便的类呢？答案是肯定的。也许有人会说，即使不用MFC框架，也可以想办法使用MFC中的API，具体的操作方法在本文最后给出操作方法。其实，可能很多人很可能会忽略掉标准C++中string类的使用。标准C++中提供的string类得功能也是非常强大的，一般都能满足我们开发项目时使用。现将具体用法的一部分罗列如下，只起一个抛砖引玉的作用吧，好了，废话少说，直接进入正题吧！ 要想使用标准C++中string类，必须要包含12345#include &lt;string&gt;// 注意是&lt;string&gt;，不是&lt;string.h&gt;，带.h的是C语言中的头文件using std::string;using std::wstring; 或1using namespace std; 下面你就可以使用string/wstring了，它们两分别对应着char和wchar_t。 string和wstring的用法是一样的，以下只用string作介绍： string类的构造函数：string(const char *s); //用c字符串s初始化string(int n,char c); //用n个字符c初始化此外，string类还支持默认构造函数和复制构造函数，如string s1；string s2=”hello”；都是正确的写法。当构造的string太长而无法表达时会抛出length_error异常 ； string类的字符操作：const char &amp;operatorconst;const char &amp;at(int n)const;char &amp;operator;char &amp;at(int n);operator[]和at()均返回当前字符串中第n个字符的位置，但at函数提供范围检查，当越界时会抛出out_of_range异常，下标运算符[]不提供检查访问。const char data()const;//返回一个非null终止的c字符数组const char c_str()const;//返回一个以null终止的c字符串int copy(char *s, int n, int pos = 0) const;//把当前串中以pos开始的n个字符拷贝到以s为起始位置的字符数组中，返回实际拷贝的数目 string的特性描述:int capacity()const; //返回当前容量（即string中不必增加内存即可存放的元素个数）int max_size()const; //返回string对象中可存放的最大字符串的长度int size()const; //返回当前字符串的大小int length()const; //返回当前字符串的长度bool empty()const; //当前字符串是否为空void resize(int len,char c);//把字符串当前大小置为len，并用字符c填充不足的部分 string类的输入输出操作:string类重载运算符operator&gt;&gt;用于输入，同样重载运算符operator&lt;&lt;用于输出操作。函数getline(istream &amp;in,string &amp;s);用于从输入流in中读取字符串到s中，以换行符’\n’分开。 string的赋值：string &amp;operator=(const string &amp;s);//把字符串s赋给当前字符串string &amp;assign(const char s);//用c类型字符串s赋值string &amp;assign(const char s,int n);//用c字符串s开始的n个字符赋值string &amp;assign(const string &amp;s);//把字符串s赋给当前字符串string &amp;assign(int n,char c);//用n个字符c赋值给当前字符串string &amp;assign(const string &amp;s,int start,int n);//把字符串s中从start开始的n个字符赋给当前字符串string &amp;assign(const_iterator first,const_itertor last);//把first和last迭代器之间的部分赋给字符串 string的连接：string &amp;operator+=(const string &amp;s);//把字符串s连接到当前字符串的结尾string &amp;append(const char s); //把c类型字符串s连接到当前字符串结尾string &amp;append(const char s,int n);//把c类型字符串s的前n个字符连接到当前字符串结尾string &amp;append(const string &amp;s); //同operator+=()string &amp;append(const string &amp;s,int pos,int n);//把字符串s中从pos开始的n个字符连接到当前字符串的结尾string &amp;append(int n,char c); //在当前字符串结尾添加n个字符cstring &amp;append(const_iterator first,const_iterator last);//把迭代器first和last之间的部分连接到当前字符串的结尾 string的比较：bool operator==(const string &amp;s1,const string &amp;s2)const;//比较两个字符串是否相等运算符”&gt;”,”&lt;”,”&gt;=”,”&lt;=”,”!=”均被重载用于字符串的比较；int compare(const string &amp;s) const;//比较当前字符串和s的大小int compare(int pos, int n,const string &amp;s)const;//比较当前字符串从pos开始的n个字符组成的字符串与s的大小int compare(int pos, int n,const string &amp;s,int pos2,int n2)const;//比较当前字符串从pos开始的n个字符组成的字符串与s中 //pos2开始的n2个字符组成的字符串的大小int compare(const char s) const;int compare(int pos, int n,const char s) const;int compare(int pos, int n,const char *s, int pos2) const;compare函数在&gt;时返回1，&lt;时返回-1，==时返回0 string的子串：string substr(int pos = 0,int n = npos) const;//返回pos开始的n个字符组成的字符串 string的交换：void swap(string &amp;s2); //交换当前字符串与s2的值 string类的查找函数：int find(char c, int pos = 0) const;//从pos开始查找字符c在当前字符串的位置int find(const char s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置int find(const char s, int pos, int n) const;//从pos开始查找字符串s中前n个字符在当前串中的位置int find(const string &amp;s, int pos = 0) const;//从pos开始查找字符串s在当前串中的位置//查找成功时返回所在位置，失败返回string::npos的值int rfind(char c, int pos = npos) const;//从pos开始从后向前查找字符c在当前串中的位置int rfind(const char s, int pos = npos) const;int rfind(const char s, int pos, int n = npos) const;int rfind(const string &amp;s,int pos = npos) const;//从pos开始从后向前查找字符串s中前n个字符组成的字符串在当前串中的位置，成功返回所在位置，失败时返回string::npos的值int find_first_of(char c, int pos = 0) const;//从pos开始查找字符c第一次出现的位置int find_first_of(const char s, int pos = 0) const;int find_first_of(const char s, int pos, int n) const;int find_first_of(const string &amp;s,int pos = 0) const;//从pos开始查找当前串中第一个在s的前n个字符组成的数组里的字符的位置。查找失败返回string::nposint find_first_not_of(char c, int pos = 0) const;int find_first_not_of(const char s, int pos = 0) const;int find_first_not_of(const char s, int pos,int n) const;int find_first_not_of(const string &amp;s,int pos = 0) const;//从当前串中查找第一个不在串s中的字符出现的位置，失败返回string::nposint find_last_of(char c, int pos = npos) const;int find_last_of(const char s, int pos = npos) const;int find_last_of(const char s, int pos, int n = npos) const;int find_last_of(const string &amp;s,int pos = npos) const;int find_last_not_of(char c, int pos = npos) const;int find_last_not_of(const char s, int pos = npos) const;int find_last_not_of(const char s, int pos, int n) const;int find_last_not_of(const string &amp;s,int pos = npos) const;//find_last_of和find_last_not_of与find_first_of和find_first_not_of相似，只不过是从后向前查找 string类的替换函数：string &amp;replace(int p0, int n0,const char s);//删除从p0开始的n0个字符，然后在p0处插入串sstring &amp;replace(int p0, int n0,const char s, int n);//删除p0开始的n0个字符，然后在p0处插入字符串s的前n个字符string &amp;replace(int p0, int n0,const string &amp;s);//删除从p0开始的n0个字符，然后在p0处插入串sstring &amp;replace(int p0, int n0,const string &amp;s, int pos, int n);//删除p0开始的n0个字符，然后在p0处插入串s中从pos开始的n个字符string &amp;replace(int p0, int n0,int n, char c);//删除p0开始的n0个字符，然后在p0处插入n个字符cstring &amp;replace(iterator first0, iterator last0,const char s);//把[first0，last0）之间的部分替换为字符串sstring &amp;replace(iterator first0, iterator last0,const char s, int n);//把[first0，last0）之间的部分替换为s的前n个字符string &amp;replace(iterator first0, iterator last0,const string &amp;s);//把[first0，last0）之间的部分替换为串sstring &amp;replace(iterator first0, iterator last0,int n, char c);//把[first0，last0）之间的部分替换为n个字符cstring &amp;replace(iterator first0, iterator last0,const_iterator first, const_iterator last);//把[first0，last0）之间的部分替换成[first，last）之间的字符串 string类的插入函数：string &amp;insert(int p0, const char s);string &amp;insert(int p0, const char s, int n);string &amp;insert(int p0,const string &amp;s);string &amp;insert(int p0,const string &amp;s, int pos, int n);//前4个函数在p0位置插入字符串s中pos开始的前n个字符string &amp;insert(int p0, int n, char c);//此函数在p0处插入n个字符citerator insert(iterator it, char c);//在it处插入字符c，返回插入后迭代器的位置void insert(iterator it, const_iterator first, const_iterator last);//在it处插入[first，last）之间的字符void insert(iterator it, int n, char c);//在it处插入n个字符c string类的删除函数iterator erase(iterator first, iterator last);//删除[first，last）之间的所有字符，返回删除后迭代器的位置iterator erase(iterator it);//删除it指向的字符，返回删除后迭代器的位置string &amp;erase(int pos = 0, int n = npos);//删除pos开始的n个字符，返回修改后的字符串 string类的迭代器处理：string类提供了向前和向后遍历的迭代器iterator，迭代器提供了访问各个字符的语法，类似于指针操作，迭代器不检查范围。用string::iterator或string::const_iterator声明迭代器变量，const_iterator不允许改变迭代的内容。常用迭代器函数有：const_iterator begin()const;iterator begin(); //返回string的起始位置const_iterator end()const;iterator end(); //返回string的最后一个字符后面的位置const_iterator rbegin()const;iterator rbegin(); //返回string的最后一个字符的位置const_iterator rend()const;iterator rend(); //返回string第一个字符位置的前面rbegin和rend用于从后向前的迭代访问，通过设置迭代器string::reverse_iterator,string::const_reverse_iterator实现 字符串流处理：通过定义ostringstream和istringstream变量实现，#include 头文件中例如： string input(“hello,this is a test”); istringstream is(input); string s1,s2,s3,s4; is&gt;&gt;s1&gt;&gt;s2&gt;&gt;s3&gt;&gt;s4;//s1=”hello,this”,s2=”is”,s3=”a”,s4=”test” ostringstream os; os&lt;&lt;s1&lt;&lt;s2&lt;&lt;s3&lt;&lt;s4; cout&lt;&lt;os.str(); 以上就是对C++ string类的一个简要介绍。 string特性描述可用下列函数来获得string的一些特性： int capacity()const; //返回当前容量（即string中不必增加内存即可存放的元素个数）int max_size()const; //返回string对象中可存放的最大字符串的长度int size()const; //返回当前字符串的大小int length()const; //返回当前字符串的长度bool empty()const; //当前字符串是否为空void resize(int len,char c); //把字符串当前大小置为len，多去少补，多出的字符c填充不足的部分测试代码：12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str; if (str.empty()) cout&lt;&lt;&quot;str is NULL.&quot;&lt;&lt;endl; else cout&lt;&lt;&quot;str is not NULL.&quot;&lt;&lt;endl; str = str + &quot;abcdefg&quot;; cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s size is &quot;&lt;&lt;str.size()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s capacity is &quot;&lt;&lt;str.capacity()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s max size is &quot;&lt;&lt;str.max_size()&lt;&lt;endl; cout&lt;&lt;&quot;str&apos;s length is &quot;&lt;&lt;str.length()&lt;&lt;endl; str.resize(20,&apos;c&apos;); cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; str.resize(5); cout&lt;&lt;&quot;str is &quot;&lt;&lt;str&lt;&lt;endl; return 0;&#125; string的查找由于查找是使用最为频繁的功能之一，string提供了非常丰富的查找函数：（注：string::npos） size_type find( const basic_string &amp;str, size_type index ); //返回str在字符串中第一次出现的位置（从index开始查找），如果没找到则返回string::npos size_type find( const char *str, size_type index ); // 同上 size_type find( const char *str, size_type index, size_type length ); //返回str在字符串中第一次出现的位置（从index开始查找，长度为length），如果没找到就返回string::npos size_type find( char ch, size_type index ); // 返回字符ch在字符串中第一次出现的位置（从index开始查找），如果没找到就返回string::npos 注意：查找字符串a是否包含子串b,不是用 strA.find(strB) &gt; 0 而是 strA.find(strB) != string:npos 这是为什么呢？（初学者比较容易犯的一个错误）本部分参考自web100与luhao1993 先看下面的代码12int idx = str.find(&quot;abc&quot;);if (idx == string::npos); 上述代码中，idx的类型被定义为int，这是错误的，即使定义为unsigned int 也是错的，它必须定义为 string::size_type。npos 是这样定义的： static const size_type npos = -1; 因为 string::size_type (由字符串配置器 allocator 定义) 描述的是 size，故需为无符号整数型别。因为缺省配置器以型别 size_t 作为 size_type，于是 -1 被转换为无符号整数型别，npos 也就成了该型别的最大无符号值。不过实际数值还是取决于型别 size_type 的实际定义。不幸的是这些最大值都不相同。事实上，(unsigned long)-1 和 (unsigned short)-1 不同(前提是两者型别大小不同)。因此，比较式 idx == string::npos 中，如果 idx 的值为-1，由于 idx 和字符串string::npos 型别不同，比较结果可能得到 false。因此要想判断 find()等查找函数的结果是否为npos，最好的办法是直接比较。 测试代码：1234567891011121314151617181920#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;int main()&#123; int loc; string s=&quot;study hard and make progress everyday! every day!!&quot;; loc=s.rfind(&quot;make&quot;,10); cout&lt;&lt;&quot;the word make is at index&quot;&lt;&lt;loc&lt;&lt;endl;//-1表示没找到 loc=s.rfind(&quot;make&quot;);//缺省状态下，从最后一个往前找 cout&lt;&lt;&quot;the word make is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_first_of(&quot;day&quot;); cout&lt;&lt;&quot;the word day(first) is at index &quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_first_not_of(&quot;study&quot;); cout&lt;&lt;&quot;the first word not of study is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find_last_of(&quot;day&quot;); cout&lt;&lt;&quot;the last word of day is at index&quot;&lt;&lt;loc&lt;&lt;endl; loc=s.find(&quot;day&quot;);//缺陷状态下从第一个往后找 cout&lt;&lt;loc; return 0;&#125; 运行结果： 其他常用函数string &amp;insert(int p,const string &amp;s); //在p位置插入字符串sstring &amp;replace(int p, int n,const char *s); //删除从p开始的n个字符，然后在p处插入串sstring &amp;erase(int p, int n); //删除p开始的n个字符，返回修改后的字符串string substr(int pos = 0,int n = npos) const; //返回pos开始的n个字符组成的字符串void swap(string &amp;s2); //交换当前字符串与s2的值string &amp;append(const char *s); //把字符串s连接到当前字符串结尾void push_back(char c) //当前字符串尾部加一个字符cconst char *data()const; //返回一个非null终止的c字符数组，data():与c_str()类似，用于string转const char*其中它返回的数组是不以空字符终止,const char *c_str()const; //返回一个以null终止的c字符串，即c_str()函数返回一个指向正规C字符串的指针, 内容与本string串相同,用于string转const char*测试代码：123456789101112131415161718192021#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str1 = &quot;abc123defg&quot;; string str2 = &quot;swap!&quot;; cout&lt;&lt;str1&lt;&lt;endl; cout&lt;&lt;str1.erase(3,3)&lt;&lt;endl; //从索引3开始的3个字符,即删除掉了&quot;123&quot; cout&lt;&lt;str1.insert(0,&quot;123&quot;)&lt;&lt;endl; //在头部插入 cout&lt;&lt;str1.append(&quot;123&quot;)&lt;&lt;endl; //append()方法可以添加字符串 str1.push_back(&apos;A&apos;); //push_back()方法只能添加一个字符 cout&lt;&lt;str1&lt;&lt;endl; cout&lt;&lt;str1.replace(0,3,&quot;hello&quot;)&lt;&lt;endl; //即将索引0开始的3个字符替换成&quot;hello&quot; cout&lt;&lt;str1.substr(5,7)&lt;&lt;endl; //从索引5开始7个字节 str1.swap(str2); cout&lt;&lt;str1&lt;&lt;endl; const char* p = str.c_str(); printf(&quot;%s\n&quot;,p); return 0;&#125; 程序执行结果为：1234567891011121314151617abc123defgabcdefg123abcdefg123abcdefg123123abcdefg123Ahelloabcdefg123Aabcdefgswap!swap!]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中的map]]></title>
    <url>%2F2019%2F04%2F10%2Fcpp%E4%B8%AD%E7%9A%84map%2F</url>
    <content type="text"><![CDATA[原文：https://blog.csdn.net/google19890102/article/details/51720305 标准库map类型是一种以键-值(key-value)存储的数据类型。 第一个可以称为关键字(key)，每个关键字只能在map中出现一次； 第二个可能称为该关键字的值(value)； map以模板(泛型)方式实现，可以存储任意类型的数据，包括使用者自定义的数据类型。Map主要用于资料一对一映射(one-to-one)的情況，map內部的实现自建一颗红黑树，这颗树具有对数据自动排序的功能。在map内部所有的数据都是有序的。 以下分别从以下的几个方面总结： map对象的定义和初始化 map对象的基本操作，主要包括添加元素，遍历等 pair类型pair类型的定义和初始化pair类型是在有文件utility中定义的，pair类型包含了两个数据值，通常有以下的一些定义和初始化的一些方法：123pair&lt;T1, T2&gt; p;pair&lt;T1, T2&gt; p(v1, v2);make_pair(v1, v2) 上述第一种方法是定义了一个空的pair对象p，第二种方法是定义了包含初始值为v1和v2的pair对象p。第三种方法是以v1和v2值创建的一个新的pair对象。 pair对象的一些操作除此之外，pair对象还有一些方法，如取出pair对象中的每一个成员的值：12p.firstp.second 一个例子：12345678910111213#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;string&gt;#include &lt;utility&gt;using namespace std;int main()&#123; pair&lt;int, string&gt; p1(0, &quot;Hello&quot;); printf(&quot;%d, %s\n&quot;, p1.first, p1.second.c_str()); pair&lt;int, string&gt; p2 = make_pair(1, &quot;World&quot;); printf(&quot;%d, %s\n&quot;, p2.first, p2.second.c_str()); return 0;&#125; map对象的定义和初始化map是键-值对的组合，有以下的一些定义的方法：123map&lt;k, v&gt; m;map&lt;k, v&gt; m(m2);map&lt;k, v&gt; m(b, e); 上述第一种方法定义了一个名为m的空的map对象；第二种方法创建了m2的副本m；第三种方法创建了map对象m，并且存储迭代器b和e范围内的所有元素的副本。 map的value_type是存储元素的键以及值的pair类型，键为const。 使用map得包含map类所在的头文件1#include &lt;map&gt; //注意，STL头文件没有扩展名.h map对象是模板类，需要关键字和存储对象两个模板参数：1std:map&lt;int, string&gt; personnel; 这样就定义了一个用int作为索引,并拥有相关联的指向string的指针. 为了使用方便，可以对模板类进行一下类型定义，1typedef aap&lt;int,CString&gt; UDT_MAP_INT_CSTRING; map共提供了6个构造函数，这块涉及到内存分配器这些东西，略过不表，在下面我们将接触到一些map的构造方法，这里要说下的就是，我们通常用如下方法构造一个map：1map&lt;int, string&gt; mapStudent; map对象的一些基本操作map中元素的插入在map中元素有两种插入方法： 使用下标 使用insert函数 在map中使用下标访问不存在的元素将导致在map容器中添加一个新的元素。 insert函数的插入方法主要有如下： m.insert(e) m.insert(beg, end) m.insert(iter, e) 上述的e一个value_type类型的值。beg和end标记的是迭代器的开始和结束。 两种插入方法如下面的例子所示：123456789101112131415161718#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 10; i ++)&#123; mp[i] = i; &#125; for (int i = 10; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d--&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; 另外的方法：12345678910111213// 定义一个map对象map&lt;int, string&gt; mapStudent; // 第一种 用insert函數插入pairmapStudent.insert(pair&lt;int, string&gt;(000, &quot;student_zero&quot;)); // 第二种 用insert函数插入value_type数据mapStudent.insert(map&lt;int, string&gt;::value_type(001, &quot;student_one&quot;)); // 第三种 用&quot;array&quot;方式插入mapStudent[123] = &quot;student_first&quot;;mapStudent[456] = &quot;student_second&quot;; 以上三种用法，虽然都可以实现数据的插入，但是它们是有区别的，当然了第一种和第二种在效果上是完成一样的，用insert函数插入数据，在数据的 插入上涉及到集合的唯一性这个概念，即当map中有这个关键字时，insert操作是不能在插入数据的，但是用数组方式就不同了，它可以覆盖以前该关键字对 应的值，用程序说明如下：12mapStudent.insert(map&lt;int, string&gt;::value_type (001, &quot;student_one&quot;));mapStudent.insert(map&lt;int, string&gt;::value_type (001, &quot;student_two&quot;)); map中元素的查找和读取注意：上述采用下标的方法读取map中元素时，若map中不存在该元素，则会在map中插入。 因此，若只是查找该元素是否存在，可以使用函数count(k)，该函数返回的是k出现的次数；若是想取得key对应的值，可以使用函数find(k)，该函数返回的是指向该元素的迭代器。 上述的两个函数的使用如下所示：123456789101112131415161718192021222324252627282930#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; if (mp.count(0))&#123; printf(&quot;yes!\n&quot;); &#125;else&#123; printf(&quot;no!\n&quot;); &#125; map&lt;int, int&gt;::iterator it_find; it_find = mp.find(0); if (it_find != mp.end())&#123; it_find-&gt;second = 20; &#125;else&#123; printf(&quot;no!\n&quot;); &#125; map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d-&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; 从map中删除元素从map中删除元素的函数是erase()，该函数有如下的三种形式： m.erase(k)m.erase(p)m.erase(b, e)第一种方法删除的是m中键为k的元素，返回的是删除的元素的个数；第二种方法删除的是迭代器p指向的元素，返回的是void；第三种方法删除的是迭代器b和迭代器e范围内的元素，返回void。 如下所示：12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123; map&lt;int, int&gt; mp; for (int i = 0; i &lt; 20; i++)&#123; mp.insert(make_pair(i, i)); &#125; mp.erase(0); mp.erase(mp.begin()); map&lt;int, int&gt;::iterator it; for (it = mp.begin(); it != mp.end(); it++)&#123; printf(&quot;%d-&gt;%d\n&quot;, it-&gt;first, it-&gt;second); &#125; return 0;&#125; map的基本操作函数：C++ maps是一种关联式容器，包含“关键字/值”对 begin() 返回指向map头部的迭代器clear() 删除所有元素count() 返回指定元素出现的次数empty() 如果map为空则返回trueend() 返回指向map末尾的迭代器equal_range() 返回特殊条目的迭代器对erase() 删除一个元素find() 查找一个元素get_allocator() 返回map的配置器insert() 插入元素key_comp() 返回比较元素key的函数lower_bound() 返回键值&gt;=给定元素的第一个位置max_size() 返回可以容纳的最大元素个数rbegin() 返回一个指向map尾部的逆向迭代器rend() 返回一个指向map头部的逆向迭代器size() 返回map中元素的个数swap() 交换两个mapupper_bound() 返回键值&gt;给定元素的第一个位置value_comp() 返回比较元素value的函数]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode535. Encode and Decode TinyURL]]></title>
    <url>%2F2019%2F04%2F10%2FLeetcode535%2F</url>
    <content type="text"><![CDATA[这道题其实不难，给一个url，要求转成一个短字符串，并且能还原出来。为什么专门做这种题呢，其实是想复习C++一些STL的用法，这道题涉及了string和map的用法，先讲题，再专门开两个md谈用法。 Encode and Decode TinyURLMedium Note: This is a companion problem to the System Design problem: Design TinyURL TinyURL is a URL shortening service where you enter a URL such as https://leetcode.com/problems/design-tinyurl and it returns a short URL such as http://tinyurl.com/4e9iAk. Design the encode and decode methods for the TinyURL service. There is no restriction on how your encode/decode algorithm should work. You just need to ensure that a URL can be encoded to a tiny URL and the tiny URL can be decoded to the original URL. 我的代码：1234567891011121314151617181920212223242526272829303132333435363738394041class Solution &#123;public: map&lt;string, int&gt; map1; map&lt;int, string&gt; map2; string s=&quot;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&quot;; // Encodes a URL to a shortened URL. string encode(string longUrl) &#123; map&lt;string,int&gt;::iterator key = map1.find(longUrl); if(key==map1.end()) &#123; map1.insert(map&lt;string, int&gt;::value_type (longUrl,map1.size()+1)); map2.insert(map&lt;int, string&gt;::value_type (map2.size()+1,longUrl)); &#125; int n=map2.size(); string result; // n is the number of longUrl while(n&gt;0)&#123; printf(&quot;(%d) &quot;,n); int r = n%62; n /= 62; result.append(1,s[r]); &#125; //printf(&quot;%s\n&quot;,result); return result; &#125; // Decodes a shortened URL to its original URL. string decode(string shortUrl) &#123; int length = shortUrl.size(); int val=0; for(int i=0;i&lt;length;i++)&#123; val = val*62+s.find(shortUrl[i]); &#125; return map2.find(val)-&gt;second; &#125;&#125;;// Your Solution object will be instantiated and called as such:// Solution solution;// solution.decode(solution.encode(url)); 别人的代码：123456789101112131415161718192021222324252627class Solution &#123;public: string alphabet = &quot;0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ&quot;; unordered_map&lt;string, string&gt; map; string key = getRandom(); string getRandom() &#123; string s; for (int i = 0; i &lt; 6 ; i++) &#123; s += alphabet[rand() % 61]; &#125; return s; &#125; // Encodes a URL to a shortened URL. string encode(string longUrl) &#123; while(map.count(key)) &#123; key = getRandom(); &#125; map.insert(make_pair(key, longUrl)); return &quot;http://tinyurl.com/&quot; + key; &#125; // Decodes a shortened URL to its original URL. string decode(string shortUrl) &#123; return map.at(shortUrl.replace(0,shortUrl.size()-6,&quot;&quot;)); &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode938. Range Sum of BST]]></title>
    <url>%2F2019%2F04%2F10%2FLeetcode938%2F</url>
    <content type="text"><![CDATA[Range Sum of BSTMedium Given the root node of a binary search tree, return the sum of values of all nodes with value between L and R (inclusive). The binary search tree is guaranteed to have unique values.一棵树，给定了根节点，再给一个范围（L，R），求这棵二叉树中在这个范围内的数的和，太简单了。。。直接递归查找，没难度，还奇怪呢这么简单的题还标着个medium。。。 1234Example 1:Input: root = [10,5,15,3,7,null,18], L = 7, R = 15Output: 32 1234Example 2:Input: root = [10,5,15,3,7,13,18,1,null,6], L = 6, R = 10Output: 23 123456789101112131415161718192021/** * Definition for a binary tree node. * struct TreeNode &#123; * int val; * TreeNode *left; * TreeNode *right; * TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: int rangeSumBST(TreeNode* root, int L, int R) &#123; if(root)&#123; if(root-&gt;val &gt;= L &amp;&amp; root-&gt;val &lt;= R) return root-&gt;val + rangeSumBST(root-&gt;left,L,R)+rangeSumBST(root-&gt;right,L,R); else return rangeSumBST(root-&gt;left,L,R)+rangeSumBST(root-&gt;right,L,R); &#125; return 0; &#125;&#125;; Note: The number of nodes in the tree is at most 10000.The final answer is guaranteed to be less than 2^31.]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux环境变量设置]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介环境变量是在操作系统中一个具有特定名字的对象，它包含了一个或多个应用程序将使用到的信息。Linux是一个多用户的操作系统，每个用户登录系统时都会有一个专用的运行环境，通常情况下每个用户的默认的环境都是相同的。这个默认环境就是一组环境变量的定义。每个用户都可以通过修改环境变量的方式对自己的运行环境进行配置。 分类根据环境变量的生命周期我们可以将其分为永久性变量和临时性变量，根据用户等级的不同又可以将其分为系统级变量和用户级变量。怎么分都无所谓，主要是对它的理解。 对所有用户生效的永久性变量（系统级）这类变量对系统内的所有用户都生效，所有用户都可以使用这类变量。作用范围是整个系统。设置方式： 用vim在/etc/profile文件中添加我们想要的环境变量。当然，这个文件只有在root（超级用户）下才能修改。我们可以在etc目录下使用ls -l查看这个文件的用户及权限。 利用vim打开/etc/ profile文件，用export指令添加环境变量。 【注意】：添加完成后新的环境变量不会立即生效，除非你调用source /etc/profile 该文件才会生效。否则只能在下次重进此用户时才能生效。 对单一用户生效的永久性变量（用户级）该类环境变量只对当前的用户永久生效。也就是说假如用户A设置了此类环境变量，这个环境变量只有A可以使用。而对于其他的B,C,D,E….用户等等，这个变量是不存在的。 设置方法：在用户主目录”~”下的隐藏文件 “.bash_profile”中添加自己想要的环境变量。查看隐藏文件： ls -a或ls -al 利用vim打开文件，利用export添加环境变量。与上相同。同样注意，添加完成后新的环境变量不会立即生效，除非你调用source ./.bash_profile 该文件才会生效。否则只能在下次重进此用户时才能生效。 可以看到我在上图中用红框框住了两个文件，.bashrc和.bash_profile。原则上来说设置此类环境变量时在这两个文件任意一个里面添加都是可以的。 ~/.bash_profile是交互式login方式进入bash shell运行。~/ .bashrc是交互式non-login方式进入bash shell运行。 二者设置大致相同。通俗点说，就是.bash_profile文件只会在用户登录的时候读取一次，而.bashrc在每次打开终端进行一次新的会话时都会读取。 临时有效的环境变量（只对当前shell有效）此类环境变量只对当前的shell有效。当我们退出登录或者关闭终端再重新打开时，这个环境变量就会消失。是临时的。 设置方法：直接使用export指令添加。 设置环境变量常用的几个指令echo查看显示环境变量，使用时要加上符号“”例：echo”例：echoPATH export设置新的环境变量export 新环境变量名=内容例:export MYNAME=”LLZZ” 修改环境变量修改环境变量没有指令，可以直接使用环境变量名进行修改。例：MYNAME=”ZZLL” env查看所有环境变量 set查看本地定义的所有shell变量 unset删除一个环境变量例 unset MYNAME readonly设置只读环境变量。例：readonly MYNAME 常用的几个环境变量（一般都为大写）PATH指定命令的搜索路径。通过设置环境变量PATH可以让我们运行程序或指令更加方便。echo $PATH 查看环境变量PATH。 每一个冒号都是一个路径，这些搜索路径都是一些可以找到可执行程序的目录列表。当我们输入一个指令时，shell会先检查命令是否是内部命令，不是的话会再检查这个命令是否是一个应用程序。然后shell会试着从这些搜索路径，即PATH（上图中路径）中寻找这些应用程序。如果shell在这些路径目录里没有找到可执行文件。则会报错。若找到，shell内部命令或应用程序将被分解为系统调用并传给Linux内核。 举个例子：现在有一个c程序test.c通过gcc编译生成的可执行文件a.out（功能：输出helloworld）。我们平常执行这个a.out的时候是使用①相对路径调用方式： ./a.out （”.”代表当前目录，”/”分隔符）。②还可以使用绝对路径调用方式：将其全部路径写出：/home/lzk/test/a.out（此路径是我的工作目录路径，只是个例子，仅供参考） ③通过设置PATH环境变量，直接用文件名调用：在没设置PATH前，我们直接使用a.out调用程序会报错，因为shell并没有从PATH已拥有的搜索路径目录中找到a.out这个可执行程序。 使用export指令，将a.out的路径添加到搜索路径当中，export PATH=$PATH:路径我们就可以使用a.out直接执行程序。 HOME指定用户的主工作目录，即为用户登录到Linux系统中时的默认目录，即“~”。 HISTSIZE指保存历史命令记录的条数。我们输入的指令都会被系统保存下来，这个环境变量记录的就是保持指令的条数。一般为1000。 这些历史指令都被保存在用户工作主目录“~”下的隐藏文件.bash_profile中。 我们可以通过指令history来查看。 LOGNAME指当前用户的登录名 HOSTNAME指主机的名称。 SHELL指当前用户用的是哪种shell LANG/LANGUGE和语言相关的环境变量，使用多种语言的用户可以修改此环境变量。 MAIL指当前用户的邮件存放目录 PS1命令提示符，root用户是#，普通用户是$ PS2附属提示符，默认是“&gt;” SECONDS从当前shell开始运行所流逝的秒数 总结环境变量是和shell紧密相关的，用户登录系统后就启动了一个shell，对于Linux来说一般是bash（Bourne Again shell，Bourne shell（sh）的扩展），也可以切换到其他版本的shell。bash有两个基本的系统级配置文件：/etc/bashrc和/etc/profile。这些配置文件包含了两组不同的变量：shell变量和环境变量。shell变量是局部的，而环境变量是全局的。环境变量是通过shell命令来设置。设置好的环境变量又可以被所以当前用户的程序使用。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 中的各种栈]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E4%B8%AD%E7%9A%84%E5%90%84%E7%A7%8D%E6%A0%88%2F</url>
    <content type="text"><![CDATA[栈是什么？栈有什么作用？首先，栈 (stack) 是一种串列形式的 数据结构。这种数据结构的特点是 后入先出 (LIFO, Last In First Out)，数据只能在串列的一端 (称为：栈顶 top) 进行 推入 (push) 和 弹出 (pop) 操作。根据栈的特点，很容易的想到可以利用数组，来实现这种数据结构。但是本文要讨论的并不是软件层面的栈，而是硬件层面的栈。 大多数的处理器架构，都有实现硬件栈。有专门的栈指针寄存器，以及特定的硬件指令来完成 入栈/出栈 的操作。例如在 ARM 架构上，R13 (SP) 指针是堆栈指针寄存器，而 PUSH 是用于压栈的汇编指令，POP 则是出栈的汇编指令。 【扩展阅读】：ARM 寄存器简介 ARM 处理器拥有 37 个寄存器。 这些寄存器按部分重叠组方式加以排列。 每个处理器模式都有一个不同的寄存器组。 编组的寄存器为处理处理器异常和特权操作提供了快速的上下文切换。 提供了下列寄存器： 三十个 32 位通用寄存器： 存在十五个通用寄存器，它们分别是 r0-r12、sp、lr sp (r13) 是堆栈指针。C/C++ 编译器始终将 sp 用作堆栈指针 lr (r14) 用于存储调用子例程时的返回地址。如果返回地址存储在堆栈上，则可将 lr 用作通用寄存器 程序计数器 (pc)：指令寄存器 应用程序状态寄存器 (APSR)：存放算术逻辑单元 (ALU) 状态标记的副本 当前程序状态寄存器 (CPSR)：存放 APSR 标记，当前处理器模式，中断禁用标记等 保存的程序状态寄存器 (SPSR)：当发生异常时，使用 SPSR 来存储 CPSR 上面是栈的原理和实现，下面我们来看看栈有什么作用。栈作用可以从两个方面体现：函数调用和多任务支持。 一、函数调用我们知道一个函数调用有以下三个基本过程： 调用参数的传入 局部变量的空间管理 函数返回 函数的调用必须是高效的，而数据存放在 CPU通用寄存器 或者 RAM 内存 中无疑是最好的选择。以传递调用参数为例，我们可以选择使用 CPU通用寄存器 来存放参数。但是通用寄存器的数目都是有限的，当出现函数嵌套调用时，子函数再次使用原有的通用寄存器必然会导致冲突。因此如果想用它来传递参数，那在调用子函数前，就必须先 保存原有寄存器的值，然后当子函数退出的时候再 恢复原有寄存器的值 。 函数的调用参数数目一般都相对少，因此通用寄存器是可以满足一定需求的。但是局部变量的数目和占用空间都是比较大的，再依赖有限的通用寄存器未免强人所难，因此我们可以采用某些 RAM 内存区域来存储局部变量。但是存储在哪里合适？既不能让函数嵌套调用的时候有冲突，又要注重效率。 这种情况下，栈无疑提供很好的解决办法。一、对于通用寄存器传参的冲突，我们可以再调用子函数前，将通用寄存器临时压入栈中；在子函数调用完毕后，在将已保存的寄存器再弹出恢复回来。二、而局部变量的空间申请，也只需要向下移动下栈顶指针；将栈顶指针向回移动，即可就可完成局部变量的空间释放；三、对于函数的返回，也只需要在调用子函数前，将返回地址压入栈中，待子函数调用结束后，将函数返回地址弹出给 PC 指针，即完成了函数调用的返回； 于是上述函数调用的三个基本过程，就演变记录一个栈指针的过程。每次函数调用的时候，都配套一个栈指针。即使循环嵌套调用函数，只要对应函数栈指针是不同的，也不会出现冲突。 【扩展阅读】：函数栈帧 (Stack Frame) 函数调用经常是嵌套的，在同一时刻，栈中会有多个函数的信息。每个未完成运行的函数占用一个独立的连续区域，称作栈帧(Stack Frame)。栈帧存放着函数参数，局部变量及恢复前一栈帧所需要的数据等，函数调用时入栈的顺序为： 实参N~1 → 主调函数返回地址 → 主调函数帧基指针EBP → 被调函数局部变量1~N 栈帧的边界由 栈帧基地址指针 EBP 和 栈指针 ESP 界定，EBP 指向当前栈帧底部(高地址)，在当前栈帧内位置固定；ESP指向当前栈帧顶部(低地址)，当程序执行时ESP会随着数据的入栈和出栈而移动。因此函数中对大部分数据的访问都基于EBP进行。函数调用栈的典型内存布局如下图所示： 二、多任务支持然而栈的意义还不只是函数调用，有了它的存在，才能构建出操作系统的多任务模式。我们以 main 函数调用为例，main 函数包含一个无限循环体，循环体中先调用 A 函数，再调用 B 函数。123456789func B(): return;func A(): B();func main(): while (1) A(); 试想在单处理器情况下，程序将永远停留在此 main 函数中。即使有另外一个任务在等待状态，程序是没法从此 main 函数里面跳转到另一个任务。因为如果是函数调用关系，本质上还是属于 main 函数的任务中，不能算多任务切换。此刻的 main 函数任务本身其实和它的栈绑定在了一起，无论如何嵌套调用函数，栈指针都在本栈范围内移动。 由此可以看出一个任务可以利用以下信息来表征： main 函数体代码 main 函数栈指针 当前 CPU 寄存器信息 假如我们可以保存以上信息，则完全可以强制让出 CPU 去处理其他任务。只要将来想继续执行此 main 任务的时候，把上面的信息恢复回去即可。有了这样的先决条件，多任务就有了存在的基础，也可以看出栈存在的另一个意义。在多任务模式下，当调度程序认为有必要进行任务切换的话，只需保存任务的信息（即上面说的三个内容）。恢复另一个任务的状态，然后跳转到上次运行的位置，就可以恢复运行了。 可见每个任务都有自己的栈空间，正是有了独立的栈空间，为了代码重用，不同的任务甚至可以混用任务的函数体本身，例如可以一个main函数有两个任务实例。至此之后的操作系统的框架也形成了，譬如任务在调用 sleep() 等待的时候，可以主动让出 CPU 给别的任务使用，或者分时操作系统任务在时间片用完是也会被迫的让出 CPU。不论是哪种方法，只要想办法切换任务的上下文空间，切换栈即可。 【扩展阅读】：任务、线程、进程 三者关系 任务是一个抽象的概念，即指软件完成的一个活动；而线程则是完成任务所需的动作；进程则指的是完成此动作所需资源的统称；关于三者的关系，有一个形象的比喻： 任务 = 送货 线程 = 开送货车 系统调度 = 决定合适开哪部送货车 进程 = 道路 + 加油站 + 送货车 + 修车厂 Linux 中有几种栈？各种栈的内存位置？介绍完栈的工作原理和用途作用后，我们回归到 Linux 内核上来。内核将栈分成四种： 进程栈线程栈内核栈中断栈 一、进程栈进程栈是属于用户态栈，和进程 虚拟地址空间 (Virtual Address Space) 密切相关。那我们先了解下什么是虚拟地址空间：在 32 位机器下，虚拟地址空间大小为 4G。这些虚拟地址通过页表 (Page Table) 映射到物理内存，页表由操作系统维护，并被处理器的内存管理单元 (MMU) 硬件引用。每个进程都拥有一套属于它自己的页表，因此对于每个进程而言都好像独享了整个虚拟地址空间。 Linux 内核将这 4G 字节的空间分为两部分，将最高的 1G 字节（0xC0000000-0xFFFFFFFF）供内核使用，称为 内核空间。而将较低的3G字节（0x00000000-0xBFFFFFFF）供各个进程使用，称为 用户空间。每个进程可以通过系统调用陷入内核态，因此内核空间是由所有进程共享的。虽然说内核和用户态进程占用了这么大地址空间，但是并不意味它们使用了这么多物理内存，仅表示它可以支配这么大的地址空间。它们是根据需要，将物理内存映射到虚拟地址空间中使用。 Linux 对进程地址空间有个标准布局，地址空间中由各个不同的内存段组成 (Memory Segment)，主要的内存段如下： 程序段 (Text Segment)：可执行文件代码的内存映射 数据段 (Data Segment)：可执行文件的已初始化全局变量的内存映射 BSS段 (BSS Segment)：未初始化的全局变量或者静态变量（用零页初始化） 堆区 (Heap) : 存储动态内存分配，匿名的内存映射 栈区 (Stack) : 进程用户空间栈，由编译器自动分配释放，存放函数的参数值、局部变量的值等 映射段(Memory Mapping Segment)：任何内存映射文件 而上面进程虚拟地址空间中的栈区，正指的是我们所说的进程栈。进程栈的初始化大小是由编译器和链接器计算出来的，但是栈的实时大小并不是固定的，Linux 内核会根据入栈情况对栈区进行动态增长（其实也就是添加新的页表）。但是并不是说栈区可以无限增长，它也有最大限制 RLIMIT_STACK (一般为 8M)，我们可以通过 ulimit 来查看或更改 RLIMIT_STACK 的值。 【扩展阅读】：如何确认进程栈的大小 我们要知道栈的大小，那必须得知道栈的起始地址和结束地址。栈起始地址 获取很简单，只需要嵌入汇编指令获取栈指针 esp 地址即可。栈结束地址 的获取有点麻烦，我们需要先利用递归函数把栈搞溢出了，然后再 GDB 中把栈溢出的时候把栈指针 esp 打印出来即可。代码如下：1234567891011121314/* file name: stacksize.c */void *orig_stack_pointer;void blow_stack() &#123; blow_stack();&#125;int main() &#123; __asm__(&quot;movl %esp, orig_stack_pointer&quot;); blow_stack(); return 0;&#125; 1234567891011121314$ g++ -g stacksize.c -o ./stacksize$ gdb ./stacksize(gdb) rStarting program: /home/home/misc-code/setrlimitProgram received signal SIGSEGV, Segmentation fault.blow_stack () at setrlimit.c:44 blow_stack();(gdb) print (void *)$esp$1 = (void *) 0xffffffffff7ff000(gdb) print (void *)orig_stack_pointer$2 = (void *) 0xffffc800(gdb) print 0xffffc800-0xff7ff000$3 = 8378368 // Current Process Stack Size is 8M 上面对进程的地址空间有个比较全局的介绍，那我们看下 Linux 内核中是怎么体现上面内存布局的。内核使用内存描述符来表示进程的地址空间，该描述符表示着进程所有地址空间的信息。内存描述符由 mm_struct 结构体表示，下面给出内存描述符结构中各个域的描述，请大家结合前面的 进程内存段布局 图一起看： 12345678910111213141516171819202122232425struct mm_struct &#123; struct vm_area_struct *mmap; /* 内存区域链表 */ struct rb_root mm_rb; /* VMA 形成的红黑树 */ ... struct list_head mmlist; /* 所有 mm_struct 形成的链表 */ ... unsigned long total_vm; /* 全部页面数目 */ unsigned long locked_vm; /* 上锁的页面数据 */ unsigned long pinned_vm; /* Refcount permanently increased */ unsigned long shared_vm; /* 共享页面数目 Shared pages (files) */ unsigned long exec_vm; /* 可执行页面数目 VM_EXEC &amp; ~VM_WRITE */ unsigned long stack_vm; /* 栈区页面数目 VM_GROWSUP/DOWN */ unsigned long def_flags; unsigned long start_code, end_code, start_data, end_data; /* 代码段、数据段 起始地址和结束地址 */ unsigned long start_brk, brk, start_stack; /* 栈区 的起始地址，堆区 起始地址和结束地址 */ unsigned long arg_start, arg_end, env_start, env_end; /* 命令行参数 和 环境变量的 起始地址和结束地址 */ ... /* Architecture-specific MM context */ mm_context_t context; /* 体系结构特殊数据 */ /* Must use atomic bitops to access the bits */ unsigned long flags; /* 状态标志位 */ ... /* Coredumping and NUMA and HugePage 相关结构体 */&#125;; 【扩展阅读】：进程栈的动态增长实现 进程在运行的过程中，通过不断向栈区压入数据，当超出栈区容量时，就会耗尽栈所对应的内存区域，这将触发一个 缺页异常 (page fault)。通过异常陷入内核态后，异常会被内核的 expand_stack() 函数处理，进而调用 acct_stack_growth() 来检查是否还有合适的地方用于栈的增长。 如果栈的大小低于 RLIMIT_STACK（通常为8MB），那么一般情况下栈会被加长，程序继续执行，感觉不到发生了什么事情，这是一种将栈扩展到所需大小的常规机制。然而，如果达到了最大栈空间的大小，就会发生 栈溢出（stack overflow），进程将会收到内核发出的 段错误（segmentation fault） 信号。 动态栈增长是唯一一种访问未映射内存区域而被允许的情形，其他任何对未映射内存区域的访问都会触发页错误，从而导致段错误。一些被映射的区域是只读的，因此企图写这些区域也会导致段错误。 二、线程栈从 Linux 内核的角度来说，其实它并没有线程的概念。Linux 把所有线程都当做进程来实现，它将线程和进程不加区分的统一到了 task_struct 中。线程仅仅被视为一个与其他进程共享某些资源的进程，而是否共享地址空间几乎是进程和 Linux 中所谓线程的唯一区别。线程创建的时候，加上了 CLONE_VM 标记，这样 线程的内存描述符 将直接指向 父进程的内存描述符。1234567if (clone_flags &amp; CLONE_VM) &#123; /* * current 是父进程而 tsk 在 fork() 执行期间是共享子进程 */ atomic_inc(&amp;current-&gt;mm-&gt;mm_users); tsk-&gt;mm = current-&gt;mm;&#125; 虽然线程的地址空间和进程一样，但是对待其地址空间的 stack 还是有些区别的。对于 Linux 进程或者说主线程，其 stack 是在 fork 的时候生成的，实际上就是复制了父亲的 stack 空间地址，然后写时拷贝 (cow) 以及动态增长。然而对于主线程生成的子线程而言，其 stack 将不再是这样的了，而是事先固定下来的，使用 mmap 系统调用，它不带有 VM_STACK_FLAGS 标记。这个可以从 glibc 的nptl/allocatestack.c 中的 allocate_stack() 函数中看到：12mem = mmap (NULL, size, prot, MAP_PRIVATE | MAP_ANONYMOUS | MAP_STACK, -1, 0); 由于线程的 mm-&gt;start_stack 栈地址和所属进程相同，所以线程栈的起始地址并没有存放在 task_struct 中，应该是使用 pthread_attr_t 中的 stackaddr 来初始化 task_struct-&gt;thread-&gt;sp（sp 指向 struct pt_regs 对象，该结构体用于保存用户进程或者线程的寄存器现场）。这些都不重要，重要的是，线程栈不能动态增长，一旦用尽就没了，这是和生成进程的 fork 不同的地方。由于线程栈是从进程的地址空间中 map 出来的一块内存区域，原则上是线程私有的。但是同一个进程的所有线程生成的时候浅拷贝生成者的 task_struct 的很多字段，其中包括所有的 vma，如果愿意，其它线程也还是可以访问到的，于是一定要注意。 三、进程内核栈在每一个进程的生命周期中，必然会通过到系统调用陷入内核。在执行系统调用陷入内核之后，这些内核代码所使用的栈并不是原先进程用户空间中的栈，而是一个单独内核空间的栈，这个称作进程内核栈。进程内核栈在进程创建的时候，通过 slab 分配器从 thread_info_cache 缓存池中分配出来，其大小为 THREAD_SIZE，一般来说是一个页大小 4K；12345union thread_union &#123; struct thread_info thread_info; unsigned long stack[THREAD_SIZE/sizeof(long)];&#125;; ` thread_union 进程内核栈 和 task_struct 进程描述符有着紧密的联系。由于内核经常要访问 task_struct，高效获取当前进程的描述符是一件非常重要的事情。因此内核将进程内核栈的头部一段空间，用于存放 thread_info 结构体，而此结构体中则记录了对应进程的描述符，两者关系如下图（对应内核函数为 dup_task_struct()）： 有了上述关联结构后，内核可以先获取到栈顶指针 esp，然后通过 esp 来获取 thread_info。这里有一个小技巧，直接将 esp 的地址与上 ~(THREAD_SIZE - 1) 后即可直接获得 thread_info 的地址。由于 thread_union 结构体是从 thread_info_cache 的 Slab 缓存池中申请出来的，而 thread_info_cache 在 kmem_cache_create 创建的时候，保证了地址是 THREAD_SIZE 对齐的。因此只需要对栈指针进行 THREAD_SIZE 对齐，即可获得 thread_union 的地址，也就获得了 thread_union 的地址。成功获取到 thread_info 后，直接取出它的 task 成员就成功得到了 task_struct。其实上面这段描述，也就是 current 宏的实现方法：1234567891011register unsigned long current_stack_pointer asm (&quot;sp&quot;);static inline struct thread_info *current_thread_info(void) &#123; return (struct thread_info *) (current_stack_pointer &amp; ~(THREAD_SIZE - 1));&#125; #define get_current() (current_thread_info()-&gt;task)#define current get_current() 四、中断栈进程陷入内核态的时候，需要内核栈来支持内核函数调用。中断也是如此，当系统收到中断事件后，进行中断处理的时候，也需要中断栈来支持函数调用。由于系统中断的时候，系统当然是处于内核态的，所以中断栈是可以和内核栈共享的。但是具体是否共享，这和具体处理架构密切相关。 X86 上中断栈就是独立于内核栈的；独立的中断栈所在内存空间的分配发生在 arch/x86/kernel/irq_32.c 的 irq_ctx_init() 函数中(如果是多处理器系统，那么每个处理器都会有一个独立的中断栈)，函数使用 __alloc_pages 在低端内存区分配 2个物理页面，也就是8KB大小的空间。有趣的是，这个函数还会为 softirq 分配一个同样大小的独立堆栈。如此说来，softirq 将不会在 hardirq 的中断栈上执行，而是在自己的上下文中执行。 而 ARM 上中断栈和内核栈则是共享的；中断栈和内核栈共享有一个负面因素，如果中断发生嵌套，可能会造成栈溢出，从而可能会破坏到内核栈的一些重要数据，所以栈空间有时候难免会捉襟见肘。 Linux 为什么需要区分这些栈？为什么需要区分这些栈，其实都是设计上的问题。这里就我看到过的一些观点进行汇总，供大家讨论： 为什么需要单独的进程内核栈？ 所有进程运行的时候，都可能通过系统调用陷入内核态继续执行。假设第一个进程 A 陷入内核态执行的时候，需要等待读取网卡的数据，主动调用 schedule() 让出 CPU；此时调度器唤醒了另一个进程 B，碰巧进程 B 也需要系统调用进入内核态。那问题就来了，如果内核栈只有一个，那进程 B 进入内核态的时候产生的压栈操作，必然会破坏掉进程 A 已有的内核栈数据；一但进程 A 的内核栈数据被破坏，很可能导致进程 A 的内核态无法正确返回到对应的用户态了；为什么需要单独的线程栈？ Linux 调度程序中并没有区分线程和进程，当调度程序需要唤醒”进程”的时候，必然需要恢复进程的上下文环境，也就是进程栈；但是线程和父进程完全共享一份地址空间，如果栈也用同一个那就会遇到以下问题。假如进程的栈指针初始值为 0x7ffc80000000；父进程 A 先执行，调用了一些函数后栈指针 esp 为 0x7ffc8000FF00，此时父进程主动休眠了；接着调度器唤醒子线程 A1：此时 A1 的栈指针 esp 如果为初始值 0x7ffc80000000，则线程 A1 一但出现函数调用，必然会破坏父进程 A 已入栈的数据。如果此时线程 A1 的栈指针和父进程最后更新的值一致，esp 为 0x7ffc8000FF00，那线程 A1 进行一些函数调用后，栈指针 esp 增加到 0x7ffc8000FFFF，然后线程 A1 休眠；调度器再次换成父进程 A 执行，那这个时候父进程的栈指针是应该为 0x7ffc8000FF00 还是 0x7ffc8000FFFF 呢？无论栈指针被设置到哪个值，都会有问题不是吗？进程和线程是否共享一个内核栈？ No，线程和进程创建的时候都调用 dup_task_struct 来创建 task 相关结构体，而内核栈也是在此函数中 alloc_thread_info_node 出来的。因此虽然线程和进程共享一个地址空间 mm_struct，但是并不共享一个内核栈。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态链接库中函数的地址确定]]></title>
    <url>%2F2019%2F04%2F09%2F%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%BA%93%E4%B8%AD%E5%87%BD%E6%95%B0%E7%9A%84%E5%9C%B0%E5%9D%80%E7%A1%AE%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[有一个问题是我们调用了动态链接库里面的函数，我们怎么知道动态链接库里面的函数的地址呢？事实上，直到我们第一次调用这个函数，我们并不知道这个函数的地址，这个功能要做延迟绑定 lazy bind。 因为程序的分支很多，并不是所有的分支都能跑到，想想我们的异常处理，异常处理分支的动态链接库里面的函数也许永远跑不到，所以，一上来就解析所有出现过的动态库里面的函数是个浪费的办法，降低性能并且没有必要。 下面我们看下延迟绑定的效果。我写了个程序，先睡15s，然后pthread_create 一个线程。我们用LD_DEBUG观察符号的解析。123456789101112131415161718192021222324252627282930313233#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;pthread.h&gt;void* myfunc()&#123; while(1) &#123; sleep(10); &#125; return NULL;&#125;int main()&#123; sleep(15); pthread_t tid = 0; int ret = pthread_create(&amp;tid,NULL,myfunc,NULL); if(ret) &#123; fprintf(stderr,&quot;pthread create failed %m \n&quot;); return -1; &#125; ret = pthread_join(tid,NULL); if(ret) &#123; fprintf(stderr,&quot;pthread join failed %m\n&quot;); return -2; &#125; return 0;&#125; 1234567891011121314151617root@libin:~/program/C/plt_got# LD_DEBUG=symbols ./test2849: symbol=_res; lookup in file=./test [0]2849: symbol=_res; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=_res; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=_IO_file_close; lookup in file=./test [0]2849: symbol=_IO_file_close; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=_IO_file_close; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=rpc_createerr; lookup in file=./test [0]2849: symbol=rpc_createerr; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=rpc_createerr; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: transferring control: ./test2849:2849: symbol=sleep; lookup in file=./test [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]=================================================================================== 然后停了15s，才解析出pthread_create的地址，由此可见，得确是运行时重定位，知道用到这个函数pthread_create才真正去找这个函数的地址。 123456789101112132849: 2849: symbol=sleep; lookup in file=./test [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=sleep; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]===================================================================================2849: symbol=pthread_create; lookup in file=./test [0]2849: symbol=pthread_create; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=__getpagesize; lookup in file=./test [0]2849: symbol=__getpagesize; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=__getpagesize; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0]2849: symbol=mmap; lookup in file=./test [0]2849: symbol=mmap; lookup in file=/lib/tls/i686/cmov/libpthread.so.0 [0]2849: symbol=mmap; lookup in file=/lib/tls/i686/cmov/libc.so.6 [0] 真正动态库中函数地址的解析是第一次调用的时候做的，然后如果再次用到动态库的解析过的函数，就直接用第一次解析的结果。很自然的想法就是，一定有地方存储函数的地址，否则第一次解析出来的结果，第二次调用也没法利用。 这个存储动态库函数的地方就要GOT，Global Offset Table。 OK，我们可以想象，如果我的程序里面用到了6个动态库里面的函数，那个这个GOT里面就应该存有6个条目，每个条目里面存储着对应函数的地址。事实的确是这样： 123456789101112131415root@libin:~/program/C/plt_got# readelf -r testRelocation section &apos;.rel.dyn&apos; at offset 0x394 contains 2 entries:Offset Info Type Sym.Value Sym. Name08049ff0 00000206 R_386_GLOB_DAT 00000000 __gmon_start__0804a020 00000905 R_386_COPY 0804a020 stderrRelocation section &apos;.rel.plt&apos; at offset 0x3a4 contains 6 entries:Offset Info Type Sym.Value Sym. Name0804a000 00000107 R_386_JUMP_SLOT 00000000 pthread_join0804a004 00000207 R_386_JUMP_SLOT 00000000 __gmon_start__0804a008 00000407 R_386_JUMP_SLOT 00000000 __libc_start_main0804a00c 00000507 R_386_JUMP_SLOT 00000000 fprintf0804a010 00000607 R_386_JUMP_SLOT 00000000 pthread_create0804a014 00000707 R_386_JUMP_SLOT 00000000 sleep 我们看到了有全局变量stderr和gmon_start需要重定位，这些本文并不关心。下面是需要重定位的函数，可以看出，我们调用动态库里面的函数都在这了，fprintf是Glibc库的，pthread_create是pthread库的等等。 .got.plt这个段的起始地址是0x8049ff4。 .got.plt这个section大小为0x24 = 36,可是我们只有6个需要解析地址的function，4*6=24个字节，只需要24个字节就能存放这6个函数指针。多出来的12个字节是dynamic段地址，ModuleID 和 _dl_runtime_resolve的地址，如下图所示 OK 。我们看一下：123456789101112131415(gdb) b mainBreakpoint 1 at 0x8048551: file test.c, line 19.(gdb) rStarting program: /home/libin/program/C/plt_got/test[Thread debugging using libthread_db enabled]Breakpoint 1, main () at test.c:1919 sleep(15);(gdb) x/24x 0x8049ff40x8049ff4 &lt;_GLOBAL_OFFSET_TABLE_&gt;: 0x08049f18 0x0012c8f8 0x00123270 0x0804841a0x804a004 &lt;_GLOBAL_OFFSET_TABLE_+16&gt;: 0x0804842a 0x0015daf0 0x0804844a 0x0804845a0x804a014 &lt;_GLOBAL_OFFSET_TABLE_+32&gt;: 0x0804846a 0x00000000 0x00000000 0x0029c5800x804a024 : 0x00000000 0x00000000 0x00000000 0x000000000x804a034: 0x00000000 0x00000000 0x00000000 0x000000000x804a044: 0x00000000 0x00000000 0x00000000 0x00000000 蓝色的0x0849f18是dynamic段的地址1[21] .dynamic DYNAMIC 08049f18 000f18 0000d8 08 WA 7 0 4 接下来，我们要分析PLT 和GOT的关系了。1234567(gdb) disas main0x0804857e &lt;+54&gt;: lea 0x1c(%esp),%eax0x08048582 &lt;+58&gt;: mov %eax,(%esp)0x08048585 &lt;+61&gt;: call 0x8048454 &lt;pthread_create@plt&gt;0x0804858a &lt;+66&gt;: mov %eax,0x18(%esp)0x0804858e &lt;+70&gt;: cmpl $0x0,0x18(%esp) 要执行pthread_create 函数，跳到PLT部分。12345678910111213141516171819202122232425262728293031323334353637383940libin@libin:~/program/C/plt_got$ objdump -dj .plt testtest: file format elf32-i386Disassembly of section .plt:08048404 :8048404: ff 35 f8 9f 04 08 pushl 0x8049ff8804840a: ff 25 fc 9f 04 08 jmp *0x8049ffc8048410: 00 00 add %al,(%eax)08048414 :8048414: ff 25 00 a0 04 08 jmp *0x804a000804841a: 68 00 00 00 00 push $0x0804841f: e9 e0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048424 &lt;__gmon_start__@plt&gt;:8048424: ff 25 04 a0 04 08 jmp *0x804a004804842a: 68 08 00 00 00 push $0x8804842f: e9 d0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048434 &lt;__libc_start_main@plt&gt;:8048434: ff 25 08 a0 04 08 jmp *0x804a008804843a: 68 10 00 00 00 push $0x10804843f: e9 c0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048444 :8048444: ff 25 0c a0 04 08 jmp *0x804a00c804844a: 68 18 00 00 00 push $0x18804844f: e9 b0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048454 :8048454: ff 25 10 a0 04 08 jmp *0x804a010804845a: 68 20 00 00 00 push $0x20804845f: e9 a0 ff ff ff jmp 8048404 &lt;_init+0x30&gt;08048464 :8048464: ff 25 14 a0 04 08 jmp *0x804a014804846a: 68 28 00 00 00 push $0x28804846f: e9 90 ff ff ff jmp 8048404 &lt;_init+0x30&gt; PLT部分认为pthread_create函数存放在GOT，0x804a010是GOT里面的一个条目，这个条目存储着pthread_create函数的地址。当第二次以至于第N次调用pthead_create的时候，的的确确存放着pthread_create的地址，但是第一次不行，第一次这个条目里面还没记录这个地址。那么这个条目记录的是什么呢？ 123456789101112131415(gdb) x/10i 0x80484540x8048454 : jmp *0x804a0100x804845a : push $0x200x804845f : jmp 0x80484040x8048464 : jmp *0x804a0140x804846a : push $0x280x804846f : jmp 0x80484040x8048474: add %al,(%eax)0x8048476: add %al,(%eax)0x8048478: add %al,(%eax)0x804847a: add %al,(%eax)(gdb) x/10x 0x804a0100x804a010 &lt;_GLOBAL_OFFSET_TABLE_+28&gt;: 0x0804845a 0x0804846a 0x00000000 0x000000000x804a020 : 0x0029c580 0x00000000 0x00000000 0x000000000x804a030: 0x00000000 0x00000000 0x804a010这个地址最终应该记录的是pthread_create的地址，但是目前还不是，记录的是0x084845a 123408048454 :8048454: ff 25 10 a0 04 08 jmp *0x804a010804845a: 68 20 00 00 00 push $0x20804845f: e9 a0 ff ff ff jmp 8048404 &lt;_init+0x30&gt; 从PLT跳到GOT 找地址，但是第一次找的时候，并不是pthread_create的地址，而是又跳回来PLT，我们看到push了0x20之后，跳到了0x8048404。 每一个PLT的代码段，都是push了一个值之后，跳到了0x8048404。大家可以去上面的图验证。 接下来，我们看0x8048404存放的是啥指令：1234567891011(gdb) x/10i 0x8048404 0x8048404: pushl 0x8049ff8 0x804840a: jmp *0x8049ffc 0x8048410: add %al,(%eax) 0x8048412: add %al,(%eax) 0x8048414 &lt;&lt;/span&gt;pthread_join@plt&gt;: jmp *0x804a000 0x804841a &lt;&lt;/span&gt;pthread_join@plt+6&gt;: push $0x0 0x804841f &lt;&lt;/span&gt;pthread_join@plt+11&gt;: jmp 0x8048404 0x8048424 &lt;&lt;/span&gt;__gmon_start__@plt&gt;: jmp *0x804a004 0x804842a &lt;&lt;/span&gt;__gmon_start__@plt+6&gt;: push $0x8 0x804842f &lt;&lt;/span&gt;__gmon_start__@plt+11&gt;: jmp 0x8048404 123456789101112131415161718192021222324252627282930313233343536373839404142434445(gdb) x/10x 0x8049ffc0x8049ffc &lt;&lt;/span&gt;_GLOBAL_OFFSET_TABLE_+8&gt;: 0x00123270 0x0804841a 0x0804842a 0x0015daf00x804a00c &lt;&lt;/span&gt;_GLOBAL_OFFSET_TABLE_+24&gt;: 0x0804844a 0x0804845a 0x0804846a 0x000000000x804a01c &lt;&lt;/span&gt;__dso_handle&gt;: 0x00000000 0x0029c580(gdb) x/10i 0x00123270 0x123270 &lt;&lt;/span&gt;_dl_runtime_resolve&gt;: push %eax 0x123271 &lt;&lt;/span&gt;_dl_runtime_resolve+1&gt;: push %ecx 0x123272 &lt;&lt;/span&gt;_dl_runtime_resolve+2&gt;: push %edx 0x123273 &lt;&lt;/span&gt;_dl_runtime_resolve+3&gt;: mov 0x10(%esp),%edx 0x123277 &lt;&lt;/span&gt;_dl_runtime_resolve+7&gt;: mov 0xc(%esp),%eax 0x12327b &lt;&lt;/span&gt;_dl_runtime_resolve+11&gt;: call 0x11d5a0 &lt;&lt;/span&gt;_dl_fixup&gt; 0x123280 &lt;&lt;/span&gt;_dl_runtime_resolve+16&gt;: pop %edx 0x123281 &lt;&lt;/span&gt;_dl_runtime_resolve+17&gt;: mov (%esp),%ecx 0x123284 &lt;&lt;/span&gt;_dl_runtime_resolve+20&gt;: mov %eax,(%esp) 0x123287 &lt;&lt;/span&gt;_dl_runtime_resolve+23&gt;: mov 0x4(%esp),%eax````` 我们看到0x8049ffc就是GOT的第三项，前文提到的dl_runtime_resolve的地址。这个函数将帮助我们将pthread_create函数地址定位，并且填入GOT表的相应位置 0x804a010。 我们watch下GOT pthread_create对应条目，看下这个条目啥时候变化：````` (gdb) b mainBreakpoint 1 at 0x8048551: file test.c, line 19.(gdb) rStarting program: /home/libin/program/C/plt_got/test [Thread debugging using libthread_db enabled]Breakpoint 1, main () at test.c:1919 sleep(15);(gdb) watch *0x804a010Hardware watchpoint 2: *0x804a010(gdb) cContinuing.Hardware watchpoint 2: *0x804a010Old value = 134513754New value = 1260912_dl_fixup (l=&lt;&lt;/span&gt;value optimized out&gt;, reloc_arg=&lt;&lt;/span&gt;value optimized out&gt;) at dl-runtime.c:155155 dl-runtime.c: 没有那个文件或目录. in dl-runtime.c(gdb) bt#0 _dl_fixup (l=&lt;&lt;/span&gt;value optimized out&gt;, reloc_arg=&lt;&lt;/span&gt;value optimized out&gt;) at dl-runtime.c:155#1 0x00123280 in _dl_runtime_resolve () at ../sysdeps/i386/dl-trampoline.S:37#2 0x0804858a in main () at test.c:21(gdb)`` 看到了，是_dl_runtime_resolve调用了_dl_fixup修改了GOT的对应条目。 (gdb) x/10i 1260912 0x133d70 &lt;&lt;/span&gt;__pthread_create_2_1&gt;: push %ebp 0x133d71 &lt;&lt;/span&gt;__pthread_create_2_1+1&gt;: mov %esp,%ebp 0x133d73 &lt;&lt;/span&gt;__pthread_create_2_1+3&gt;: push %edi 0x133d74 &lt;&lt;/span&gt;__pthread_create_2_1+4&gt;: push %esi 0x133d75 &lt;&lt;/span&gt;__pthread_create_2_1+5&gt;: push %ebx 0x133d76 &lt;&lt;/span&gt;__pthread_create_2_1+6&gt;: call 0x132340 &lt;&lt;/span&gt;__i686.get_pc_thunk.bx&gt; 0x133d7b &lt;&lt;/span&gt;__pthread_create_2_1+11&gt;: add $0x10279,%ebx 0x133d81 &lt;&lt;/span&gt;__pthread_create_2_1+17&gt;: sub $0x4c,%esp 0x133d84 &lt;&lt;/span&gt;__pthread_create_2_1+20&gt;: mov 0xc(%ebp),%edx 0x133d87 &lt;&lt;/span&gt;__pthread_create_2_1+23&gt;: test %edx,%edx 这是第一次。第二次就比较简单了，因为GOT里面有一个条目已经有了pthread_create函数的地址。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++内存管理]]></title>
    <url>%2F2019%2F04%2F09%2Fcpp%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[导语内存管理是C++最令人切齿痛恨的问题，也是C++最有争议的问题，C++高手从中获得了更好的性能，更大的自由，C++菜鸟的收获则是一遍一遍的检查代码和对C++的痛恨，但内存管理在C++中无处不在，内存泄漏几乎在每个C++程序中都会发生，因此要想成为C++高手，内存管理一关是必须要过的，除非放弃C++，转到Java或者.NET，他们的内存管理基本是自动的，当然你也放弃了自由和对内存的支配权，还放弃了C++超绝的性能。本期专题将从内存管理、内存泄漏、内存回收这三个方面来探讨C++内存管理问题。 内存管理伟大的Bill Gates 曾经失言： 640K ought to be enough for everybody —— Bill Gates 1981 程序员们经常编写内存管理程序，往往提心吊胆。如果不想触雷，唯一的解决办法就是发现所有潜伏的地雷并且排除它们，躲是躲不了的。本文的内容比一般教科书的要深入得多，读者需细心阅读，做到真正地通晓内存管理。 C++内存管理详解内存分配方式分配方式简介在C++中，内存分成5个区，他们分别是堆、栈、自由存储区、全局/静态存储区和常量存储区。 栈，在执行函数时，函数内局部变量的存储单元都可以在栈上创建，函数执行结束时这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。 堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete。如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。 自由存储区，就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。 全局/静态存储区，全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。 常量存储区，这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改。 明确区分堆与栈在bbs上，堆与栈的区分问题，似乎是一个永恒的话题，由此可见，初学者对此往往是混淆不清的，所以我决定拿他第一个开刀。 首先，我们举一个例子：1void f() &#123; int* p=new int[5]; &#125; 这条短短的一句话就包含了堆与栈，看到new，我们首先就应该想到，我们分配了一块堆内存，那么指针p呢？他分配的是一块栈内存，所以这句话的意思就是：在栈内存中存放了一个指向一块堆内存的指针p。在程序会先确定在堆中分配内存的大小，然后调用operator new分配内存，然后返回这块内存的首地址，放入栈中，他在VC6下的汇编代码如下：12345600401028 push 14h0040102A call operator new (00401060)0040102F add esp,400401032 mov dword ptr [ebp-8],eax00401035 mov eax,dword ptr [ebp-8]00401038 mov dword ptr [ebp-4],eax 这里，我们为了简单并没有释放内存，那么该怎么去释放呢？是delete p么？澳，错了，应该是delete []p，这是为了告诉编译器：我删除的是一个数组，VC6就会根据相应的Cookie信息去进行释放内存的工作。 堆和栈究竟有什么区别？好了，我们回到我们的主题：堆和栈究竟有什么区别？ 主要的区别由以下几点：1.管理方式不同；2.空间大小不同；3.能否产生碎片不同；4.生长方向不同；5.分配方式不同；6.分配效率不同；管理方式：对于栈来讲，是由编译器自动管理，无需我们手工控制；对于堆来说，释放工作由程序员控制，容易产生memory leak。 空间大小：一般来讲在32位系统下，堆内存可以达到4G的空间，从这个角度来看堆内存几乎是没有什么限制的。但是对于栈来讲，一般都是有一定的空间大小的，例如，在VC6下面，默认的栈空间大小是1M（好像是，记不清楚了）。当然，我们可以修改： 打开工程，依次操作菜单如下：Project-&gt;Setting-&gt;Link，在Category 中选中Output，然后在Reserve中设定堆栈的最大值和commit。 注意：reserve最小值为4Byte；commit是保留在虚拟内存的页文件里面，它设置的较大会使栈开辟较大的值，可能增加内存的开销和启动时间。 碎片问题：对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。对于栈来讲，则不会存在这个问题，因为栈是先进后出的队列，他们是如此的一一对应，以至于永远都不可能有一个内存块从栈中间弹出，在他弹出之前，在他上面的后进的栈内容已经被弹出，详细的可以参考数据结构，这里我们就不再一一讨论了。 生长方向：对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；对于栈来讲，它的生长方向是向下的，是向着内存地址减小的方向增长。 分配方式：堆都是动态分配的，没有静态分配的堆。栈有2种分配方式：静态分配和动态分配。静态分配是编译器完成的，比如局部变量的分配。动态分配由alloca函数进行分配，但是栈的动态分配和堆是不同的，他的动态分配是由编译器进行释放，无需我们手工实现。 分配效率：栈是机器系统提供的数据结构，计算机会在底层对栈提供支持：分配专门的寄存器存放栈的地址，压栈出栈都有专门的指令执行，这就决定了栈的效率比较高。堆则是C/C++函数库提供的，它的机制是很复杂的，例如为了分配一块内存，库函数会按照一定的算法（具体的算法可以参考数据结构/操作系统）在堆内存中搜索可用的足够大小的空间，如果没有足够大小的空间（可能是由于内存碎片太多），就有可能调用系统功能去增加程序数据段的内存空间，这样就有机会分到足够大小的内存，然后进行返回。显然，堆的效率比栈要低得多。 从这里我们可以看到，堆和栈相比，由于大量new/delete的使用，容易造成大量的内存碎片；由于没有专门的系统支持，效率很低；由于可能引发用户态和核心态的切换，内存的申请，代价变得更加昂贵。所以栈在程序中是应用最广泛的，就算是函数的调用也利用栈去完成，函数调用过程中的参数，返回地址，EBP和局部变量都采用栈的方式存放。所以，我们推荐大家尽量用栈，而不是用堆。 虽然栈有如此众多的好处，但是由于和堆相比不是那么灵活，有时候分配大量的内存空间，还是用堆好一些。 无论是堆还是栈，都要防止越界现象的发生（除非你是故意使其越界），因为越界的结果要么是程序崩溃，要么是摧毁程序的堆、栈结构，产生以想不到的结果,就算是在你的程序运行过程中，没有发生上面的问题，你还是要小心，说不定什么时候就崩掉，那时候debug可是相当困难的：） 控制C++的内存分配在嵌入式系统中使用C++的一个常见问题是内存分配，即对new和delete操作符的失控。 具有讽刺意味的是，问题的根源却是C++对内存的管理非常的容易而且安全。具体地说，当一个对象被消除时，它的析构函数能够安全的释放所分配的内存。 这当然是个好事情，但是这种使用的简单性使得程序员们过度使用new和delete，而不注意在嵌入式C++环境中的因果关系。并且，在嵌入式系统中，由于内存的限制，频繁的动态分配不定大小的内存会引起很大的问题以及堆破碎的风险。 作为忠告，保守的使用内存分配是嵌入式环境中的第一原则。 但当你必须要使用new 和delete时，你不得不控制C++中的内存分配。你需要用一个全局的new和delete来代替系统的内存分配符，并且一个类一个类的重载new和delete。 一个防止堆破碎的通用方法是从不同固定大小的内存持中分配不同类型的对象。对每个类重载new 和delete就提供了这样的控制。 重载全局的new和delete操作符可以很容易地重载new 和 delete 操作符，如下所示:12345678910void * operator new(size_t size)&#123; void *p = malloc(size); return (p);&#125;void operator delete(void *p);&#123; free(p);&#125; 这段代码可以代替默认的操作符来满足内存分配的请求。出于解释C++的目的，我们也可以直接调用malloc() 和free()。 也可以对单个类的new 和 delete 操作符重载。这是你能灵活的控制对象的内存分配。123456789101112131415class TestClass &#123;public: void * operator new(size_t size); void operator delete(void *p); // .. other members here ...&#125;;void *TestClass::operator new(size_t size)&#123; void *p = malloc(size); // Replace this with alternative allocator return (p);&#125;void TestClass::operator delete(void *p)&#123; free(p); // Replace this with alternative de-allocator&#125; 所有TestClass 对象的内存分配都采用这段代码。更进一步，任何从TestClass 继承的类也都采用这一方式，除非它自己也重载了new 和 delete 操作符。通过重载new 和 delete 操作符的方法，你可以自由地采用不同的分配策略，从不同的内存池中分配不同的类对象。 为单个的类重载 new[ ]和delete[ ]必须小心对象数组的分配。你可能希望调用到被你重载过的new 和 delete 操作符，但并不如此。内存的请求被定向到全局的new[ ]和delete[ ] 操作符，而这些内存来自于系统堆。 C++将对象数组的内存分配作为一个单独的操作，而不同于单个对象的内存分配。为了改变这种方式，你同样需要重载new[ ] 和 delete[ ]操作符。123456789101112131415161718192021class TestClass &#123;public: void * operator new[ ](size_t size); void operator delete[ ](void *p); // .. other members here ..&#125;;void *TestClass::operator new[ ](size_t size)&#123; void *p = malloc(size); return (p);&#125;void TestClass::operator delete[ ](void *p)&#123; free(p);&#125;int main(void)&#123; TestClass *p = new TestClass[10]; // ... etc ... delete[ ] p;&#125; 但是注意：对于多数C++的实现，new[]操作符中的个数参数是数组的大小加上额外的存储对象数目的一些字节。在你的内存分配机制重要考虑的这一点。你应该尽量避免分配对象数组，从而使你的内存分配策略简单。 常见的内存错误及其对策发生内存错误是件非常麻烦的事情。编译器不能自动发现这些错误，通常是在程序运行时才能捕捉到。而这些错误大多没有明显的症状，时隐时现，增加了改错的难度。有时用户怒气冲冲地把你找来，程序却没有发生任何问题，你一走，错误又发作了。 常见的内存错误及其对策如下： 内存分配未成功，却使用了它。 编程新手常犯这种错误，因为他们没有意识到内存分配会不成功。常用解决办法是，在使用内存之前检查指针是否为NULL。如果指针p是函数的参数，那么在函数的入口处用assert(p!=NULL)进行 检查。如果是用malloc或new来申请内存，应该用if(p==NULL) 或if(p!=NULL)进行防错处理。 内存分配虽然成功，但是尚未初始化就引用它。 犯这种错误主要有两个起因：一是没有初始化的观念；二是误以为内存的缺省初值全为零，导致引用初值错误（例如数组）。 内存的缺省初值究竟是什么并没有统一的标准，尽管有些时候为零值，我们宁可信其无不可信其有。所以无论用何种方式创建数组，都别忘了赋初值，即便是赋零值也不可省略，不要嫌麻烦。 内存分配成功并且已经初始化，但操作越过了内存的边界。 例如在使用数组时经常发生下标”多1”或者”少1”的操作。特别是在for循环语句中，循环次数很容易搞错，导致数组操作越界。 忘记了释放内存，造成内存泄露。 含有这种错误的函数每被调用一次就丢失一块内存。刚开始时系统的内存充足，你看不到错误。终有一次程序突然死掉，系统出现提示：内存耗尽。 动态内存的申请与释放必须配对，程序中malloc与free的使用次数一定要相同，否则肯定有错误（new/delete同理）。 释放了内存却继续使用它。 有三种情况： （1）程序中的对象调用关系过于复杂，实在难以搞清楚某个对象究竟是否已经释放了内存，此时应该重新设计数据结构，从根本上解决对象管理的混乱局面。 （2）函数的return语句写错了，注意不要返回指向”栈内存”的”指针”或者”引用”，因为该内存在函数体结束时被自动销毁。 （3）使用free或delete释放了内存后，没有将指针设置为NULL。导致产生”野指针”。 【规则1】用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。 【规则2】不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。 【规则3】避免数组或指针的下标越界，特别要当心发生”多1”或者”少1”操作。 【规则4】动态内存的申请与释放必须配对，防止内存泄漏。 【规则5】用free或delete释放了内存之后，立即将指针设置为NULL，防止产生”野指针”。 指针与数组的对比C++/C程序中，指针和数组在不少地方可以相互替换着用，让人产生一种错觉，以为两者是等价的。 数组要么在静态存储区被创建（如全局数组），要么在栈上被创建。数组名对应着（而不是指向）一块内存，其地址与容量在生命期内保持不变，只有数组的内容可以改变。 指针可以随时指向任意类型的内存块，它的特征是”可变”，所以我们常用指针来操作动态内存。指针远比数组灵活，但也更危险。 下面以字符串为例比较指针与数组的特性。 修改内容下面示例中，字符数组a的容量是6个字符，其内容为hello。a的内容可以改变，如a[0]= ‘X’。指针p指向常量字符串”world”（位于静态存储区，内容为world），常量字符串的内容是不可以被修改的。从语法上看，编译器并不觉得语句p[0]=’X’有什么不妥，但是该语句企图修改常量字符串的内容而导致运行错误。123456char a[] =&quot;hello&quot;;a[0] = &apos;X&apos;;cout&lt;&lt;a&lt;&lt;endl;char *p = &quot;world&quot;; // 注意p指向常量字符串p[0] = &apos;X&apos;; // 编译器不能发现该错误cout&lt;&lt;p&lt;&lt;endl; 内容复制与比较不能对数组名进行直接复制与比较。若想把数组a的内容复制给数组b，不能用语句 b = a ，否则将产生编译错误。应该用标准库函数strcpy进行复制。同理，比较b和a的内容是否相同，不能用if(b==a) 来判断，应该用标准库函数strcmp进行比较。 语句p = a 并不能把a的内容复制指针p，而是把a的地址赋给了p。要想复制a的内容，可以先用库函数malloc为p申请一块容量为strlen(a)+1个字符的内存，再用strcpy进行字符串复制。同理，语句if(p==a) 比较的不是内容而是地址，应该用库函数strcmp来比较。1234567891011// 数组…char a[] = &quot;hello&quot;;char b[10];strcpy(b, a); // 不能用 b = a;if(strcmp(b, a) == 0) // 不能用 if (b == a)…// 指针…int len = strlen(a);char *p = (char *)malloc(sizeof(char)*(len+1));strcpy(p,a); // 不要用 p = a;if(strcmp(p, a) == 0) // 不要用 if (p == a) 计算内存容量用运算符sizeof可以计算出数组的容量（字节数）。如下示例中，sizeof(a)的值是12（注意别忘了’’）。指针p指向a，但是sizeof(p)的值却是4。这是因为sizeof(p)得到的是一个指针变量的字节数，相当于sizeof(char*)，而不是p所指的内存容量。C++/C语言没有办法知道指针所指的内存容量，除非在申请内存时记住它。1234char a[] = &quot;hello world&quot;;char *p = a;cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 12字节cout&lt;&lt; sizeof(p) &lt;&lt; endl; // 4字节 注意当数组作为函数的参数进行传递时，该数组自动退化为同类型的指针。如下示例中，不论数组a的容量是多少，sizeof(a)始终等于sizeof(char *)。1234void Func(char a[100])&#123; cout&lt;&lt; sizeof(a) &lt;&lt; endl; // 4字节而不是100字节&#125; 指针参数是如何传递内存的？如果函数的参数是一个指针，不要指望用该指针去申请动态内存。如下示例中，Test函数的语句GetMemory(str, 200)并没有使str获得期望的内存，str依旧是NULL，为什么？12345678910void GetMemory(char *p, int num)&#123; p = (char *)malloc(sizeof(char) * num);&#125;void Test(void)&#123; char *str = NULL; GetMemory(str, 100); // str 仍然为 NULL strcpy(str, &quot;hello&quot;); // 运行错误&#125; 毛病出在函数GetMemory中。编译器总是要为函数的每个参数制作临时副本，指针参数p的副本是 _p，编译器使 _p = p。如果函数体内的程序修改了_p的内容，就导致参数p的内容作相应的修改。这就是指针可以用作输出参数的原因。在本例中，_p申请了新的内存，只是把_p所指的内存地址改变了，但是p丝毫未变。所以函数GetMemory并不能输出任何东西。事实上，每执行一次GetMemory就会泄露一块内存，因为没有用free释放内存。 如果非得要用指针参数去申请内存，那么应该改用“指向指针的指针”，见示例：123456789101112void GetMemory2(char **p, int num)&#123; *p = (char *)malloc(sizeof(char) * num);&#125;void Test2(void)&#123; char *str = NULL; GetMemory2(&amp;str, 100); // 注意参数是 &amp;str，而不是str strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 由于“指向指针的指针”这个概念不容易理解，我们可以用函数返回值来传递动态内存。这种方法更加简单，见示例：12345678910111213char *GetMemory3(int num)&#123; char *p = (char *)malloc(sizeof(char) * num); return p;&#125;void Test3(void)&#123; char *str = NULL; str = GetMemory3(100); strcpy(str, &quot;hello&quot;); cout&lt;&lt; str &lt;&lt; endl; free(str);&#125; 用函数返回值来传递动态内存这种方法虽然好用，但是常常有人把return语句用错了。这里强调不要用return语句返回指向”栈内存”的指针，因为该内存在函数结束时自动消亡，见示例：1234567891011char *GetString(void)&#123; char p[] = &quot;hello world&quot;; return p; // 编译器将提出警告&#125;void Test4(void)&#123; char *str = NULL; str = GetString(); // str 的内容是垃圾 cout&lt;&lt; str &lt;&lt; endl;&#125; 用调试器逐步跟踪Test4，发现执行str = GetString语句后str不再是NULL指针，但是str的内容不是“hello world”而是垃圾。 如果把上述示例改写成如下示例，会怎么样？1234567891011char *GetString2(void)&#123; char *p = &quot;hello world&quot;; return p;&#125;void Test5(void)&#123; char *str = NULL; str = GetString2(); cout&lt;&lt; str &lt;&lt; endl;&#125; 函数Test5运行虽然不会出错，但是函数GetString2的设计概念却是错误的。因为GetString2内的“hello world”是常量字符串，位于静态存储区，它在程序生命期内恒定不变。无论什么时候调用GetString2，它返回的始终是同一个“只读”的内存块。 杜绝“野指针”“野指针”不是NULL指针，是指向“垃圾”内存的指针。人们一般不会错用NULL指针，因为用if语句很容易判断。但是“野指针”是很危险的，if语句对它不起作用。 “野指针”的成因主要有两种： 指针变量没有被初始化。任何指针变量刚被创建时不会自动成为NULL指针，它的缺省值是随机的，它会乱指一气。所以，指针变量在创建的同时应当被初始化，要么将指针设置为NULL，要么让它指向合法的内存。例如12char *p = NULL;char *str = (char *) malloc(100); 指针p被free或者delete之后，没有置为NULL，让人误以为p是个合法的指针。 指针操作超越了变量的作用域范围。这种情况让人防不胜防，示例程序如下：1234567891011121314class A&#123; public: void Func(void)&#123; cout &lt;&lt; “Func of class A” &lt;&lt; endl; &#125;&#125;;void Test(void)&#123; A *p; &#123; A a; p = &amp;a; // 注意 a 的生命期 &#125; p-&gt;Func(); // p是&quot;野指针&quot;&#125; 函数Test在执行语句p-&gt;Func()时，对象a已经消失，而p是指向a的，所以p就成了”野指针”。但奇怪的是我运行这个程序时居然没有出错，这可能与编译器有关。 有了malloc/free为什么还要new/delete？malloc与free是C++/C语言的标准库函数，new/delete是C++的运算符。它们都可用于申请动态内存和释放内存。 对于非内部数据类型的对象而言，光用malloc/free无法满足动态对象的要求。对象在创建的同时要自动执行构造函数，对象在消亡之前要自动执行析构函数。由于malloc/free是库函数而不是运算符，不在编译器控制权限之内，不能够把执行构造函数和析构函数的任务强加于malloc/free。 因此C++语言需要一个能完成动态内存分配和初始化工作的运算符new，以及一个能完成清理与释放内存工作的运算符delete。注意new/delete不是库函数。我们先看一看malloc/free和new/delete如何实现对象的动态内存管理，见示例：12345678910111213141516171819202122class Obj&#123; public : Obj(void)&#123; cout &lt;&lt; “Initialization” &lt;&lt; endl; &#125; ~Obj(void)&#123; cout &lt;&lt; “Destroy” &lt;&lt; endl; &#125; void Initialize(void)&#123; cout &lt;&lt; “Initialization” &lt;&lt; endl; &#125; void Destroy(void)&#123; cout &lt;&lt; “Destroy” &lt;&lt; endl; &#125;&#125;;void UseMallocFree(void)&#123; Obj *a = (obj *)malloc(sizeof(obj)); // 申请动态内存 a-&gt;Initialize(); // 初始化 //… a-&gt;Destroy(); // 清除工作 free(a); // 释放内存&#125;void UseNewDelete(void)&#123; Obj *a = new Obj; // 申请动态内存并且初始化 //… delete a; // 清除并且释放内存&#125; 类Obj的函数Initialize模拟了构造函数的功能，函数Destroy模拟了析构函数的功能。函数UseMallocFree中，由于malloc/free不能执行构造函数与析构函数，必须调用成员函数Initialize和Destroy来完成初始化与清除工作。函数UseNewDelete则简单得多。 所以我们不要企图用malloc/free来完成动态对象的内存管理，应该用new/delete。由于内部数据类型的”对象”没有构造与析构的过程，对它们而言malloc/free和new/delete是等价的。 既然new/delete的功能完全覆盖了malloc/free，为什么C++不把malloc/free淘汰出局呢？这是因为C++程序经常要调用C函数，而C程序只能用malloc/free管理动态内存。 如果用free释放”new创建的动态对象”，那么该对象因无法执行析构函数而可能导致程序出错。如果用delete释放”malloc申请的动态内存”，结果也会导致程序出错，但是该程序的可读性很差。所以new/delete必须配对使用，malloc/free也一样。 内存耗尽怎么办？如果在申请动态内存时找不到足够大的内存块，malloc和new将返回NULL指针，宣告内存申请失败。通常有三种方式处理”内存耗尽”问题。 判断指针是否为NULL，如果是则马上用return语句终止本函数。例如： 12345678void Func(void)&#123; A *a = new A; if(a == NULL) &#123; return; &#125;&#125; 判断指针是否为NULL，如果是则马上用exit(1)终止整个程序的运行。例如： 123456789void Func(void)&#123; A *a = new A; if(a == NULL) &#123; cout &lt;&lt; “Memory Exhausted” &lt;&lt; endl; exit(1); &#125;&#125; 为new和malloc设置异常处理函数。例如Visual C++可以用_set_new_hander函数为new设置用户自己定义的异常处理函数，也可以让malloc享用与new相同的异常处理函数。详细内容请参考C++使用手册。 上述（1）（2）方式使用最普遍。如果一个函数内有多处需要申请动态内存，那么方式（1）就显得力不从心（释放内存很麻烦），应该用方式（2）来处理。 很多人不忍心用exit(1)，问：”不编写出错处理程序，让操作系统自己解决行不行？” 不行。如果发生”内存耗尽”这样的事情，一般说来应用程序已经无药可救。如果不用exit(1)把坏程序杀死，它可能会害死操作系统。道理如同：如果不把歹徒击毙，歹徒在老死之前会犯下更多的罪。 有一个很重要的现象要告诉大家。对于32位以上的应用程序而言，无论怎样使用malloc与new，几乎不可能导致”内存耗尽”。我在Windows 98下用Visual C++编写了测试程序，见示例7。这个程序会无休止地运行下去，根本不会终止。因为32位操作系统支持”虚存”，内存用完了，自动用硬盘空间顶替。我只听到硬盘嘎吱嘎吱地响，Window 98已经累得对键盘、鼠标毫无反应。 我可以得出这么一个结论：对于32位以上的应用程序，”内存耗尽”错误处理程序毫无用处。这下可把Unix和Windows程序员们乐坏了：反正错误处理程序不起作用，我就不写了，省了很多麻烦。 我不想误导读者，必须强调：不加错误处理将导致程序的质量很差，千万不可因小失大。1234567891011void main(void)&#123; float *p = NULL; while(TRUE) &#123; p = new float[1000000]; cout &lt;&lt; “eat memory” &lt;&lt; endl; if(p==NULL) exit(1); &#125;&#125; malloc/free的使用要点函数malloc的原型如下：1void * malloc(size_t size); 用malloc申请一块长度为length的整数类型的内存，程序如下：1int *p = (int *) malloc(sizeof(int) * length); 我们应当把注意力集中在两个要素上：”类型转换”和”sizeof”。 malloc返回值的类型是void ，所以在调用malloc时要显式地进行类型转换，将void 转换成所需要的指针类型。 malloc函数本身并不识别要申请的内存是什么类型，它只关心内存的总字节数。我们通常记不住int, float等数据类型的变量的确切字节数。例如int变量在16位系统下是2个字节，在32位下是4个字节；而float变量在16位系统下是4个字节，在32位下也是4个字节。最好用以下程序作一次测试： 12345678cout &lt;&lt; sizeof(char) &lt;&lt; endl;cout &lt;&lt; sizeof(int) &lt;&lt; endl;cout &lt;&lt; sizeof(unsigned int) &lt;&lt; endl;cout &lt;&lt; sizeof(long) &lt;&lt; endl;cout &lt;&lt; sizeof(unsigned long) &lt;&lt; endl;cout &lt;&lt; sizeof(float) &lt;&lt; endl;cout &lt;&lt; sizeof(double) &lt;&lt; endl;cout &lt;&lt; sizeof(void *) &lt;&lt; endl; 在malloc的”()”中使用sizeof运算符是良好的风格，但要当心有时我们会昏了头，写出 p = malloc(sizeof(p))这样的程序来。 函数free的原型如下：1void free( void * memblock ); 为什么free函数不象malloc函数那样复杂呢？这是因为指针p的类型以及它所指的内存的容量事先都是知道的，语句free(p)能正确地释放内存。如果p是NULL指针，那么free对p无论操作多少次都不会出问题。如果p不是NULL指针，那么free对p连续操作两次就会导致程序运行错误。 new/delete的使用要点运算符new使用起来要比函数malloc简单得多，例如：123int *p1 = (int *)malloc(sizeof(int) * length);int *p2 = new int[length]; 这是因为new内置了sizeof、类型转换和类型安全检查功能。对于非内部数据类型的对象而言，new在创建动态对象的同时完成了初始化工作。如果对象有多个构造函数，那么new的语句也可以有多种形式。例如1234567891011121314class Obj&#123; public : Obj(void); // 无参数的构造函数 Obj(int x); // 带一个参数的构造函数&#125;void Test(void)&#123; Obj *a = new Obj; Obj *b = new Obj(1); // 初值为1 delete a; delete b;&#125; 如果用new创建对象数组，那么只能使用对象的无参数构造函数。例如：1Obj *objects = new Obj[100]; // 创建100个动态对象 不能写成：1Obj *objects = new Obj[100](1);// 创建100个动态对象的同时赋初值1 在用delete释放对象数组时，留意不要丢了符号’[]’。例如：12delete []objects; // 正确的用法delete objects; // 错误的用法 后者有可能引起程序崩溃和内存泄漏。 C++中的健壮指针和资源管理我最喜欢的对资源的定义是：”任何在你的程序中获得并在此后释放的东西?quot;内存是一个相当明显的资源的例子。它需要用new来获得，用delete来释放。同时也有许多其它类型的资源文件句柄、重要的片断、Windows中的GDI资源，等等。将资源的概念推广到程序中创建、释放的所有对象也是十分方便的，无论对象是在堆中分配的还是在栈中或者是在全局作用于内生命的。 对于给定的资源的拥有着，是负责释放资源的一个对象或者是一段代码。所有权分立为两种级别——自动的和显式的（automatic and explicit），如果一个对象的释放是由语言本身的机制来保证的，这个对象的就是被自动地所有。例如，一个嵌入在其他对象中的对象，他的清除需要其他对象来在清除的时候保证。外面的对象被看作嵌入类的所有者。 类似地，每个在栈上创建的对象（作为自动变量）的释放（破坏）是在控制流离开了对象被定义的作用域的时候保证的。这种情况下，作用于被看作是对象的所有者。注意所有的自动所有权都是和语言的其他机制相容的，包括异常。无论是如何退出作用域的————正常流程控制退出、一个break语句、一个return、一个goto、或者是一个throw————自动资源都可以被清除。 到目前为止，一切都很好！问题是在引入指针、句柄和抽象的时候产生的。如果通过一个指针访问一个对象的话，比如对象在堆中分配，C++不自动地关注它的释放。程序员必须明确的用适当的程序方法来释放这些资源。比如说，如果一个对象是通过调用new来创建的，它需要用delete来回收。一个文件是用CreateFile(Win32 API)打开的，它需要用CloseHandle来关闭。用EnterCritialSection进入的临界区（Critical Section）需要LeaveCriticalSection退出，等等。一个”裸”指针，文件句柄，或者临界区状态没有所有者来确保它们的最终释放。基本的资源管理的前提就是确保每个资源都有他们的所有者。 第一条规则（RAII）一个指针，一个句柄，一个临界区状态只有在我们将它们封装入对象的时候才会拥有所有者。这就是我们的第一规则：在构造函数中分配资源，在析构函数中释放资源。 当你按照规则将所有资源封装的时候，你可以保证你的程序中没有任何的资源泄露。这点在当封装对象（Encapsulating Object）在栈中建立或者嵌入在其他的对象中的时候非常明显。但是对那些动态申请的对象呢？不要急！任何动态申请的东西都被看作一种资源，并且要按照上面提到的方法进行封装。这一对象封装对象的链不得不在某个地方终止。它最终终止在最高级的所有者，自动的或者是静态的。这些分别是对离开作用域或者程序时释放资源的保证。 下面是资源封装的一个经典例子。在一个多线程的应用程序中，线程之间共享对象的问题是通过用这样一个对象联系临界区来解决的。每一个需要访问共享资源的客户需要获得临界区。例如，这可能是Win32下临界区的实现方法。123456789101112131415161718class CritSect&#123; friend class Lock; public: CritSect () &#123; InitializeCriticalSection (&amp;_critSection); &#125; ~CritSect () &#123; DeleteCriticalSection (&amp;_critSection); &#125; private: void Acquire () &#123; EnterCriticalSection (&amp;_critSection); &#125; void Release () &#123; LeaveCriticalSection (&amp;_critSection); &#125; private: CRITICAL_SECTION _critSection;&#125;; 这里聪明的部分是我们确保每一个进入临界区的客户最后都可以离开。”进入”临界区的状态是一种资源，并应当被封装。封装器通常被称作一个锁（lock）。1234567891011121314class Lock&#123; public: Lock (CritSect&amp; critSect) : _critSect (critSect) &#123; _critSect.Acquire (); &#125; ~Lock () &#123; _critSect.Release (); &#125; private CritSect &amp; _critSect;&#125;; 锁一般的用法如下：123456void Shared::Act () throw (char *)&#123; Lock lock (_critSect); // perform action —— may throw // automatic destructor of lock&#125; 注意无论发生什么，临界区都会借助于语言的机制保证释放。 还有一件需要记住的事情————每一种资源都需要被分别封装。这是因为资源分配是一个非常容易出错的操作，是要资源是有限提供的。我们会假设一个失败的资源分配会导致一个异常————事实上，这会经常的发生。所以如果你想试图用一个石头打两只鸟的话，或者在一个构造函数中申请两种形式的资源，你可能就会陷入麻烦。只要想想在一种资源分配成功但另一种失败抛出异常时会发生什么。因为构造函数还没有全部完成，析构函数不可能被调用，第一种资源就会发生泄露。 这种情况可以非常简单的避免。无论何时你有一个需要两种以上资源的类时，写两个小的封装器将它们嵌入你的类中。每一个嵌入的构造都可以保证删除，即使包装类没有构造完成。 Smart Pointers我们至今还没有讨论最常见类型的资源————用操作符new分配，此后用指针访问的一个对象。我们需要为每个对象分别定义一个封装类吗？（事实上，C++标准模板库已经有了一个模板类，叫做auto_ptr，其作用就是提供这种封装。我们一会儿在回到auto_ptr。）让我们从一个极其简单、呆板但安全的东西开始。看下面的Smart Pointer模板类，它十分坚固，甚至无法实现。123456789101112template &lt;class T&gt;class SmartPointer&#123; public: ~SmartPointer () &#123; delete _p; &#125; T * operator-&gt;() &#123; return _p; &#125; T const * operator-&gt;() const &#123; return _p; &#125; protected: SmartPointer (): _p (0) &#123;&#125; explicit SmartPointer (T* p): _p (p) &#123;&#125; T * _p;&#125;; 为什么要把SmartPointer的构造函数设计为protected呢？如果我需要遵守第一条规则，那么我就必须这样做。资源————在这里是class T的一个对象————必须在封装器的构造函数中分配。但是我不能只简单的调用new T，因为我不知道T的构造函数的参数。因为，在原则上，每一个T都有一个不同的构造函数；我需要为他定义个另外一个封装器。模板的用处会很大，为每一个新的类，我可以通过继承SmartPointer定义一个新的封装器，并且提供一个特定的构造函数。123456class SmartItem: public SmartPointer&lt;Item&gt;&#123; public: explicit SmartItem (int i) : SmartPointer&lt;Item&gt; (new Item (i)) &#123;&#125;&#125;; 为每一个类提供一个Smart Pointer真的值得吗？说实话————不！他很有教学的价值，但是一旦你学会如何遵循第一规则的话，你就可以放松规则并使用一些高级的技术。这一技术是让SmartPointer的构造函数成为public，但是只是是用它来做资源转换（Resource Transfer）我的意思是用new操作符的结果直接作为SmartPointer的构造函数的参数，像这样：1SmartPointer&lt;Item&gt; item (new Item (i)); 这个方法明显更需要自控性，不只是你，而且包括你的程序小组的每个成员。他们都必须发誓出了作资源转换外不把构造函数用在人以其他用途。幸运的是，这条规矩很容易得以加强。只需要在源文件中查找所有的new即可。 Resource Transfer到目前为止，我们所讨论的一直是生命周期在一个单独的作用域内的资源。现在我们要解决一个困难的问题————如何在不同的作用域间安全的传递资源。这一问题在当你处理容器的时候会变得十分明显。你可以动态的创建一串对象，将它们存放至一个容器中，然后将它们取出，并且在最终安排它们。为了能够让这安全的工作————没有泄露————对象需要改变其所有者。 这个问题的一个非常显而易见的解决方法是使用Smart Pointer，无论是在加入容器前还是还找到它们以后。这是他如何运作的，你加入Release方法到Smart Pointer中：1234567template &lt;class T&gt;T * SmartPointer&lt;T&gt;::Release ()&#123; T * pTmp = _p; _p = 0; return pTmp;&#125; 注意在Release调用以后，Smart Pointer就不再是对象的所有者了————它内部的指针指向空。现在，调用了Release都必须是一个负责的人并且迅速隐藏返回的指针到新的所有者对象中。在我们的例子中，容器调用了Release，比如这个Stack的例子：123456void Stack::Push (SmartPointer &lt;Item&gt; &amp; item) throw (char *)&#123; if (_top == maxStack) throw &quot;Stack overflow&quot;; _arr [_top++] = item.Release ();&#125;; 同样的，你也可以再你的代码中用加强Release的可靠性。 相应的Pop方法要做些什么呢？他应该释放了资源并祈祷调用它的是一个负责的人而且立即作一个资源传递它到一个Smart Pointer？这听起来并不好。 Strong Pointers资源管理在内容索引（Windows NT Server上的一部分，现在是Windows 2000）上工作，并且，我对这十分满意。然后我开始想……这一方法是在这样一个完整的系统中形成的，如果可以把它内建入语言的本身岂不是一件非常好？我提出了强指针（Strong Pointer）和弱指针(Weak Pointer)。一个Strong Pointer会在许多地方和我们这个SmartPointer相似–它在超出它的作用域后会清除他所指向的对象。资源传递会以强指针赋值的形式进行。也可以有Weak Pointer存在，它们用来访问对象而不需要所有对象–比如可赋值的引用。 任何指针都必须声明为Strong或者Weak，并且语言应该来关注类型转换的规定。例如，你不可以将Weak Pointer传递到一个需要Strong Pointer的地方，但是相反却可以。Push方法可以接受一个Strong Pointer并且将它转移到Stack中的Strong Pointer的序列中。Pop方法将会返回一个Strong Pointer。把Strong Pointer的引入语言将会使垃圾回收成为历史。 这里还有一个小问题–修改C++标准几乎和竞选美国总统一样容易。当我将我的注意告诉给Bjarne Stroutrup的时候，他看我的眼神好像是我刚刚要向他借一千美元一样。 然后我突然想到一个念头。我可以自己实现Strong Pointers。毕竟，它们都很想Smart Pointers。给它们一个拷贝构造函数并重载赋值操作符并不是一个大问题。事实上，这正是标准库中的auto_ptr有的。重要的是对这些操作给出一个资源转移的语法，但是这也不是很难。1234567891011121314template &lt;class T&gt;SmartPointer&lt;T&gt;::SmartPointer (SmartPointer&lt;T&gt; &amp; ptr)&#123; _p = ptr.Release ();&#125;template &lt;class T&gt;void SmartPointer&lt;T&gt;::operator = (SmartPointer&lt;T&gt; &amp; ptr)&#123; if (_p != ptr._p) &#123; delete _p; _p = ptr.Release (); &#125;&#125; 使这整个想法迅速成功的原因之一是我可以以值方式传递这种封装指针！我有了我的蛋糕，并且也可以吃了。看这个Stack的新的实现：1234567891011121314151617181920212223class Stack&#123; enum &#123; maxStack = 3 &#125;; public: Stack () : _top (0) &#123;&#125; void Push (SmartPointer&lt;Item&gt; &amp; item) throw (char *) &#123; if (_top &gt;= maxStack) throw &quot;Stack overflow&quot;; _arr [_top++] = item; &#125; SmartPointer&lt;Item&gt; Pop () &#123; if (_top == 0) return SmartPointer&lt;Item&gt; (); return _arr [--_top]; &#125; private int _top; SmartPointer&lt;Item&gt; _arr [maxStack];&#125;; Pop方法强制客户将其返回值赋给一个Strong Pointer,SmartPointer。任何试图将他对一个普通指针的赋值都会产生一个编译期错误，因为类型不匹配。此外，因为Pop以值方式返回一个Strong Pointer(在Pop的声明时SmartPointer后面没有&amp;符号)，编译器在return时自动进行了一个资源转换。他调用了operator =来从数组中提取一个Item,拷贝构造函数将他传递给调用者。调用者最后拥有了指向Pop赋值的Strong Pointer指向的一个Item。 我马上意识到我已经在某些东西之上了。我开始用了新的方法重写原来的代码。 Parser我过去有一个老的算术操作分析器，是用老的资源管理的技术写的。分析器的作用是在分析树中生成节点，节点是动态分配的。例如分析器的Expression方法生成一个表达式节点。我没有时间用Strong Pointer去重写这个分析器。我令Expression、Term和Factor方法以传值的方式将Strong Pointer返回到Node中。看下面的Expression方法的实现：123456789101112131415161718192021SmartPointer&lt;Node&gt; Parser::Expression()&#123; // Parse a term SmartPointer&lt;Node&gt; pNode = Term (); EToken token = _scanner.Token(); if ( token == tPlus || token == tMinus ) &#123; // Expr := Term &#123; (&apos;+&apos; | &apos;-&apos;) Term &#125; SmartPointer&lt;MultiNode&gt; pMultiNode = new SumNode (pNode); do &#123; _scanner.Accept(); SmartPointer&lt;Node&gt; pRight = Term (); pMultiNode-&gt;AddChild (pRight, (token == tPlus)); token = _scanner.Token(); &#125; while (token == tPlus || token == tMinus); pNode = up_cast&lt;Node, MultiNode&gt; (pMultiNode); &#125; // otherwise Expr := Term return pNode; // by value!&#125; 最开始，Term方法被调用。他传值返回一个指向Node的Strong Pointer并且立刻把它保存到我们自己的Strong Pointer,pNode中。如果下一个符号不是加号或者减号，我们就简单的把这个SmartPointer以值返回，这样就释放了Node的所有权。另外一方面，如果下一个符号是加号或者减号，我们创建一个新的SumMode并且立刻（直接传递）将它储存到MultiNode的一个Strong Pointer中。这里，SumNode是从MultiMode中继承而来的，而MulitNode是从Node继承而来的。原来的Node的所有权转给了SumNode。 只要是他们在被加号和减号分开的时候，我们就不断的创建terms，我们将这些term转移到我们的MultiNode中，同时MultiNode得到了所有权。最后，我们将指向MultiNode的Strong Pointer向上映射为指向Mode的Strong Pointer，并且将他返回调用着。 我们需要对Strong Pointers进行显式的向上映射，即使指针是被隐式的封装。例如，一个MultiNode是一个Node，但是相同的is-a关系在SmartPointer和SmartPointer之间并不存在，因为它们是分离的类（模板实例）并不存在继承关系。up-cast模板是像下面这样定义的：12345template&lt;class To, class From&gt;inline SmartPointer&lt;To&gt; up_cast (SmartPointer&lt;From&gt; &amp; from)&#123; return SmartPointer&lt;To&gt; (from.Release ());&#125; 如果你的编译器支持新加入标准的成员模板（member template）的话，你可以为SmartPointer定义一个新的构造函数用来从接受一个class U。1234template &lt;class T&gt;template &lt;class U&gt; SmartPointer&lt;T&gt;::SmartPointer (SPrt&lt;U&gt; &amp; uptr): _p (uptr.Release ())&#123;&#125; 这里的这个花招是模板在U不是T的子类的时候就不会编译成功（换句话说，只在U is-a T的时候才会编译）。这是因为uptr的缘故。Release()方法返回一个指向U的指针，并被赋值为_p，一个指向T的指针。所以如果U不是一个T的话，赋值会导致一个编译时刻错误。1std::auto_ptr 后来我意识到在STL中的auto_ptr模板，就是我的Strong Pointer。在那时候还有许多的实现差异（auto_ptr的Release方法并不将内部的指针清零–你的编译器的库很可能用的就是这种陈旧的实现），但是最后在标准被广泛接受之前都被解决了。 Transfer Semantics目前为止，我们一直在讨论在C++程序中资源管理的方法。宗旨是将资源封装到一些轻量级的类中，并由类负责它们的释放。特别的是，所有用new操作符分配的资源都会被储存并传递进Strong Pointer（标准库中的auto_ptr）的内部。 这里的关键词是传递（passing）。一个容器可以通过传值返回一个StrongPointer来安全的释放资源。容器的客户只能够通过提供一个相应的Strong Pointer来保存这个资源。任何一个将结果赋给一个”裸”指针的做法都立即会被编译器发现。12auto_ptr&lt;Item&gt; item = stack.Pop (); // okItem * p = stack.Pop (); // Error! Type mismatch. 以传值方式被传递的对象有value semantics 或者称为 copy semantics。Strong Pointers是以值方式传递的–但是我们能说它们有copy semantics吗？不是这样的！它们所指向的对象肯定没有被拷贝过。事实上，传递过后，源auto_ptr不在访问原有的对象，并且目标auto_ptr成为了对象的唯一拥有者（但是往往auto_ptr的旧的实现即使在释放后仍然保持着对对象的所有权）。自然而然的我们可以将这种新的行为称作Transfer Semantics。 拷贝构造函数（copy construcor）和赋值操作符定义了auto_ptr的Transfer Semantics，它们用了非const的auto_ptr引用作为它们的参数。12auto_ptr (auto_ptr&lt;T&gt; &amp; ptr);auto_ptr &amp; operator = (auto_ptr&lt;T&gt; &amp; ptr); 这是因为它们确实改变了他们的源–剥夺了对资源的所有权。 通过定义相应的拷贝构造函数和重载赋值操作符，你可以将Transfer Semantics加入到许多对象中。例如，许多Windows中的资源，比如动态建立的菜单或者位图，可以用有Transfer Semantics的类来封装。 Strong Vectors标准库只在auto_ptr中支持资源管理。甚至连最简单的容器也不支持ownership semantics。你可能想将auto_ptr和标准容器组合到一起可能会管用，但是并不是这样的。例如，你可能会这样做，但是会发现你不能够用标准的方法来进行索引。1vector&lt; auto_ptr&lt;Item&gt; &gt; autoVector; 这种建造不会编译成功；1Item * item = autoVector [0]; 另一方面，这会导致一个从autoVect到auto_ptr的所有权转换：1auto_ptr&lt;Item&gt; item = autoVector [0]; 我们没有选择，只能够构造我们自己的Strong Vector。最小的接口应该如下：123456789101112template &lt;class T&gt;class auto_vector&#123; public: explicit auto_vector (size_t capacity = 0); T const * operator [] (size_t i) const; T * operator [] (size_t i); void assign (size_t i, auto_ptr&lt;T&gt; &amp; p); void assign_direct (size_t i, T * p); void push_back (auto_ptr&lt;T&gt; &amp; p); auto_ptr&lt;T&gt; pop_back ();&#125;; 你也许会发现一个非常防御性的设计态度。我决定不提供一个对vector的左值索引的访问，取而代之，如果你想设定(set)一个值的话，你必须用assign或者assign_direct方法。我的观点是，资源管理不应该被忽视，同时，也不应该在所有的地方滥用。在我的经验里，一个strong vector经常被许多push_back方法充斥着。 Strong vector最好用一个动态的Strong Pointers的数组来实现：123456789template &lt;class T&gt;class auto_vector&#123;private void grow (size_t reqCapacity); auto_ptr&lt;T&gt; *_arr; size_t _capacity; size_t _end;&#125;; grow方法申请了一个很大的auto_ptr的数组，将所有的东西从老的书组类转移出来，在其中交换，并且删除原来的数组。 auto_vector的其他实现都是十分直接的，因为所有资源管理的复杂度都在auto_ptr中。例如，assign方法简单的利用了重载的赋值操作符来删除原有的对象并转移资源到新的对象：1234void assign (size_t i, auto_ptr&lt;T&gt; &amp; p)&#123; _arr [i] = p;&#125; 我已经讨论了push_back和pop_back方法。push_back方法传值返回一个auto_ptr，因为它将所有权从auto_vector转换到auto_ptr中。 对auto_vector的索引访问是借助auto_ptr的get方法来实现的，get简单的返回一个内部指针。1234T * operator [] (size_t i)&#123; return _arr [i].get ();&#125; 没有容器可以没有iterator。我们需要一个iterator让auto_vector看起来更像一个普通的指针向量。特别是，当我们废弃iterator的时候，我们需要的是一个指针而不是auto_ptr。我们不希望一个auto_vector的iterator在无意中进行资源转换。123456789101112131415template&lt;class T&gt;class auto_iterator: publiciterator&lt;random_access_iterator_tag, T *&gt;&#123; public: auto_iterator () : _pp (0) &#123;&#125; auto_iterator (auto_ptr&lt;T&gt; * pp) : _pp (pp) &#123;&#125; bool operator != (auto_iterator&lt;T&gt; const &amp; it) const &#123; return it._pp != _pp; &#125; auto_iterator const &amp; operator++ (int) &#123; return _pp++; &#125; auto_iterator operator++ () &#123; return ++_pp; &#125; T * operator * () &#123; return _pp-&gt;get (); &#125; private auto_ptr&lt;T&gt; * _pp;&#125;; 我们给auto_vect提供了标准的begin和end方法来找回iterator：1234567class auto_vector&#123;public: typedef auto_iterator&lt;T&gt; iterator; iterator begin () &#123; return _arr; &#125; iterator end () &#123; return _arr + _end; &#125;&#125;; 你也许会问我们是否要利用资源管理重新实现每一个标准的容器？幸运的是，不；事实是strongvector解决了大部分所有权的需求。当你把你的对象都安全的放置到一个strong vector中，你可以用所有其它的容器来重新安排（weak）pointer。 设想，例如，你需要对一些动态分配的对象排序的时候。你将它们的指针保存到一个strongvector中。然后你用一个标准的vector来保存从strong vector中获得的weak指针。你可以用标准的算法对这个vector进行排序。这种中介vector叫做permutation vector。相似的，你也可以用标准的maps, priority queues, heaps, hash tables等等。 Code Inspection如果你严格遵照资源管理的条款，你就不会再资源泄露或者两次删除的地方遇到麻烦。你也降低了访问野指针的几率。同样的，遵循原有的规则，用delete删除用new申请的德指针，不要两次删除一个指针。你也不会遇到麻烦。但是，那个是更好的注意呢？ 这两个方法有一个很大的不同点。就是和寻找传统方法的bug相比，找到违反资源管理的规定要容易的多。后者仅需要一个代码检测或者一个运行测试，而前者则在代码中隐藏得很深，并需要很深的检查。 设想你要做一段传统的代码的内存泄露检查。第一件事，你要做的就是grep所有在代码中出现的new，你需要找出被分配空间地指针都作了什么。你需要确定导致删除这个指针的所有的执行路径。你需要检查break语句，过程返回，异常。原有的指针可能赋给另一个指针，你对这个指针也要做相同的事。 相比之下，对于一段用资源管理技术实现的代码。你也用grep检查所有的new，但是这次你只需要检查邻近的调用： ● 这是一个直接的Strong Pointer转换，还是我们在一个构造函数的函数体中？ ● 调用的返回知是否立即保存到对象中，构造函数中是否有可以产生异常的代码。？ ● 如果这样的话析构函数中时候有delete? 下一步，你需要用grep查找所有的release方法，并实施相同的检查。 不同点是需要检查、理解单个执行路径和只需要做一些本地的检验。这难道不是提醒你非结构化的和结构化的程序设计的不同吗？原理上，你可以认为你可以应付goto，并且跟踪所有的可能分支。另一方面，你可以将你的怀疑本地化为一段代码。本地化在两种情况下都是关键所在。 在资源管理中的错误模式也比较容易调试。最常见的bug是试图访问一个释放过的strong pointer。这将导致一个错误，并且很容易跟踪。 共享的所有权为每一个程序中的资源都找出或者指定一个所有者是一件很容易的事情吗？答案是出乎意料的，是！如果你发现了一些问题，这可能说明你的设计上存在问题。还有另一种情况就是共享所有权是最好的甚至是唯一的选择。 共享的责任分配给被共享的对象和它的客户（client）。一个共享资源必须为它的所有者保持一个引用计数。另一方面，所有者再释放资源的时候必须通报共享对象。最后一个释放资源的需要在最后负责free的工作。 最简单的共享的实现是共享对象继承引用计数的类RefCounted：12345678910class RefCounted&#123;public: RefCounted () : _count (1) &#123;&#125; int GetRefCount () const &#123; return _count; &#125; void IncRefCount () &#123; _count++; &#125; int DecRefCount () &#123; return --_count; &#125;private int _count;&#125;; 按照资源管理，一个引用计数是一种资源。如果你遵守它，你需要释放它。当你意识到这一事实的时候，剩下的就变得简单了。简单的遵循规则–再构造函数中获得引用计数，在析构函数中释放。甚至有一个RefCounted的smart pointer等价物：123456789101112131415161718template &lt;class T&gt;class RefPtr&#123; public: RefPtr (T * p) : _p (p) &#123;&#125; RefPtr (RefPtr&lt;T&gt; &amp; p) &#123; _p = p._p; _p-&gt;IncRefCount (); &#125; ~RefPtr () &#123; if (_p-&gt;DecRefCount () == 0) delete _p; &#125; private T * _p;&#125;; 注意模板中的T不比成为RefCounted的后代，但是它必须有IncRefCount和DecRefCount的方法。当然，一个便于使用的RefPtr需要有一个重载的指针访问操作符。在RefPtr中加入转换语义学（transfer semantics）是读者的工作。 所有权网络链表是资源管理分析中的一个很有意思的例子。如果你选择表成为链(link)的所有者的话，你会陷入实现递归的所有权。每一个link都是它的继承者的所有者，并且，相应的，余下的链表的所有者。下面是用smart pointer实现的一个表单元：123456class Link&#123;// ...private auto_ptr&lt;Link&gt; _next;&#125;; 最好的方法是，将连接控制封装到一个弄构进行资源转换的类中。 对于双链表呢？安全的做法是指明一个方向，如forward:1234567class DoubleLink&#123;// ...private DoubleLink *_prev; auto_ptr&lt;DoubleLink&gt; _next;&#125;; 注意不要创建环形链表。 这给我们带来了另外一个有趣的问题–资源管理可以处理环形的所有权吗？它可以，用一个mark-and-sweep的算法。这里是实现这种方法的一个例子：12345678910111213141516171819202122template&lt;class T&gt;class CyclPtr&#123; public: CyclPtr (T * p) :_p (p), _isBeingDeleted (false) &#123;&#125; ~CyclPtr () &#123; _isBeingDeleted = true; if (!_p-&gt;IsBeingDeleted ()) delete _p; &#125; void Set (T * p) &#123; _p = p; &#125; bool IsBeingDeleted () const &#123; return _isBeingDeleted; &#125; private T * _p; bool _isBeingDeleted;&#125;; 注意我们需要用class T来实现方法IsBeingDeleted，就像从CyclPtr继承。对特殊的所有权网络普通化是十分直接的。 将原有代码转换为资源管理代码 如果你是一个经验丰富的程序员，你一定会知道找资源的bug是一件浪费时间的痛苦的经历。我不必说服你和你的团队花费一点时间来熟悉资源管理是十分值得的。你可以立即开始用这个方法，无论你是在开始一个新项目或者是在一个项目的中期。转换不必立即全部完成。下面是步骤。 首先，在你的工程中建立基本的Strong Pointer。然后通过查找代码中的new来开始封装裸指针。 最先封装的是在过程中定义的临时指针。简单的将它们替换为auto_ptr并且删除相应的delete。如果一个指针在过程中没有被删除而是被返回，用auto_ptr替换并在返回前调用release方法。在你做第二次传递的时候，你需要处理对release的调用。注意，即使是在这点，你的代码也可能更加”精力充沛”–你会移出代码中潜在的资源泄漏问题。 下面是指向资源的裸指针。确保它们被独立的封装到auto_ptr中，或者在构造函数中分配在析构函数中释放。如果你有传递所有权的行为的话，需要调用release方法。如果你有容器所有对象，用Strong Pointers重新实现它们。 接下来，找到所有对release的方法调用并且尽力清除所有，如果一个release调用返回一个指针，将它修改传值返回一个auto_ptr。 重复着一过程，直到最后所有new和release的调用都在构造函数或者资源转换的时候发生。这样，你在你的代码中处理了资源泄漏的问题。对其他资源进行相似的操作。 你会发现资源管理清除了许多错误和异常处理带来的复杂性。不仅仅你的代码会变得精力充沛，它也会变得简单并容易维护。 内存泄漏C++中动态内存分配引发问题的解决方案假设我们要开发一个String类，它可以方便地处理字符串数据。我们可以在类中声明一个数组，考虑到有时候字符串极长，我们可以把数组大小设为200，但一般的情况下又不需要这么多的空间，这样是浪费了内存。对了，我们可以使用new操作符，这样是十分灵活的，但在类中就会出现许多意想不到的问题，本文就是针对这一现象而写的。现在，我们先来开发一个String类，但它是一个不完善的类。的确，我们要刻意地使它出现各种各样的问题，这样才好对症下药。好了，我们开始吧！1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* String.h */#ifndef STRING_H_#define STRING_H_class String&#123;private: char * str; //存储数据 int len; //字符串长度public: String(const char * s); //构造函数 String(); // 默认构造函数 ~String(); // 析构函数 friend ostream &amp; operator&lt;&lt;(ostream &amp; os,const String&amp; st);&#125;;#endif/*String.cpp*/#include &lt;iostream＞#include &lt;cstring＞#include &quot;String.h&quot;using namespace std;String::String(const char * s)&#123; len = strlen(s); str = new char[len + 1]; strcpy(str, s);&#125;//拷贝数据String::String()&#123; len =0; str = new char[len+1]; str[0]=&apos;&quot;0&apos;;&#125;String::~String()&#123; cout&lt;&lt;&quot;这个字符串将被删除：&quot;&lt;&lt;str&lt;&lt;&apos;&quot;n&apos;;//为了方便观察结果，特留此行代码。 delete [] str;&#125;ostream &amp; operator&lt;&lt;(ostream &amp; os, const String &amp; st)&#123; os &lt;&lt; st.str; return os;&#125;/*test_right.cpp*/#include &lt;iostream＞#include &lt;stdlib.h＞#include &quot;String.h&quot;using namespace std;int main()&#123; String temp(&quot;天极网&quot;); cout&lt;&lt;temp&lt;&lt;&apos;&quot;n&apos;; system(&quot;PAUSE&quot;); return 0;&#125; 运行结果：123天极网按任意键继续. . . 大家可以看到，以上程序十分正确，而且也是十分有用的。可是，我们不能被表面现象所迷惑！下面，请大家用test_String.cpp文件替换test_right.cpp文件进行编译，看看结果。有的编译器可能就是根本不能进行编译！ test_String.cpp:12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream＞#include &lt;stdlib.h＞#include &quot;String.h&quot;using namespace std;void show_right(const String&amp;);void show_String(const String);//注意，参数非引用，而是按值传递。int main()&#123; String test1(&quot;第一个范例。&quot;); String test2(&quot;第二个范例。&quot;); String test3(&quot;第三个范例。&quot;); String test4(&quot;第四个范例。&quot;); cout&lt;&lt;&quot;下面分别输入三个范例&quot;; cout&lt;&lt;test1&lt;&lt;endl; cout&lt;&lt;test2&lt;&lt;endl; cout&lt;&lt;test3&lt;&lt;endl; String* String1=new String(test1); cout&lt;&lt;*String1&lt;&lt;endl; delete String1; cout&lt;&lt;test1&lt;&lt;endl; //在Dev-cpp上没有任何反应。 cout&lt;&lt;&quot;使用正确的函数：&quot;&lt;&lt;endl; show_right(test2); cout&lt;&lt;test2&lt;&lt;endl; cout&lt;&lt;&quot;使用错误的函数：&quot;&lt;&lt;endl; show_String(test2); cout&lt;&lt;test2&lt;&lt;endl; //这一段代码出现严重的错误！ String String2(test3); cout&lt;&lt;&quot;String2: &quot;&lt;&lt;String2&lt;&lt;endl; String String3; String3=test4; cout&lt;&lt;&quot;String3: &quot;&lt;&lt;String3&lt;&lt;endl; cout&lt;&lt;&quot;下面，程序结束，析构函数将被调用。&quot;&lt;&lt;endl; return 0;&#125;void show_right(const String&amp; a)&#123; cout&lt;&lt;a&lt;&lt;endl;&#125;void show_String(const String a)&#123; cout&lt;&lt;a&lt;&lt;endl;&#125; 运行结果：1234567891011121314151617181920212223下面分别输入三个范例：第一个范例。第二个范例。第三个范例。第一个范例。这个字符串将被删除：第一个范例。使用正确的函数：第二个范例。第二个范例。使用错误的函数：第二个范例。这个字符串将被删除：第二个范例。这个字符串将被删除：?=?=String2: 第三个范例。String3: 第四个范例。下面，程序结束，析构函数将被调用。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：?=这个字符串将被删除：x =这个字符串将被删除：?=这个字符串将被删除： 现在，请大家自己试试运行结果，或许会更加惨不忍睹呢！下面，我为大家一一分析原因。 首先，大家要知道，C＋＋类有以下这些极为重要的函数： 一：复制构造函数。 二：赋值函数。 我们先来讲复制构造函数。什么是复制构造函数呢？比如，我们可以写下这样的代码：String test1(test2);这是进行初始化。我们知道，初始化对象要用构造函数。可这儿呢？按理说，应该有声明为这样的构造函数：String(const String &amp;);可是，我们并没有定义这个构造函数呀？答案是，C＋＋提供了默认的复制构造函数，问题也就出在这儿。 （1）：什么时候会调用复制构造函数呢？（以String类为例。） 在我们提供这样的代码：String test1(test2)时，它会被调用；当函数的参数列表为按值传递，也就是没有用引用和指针作为类型时，如：void show_String(const String)，它会被调用。其实，还有一些情况，但在这儿就不列举了。 （2）：它是什么样的函数。 它的作用就是把两个类进行复制。拿String类为例，C＋＋提供的默认复制构造函数是这样的：12345String(const String&amp; a)&#123; str=a.str; len=a.len;&#125; 在平时，这样并不会有任何的问题出现，但我们用了new操作符，涉及到了动态内存分配，我们就不得不谈谈浅复制和深复制了。以上的函数就是实行的浅复制，它只是复制了指针，而并没有复制指针指向的数据，可谓一点儿用也没有。打个比方吧！就像一个朋友让你把一个程序通过网络发给他，而你大大咧咧地把快捷方式发给了他，有什么用处呢？我们来具体谈谈： 假如，A对象中存储了这样的字符串：”C＋＋”。它的地址为2000。现在，我们把A对象赋给B对象：String B=A。现在，A和B对象的str指针均指向2000地址。看似可以使用，但如果B对象的析构函数被调用时，则地址2000处的字符串”C＋＋”已经被从内存中抹去，而A对象仍然指向地址2000。这时，如果我们写下这样的代码：cout&lt;&lt;A&lt;&lt;endl;或是等待程序结束，A对象的析构函数被调用时，A对象的数据能否显示出来呢？只会是乱码。而且，程序还会这样做：连续对地址2000处使用两次delete操作符，这样的后果是十分严重的！ 本例中，有这样的代码：12345String* String1=new String(test1);cout&lt;&lt;*String1&lt;&lt;endl;delete String1; 假设test1中str指向的地址为2000,而String中str指针同样指向地址2000，我们删除了2000处的数据，而test1对象呢？已经被破坏了。大家从运行结果上可以看到，我们使用cout&lt;&lt;test1时，一点反应也没有。而在test1的析构函数被调用时，显示是这样：”这个字符串将被删除：”。 再看看这段代码：123cout&lt;&lt;&quot;使用错误的函数：&quot;&lt;&lt;endl;show_String(test2);cout&lt;&lt;test2&lt;&lt;endl;//这一段代码出现严重的错误！ show_String函数的参数列表void show_String(const String a)是按值传递的，所以，我们相当于执行了这样的代码：String a=test2;函数执行完毕，由于生存周期的缘故，对象a被析构函数删除，我们马上就可以看到错误的显示结果了：这个字符串将被删除：?=。当然，test2也被破坏了。解决的办法很简单，当然是手工定义一个复制构造函数喽！人力可以胜天！123456String::String(const String&amp; a)&#123; len=a.len; str=new char(len+1); strcpy(str,a.str);&#125; 我们执行的是深复制。这个函数的功能是这样的：假设对象A中的str指针指向地址2000，内容为”I am a C++ Boy!”。我们执行代码String B=A时，我们先开辟出一块内存，假设为3000。我们用strcpy函数将地址2000的内容拷贝到地址3000中，再将对象B的str指针指向地址3000。这样，就互不干扰了。 大家把这个函数加入程序中，问题就解决了大半，但还没有完全解决，问题在赋值函数上。我们的程序中有这样的段代码：12String String3;String3=test4; 经过我前面的讲解，大家应该也会对这段代码进行寻根摸底：凭什么可以这样做：String3=test4？？？原因是，C＋＋为了用户的方便，提供的这样的一个操作符重载函数：operator=。所以，我们可以这样做。大家应该猜得到，它同样是执行了浅复制，出了同样的毛病。比如，执行了这段代码后，析构函数开始大展神威。由于这些变量是后进先出的，所以最后的String3变量先被删除：这个字符串将被删除：第四个范例。很正常。最后，删除到test4的时候，问题来了：这个字符串将被删除：?=。原因我不用赘述了，只是这个赋值函数怎么写，还有一点儿学问呢！大家请看： 平时，我们可以写这样的代码：x=y=z。（均为整型变量。）而在类对象中，我们同样要这样，因为这很方便。而对象A=B=C就是A.operator=(B.operator=(c))。而这个operator=函数的参数列表应该是：const String&amp; a，所以，大家不难推出，要实现这样的功能，返回值也要是String&amp;，这样才能实现A＝B＝C。我们先来写写看：12345678String&amp; String::operator=(const String&amp; a)&#123; delete [] str;//先删除自身的数据 len=a.len; str=new char[len+1]; strcpy(str,a.str);//此三行为进行拷贝 return *this;//返回自身的引用&#125; 是不是这样就行了呢？我们假如写出了这种代码：A=A，那么大家看看，岂不是把A对象的数据给删除了吗？这样可谓引发一系列的错误。所以，我们还要检查是否为自身赋值。只比较两对象的数据是不行了，因为两个对象的数据很有可能相同。我们应该比较地址。以下是完好的赋值函数：12345678910String&amp; String::operator=(const String&amp; a)&#123; if(this==&amp;a) return *this; delete [] str; len=a.len; str=new char[len+1]; strcpy(str,a.str); return *this;&#125; 把这些代码加入程序，问题就完全解决，下面是运行结果：1234567891011121314151617181920212223下面分别输入三个范例：第一个范例第二个范例第三个范例第一个范例这个字符串将被删除：第一个范例。第一个范例使用正确的函数：第二个范例。第二个范例。使用错误的函数：第二个范例。这个字符串将被删除：第二个范例。第二个范例。String2: 第三个范例。String3: 第四个范例。下面，程序结束，析构函数将被调用。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：第四个范例。这个字符串将被删除：第三个范例。这个字符串将被删除：第二个范例。这个字符串将被删除：第一个范例。 如何对付内存泄漏？写出那些不会导致任何内存泄漏的代码。很明显，当你的代码中到处充满了new 操作、delete操作和指针运算的话，你将会在某个地方搞晕了头，导致内存泄漏，指针引用错误，以及诸如此类的问题。这和你如何小心地对待内存分配工作其实完全没有关系：代码的复杂性最终总是会超过你能够付出的时间和努力。于是随后产生了一些成功的技巧，它们依赖于将内存分配（allocations）与重新分配（deallocation）工作隐藏在易于管理的类型之后。标准容器（standard containers）是一个优秀的例子。它们不是通过你而是自己为元素管理内存，从而避免了产生糟糕的结果。想象一下，没有string和vector的帮助，写出这个：12345678910111213141516171819#include&lt;vector&gt;#include&lt;string&gt;#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int main() // small program messing around with strings&#123; cout &lt;&lt; &quot;enter some whitespace-separated words:&quot;n&quot;; vector&lt;string&gt; v; string s; while (cin&gt;&gt;s) v.push_back(s); sort(v.begin(),v.end()); string cat; typedef vector&lt;string&gt;::const_iterator Iter; for (Iter p = v.begin(); p!=v.end(); ++p) cat += *p+&quot;+&quot;; cout &lt;&lt; cat &lt;&lt; &apos;&quot;n&apos;;&#125; 你有多少机会在第一次就得到正确的结果？你又怎么知道你没有导致内存泄漏呢？ 注意，没有出现显式的内存管理，宏，造型，溢出检查，显式的长度限制，以及指针。通过使用函数对象和标准算法（standard algorithm），我可以避免使用指针————例如使用迭代子（iterator），不过对于一个这么小的程序来说有点小题大作了。 这些技巧并不完美，要系统化地使用它们也并不总是那么容易。但是，应用它们产生了惊人的差异，而且通过减少显式的内存分配与重新分配的次数，你甚至可以使余下的例子更加容易被跟踪。早在1981年，我就指出，通过将我必须显式地跟踪的对象的数量从几万个减少到几打，为了使程序正确运行而付出的努力从可怕的苦工，变成了应付一些可管理的对象，甚至更加简单了。 如果你的程序还没有包含将显式内存管理减少到最小限度的库，那么要让你程序完成和正确运行的话，最快的途径也许就是先建立一个这样的库。 模板和标准库实现了容器、资源句柄以及诸如此类的东西，更早的使用甚至在多年以前。异常的使用使之更加完善。 如果你实在不能将内存分配/重新分配的操作隐藏到你需要的对象中时，你可以使用资源句柄（resource handle），以将内存泄漏的可能性降至最低。这里有个例子：我需要通过一个函数，在空闲内存中建立一个对象并返回它。这时候可能忘记释放这个对象。毕竟，我们不能说，仅仅关注当这个指针要被释放的时候，谁将负责去做。使用资源句柄，这里用了标准库中的auto_ptr，使需要为之负责的地方变得明确了。12345678910111213141516171819202122232425262728#include&lt;memory&gt;#include&lt;iostream&gt;using namespace std;struct S &#123; S() &#123; cout &lt;&lt; &quot;make an S&quot;n&quot;; &#125; ~S() &#123; cout &lt;&lt; &quot;destroy an S&quot;n&quot;; &#125; S(const S&amp;) &#123; cout &lt;&lt; &quot;copy initialize an S&quot;n&quot;; &#125; S&amp; operator=(const S&amp;) &#123; cout &lt;&lt; &quot;copy assign an S&quot;n&quot;; &#125;&#125;;S* f()&#123; return new S; // 谁该负责释放这个S？&#125;;auto_ptr&lt;S&gt; g()&#123; return auto_ptr&lt;S&gt;(new S); // 显式传递负责释放这个S&#125;int main()&#123; cout &lt;&lt; &quot;start main&quot;n&quot;; S* p = f(); cout &lt;&lt; &quot;after f() before g()&quot;n&quot;; // S* q = g(); // 将被编译器捕捉 auto_ptr&lt;S&gt; q = g(); cout &lt;&lt; &quot;exit main&quot;n&quot;; // *p产生了内存泄漏 // *q被自动释放&#125; 在更一般的意义上考虑资源，而不仅仅是内存。 如果在你的环境中不能系统地应用这些技巧（例如，你必须使用别的地方的代码，或者你的程序的另一部分简直是原始人类（译注：原文是Neanderthals，尼安德特人，旧石器时代广泛分布在欧洲的猿人）写的，如此等等），那么注意使用一个内存泄漏检测器作为开发过程的一部分，或者插入一个垃圾收集器（garbage collector）。 浅谈C/C++内存泄漏及其检测工具对于一个c/c++程序员来说，内存泄漏是一个常见的也是令人头疼的问题。已经有许多技术被研究出来以应对这个问题，比如Smart Pointer，Garbage Collection等。Smart Pointer技术比较成熟，STL中已经包含支持Smart Pointer的class，但是它的使用似乎并不广泛，而且它也不能解决所有的问题；Garbage Collection技术在Java中已经比较成熟，但是在c/c++领域的发展并不顺畅，虽然很早就有人思考在C++中也加入GC的支持。现实世界就是这样的，作为一个c/c++程序员，内存泄漏是你心中永远的痛。不过好在现在有许多工具能够帮助我们验证内存泄漏的存在，找出发生问题的代码。 内存泄漏的定义一般我们常说的内存泄漏是指堆内存的泄漏。堆内存是指程序从堆中分配的，大小任意的（内存块的大小可以在程序运行期决定），使用完后必须显示释放的内存。应用程序一般使用malloc，realloc，new等函数从堆中分配到一块内存，使用完后，程序必须负责相应的调用free或delete释放该内存块，否则，这块内存就不能被再次使用，我们就说这块内存泄漏了。以下这段小程序演示了堆内存发生泄漏的情形：12345678910void MyFunction(int nSize)&#123; char* p= new char[nSize]; if( !GetStringFrom( p, nSize ) )&#123; MessageBox(“Error”); return; &#125; …//using the string pointed by p; delete p;&#125; 当函数GetStringFrom()返回零的时候，指针p指向的内存就不会被释放。这是一种常见的发生内存泄漏的情形。程序在入口处分配内存，在出口处释放内存，但是c函数可以在任何地方退出，所以一旦有某个出口处没有释放应该释放的内存，就会发生内存泄漏。 广义的说，内存泄漏不仅仅包含堆内存的泄漏，还包含系统资源的泄漏(resource leak)，比如核心态HANDLE，GDI Object，SOCKET， Interface等，从根本上说这些由操作系统分配的对象也消耗内存，如果这些对象发生泄漏最终也会导致内存的泄漏。而且，某些对象消耗的是核心态内存，这些对象严重泄漏时会导致整个操作系统不稳定。所以相比之下，系统资源的泄漏比堆内存的泄漏更为严重。 GDI Object的泄漏是一种常见的资源泄漏：12345678910111213void CMyView::OnPaint( CDC* pDC )&#123; CBitmap bmp; CBitmap* pOldBmp; bmp.LoadBitmap(IDB_MYBMP); pOldBmp = pDC-&gt;SelectObject( &amp;bmp ); ... if( Something() )&#123; return; &#125; pDC-&gt;SelectObject( pOldBmp ); return;&#125; 当函数Something()返回非零的时候，程序在退出前没有把pOldBmp选回pDC中，这会导致pOldBmp指向的HBITMAP对象发生泄漏。这个程序如果长时间的运行，可能会导致整个系统花屏。这种问题在Win9x下比较容易暴露出来，因为Win9x的GDI堆比Win2k或NT的要小很多。 内存泄漏的发生方式以发生的方式来分类，内存泄漏可以分为4类： 常发性内存泄漏。发生内存泄漏的代码会被多次执行到，每次被执行的时候都会导致一块内存泄漏。比如例二，如果Something()函数一直返回True，那么pOldBmp指向的HBITMAP对象总是发生泄漏。 偶发性内存泄漏。发生内存泄漏的代码只有在某些特定环境或操作过程下才会发生。比如例二，如果Something()函数只有在特定环境下才返回True，那么pOldBmp指向的HBITMAP对象并不总是发生泄漏。常发性和偶发性是相对的。对于特定的环境，偶发性的也许就变成了常发性的。所以测试环境和测试方法对检测内存泄漏至关重要。 一次性内存泄漏。发生内存泄漏的代码只会被执行一次，或者由于算法上的缺陷，导致总会有一块仅且一块内存发生泄漏。比如，在类的构造函数中分配内存，在析构函数中却没有释放该内存，但是因为这个类是一个Singleton，所以内存泄漏只会发生一次。另一个例子： 12345678char* g_lpszFileName = NULL;void SetFileName( const char* lpcszFileName )&#123; if( g_lpszFileName )&#123; free( g_lpszFileName ); &#125; g_lpszFileName = strdup( lpcszFileName );&#125; 如果程序在结束的时候没有释放g_lpszFileName指向的字符串，那么，即使多次调用SetFileName()，总会有一块内存，而且仅有一块内存发生泄漏。 隐式内存泄漏。程序在运行过程中不停的分配内存，但是直到结束的时候才释放内存。严格的说这里并没有发生内存泄漏，因为最终程序释放了所有申请的内存。但是对于一个服务器程序，需要运行几天，几周甚至几个月，不及时释放内存也可能导致最终耗尽系统的所有内存。所以，我们称这类内存泄漏为隐式内存泄漏。举一个例子：123456789101112131415161718192021222324252627282930class Connection&#123; public: Connection( SOCKET s); ~Connection(); private: SOCKET _socket;&#125;;class ConnectionManager&#123; public: ConnectionManager()&#123;&#125; ~ConnectionManager()&#123; list::iterator it; for( it = _connlist.begin(); it != _connlist.end(); ++it )&#123; delete （*it）; &#125; _connlist.clear(); &#125; void OnClientConnected( SOCKET s )&#123; Connection* p = new Connection(s); _connlist.push_back(p); &#125; void OnClientDisconnected( Connection* pconn )&#123; _connlist.remove( pconn ); delete pconn; &#125; private: list _connlist;&#125;; 假设在Client从Server端断开后，Server并没有呼叫OnClientDisconnected()函数，那么代表那次连接的Connection对象就不会被及时的删除（在Server程序退出的时候，所有Connection对象会在ConnectionManager的析构函数里被删除）。当不断的有连接建立、断开时隐式内存泄漏就发生了。 从用户使用程序的角度来看，内存泄漏本身不会产生什么危害，作为一般的用户，根本感觉不到内存泄漏的存在。真正有危害的是内存泄漏的堆积，这会最终消耗尽系统所有的内存。从这个角度来说，一次性内存泄漏并没有什么危害，因为它不会堆积，而隐式内存泄漏危害性则非常大，因为较之于常发性和偶发性内存泄漏它更难被检测到。 检测内存泄漏检测内存泄漏的关键是要能截获住对分配内存和释放内存的函数的调用。截获住这两个函数，我们就能跟踪每一块内存的生命周期，比如，每当成功的分配一块内存后，就把它的指针加入一个全局的list中；每当释放一块内存，再把它的指针从list中删除。这样，当程序结束的时候，list中剩余的指针就是指向那些没有被释放的内存。这里只是简单的描述了检测内存泄漏的基本原理，详细的算法可以参见Steve Maguire的&lt;&gt;。 如果要检测堆内存的泄漏，那么需要截获住malloc/realloc/free和new/delete就可以了（其实new/delete最终也是用malloc/free的，所以只要截获前面一组即可）。对于其他的泄漏，可以采用类似的方法，截获住相应的分配和释放函数。比如，要检测BSTR的泄漏，就需要截获SysAllocString/SysFreeString；要检测HMENU的泄漏，就需要截获CreateMenu/ DestroyMenu。（有的资源的分配函数有多个，释放函数只有一个，比如，SysAllocStringLen也可以用来分配BSTR，这时就需要截获多个分配函数） 在Windows平台下，检测内存泄漏的工具常用的一般有三种，MS C-Runtime Library内建的检测功能；外挂式的检测工具，诸如，Purify，BoundsChecker等；利用Windows NT自带的Performance Monitor。这三种工具各有优缺点，MS C-Runtime Library虽然功能上较之外挂式的工具要弱，但是它是免费的；Performance Monitor虽然无法标示出发生问题的代码，但是它能检测出隐式的内存泄漏的存在，这是其他两类工具无能为力的地方。 以下我们详细讨论这三种检测工具： VC下内存泄漏的检测方法用MFC开发的应用程序，在DEBUG版模式下编译后，都会自动加入内存泄漏的检测代码。在程序结束后，如果发生了内存泄漏，在Debug窗口中会显示出所有发生泄漏的内存块的信息，以下两行显示了一块被泄漏的内存块的信息：12E:&quot;TestMemLeak&quot;TestDlg.cpp(70) : &#123;59&#125; normal block at 0x00881710, 200 bytes long.Data: &lt;abcdefghijklmnop&gt; 61 62 63 64 65 66 67 68 69 6A 6B 6C 6D 6E 6F 70 第一行显示该内存块由TestDlg.cpp文件，第70行代码分配，地址在0x00881710，大小为200字节，{59}是指调用内存分配函数的Request Order，关于它的详细信息可以参见MSDN中_CrtSetBreakAlloc()的帮助。第二行显示该内存块前16个字节的内容，尖括号内是以ASCII方式显示，接着的是以16进制方式显示。 一般大家都误以为这些内存泄漏的检测功能是由MFC提供的，其实不然。MFC只是封装和利用了MS C-Runtime Library的Debug Function。非MFC程序也可以利用MS C-Runtime Library的Debug Function加入内存泄漏的检测功能。MS C-Runtime Library在实现malloc/free，strdup等函数时已经内建了内存泄漏的检测功能。 注意观察一下由MFC Application Wizard生成的项目，在每一个cpp文件的头部都有这样一段宏定义：123456789#ifdef _DEBUG#define new DEBUG_NEW#undef THIS_FILEstatic char THIS_FILE[] = __FILE__;#endif 有了这样的定义，在编译DEBUG版时，出现在这个cpp文件中的所有new都被替换成DEBUG_NEW了。那么DEBUG_NEW是什么呢？DEBUG_NEW也是一个宏，以下摘自afx.h，1632行1#define DEBUG_NEW new(THIS_FILE, __LINE__) 所以如果有这样一行代码：1char* p = new char[200]; 经过宏替换就变成了：1char* p = new( THIS_FILE, __LINE__)char[200]; 根据C++的标准，对于以上的new的使用方法，编译器会去找这样定义的operator new：1void* operator new(size_t, LPCSTR, int) 我们在afxmem.cpp 63行找到了一个这样的operator new 的实现1234567891011void* AFX_CDECL operator new(size_t nSize, LPCSTR lpszFileName, int nLine)&#123; return ::operator new(nSize, _NORMAL_BLOCK, lpszFileName, nLine);&#125;void* __cdecl operator new(size_t nSize, int nType, LPCSTR lpszFileName, int nLine)&#123; pResult = _malloc_dbg(nSize, nType, lpszFileName, nLine); if (pResult != NULL) return pResult; ...&#125; 第二个operator new函数比较长，为了简单期间，我只摘录了部分。很显然最后的内存分配还是通过_malloc_dbg函数实现的，这个函数属于MS C-Runtime Library 的Debug Function。这个函数不但要求传入内存的大小，另外还有文件名和行号两个参数。文件名和行号就是用来记录此次分配是由哪一段代码造成的。如果这块内存在程序结束之前没有被释放，那么这些信息就会输出到Debug窗口里。 这里顺便提一下THIS_FILE，FILE和LINE__。FILE和LINE都是编译器定义的宏。当碰到FILE时，编译器会把FILE替换成一个字符串，这个字符串就是当前在编译的文件的路径名。当碰到LINE时，编译器会把LINE替换成一个数字，这个数字就是当前这行代码的行号。在DEBUG_NEW的定义中没有直接使用FILE，而是用了THIS_FILE，其目的是为了减小目标文件的大小。假设在某个cpp文件中有100处使用了new，如果直接使用FILE，那编译器会产生100个常量字符串，这100个字符串都是cpp文件的路径名，显然十分冗余。如果使用THIS_FILE，编译器只会产生一个常量字符串，那100处new的调用使用的都是指向常量字符串的指针。 再次观察一下由MFC Application Wizard生成的项目，我们会发现在cpp文件中只对new做了映射，如果你在程序中直接使用malloc函数分配内存，调用malloc的文件名和行号是不会被记录下来的。如果这块内存发生了泄漏，MS C-Runtime Library仍然能检测到，但是当输出这块内存块的信息，不会包含分配它的的文件名和行号。 要在非MFC程序中打开内存泄漏的检测功能非常容易，你只要在程序的入口处加入以下几行代码：123int tmpFlag = _CrtSetDbgFlag( _CRTDBG_REPORT_FLAG );tmpFlag |= _CRTDBG_LEAK_CHECK_DF;_CrtSetDbgFlag( tmpFlag ); 这样，在程序结束的时候，也就是winmain，main或dllmain函数返回之后，如果还有内存块没有释放，它们的信息会被打印到Debug窗口里。 如果你试着创建了一个非MFC应用程序，而且在程序的入口处加入了以上代码，并且故意在程序中不释放某些内存块，你会在Debug窗口里看到以下的信息：123&#123;47&#125; normal block at 0x00C91C90, 200 bytes long.Data: &lt; &gt; 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F 内存泄漏的确检测到了，但是和上面MFC程序的例子相比，缺少了文件名和行号。对于一个比较大的程序，没有这些信息，解决问题将变得十分困难。 为了能够知道泄漏的内存块是在哪里分配的，你需要实现类似MFC的映射功能，把new，maolloc等函数映射到_malloc_dbg函数上。这里我不再赘述，你可以参考MFC的源代码。 由于Debug Function实现在MS C-RuntimeLibrary中，所以它只能检测到堆内存的泄漏，而且只限于malloc，realloc或strdup等分配的内存，而那些系统资源，比如HANDLE，GDI Object，或是不通过C-Runtime Library分配的内存，比如VARIANT，BSTR的泄漏，它是无法检测到的，这是这种检测法的一个重大的局限性。另外，为了能记录内存块是在哪里分配的，源代码必须相应的配合，这在调试一些老的程序非常麻烦，毕竟修改源代码不是一件省心的事，这是这种检测法的另一个局限性。 对于开发一个大型的程序，MS C-Runtime Library提供的检测功能是远远不够的。接下来我们就看看外挂式的检测工具。我用的比较多的是BoundsChecker，一则因为它的功能比较全面，更重要的是它的稳定性。这类工具如果不稳定，反而会忙里添乱。到底是出自鼎鼎大名的NuMega，我用下来基本上没有什么大问题。 使用BoundsChecker检测内存泄漏BoundsChecker采用一种被称为 Code Injection的技术，来截获对分配内存和释放内存的函数的调用。简单地说，当你的程序开始运行时，BoundsChecker的DLL被自动载入进程的地址空间（这可以通过system-level的Hook实现），然后它会修改进程中对内存分配和释放的函数调用，让这些调用首先转入它的代码，然后再执行原来的代码。BoundsChecker在做这些动作的时，无须修改被调试程序的源代码或工程配置文件，这使得使用它非常的简便、直接。 这里我们以malloc函数为例，截获其他的函数方法与此类似。 需要被截获的函数可能在DLL中，也可能在程序的代码里。比如，如果静态连结C-Runtime Library，那么malloc函数的代码会被连结到程序里。为了截获住对这类函数的调用，BoundsChecker会动态修改这些函数的指令。 以下两段汇编代码，一段没有BoundsChecker介入，另一段则有BoundsChecker的介入：1234567891011121314151617126: _CRTIMP void * __cdecl malloc (127: size_t nSize128: )129: &#123;00403C10 push ebp00403C11 mov ebp,esp130: return _nh_malloc_dbg(nSize, _newmode, _NORMAL_BLOCK, NULL, 0);00403C13 push 000403C15 push 000403C17 push 100403C19 mov eax,[__newmode (0042376c)]00403C1E push eax00403C1F mov ecx,dword ptr [nSize]00403C22 push ecx00403C23 call _nh_malloc_dbg (00403c80)00403C28 add esp,14h131: &#125; 以下这一段代码有BoundsChecker介入：1234567891011121314126: _CRTIMP void * __cdecl malloc (127: size_t nSize128: )129: &#123;00403C10 jmp 01F41EC800403C15 push 000403C17 push 100403C19 mov eax,[__newmode (0042376c)]00403C1E push eax00403C1F mov ecx,dword ptr [nSize]00403C22 push ecx00403C23 call _nh_malloc_dbg (00403c80)00403C28 add esp,14h131: &#125; 当BoundsChecker介入后，函数malloc的前三条汇编指令被替换成一条jmp指令，原来的三条指令被搬到地址01F41EC8处了。当程序进入malloc后先jmp到01F41EC8，执行原来的三条指令，然后就是BoundsChecker的天下了。大致上它会先记录函数的返回地址（函数的返回地址在stack上，所以很容易修改），然后把返回地址指向属于BoundsChecker的代码，接着跳到malloc函数原来的指令，也就是在00403c15的地方。当malloc函数结束的时候，由于返回地址被修改，它会返回到BoundsChecker的代码中，此时BoundsChecker会记录由malloc分配的内存的指针，然后再跳转到到原来的返回地址去。 如果内存分配/释放函数在DLL中，BoundsChecker则采用另一种方法来截获对这些函数的调用。BoundsChecker通过修改程序的DLL Import Table让table中的函数地址指向自己的地址，以达到截获的目的。 截获住这些分配和释放函数，BoundsChecker就能记录被分配的内存或资源的生命周期。接下来的问题是如何与源代码相关，也就是说当BoundsChecker检测到内存泄漏，它如何报告这块内存块是哪段代码分配的。答案是调试信息（Debug Information）。当我们编译一个Debug版的程序时，编译器会把源代码和二进制代码之间的对应关系记录下来，放到一个单独的文件里(.pdb)或者直接连结进目标程序，通过直接读取调试信息就能得到分配某块内存的源代码在哪个文件，哪一行上。使用Code Injection和Debug Information，使BoundsChecker不但能记录呼叫分配函数的源代码的位置，而且还能记录分配时的Call Stack，以及Call Stack上的函数的源代码位置。这在使用像MFC这样的类库时非常有用，以下我用一个例子来说明：12345678910111213141516171819202122232425void ShowXItemMenu()&#123; ... CMenu menu; menu.CreatePopupMenu(); //add menu items. menu.TrackPropupMenu(); ...&#125;void ShowYItemMenu( )&#123; ... CMenu menu; menu.CreatePopupMenu(); //add menu items. menu.TrackPropupMenu(); menu.Detach();//this will cause HMENU leak ...&#125;BOOL CMenu::CreatePopupMenu()&#123; ... hMenu = CreatePopupMenu(); ...&#125; 当调用ShowYItemMenu()时，我们故意造成HMENU的泄漏。但是，对于BoundsChecker来说被泄漏的HMENU是在class CMenu::CreatePopupMenu()中分配的。假设的你的程序有许多地方使用了CMenu的CreatePopupMenu()函数，如CMenu::CreatePopupMenu()造成的，你依然无法确认问题的根结到底在哪里，在ShowXItemMenu()中还是在ShowYItemMenu()中，或者还有其它的地方也使用了CreatePopupMenu()？有了Call Stack的信息，问题就容易了。BoundsChecker会如下报告泄漏的HMENU的信息：123456789FunctionFileLineCMenu::CreatePopupMenuE:&quot;8168&quot;vc98&quot;mfc&quot;mfc&quot;include&quot;afxwin1.inl1009ShowYItemMenuE:&quot;testmemleak&quot;mytest.cpp100 这里省略了其他的函数调用 如此，我们很容易找到发生问题的函数是ShowYItemMenu()。当使用MFC之类的类库编程时，大部分的API调用都被封装在类库的class里，有了Call Stack信息，我们就可以非常容易的追踪到真正发生泄漏的代码。 记录Call Stack信息会使程序的运行变得非常慢，因此默认情况下BoundsChecker不会记录Call Stack信息。可以按照以下的步骤打开记录Call Stack信息的选项开关： 打开菜单：BoundsChecker|Setting… 在Error Detection页中，在Error Detection Scheme的List中选择Custom 在Category的Combox中选择 Pointer and leak error check 钩上Report Call Stack复选框 点击Ok 基于Code Injection，BoundsChecker还提供了API Parameter的校验功能，memory over run等功能。这些功能对于程序的开发都非常有益。由于这些内容不属于本文的主题，所以不在此详述了。 尽管BoundsChecker的功能如此强大，但是面对隐式内存泄漏仍然显得苍白无力。所以接下来我们看看如何用Performance Monitor检测内存泄漏。 使用Performance Monitor检测内存泄漏NT的内核在设计过程中已经加入了系统监视功能，比如CPU的使用率，内存的使用情况，I/O操作的频繁度等都作为一个个Counter，应用程序可以通过读取这些Counter了解整个系统的或者某个进程的运行状况。Performance Monitor就是这样一个应用程序。 为了检测内存泄漏，我们一般可以监视Process对象的Handle Count，Virutal Bytes 和Working Set三个Counter。Handle Count记录了进程当前打开的HANDLE的个数，监视这个Counter有助于我们发现程序是否有Handle泄漏；Virtual Bytes记录了该进程当前在虚地址空间上使用的虚拟内存的大小，NT的内存分配采用了两步走的方法，首先，在虚地址空间上保留一段空间，这时操作系统并没有分配物理内存，只是保留了一段地址。然后，再提交这段空间，这时操作系统才会分配物理内存。所以，Virtual Bytes一般总大于程序的Working Set。监视Virutal Bytes可以帮助我们发现一些系统底层的问题; Working Set记录了操作系统为进程已提交的内存的总量，这个值和程序申请的内存总量存在密切的关系，如果程序存在内存的泄漏这个值会持续增加，但是Virtual Bytes却是跳跃式增加的。 监视这些Counter可以让我们了解进程使用内存的情况，如果发生了泄漏，即使是隐式内存泄漏，这些Counter的值也会持续增加。但是，我们知道有问题却不知道哪里有问题，所以一般使用Performance Monitor来验证是否有内存泄漏，而使用BoundsChecker来找到和解决。 当Performance Monitor显示有内存泄漏，而BoundsChecker却无法检测到，这时有两种可能：第一种，发生了偶发性内存泄漏。这时你要确保使用Performance Monitor和使用BoundsChecker时，程序的运行环境和操作方法是一致的。第二种，发生了隐式的内存泄漏。这时你要重新审查程序的设计，然后仔细研究Performance Monitor记录的Counter的值的变化图，分析其中的变化和程序运行逻辑的关系，找到一些可能的原因。这是一个痛苦的过程，充满了假设、猜想、验证、失败，但这也是一个积累经验的绝好机会。 探讨C++内存回收C++内存对象大会战如果一个人自称为程序高手，却对内存一无所知，那么我可以告诉你，他一定在吹牛。用C或C++写程序，需要更多地关注内存，这不仅仅是因为内存的分配是否合理直接影响着程序的效率和性能，更为主要的是，当我们操作内存的时候一不小心就会出现问题，而且很多时候，这些问题都是不易发觉的，比如内存泄漏，比如悬挂指针。笔者今天在这里并不是要讨论如何避免这些问题，而是想从另外一个角度来认识C++内存对象。 我们知道，C++将内存划分为三个逻辑区域：堆、栈和静态存储区。既然如此，我称位于它们之中的对象分别为堆对象，栈对象以及静态对象。那么这些不同的内存对象有什么区别了？堆对象和栈对象各有什么优劣了？如何禁止创建堆对象或栈对象了？这些便是今天的主题。 基本概念先来看看栈。栈，一般用于存放局部变量或对象，如我们在函数定义中用类似下面语句声明的对象：1Type stack_object ; stack_object便是一个栈对象，它的生命期是从定义点开始，当所在函数返回时，生命结束。 另外，几乎所有的临时对象都是栈对象。比如，下面的函数定义：1Type fun(Type object); 这个函数至少产生两个临时对象，首先，参数是按值传递的，所以会调用拷贝构造函数生成一个临时对象object_copy1 ，在函数内部使用的不是使用的不是object，而是object_copy1，自然，object_copy1是一个栈对象，它在函数返回时被释放；还有这个函数是值返回的，在函数返回时，如果我们不考虑返回值优化（NRV），那么也会产生一个临时对象object_copy2，这个临时对象会在函数返回后一段时间内被释放。比如某个函数中有如下代码：123Type tt ,result ; //生成两个栈对象tt = fun(tt); //函数返回时，生成的是一个临时对象object_copy2 上面的第二个语句的执行情况是这样的，首先函数fun返回时生成一个临时对象object_copy2 ，然后再调用赋值运算符执行1tt = object_copy2 ; //调用赋值运算符 看到了吗？编译器在我们毫无知觉的情况下，为我们生成了这么多临时对象，而生成这些临时对象的时间和空间的开销可能是很大的，所以，你也许明白了，为什么对于”大”对象最好用const引用传递代替按值进行函数参数传递了。 接下来，看看堆。堆，又叫自由存储区，它是在程序执行的过程中动态分配的，所以它最大的特性就是动态性。在C++中，所有堆对象的创建和销毁都要由程序员负责，所以，如果处理不好，就会发生内存问题。如果分配了堆对象，却忘记了释放，就会产生内存泄漏；而如果已释放了对象，却没有将相应的指针置为NULL，该指针就是所谓的”悬挂指针”，再度使用此指针时，就会出现非法访问，严重时就导致程序崩溃。 那么，C++中是怎样分配堆对象的？唯一的方法就是用new（当然，用类malloc指令也可获得C式堆内存），只要使用new，就会在堆中分配一块内存，并且返回指向该堆对象的指针。 再来看看静态存储区。所有的静态对象、全局对象都于静态存储区分配。关于全局对象，是在main()函数执行前就分配好了的。其实，在main()函数中的显示代码执行之前，会调用一个由编译器生成的_main()函数，而_main()函数会进行所有全局对象的的构造及初始化工作。而在main()函数结束之前，会调用由编译器生成的exit函数，来释放所有的全局对象。比如下面的代码：1234void main（void）&#123; ... ...// 显式代码&#125; 实际上，被转化成这样：1234567void main（void）&#123; _main（）; //隐式代码，由编译器产生，用以构造所有全局对象 ... ... // 显式代码 ... ... exit（） ; // 隐式代码，由编译器产生，用以释放所有全局对象&#125; 所以，知道了这个之后，便可以由此引出一些技巧，如，假设我们要在main()函数执行之前做某些准备工作，那么我们可以将这些准备工作写到一个自定义的全局对象的构造函数中，这样，在main()函数的显式代码执行之前，这个全局对象的构造函数会被调用，执行预期的动作，这样就达到了我们的目的。 刚才讲的是静态存储区中的全局对象，那么，局部静态对象了？局部静态对象通常也是在函数中定义的，就像栈对象一样，只不过，其前面多了个static关键字。局部静态对象的生命期是从其所在函数第一次被调用，更确切地说，是当第一次执行到该静态对象的声明代码时，产生该静态局部对象，直到整个程序结束时，才销毁该对象。 还有一种静态对象，那就是它作为class的静态成员。考虑这种情况时，就牵涉了一些较复杂的问题。 第一个问题是class的静态成员对象的生命期，class的静态成员对象随着第一个class object的产生而产生，在整个程序结束时消亡。也就是有这样的情况存在，在程序中我们定义了一个class，该类中有一个静态对象作为成员，但是在程序执行过程中，如果我们没有创建任何一个该class object，那么也就不会产生该class所包含的那个静态对象。还有，如果创建了多个class object，那么所有这些object都共享那个静态对象成员。 第二个问题是，当出现下列情况时：12345678910111213141516171819class Base&#123; public: static Type s_object ;&#125;class Derived1 : public Base / / 公共继承&#123; ... ...// other data&#125;class Derived2 : public Base / / 公共继承&#123; ... ...// other data&#125;Base example ;Derivde1 example1 ;Derivde2 example2 ;**example.s_object = ...... ;****example1.s_object = ...... ;****example2.s_object = ...... ; ** 请注意上面标为黑体的三条语句，它们所访问的s_object是同一个对象吗？答案是肯定的，它们的确是指向同一个对象，这听起来不像是真的，是吗？但这是事实，你可以自己写段简单的代码验证一下。我要做的是来解释为什么会这样？ 我们知道，当一个类比如Derived1，从另一个类比如Base继承时，那么，可以看作一个Derived1对象中含有一个Base型的对象，这就是一个subobject。一个Derived1对象的大致内存布局如下： 让我们想想，当我们将一个Derived1型的对象传给一个接受非引用Base型参数的函数时会发生切割，那么是怎么切割的呢？相信现在你已经知道了，那就是仅仅取出了Derived1型的对象中的subobject，而忽略了所有Derived1自定义的其它数据成员，然后将这个subobject传递给函数（实际上，函数中使用的是这个subobject的拷贝）。 所有继承Base类的派生类的对象都含有一个Base型的subobject（这是能用Base型指针指向一个Derived1对象的关键所在，自然也是多态的关键了），而所有的subobject和所有Base型的对象都共用同一个s_object对象，自然，从Base类派生的整个继承体系中的类的实例都会共用同一个s_object对象了。上面提到的example、example1、example2的对象布局如下图所示： 三种内存对象的比较栈对象的优势是在适当的时候自动生成，又在适当的时候自动销毁，不需要程序员操心；而且栈对象的创建速度一般较堆对象快，因为分配堆对象时，会调用operator new操作，operator new会采用某种内存空间搜索算法，而该搜索过程可能是很费时间的，产生栈对象则没有这么麻烦，它仅仅需要移动栈顶指针就可以了。但是要注意的是，通常栈空间容量比较小，一般是1MB～2MB，所以体积比较大的对象不适合在栈中分配。特别要注意递归函数中最好不要使用栈对象，因为随着递归调用深度的增加，所需的栈空间也会线性增加，当所需栈空间不够时，便会导致栈溢出，这样就会产生运行时错误。 堆对象，其产生时刻和销毁时刻都要程序员精确定义，也就是说，程序员对堆对象的生命具有完全的控制权。我们常常需要这样的对象，比如，我们需要创建一个对象，能够被多个函数所访问，但是又不想使其成为全局的，那么这个时候创建一个堆对象无疑是良好的选择，然后在各个函数之间传递这个堆对象的指针，便可以实现对该对象的共享。另外，相比于栈空间，堆的容量要大得多。实际上，当物理内存不够时，如果这时还需要生成新的堆对象，通常不会产生运行时错误，而是系统会使用虚拟内存来扩展实际的物理内存。 接下来看看static对象。 首先是全局对象。全局对象为类间通信和函数间通信提供了一种最简单的方式，虽然这种方式并不优雅。一般而言，在完全的面向对象语言中，是不存在全局对象的，比如C#，因为全局对象意味着不安全和高耦合，在程序中过多地使用全局对象将大大降低程序的健壮性、稳定性、可维护性和可复用性。C++也完全可以剔除全局对象，但是最终没有，我想原因之一是为了兼容C。 其次是类的静态成员，上面已经提到，基类及其派生类的所有对象都共享这个静态成员对象，所以当需要在这些class之间或这些class objects之间进行数据共享或通信时，这样的静态成员无疑是很好的选择。 接着是静态局部对象，主要可用于保存该对象所在函数被屡次调用期间的中间状态，其中一个最显著的例子就是递归函数，我们都知道递归函数是自己调用自己的函数，如果在递归函数中定义一个nonstatic局部对象，那么当递归次数相当大时，所产生的开销也是巨大的。这是因为nonstatic局部对象是栈对象，每递归调用一次，就会产生一个这样的对象，每返回一次，就会释放这个对象，而且，这样的对象只局限于当前调用层，对于更深入的嵌套层和更浅露的外层，都是不可见的。每个层都有自己的局部对象和参数。 在递归函数设计中，可以使用static对象替代nonstatic局部对象（即栈对象），这不仅可以减少每次递归调用和返回时产生和释放nonstatic对象的开销，而且static对象还可以保存递归调用的中间状态，并且可为各个调用层所访问。 使用栈对象的意外收获前面已经介绍到，栈对象是在适当的时候创建，然后在适当的时候自动释放的，也就是栈对象有自动管理功能。那么栈对象会在什么会自动释放了？第一，在其生命期结束的时候；第二，在其所在的函数发生异常的时候。你也许说，这些都很正常啊，没什么大不了的。是的，没什么大不了的。但是只要我们再深入一点点，也许就有意外的收获了。 栈对象，自动释放时，会调用它自己的析构函数。如果我们在栈对象中封装资源，而且在栈对象的析构函数中执行释放资源的动作，那么就会使资源泄漏的概率大大降低，因为栈对象可以自动的释放资源，即使在所在函数发生异常的时候。实际的过程是这样的：函数抛出异常时，会发生所谓的stack_unwinding（堆栈回滚），即堆栈会展开，由于是栈对象，自然存在于栈中，所以在堆栈回滚的过程中，栈对象的析构函数会被执行，从而释放其所封装的资源。除非，除非在析构函数执行的过程中再次抛出异常――而这种可能性是很小的，所以用栈对象封装资源是比较安全的。基于此认识，我们就可以创建一个自己的句柄或代理来封装资源了。智能指针（auto_ptr）中就使用了这种技术。在有这种需要的时候，我们就希望我们的资源封装类只能在栈中创建，也就是要限制在堆中创建该资源封装类的实例。 禁止产生堆对象上面已经提到，你决定禁止产生某种类型的堆对象，这时你可以自己创建一个资源封装类，该类对象只能在栈中产生，这样就能在异常的情况下自动释放封装的资源。 那么怎样禁止产生堆对象了？我们已经知道，产生堆对象的唯一方法是使用new操作，如果我们禁止使用new不就行了么。再进一步，new操作执行时会调用operator new，而operator new是可以重载的。方法有了，就是使new operator 为private，为了对称，最好将operator delete也重载为private。现在，你也许又有疑问了,难道创建栈对象不需要调用new吗？是的，不需要，因为创建栈对象不需要搜索内存，而是直接调整堆栈指针，将对象压栈，而operator new的主要任务是搜索合适的堆内存，为堆对象分配空间，这在上面已经提到过了。好，让我们看看下面的示例代码：1234567891011121314151617181920212223242526#include &lt;stdlib.h&gt; //需要用到C式内存分配函数class Resource ; //代表需要被封装的资源类class NoHashObject&#123; private: Resource* ptr ;//指向被封装的资源 ... ... //其它数据成员 void* operator new(size_t size) //非严格实现，仅作示意之用 &#123; return malloc(size) ; &#125; void operator delete(void* pp) //非严格实现，仅作示意之用 &#123; free(pp) ; &#125; public: NoHashObject() &#123; //此处可以获得需要封装的资源，并让ptr指针指向该资源 ptr = new Resource() ; &#125; ~NoHashObject() &#123; delete ptr ; //释放封装的资源 &#125;&#125;; NoHashObject现在就是一个禁止堆对象的类了，如果你写下如下代码：12NoHashObject* fp = new NoHashObject() ; //编译期错误！delete fp ; 上面代码会产生编译期错误。好了，现在你已经知道了如何设计一个禁止堆对象的类了，你也许和我一样有这样的疑问，难道在类NoHashObject的定义不能改变的情况下，就一定不能产生该类型的堆对象了吗？不，还是有办法的，我称之为”暴力破解法”。C++是如此地强大，强大到你可以用它做你想做的任何事情。这里主要用到的是技巧是指针类型的强制转换。1234567891011121314151617void main(void)&#123; char* temp = new char[sizeof(NoHashObject)] ; //强制类型转换，现在ptr是一个指向NoHashObject对象的指针 NoHashObject* obj_ptr = (NoHashObject*)temp ; temp = NULL ; //防止通过temp指针修改NoHashObject对象 //再一次强制类型转换，让rp指针指向堆中NoHashObject对象的ptr成员 Resource* rp = (Resource*)obj_ptr ; //初始化obj_ptr指向的NoHashObject对象的ptr成员 rp = new Resource() ; //现在可以通过使用obj_ptr指针使用堆中的NoHashObject对象成员了 .. ... delete rp ;//释放资源 temp = (char*)obj_ptr ; obj_ptr = NULL ;//防止悬挂指针产生 delete [] temp ;//释放NoHashObject对象所占的堆空间。&#125; 上面的实现是麻烦的，而且这种实现方式几乎不会在实践中使用，但是我还是写出来路，因为理解它，对于我们理解C++内存对象是有好处的。对于上面的这么多强制类型转换，其最根本的是什么了？我们可以这样理解： 某块内存中的数据是不变的，而类型就是我们戴上的眼镜，当我们戴上一种眼镜后，我们就会用对应的类型来解释内存中的数据，这样不同的解释就得到了不同的信息。 所谓强制类型转换实际上就是换上另一副眼镜后再来看同样的那块内存数据。 另外要提醒的是，不同的编译器对对象的成员数据的布局安排可能是不一样的，比如，大多数编译器将NoHashObject的ptr指针成员安排在对象空间的头4个字节，这样才会保证下面这条语句的转换动作像我们预期的那样执行：1Resource* rp = (Resource*)obj_ptr ; 但是，并不一定所有的编译器都是如此。 既然我们可以禁止产生某种类型的堆对象，那么可以设计一个类，使之不能产生栈对象吗？当然可以。 禁止产生栈对象前面已经提到了，创建栈对象时会移动栈顶指针以”挪出”适当大小的空间，然后在这个空间上直接调用对应的构造函数以形成一个栈对象，而当函数返回时，会调用其析构函数释放这个对象，然后再调整栈顶指针收回那块栈内存。在这个过程中是不需要operator new/delete操作的，所以将operator new/delete设置为private不能达到目的。当然从上面的叙述中，你也许已经想到了：将构造函数或析构函数设为私有的，这样系统就不能调用构造/析构函数了，当然就不能在栈中生成对象了。 这样的确可以，而且我也打算采用这种方案。但是在此之前，有一点需要考虑清楚,那就是，如果我们将构造函数设置为私有，那么我们也就不能用new来直接产生堆对象了，因为new在为对象分配空间后也会调用它的构造函数啊。所以，我打算只将析构函数设置为private。再进一步，将析构函数设为private除了会限制栈对象生成外，还有其它影响吗？是的，这还会限制继承。 如果一个类不打算作为基类，通常采用的方案就是将其析构函数声明为private。 为了限制栈对象，却不限制继承，我们可以将析构函数声明为protected，这样就两全其美了。如下代码所示：12345678910class NoStackObject&#123; protected: ~NoStackObject() &#123; &#125; public: void destroy() &#123; delete this ;//调用保护析构函数 &#125;&#125;; 接着，可以像这样使用NoStackObject类：123NoStackObject* hash_ptr = new NoStackObject() ;... ... //对hash_ptr指向的对象进行操作hash_ptr-&gt;destroy() ; 呵呵，是不是觉得有点怪怪的，我们用new创建一个对象，却不是用delete去删除它，而是要用destroy方法。很显然，用户是不习惯这种怪异的使用方式的。所以，我决定将构造函数也设为private或protected。这又回到了上面曾试图避免的问题，即不用new，那么该用什么方式来生成一个对象了？我们可以用间接的办法完成，即让这个类提供一个static成员函数专门用于产生该类型的堆对象。（设计模式中的singleton模式就可以用这种方式实现。）让我们来看看：123456789101112131415class NoStackObject&#123; protected: NoStackObject() &#123; &#125; ~NoStackObject() &#123; &#125; public: static NoStackObject* creatInstance() &#123; return new NoStackObject() ;//调用保护的构造函数 &#125;void destroy()&#123; delete this ;//调用保护的析构函数&#125;&#125;; 现在可以这样使用NoStackObject类了：1234NoStackObject* hash_ptr = NoStackObject::creatInstance() ;... ... //对hash_ptr指向的对象进行操作hash_ptr-&gt;destroy() ;hash_ptr = NULL ; //防止使用悬挂指针 现在感觉是不是好多了，生成对象和释放对象的操作一致了。 浅议C++ 中的垃圾回收方法许多 C 或者 C++ 程序员对垃圾回收嗤之以鼻，认为垃圾回收肯定比自己来管理动态内存要低效，而且在回收的时候一定会让程序停顿在那里，而如果自己控制内存管理的话，分配和释放时间都是稳定的，不会导致程序停顿。最后，很多 C/C++ 程序员坚信在C/C++ 中无法实现垃圾回收机制。这些错误的观点都是由于不了解垃圾回收的算法而臆想出来的。 其实垃圾回收机制并不慢，甚至比动态内存分配更高效。因为我们可以只分配不释放，那么分配内存的时候只需要从堆上一直的获得新的内存，移动堆顶的指针就够了；而释放的过程被省略了，自然也加快了速度。现代的垃圾回收算法已经发展了很多，增量收集算法已经可以让垃圾回收过程分段进行，避免打断程序的运行了。而传统的动态内存管理的算法同样有在适当的时间收集内存碎片的工作要做，并不比垃圾回收更有优势。 而垃圾回收的算法的基础通常基于扫描并标记当前可能被使用的所有内存块，从已经被分配的所有内存中把未标记的内存回收来做的。C/C++ 中无法实现垃圾回收的观点通常基于无法正确扫描出所有可能还会被使用的内存块，但是，看似不可能的事情实际上实现起来却并不复杂。首先，通过扫描内存的数据，指向堆上动态分配出来内存的指针是很容易被识别出来的，如果有识别错误，也只能是把一些不是指针的数据当成指针，而不会把指针当成非指针数据。这样，回收垃圾的过程只会漏回收掉而不会错误的把不应该回收的内存清理。其次，如果回溯所有内存块被引用的根，只可能存在于全局变量和当前的栈内，而全局变量(包括函数内的静态变量)都是集中存在于 bss 段或 data段中。 垃圾回收的时候，只需要扫描 bss 段, data 段以及当前被使用着的栈空间，找到可能是动态内存指针的量，把引用到的内存递归扫描就可以得到当前正在使用的所有动态内存了。 如果肯为你的工程实现一个不错的垃圾回收器，提高内存管理的速度，甚至减少总的内存消耗都是可能的。如果有兴趣的话，可以搜索一下网上已有的关于垃圾回收的论文和实现了的库，开拓视野对一个程序员尤为重要。]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解软件包的配置、编译与安装]]></title>
    <url>%2F2019%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E9%85%8D%E7%BD%AE%E3%80%81%E7%BC%96%E8%AF%91%E4%B8%8E%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[从源代码安装过软件的朋友一定对 ./configure &amp;&amp; make &amp;&amp; make install 安装三步曲非常熟悉了。然而究竟这个过程中的每一步幕后都发生了些什么呢？本文将带领你一探究竟。深入理解这个过程将有助于你在LFS的基础上玩出自己的花样来。不过需要说明的是本文对 Makefile 和 make 的讲解是相当近视和粗浅的，但是对于理解安装过程来说足够了。 概述用一句话来解释这个过程就是： 根据源码包中 Makefile.in 文件的指示，configure 脚本检查当前的系统环境和配置选项，在当前目录中生成 Makefile 文件(还有其它本文无需关心的文件)，然后 make 程序就按照当前目录中的 Makefile 文件的指示将源代码编译为二进制文件，最后将这些二进制文件移动(即安装)到指定的地方(仍然按照 Makefile 文件的指示)。 由此可见 Makefile 文件是幕后的核心。要深入理解安装过程，必须首先对 Makefile 文件有充分的了解。本文将首先讲述 Makefile 与 make ，然后再讲述 configure 脚本。并且在讲述这两部分内容时，提供了尽可能详细的、可以运用于实践的参考资料。 Makefile 与 make用一句话来概括Makefile 与 make 的关系就是：Makefile 包含了所有的规则和目标，而 make 则是为了完成目标而去解释 Makefile 规则的工具。 make 语法首先看看 make 的命令行语法： make [options] [targets] [VAR=VALUE]...[options]是命令行选项，可以用 make –help 命令查看全部，[VAR=VALUE]是在命令行上指定环境变量，这两个大家都很熟悉，将在稍后详细讲解。而[targets]是什么呢？字面的意思是”目标”，也就是希望本次 make 命令所完成的任务。凭经验猜测，这个[targets]大概可以用”check”,”install”之类(也就是常见的测试和安装命令)。但是它到底是个啥玩意儿？不带任何”目标”的 make 命令是什么意思？为什么在安装 LFS 工具链中的 Perl-5.8.8 软件包时会出现”make perl utilities”这样怪异的命令？要回答这些问题必须首先理解 Makefile 文件中的”规则”。 Makefile 规则Makefile 规则包含了文件之间的依赖关系和更新此规则目标所需要的命令。 一个简单的 Makefile 规则是这样写的：12TARGET : PREREQUISITES COMMAND TARGET规则的目标。也就是可以被 make 使用的”目标”。有些目标可以没有依赖而只有动作(命令行)，比如”clean”，通常仅仅定义一系列删除中间文件的命令。同样，有些目标可以没有动作而只有依赖，比如”all”，通常仅仅用作”终极目标”。PREREQUISITES规则的依赖。通常一个目标依赖于一个或者多个文件。COMMAND规则的命令行。一个规则可以有零个或多个命令行。OK! 现在你明白[targets]是什么了，原来它们来自于 Makefile 文件中一条条规则的目标(TARGET)。另外，Makefile文件中第一条规则的目标被称为”终极目标”，也就是你省略[targets]参数时的目标(通常为”all”)。 当你查看一个实际的 Makefile 文件时，你会发现有些规则非常复杂，但是它都符合规则的基本格式。此外，Makefile 文件中通常还包含了除规则以外的其它很多东西，不过本文只关心其中的变量。 Makefile 变量Makefile 中的”变量”更像是 C 语言中的宏，代表一个文本字符串(变量的值)，可以用于规则的任何部分。变量的定义很简单：VAR=VALUE；变量的引用也很简单：$(VAR) 或者 ${VAR}。变量引用的展开过程是严格的文本替换过程，就是说变量值的字符串被精确的展开在变量被引用的地方。比如，若定义：VAR=c，那么，”$(VAR) $(VAR)-$(VAR) VAR.$(VAR)”将被展开为”c c-c VAR.c”。 虽然在 Makefile 中可以直接使用系统的环境变量，但是也可以通过在 Makefile 中定义同名变量来”遮盖”系统的环境变量。另一方面，我们可以在调用 make 时使用 -e 参数强制使系统中的环境变量覆盖 Makefile 中的同名变量，除此之外，在调用 make 的命令行上使用 VAR=VALUE 格式指定的环境变量也可以覆盖 Makefile 中的同名变量。 Makefile 实例下面看一个简单的、实际的Makefile文件：123456789101112131415161718192021222324252627282930313233CC=gccCPPFLAGS=CFLAGS=-O2 -pipeLDFLAGS=-sPREFIX=/usrall : prog1 prog2prog1 : prog1.o $(CC) $(LDFLAGS) -o prog1 prog1.oprog1.o : prog1.c $(CC) -c $(CFLAGS) prog1.cprog2 : prog2.o $(CC) $(CFLAGS) $(LDFLAGS) -o prog2 prog2.oprog2.o : prog2.c $(CC) -c $(CPPFLAGS) $(CFLAGS) prog2.cclean : rm -f *.&#123;o,a&#125; prog&#123;1,2&#125;install : prog1 prog2 if ( test ! -d $(PREFIX)/bin ) ; then mkdir -p $(PREFIX)/bin ; fi cp -f prog1 $(PREFIX)/bin/prog1 cp -f prog2 $(PREFIX)/bin/prog2check test : prog1 prog2 prog1 &lt; sample1.ref &gt; sample1.rz prog1 &lt; sample2.ref &gt; sample3.rz cmp sample1.ok sample1.rz cmp sample2.ok sample2.rz 从中可以看出，make 与 make all 以及 make prog1 prog2 三条命令其实是等价的。而常用的 make check 和 make install 也找到了归属。同时我们也看到了 Makefile 中的各种变量是如何影响编译的。针对这个特定的 Makefile ，你甚至可以省略安装三步曲中的 make 命令而直接使用 make install 进行安装。 同样，为了使用自定义的编译参数编译 prog2 ，我们可以使用 make prog2 CFLAGS=”-O3 -march=athlon64” 或 CFLAGS=”-O3 -march=athlon64” &amp;&amp; make -e prog2 命令达到此目的。 Makefile 惯例下面是Makefile中一些约定俗成的目标名称及其含义： all编译整个软件包，但不重建任何文档。一般此目标作为默认的终极目标。此目标一般对所有源程序的编译和连接使用”-g”选项，以使最终的可执行程序中包含调试信息。可使用 strip 程序去掉这些调试符号。clean清除当前目录下在 make 过程中产生的文件。它不能删除软件包的配置文件，也不能删除 build 时创建的那些文件。distclean类似于”clean”，但增加删除当前目录下的的配置文件、build 过程产生的文件。info产生必要的 Info 文档。check 或 test完成所有的自检功能。在执行检查之前，应确保所有程序已经被创建(但可以尚未安装)。为了进行测试，需要实现在程序没有安装的情况下被执行的测试命令。install完成程序的编译并将最终的可执行程序、库文件等拷贝到指定的目录。此种安装一般不对可执行程序进行 strip 操作。install-strip和”install”类似，但是会对复制到安装目录下的可执行文件进行 strip 操作。uninstall删除所有由”install”安装的文件。installcheck执行安装检查。在执行安装检查之前，需要确保所有程序已经被创建并且被安装。installdirs创建安装目录及其子目录。它不能更改软件的编译目录，而仅仅是创建程序的安装目录。下面是 Makefile 中一些约定俗成的变量名称及其含义： 这些约定俗成的变量分为三类。第一类代表可执行程序的名字，例如 CC 代表编译器这个可执行程序；第二类代表程序使用的参数(多个参数使用空格分开)，例如 CFLAGS 代表编译器执行时使用的参数(一种怪异的做法是直接在 CC 中包含参数)；第三类代表安装目录，例如 prefix 等等，含义简单，下面只列出它们的默认值。12345678910111213141516171819202122232425262728293031323334AR 函数库打包程序，可创建静态库.a文档。默认是&quot;ar&quot;。AS 汇编程序。默认是&quot;as&quot;。CC C编译程序。默认是&quot;cc&quot;。CXX C++编译程序。默认是&quot;g++&quot;。CPP C/C++预处理器。默认是&quot;$(CC) -E&quot;。FC Fortran编译器。默认是&quot;f77&quot;。PC Pascal语言编译器。默认是&quot;pc&quot;。YACC Yacc文法分析器。默认是&quot;yacc&quot;。ARFLAGS 函数库打包程序的命令行参数。默认值是&quot;rv&quot;。ASFLAGS 汇编程序的命令行参数。CFLAGS C编译程序的命令行参数。CXXFLAGS C++编译程序的命令行参数。CPPFLAGS C/C++预处理器的命令行参数。FFLAGS Fortran编译器的命令行参数。PFLAGS Pascal编译器的命令行参数。YFLAGS Yacc文法分析器的命令行参数。LDFLAGS 链接器的命令行参数。prefix /usr/localexec_prefix $(prefix)bindir $(exec_prefix)/binsbindir $(exec_prefix)/sbinlibexecdir $(exec_prefix)/libexecdatadir $(prefix)/sharesysconfdir $(prefix)/etcsharedstatedir $(prefix)/comlocalstatedir $(prefix)/varlibdir $(exec_prefix)/libinfodir $(prefix)/infoincludedir $(prefix)/includeoldincludedir $(prefix)/includemandir $(prefix)/mansrcdir 需要编译的源文件所在的目录，无默认值 make 选项最后说说 make 的命令行选项(以Make-3.81版本为准)： -B, –always-make无条件的重建所有规则的目标，而不是根据规则的依赖关系决定是否重建某些目标文件。-C DIR, –directory=DIR在做任何动作之前先切换工作目录到 DIR ，然后再执行 make 程序。-d在 make 执行过程中打印出所有的调试信息。包括：make 认为那些文件需要重建；那些文件需要比较它们的最后修改时间、比较的结果；重建目标所要执行的命令；使用的隐含规则等。使用该选项我们可以看到 make 构造依赖关系链、重建目标过程的所有信息，它等效于”-debug=a”。–debug=FLAGS在 make 执行过程中打印出调试信息。FLAGS 用于控制调试信息级别：a输出所有类型的调试信息b输出基本调试信息。包括：那些目标过期、是否重建成功过期目标文件。v除 b 级别以外还包括：解析的 makefile 文件名，不需要重建文件等。i除 b 级别以外还包括：所有使用到的隐含规则描述。j输出所有执行命令的子进程，包括命令执行的 PID 等。m输出 make 读取、更新、执行 makefile 的信息。-e, –environment-overrides使用系统环境变量的定义覆盖 Makefile 中的同名变量定义。-f FILE, –file=FILE, –makefile=FILE将 FILE 指定为 Makefile 文件。-h, –help打印帮助信息。-i, –ignore-errors忽略规则命令执行过程中的错误。-I DIR, –include-dir=DIR指定包含 Makefile 文件的搜索目录。使用多个”-I”指定目录时，搜索目录按照指定顺序进行。-j [N], –jobs[=N]指定并行执行的命令数目。在没有指定”-j”参数的情况下，执行的命令数目将是系统允许的最大可能数目。-k, –keep-going遇见命令执行错误时不终止 make 的执行，也就是尽可能执行所有的命令，直到出现致命错误才终止。-l [N], –load-average[=N], –max-load[=N]如果系统负荷超过 LOAD(浮点数)，不再启动新任务。-L, –check-symlink-times同时考察符号连接的时间戳和它所指向的目标文件的时间戳，以两者中较晚的时间戳为准。-n, –just-print, –dry-run, –recon只打印出所要执行的命令，但并不实际执行命令。-o FILE, –old-file=FILE, –assume-old=FILE即使相对于它的依赖已经过期也不重建 FILE 文件；同时也不重建依赖于此文件任何文件。-p, –print-data-base命令执行之前，打印出 make 读取的 Makefile 的所有数据（包括规则和变量的值），同时打印出 make 的版本信息。如果只需要打印这些数据信息，可以使用 make -qp 命令。查看 make 执行前的预设规则和变量，可使用命令 make -p -f /dev/null 。-q, –question“询问模式”。不运行任何命令，并且无输出，只是返回一个查询状态。返回状态为 0 表示没有目标需要重建，1 表示存在需要重建的目标，2 表示有错误发生。-r, –no-builtin-rules取消所有内嵌的隐含规则，不过你可以在 Makefile 中使用模式规则来定义规则。同时还会取消所有支持后追规则的隐含后缀列表，同样我们也可以在 Makefile 中使用”.SUFFIXES”定义我们自己的后缀规则。此选项不会取消 make 内嵌的隐含变量。-R, –no-builtin-variables取消 make 内嵌的隐含变量，不过我们可以在 Makefile 中明确定义某些变量。注意，此选项同时打开了”-r”选项。因为隐含规则是以内嵌的隐含变量为基础的。-s, –silent, –quiet不显示所执行的命令。-S, –no-keep-going, –stop取消”-k”选项。在递归的 make 过程中子 make 通过 MAKEFLAGS 变量继承了上层的命令行选项。我们可以在子 make 中使用”-S”选项取消上层传递的”-k”选项，或者取消系统环境变量 MAKEFLAGS 中的”-k”选项。-t, –touch更新所有目标文件的时间戳到当前系统时间。防止 make 对所有过时目标文件的重建。-v, –version打印版本信息。-w, –print-directory在 make 进入一个目录之前打印工作目录。使用”-C”选项时默认打开这个选项。–no-print-directory取消”-w”选项。可以是用在递归的 make 调用过程中，取消”-C”参数将默认打开”-w”。-W FILE, –what-if=FILE, –new-file=FILE, –assume-new=FILE设定 FILE 文件的时间戳为当前时间，但不改变文件实际的最后修改时间。此选项主要是为实现了对所有依赖于 FILE 文件的目标的强制重建。–warn-undefined-variables在发现 Makefile 中存在对未定义的变量进行引用时给出告警信息。此功能可以帮助我们调试一个存在多级套嵌变量引用的复杂 Makefile 。但是：我们建议在书写 Makefile 时尽量避免超过三级以上的变量套嵌引用。 configure此阶段的主要目的是生成 Makefile 文件，是最关键的运筹帷幄阶段，基本上所有可以对安装过程进行的个性化调整都集中在这一步。 configure 脚本能够对 Makefile 中的哪些内容产生影响呢？基本上可以这么说：所有内容，包括本文最关心的 Makefile 规则与 Makefile 变量。那么又是哪些因素影响着最终生成的 Makefile 文件呢？答曰：系统环境和配置选项。 配置选项的影响是显而易见的。但是”系统环境”的概念却很宽泛，包含很多方面内容，不过我们这里只关心环境变量，具体说来就是将来会在 Makefile 中使用到的环境变量以及与 Makefile 中的变量同名的环境变量。 通用 configure 语法在进一步讲述之前，先看看 configure 脚本的语法，一般有两种：12configure [OPTIONS] [VAR=VALUE]...configure [OPTIONS] [HOST] 不管是哪种语法，我们都可以用 configure –help 查看所有可用的[OPTIONS]，并且通常在结尾部分还能看到这个脚本所关心的环境变量有哪些。在本文中将对这两种语法进行合并，使用下面这种简化的语法：1configure [OPTIONS] 这种语法能够被所有的 configure 脚本所识别，同时也能通过设置环境变量和使用特定的[OPTIONS]完成上述两种语法的一切功能。 通用 configure 选项虽然每个软件包的 configure 脚本千差万别，但是它们却都有一些共同的选项，也基本上都遵守相同的选项语法。 脚本自身选项–help显示帮助信息。–version显示版本信息。–cache-file=FILE在FILE文件中缓存测试结果(默认禁用)。–no-createconfigure脚本运行结束后不输出结果文件，常用于正式编译前的测试。–quiet, –silent不显示脚本工作期间输出的”checking …”消息。目录选项–srcdir=DIR源代码文件所在目录，默认为configure脚本所在目录或其父目录。–prefix=PREFIX体系无关文件的顶级安装目录PREFIX ，默认值一般是 /usr/local 或 /usr/local/pkgName–exec-prefix=EPREFIX体系相关文件的顶级安装目录EPREFIX ，默认值一般是 PREFIX–bindir=DIR用户可执行文件的存放目录DIR ，默认值一般是 EPREFIX/bin–sbindir=DIR系统管理员可执行目录DIR ，默认值一般是 EPREFIX/sbin–libexecdir=DIR程序可执行目录DIR ，默认值一般是 EPREFIX/libexec–datadir=DIR通用数据文件的安装目录DIR ，默认值一般是 PREFIX/share–sysconfdir=DIR只读的单一机器数据目录DIR ，默认值一般是 PREFIX/etc–sharedstatedir=DIR可写的体系无关数据目录DIR ，默认值一般是 PREFIX/com–localstatedir=DIR可写的单一机器数据目录DIR ，默认值一般是 PREFIX/var–libdir=DIR库文件的安装目录DIR ，默认值一般是 EPREFIX/lib–includedir=DIRC头文件目录DIR ，默认值一般是 PREFIX/include–oldincludedir=DIR非gcc的C头文件目录DIR ，默认值一般是 /usr/include–infodir=DIRInfo文档的安装目录DIR ，默认值一般是 PREFIX/info–mandir=DIRMan文档的安装目录DIR ，默认值一般是 PREFIX/man体系结构选项玩交叉编译的朋友对这些选项已经很熟悉了，对于不使用交叉编译的朋友也不必担心，不要理它们就可以了。 –build=BUILD工具链当前的运行环境，默认是 config.guess 脚本的输出结果。–host=HOST编译出的二进制代码将要运行在HOST上，默认值是BUILD。–target=TARGET编译出的工具链所将来生成的二进制代码要在TARGET上运行，这个选项仅对工具链(也就是GCC和Binutils两者)有意义。特性选项–enable-FEATURE启用FEATURE特性–disable-FEATURE禁用FEATURE特性–with-PACKAGE[=DIR]启用附加软件包PACKAGE，亦可同时指定PACKAGE所在目录DIR–without-PACKAGE禁用附加软件包PACKAGE通用环境变量除了上述通用的选项外，下列环境变量影响着最终生成的 Makefile 文件： CPPC预处理器命令CXXCPPC++预处理器命令CPPFLAGSC/C++预处理器命令行参数CCC编译器命令CFLAGSC编译器命令行参数CXXC++编译器命令CXXFLAGSC++编译器命令行参数LDFLAGS连接器命令行参数至于设置这些环境变量的方法，你可以将它们 export 为全局变量在全局范围内使用，也可以在命令行上使用 [VAR=VALUE]… configure [OPTIONS] 的语法局部使用。此处就不详细描述了。 看完上述内容以后，不用多说你应当自然而然的明白该进行如何对自己的软件包进行定制安装了。祝你好运！]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GCC 编译优化指南]]></title>
    <url>%2F2019%2F04%2F09%2FGCC%E7%BC%96%E8%AF%91%E4%BC%98%E5%8C%96%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[基本原理我们首先从三个方面来看与优化相关的内容： 从运行时的依赖关系来看，对性能有较大影响的组件有 kernel 和 glibc ，虽然这严格说来这不属于本文的话题，但是经过精心选择、精心配置、精心编译的内核与C库将对提高系统的运行速度起着基础性的作用。从被编译的软件包来看，每个软件包的 configure 脚本都提供了许多配置选项，其中有许多选项是与性能息息相关的。比如，对于 Apache-2.2.6 而言，你可以使用 –enable-MODULE=static 将模块静态编译进核心，使用 –disable-MODULE 禁用不需要的模块，使用 –with-mpm=MPM 选择一个高效的多路处理模块，在不需要IPv6的情况下使用 –disable-ipv6 禁用IPv6支持，在不使用线程化的MPM时使用 –disable-threads 禁用线程支持，等等……这部分内容显然不可能在本文中进行完整的讲述，本文只能讲述与优化相关的通用选项。针对特定的软件包，请在编译前使用 configure –help 查看所有选项，并精心选择。从编译过程自身来看，将源代码编译为二进制文件是在 Makefile 文件的指导下，由 make 程序调用一条条编译命令完成的。而将源代码编译为二进制文件又需要经过以下四个步骤：预处理(cpp) → 编译(gcc或g++) → 汇编(as) → 连接(ld) ；括号中表示每个阶段所使用的程序，它们分别属于 GCC 和 Binutils 软件包。显然的，优化应当从编译工具自身的选择以及控制编译工具的行为入手。大体上编译优化就这”三板斧”(其实是”三脚猫”)了，本文接下来的内容将讨论这只猫的后两只脚。 编译工具的选择对于编译工具自身的选择，在假定使用 Binutils 和 GCC 以及 Make 的前提下，没什么好说的，基本上新版本都能带来性能提升，同时比老版本对新硬件的支持更好，所以应当尽量选用新版本。不过追新也可能带来系统的不稳定，这就要针对实际情况进行权衡了。本文以 Binutils-2.18 和 GCC-4.2.2/GCC-4.3.0 以及 Make-3.81 为例进行说明。 configure 选项这里我们只讲解通用的”体系结构选项”，由于”特性选项”在每个软件包之间千差万别，所以不可能在此处进行讲解。 这部分内容很简单，并且其含义也是不言而喻的，下面只列出常用的值： i586-pc-linux-gnui686-pc-linux-gnux86_64-pc-linux-gnupowerpc-unknown-linux-gnupowerpc64-unknown-linux-gnu如果你实在不知道应当使用哪一个，那么就干脆不使用这几个选项，让 config.guess 脚本自己去猜吧，反正也挺准的。 编译选项让我们先看看 Makefile 规则中的编译命令通常是怎么写的。 大多数软件包遵守如下约定俗成的规范： 首先从源代码生成目标文件(预处理,编译,汇编)，”-c”选项表示不执行链接步骤。$(CC) $(CPPFLAGS) $(CFLAGS) example.c -c -o example.o 然后将目标文件连接为最终的结果(连接)，”-o”选项用于指定输出文件的名字。$(CC) $(LDFLAGS) example.o -o example 有一些软件包一次完成四个步骤：$(CC) $(CPPFLAGS) $(CFLAGS) $(LDFLAGS) example.c -o example当然也有少数软件包不遵守这些约定俗成的规范，比如： 有些在命令行中漏掉应有的Makefile变量(注意：有些遗漏是故意的)$(CC) $(CFLAGS) example.c -c -o example.o$(CC) $(CPPFLAGS) example.c -c -o example.o$(CC) example.o -o example$(CC) example.c -o example 有些在命令行中增加了不必要的Makefile变量$(CC) $(CFLAGS) $(LDFLAGS) example.o -o example$(CC) $(CPPFLAGS) $(CFLAGS) $(LDFLAGS) example.c -c -o example.o当然还有极个别软件包完全是”胡来”：乱用变量(增加不必要的又漏掉了应有的)者有之，不用$(CC)者有之，不一而足….. 尽管将源代码编译为二进制文件的四个步骤由不同的程序(cpp,gcc/g++,as,ld)完成，但是事实上 cpp, as, ld 都是由 gcc/g++ 进行间接调用的。换句话说，控制了 gcc/g++ 就等于控制了所有四个步骤。从 Makefile 规则中的编译命令可以看出，编译工具的行为全靠 CC/CXX CPPFLAGS CFLAGS/CXXFLAGS LDFLAGS 这几个变量在控制。当然理论上控制编译工具行为的还应当有 AS ASFLAGS ARFLAGS 等变量，但是实践中基本上没有软件包使用它们。 那么我们如何控制这些变量呢？一种简易的做法是首先设置与这些 Makefile 变量同名的环境变量并将它们 export 为全局，然后运行 configure 脚本，大多数 configure 脚本会使用这同名的环境变量代替 Makefile 中的值。但是少数 configure 脚本并不这样做(比如GCC-3.4.6和Binutils-2.16.1的脚本就不传递LDFLAGS)，你必须手动编辑生成的 Makefile 文件，在其中寻找这些变量并修改它们的值，许多源码包在每个子文件夹中都有 Makefile 文件，真是一件很累人的事！ CC 与 CXX这是 C 与 C++ 编译器命令。默认值一般是 “gcc” 与 “g++”。这个变量本来与优化没有关系，但是有些人因为担心软件包不遵守那些约定俗成的规范，害怕自己苦心设置的 CFLAGS/CXXFLAGS/LDFLAGS 之类的变量被忽略了，而索性将原本应当放置在其它变量中的选项一股老儿塞到 CC 或 CXX 中，比如：CC=”gcc -march=k8 -O2 -s”。这是一种怪异的用法，本文不提倡这种做法，而是提倡按照变量本来的含义使用变量。 CPPFLAGS这是用于预处理阶段的选项。不过能够用于此变量的选项，看不出有哪个与优化相关。如果你实在想设一个，那就使用下面这两个吧： -DNDEBUG“NDEBUG”是一个标准的 ANSI 宏，表示不进行调试编译。-D_FILE_OFFSET_BITS=64大多数包使用这个来提供大文件(&gt;2G)支持。CFLAGS 与 CXXFLAGSCFLAGS 表示用于 C 编译器的选项，CXXFLAGS 表示用于 C++ 编译器的选项。这两个变量实际上涵盖了编译和汇编两个步骤。大多数程序和库在编译时默认的优化级别是”2”(使用”-O2”选项)并且带有调试符号来编译，也就是 CFLAGS=”-O2 -g”, CXXFLAGS=$CFLAGS 。事实上，”-O2”已经启用绝大多数安全的优化选项了。另一方面，由于大部分选项可以同时用于这两个变量，所以仅在最后讲述只能用于其中一个变量的选项。[提醒]下面所列选项皆为非默认选项，你只要按需添加即可。 先说说”-O3”在”-O2”基础上增加的几项： -finline-functions允许编译器选择某些简单的函数在其被调用处展开，比较安全的选项，特别是在CPU二级缓存较大时建议使用。-funswitch-loops将循环体中不改变值的变量移动到循环体之外。-fgcse-after-reload为了清除多余的溢出，在重载之后执行一个额外的载入消除步骤。另外： -fomit-frame-pointer对于不需要栈指针的函数就不在寄存器中保存指针，因此可以忽略存储和检索地址的代码，同时对许多函数提供一个额外的寄存器。所有”-O”级别都打开它，但仅在调试器可以不依靠栈指针运行时才有效。在AMD64平台上此选项默认打开，但是在x86平台上则默认关闭。建议显式的设置它。-falign-functions=N-falign-jumps=N-falign-loops=N-falign-labels=N这四个对齐选项在”-O2”中打开，其中的根据不同的平台N使用不同的默认值。如果你想指定不同于默认值的N，也可以单独指定。比如，对于L2-cache&gt;=1M的cpu而言，指定 -falign-functions=64 可能会获得更好的性能。建议在指定了 -march 的时候不明确指定这里的值。调试选项： -fprofile-arcs在使用这一选项编译程序并运行它以创建包含每个代码块的执行次数的文件后，程序可以再次使用 -fbranch-probabilities 编译，文件中的信息可以用来优化那些经常选取的分支。如果没有这些信息，gcc将猜测哪个分支将被经常运行以进行优化。这类优化信息将会存放在一个以源文件为名字的并以”.da”为后缀的文件中。全局选项： -pipe在编译过程的不同阶段之间使用管道而非临时文件进行通信，可以加快编译速度。建议使用。目录选项： –sysroot=dir将dir作为逻辑根目录。比如编译器通常会在 /usr/include 和 /usr/lib 中搜索头文件和库，使用这个选项后将在 dir/usr/include 和 dir/usr/lib 目录中搜索。如果使用这个选项的同时又使用了 -isysroot 选项，则此选项仅作用于库文件的搜索路径，而 -isysroot 选项将作用于头文件的搜索路径。这个选项与优化无关，但是在 CLFS 中有着神奇的作用。代码生成选项： -fno-bounds-check关闭所有对数组访问的边界检查。该选项将提高数组索引的性能，但当超出数组边界时，可能会造成不可接受的行为。-freg-struct-return如果struct和union足够小就通过寄存器返回，这将提高较小结构的效率。如果不够小，无法容纳在一个寄存器中，将使用内存返回。建议仅在完全使用GCC编译的系统上才使用。-fpic生成可用于共享库的位置独立代码。所有的内部寻址均通过全局偏移表完成。要确定一个地址，需要将代码自身的内存位置作为表中一项插入。该选项产生可以在共享库中存放并从中加载的目标模块。-fstack-check为防止程序栈溢出而进行必要的检测，仅在多线程环境中运行时才可能需要它。-fvisibility=hidden设置默认的ELF镜像中符号的可见性为隐藏。使用这个特性可以非常充分的提高连接和加载共享库的性能，生成更加优化的代码，提供近乎完美的API输出和防止符号碰撞。我们强烈建议你在编译任何共享库的时候使用该选项。参见 -fvisibility-inlines-hidden 选项。硬件体系结构相关选项[仅仅针对x86与x86_64]： -march=cpu-type为特定的cpu-type编译二进制代码(不能在更低级别的cpu上运行)。Intel可以用：pentium2, pentium3(=pentium3m), pentium4(=pentium4m), pentium-m, prescott, nocona, core2(GCC-4.3新增) 。AMD可以用：k6-2(=k6-3), athlon(=athlon-tbird), athlon-xp(=athlon-mp), k8(=opteron=athlon64=athlon-fx)-mfpmath=sseP3和athlon-xp级别及以上的cpu支持”sse”标量浮点指令。仅建议在P4和K8以上级别的处理器上使用该选项。-malign-double将double, long double, long long对齐于双字节边界上；有助于生成更高速的代码，但是程序的尺寸会变大，并且不能与未使用该选项编译的程序一起工作。-m128bit-long-double指定long double为128位，pentium以上的cpu更喜欢这种标准，并且符合x86-64的ABI标准，但是却不附合i386的ABI标准。-mregparm=N指定用于传递整数参数的寄存器数目(默认不使用寄存器)。0&lt;=N&lt;=3 ；注意：当N&gt;0时你必须使用同一参数重新构建所有的模块，包括所有的库。-msseregparm使用SSE寄存器传递float和double参数和返回值。注意：当你使用了这个选项以后，你必须使用同一参数重新构建所有的模块，包括所有的库。-mmmx-msse-msse2-msse3-m3dnow-mssse3(没写错!GCC-4.3新增)-msse4.1(GCC-4.3新增)-msse4.2(GCC-4.3新增)-msse4(含4.1和4.2,GCC-4.3新增)是否使用相应的扩展指令集以及内置函数，按照自己的cpu选择吧！-maccumulate-outgoing-args指定在函数引导段中计算输出参数所需最大空间，这在大部分现代cpu中是较快的方法；缺点是会明显增加二进制文件尺寸。-mthreads支持Mingw32的线程安全异常处理。对于依赖于线程安全异常处理的程序，必须启用这个选项。使用这个选项时会定义”-D_MT”，它将包含使用选项”-lmingwthrd”连接的一个特殊的线程辅助库，用于为每个线程清理异常处理数据。-minline-all-stringops默认时GCC只将确定目的地会被对齐在至少4字节边界的字符串操作内联进程序代码。该选项启用更多的内联并且增加二进制文件的体积，但是可以提升依赖于高速 memcpy, strlen, memset 操作的程序的性能。-minline-stringops-dynamicallyGCC-4.3新增。对未知尺寸字符串的小块操作使用内联代码，而对大块操作仍然调用库函数，这是比”-minline-all-stringops”更聪明的策略。决定策略的算法可以通过”-mstringop-strategy”控制。-momit-leaf-frame-pointer不为叶子函数在寄存器中保存栈指针，这样可以节省寄存器，但是将会使调试变的困难。注意：不要与 -fomit-frame-pointer 同时使用，因为会造成代码效率低下。-m64生成专门运行于64位环境的代码，不能运行于32位环境，仅用于x86_64[含EMT64]环境。-mcmodel=small[默认值]程序和它的符号必须位于2GB以下的地址空间。指针仍然是64位。程序可以静态连接也可以动态连接。仅用于x86_64[含EMT64]环境。-mcmodel=kernel内核运行于2GB地址空间之外。在编译linux内核时必须使用该选项！仅用于x86_64[含EMT64]环境。-mcmodel=medium程序必须位于2GB以下的地址空间，但是它的符号可以位于任何地址空间。程序可以静态连接也可以动态连接。注意：共享库不能使用这个选项编译！仅用于x86_64[含EMT64]环境。其它优化选项： -fforce-addr必须将地址复制到寄存器中才能对他们进行运算。由于所需地址通常在前面已经加载到寄存器中了，所以这个选项可以改进代码。-finline-limit=n对伪指令数超过n的函数，编译程序将不进行内联展开，默认为600。增大此值将增加编译时间和编译内存用量并且生成的二进制文件体积也会变大，此值不宜太大。-fmerge-all-constants试图将跨编译单元的所有常量值和数组合并在一个副本中。但是标准C/C++要求每个变量都必须有不同的存储位置，所以该选项可能会导致某些不兼容的行为。-fgcse-sm在全局公共子表达式消除之后运行存储移动，以试图将存储移出循环。gcc-3.4中曾属于”-O2”级别的选项。-fgcse-las在全局公共子表达式消除之后消除多余的在存储到同一存储区域之后的加载操作。gcc-3.4中曾属于”-O2”级别的选项。-floop-optimize已废除(GCC-4.1曾包含在”-O1”中)。-floop-optimize2使用改进版本的循环优化器代替原来”-floop-optimize”。该优化器将使用不同的选项(-funroll-loops, -fpeel-loops, -funswitch-loops, -ftree-loop-im)分别控制循环优化的不同方面。目前这个新版本的优化器尚在开发中，并且生成的代码质量并不比以前的版本高。已废除，仅存在于GCC-4.1之前的版本中。-funsafe-loop-optimizations假定循环不会溢出，并且循环的退出条件不是无穷。这将可以在一个比较广的范围内进行循环优化，即使优化器自己也不能断定这样做是否正确。-fsched-spec-load允许一些装载指令执行一些投机性的动作。-ftree-loop-linear在trees上进行线型循环转换。它能够改进缓冲性能并且允许进行更进一步的循环优化。-fivopts在trees上执行归纳变量优化。-ftree-vectorize在trees上执行循环向量化。-ftracer执行尾部复制以扩大超级块的尺寸，它简化了函数控制流，从而允许其它的优化措施做的更好。据说挺有效。-funroll-loops仅对循环次数能够在编译时或运行时确定的循环进行展开，生成的代码尺寸将变大，执行速度可能变快也可能变慢。-fprefetch-loop-arrays生成数组预读取指令，对于使用巨大数组的程序可以加快代码执行速度，适合数据库相关的大型软件等。具体效果如何取决于代码。-fweb建立经常使用的缓存器网络，提供更佳的缓存器使用率。gcc-3.4中曾属于”-O3”级别的选项。-ffast-math违反IEEE/ANSI标准以提高浮点数计算速度，是个危险的选项，仅在编译不需要严格遵守IEEE规范且浮点计算密集的程序考虑采用。-fsingle-precision-constant将浮点常量作为单精度常量对待，而不是隐式地将其转换为双精度。-fbranch-probabilities在使用 -fprofile-arcs 选项编译程序并执行它来创建包含每个代码块执行次数的文件之后，程序可以利用这一选项再次编译，文件中所产生的信息将被用来优化那些经常发生的分支代码。如果没有这些信息，gcc将猜测那一分支可能经常发生并进行优化。这类优化信息将会存放在一个以源文件为名字的并以”.da”为后缀的文件中。-frename-registers试图驱除代码中的假依赖关系，这个选项对具有大量寄存器的机器很有效。gcc-3.4中曾属于”-O3”级别的选项。-fbranch-target-load-optimize-fbranch-target-load-optimize2在执行序启动以及结尾之前执行分支目标缓存器加载最佳化。-fstack-protector在关键函数的堆栈中设置保护值。在返回地址和返回值之前，都将验证这个保护值。如果出现了缓冲区溢出，保护值不再匹配，程序就会退出。程序每次运行，保护值都是随机的，因此不会被远程猜出。-fstack-protector-all同上，但是在所有函数的堆栈中设置保护值。–param max-gcse-memory=xxM执行GCSE优化使用的最大内存量(xxM)，太小将使该优化无法进行，默认为50M。–param max-gcse-passes=n执行GCSE优化的最大迭代次数，默认为 1。传递给汇编器的选项： -Wa,optionsoptions是一个或多个由逗号分隔的可以传递给汇编器的选项列表。其中的每一个均可作为命令行选项传递给汇编器。-Wa,–strip-local-absolute从输出符号表中移除局部绝对符号。-Wa,-R合并数据段和正文段，因为不必在数据段和代码段之间转移，所以它可能会产生更短的地址移动。-Wa,–64设置字长为64bit，仅用于x86_64，并且仅对ELF格式的目标文件有效。此外，还需要使用”–enable-64-bit-bfd”选项编译的BFD支持。-Wa,-march=CPU按照特定的CPU进行优化：pentiumiii, pentium4, prescott, nocona, core, core2; athlon, sledgehammer, opteron, k8 。仅可用于 CFLAGS 的选项： -fhosted按宿主环境编译，其中需要有完整的标准库，入口必须是main()函数且具有int型的返回值。内核以外几乎所有的程序都是如此。该选项隐含设置了 -fbuiltin，且与 -fno-freestanding 等价。-ffreestanding按独立环境编译，该环境可以没有标准库，且对main()函数没有要求。最典型的例子就是操作系统内核。该选项隐含设置了 -fno-builtin，且与 -fno-hosted 等价。仅可用于 CXXFLAGS 的选项： -fno-enforce-eh-specsC++标准要求强制检查异常违例，但是该选项可以关闭违例检查，从而减小生成代码的体积。该选项类似于定义了”NDEBUG”宏。-fno-rtti如果没有使用’dynamic_cast’和’typeid’，可以使用这个选项禁止为包含虚方法的类生成运行时表示代码，从而节约空间。此选项对于异常处理无效(仍然按需生成rtti代码)。-ftemplate-depth-n将最大模版实例化深度设为’n’，符合标准的程序不能超过17，默认值为500。-fno-optional-diags禁止输出诊断消息，C++标准并不需要这些消息。-fno-threadsafe-staticsGCC自动在访问C++局部静态变量的代码上加锁，以保证线程安全。如果你不需要线程安全，可以使用这个选项。-fvisibility-inlines-hidden默认隐藏所有内联函数，从而减小导出符号表的大小，既能缩减文件的大小，还能提高运行性能，我们强烈建议你在编译任何共享库的时候使用该选项。参见 -fvisibility=hidden 选项。LDFLAGSLDFLAGS 是传递给连接器的选项。这是一个常被忽视的变量，事实上它对优化的影响也是很明显的。 -s删除可执行程序中的所有符号表和所有重定位信息。其结果与运行命令 strip 所达到的效果相同，这个选项是比较安全的。-Wl,optionsoptions是由一个或多个逗号分隔的传递给链接器的选项列表。其中的每一个选项均会作为命令行选项提供给链接器。-Wl,-On当n&gt;0时将会优化输出，但是会明显增加连接操作的时间，这个选项是比较安全的。-Wl,–exclude-libs=ALL不自动导出库中的符号，也就是默认将库中的符号隐藏。-Wl,-m仿真连接器，当前ld所有可用的仿真可以通过”ld -V”命令获取。默认值取决于ld的编译时配置。-Wl,–sort-common把全局公共符号按照大小排序后放到适当的输出节，以防止符号间因为排布限制而出现间隙。-Wl,-x删除所有的本地符号。-Wl,-X删除所有的临时本地符号。对于大多数目标平台，就是所有的名字以’L’开头的本地符号。-Wl,-zcomberloc组合多个重定位节并重新排布它们，以便让动态符号可以被缓存。-Wl,–enable-new-dtags在ELF中创建新式的”dynamic tags”，但在老式的ELF系统上无法识别。-Wl,–as-needed移除不必要的符号引用，仅在实际需要的时候才连接，可以生成更高效的代码。-Wl,–no-define-common限制对普通符号的地址分配。该选项允许那些从共享库中引用的普通符号只在主程序中被分配地址。这会消除在共享库中的无用的副本的空间，同时也防止了在有多个指定了搜索路径的动态模块在进行运行时符号解析时引起的混乱。-Wl,–hash-style=gnu使用gnu风格的符号散列表格式。它的动态链接性能比传统的sysv风格(默认)有较大提升，但是它生成的可执行程序和库与旧的Glibc以及动态链接器不兼容。最后说两个与优化无关的系统环境变量，因为会影响GCC编译程序的方式，下面两个是咱中国人比较关心的： LANG指定编译程序使用的字符集，可用于创建宽字符文件、串文字、注释；默认为英文。[目前只支持日文”C-JIS,C-SJIS,C-EUCJP”，不支持中文]LC_ALL指定多字节字符的字符分类，主要用于确定字符串的字符边界以及编译程序使用何种语言发出诊断消息；默认设置与LANG相同。中文相关的几项：”zh_CN.GB2312 , zh_CN.GB18030 , zh_CN.GBK , zh_CN.UTF-8 , zh_TW.BIG5”。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Glibc Binutils GCC 安装]]></title>
    <url>%2F2019%2F04%2F09%2FGlibc%2BBinutils%2BGCC%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[从别的地方抓过来一篇文章，非常详尽。做个备份。 Glibc 安装指南(2.6.1 → 2.9)安装信息的来源源码包内的下列文件：configure FAQ INSTALL NOTES Makeconfig README localedata/READMEhttp://www.gnu.org/software/libc/manual/html_node/System-Configuration.htmlhttp://www.gnu.org/software/libc/manual/html_node/Installation.htmlhttp://www.gnu.org/software/libc/manual/html_node/Name-Service-Switch.html 要点提示编译Glibc的时候应该尽可能使用最新的内核头文件，至少要使用 2.6.16 以上版本的内核，先前的版本有一些缺陷会导致”make check”时一些与pthreads测试相关的项目失败。使用高版本内核头文件编译的Glibc二进制文件完全可以运行在较低版本的内核上，并且当你升级内核后新内核的特性仍然可以得到充分发挥而无需重新编译Glibc。但是如果编译时使用的头文件的版本较低，那么运行在更高版本的内核上时，新内核的特性就不能得到充分发挥。更多细节可以查看[八卦故事]内核头文件传奇的跟帖部分。 推荐使用GCC-4.1以上的版本编译，老版本的GCC可能会生成有缺陷的代码。 不要在运行中的系统上安装 Glibc，否则将会导致系统崩溃，至少应当将新 Glibc 安装到其他的单独目录，以保证不覆盖当前正在使用的 Glibc 。 Glibc 不能在源码目录中编译，它必须在一个额外分开的目录中编译。这样在编译发生错误的时候，就可以删除整个编译目录重新开始。 源码树下的Makeconfig文件中有许多用于特定目的的变量，你可以在编译目录下创建一个configparms文件来改写这些变量。执行make命令的时候configparms文件中的内容将会按照Makefile规则进行解析。比如可以通过在其中设置 CFLAGS LDFLAGS 环境变量来优化编译，设置 CC BUILD_CC AR RANLIB 来指定交叉编译环境。 需要注意的是有些测试项目假定是以非 root 身份执行的，因此我们强烈建议你使用非 root 身份编译和测试 Glibc 。 配置选项下列选项皆为非默认值[特别说明的除外] –help–version–quiet–config-cache–no-create–srcdir=DIR–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–datarootdir=DIR–datadir=DIR–infodir=DIR–localedir=DIR–mandir=DIR–docdir=DIR–htmldir=DIR–dvidir=DIR–pdfdir=DIR–psdir=DIR–build=BUILD–host=HOST这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。需要注意的是：没有–target=TARGET选项。 –prefix=PREFIX安装目录，默认为 /usr/localLinux文件系统标准要求基本库必须位于 /lib 目录并且必须与根目录在同一个分区上，但是 /usr 可以在其他分区甚至是其他磁盘上。因此，如果在Linux平台上指定 –prefix=/usr ，那么基本库部分将自动安装到 /lib 目录下，而非基本库部分则会自动安装到 /usr/lib 目录中，同时将使用 /etc 作为配置目录，也就是等价于”slibdir=/lib sysconfdir=/etc”。但是如果保持默认值或指定其他目录，那么所有组件都间被安装到PREFIX目录下。 –disable-sanity-checks真正禁用线程(仅在特殊环境下使用该选项)。 –enable-check-abi在”make check”时执行”make check-abi”。[提示]在我的机器上始终导致check-abi-libm测试失败。 –disable-shared不编译共享库(即使平台支持)。在支持 ELF 并且使用 GNU 连接器的系统上默认为enable 。[提示] –disable-static 选项实际上是不存在的，静态库总是被无条件的编译和安装。 –enable-profile启用 profiling 信息相关的库文件编译。主要用于调试目的。 –enable-omitfp编译时忽略帧指示器(使用 -fomit-frame-pointer 编译)，并采取一些其他优化措施。忽略帧指示器可以提高运行效率，但是调试将变得不可用，并且可能生成含有 bug 的代码。使用这个选项还将导致额外编译带有调试信息的非优化版本的静态库(库名称以”_g”结尾)。 –enable-bounded启用运行时边界检查(比如数组越界)，这样会降低运行效率，但能防止某些溢出漏洞。 –disable-versioning不在共享库对象中包含符号的版本信息。这样可以减小库的体积，但是将不兼容依赖于老版本 C 库的二进制程序。[提示]在我的机器上使用此选项总是导致编译失败。 –enable-oldest-abi=ABI启用老版本的应用程序二进制接口支持。ABI是Glibc的版本号，只有明确指定版本号时此选项才有效。 –enable-stackguard-randomization在程序启动时使用一个随机数初始化 __stack_chk_guard ，主要用来抵抗恶意攻击。 –enable-add-ons[=DIRS…]为了减小软件包的复杂性，一些可选的libc特性被以单独的软件包发布，比如’linuxthreads’(现在已经被废弃了)，他们被称为’add-ons’。要使用这些额外的包，可以将他们解压到Glibc的源码树根目录下，然后使用此选项将DIR1,DIR2,…中的附加软件包包含进来。其中的”DIR”是附加软件包的目录名。默认值”yes”表示编译所有源码树根目录下找到的附加软件包。 –disable-hidden-plt默认情况下隐藏仅供内部调用的函数，以避免这些函数被加入到过程链接表(PLT,Procedure Linkage Table)中，这样可以减小 PLT 的体积并将仅供内部使用的函数隐藏起来。而使用该选项将把这些函数暴露给外部用户。 –enable-bind-now禁用”lazy binding”，也就是动态连接器在载入 DSO 时就解析所有符号(不管应用程序是否用得到)，默认行为是”lazy binding”，也就是仅在应用程序首次使用到的时候才对符号进行解析。因为在大多数情况下，应用程序并不需要使用动态库中的所有符号，所以默认的 “lazy binding”可以提高应用程序的加载性能并节约内存用量。然而，在两种情况下，”lazy binding”是不利的：①因为第一次调用DSO中的函数时，动态连接器要先拦截该调用来解析符号，所以初次引用DSO中的函数所花的时间比再次调用要花的时间长，但是某些应用程序不能容忍这种不可预知性。②如果一个错误发生并且动态连接器不能解析该符号，动态连接器将终止整个程序。在”lazy binding”方式下，这种情况可能发生在程序运行过程中的某个时候。某些应用程序也是不能容忍这种不可预知性的。通过关掉”lazy binding”方式，在应用程序接受控制权之前，让动态连接器在处理进程初始化期间就发现这些错误，而不要到运行时才出乱子。 –enable-static-nss编译静态版本的NSS(Name Service Switch)库。仅在/etc/nsswitch.conf中只使用dns和files的情况下，NSS才能编译成静态库，并且你还需要在静态编译应用程序的时候明确的连接所有与NSS库相关的库才行[比如：gcc -static test.c -o test -Wl,-lc,-lnss_files,-lnss_dns,-lresolv]。不推荐使用此选项，因为连接到静态NSS库的程序不能动态配置以使用不同的名字数据库。 –disable-force-install不强制安装当前新编译的版本(即使已存在的文件版本更新)。 –enable-kernel=VERSIONVERSION 的格式是 X.Y.Z，表示编译出来的 Glibc 支持的最低内核版本。VERSION 的值越高(不能超过内核头文件的版本)，加入的兼容性代码就越少，库的运行速度就越快。 –enable-all-warnings在编译时显示所有编译器警告，也就是使用 -Wall 选项编译。 –with-gd–with-gd-include –with-gd-lib指定libgd的安装目录(DIR/include和DIR/lib)。后两个选项分别指定包含文件和库目录。 –without-fp仅在硬件没有浮点运算单元并且操作系统没有模拟的情况下使用。x86 与 x86_64 的 CPU 都有专门的浮点运算单元。而且 Linux 有 FPU 模拟。简单的说，不要 without 这个选项！因为它会导致许多问题！ –with-binutils=DIR明确指定编译时使用的Binutils(as,ld)所在目录。 –with-elf指定使用 ELF 对象格式，默认不使用。建议在支持 ELF 的 Linux 平台上明确指定此选项。 –with-selinux–without-selinux启用/禁用 SELinux 支持，默认值自动检测。 –with-xcoff使用XCOFF对象格式(主要用于windows)。 –without-cvs不访问CVS服务器。推荐使用该选项，特别对于从CVS下载的的版本。 –with-headers=DIR指定内核头文件的所在目录，在Linux平台上默认是’/usr/include’。 –without-tls禁止编译支持线程本地存储(TLS)的库。使用这个选项将导致兼容性问题。 –without-__thread即使平台支持也不使用TSL特性。建议不要使用该选项。 –with-cpu=CPU在 gcc 命令行中加入”-mcpu=CPU”。鉴于”-mcpu”已经被反对使用，所以建议不要设置该选项，或者设为 –without-cpu 。 编译与测试使用 make 命令编译，使用 make check 测试。如果 make check 没有完全成功，就千万不要使用这个编译结果。需要注意的是有些测试项目假定是以非 root 身份执行的，因此我们强烈建议你使用非 root 身份编译和测试。 测试中需要使用一些已经存在的文件(包括随后的安装过程)，比如 /etc/passwd, /etc/nsswitch.conf 之类。请确保这些文件中包含正确的内容。 安装与配置使用 make install 命令安装。比如：make install LC_ALL=C 如果你打算将此 Glibc 安装为主 C 库，那么我们强烈建议你关闭系统，重新引导到单用户模式下安装。这样可以将可能的损害减小到最低。 安装后需要配置 GCC 以使其使用新安装的 C 库。最简单的办法是使用恰当 GCC 的编译选项(比如 -Wl,–dynamic-linker=/lib/ld-linux.so.2 )重新编译 GCC 。然后还需要修改 specs 文件(通常位于 /usr/lib/gcc-lib/TARGET/VERSION/specs )，这个工作有点像巫术，调整实例请参考 LFS 中的两次工具链调整。 可以在 make install 命令行使用’install_root’变量指定安装实际的安装目录(不同于 –prefix 指定的值)。这个在 chroot 环境下或者制作二进制包的时候通常很有用。’install_root’必须使用绝对路径。 被’grantpt’函数调用的辅助程序’/usr/libexec/pt_chown’以 setuid ‘root’ 安装。这个可能成为安全隐患。如果你的 Linux 内核支持’devptsfs’或’devfs’文件系统提供的 pty slave ，那么就不需要使用 pt_chown 程序。 安装完毕之后你还需要配置时区和 locale 。使用 localedef 来配置locale 。比如使用’localedef -i de_DE -f ISO-8859-1 de_DE’将 locale 设置为’de_DE.ISO-8859-1’。可以在编译目录中使用’make localedata/install-locales’命令配置所有可用的 locale ，但是一般不需要这么做。 时区使用’TZ’环境变量设置。tzselect 脚本可以帮助你选择正确的值。设置系统全局范围内的时区可以将 /etc/localtime 文件连接到 /usr/share/zoneinfo 目录下的正确文件上。比如对于中国人可以’ln -s /usr/share/zoneinfo/PRC /etc/localtime’。 Binutils 安装指南(2.18 → 2.19.1)安装信息的来源源码包内的下列文件：各级目录下的configure脚本 README {bfd,binutils,gas,gold,libiberty}/README要点提示如果想与GCC联合编译，那么可以将binutils包的内容解压到GCC的源码目录中(tar -xvf binutils-2.19.1.tar.bz2 –strip-components=1 -C gcc-4.3.3)，然后按照正常编译GCC的方法编译即可。这样做的好处之一是可以完整的将 GCC 与 Binutils 进行一次bootstrap。 推荐用一个新建的目录来编译，而不是在源码目录中。编译完毕后可以使用”make check”运行测试套件。这个测试套件依赖于DejaGnu软件包，而DejaGnu又依赖于expect，expect依赖于tcl。 如果只想编译 ld 可以使用”make all-ld”，如果只想编译 as 可以使用”make all-gas”。类似的还有 clean-ld clean-as distclean-ld distclean-as check-ld check-as 等。 配置选项下列选项皆为非默认值[特别说明的除外] –help–version–quiet–config-cache–no-create–srcdir=DIR–prefix=PREFIX–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–datadir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–infodir=DIR–mandir=DIR–program-prefix=PREFIX–program-suffix=SUFFIX–program-transform-name=PROGRAM–build=BUILD–host=HOST–target=TARGET这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。 –disable-nls禁用本地语言支持(它允许按照非英语的本地语言显示警告和错误消息)。编译时出现”undefined reference to ‘libintl_gettext’”错误则必须禁用。 –disable-rpath不在二进制文件中硬编码库文件的路径。 –disable-multilib禁止编译适用于多重目标体系的库。例如，在x86_64平台上，默认既可以生成64位代码，也可以生成32位代码，若使用此选项，那么将只能生成64位代码。 –enable-cgen-maint=CGENDIR编译cgen相关的文件[主要用于GDB调试]。 –enable-shared[=PKG[,…]]–disable-shared–enable-static[=PKG[,…]]–disable-static允许/禁止编译共享或静态版本的库和可执行程序，全部可识别的PKG如下：binutils,gas,gprof,ld,bfd,opcodes,libiberty(仅支持作为静态库)。static在所有目录下的默认值都是”yes”；而shared在不同子目录下默认值不同，有些为”yes”(binutils,gas,gprof,ld)有些为”no”(bfd,opcodes,libiberty)。 –enable-install-libbfd–disable-install-libbfd允许或禁止安装 libbfd 以及相关的头文件( libbfd 是二进制文件描述库,用于读写目标文件”.o”,被GDB/ld/as等程序使用)。本地编译或指定–enable-shared的情况下默认值为”yes”，否则默认值为”no”。 –enable-64-bit-bfd让BFD支持64位目标，如果希望在32位平台上编译64程序就需要使用这个选项。如果指定的目标(TARGET)是64位则此选项默认打开，否则默认关闭(即使 –enable-targets=all 也是如此)。 –enable-elf-stt-common允许BFD生成STT_COMMON类型的ELF符号。[2.19版本新增选项] –enable-checking–disable-checking允许 as 执行运行时检查。正式发布版本默认禁用，快照版本默认启用。 –disable-werror禁止将所有编译器警告当作错误看待(因为当编译器为GCC时默认使用-Werror)。 –enable-got=target|single|negative|multigot指定GOT的处理模式。默认值是”target”。[2.19版本新增选项] –enable-gold使用gold代替GNU ld。gold是Google开发的连接器，2008年捐赠给FSF，目的是取代现有的GNU ld，但目前两者还不能完兼容。[2.19版本新增选项] –enable-plugins启用gold连接器的插件支持。[2.19版本新增选项] –enable-threads编译多线程版本的gold连接器。[2.19版本新增选项] –with-lib-path=dir1:dir2…指定编译出来的binutils工具(比如：ld)将来默认的库搜索路径，在绝大多数时候其默认值是”/lib:/usr/lib”。这个工作也可以通过设置 Makefile 中的 LIB_PATH 变量值完成。 –with-libiconv-prefix[=DIR]–without-libiconv-prefix在 DIR/include 目录中搜索 libiconv 头文件，在 DIR/lib 目录中搜索 libiconv 库文件。或者根本不使用 libiconv 库。 –with-libintl-prefix[=DIR]–without-libintl-prefix在 DIR/include 目录中搜索 libintl 头文件，在 DIR/lib 目录中搜索 libintl 库文件。或者根本不使用 libintl 库。 –with-mmap使用mmap访问BFD输入文件。某些平台上速度较快，某些平台上速度较慢，某些平台上无法正常工作。 –with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。以下选项仅在与GCC联合编译时才有意义，其含义与GCC相应选项的含义完全一样，默认值也相同。 –enable-bootstrap–disable-bootstrap–enable-languages=lang1,lang2,…–enable-stage1-checking–enable-stage1-languages–disable-libada–disable-libgcj–disable-libgomp–disable-libmudflap–disable-libssp–enable-objc-gc–disable-cloog-version-check–disable-ppl-version-check–with-gnu-as–with-gnu-ld–with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR–with-mpfr=MPFRDIR–with-mpfr-include=MPFRINCDIR–with-mpfr-lib=MPFRLIBDIR–with-cloog=CLOOGDIR–with-cloog_include=CLOOGINCDIR–with-cloog_lib=CLOOGLIBDIR–with-ppl=PPLDIR–with-ppl_include=PPLINCDIR–with-ppl_lib=PPLLIBDIR–with-stabs以下选项仅用于交叉编译环境 –enable-serial-[{host,target,build}-]configure强制为 host, target, build 顺序配置子包，如果使用”all”则表示所有子包。 –with-sysroot=dir将 dir 看作目标系统的根目录。目标系统的头文件、库文件、运行时对象都将被限定在其中。 –with-target-subdir=SUBDIR为 target 在 SUBDIR 子目录中进行配置。 –with-newlib将’newlib’(另一种标准C库，主要用于嵌入式环境)指定为目标系统的C库进行使用。 –with-build-sysroot=sysroot在编译时将’sysroot’当作指定 build 平台的根目录看待。仅在已经使用了–with-sysroot选项的时候，该选项才有意义。 –with-build-subdir=SUBDIR为 build 在 SUBDIR 子目录中进行配置。 –with-build-libsubdir=DIR指定 build 平台的库文件目录。默认值是SUBDIR。 –with-build-time-tools=path在给定的path中寻找用于编译Binutils自身的目标工具。该目录中必须包含 ar, as, ld, nm, ranlib, strip 程序，有时还需要包含 objdump 程序。例如，当编译Binutils的系统的文件布局和将来部署Binutils的目标系统不一致时就需要使用此选项。 –with-cross-host=HOST这个选项已经被反对使用，应该使用–with-sysroot来代替其功能。以下选项意义不大，一般不用考虑它们 –disable-dependency-tracking禁止对Makefile规则的依赖性追踪。–disable-largefile禁止支持大文件。[2.19版本新增选项]–disable-libtool-lock禁止 libtool 锁定以加快编译速度(可能会导致并行编译的失败)–disable-build-warnings禁止显示编译时的编译器警告，也就是使用”-w”编译器选项进行编译。–disable-fast-install禁止为快速安装而进行优化。–enable-maintainer-mode启用无用的 make 规则和依赖性(它们有时会导致混淆)–enable-commonbfdlib–disable-commonbfdlib允许或禁止编译共享版本的 BFD/opcodes/libiberty 库。分析configure脚本后发现这个选项事实上没有任何实际效果。–enable-install-libiberty安装 libiberty 的头文件(libiberty.h)，许多程序都会用到这个库中的函数(getopt,strerror,strtol,strtoul)。这个选项经过实验，没有实际效果(相当于disable)。–enable-secureplt使得binutils默认创建只读的 plt 项。相当于将来调用 gcc 时默认使用 -msecure-plt 选项。仅对 powerpc-linux 平台有意义。–enable-targets=TARGET,TARGET,TARGET…使BFD在默认格式之外再支持多种其它平台的二进制文件格式，”all”表示所有已知平台。在32位系统上，即使使用”all”也只能支持所有32位目标，除非同时使用 –enable-64-bit-bfd 选项。由于目前 gas 并不能使用内置的默认平台之外的其它目标，因此这个选项没什么实际意义。此选项在所有目录下都没有默认值。但对于2.19版本，此选项在gold子目录下的默认值是”all”。–with-bugurl=URL–without-bugurl指定发送bug报告的URL/禁止发送bug报告。默认值是”http://www.sourceware.org/bugzilla/&quot;。–with-datarootdir=DATADIR将 DATADIR 用作数据根目录，默认值是[PREFIX/share]–with-docdir=DOCDIR–with-htmldir=HTMLDIR–with-pdfdir=PDFDIR指定各种文档的安装目录。DOCDIR默认值的默认值是DATADIR，HTMLDIR和PDFDIR的默认值是DOCDIR。–with-included-gettext使用软件包中自带的 GNU gettext 库。如果你已经使用了Glibc-2.0以上的版本，或者系统中已经安装了GNU gettext软件包，那么就没有必要使用这个选项。默认不使用。–with-pkgversion=PKG在 bfd 库中使用”PKG”代替默认的”GNU Binutils”作为版本字符串。比如你可以在其中嵌入编译时间或第多少次编译之类的信息。–with-separate-debug-dir=DIR在DIR中查找额外的全局debug信息，默认值：${libdir}/debug–with-debug-prefix-map=’A=B C=D …’在调试信息中建立 A-B,C-D, … 这样的映射关系。默认为空。[2.19版本新增选项]环境变量tooldir可执行文件的安装目录。其默认值是”$(exec_prefix)/$(target_alias)”。 GCC 安装指南(4.3 → 4.4)安装信息的来源源码包内的下列文件：各级目录下的configure脚本 ABOUT-NLS gcc/testsuite/README INSTALL/ libstdc++-v3/docs/html/manual/bk01pt01ch02.htmlhttp://gcc.gnu.org/faq.htmlhttp://gcc.gnu.org/install/http://gcc.gnu.org/onlinedocs/libstdc++/faq.htmlhttp://gcc.gnu.org/onlinedocs/libstdc++/manual/bk01pt01ch02.html 要点提示从GCC-4.3起，安装GCC将依赖于GMP-4.1以上版本和MPFR-2.3.2以上版本。如果将这两个软件包分别解压到GCC源码树的根目录下，并分别命名为”gmp”和”mpfr”，那么GCC的编译程序将自动将两者与GCC一起编译。建议尽可能使用最新的GMP和MPFR版本。 推荐用一个新建的目录来编译GCC，而不是在源码目录中，这一点玩过LFS的兄弟都很熟悉了。另外，如果先前在编译中出现了错误，推荐使用 make distclean 命令进行清理，然后重新运行 configure 脚本进行配置，再在另外一个空目录中进行编译。 如果想要安装C++编译器，那么 libstdc++ 将要求系统的C库必须至少带有 de_DE locale 支持，如果使用了 –enable-clocale=gnu 配置选项(很可能就是默认值)，那么还需要下列 locale ： locale 字符集de_DE ISO-8859-1de_DE@euro ISO-8859-15en_HK ISO-8859-1en_PH ISO-8859-1en_US ISO-8859-1en_US.ISO-8859-1 ISO-8859-1en_US.ISO-8859-15 ISO-8859-15en_US.UTF-8 UTF-8es_ES ISO-8859-1es_MX ISO-8859-1fr_FR ISO-8859-1fr_FR@euro ISO-8859-15is_IS UTF-8it_IT ISO-8859-1ja_JP.eucjp EUC-JPse_NO.UTF-8 UTF-8ta_IN UTF-8zh_TW BIG5 不过，这些locale并非严格必须，即使缺少上述 locale ，C++编译器也不会失效，只是libstdc++就不能提供”named locale”特性了，并且测试程序也会跳过与此相关的测试。 配置选项[注意]这里仅包含适用于 C/C++ 语言编译器、十进制数字扩展库(libdecnumber)、在多处理机上编写并行程序的应用编程接口GOMP库(libgomp)、大杂烩的libiberty库、执行运行时边界检查的库(libmudflap)、保护堆栈溢出的库(libssp)、标准C++库(libstdc++) 相关的选项。也就是相当于 gcc-core 与 gcc-g++ 两个子包的选项。并不包括仅仅适用于其他语言的选项。 每一个 –enable 选项都有一个对应的 –disable 选项，同样，每一个 –with 选项也都用一个对应的 –without 选项。每一对选项中必有一个是默认值(依赖平台的不同而不同)。下面所列选项若未特别说明皆为非默认值。 –help–version–quiet–config-cache–no-create–srcdir=DIR–prefix=PREFIX–exec-prefix=EPREFIX–bindir=DIR–sbindir=DIR–libexecdir=DIR–datadir=DIR–sysconfdir=DIR–sharedstatedir=DIR–localstatedir=DIR–libdir=DIR–includedir=DIR–oldincludedir=DIR–infodir=DIR–mandir=DIR–program-prefix=PREFIX–program-suffix=SUFFIX–program-transform-name=PROGRAM–build=BUILD–host=HOST–target=TARGET这些选项的含义基本上通用于所有软件包，这里就不特别讲解了。 –disable-nls禁用本地语言支持(它允许按照非英语的本地语言显示警告和错误消息)。编译时出现”undefined reference to ‘libintl_gettext’”错误则必须禁用。 –disable-rpath不在二进制文件中硬编码库文件的路径。 –enable-bootstrap–disable-bootstrap“bootstrap”的意思是用第一次编译生成的程序来第二次编译自己，然后又用第二次编译生成的程序来第三次编译自己，最后比较第二次和第三次编译的结果，以确保编译器能毫无差错的编译自身，这通常表明编译是正确的。非交叉编译的情况下enable是默认值；交叉编译的情况下，disable是默认值。提示：stage2出来的结果是”最终结果”。 –enable-checking[=LIST]该选项会在编译器内部生成一致性检查的代码，它并不改变编译器生成的二进制结果。这样导致编译时间增加，并且仅在使用GCC作为编译器的时候才有效，但是对输出结果没有影响。在”gcc”子目录下，对从CVS下载的版本默认值是”yes”(=assert,misc,tree,gc,rtlflag,runtime)，对于正式发布的版本则是”release”(=assert,runtime)，在”libgcc”子目录下，默认值始终是”no”。可以从 “assert,df,fold,gc,gcac,misc,rtlflag,rtl,runtime,tree,valgrind”中选择你想要检查的项目(逗号隔开的列表，”all”表示全部)，其中rtl,gcac,valgrind非常耗时。使用 –disable-checking 完全禁止这种检查会增加未能检测内部错误的风险，所以不建议这样做。 –enable-languages=lang1,lang2,…只安装指定语言的编译器及其运行时库，可以使用的语言是：ada, c, c++, fortran, java, objc, obj-c++ ，若不指定则安装所有默认可用的语言(ada和obj-c++为非默认语言)。 –disable-multilib禁止编译适用于多重目标体系的库。例如，在x86_64平台上，编译器默认既可以生成64位代码，也可以生成32位代码，若使用此选项，那么将只能生成64位代码。 –enable-shared[=PKG[,…]]–disable-shared–enable-static[=PKG[,…]]–disable-static允许/禁止编译共享或静态版本的库，全部可识别的库如下：libgcc,libstdc++,libffi,zlib,boehm-gc,ada,libada,libjava,libobjc,libiberty(仅支持作为静态库)。static在所有目录下的默认值都是”yes”；shared除了在libiberty目录下的默认值是”no”外，在其它目录下的默认值也都是”yes”。 –enable-decimal-float[=bid|dpd]–disable-decimal-float启用或禁用 libdecnumber 库符合 IEEE 754-2008 标准的 C 语言十进制浮点扩展，还可以进一步选择浮点格式(bid是i386与x86_64的默认值；dpd是PowerPC的默认值)。在 PowerPC/i386/x86_64 GNU/Linux 系统默认启用，在其他系统上默认禁用。 –disable-libgomp不编译在多处理机上编写并行程序的应用编程接口GOMP库(libgomp)。 –disable-libmudflap不编译执行运行时边界检查的库(libmudflap)。 –disable-libssp不编译保护缓冲区溢出的运行时库。 –disable-symvers禁用共享库对象中符号包含的版本信息。使用这个选项将导致 ABI 发生改变。禁用版本信息可以减小库的体积，但是将不兼容依赖于老版本库的二进制程序。它还会导致 libstdc++ 的 abi_check 测试失败，但你可以忽略这个失败。 –enable-threads=posix|aix|dce|gnat|mach|rtems|solaris|vxworks|win32|nks–disable-threads启用或禁用线程支持，若启用，则必须同时明确指定线程模型(不同平台支持的线程库并不相同，Linux现在一般使用posix)。这将对Objective-C编译器、运行时库，以及C++/Java等面向对象语言的异常处理产生影响。 –enable-version-specific-runtime-libs将运行时库安装在编译器特定的子目录中(${libdir}/gcc-lib/${target_alias}/${gcc_version})，而不是默认的${libdir}目录中。另外，’libstdc++’的头文件将被安装在 ${libdir}/gcc-lib/${target_alias}/${gcc_version}/include/g++ 目录中(除非同时又指定了 –with-gxx-include-dir)。如果你打算同时安装几个不同版本的 GCC ，这个选项就很有用处了。当前，libgfortran,libjava,libmudflap,libstdc++,libobjc都支持该选项。 –enable-werror–disable-werror是否将所有编译器警告当作错误看待(使用-Werror来编译)。对于开发中的版本和快照默认为”yes”，对于正式发布的版本则默认为”no”。 –with-as=pathname–with-ld=pathname指定将来GCC使用的汇编器/连接器的位置，必须使用绝对路径。如果configure的默认查找过程找不到汇编器/连接器，就会需要该选项。或者系统中有多个汇编器/连接器，也需要它来指定使用哪一个。如果使用GNU的汇编器，那么你必须同时使用GNU连接器。 –with-datarootdir=DATADIR将 DATADIR 用作数据根目录，默认值是[PREFIX/share] –with-docdir=DOCDIR–with-htmldir=HTMLDIR–with-pdfdir=PDFDIR指定各种文档的安装目录。DOCDIR默认值的默认值是DATADIR，HTMLDIR和PDFDIR的默认值是DOCDIR。 –with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR指定 GMP 库的安装目录/头文件目录/库目录。指定GMPDIR相当于同时指定了：GMPINCDIR=GMPDIR/include,GMPLIBDIR=GMPDIR/lib 。 –with-mpfr=MPFRDIR–with-mpfr-include=MPFRINCDIR–with-mpfr-lib=MPFRLIBDIR指定 MPFR 库的安装目录/头文件目录/库目录。指定MPFRDIR相当于同时指定了：MPFRINCDIR=MPFRDIR/include,MPFRLIBDIR=MPFRDIR/lib 。 –with-cloog=CLOOGDIR–with-cloog_include=CLOOGINCDIR–with-cloog_lib=CLOOGLIBDIR指定CLooG(Chunky Loop Generator)的安装目录/头文件目录/库目录。指定CLOOGDIR相当于同时指定了：CLOOGINCDIR=CLOOGDIR/include,CLOOGLIBDIR=CLOOGDIR/lib 。[GCC-4.4新增选项] –with-ppl=PPLDIR–with-ppl_include=PPLINCDIR–with-ppl_lib=PPLLIBDIR指定PPL(Parma Polyhedra Library)的安装目录/头文件目录/库目录。指定PPLDIR相当于同时指定了：PPLINCDIR=PPLDIR/include,PPLLIBDIR=PPLDIR/lib 。[GCC-4.4新增选项] –with-gxx-include-dir=DIRG++头文件的安装目录，默认为”prefix/include/c++/版本”。 –with-libiconv-prefix[=DIR]–without-libiconv-prefix在 DIR/include 目录中搜索 libiconv 头文件，在 DIR/lib 目录中搜索 libiconv 库文件。或者根本不使用 libiconv 库。 –with-libintl-prefix[=DIR]–without-libintl-prefix在 DIR/include 目录中搜索 libintl 头文件，在 DIR/lib 目录中搜索 libintl 库文件。或者根本不使用 libintl 库。 –with-local-prefix=DIR指定本地包含文件的安装目录，不管如何设置–prefix，其默认值都为 /usr/local 。只有在系统已经建立了某些特定的目录规则，而不再是在 /usr/local/include 中查找本地安装的头文件的时候，该选项才使必须的。不能指定为 /usr ，也不能指定为安装GCC自身头文件的目录(默认为$libdir/gcc/$target/$version/include)，因为安装的头文件会和系统的头文件混合，从而造成冲突，导致不能编译某些程序。 –with-long-double-128–without-long-double-128指定long double类型为 128-bit 或 64-bit(等于double) 。基于 Glibc 2.4 或以上版本编译时默认为 128-bit ，其他情况默认为 64-bit ；但是可以使用这个选项强制指定。 –with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。 –with-slibdir=DIR共享库(libgcc)的安装目录，默认等于 –libdir 的值。 –with-system-libunwind使用系统中已经安装的libunwind库，默认自动检测。 –with-system-zlib使用系统中的libz库，默认使用GCC自带的库。 以下选项仅适用于 C++ 语言： –enable-cxa_atexit用 cxa_atexit() 代替 atexit() 来登记 C++ 对象的本地静态和全局析构函数以符合C++标准对析构函数的处理规定。启用它相当于在将来调用 gcc 时默认使用 -fuse-cxa-exit 选项。该选项仅在使用Glibc的时候才有意义。 –disable-c99禁止支持 C99 标准。该选项将导致 ABI 接口发生改变。 –enable-cheaders=c|c_std|c_global为 g++ 创建C语言兼容的头文件，默认为”c_global”。 –enable-clocale[=gnu|ieee_1003.1-2001|generic]指定目标系统的 locale 模块，默认值为自动检测。建议明确设为”gnu”，否则可能会编译出 ABI 不兼容的 C++ 库。 –enable-clock-gettime[=yes|no|rt]指明如何获取C++0x草案里面time.clock中clock_gettime()函数：”yes”表示在libc和libposix4库中检查(而libposix4在需要的时候还可能会链接到libstdc++)。”rt”表示还额外在librt库中查找，这一般并不是一个很好的选择，因为librt经常还会连接到libpthread上，从而使得单线程的程序产生不必要的锁定开销。默认值”no”则完全跳过这个检查。[GCC-4.4新增选项] –enable-concept-checks打开额外的实例化库模板编译时检查(以特定的模板形式)，这可以帮助用户在他们的程序运行之前就发现这些程序在何处违反了STL规则。 –enable-cstdio=PACKAGE使用目标平台特定的 I/O 包，PACKAGE的默认值是”stdio”，也是唯一可用的值。使用这个选项将导致 ABI 接口发生改变。 –enable-cxx-flags=FLAGS编译 libstdc++ 库文件时传递给编译器的编译标志，是一个引号界定的字符串。默认为空，表示使用环境变量 CXXFLAGS 的值。 –enable-fully-dynamic-string该选项启用了一个特殊版本的 basic_string 来禁止在预处理的静态存储区域中放置空字符串的优化手段。参见 PR libstdc++/16612 获取更多细节。 –disable-hosted-libstdcxx默认编译特定于主机环境的C++库。使用该选项将仅编译独立于主机环境的C++运行时库(前者的子集)。 –enable-libstdcxx-allocator[=new|malloc|mt|bitmap|pool]指定目标平台特定的底层 std::allocator ，默认自动检测。使用这个选项将导致 ABI 接口发生改变。 –enable-libstdcxx-debug额外编译调试版本的 libstdc++ 库文件，并默认安装在 ${libdir}/debug 目录中。 –enable-libstdcxx-debug-flags=FLAGS编译调试版本的 libstdc++ 库文件时使用的编译器标志，默认为”-g3 -O0” –disable-libstdcxx-pch禁止创建预编译的 libstdc++ 头文件(stdc++.h.gch)，这个文件包含了所有标准 C++ 的头文件。该选项的默认值等于hosted-libstdcxx的值。 –disable-long-long禁止使用模板支持’long long’类型。’long long’是 C99 新引进的类型，也是 GNU 对 C++98 标准的一个扩展。该选项将导致 ABI 接口发生改变。 –enable-sjlj-exceptions强制使用旧式的 setjmp/longjmp 异常处理模型，使用这个选项将导致 ABI 接口发生改变。默认使用可以大幅降低二进制文件尺寸和内存占用的新式的 libunwind 库进行异常处理。建议不要使用此选项。 –disable-visibility禁止 -fvisibility 编译器选项的使用(使其失效)。 –disable-wchar_t禁止使用模板支持多字节字符类型’wchar_t’。该选项将导致 ABI 接口发生改变。 以下选项仅用于交叉编译： –enable-serial-[{host,target,build}-]configure强制为 host, target, build 顺序配置子包，如果使用”all”则表示所有子包。 –with-sysroot=DIR将DIR看作目标系统的根目录。目标系统的头文件、库文件、运行时对象都将被限定在其中。其默认值是 ${gcc_tooldir}/sys-root 。 –with-target-subdir=SUBDIR为 target 在 SUBDIR 子目录中进行配置。 –with-newlib将’newlib’指定为目标系统的C库进行使用。这将导致 libgcc.a 中的 __eprintf 被忽略，因为它被假定为由’newlib’提供。 –with-build-subdir=SUBDIR为 build 在 SUBDIR 子目录中进行配置。 –with-build-libsubdir=DIR指定 build 平台的库文件目录。默认值是SUBDIR。 –with-build-sysroot=sysroot在编译时将’sysroot’当作指定 build 平台的根目录看待。仅在已经使用了–with-sysroot选项的时候，该选项才有意义。 –with-build-time-tools=path在给定的path中寻找用于编译GCC自身的目标工具。该目录中必须包含 ar, as, ld, nm, ranlib, strip 程序，有时还需要包含 objdump 程序。例如，当编译GCC的系统的文件布局和将来部署GCC的目标系统不一致时就需要使用此选项。 –with-cross-host=HOST这个选项已经被反对使用，应该使用–with-sysroot来代替其功能。 以下选项意义不大，一般不用考虑它们：–enable-cld启用它相当于将来对32位x86平台调用GCC时默认使用-mcld命令行选项，主要用于兼容一些老旧的平台。–disable-cloog-version-check禁止检测CLooG(Chunky Loop Generator)的版本是否满足要求。[GCC-4.4新增选项]–enable-coverage[=opt|noopt]在编译器每次编译时收集自身的 coverage 信息。这个仅用于内部测试的目的，并且仅在使用GCC编译的时候才有效。参数控制着是否在编译编译器时使用优化，在需要进行 coverage 分析的时候使用”noopt”(默认)，在需要进行性能分析的时候使用”opt”。–disable-dependency-tracking禁止对Makefile规则的依赖性追踪。–disable-fast-install禁止为快速安装而进行优化。–enable-fixed-point启用C定点浮点运算(fixed-point arithmetic)，这是一种非常快速的模拟浮点运算的方法，特别是在具有相应硬件支持的处理器(比如MIPS)上。在MIPS平台上默认开启，在其他平台上则默认关闭。–enable-gold仅在与Binutils联合编译时才有意义。使用gold代替GNU ld。gold是Google开发的连接器，2008年捐赠给FSF，目的是取代现有的GNU ld，但目前两者还不能完兼容。[GCC-4.4新增选项]–enable-gather-detailed-mem-stats允许收集详细的内存使用信息，将来在调用 gcc 时如果使用了 -fmem-report 选项就可以打印这些信息。–enable-generated-files-in-srcdir将生成的文件的副本保存在源代码目录中，以便于没有 texinfo, perl, bison, flex 的用户创建源代码的归档(比如创建正式发布的tarball)。–enable-initfini-array为构造函数和析构函数使用 .init_array 和 .fini_array (而不是 .init 和 .fini) 节。该选项的默认值由configure脚本自动检测决定。–enable-intermodule仅用一步来编译 compiler ，以达到内部模块最佳化。(什么意思?)–enable-install-libiberty安装 libiberty 的头文件(libiberty.h)，许多程序都会用到这个库中的函数(getopt,strerror,strtol,strtoul)。这个选项经过实验，没有实际效果(相当于disable)。–disable-largefile禁止支持大文件。[GCC-4.4新增选项]–disable-libada禁止编译GNAT的运行时库(libada，ADA编译器的运行时库)和相应的工具。–disable-libgcj禁止编译GCJ的运行时库(libgcj，Java编译器的运行时库)。–disable-libtool-lock禁止 libtool 锁定以加快编译速度(可能会导致并行编译的失败)–enable-linux-futex在libgomp和libstdc++库中使用Linux的futex系统调用(快速用户空间互斥体)。默认值根据内核头文件sys/syscall.h中是否包含futex函数的定义而定。–enable-maintainer-mode启用无用的 make 规则和依赖性(它们有时会导致混淆)。–enable-objc-gc允许在 Objective-C 运行时库中使用 Boehm 垃圾回收器。当前并不支持Boehm，所以该选项没有实际意义。–disable-ppl-version-check禁止检测PPL(Parma Polyhedra Library)的版本是否满足要求。[GCC-4.4新增选项]–enable-secureplt使编译器默认创建只读的 plt 项，相当于将来调用 gcc 时默认使用 -msecure-plt 选项。仅对 powerpc-linux 平台有意义。–enable-stage1-checking对处于 stage1 状态的编译器执行额外的检查。默认值等于–enable-checking选项的值。–enable-stage1-languages在bootstrap时，在 stage1 时使用系统原有的C编译器编译更多的语言支持，而不是使用stage1编译出来的C编译器来编译他们。该选项一般仅供编译器开发者使用。无默认值，可用的取值为：no, yes, all, ada, c, c++, fortran, java, objc, obj-c++ 。–enable-tls–disable-tls允许或禁止目标系统支持TLS(线程本地存储)，”gcc”子目录下没有默认值，”libgcc libgomp libmudflap libstdc++-v3”子目录下默认为”yes”。一般情况下不需要明确指定，因为 configure 脚本可以自动检测。仅在你认为检测不正确的情况下(比如汇编器支持 TLS 但 C 却不支持或汇编器检测错误)才使用这个选项明确指定。–enable-twoprocessChoose two-process fix methodology(啥意思?)。对于那些不支持双向pipe的系统，必须使用two-process方法。在 mingw32,beos 平台上默认为”yes”，其它平台上默认为”no”。–enable-werror-always不管编译器是否支持，总是使用-Werror来编译，也就是将所有编译器警告当作错误看待。–enable-win32-registry=KEY仅对Windows平台有意义。而且即使在Windows平台上也可以忽略该选项。–with-gnu-as–with-gnu-ld指定编译器将来使用的是GNU汇编器/连接器，默认值为未指定。如果你实际使用的不是GNU汇编器/连接器，指定这个选项会引起混淆；另一方面如果你实际使用的是GNU汇编器/连接器，但是却没有指定这个选项，也有可能会造成混淆。此选项仅在 hppa, sparc, sparc64 平台上才有意义。–with-bugurl=URL提示用户发送bug报告的URL。默认值是”http://gcc.gnu.org/bugs.html&quot;。–with-cpp-install-dir=DIR除了将用户可见的 cpp 程序安装到默认的 PREFIX/bin 目录外，还将安装到 prefix/DIR 目录。–with-debug-prefix-map=’A=B C=D …’在调试信息中将A映射B,C映射到D…–with-demangler-in-ld尝试在 GNU ld 中使用 demangler–with-dwarf2指定编译程序产生的调试信息默认为DWARF2格式。–with-gc=[page|zone]指定编译过程中使用的垃圾回收方案(默认为”page”)。–with-included-gettext使用软件包中自带的 GNU gettext 库。如果你已经使用了Glibc-2.0以上的版本，或者系统中已经安装了GNU gettext软件包，那么就没有必要使用这个选项。默认不使用。–with-pkgversion=PKG使用”PKG”代替默认的”GCC”作为版本字符串，这个信息将会在”gcc –version”命令下显示。比如你可以在其中嵌入编译时间或第多少次编译之类的信息。–with-stabs指定将来编译器产生的调试信息默认为stabs格式，而不是宿主系统的默认格式。通常GCC产生的默认调试信息是ECOFF格式，但是它包含的调试信息没有stabs多。编译、测试、安装除了使用 CFLAGS,LDFLAGS 之外，还可以使用 LIBCFLAGS,LIBCXXFLAGS 控制库文件(由stage3编译)的编译器选项。可以在 make 命令行上使用 BOOT_CFLAGS,BOOT_LDFLAGS 来控制 stage2,stage3 的编译。可以使用 make bootstrap4 来增加步骤以避免 stage1 可能被错误编译所导致的错误。可以使用 make profiledbootstrap 在编译stage1时收集一些有用的统计信息，然后使用这些信息编译最终的二进制文件，这样可以提升编译器和相应库文件的执行效率。 编译完毕后可以使用”make check”运行测试套件，然后可以和http://gcc.gnu.org/buildstat.html里面列出来的结果进行对比，只要&quot;unexpected failures”不要太多就好说。这个测试套件依赖于DejaGnu软件包，而DejaGnu又依赖于expect，expect依赖于tcl。如果只想运行C++测试，可以使用”make check-g++”命令；如果只想运行C编译器测试，可以使用”make check-gcc”。还可以制定只运行某些单项测试：比如使用 make check RUNTESTFLAGS=”compile.exp -v” 运行编译测试。另一方面，GCC并不支持使用”make uninstall”进行卸载，建议你将GCC安装在一个特别的目录中，然后在不需要的时候直接删除这个目录。 因为GCC的安装依赖于GMP和MPFR，所以下面附上GMP和MPFR的安装信息，主要是configure选项。 GMP-4.2.4下面所列选项若未特别说明皆为非默认值。并且仅选择有实际意义的选项介绍： –enable-assert启用断言检查，主要用于调试目的。–enable-alloca=alloca|malloc-reentrant|malloc-notreentrant分配临时工作区内存的方法：alloca - 使用libc或编译器内置的方法malloc-reentrant - 在堆上使用可重入的(re-entrant)方法分配malloc-notreentrant - 在堆上使用全局变量的方法分配默认值是优先使用alloca，不可用时使用malloc-reentrant。–enable-cxx启用C++支持(必须同时拥有C++编译器支持)。也就是将要安装libgmpxx.la库和gmpxx.h头文件。–enable-fat在运行时根据CPU型号选择相应的底层子程序。这将使得代码变得臃肿但可以获得更好的性能。–disable-fft默认情况下，GMP使用 Karatsuba, 3-way Toom, Fermat FFT 三种算法进行乘法运算。而 Fermat FFT 算法仅用于操作数非常巨大的场合，所以，如果你预计到并不需要操作非常巨大的数字，那么可以禁用这个算法，这样可以减小一些二进制文件的体积。–enable-mpbsd编译与Berkeley MP接口兼容的库文件(libmp.{so,a})和头文件(mp.h)–enable-nails=偶数在limbs中使用nail(?何意?)–enable-profile启用 profiling 信息相关的库文件编译。主要用于调试目的。–disable-shared–disable-static禁止编译共享或静态版本的库。–with-readline在calc演示程序中使用readline库，默认值自动检测。–with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。MPFR-2.3.2此包依赖于GMP，并且总是在http://www.mpfr.org/mpfr-current/patches存放最新版本的patch，可以使用 patch -N -Z -p1 &lt; patches命令打补丁。下面所列选项若未特别说明皆为非默认值。并且仅选择有实际意义的选项介绍： –enable-assert启用断言检查，主要用于调试目的。–enable-decimal-float编译与十进制浮点数之间的转换函数(要求GCC&gt;=4.2)–enable-logging启用MPFR日志(必须要有底层操作系统的支持)–disable-shared–disable-static禁止编译共享或静态版本的库。–enable-tests-timeout=NUM设定测试程序的超时秒数(NUM&lt;=9999)，默认没有超时限制。–enable-thread-safe编译线程安全的MPFR库–enable-warnings允许MPFR将错误输出到stderr–with-gmp=GMPDIR–with-gmp-include=GMPINCDIR–with-gmp-lib=GMPLIBDIR指定 GMP 库的安装目录/头文件目录/库目录。指定GMPDIR相当于同时指定了：GMPINCDIR=GMPDIR/include,GMPLIBDIR=GMPDIR/lib 。–with-mulhigh_size=NUMmulhigh的内置阈值表大小，没有默认值。–with-pic–without-pic试图仅使用 PIC 或 non-PIC 对象，默认两者都使用。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[管理处理器的亲和性（affinity）]]></title>
    <url>%2F2019%2F04%2F09%2F%E7%AE%A1%E7%90%86%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84%E4%BA%B2%E5%92%8C%E6%80%A7affinity%2F</url>
    <content type="text"><![CDATA[简单地说，CPU 亲和性（affinity） 就是进程要在某个给定的 CPU 上尽量长时间地运行而不被迁移到其他处理器的倾向性。Linux 内核进程调度器天生就具有被称为 软 CPU 亲和性（affinity） 的特性，这意味着进程通常不会在处理器之间频繁迁移。这种状态正是我们希望的，因为进程迁移的频率小就意味着产生的负载小。 2.6 版本的 Linux 内核还包含了一种机制，它让开发人员可以编程实现 硬 CPU 亲和性（affinity）。这意味着应用程序可以显式地指定进程在哪个（或哪些）处理器上运行。 什么是 Linux 内核硬亲和性（affinity）？在 Linux 内核中，所有的进程都有一个相关的数据结构，称为 task_struct。这个结构非常重要，原因有很多；其中与 亲和性（affinity）相关度最高的是 cpus_allowed 位掩码。这个位掩码由 n 位组成，与系统中的 n 个逻辑处理器一一对应。 具有 4 个物理 CPU 的系统可以有 4 位。如果这些 CPU 都启用了超线程，那么这个系统就有一个 8 位的位掩码。 如果为给定的进程设置了给定的位，那么这个进程就可以在相关的 CPU 上运行。因此，如果一个进程可以在任何 CPU 上运行，并且能够根据需要在处理器之间进行迁移，那么位掩码就全是 1。实际上，这就是 Linux 中进程的缺省状态。 Linux 内核 API 提供了一些方法，让用户可以修改位掩码或查看当前的位掩码： sched_set_affinity() （用来修改位掩码）sched_get_affinity() （用来查看当前的位掩码）注意，cpu_affinity 会被传递给子线程，因此应该适当地调用 sched_set_affinity。 #为什么应该使用硬亲和性（affinity）？通常 Linux 内核都可以很好地对进程进行调度，在应该运行的地方运行进程（这就是说，在可用的处理器上运行并获得很好的整体性能）。内核包含了一些用来检测 CPU 之间任务负载迁移的算法，可以启用进程迁移来降低繁忙的处理器的压力。 一般情况下，在应用程序中只需使用缺省的调度器行为。然而，您可能会希望修改这些缺省行为以实现性能的优化。让我们来看一下使用硬亲和性（affinity） 的 3 个原因。 原因 1. 有大量计算要做基于大量计算的情形通常出现在科学和理论计算中，但是通用领域的计算也可能出现这种情况。一个常见的标志是您发现自己的应用程序要在多处理器的机器上花费大量的计算时间。 原因 2. 您在测试复杂的应用程序测试复杂软件是我们对内核的亲和性（affinity）技术感兴趣的另外一个原因。考虑一个需要进行线性可伸缩性测试的应用程序。有些产品声明可以在 使用更多硬件 时执行得更好。 我们不用购买多台机器（为每种处理器配置都购买一台机器），而是可以： 购买一台多处理器的机器不断增加分配的处理器测量每秒的事务数评估结果的可伸缩性如果应用程序随着 CPU 的增加可以线性地伸缩，那么每秒事务数和 CPU 个数之间应该会是线性的关系（例如斜线图 —— 请参阅下一节的内容）。这样建模可以确定应用程序是否可以有效地使用底层硬件。 Amdahl 法则Amdahl 法则是有关使用并行处理器来解决问题相对于只使用一个串行处理器来解决问题的加速比的法则。加速比（Speedup） 等于串行执行（只使用一个处理器）的时间除以程序并行执行（使用多个处理器）的时间： 其中 T(j) 是在使用 j 个处理器执行程序时所花费的时间。 Amdahl 法则说明这种加速比在现实中可能并不会发生，但是可以非常接近于该值。对于通常情况来说，我们可以推论出每个程序都有一些串行的组件。随着问题集不断变大，串行组件最终会在优化解决方案时间方面达到一个上限。 Amdahl 法则在希望保持高 CPU 缓存命中率时尤其重要。如果一个给定的进程迁移到其他地方去了，那么它就失去了利用 CPU 缓存的优势。实际上，如果正在使用的 CPU 需要为自己缓存一些特殊的数据，那么所有其他 CPU 都会使这些数据在自己的缓存中失效。 因此，如果有多个线程都需要相同的数据，那么将这些线程绑定到一个特定的 CPU 上是非常有意义的，这样就确保它们可以访问相同的缓存数据（或者至少可以提高缓存的命中率）。否则，这些线程可能会在不同的 CPU 上执行，这样会频繁地使其他缓存项失效。 原因 3. 您正在运行时间敏感的、决定性的进程我们对 CPU 亲和性（affinity）感兴趣的最后一个原因是实时（对时间敏感的）进程。例如，您可能会希望使用硬亲和性（affinity）来指定一个 8 路主机上的某个处理器，而同时允许其他 7 个处理器处理所有普通的系统调度。这种做法确保长时间运行、对时间敏感的应用程序可以得到运行，同时可以允许其他应用程序独占其余的计算资源。 下面的样例应用程序显示了这是如何工作的。 如何利用硬亲和性（affinity）现在让我们来设计一个程序，它可以让 Linux 系统非常繁忙。可以使用前面介绍的系统调用和另外一些用来说明系统中有多少处理器的 API 来构建这个应用程序。实际上，我们的目标是编写这样一个程序：它可以让系统中的每个处理器都繁忙几秒钟。 清单 1. 让处理器繁忙123456789101112131415161718192021/* This method will create threads, then bind each to its own cpu. */bool do_cpu_stress(int numthreads)&#123; int ret = TRUE; int created_thread = 0; /* We need a thread for each cpu we have... */ while ( created_thread &lt; numthreads - 1 ) &#123; int mypid = fork(); if (mypid == 0) /* Child process */ &#123; printf(&quot;\tCreating Child Thread: #%i\n&quot;, created_thread); break; &#125; else /* Only parent executes this */ &#123; /* Continue looping until we spawned enough threads! */ ; created_thread++; &#125; &#125; /* NOTE: All threads execute code from here down! */ 正如您可以看到的一样，这段代码只是通过 fork 调用简单地创建一组线程。每个线程都执行这个方法中后面的代码。现在我们让每个线程都将亲和性（affinity）设置为自己的 CPU。 清单 2. 为每个线程设置 CPU 亲和性（affinity）12345678910cpu_set_t mask;/* CPU_ZERO initializes all the bits in the mask to zero. */ CPU_ZERO( &amp;mask );/* CPU_SET sets only the bit corresponding to cpu. */ CPU_SET( created_thread, &amp;mask );/* sched_setaffinity returns 0 in success */ if( sched_setaffinity( 0, sizeof(mask), &amp;mask ) == -1 )&#123; printf(&quot;WARNING: Could not set CPU Affinity, continuing...\n&quot;);&#125; 如果程序可以执行到这儿，那么我们的线程就已经设置了自己的亲和性（affinity）。调用 sched_setaffinity 会设置由 pid 所引用的进程的 CPU 亲和性（affinity）掩码。如果 pid 为 0，那么就使用当前进程。 亲和性（affinity）掩码是使用在 mask 中存储的位掩码来表示的。最低位对应于系统中的第一个逻辑处理器，而最高位则对应于系统中最后一个逻辑处理器。 每个设置的位都对应一个可以合法调度的 CPU，而未设置的位则对应一个不可调度的 CPU。换而言之，进程都被绑定了，只能在那些对应位被设置了的处理器上运行。通常，掩码中的所有位都被置位了。这些线程的亲和性（affinity）都会传递给从它们派生的子进程中。 注意不应该直接修改位掩码。应该使用下面的宏。虽然在我们的例子中并没有全部使用这些宏，但是在本文中还是详细列出了这些宏，您在自己的程序中可能需要这些宏。 清单 3. 间接修改位掩码的宏12345678void CPU_ZERO (cpu_set_t *set)这个宏对 CPU 集 set 进行初始化，将其设置为空集。void CPU_SET (int cpu, cpu_set_t *set)这个宏将 cpu 加入 CPU 集 set 中。void CPU_CLR (int cpu, cpu_set_t *set)这个宏将 cpu 从 CPU 集 set 中删除。int CPU_ISSET (int cpu, const cpu_set_t *set)如果 cpu 是 CPU 集 set 的一员，这个宏就返回一个非零值（true），否则就返回零（false）。 对于本文来说，样例代码会继续让每个线程都执行某些计算量较大的操作。 清单 4. 每个线程都执行一个计算敏感的操作123456789101112131415161718/* Now we have a single thread bound to each cpu on the system */ int computation_res = do_cpu_expensive_op(41); cpu_set_t mycpuid; sched_getaffinity(0, sizeof(mycpuid), &amp;mycpuid); if ( check_cpu_expensive_op(computation_res) ) &#123; printf(&quot;SUCCESS: Thread completed, and PASSED integrity check!\n&quot;, mycpuid); ret = TRUE; &#125; else &#123; printf(&quot;FAILURE: Thread failed integrity check!\n&quot;, mycpuid); ret = FALSE; &#125; return ret;&#125; 我们使用一个 main 程序来封装这些方法，它使用一个用户指定的参数来说明要让多少个 CPU 繁忙。我们可以使用另外一个方法来确定系统中有多少个处理器： int NUM_PROCS = sysconf(_SC_NPROCESSORS_CONF); 这个方法让程序能够自己确定要让多少个处理器保持繁忙，例如缺省让所有的处理器都处于繁忙状态，并允许用户指定系统中实际处理器范围的一个子集。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux命令速查表]]></title>
    <url>%2F2019%2F04%2F09%2FLinux%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[文件和目录cd命令（它用于切换当前目录，它的参数是要切换到的目录的路径，可以是绝对路径，也可以是相对路径）cd /home 进入 ‘/ home’ 目录cd .. 返回上一级目录cd ../.. 返回上两级目录cd 进入个人的主目录cd ~user1 进入个人的主目录cd - 返回上次所在的目录 pwd命令pwd 显示工作路径 ls命令（查看文件与目录的命令，list之意）ls 查看目录中的文件ls -l 显示文件和目录的详细资料ls -a 列出全部文件，包含隐藏文件ls -R 连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来ls [0-9] 显示包含数字的文件名和目录名ls -al 长格式显示当前目录下所有文件ls -h 文件大小显示为常见大小单位 B KB MB …ls -d 显示目录本身，而不是里面的子文件 长格式显示项 -rw——- 1 root root 1190 08-10 23:37 anaconda-ks.cfg ① ② ③ ④ ⑤ ⑥ ⑦ 第①项：权限位第②项：引用计数第③项：属主（所有者）第④项：属组第⑤项：大小第⑥项：最后一次修改时间第⑦项：文件名 cp 命令（用于复制文件，copy之意，它还可以把多个文件一次性地复制到一个目录下）-a ：将文件的特性一起复制-p ：连同文件的属性一起复制，而非使用默认方式，与-a相似，常用于备份-i ：若目标文件已经存在时，在覆盖时会先询问操作的进行-r ：递归持续复制，用于目录的复制行为-u ：目标文件与源文件有差异时才会复制 mv命令（用于移动文件、目录或更名，move之意）-f ：force强制的意思，如果目标文件已经存在，不会询问而直接覆盖-i ：若目标文件已经存在，就会询问是否覆盖-u ：若目标文件已经存在，且比目标文件新，才会更新 rm 命令（用于删除文件或目录，remove之意）-f ：就是force的意思，忽略不存在的文件，不会出现警告消息-i ：互动模式，在删除前会询问用户是否操作-r ：递归删除，最常用于目录删除，它是一个非常危险的参数 mkdir命令名称：mkdir命令英文原意：make directories命令所在路径：/bin/mkdir执行权限：所有用户功能描述：建立目录mkdir test 创建名为test的目录mkdir -p test1/test2/test3 递归创建 rmdir命令名称：rmdir命令英文原意：remove empty directories命令所在路径：/bin/rmdir执行权限：所有用户功能描述：删除目录 (只能删除空目录) 查看文件内容touch命令名称：touch命令所在路径：/bin/touch权限：所有用户能描述：创建空文件 或 修改文件时间touch test.py 创建空文件，如果文件存在，则修改文件创建时间 more命令所在路径：/bin/more执行权限：所有用户功能描述：分屏显示文件内容more 文件名 分屏显示文件内容向上翻页 空格键向下翻页 b键退出查看 q键 head命令所在路径：/usr/bin/head执行权限：所有用户功能描述：显示文件头head 文件名 显示文件头几行(默认显示10行)head -n 20 文件名 显示文件前20行head -n -20 文件名 显示文件最后20行ctrl + c 强制终止查看模式ctrl + l 清屏 ln命令所在路径：/bin/ln执行权限：所有用户功能描述：链接文件等同于Windows中的快捷方式新建的链接，占用不同的硬盘位置修改一个文件，两边都会改变删除源文件，软连接文件打不开ln -s 源文件 目标文件 创建链接文件(文件名都必须写绝对路径) cat命令（用于查看文本文件的内容，后接要查看的文件名，通常可用管道与more和less一起使用）cat file1 从第一个字节开始正向查看文件的内容tac file1 从最后一行开始反向查看一个文件的内容cat -n file1 标示文件的行数more file1 查看一个长文件的内容head -n 2 file1 查看一个文件的前两行tail -n 2 file1 查看一个文件的最后两行tail -n +1000 file1 从1000行开始显示，显示1000行以后的cat filename | head -n 3000 | tail -n +1000 显示1000行到3000行cat filename | tail -n +3000 | head -n 1000 从第3000行开始，显示1000(即显示3000~3999行) 文件搜索find命令find / -name file1 从 ‘/‘ 开始进入根文件系统搜索文件和目录find / -user user1 搜索属于用户 ‘user1’ 的文件和目录find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件whereis halt 显示一个二进制文件、源码或man的位置which halt 显示一个二进制文件或可执行文件的完整路径 删除大于50M的文件：find /var/mail/ -size +50M -exec rm {} ＼; 文件的权限-rw-r–r–. 1 root root 44736 7月 18 00:38 install.log权限位是十位第一位：代表文件类型 - 普通文件 d 目录文件 l 链接文件其他九位：代表各用户的权限(前三位=属主权限u 中间三位=属组权限g 其他人权限o)r 读 4w 写 2x 执行 1 权限对文件的含义： r：读取文件内容 如：cat、more、head、tail w：编辑、新增、修改文件内容 如：vi、echo 但是不包含删除文件 x：可执行 /tmp/11/22/abc ——— 权限对目录的含义： r：可以查询目录下文件名 如：ls w：具有修改目录结构的权限 如：touch、rm、mv、cp x：可以进入目录 如：cd chmod 命令ls -lh 显示权限chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r，4 ）、写(w，2)和执行(x，1)的权限chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限 chown 命令（改变文件的所有者）chown user1 file1 改变一个文件的所有人属性chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性chown user1:group1 file1 改变一个文件的所有人和群组属性 chgrp 命令（改变文件所属用户组）chgrp group1 file1 改变文件的群组 文本处理grep 命令（分析一行的信息，若当中有我们所需要的信息，就将该行显示出来，该命令通常与管道命令一起使用，用于对一些命令的输出进行筛选加工等等）grep Aug /var/log/messages 在文件 ‘/var/log/messages’中查找关键词”Aug”grep ^Aug /var/log/messages 在文件 ‘/var/log/messages’中查找以”Aug”开始的词汇grep [0-9] /var/log/messages 选择 ‘/var/log/messages’ 文件中所有包含数字的行grep Aug -R /var/log/* 在目录 ‘/var/log’ 及随后的目录中搜索字符串”Aug”sed ‘s/stringa1/stringa2/g’ example.txt 将example.txt文件中的 “string1” 替换成 “string2”sed ‘/^$/d’ example.txt 从example.txt文件中删除所有空白行 paste 命令paste file1 file2 合并两个文件或两栏的内容paste -d ‘+’ file1 file2 合并两个文件或两栏的内容，中间用”+”区分 sort 命令sort file1 file2 排序两个文件的内容sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份)sort file1 file2 | uniq -u 删除交集，留下其他的行sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件) comm 命令comm -1 file1 file2 比较两个文件的内容只删除 ‘file1’ 所包含的内容comm -2 file1 file2 比较两个文件的内容只删除 ‘file2’ 所包含的内容comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 打包和压缩文件tar 命令（对文件进行打包，默认情况并不会压缩，如果指定了相应的参数，它还会调用相应的压缩程序（如gzip和bzip等）进行压缩和解压）-c ：新建打包文件-t ：查看打包文件的内容含有哪些文件名-x ：解打包或解压缩的功能，可以搭配-C（大写）指定解压的目录，注意-c,-t,-x不能同时出现在同一条命令中-j ：通过bzip2的支持进行压缩/解压缩-z ：通过gzip的支持进行压缩/解压缩-v ：在压缩/解压缩过程中，将正在处理的文件名显示出来-f filename ：filename为要处理的文件-C dir ：指定压缩/解压缩的目录dir压缩：tar -jcv -f filename.tar.bz2 要被处理的文件或目录名称查询：tar -jtv -f filename.tar.bz2解压：tar -jxv -f filename.tar.bz2 -C 欲解压缩的目录 bunzip2 file1.bz2 解压一个叫做 ‘file1.bz2’的文件bzip2 file1 压缩一个叫做 ‘file1’ 的文件gunzip file1.gz 解压一个叫做 ‘file1.gz’的文件gzip file1 压缩一个叫做 ‘file1’的文件gzip -9 file1 最大程度压缩rar a file1.rar test_file 创建一个叫做 ‘file1.rar’ 的包rar a file1.rar file1 file2 dir1 同时压缩 ‘file1’, ‘file2’ 以及目录 ‘dir1’rar x file1.rar 解压rar包 zip file1.zip file1 创建一个zip格式的压缩包unzip file1.zip 解压一个zip格式压缩包zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包 系统和关机 (系统的关机、重启以及登出 )shutdown -h now 关闭系统(1)init 0 关闭系统(2)telinit 0 关闭系统(3)shutdown -h hours:minutes &amp; 按预定时间关闭系统shutdown -c 取消按预定时间关闭系统shutdown -r now 重启(1)reboot 重启(2)logout 注销time 测算一个命令（即程序）的执行时间 进程相关的命令jps命令（显示当前系统的java进程情况，及其id号）jps(Java Virtual Machine Process Status Tool)是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/unix平台上简单察看当前java进程的一些简单情况。 ps命令（用于将某个时间点的进程运行情况选取下来并输出，process之意）-A ：所有的进程均显示出来-a ：不与terminal有关的所有进程-u ：有效用户的相关进程-x ：一般与a参数一起使用，可列出较完整的信息-l ：较长，较详细地将PID的信息列出 ps aux # 查看系统所有的进程数据ps ax # 查看不与terminal有关的所有进程ps -lA # 查看系统所有的进程数据ps axjf # 查看连同一部分进程树状态 kill命令（用于向某个工作（%jobnumber）或者是某个PID（数字）传送一个信号，它通常与ps和jobs命令一起使用） killall命令（向一个命令启动的进程发送一个信号） top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。 如何杀死进程：（1）图形化界面的方式（2）kill -9 pid （-9表示强制关闭）（3）killall -9 程序的名字（4）pkill 程序的名字 查看进程端口号：netstat -tunlp|grep 端口号 普通文件和目录文件的区别文件的类型Linux下面一切皆文件，配置是文件，设备是文件，目录也是特殊的文件，文件有如下几种：d：目录文件的标识是，-：普通文件标识，l：软连接文件，亦称符号链接文件；b，块文件，是设备文件的一种（还有另一种），b是block的简写。c，字符文件，也是设备文件的一种，c是character的文件。 普通文件和目录文件普通文件：存储普通数据，一般就是字符串。目录文件：存储了一张表，该表就是该目录文件下，所有文件名和inode的映射关系。 权限的区别对于普通文件来说，rwx的意义是：r：可以获得这个普通文件的名字和内容。w：可以修改这个文件的内容和文件名。可以删除该文件。x：该文件是否具有被执行的权限。 对于目录文件来说，rwx的意义是：r：表示具有读取目录结构列表的权限，所以当你具有读取(r)一个目录的权限时，表示你可以查询该目录下的文件名。 就可以利用 ls 这个命令将该目录的内容列表显示出来， 必须这个目录有x的权限，才可以进入这个目录。w：移动该目录结构列表的权限（建立新的文件与目录、删除已经存在的文件与目录、更名、移动位置）。x：目录不可以被执行，目录的x代表的是用户能否进入该目录成为工作目录。 Linux 常见目录/ 根目录/bin 命令保存目录（普通用户就可以读取的命令）/boot 启动目录，启动相关文件/dev 设备文件保存目录/etc 配置文件保存目录/home 普通用户的家目录/lib 系统库保存目录/mnt 系统挂载目录/media 挂载目录/root 超级用户的家目录/tmp 临时目录/sbin 命令保存目录（超级用户才能使用的目录）/proc 直接写入内存的/sys 将内核的一些信息映射，可供应用程序所用/usr 系统软件资源目录/usr/bin/ 系统命令（普通用户）/usr/sbin/ 系统命令（超级用户）/var 系统相关文档内容/var/log/ 系统日志位置/var/spool/mail/ 系统默认邮箱位置/var/lib/ 默认安装的库文件目录]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp中vector和set使用sort方法进行排序]]></title>
    <url>%2F2019%2F04%2F09%2Fcpp%E4%B8%ADvector%E5%92%8Cset%E4%BD%BF%E7%94%A8sort%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[C++中vector和set都是非常方便的容器， sort方法是algorithm头文件里的一个标准函数，能进行高效的排序，默认是按元素从小到大排序 将sort方法用到vector和set中能实现多种符合自己需求的排序 首先sort方法可以对静态的数组进行排序123456789#include&lt;iostream&gt;using namespace std;int main()&#123; int a[10] = &#123; 9, 0, 1, 2, 3, 7, 4, 5, 100, 10 &#125;; sort(a, a +10); for (int i = 0; i &lt; 10; i++) cout &lt;&lt; a[i] &lt;&lt; endl; return 0;&#125; 运行结果如下： 这里可以看到是sort(a,a+10)，但是数组a一共只有9个元素，为什么是a+10而不是a+9呢？ 因为sort方法实际上最后一位地址对应的数是不取的， 而且vector，set，map这些容器的end()取出来的值实际上并不是最后一个值，而end的前一个才是最后一个值！ 需要用prev(xxx.end())，才能取出容器中最后一个元素。 对vector使用sort函数： 第一种情形：基本类型,如vector,vector,vector也是可以的1234567891011121314151617181920#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;using namespace std;int main()&#123; vector&lt;int&gt; a; int n = 5; while (n--)&#123; int score; cin &gt;&gt; score; a.push_back(score); &#125; //cout &lt;&lt;&quot; a.end()&quot;&lt;&lt; *a.end() &lt;&lt; endl; 执行这句话会报错！ cout &lt;&lt; &quot; prev(a.end)&quot; &lt;&lt; *prev(a.end()) &lt;&lt; endl; sort(a.begin(), a.end()); for (vector&lt;int&gt;::iterator it = a.begin(); it != a.end(); it++)&#123; cout &lt;&lt; *it &lt;&lt; endl; &#125; return 0;&#125; 看到了吗，实际上end的前一个指针指向的元素才是插入时的最后一个值！ 排序后从小大大。 第二种情形：用自定义的结构体进行sort算法， 这时候需要自己定义个比较函数，因为sort算法是基于容器中的元素是可以两两比较的，然后从小到大排序，所以要自定义怎么样才是小于（’&lt;’） 12345678910111213141516171819202122232425262728293031323334353637#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;set&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;struct student&#123; char name[10]; int score;&#125;;//自定义“小于”bool comp(const student &amp;a, const student &amp;b)&#123; return a.score &lt; b.score;&#125;int main()&#123; vector&lt;student&gt; vectorStudents; int n = 5; while (n--)&#123; student oneStudent; string name; int score; cin &gt;&gt; name &gt;&gt; score; strcpy(oneStudent.name, name.c_str()); oneStudent.score = score; vectorStudents.push_back(oneStudent); &#125; cout &lt;&lt; &quot;===========排序前================&quot; &lt;&lt; endl; for (vector&lt;student&gt;::iterator it = vectorStudents.begin(); it != vectorStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; sort(vectorStudents.begin(),vectorStudents.end(),comp); cout &lt;&lt; &quot;===========排序后================&quot; &lt;&lt; endl; for (vector&lt;student&gt;::iterator it = vectorStudents.begin(); it != vectorStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; return 0;&#125; 对于set做类似的操作。 set是一个集合，内部的元素不会重复，同时它会自动进行排序，也是从小到大 而且set的insert方法没有insert(a,cmp)这种重载，所以如果要把结构体插入set中，我们就要重载’&lt;’运算符。 set方法在插入的时候也是从小到大的，那么我们重载一下&lt;运算符让它从大到小排序123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;set&gt;#include&lt;string&gt;#include&lt;algorithm&gt;using namespace std;struct student&#123; char name[10]; int score;&#125;;//自定义“小于”bool comp(const student &amp;a, const student &amp;b)&#123; return a.score &lt; b.score;&#125;bool operator &lt; (const student &amp; stu1,const student &amp;stu2)&#123; return stu1.score &gt; stu2.score;&#125;int main()&#123; //vector&lt;student&gt; vectorStudents; set&lt;student&gt; setStudents; //int n = 5; int n = 6; while (n--)&#123; student oneStudent; string name; int score; cin &gt;&gt; name &gt;&gt; score; strcpy(oneStudent.name, name.c_str()); oneStudent.score = score; setStudents.insert(oneStudent); &#125; cout &lt;&lt; &quot;===========排序前================&quot; &lt;&lt; endl; for (set&lt;student&gt;::iterator it = setStudents.begin(); it != setStudents.end(); it++)&#123; cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; &#125; //sort(setStudents.begin(), setStudents.end(), comp); //cout &lt;&lt; &quot;===========排序后================&quot; &lt;&lt; endl; //for (set&lt;student&gt;::iterator it = setStudents.begin(); it != setStudents.end(); it++)&#123; // cout &lt;&lt; &quot;name: &quot; &lt;&lt; it-&gt;name &lt;&lt; &quot; score: &quot; &lt;&lt; it-&gt;score &lt;&lt; endl; //&#125; return 0;&#125;]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode56. Merge Intervals]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode56%2F</url>
    <content type="text"><![CDATA[Merge IntervalsMedium Given a collection of intervals, merge all overlapping intervals.一些区间，要求合并重叠的区间，返回一个vector保存结果。 Example 1:·123Input: [[1,3],[2,6],[8,10],[15,18]]Output: [[1,6],[8,10],[15,18]]Explanation: Since intervals [1,3] and [2,6] overlaps, merge them into [1,6]. Example 2:123Input: [[1,4],[4,5]]Output: [[1,5]]Explanation: Intervals [1,4] and [4,5] are considered overlapping. 贪心思路，将初始区间序列ins按照左端点的从小到大排序，接着遍历ins。 一开始将第一个区间ins[0]放入结果区间序列res，接着每次遍历到一个新的区间[l,r]，将其与当前合并后的最后一个区间[L,R]比较： 若l &lt;= R，说明新区间与当前最有一个区间有重叠，应该将这两个区间合并，也就需要修改当前最后一个区间为[L，max(r,R)]。若l &gt; R，说明新区间与当前最后一个区间没有重叠，所以不需要合并，直接将新区间加入结果序列res，成为新的最后一个区间。 算法正确性： 在上述贪心思路中，只考虑了新区间的左端点与最后一个区间的右端点的大小比较，最后只会对最后区间的右端点进行修改，却不会修改左端点。之所以不考虑左端点，是因为初始化时已经将ins按照左端点排序，保证后遍历的左端点l &gt;= 之前遍历过的左端点L。 算法复杂度为O(nlogn)。 我的代码：123456789101112131415161718192021222324252627282930313233343536373839/** * Definition for an interval. * struct Interval &#123; * int start; * int end; * Interval() : start(0), end(0) &#123;&#125; * Interval(int s, int e) : start(s), end(e) &#123;&#125; * &#125;; */class Solution &#123;public: static bool comp(const Interval &amp;a, const Interval &amp;b) &#123; return a.start &lt; b.start; &#125; vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; intervals) &#123; vector&lt;Interval&gt; answer; if(intervals.size()==0) return answer; sort(intervals.begin(),intervals.end(),comp); Interval ttt(intervals[0].start,intervals[0].end); vector&lt;Interval&gt;::iterator it = intervals.begin(); it++; for(; it != intervals.end(); it++)&#123; if(ttt.end&gt;=it-&gt;start)&#123; if(ttt.end&lt;it-&gt;end) ttt.end=it-&gt;end; &#125; else if(ttt.end&lt;it-&gt;start)&#123; answer.push_back(ttt); ttt.start=it-&gt;start; ttt.end = it-&gt;end; &#125; &#125; answer.push_back(ttt); return answer; &#125;&#125;; 题解的代码：1234567891011121314151617181920212223class Solution &#123; public: static bool cmp(const Interval &amp;a, const Interval &amp;b) &#123; return a.start &lt; b.start; &#125; vector&lt;Interval&gt; merge(vector&lt;Interval&gt;&amp; ins) &#123; vector &lt;Interval&gt; res; if (ins.empty()) return res; sort(ins.begin(), ins.end(), cmp); res.push_back(ins[0]); int cnt = ins.size(); for (int i = 1; i &lt; cnt; i++) &#123; if (ins[i].start &lt;= res.back().end) &#123; res.back().end = max(res.back().end, ins[i].end); &#125; else &#123; res.push_back(ins[i]); &#125; &#125; return res; &#125;&#125;; SolutionApproach 1: Connected ComponentsIntuition If we draw a graph (with intervals as nodes) that contains undirected edges between all pairs of intervals that overlap, then all intervals in each connected component of the graph can be merged into a single interval. Algorithm With the above intuition in mind, we can represent the graph as an adjacency list, inserting directed edges in both directions to simulate undirected edges. Then, to determine which connected component each node is it, we perform graph traversals from arbitrary unvisited nodes until all nodes have been visited. To do this efficiently, we store visited nodes in a Set, allowing for constant time containment checks and insertion. Finally, we consider each connected component, merging all of its intervals by constructing a new Interval with start equal to the minimum start among them and end equal to the maximum end. This algorithm is correct simply because it is basically the brute force solution. We compare every interval to every other interval, so we know exactly which intervals overlap. The reason for the connected component search is that two intervals may not directly overlap, but might overlap indirectly via a third interval. See the example below to see this more clearly. Components Example Although (1, 5) and (6, 10) do not directly overlap, either would overlap with the other if first merged with (4, 7). There are two connected components, so if we merge their nodes, we expect to get the following two merged intervals: (1, 10), (15, 20) 123456789101112131415161718192021222324252627class Solution &#123; private Map&lt;Interval, List&lt;Interval&gt; &gt; graph; private Map&lt;Integer, List&lt;Interval&gt; &gt; nodesInComp; private Set&lt;Interval&gt; visited; // return whether two intervals overlap (inclusive) private boolean overlap(Interval a, Interval b) &#123; return a.start &lt;= b.end &amp;&amp; b.start &lt;= a.end; &#125; // build a graph where an undirected edge between intervals u and v exists // iff u and v overlap. private void buildGraph(List&lt;Interval&gt; intervals) &#123; graph = new HashMap&lt;&gt;(); for (Interval interval : intervals) &#123; graph.put(interval, new LinkedList&lt;&gt;()); &#125; for (Interval interval1 : intervals) &#123; for (Interval interval2 : intervals) &#123; if (overlap(interval1, interval2)) &#123; graph.get(interval1).add(interval2); graph.get(interval2).add(interval1); &#125; &#125; &#125; &#125; 12345678910111213141516class Solution: def merge(self, intervals): intervals.sort(key=lambda x: x.start) merged = [] for interval in intervals: # if the list of merged intervals is empty or if the current # interval does not overlap with the previous, simply append it. if not merged or merged[-1].end &lt; interval.start: merged.append(interval) else: # otherwise, there is overlap, so we merge the current and previous # intervals. merged[-1].end = max(merged[-1].end, interval.end) return merged]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树高频面试题和答案]]></title>
    <url>%2F2019%2F04%2F09%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E9%AB%98%E9%A2%91%E9%9D%A2%E8%AF%95%E9%A2%98%E5%92%8C%E7%AD%94%E6%A1%88%2F</url>
    <content type="text"><![CDATA[先上二叉树的数据结构：1234567class TreeNode&#123; int val; //左孩子 TreeNode left; //右孩子 TreeNode right;&#125; 二叉树的题目普遍可以用递归和迭代的方式来解 求二叉树的最大深度 12345678int maxDeath(TreeNode node)&#123; if(node==null)&#123; return 0; &#125; int left = maxDeath(node.left); int right = maxDeath(node.right); return Math.max(left,right) + 1;&#125; 求二叉树的最小深度 123456789101112131415int getMinDepth(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; return getMin(root); &#125; int getMin(TreeNode root)&#123; if(root == null)&#123; return Integer.MAX_VALUE; &#125; if(root.left == null&amp;&amp;root.right == null)&#123; return 1; &#125; return Math.min(getMin(root.left),getMin(root.right)) + 1; &#125; 求二叉树中节点的个数 12345678int numOfTreeNode(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; int left = numOfTreeNode(root.left); int right = numOfTreeNode(root.right); return left + right + 1; &#125; 求二叉树中叶子节点的个数 123456789 int numsOfNoChildNode(TreeNode root)&#123; if(root == null)&#123; return 0; &#125; if(root.left==null&amp;&amp;root.right==null)&#123; return 1; &#125; return numsOfNodeTreeNode(root.left)+numsOfNodeTreeNode(root.right);&#125; 求二叉树中第k层节点的个数 1234567891011int numsOfkLevelTreeNode(TreeNode root,int k)&#123; if(root == null||k&lt;1)&#123; return 0; &#125; if(k==1)&#123; return 1; &#125; int numsLeft = numsOfkLevelTreeNode(root.left,k-1); int numsRight = numsOfkLevelTreeNode(root.right,k-1); return numsLeft + numsRight; &#125; 判断二叉树是否是平衡二叉树 1234567891011121314boolean isBalanced(TreeNode node)&#123; return maxDeath2(node)!=-1; &#125; int maxDeath2(TreeNode node)&#123; if(node == null)&#123; return 0; &#125; int left = maxDeath2(node.left); int right = maxDeath2(node.right); if(left==-1||right==-1||Math.abs(left-right)&gt;1)&#123; return -1; &#125; return Math.max(left, right) + 1; &#125; 7.判断二叉树是否是完全二叉树1234567891011121314151617181920212223242526272829303132boolean isCompleteTreeNode(TreeNode root)&#123; if(root == null)&#123; return false; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); boolean result = true; boolean hasNoChild = false; while(!queue.isEmpty())&#123; TreeNode current = queue.remove(); if(hasNoChild)&#123; if(current.left!=null||current.right!=null)&#123; result = false; break; &#125; &#125;else&#123; if(current.left!=null&amp;&amp;current.right!=null)&#123; queue.add(current.left); queue.add(current.right); &#125;else if(current.left!=null&amp;&amp;current.right==null)&#123; queue.add(current.left); hasNoChild = true; &#125;else if(current.left==null&amp;&amp;current.right!=null)&#123; result = false; break; &#125;else&#123; hasNoChild = true; &#125; &#125; &#125; return result; &#125; 两个二叉树是否完全相同 1234567891011121314boolean isSameTreeNode(TreeNode t1,TreeNode t2)&#123; if(t1==null&amp;&amp;t2==null)&#123; return true; &#125; else if(t1==null||t2==null)&#123; return false; &#125; if(t1.val != t2.val)&#123; return false; &#125; boolean left = isSameTreeNode(t1.left,t2.left); boolean right = isSameTreeNode(t1.right,t2.right); return left&amp;&amp;right;&#125; 两个二叉树是否互为镜像 123456789101112 boolean isMirror(TreeNode t1,TreeNode t2)&#123; if(t1==null&amp;&amp;t2==null)&#123; return true; &#125; if(t1==null||t2==null)&#123; return false; &#125; if(t1.val != t2.val)&#123; return false; &#125; return isMirror(t1.left,t2.right)&amp;&amp;isMirror(t1.right,t2.left);&#125; 翻转二叉树or镜像二叉树 12345678910 TreeNode mirrorTreeNode(TreeNode root)&#123; if(root == null)&#123; return null; &#125; TreeNode left = mirrorTreeNode(root.left); TreeNode right = mirrorTreeNode(root.right); root.left = right; root.right = left; return root;&#125; 求两个二叉树的最低公共祖先节点 1234567891011121314151617181920212223242526272829TreeNode getLastCommonParent(TreeNode root,TreeNode t1,TreeNode t2)&#123; if(findNode(root.left,t1))&#123; if(findNode(root.right,t2))&#123; return root; &#125;else&#123; return getLastCommonParent(root.left,t1,t2); &#125; &#125;else&#123; if(findNode(root.left,t2))&#123; return root; &#125;else&#123; return getLastCommonParent(root.right,t1,t2) &#125; &#125;&#125;// 查找节点node是否在当前 二叉树中boolean findNode(TreeNode root,TreeNode node)&#123; if(root == null || node == null)&#123; return false; &#125; if(root == node)&#123; return true; &#125; boolean found = findNode(root.left,node); if(!found)&#123; found = findNode(root.right,node); &#125; return found;&#125; 二叉树的前序遍历 迭代解法12345678910111213141516171819ArrayList&lt;Integer&gt; preOrder(TreeNode root)&#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if(root == null)&#123; return list; &#125; stack.push(root); while(!stack.empty())&#123; TreeNode node = stack.pop(); list.add(node.val); if(node.right!=null)&#123; stack.push(node.right); &#125; if(node.left != null)&#123; stack.push(node.left); &#125; &#125; return list; &#125; 递归解法12345678910111213ArrayList&lt;Integer&gt; preOrderReverse(TreeNode root)&#123; ArrayList&lt;Integer&gt; result = new ArrayList&lt;Integer&gt;(); preOrder2(root,result); return result; &#125; void preOrder2(TreeNode root,ArrayList&lt;Integer&gt; result)&#123; if(root == null)&#123; return; &#125; result.add(root.val); preOrder2(root.left,result); preOrder2(root.right,result); &#125; 二叉树的中序遍历12345678910111213141516ArrayList&lt;Integer&gt; inOrder(TreeNode root)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode current = root; while(current != null|| !stack.empty())&#123; while(current != null)&#123; stack.add(current); current = current.left; &#125; current = stack.peek(); stack.pop(); list.add(current.val); current = current.right; &#125; return list; &#125; 14.二叉树的后序遍历12345678910ArrayList&lt;Integer&gt; postOrder(TreeNode root)&#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); if(root == null)&#123; return list; &#125; list.addAll(postOrder(root.left)); list.addAll(postOrder(root.right)); list.add(root.val); return list; &#125; 15.前序遍历和后序遍历构造二叉树12345678910111213141516171819202122232425TreeNode buildTreeNode(int[] preorder,int[] inorder)&#123; if(preorder.length!=inorder.length)&#123; return null; &#125; return myBuildTree(inorder,0,inorder.length-1,preorder,0,preorder.length-1); &#125; TreeNode myBuildTree(int[] inorder,int instart,int inend,int[] preorder,int prestart,int preend)&#123; if(instart&gt;inend)&#123; return null; &#125; TreeNode root = new TreeNode(preorder[prestart]); int position = findPosition(inorder,instart,inend,preorder[start]); root.left = myBuildTree(inorder,instart,position-1,preorder,prestart+1,prestart+position-instart); root.right = myBuildTree(inorder,position+1,inend,preorder,position-inend+preend+1,preend); return root; &#125; int findPosition(int[] arr,int start,int end,int key)&#123; int i; for(i = start;i&lt;=end;i++)&#123; if(arr[i] == key)&#123; return i; &#125; &#125; return -1; &#125; 16.在二叉树中插入节点123456789101112131415161718192021222324TreeNode insertNode(TreeNode root,TreeNode node)&#123; if(root == node)&#123; return node; &#125; TreeNode tmp = new TreeNode(); tmp = root; TreeNode last = null; while(tmp!=null)&#123; last = tmp; if(tmp.val&gt;node.val)&#123; tmp = tmp.left; &#125;else&#123; tmp = tmp.right; &#125; &#125; if(last!=null)&#123; if(last.val&gt;node.val)&#123; last.left = node; &#125;else&#123; last.right = node; &#125; &#125; return root; &#125; 17.输入一个二叉树和一个整数，打印出二叉树中节点值的和等于输入整数所有的路径1234567891011121314151617181920212223242526void findPath(TreeNode r,int i)&#123; if(root == null)&#123; return; &#125; Stack&lt;Integer&gt; stack = new Stack&lt;Integer&gt;(); int currentSum = 0; findPath(r, i, stack, currentSum); &#125; void findPath(TreeNode r,int i,Stack&lt;Integer&gt; stack,int currentSum)&#123; currentSum+=r.val; stack.push(r.val); if(r.left==null&amp;&amp;r.right==null)&#123; if(currentSum==i)&#123; for(int path:stack)&#123; System.out.println(path); &#125; &#125; &#125; if(r.left!=null)&#123; findPath(r.left, i, stack, currentSum); &#125; if(r.right!=null)&#123; findPath(r.right, i, stack, currentSum); &#125; stack.pop(); &#125; 18.二叉树的搜索区间给定两个值 k1 和 k2（k1 &lt; k2）和一个二叉查找树的根节点。找到树中所有值在 k1 到 k2 范围内的节点。即打印所有x (k1 &lt;= x &lt;= k2) 其中 x 是二叉查找树的中的节点值。返回所有升序的节点值。1234567891011121314151617181920ArrayList&lt;Integer&gt; result; ArrayList&lt;Integer&gt; searchRange(TreeNode root,int k1,int k2)&#123; result = new ArrayList&lt;Integer&gt;(); searchHelper(root,k1,k2); return result; &#125; void searchHelper(TreeNode root,int k1,int k2)&#123; if(root == null)&#123; return; &#125; if(root.val&gt;k1)&#123; searchHelper(root.left,k1,k2); &#125; if(root.val&gt;=k1&amp;&amp;root.val&lt;=k2)&#123; result.add(root.val); &#125; if(root.val&lt;k2)&#123; searchHelper(root.right,k1,k2); &#125; &#125; 19.二叉树的层次遍历123456789101112131415161718192021222324ArrayList&lt;ArrayList&lt;Integer&gt;&gt; levelOrder(TreeNode root)&#123; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; result = new ArrayList&lt;ArrayList&lt;Integer&gt;&gt;(); if(root == null)&#123; return result; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.offer(root); while(!queue.isEmpty())&#123; int size = queue.size(); ArrayList&lt;&lt;Integer&gt; level = new ArrayList&lt;Integer&gt;(): for(int i = 0;i &lt; size ;i++)&#123; TreeNode node = queue.poll(); level.add(node.val); if(node.left != null)&#123; queue.offer(node.left); &#125; if(node.right != null)&#123; queue.offer(node.right); &#125; &#125; result.add(Level); &#125; return result; &#125; 20.二叉树内两个节点的最长距离二叉树中两个节点的最长距离可能有三种情况： 左子树的最大深度+右子树的最大深度为二叉树的最长距离 左子树中的最长距离即为二叉树的最长距离 右子树种的最长距离即为二叉树的最长距离 因此，递归求解即可12345678910111213141516171819202122232425 private static class Result&#123; int maxDistance; int maxDepth; public Result() &#123; &#125; public Result(int maxDistance, int maxDepth) &#123; this.maxDistance = maxDistance; this.maxDepth = maxDepth; &#125; &#125; int getMaxDistance(TreeNode root)&#123; return getMaxDistanceResult(root).maxDistance; &#125; Result getMaxDistanceResult(TreeNode root)&#123; if(root == null)&#123; Result empty = new Result(0,-1); return empty; &#125; Result lmd = getMaxDistanceResult(root.left); Result rmd = getMaxDistanceResult(root.right); Result result = new Result(); result.maxDepth = Math.max(lmd.maxDepth,rmd.maxDepth) + 1; result.maxDistance = Math.max(lmd.maxDepth + rmd.maxDepth,Math.max(lmd.maxDistance,rmd.maxDistance)); return result; &#125; 21.不同的二叉树给出 n，问由 1…n 为节点组成的不同的二叉查找树有多少种？1234567891011int numTrees(int n )&#123; int[] counts = new int[n+2]; counts[0] = 1; counts[1] = 1; for(int i = 2;i&lt;=n;i++)&#123; for(int j = 0;j&lt;i;j++)&#123; counts[i] += counts[j] * counts[i-j-1]; &#125; &#125; return counts[n]; &#125; 22.判断二叉树是否是合法的二叉查找树(BST)一棵BST定义为： 节点的左子树中的值要严格小于该节点的值。 节点的右子树中的值要严格大于该节点的值。 左右子树也必须是二叉查找树。 一个节点的树也是二叉查找树。1234567891011121314151617181920public int lastVal = Integer.MAX_VALUE; public boolean firstNode = true; public boolean isValidBST(TreeNode root) &#123; // write your code here if(root==null)&#123; return true; &#125; if(!isValidBST(root.left))&#123; return false; &#125; if(!firstNode&amp;&amp;lastVal &gt;= root.val)&#123; return false; &#125; firstNode = false; lastVal = root.val; if (!isValidBST(root.right)) &#123; return false; &#125; return true; &#125;]]></content>
      <tags>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb调试相关]]></title>
    <url>%2F2019%2F04%2F09%2Fgdb%E8%B0%83%E8%AF%95%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[给师兄debug测试的时候深深觉得自己太垃圾了，gdb用的不熟，所以去找了一篇gdb的博文搬过来整理好，纯当复习了。贴原文链接：https://blog.csdn.net/zb872676223/article/details/37906049 GDB是GNU开源组织发布的一个强大的UNIX下的程序调试工具。或许，各位比较喜欢那种图形界面方式的，像VC、BCB等IDE的调试，但如果你是在UNIX平台下做软件，你会发现GDB这个调试工具有比VC、BCB的图形化调试器更强大的功能。所谓“寸有所长，尺有所短”就是这个道理。 一般来说，GDB主要帮忙你完成下面四个方面的功能： 启动你的程序，可以按照你的自定义的要求随心所欲的运行程序。 可让被调试的程序在你所指定的调置的断点处停住。（断点可以是条件表达式） 当程序被停住时，可以检查此时你的程序中所发生的事。 动态的改变你程序的执行环境。 测试程序我们先看看我们的测试程序:123456789101112131415161718192021222324252627282930313233343536373839404142/* in eg1.c */int wib(int no1, int no2)&#123; int result, diff; diff = no1 - no2; result = no1 / diff; return result;&#125;int main()&#123; pid_t pid; pid = fork(); if (pid &lt;0) &#123; printf(&quot;fork err\n&quot;); exit(-1); &#125; else if (pid == 0) &#123; /* in child process */ sleep(60); ------------------ (!) int value = 10; int div = 6; int total = 0; int i = 0; int result = 0; for (i = 0; i &lt; 10; i++) &#123; result = wib(value, div); total += result; div++; value--; &#125; printf(&quot;%d wibed by %d equals %d\n&quot;, value, div, total); exit(0); &#125; else &#123; /* in parent process */ sleep(4); wait(-1); exit(0); &#125;&#125; 该测试程序中子进程运行过程中会在wib函数中出现一个’除0’异常。现在我们就要调试该子进程。 调试原理不知道大家发现没有，在(!)处在我们的测试程序在父进程fork后，子进程调用sleep睡了60秒。这就是关键，这个sleep本来是不该存在于子进程代码中的，而是而了使用GDB调试后加入的，它是我们调试的一个关键点。为什么要让子进程刚刚运行就开始sleep呢？因为我们要在子进程睡眠期间，利用 shell命令获取其process id，然后再利用gdb调试外部进程的方法attach到该process id上，调试该进程。我们现在调试的是mpi程序，intel的mpiexec可以直接-gdb进行调试，但是用gnu的话就不行了，只能gdb attach来调试，下述。 调试过程GDB 调试程序的前提条件就是你编译程序时必须加入调试符号信息，即使用’-g’编译选项。首先编译我们的源程序gcc -g -o eg1 eg1.c。编译好之后，我们就有了我们的调试目标eg1。由于我们在调试过程中需要多个工具配合，所以你最好多打开几个终端窗口，另外一点需要注意的是最好在eg1的working directory下执行gdb程序，否则gdb回提示’No symbol table is loaded’。你还得手工load symbol table。好了，下面我们就’按部就班’的开始调试我们的eg1。 执行eg1:eg1 &amp; --- 让eg1后台运行 查找进程id:ps -fu YOUR_USER_NAME或在linux下使用getpid()函数 运行gdb:12345678910111213141516171819202122232425262728293031323334353637gdb(gdb) attach xxxxx --- xxxxx为利用ps命令获得的子进程process id(gdb) stop --- 这点很重要，你需要先暂停那个子进程，然后设置一些断点和一些Watch(gdb) break 37 -- 在result = wib(value, div);这行设置一个断点,可以使用list命令察看源代码Breakpoint 1 at 0x10808: file eg1.c, line 37.(gdb) continueContinuing.这里一定要continue，要不的话。。。。。。傻呼呼的等那么久还不运行。Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=10, no2=6) at eg1.c:1313 diff = no1 - no2;(gdb) continueContinuing.Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=9, no2=7) at eg1.c:1313 diff = no1 - no2;(gdb) continueContinuing.Breakpoint 1, main () at eg1.c:3737 result = wib(value, div);(gdb) stepwib (no1=8, no2=8) at eg1.c:1313 diff = no1 - no2;(gdb) next14 result = no1 / diff;(gdb) print diff$6 = 0 ------- 除数为0，我们找到罪魁祸首了。(gdb) nextProgram received signal SIGFPE, Arithmetic exception.0xff29d830 in .div () from /usr/lib/libc.so.1 至此，我们调试完毕。 GDB调试精粹一、列文件清单list / l列出产生执行文件的源代码的一部分 1234567891011//列出 line1 到 line2 行之间的源代码 (gdb) list line1, line2 //输出从上次调用list命令开始往后的10行程序代码 (gdb) list //输出第 n 行附近的10行程序代码 (gdb) list n //输出函数function前后的10行程序代码 (gdb) list function 二、执行程序run / r运行准备调试的程序，在它后面可以跟随发给该程序的任何参数，包括标准输入和标准输出说明符(&lt;和&gt;)和shell通配符（*、？、[、]）在内。如果你使用不带参数的run命令，gdb就再次使用你给予前一条run命令的参数，这是很有用的。 set args命令就可以修改发送给程序的参数，而使用 show args命令就可以查看其缺省参数的列表。 12(gdb) set args –b –x (gdb) show args 三、显示数据print / p查看变量的值 1234567891011121314151617181920//利用print 命令可以检查各个变量的值。 (gdb) print p (p为变量名) print 是 gdb 的一个功能很强的命令，利用它可以显示被调试的语言中任何有效的表达式。表达式除了包含你程序中的变量外，还可以包含以下内容：//对程序中函数的调用 (gdb) print find_entry(1, 0) //数据结构和其他复杂对象 (gdb) print *table_start $8=&#123;e=reference=’\000’,location=0x0,next=0x0&#125; //值的历史成分 (gdb)print $1 ($1为历史记录变量,在以后可以直接引用 $1 的值) whatis 查看变量的类型//whatis 命令可以显示某个变量的类型 (gdb) whatis p type = int * 四、设置与清除断点break / b可以用来在调试的程序中设置断点，该命令有如下四种形式：123456789101112//使程序恰好在执行给定行之前停止 break line-number //使程序恰好在进入指定的函数之前停止 break function-name //如果condition（条件）是真，程序到达指定行或函数时停止 break line-or-function if condition //在指定例程的入口处设置断点 break routine-name 如果该程序是由很多原文件构成的，你可以在各个原文件中设置断点，而不是在当前的原文件中设置断点，其方法如下：1234(gdb) break filename:line-number (gdb) break filename:function-name break if 要想设置一个条件断点，可以利用break if命令，如下所示：1234(gdb) break line-or-function if expr (gdb) break 46 if testsize==100 clean number 清除原文件中某一代码行上的所有断点 注：number 为原文件的某个代码行的行号 五、断点的管理 显示当前gdb的断点信息info break delete 删除指定的某个断点delete breakpoint 12345//该命令将会删除编号为1的断点 (gdb) delete breakpoint 1 //如果不带编号参数，将删除所有的断点 (gdb) delete breakpoint 禁止、允许使用某个断点12disable breakpoint 1enable breakpoint 1 该命令将禁止、允许断点 1，同时断点信息的 (Enb)域将变为 n、y 六、单步执行next / n不进入的单步执行 step进入的单步执行 finish如果已经进入了某函数，而想退出该函数返回到它的调用函数中，可使用命令finish until结束当前循环 七、函数的调用call name调用和执行一个函数123(gdb) call gen_and_sork( 1234,1,0 ) (gdb) call printf(“abcd”) $1=4 八、 原文件的搜索search text 该命令可显示在当前文件中包含text串的下一行。 reverse-search text 该命令可以显示包含text 的前一行。 小结：常用的 gdb 命令 backtrace / bt 显示程序中的当前位置和表示如何到达当前位置的栈跟踪（同义词：where） breakpoint / b 在程序中设置一个断点 cd 改变当前工作目录 clear 删除刚才停止处的断点 commands 命中断点时，列出将要执行的命令 continue 从断点开始继续执行 delete 删除一个断点或监测点；也可与其他命令一起使用 display 程序停止时显示变量和表达时 down 下移栈帧，使得另一个函数成为当前函数 frame 选择下一条continue命令的帧 info 显示与该程序有关的各种信息 jump 在源程序中的另一点开始运行 kill 异常终止在gdb 控制下运行的程序 list 列出相应于正在执行的程序的原文件内容 next 执行下一个源程序行，从而执行其整体中的一个函数 print 显示变量或表达式的值 pwd 显示当前工作目录 ptype 显示一个数据结构（如一个结构或C++类）的内容 quit 退出gdb reverse-search 在源文件中反向搜索正规表达式 run 执行该程序 search 在源文件中搜索正规表达式 set variable 给变量赋值 signal 将一个信号发送到正在运行的进程 step 执行下一个源程序行，必要时进入下一个函数 undisplay display 命令的反命令，不要显示表达式 until 结束当前循环 up 上移栈帧，使另一函数成为当前函数 watch 在程序中设置一个监测点（即数据断点） whatis 显示变量或函数类型 九、查看运行时数据在你调试程序时，当程序被停住时，你可以使用print命令（简写命令为p），或是同义命令inspect来查看当前程序的运行数据。print命令的格式是：print print /是表达式，是你所调试的程序的语言的表达式（GDB可以调试多种编程语言），是输出的格式，比如，如果要把表达式按16进制的格式输出，那么就是/x。 表达式print和许多GDB的命令一样，可以接受一个表达式，GDB会根据当前的程序运行的数据来计算这个表达式，既然是表达式，那么就可以是当前程序运行中的const常量、变量、函数等内容。可惜的是GDB不能使用你在程序中所定义的宏。表达式的语法应该是当前所调试的语言的语法，由于C/C++是一种大众型的语言，所以，本文中的例子都是关于C/C++的。（而关于用GDB调试其它语言的章节，我将在后面介绍）。在表达式中，有几种GDB所支持的操作符，它们可以用在任何一种语言中。@是一个和数组有关的操作符，在后面会有更详细的说明。::指定一个在文件或是一个函数中的变量。{}表示一个指向内存地址的类型为type的一个对象。 程序变量在GDB中，你可以随时查看以下三种变量的值：1、全局变量（所有文件可见的）2、静态全局变量（当前文件可见的）3、局部变量（当前Scope可见的）如果你的局部变量和全局变量发生冲突（也就是重名），一般情况下是局部变量会隐藏全局变量，也就是说，如果一个全局变量和一个函数中的局部变量同名时，如果当前停止点在函数中，用print显示出的变量的值会是函数中的局部变量的值。如果此时你想查看全局变量的值时，你可以使用“::”操作符： 12file::variable function::variable 可以通过这种形式指定你所想查看的变量，是哪个文件中的或是哪个函数中的。例如，查看文件f2.c中的全局变量x的值：1(gdb) p &apos;f2.c&apos;::x 当然，“::”操作符会和C++中的发生冲突，GDB能自动识别“::” 是否C++的操作符，所以你不必担心在调试C++程序时会出现异常。 另外，需要注意的是，如果你的程序编译时开启了优化选项，那么在用GDB调试被优化过的程序时，可能会发生某些变量不能访问，或是取值错误码的情况。这个是很正常的，因为优化程序会删改你的程序，整理你程序的语句顺序，剔除一些无意义的变量等，所以在GDB调试这种程序时，运行时的指令和你所编写指令就有不一样，也就会出现你所想象不到的结果。对付这种情况时，需要在编译程序时关闭编译优化。一般来说，几乎所有的编译器都支持编译优化的开关，例如，GNU的C/C++编译器GCC，你可以使用“-gstabs”选项来解决这个问题。关于编译器的参数，还请查看编译器的使用说明文档。 数组有时候，你需要查看一段连续的内存空间的值。比如数组的一段，或是动态分配的数据的大小。你可以使用GDB的“@”操作符，“@”的左边是第一个内存的地址的值，“@”的右边则你你想查看内存的长度。例如，你的程序中有这样的语句：int *array = (int *) malloc (len * sizeof (int));于是，在GDB调试过程中，你可以以如下命令显示出这个动态数组的取值： 1p *array@len @的左边是数组的首地址的值，也就是变量array所指向的内容，右边则是数据的长度，其保存在变量len中，其输出结果，大约是下面这个样子的：12(gdb) p *array@len $1 = &#123;2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40&#125; 如果是静态数组的话，可以直接用print数组名，就可以显示数组中所有数据的内容了。 输出格式一般来说，GDB会根据变量的类型输出变量的值。但你也可以自定义GDB的输出的格式。例如，你想输出一个整数的十六进制，或是二进制来查看这个整型变量的中的位的情况。要做到这样，你可以使用GDB的数据显示格式： 1234567891011121314151617181920x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 (gdb) p i $21 = 101 (gdb) p/a i $22 = 0x65 (gdb) p/c i $23 = 101 &apos;e&apos; (gdb) p/f i $24 = 1.41531145e-43 (gdb) p/x i $25 = 0x65 (gdb) p/t i $26 = 1100101 查看内存你可以使用examine命令（简写是x）来查看内存地址中的值。x命令的语法如下所示： 1x/ n、f、u是可选的参数。n 是一个正整数，表示显示内存的长度，也就是说从当前地址向后显示几个地址的内容。 f 表示显示的格式，参见上面。如果地址所指的是字符串，那么格式可以是s，如果地址是指令地址，那么格式可以是i。u 表示从当前地址往后请求的字节数，如果不指定的话，GDB默认是4个bytes。u参数可以用下面的字符来代替，b表示单字节，h表示双字节，w表示四字节，g表示八字节。当我们指定了字节长度后，GDB会从指内存定的内存地址开始，读写指定字节，并把其当作一个值取出来。 n/f/u三个参数可以一起使用。例如：命令：x/3uh 0x54320 表示，从内存地址0x54320读取内容，h表示以双字节为一个单位，3表示三个单位，u表示按十六进制显示。 自动显示你可以设置一些自动显示的变量，当程序停住时，或是在你单步跟踪时，这些变量会自动显示。相关的GDB命令是display。display格式i和s同样被display支持，一个非常有用的命令是：display/i $pc$pc是GDB的环境变量，表示着指令的地址，/i则表示输出格式为机器指令码，也就是汇编。于是当程序停下后，就会出现源代码和机器指令码相对应的情形，这是一个很有意思的功能。info display查看display设置的自动显示的信息。GDB会打出一张表格，向你报告当然调试中设置了多少个自动显示设置，其中包括，设置的编号，表达式，是否enable。 设置显示选项GDB中关于显示的选项比较多，这里我只例举大多数常用的选项。 12set print address set print address on 打开地址输出，当程序显示函数信息时，GDB会显出函数的参数地址。系统默认为打开的，如：1234(gdb) f #0 set_quotes (lq=0x34c78 &quot;&lt;&lt;&quot;, rq=0x34c88 &quot;&gt;&gt;&quot;) at input.c:530 530 if (lquote != def_lquote) set print address off1关闭函数的参数地址显示，如： (gdb) set print addr off(gdb) f #0 set_quotes (lq=”&lt;&lt;”, rq=”&gt;&gt;”) at input.c:530530 if (lquote != def_lquote) 1show print address 查看当前地址显示选项是否打开。 12set print array set print array on 打开数组显示，打开后当数组显示时，每个元素占一行，如果不打开的话，每个元素则以逗号分隔。这个选项默认是关闭的。与之相关的两个命令如下，我就不再多说了。set print array offshow print array 1set print elements 这个选项主要是设置数组的，如果你的数组太大了，那么就可以指定一个来指定数据显示的最大长度，当到达这个长度时，GDB就不再往下显示了。如果设置为0，则表示不限制。 1show print elements 查看print elements的选项信息。 1set print null-stop 如果打开了这个选项，那么当显示字符串时，遇到结束符则停止显示。这个选项默认为off。 1set print pretty on 如果打开printf pretty这个选项，那么当GDB显示结构体时会比较漂亮。如：12345678$1 = &#123; next = 0x0, flags = &#123; sweet = 1, sour = 1 &#125;, meat = 0x54 &quot;Pork&quot; &#125; 1set print pretty off 关闭printf pretty这个选项，GDB显示结构体时会如下显示：1$1 = &#123;next = 0x0, flags = &#123;sweet = 1, sour = 1&#125;, meat = 0x54 &quot;Pork&quot;&#125; show print pretty查看GDB是如何显示结构体的。 set print sevenbit-strings设置字符显示，是否按“/nnn”的格式显示，如果打开，则字符串或字符数据按/nnn显示，如“/065”。 show print sevenbit-strings查看字符显示开关是否打开。 set print union设置显示结构体时，是否显式其内的联合体数据。例如有以下数据结构：12345678910111213typedef enum &#123;Tree, Bug&#125; Species; typedef enum &#123;Big_tree, Acorn, Seedling&#125; Tree_forms; typedef enum &#123;Caterpillar, Cocoon, Butterfly&#125; Bug_forms; struct thing &#123; Species it; union &#123;Tree_forms tree; Bug_forms bug; &#125; form; &#125;; struct thing foo = &#123;Tree, &#123;Acorn&#125;&#125;; 当打开这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {tree = Acorn, bug = Cocoon}}当关闭这个开关时，执行 p foo 命令后，会如下显示：$1 = {it = Tree, form = {...}} show print union查看联合体数据的显示方式set print object在C++中，如果一个对象指针指向其派生类，如果打开这个选项，GDB会自动按照虚方法调用的规则显示输出，如果关闭这个选项的话，GDB就不管虚函数表了。这个选项默认是off。 show print object查看对象选项的设置。 set print static-members这个选项表示，当显示一个C++对象中的内容是，是否显示其中的静态数据成员。默认是on。 show print static-members查看静态数据成员选项设置。 set print vtbl当此选项打开时，GDB将用比较规整的格式来显示虚函数表时。其默认是关闭的。 show print vtbl查看虚函数显示格式的选项。 历史记录当你用GDB的print查看程序运行时的数据时，你每一个print都会被GDB记录下来。GDB会以$1, $2, $3 …..这样的方式为你每一个print命令编上号。于是，你可以使用这个编号访问以前的表达式，如$1。这个功能所带来的好处是，如果你先前输入了一个比较长的表达式，如果你还想查看这个表达式的值，你可以使用历史记录来访问，省去了重复输入。 GDB环境变量你可以在GDB的调试环境中定义自己的变量，用来保存一些调试程序中的运行数据。要定义一个GDB的变量很简单只需。使用GDB的set命令。GDB的环境变量和UNIX一样，也是以$起头。如：set $foo = *object_ptr 使用环境变量时，GDB会在你第一次使用时创建这个变量，而在以后的使用中，则直接对其賦值。环境变量没有类型，你可以给环境变量定义任一的类型。包括结构体和数组。 show convenience该命令查看当前所设置的所有的环境变量。这是一个比较强大的功能，环境变量和程序变量的交互使用，将使得程序调试更为灵活便捷。例如：12set $i = 0 print bar[$i++]-&gt;contents 于是，当你就不必，print bar[0]-&gt;contents, print bar[1]-&gt;contents地输入命令了。输入这样的命令后，只用敲回车，重复执行上一条语句，环境变量会自动累加，从而完成逐个输出的功能。 查看寄存器要查看寄存器的值，很简单，可以使用如下命令： info registers查看寄存器的情况。（除了浮点寄存器） info all-registers查看所有寄存器的情况。（包括浮点寄存器） info registers查看所指定的寄存器的情况。寄存器中放置了程序运行时的数据，比如程序当前运行的指令地址（ip），程序的当前堆栈地址（sp）等等。你同样可以使用print命令来访问寄存器的情况，只需要在寄存器名字前加一个$符号就可以了。如：p $eip。 改变程序的执行 一旦使用GDB挂上被调试程序，当程序运行起来后，你可以根据自己的调试思路来动态地在GDB中更改当前被调试程序的运行线路或是其变量的值，这个强大的功能能够让你更好的调试你的程序，比如，你可以在程序的一次运行中走遍程序的所有分支。 修改变量值修改被调试程序运行时的变量值，在GDB中很容易实现，使用GDB的print命令即可完成。如：1(gdb) print x=4 x=4这个表达式是C/C++的语法，意为把变量x的值修改为4，如果你当前调试的语言是Pascal，那么你可以使用Pascal的语法：x:=4。在某些时候，很有可能你的变量和GDB中的参数冲突，如： 123456(gdb) whatis width type = double (gdb) p width $4 = 13 (gdb) set width=47 Invalid syntax in expression. 因为，set width是GDB的命令，所以，出现了“Invalid syntax in expression”的设置错误，此时，你可以使用set var命令来告诉GDB，width不是你GDB的参数，而是程序的变量名，如：(gdb) set var width=47 另外，还可能有些情况，GDB并不报告这种错误，所以保险起见，在你改变程序变量取值时，最好都使用set var格式的GDB命令。 跳转执行一般来说，被调试程序会按照程序代码的运行顺序依次执行。GDB提供了乱序执行的功能，也就是说，GDB可以修改程序的执行顺序，可以让程序执行随意跳跃。这个功能可以由GDB的jump命令来完：1jump 指定下一条语句的运行点。可以是文件的行号，可以是file:line格式，可以是+num这种偏移量格式。表式着下一条运行语句从哪里开始。注意，jump命令不会改变当前的程序栈中的内容，所以，当你从一个函数跳到另一个函数时，当函数运行完返回时进行弹栈操作时必然会发生错误，可能结果还是非常奇怪的，甚至于产生程序Core Dump。所以最好是同一个函数中进行跳转。 熟悉汇编的人都知道，程序运行时，有一个寄存器用于保存当前代码所在的内存地址。所以，jump命令也就是改变了这个寄存器中的值。于是，你可以使用“set $pc”来更改跳转执行的地址。如：set $pc = 0x485 产生信号量使用singal命令，可以产生一个信号量给被调试的程序。如：中断信号Ctrl+C。这非常方便于程序的调试，可以在程序运行的任意位置设置断点，并在该断点用GDB产生一个信号量，这种精确地在某处产生信号非常有利程序的调试。 语法是：signal ，UNIX的系统信号量通常从1到15。所以取值也在这个范围。single命令和shell的kill命令不同，系统的kill命令发信号给被调试程序时，是由GDB截获的，而single命令所发出一信号则是直接发给被调试程序的。 强制函数返回如果你的调试断点在某个函数中，并还有语句没有执行完。你可以使用return命令强制函数忽略还没有执行的语句并返回。return使用return命令取消当前函数的执行，并立即返回，如果指定了，那么该表达式的值会被认作函数的返回值。 强制调用函数 call表达式中可以一是函数，以此达到强制调用函数的目的。并显示函数的返回值，如果函数返回值是void，那么就不显示。 另一个相似的命令也可以完成这一功能——print，print后面可以跟表达式，所以也可以用他来调用函数，print和call的不同是，如果函数返回void，call则不显示，print则显示函数返回值，并把该值存入历史数据中。 GDB支持下列语言：C, C++, Fortran, PASCAL, Java, Chill, assembly, 和 Modula-2。一般说来，GDB会根据你所调试的程序来确定当然的调试语言，比如：发现文件名后缀为“.c”的，GDB会认为是C程序。文件名后缀为“.C, .cc, .cp, .cpp, .cxx, .c++”的，GDB会认为是C++程序。而后缀是“.f, .F”的，GDB会认为是Fortran程序，还有，后缀为如果是“.s, .S”的会认为是汇编语言。 也就是说，GDB会根据你所调试的程序的语言，来设置自己的语言环境，并让GDB的命令跟着语言环境的改变而改变。比如一些GDB命令需要用到表达式或变量时，这些表达式或变量的语法，完全是根据当前的语言环境而改变的。例如C/C++中对指针的语法是*p，而在Modula-2中则是p^。并且，如果你当前的程序是由几种不同语言一同编译成的，那到在调试过程中，GDB也能根据不同的语言自动地切换语言环境。这种跟着语言环境而改变的功能，真是体贴开发人员的一种设计。 下面是几个相关于GDB语言环境的命令：show language查看当前的语言环境。如果GDB不能识为你所调试的编程语言，那么，C语言被认为是默认的环境。 info frame查看当前函数的程序语言。 info source查看当前文件的程序语言。如果GDB没有检测出当前的程序语言，那么你也可以手动设置当前的程序语言。使用set language命令即可做到。当set language命令后什么也不跟的话，你可以查看GDB所支持的语言种类：123456789101112(gdb) set language The currently understood settings are: local or auto Automatic setting based on source file c Use the C language c++ Use the C++ language asm Use the Asm language chill Use the Chill language fortran Use the Fortran language java Use the Java language modula-2 Use the Modula-2 language pascal Use the Pascal language scheme Use the Scheme language 于是你可以在set language后跟上被列出来的程序语言名，来设置当前的语言环境。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由Leetcode807引发的memset问题]]></title>
    <url>%2F2019%2F04%2F09%2F%E7%94%B1Leetcode807%E5%BC%95%E5%8F%91%E7%9A%84memset%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[做Leetcode807时遇到了memset初始化整个数组的问题，好久不用memset了，有些生疏了。 对数组来说，只能初始化为0，或者-1，其他的时候数字是不正确的。而对于字符数组来说，任意字符都可以。 123456789101112131415161718192021222324252627// 1. 字符数组初始化为&apos;A&apos;char a[5];memset(a, &apos;A&apos;, 5); // OK!memset(a, 0, sizeof(char) * 5); // OK! // 2. 整数数组初始化为0int a[5];memset(a, 0, sizeof(int) * 5); // OK!memset(a, 0, 20); // OK! // 3. 动态字符数组初始化为&apos;A&apos;char* a = new char[5];memset(a, &apos;A&apos;, 5); // OK!memset(a, 0, sizeof(char) * 5); // OK! // 错误用法及改正用法示例：memset(a, &apos;A&apos;, sizeof(a)); // wrong! sizeof(a)相当于sizeof(char*)memset(a, &apos;A&apos;, sizeof(a[0]) * 5); // OK! // 4. 整数数组初始化为非0int a[5];fill(a, a+5, 1); // OK!fill_n(a, 5, 1); // OK! // 错误用法示例：memset(a, 1, 5); // wrong!memset(a, 1, sizeof(int) * 5) // wrong! 字符数组是字符型的，字符型占据内存大小是1Byte，而memset函数也是以字节为单位进行赋值的，所以你输出没有问题。而int数组是整型的，使用 memset还是按字节赋值，这样赋值完以后，每个数组元素的值实际上是0x01010101即十进制的16843009 memset主要用于字符型数组的初始化，整数型数组初始化为0时可以用memset。 memset在初始化动态数组时不能sizeof(数组名)，而应该sizeof(元素)*元素个数。 fill (fill_n)是超级大法，万物皆可fill。]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode807. Max Increase to Keep City Skyline]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode807%2F</url>
    <content type="text"><![CDATA[Max Increase to Keep City SkylineMedium In a 2 dimensional array grid, each value grid[i][j] represents the height of a building located there. We are allowed to increase the height of any number of buildings, by any amount (the amounts can be different for different buildings). Height 0 is considered to be a building as well. At the end, the “skyline” when viewed from all four directions of the grid, i.e. top, bottom, left, and right, must be the same as the skyline of the original grid. A city’s skyline is the outer contour of the rectangles formed by all the buildings when viewed from a distance. See the following example. What is the maximum total sum that the height of the buildings can be increased? Example:123456789101112131415161718Input: grid = [[3,0,8,4],[2,4,5,7],[9,2,6,3],[0,3,1,0]]Output: 35Explanation: The grid is:[ [3, 0, 8, 4], [2, 4, 5, 7], [9, 2, 6, 3], [0, 3, 1, 0] ]The skyline viewed from top or bottom is: [9, 4, 8, 7]The skyline viewed from left or right is: [8, 7, 9, 3]The grid after increasing the height of buildings without affecting skylines is:gridNew = [ [8, 4, 8, 7], [7, 4, 7, 7], [9, 4, 8, 7], [3, 3, 3, 3] ] Notes: 1 &lt; grid.length = grid[0].length &lt;= 50. All heights grid[i][j] are in the range [0, 100]. All buildings in grid[i][j] occupy the entire grid cell: that is, they are a 1 x 1 x grid[i][j] rectangular prism. 这道题非常简单，首先找到每行每列的最大值，然后每个元素要小于对应的最大值中的小者，比如grid[0][0]要小于topmax[0]和leftmax[0]之中的最小值，grid[0][1]要小于topmax[0]和leftmax[1]之中的最小值。为什么花了这么长时间呢，是因为傻逼了，max数组设成了4爆了。。。煞笔。。。 1234567891011121314151617181920212223class Solution &#123;public: int maxIncreaseKeepingSkyline(vector&lt;vector&lt;int&gt;&gt;&amp; grid) &#123; int length = grid[0].size(); int* topmax,*leftmax; topmax=(int*)malloc(sizeof(int)*length); leftmax=(int*)malloc(sizeof(int)*length); for(int i=0;i&lt;length;i++) topmax[i]=leftmax[i]=0; for(int i=0;i&lt;length;i++) for(int j=0;j&lt;length;j++)&#123; if(grid[i][j]&gt;topmax[i]) topmax[i]=grid[i][j]; if(grid[i][j]&gt;leftmax[j]) leftmax[j]=grid[i][j]; &#125; int result=0; for(int i=0;i&lt;length;i++) for(int j=0;j&lt;length;j++) result += ((leftmax[j]&gt;topmax[i]?topmax[i]:leftmax[j])-grid[i][j]); return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++标准库之stack]]></title>
    <url>%2F2019%2F04%2F09%2FC-%E6%A0%87%E5%87%86%E5%BA%93%E4%B9%8Bstack%2F</url>
    <content type="text"><![CDATA[函数名 功能 复杂度 size() 返回栈的元素数 O(1) top() 返回栈顶的元素 O(1) pop() 从栈中取出并删除元素 O(1) push(x) 向栈中添加元素x O(1) empty() 在栈为空时返回true O(1) 贴一些代码12345678910111213141516171819202122#include &quot;stdafx.h&quot;#include&lt;iostream&gt;#include&lt;stack&gt;using namespace std;int main()&#123; stack&lt;int&gt; S; S.push(3); S.push(7); S.push(1); cout &lt;&lt; S.size() &lt;&lt; &quot; &quot;; cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.push(5); cout &lt;&lt; S.top() &lt;&lt; &quot; &quot;; S.pop(); cout &lt;&lt; S.top() &lt;&lt; endl; return 0;&#125;]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1021. Remove Outermost Parentheses]]></title>
    <url>%2F2019%2F04%2F09%2FLeetcode1021%2F</url>
    <content type="text"><![CDATA[Remove Outermost ParenthesesEasy A valid parentheses string is either empty (“”), “(“ + A + “)”, or A + B, where A and B are valid parentheses strings, and + represents string concatenation. For example, “”, “()”, “(())()”, and “(()(()))” are all valid parentheses strings. A valid parentheses string S is primitive if it is nonempty, and there does not exist a way to split it into S = A+B, with A and B nonempty valid parentheses strings. Given a valid parentheses string S, consider its primitive decomposition: S = P_1 + P_2 + … + P_k, where P_i are primitive valid parentheses strings. Return S after removing the outermost parentheses of every primitive string in the primitive decomposition of S. Example 1:12345Input: &quot;(()())(())&quot;Output: &quot;()()()&quot;Explanation: The input string is &quot;(()())(())&quot;, with primitive decomposition &quot;(()())&quot; + &quot;(())&quot;.After removing outer parentheses of each part, this is &quot;()()&quot; + &quot;()&quot; = &quot;()()()&quot;. Example 2:12345Input: &quot;(()())(())(()(()))&quot;Output: &quot;()()()()(())&quot;Explanation: The input string is &quot;(()())(())(()(()))&quot;, with primitive decomposition &quot;(()())&quot; + &quot;(())&quot; + &quot;(()(()))&quot;.After removing outer parentheses of each part, this is &quot;()()&quot; + &quot;()&quot; + &quot;()(())&quot; = &quot;()()()()(())&quot;. Example 3:12345Input: &quot;()()&quot;Output: &quot;&quot;Explanation: The input string is &quot;()()&quot;, with primitive decomposition &quot;()&quot; + &quot;()&quot;.After removing outer parentheses of each part, this is &quot;&quot; + &quot;&quot; = &quot;&quot;. Note: S.length &lt;= 10000 S[i] is “(“ or “)” S is a valid parentheses string 比较简单，把最外边的一层括号移走，可以用栈，也可以用计数器。如果遇到左括号且栈不空说明这个左括号不是外边的括号，加到结果中，再把这个左括号压栈；如果是右括号，就先弹出栈，再判断如果栈不空则说明这个右括号也不是外边的括号，加到结果中。 不知道为啥我这个这么慢，反正过了就行。 123456789101112131415161718192021class Solution &#123;public: string removeOuterParentheses(string S) &#123; string result=&quot;&quot;; int length = S.length(); int ss=0; for(int i=0;i&lt;length;i++)&#123; if(S[i]==&apos;(&apos;)&#123; if(ss!=0) result=result+&apos;(&apos;; ss++; &#125; else if(S[i]==&apos;)&apos;)&#123; ss--; if(ss!=0) result=result+&quot;)&quot;; &#125; &#125; return result; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode9. Palindrome Number]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode9%2F</url>
    <content type="text"><![CDATA[Palindrome NumberEasy Determine whether an integer is a palindrome. An integer is a palindrome when it reads the same backward as forward. Example 1:12Input: 121Output: true Example 2:123Input: -121Output: falseExplanation: From left to right, it reads -121. From right to left, it becomes 121-. Therefore it is not a palindrome. Example 3:123Input: 10Output: falseExplanation: Reads 01 from right to left. Therefore it is not a palindrome. Follow up: Could you solve it without converting the integer to a string? 回文数，如果是负数直接返回false，正数的话转成string再判断。 12345678910111213141516171819202122class Solution &#123;public: bool isPalindrome(int x) &#123; int i=0; if(x&lt;0) return false; int length = 0; int str[100000]; while(x&gt;0)&#123; str[i++]=(x%10); x/=10; &#125; int middle = i/2; int j=0; while(j&lt;middle)&#123; if(str[j]!=str[i-1-j]) return false; j++; &#125; return true; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode26. Remove Duplicates from Sorted Array]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode26%2F</url>
    <content type="text"><![CDATA[Remove Duplicates from Sorted ArrayEasy Given a sorted array nums, remove the duplicates in-place such that each element appear only once and return the new length. Do not allocate extra space for another array, you must do this by modifying the input array in-place with O(1) extra memory. Example 1:12345Given nums = [1,1,2],Your function should return length = 2, with the first two elements of nums being 1 and 2 respectively.It doesn&apos;t matter what you leave beyond the returned length. Example 2:12345Given nums = [0,0,1,1,1,2,2,3,3,4],Your function should return length = 5, with the first five elements of nums being modified to 0, 1, 2, 3, and 4 respectively.It doesn&apos;t matter what values are set beyond the returned length. Clarification: Confused why the returned value is an integer but your answer is an array? Note that the input array is passed in by reference, which means modification to the input array will be known to the caller as well. Internally you can think of this:12345678// nums is passed in by reference. (i.e., without making a copy)int len = removeDuplicates(nums);// any modification to nums in your function would be known by the caller.// using the length returned by your function, it prints the first len elements.for (int i = 0; i &lt; len; i++) &#123; print(nums[i]);&#125; 真的是非常简单的一道题，但是因为某种原因WA了好几次。。。去掉重复的数并返回去重之后的长度。12345678910111213141516class Solution &#123;public: int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123; int length=nums.size(); if(length==0) return 0; int j=0; for(int i=1;i&lt;length;i++)&#123; if(nums[i]!=nums[j])&#123; j++; nums[j]=nums[i]; &#125; &#125; return j+1; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode1.Two Sum]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode1%2F</url>
    <content type="text"><![CDATA[Two SumEasy Given an array of integers, return indices of the two numbers such that they add up to a specific target. You may assume that each input would have exactly one solution, and you may not use the same element twice. Example:12345Given nums = [2, 7, 11, 15], target = 9,Because nums[0] + nums[1] = 2 + 7 = 9,return [0, 1]. 也十分简单，不知道啥时候做的了，现在补上。就是找一对数，使二者之和等于target，可以暴力，也可以用巧妙的方法，下边有巧妙方法，是从solution中找的。 我的方法：12345678910111213141516class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123; vector&lt;int&gt; result; int length = nums.size(),j=-1; for(int i=0;i&lt;length;i++)&#123; for(j=i+1;j&lt;length;j++) if(nums[j]==target-nums[i])&#123; result.push_back(i); result.push_back(j); return result; &#125; &#125; return result; &#125;&#125;; 跟我一样的方法，用java实现：12345678910111213public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; map.put(nums[i], i); &#125; for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement) &amp;&amp; map.get(complement) != i) &#123; return new int[] &#123; i, map.get(complement) &#125;; &#125; &#125; throw new IllegalArgumentException(&quot;No two sum solution&quot;);&#125; 第三种方法：One-pass Hash TableIt turns out we can do it in one-pass. While we iterate and inserting elements into the table, we also look back to check if current element’s complement already exists in the table. If it exists, we have found a solution and return immediately.1234567891011public int[] twoSum(int[] nums, int target) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; int complement = target - nums[i]; if (map.containsKey(complement)) &#123; return new int[] &#123; map.get(complement), i &#125;; &#125; map.put(nums[i], i); &#125; throw new IllegalArgumentException(&quot;No two sum solution&quot;);&#125; 反正都是很简单的。。。]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leetcode2. Add Two Numbers]]></title>
    <url>%2F2019%2F04%2F07%2FLeetcode2%2F</url>
    <content type="text"><![CDATA[Add Two NumbersMedium You are given two non-empty linked lists representing two non-negative integers. The digits are stored in reverse order and each of their nodes contain a single digit. Add the two numbers and return it as a linked list. You may assume the two numbers do not contain any leading zero, except the number 0 itself. Example:123Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 0 -&gt; 8Explanation: 342 + 465 = 807. 非常简单，给两个链表，相当于两个数，不过是倒着的，然后求这两个数的和再转换成链表。只是第一次用类的方法做题，不太习惯，然后对链表的使用也快忘光了，这是一个良好的开始吧。 1234567891011121314151617181920212223242526272829303132/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; long int ll1=0,ll2=0,result = 0; ListNode* head=new ListNode(0); ListNode* curr=head; int t=0;//jinwei while(l1 != NULL || l2 != NULL)&#123; ll1 = (l1!=NULL)? l1-&gt;val:0; ll2 = (l2!=NULL)? l2-&gt;val:0; int sum=t+ll1+ll2; t=sum/10; curr-&gt;next=new ListNode(sum%10); curr=curr-&gt;next; if(l1!=NULL) l1=l1-&gt;next; if(l2!=NULL) l2=l2-&gt;next; &#125; if(t&gt;0) &#123; curr-&gt;next=new ListNode(t); &#125; return head-&gt;next; &#125;&#125;;]]></content>
      <tags>
        <tag>Leetcode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给自己的博客加上各种控件]]></title>
    <url>%2F2019%2F04%2F05%2F%E7%BB%99%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2%E5%8A%A0%E4%B8%8A%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[1&lt;!-- &lt;iframe src=&quot;/resource/test_pdf.pdf&quot; width=&quot;700&quot; height=&quot;600&quot;&gt;&lt;/iframe&gt; --&gt; 12&lt;input type=&quot;button&quot; value=&quot;我是一个按钮&quot;onclick=&quot;javascrtpt:window.location.href=&apos;http://blog.sina.com.cn/mleavs&apos;&quot;&gt; 触发一个函数跳转：1234567&lt;script&gt;function jump()&#123; window.location.href=&quot;http://blog.sina.com.cn/mleavs&quot;;&#125;&lt;/script&gt;&lt;input type=&quot;button&quot; value=&quot;我是一个按钮&quot; onclick=javascrtpt:jump()&gt; 如何给自己的博客加上图片，这是一个介绍，也是备忘。 1.首先把blog（hexo）目录下的_config.yml里的post_asset_folder:设置为true； 2.在blog（hexo）目录下执行:1npm install hexo-asset-image --save 3.在blog（hexo）目录下运行hexo n “博客名”来生成md博客时，会在_post目录下看到一个与博客同名的文件夹。 4.将想要上传的图片先扔到文件夹下，然后在博客中使用markdown的格式引入图片：1![你想要输入的替代文字](xxxx/图片名.jpg) ps：因为博客名和文件夹名字相同，所以不需要绝对路径，只要xxxx是文件夹的名字就可以了。 5.然后，使用hexo g部署的时候，进入public\2018\04\19\index.html文件中查看相关字段，可以发现html标签内的语句是img src = “2018/04/19/xxxx/图片名.jpg”而不是img src=”xxxx.图片名.jpg”，这就成功了，当然前面步骤操作正确的话，这一步也不用检查。 6.测试的话当然要拿微博小姐姐来测试啦，附上微博链接严屹南啊 这是第一种方法，也可以在source文件夹下建立img文件夹，把要引用的图片文件放到这个文件夹里，然后使用/img/...使用图片，测试如下 1![微博上最喜欢的小姐姐](/img/1.jpg)]]></content>
      <tags>
        <tag>日常</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机系统研究的一些视频与文章]]></title>
    <url>%2F2019%2F04%2F05%2F%E5%BE%AE%E5%8D%9A%E7%9C%8B%E5%88%B0%E7%9A%84%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%A0%94%E7%A9%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E8%A7%86%E9%A2%91%E4%B8%8E%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[Videos Perspectives on Research Productivity (In Chinese) What My Mentors Taught Me (In Chinese) A Reflection on First 10 Years in Academia (In Chinese) Articles How (and How Not) to Write a Good Systems Paper (In English) Slides(In Chinese) How to Read a CS Research Paper? (In English) THE PH.D. GRIND (In English) 一名系统研究者的攀登之路 (In Chinese) 与学生合作开展研究的体会 (In Chinese) 对计算机体系结构研究的一点认识 (In Chinese) 印度 Bangalore 之 HPCA/PPoPP-2010 与会小记 (In Chinese) ISCA-2014与北美学术之旅 (In Chinese) PACT-2015 PC讨论会记录 (In Chinese) 博士五年总结 (In Chinese) 系统设计黄金法则: 简单之美 (In Chinese) 你的学生就是你的财富 (In Chinese) Your Students Are Your Legacy(In English) ISCA08见闻 (In Chinese) 与新晋图灵奖得主的虚拟对话 (In Chinese) 关于“国家重点实验室应该追求什么”的讨论 (In Chinese) SOSP 2013 Analysis (In Chinese) OSDI, SOSP与美国著名计算机系的调查 (In Chinese) HIT CS科班对计算机专业领域的汇编 (In Chinese) Prolific System Scholars (to 2013) (In English) ASPLOS系列专访—Mark D. Hill 谈体系结构：中国正从跟随者到创新领导者 (In Chinese) ASPLOS系列专访—Shan Lu谈bug finding：学术研究应超前于产品 (In Chinese) ASPLOS系列专访—李涛谈学术研究和学生培养 (In Chinese)]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cpp的tr1_function使用]]></title>
    <url>%2F2019%2F04%2F04%2Fcpp%E7%9A%84std_tr1_function%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[介绍 function是一种通用、多态的函数封装。std::function的实例可以对任何可以调用的目标 进行存储、复制、和调用操作，这些目标包括函数、lambda表达式、绑定表达式、以及其它函数对象等。（c++11起的版本可用） function（和bind一样）可以实现类似函数指针的功能，却比函数指针更加灵活（体现在占位符上面），尤其是在很多成员调用同一个函数（仅仅是参数类型不同）的时候比较方便。 特点： 1.可以作为函数和成员函数。 2.可做回调函数，取代函数指针。 3.可作为函数的参数，从外部控制函数内部的行为。 示例代码 先看一下下面这块代码： 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;#include &lt;tr1/functional&gt;typedef std::tr1::function&lt;void()&gt; HandleEvent;class Animal&#123;public: Animal()&#123;&#125; ~Animal()&#123;&#125; static void Move()&#123; std::cout&lt;&lt;&quot;I am moving...\n&quot;; &#125;&#125;;class Fish: public Animal&#123;public: Fish()&#123;&#125; ~Fish()&#123;&#125; static void Move()&#123; std::cout&lt;&lt;&quot;I am swimming...\n&quot;; &#125;&#125;;int main()&#123; std::tr1::function&lt;void()&gt; move = &amp;Animal::Move; move(); move = &amp;Fish::Move; move(); return 0;&#125; Animal类是父类，Fish继承于Animal。测试程序中分别将子类和父类的Move()函数地址赋值给function的指针。调用的结果如下： 12I am moving… I am swimming… 为了体现function可以作为函数的参数传入，我们再写一个函数加到原来的代码中进行测试： 1234567891011121314151617181920212223void Moving(int option, std::tr1::function&lt;void()&gt; move)&#123; if(option &amp; 1 == 0)&#123; //如果option为偶数，则执行Animal类中的Move方法 move = &amp;Animal::Move; &#125; else&#123; move = &amp;Fish::Move; &#125; move();&#125;int main()&#123; std::tr1::function&lt;void()&gt; move = &amp;Animal::Move; move(); move = &amp;Fish::Move; move(); std::cout&lt;&lt;&quot;-------------divid line------------\n&quot;; Moving(4,move); return 0;&#125; 测试结果如下： 1234I am moving… I am swimming… ————-divid line———— I am moving…]]></content>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[What I want to learn]]></title>
    <url>%2F2019%2F04%2F04%2Fbookmark%2F</url>
    <content type="text"><![CDATA[Markdown参考https://blog.csdn.net/u014061630/article/details/81359144 想读的书《深度探索C++对象模型（Inside The C++ Object Model ）》 《algorithm》 《UNIX环境高级编程》 《数据结构与算法经典问题解析》 《高性能并行珠玑》 各种书签矩阵求导刘咏彬分享 汇编语言8086笔记 不基于旋转的treap 数据结构与算法(c++)——跳跃表(skip list) 块状链表 Targan算法 有向图强连通分量 树状数组 2-3-4Tree 后台开发面试问题整理 解读Raft（一 算法基础） 彻底弄懂HTTP缓存机制及原理 TCP的数据流——滑动窗口，拥塞窗口，慢启动，Nagle算法，经受时延的确认等 TCP协议总结–停止等待协议,连续ARQ协议,滑动窗口协议 tcp的半连接与完全连接队列 - go4it - 简书 数位dp总结 之 从入门到模板 IP分片和TCP分片的区别 TCP-IP详解：糊涂窗口综合症（Silly Window syndrome） STL源码剖析—红黑树原理详解上 CSDN博客 valgrind 的使用简介 堆排算法的分析与总结 HTTP必知必会——常见面试题总结 ORM框架使用优缺点 高性能服务开发之定时器 Https协议详解 图解SSL/TLS协议 - 阮一峰的网络日志 HTTPS 原理解析 TCP系列13—重传—3、协议中RTO计算和RTO定时器维护 【经典算法】——KMP，深入讲解next数组的求解 HTTP Session、Cookie机制详解 HttpSession详解 HTTP的长连接和短连接 关于TCP乱序和重传的问题 DNS 原理入门 - 阮一峰的网络日志 数据结构专题——线段树 一步一步理解线段树 HTTP详解(1)-工作原理 浅谈数位DP socket编程中write、read和send、recv之间的区别 树状数组彻底入门 B树与B+树 胜者树与败者树 拓扑排序的原理及其实现 Manacher算法–O(n)回文子串算法 二叉树、B树、B+树、B*树 B树、B-树、B+树、B*树详解（转） 红黑树(一)之 原理和算法详细介绍 平衡二叉树详解]]></content>
      <tags>
        <tag>积累</tag>
      </tags>
  </entry>
</search>
